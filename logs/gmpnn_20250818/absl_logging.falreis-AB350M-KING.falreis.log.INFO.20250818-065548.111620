I0818 06:55:51.187774 131052307244544 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0818 06:55:51.188422 131052307244544 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0818 06:55:51.417926 131052307244544 run.py:411] Model: triplet_gmpnn ['activity_selector']
I0818 06:55:51.418024 131052307244544 run.py:413] algorithms ['activity_selector']
I0818 06:55:51.418206 131052307244544 run.py:414] train_lengths ['3', '4', '7', '11', '13', '15', '16']
I0818 06:55:51.418243 131052307244544 run.py:415] train_batch_size 32
I0818 06:55:51.418341 131052307244544 run.py:416] val_batch_size 32
I0818 06:55:51.418373 131052307244544 run.py:417] test_batch_size 32
I0818 06:55:51.418402 131052307244544 run.py:418] chunked_training True
I0818 06:55:51.418519 131052307244544 run.py:419] chunk_length 8
I0818 06:55:51.418550 131052307244544 run.py:420] train_steps 10000
I0818 06:55:51.418581 131052307244544 run.py:421] eval_every 50
I0818 06:55:51.418612 131052307244544 run.py:422] test_every 500
I0818 06:55:51.418641 131052307244544 run.py:423] hidden_size 128
I0818 06:55:51.418669 131052307244544 run.py:424] nb_msg_passing_steps 1
I0818 06:55:51.418696 131052307244544 run.py:425] learning_rate 0.001
I0818 06:55:51.418792 131052307244544 run.py:426] grad_clip_max_norm 1.0
I0818 06:55:51.418823 131052307244544 run.py:427] dropout_prob 0.0
I0818 06:55:51.418851 131052307244544 run.py:428] hint_teacher_forcing 0.0
I0818 06:55:51.418879 131052307244544 run.py:429] hint_mode encoded_decoded
I0818 06:55:51.418985 131052307244544 run.py:430] hint_repred_mode soft
I0818 06:55:51.419014 131052307244544 run.py:431] use_ln False
I0818 06:55:51.419043 131052307244544 run.py:432] use_lstm True
I0818 06:55:51.419070 131052307244544 run.py:433] nb_triplet_fts 8
I0818 06:55:51.419097 131052307244544 run.py:434] encoder_init xavier_on_scalars
I0818 06:55:51.419136 131052307244544 run.py:435] processor_type triplet_gmpnn
I0818 06:55:51.419165 131052307244544 run.py:436] checkpoint_path CLRS30
I0818 06:55:51.419193 131052307244544 run.py:437] dataset_path CLRS30
I0818 06:55:51.419220 131052307244544 run.py:438] freeze_processor False
I0818 06:55:51.419248 131052307244544 run.py:439] reduction min
I0818 06:55:51.419276 131052307244544 run.py:440] activation elu
I0818 06:55:51.419306 131052307244544 run.py:441] restore_model 
I0818 06:55:51.419334 131052307244544 run.py:442] gated True
I0818 06:55:51.419362 131052307244544 run.py:443] gated_activation sigmoid
I0818 06:55:51.422008 131052307244544 run.py:469] Creating samplers for algo activity_selector
W0818 06:55:51.422208 131052307244544 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0818 06:55:51.422460 131052307244544 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0818 06:55:51.615746 131052307244544 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0818 06:55:51.844449 131052307244544 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0818 06:55:52.084361 131052307244544 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0818 06:55:52.380553 131052307244544 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0818 06:55:52.708691 131052307244544 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0818 06:55:53.068845 131052307244544 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0818 06:55:53.446458 131052307244544 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0818 06:55:53.446732 131052307244544 samplers.py:124] Creating a dataset with 64 samples.
I0818 06:55:53.472224 131052307244544 run.py:255] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0818 06:55:53.472915 131052307244544 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0818 06:55:53.475717 131052307244544 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0818 06:55:53.478702 131052307244544 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0818 06:55:53.529249 131052307244544 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W0818 06:55:53.549890 131052307244544 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x773079ab7420> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0818 06:56:25.548518 131052307244544 run.py:692] Algo activity_selector step 0 current loss 4.301664, current_train_items 32.
I0818 06:56:31.202067 131052307244544 run.py:727] (val) algo activity_selector step 0: {'selected': 0.059880239520958084, 'score': 0.059880239520958084, 'examples_seen': 32, 'step': 0, 'algorithm': 'activity_selector'}
I0818 06:56:31.202237 131052307244544 run.py:748] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.060, val scores are: activity_selector: 0.060
I0818 06:57:43.839692 131052307244544 run.py:692] Algo activity_selector step 50 current loss 4.067295, current_train_items 1600.
I0818 06:57:43.860527 131052307244544 run.py:727] (val) algo activity_selector step 50: {'selected': 0.6384180790960452, 'score': 0.6384180790960452, 'examples_seen': 1600, 'step': 50, 'algorithm': 'activity_selector'}
I0818 06:57:43.860683 131052307244544 run.py:748] Checkpointing best model, best avg val score was 0.060, current avg val score is 0.638, val scores are: activity_selector: 0.638
I0818 06:57:44.809688 131052307244544 run.py:692] Algo activity_selector step 100 current loss 4.193387, current_train_items 3136.
I0818 06:57:44.832675 131052307244544 run.py:727] (val) algo activity_selector step 100: {'selected': 0.7131782945736433, 'score': 0.7131782945736433, 'examples_seen': 3136, 'step': 100, 'algorithm': 'activity_selector'}
I0818 06:57:44.832821 131052307244544 run.py:748] Checkpointing best model, best avg val score was 0.638, current avg val score is 0.713, val scores are: activity_selector: 0.713
I0818 06:57:45.769785 131052307244544 run.py:692] Algo activity_selector step 150 current loss 5.452799, current_train_items 4704.
I0818 06:57:45.794325 131052307244544 run.py:727] (val) algo activity_selector step 150: {'selected': 0.7253886010362695, 'score': 0.7253886010362695, 'examples_seen': 4704, 'step': 150, 'algorithm': 'activity_selector'}
I0818 06:57:45.794478 131052307244544 run.py:748] Checkpointing best model, best avg val score was 0.713, current avg val score is 0.725, val scores are: activity_selector: 0.725
I0818 06:57:46.718342 131052307244544 run.py:692] Algo activity_selector step 200 current loss 5.203543, current_train_items 6272.
I0818 06:57:46.745596 131052307244544 run.py:727] (val) algo activity_selector step 200: {'selected': 0.7432675044883303, 'score': 0.7432675044883303, 'examples_seen': 6272, 'step': 200, 'algorithm': 'activity_selector'}
I0818 06:57:46.745741 131052307244544 run.py:748] Checkpointing best model, best avg val score was 0.725, current avg val score is 0.743, val scores are: activity_selector: 0.743
I0818 06:57:47.702492 131052307244544 run.py:692] Algo activity_selector step 250 current loss 5.337734, current_train_items 7776.
I0818 06:57:47.729460 131052307244544 run.py:727] (val) algo activity_selector step 250: {'selected': 0.7153502235469448, 'score': 0.7153502235469448, 'examples_seen': 7776, 'step': 250, 'algorithm': 'activity_selector'}
I0818 06:57:47.729607 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.743, current avg val score is 0.715, val scores are: activity_selector: 0.715
I0818 06:57:48.654034 131052307244544 run.py:692] Algo activity_selector step 300 current loss 2.083265, current_train_items 9376.
I0818 06:57:48.672898 131052307244544 run.py:727] (val) algo activity_selector step 300: {'selected': 0.6964028776978416, 'score': 0.6964028776978416, 'examples_seen': 9376, 'step': 300, 'algorithm': 'activity_selector'}
I0818 06:57:48.673042 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.743, current avg val score is 0.696, val scores are: activity_selector: 0.696
I0818 06:57:49.598502 131052307244544 run.py:692] Algo activity_selector step 350 current loss 2.869891, current_train_items 10976.
I0818 06:57:49.616786 131052307244544 run.py:727] (val) algo activity_selector step 350: {'selected': 0.7934426229508197, 'score': 0.7934426229508197, 'examples_seen': 10976, 'step': 350, 'algorithm': 'activity_selector'}
I0818 06:57:49.616930 131052307244544 run.py:748] Checkpointing best model, best avg val score was 0.743, current avg val score is 0.793, val scores are: activity_selector: 0.793
I0818 06:57:50.564286 131052307244544 run.py:692] Algo activity_selector step 400 current loss 2.483010, current_train_items 12512.
I0818 06:57:50.584740 131052307244544 run.py:727] (val) algo activity_selector step 400: {'selected': 0.7816901408450705, 'score': 0.7816901408450705, 'examples_seen': 12512, 'step': 400, 'algorithm': 'activity_selector'}
I0818 06:57:50.584884 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.793, current avg val score is 0.782, val scores are: activity_selector: 0.782
I0818 06:57:51.505568 131052307244544 run.py:692] Algo activity_selector step 450 current loss 4.086679, current_train_items 14048.
I0818 06:57:51.530832 131052307244544 run.py:727] (val) algo activity_selector step 450: {'selected': 0.8815533980582524, 'score': 0.8815533980582524, 'examples_seen': 14048, 'step': 450, 'algorithm': 'activity_selector'}
I0818 06:57:51.530977 131052307244544 run.py:748] Checkpointing best model, best avg val score was 0.793, current avg val score is 0.882, val scores are: activity_selector: 0.882
I0818 06:57:52.452164 131052307244544 run.py:692] Algo activity_selector step 500 current loss 5.859680, current_train_items 15552.
I0818 06:57:52.476934 131052307244544 run.py:727] (val) algo activity_selector step 500: {'selected': 0.7619047619047619, 'score': 0.7619047619047619, 'examples_seen': 15552, 'step': 500, 'algorithm': 'activity_selector'}
I0818 06:57:52.477079 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.882, current avg val score is 0.762, val scores are: activity_selector: 0.762
I0818 06:57:53.412711 131052307244544 run.py:692] Algo activity_selector step 550 current loss 4.292438, current_train_items 17152.
I0818 06:57:53.440897 131052307244544 run.py:727] (val) algo activity_selector step 550: {'selected': 0.8013937282229965, 'score': 0.8013937282229965, 'examples_seen': 17152, 'step': 550, 'algorithm': 'activity_selector'}
I0818 06:57:53.441041 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.882, current avg val score is 0.801, val scores are: activity_selector: 0.801
I0818 06:57:54.346653 131052307244544 run.py:692] Algo activity_selector step 600 current loss 4.062246, current_train_items 18656.
I0818 06:57:54.377040 131052307244544 run.py:727] (val) algo activity_selector step 600: {'selected': 0.8830188679245283, 'score': 0.8830188679245283, 'examples_seen': 18656, 'step': 600, 'algorithm': 'activity_selector'}
I0818 06:57:54.377192 131052307244544 run.py:748] Checkpointing best model, best avg val score was 0.882, current avg val score is 0.883, val scores are: activity_selector: 0.883
I0818 06:57:55.339080 131052307244544 run.py:692] Algo activity_selector step 650 current loss 0.959529, current_train_items 20256.
I0818 06:57:55.357203 131052307244544 run.py:727] (val) algo activity_selector step 650: {'selected': 0.822429906542056, 'score': 0.822429906542056, 'examples_seen': 20256, 'step': 650, 'algorithm': 'activity_selector'}
I0818 06:57:55.357347 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.883, current avg val score is 0.822, val scores are: activity_selector: 0.822
I0818 06:57:56.305306 131052307244544 run.py:692] Algo activity_selector step 700 current loss 1.973536, current_train_items 21824.
I0818 06:57:56.323939 131052307244544 run.py:727] (val) algo activity_selector step 700: {'selected': 0.7862903225806451, 'score': 0.7862903225806451, 'examples_seen': 21824, 'step': 700, 'algorithm': 'activity_selector'}
I0818 06:57:56.324096 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.883, current avg val score is 0.786, val scores are: activity_selector: 0.786
I0818 06:57:57.224132 131052307244544 run.py:692] Algo activity_selector step 750 current loss 2.262126, current_train_items 23392.
I0818 06:57:57.244569 131052307244544 run.py:727] (val) algo activity_selector step 750: {'selected': 0.8469184890656065, 'score': 0.8469184890656065, 'examples_seen': 23392, 'step': 750, 'algorithm': 'activity_selector'}
I0818 06:57:57.244714 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.883, current avg val score is 0.847, val scores are: activity_selector: 0.847
I0818 06:57:58.185503 131052307244544 run.py:692] Algo activity_selector step 800 current loss 3.243488, current_train_items 24928.
I0818 06:57:58.208147 131052307244544 run.py:727] (val) algo activity_selector step 800: {'selected': 0.8521400778210118, 'score': 0.8521400778210118, 'examples_seen': 24928, 'step': 800, 'algorithm': 'activity_selector'}
I0818 06:57:58.208296 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.883, current avg val score is 0.852, val scores are: activity_selector: 0.852
I0818 06:57:59.107686 131052307244544 run.py:692] Algo activity_selector step 850 current loss 3.665807, current_train_items 26496.
I0818 06:57:59.131583 131052307244544 run.py:727] (val) algo activity_selector step 850: {'selected': 0.8833333333333333, 'score': 0.8833333333333333, 'examples_seen': 26496, 'step': 850, 'algorithm': 'activity_selector'}
I0818 06:57:59.131729 131052307244544 run.py:748] Checkpointing best model, best avg val score was 0.883, current avg val score is 0.883, val scores are: activity_selector: 0.883
I0818 06:58:00.061478 131052307244544 run.py:692] Algo activity_selector step 900 current loss 3.901934, current_train_items 28032.
I0818 06:58:00.090044 131052307244544 run.py:727] (val) algo activity_selector step 900: {'selected': 0.8998178506375227, 'score': 0.8998178506375227, 'examples_seen': 28032, 'step': 900, 'algorithm': 'activity_selector'}
I0818 06:58:00.090201 131052307244544 run.py:748] Checkpointing best model, best avg val score was 0.883, current avg val score is 0.900, val scores are: activity_selector: 0.900
I0818 06:58:01.050400 131052307244544 run.py:692] Algo activity_selector step 950 current loss 1.385094, current_train_items 29568.
I0818 06:58:01.077793 131052307244544 run.py:727] (val) algo activity_selector step 950: {'selected': 0.7941787941787942, 'score': 0.7941787941787942, 'examples_seen': 29568, 'step': 950, 'algorithm': 'activity_selector'}
I0818 06:58:01.077948 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.900, current avg val score is 0.794, val scores are: activity_selector: 0.794
I0818 06:58:01.993360 131052307244544 run.py:692] Algo activity_selector step 1000 current loss 0.601438, current_train_items 31168.
I0818 06:58:02.011533 131052307244544 run.py:727] (val) algo activity_selector step 1000: {'selected': 0.9038461538461539, 'score': 0.9038461538461539, 'examples_seen': 31168, 'step': 1000, 'algorithm': 'activity_selector'}
I0818 06:58:02.011690 131052307244544 run.py:748] Checkpointing best model, best avg val score was 0.900, current avg val score is 0.904, val scores are: activity_selector: 0.904
I0818 06:58:02.987738 131052307244544 run.py:692] Algo activity_selector step 1050 current loss 2.291869, current_train_items 32736.
I0818 06:58:03.005834 131052307244544 run.py:727] (val) algo activity_selector step 1050: {'selected': 0.8109243697478992, 'score': 0.8109243697478992, 'examples_seen': 32736, 'step': 1050, 'algorithm': 'activity_selector'}
I0818 06:58:03.005980 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.904, current avg val score is 0.811, val scores are: activity_selector: 0.811
I0818 06:58:03.921853 131052307244544 run.py:692] Algo activity_selector step 1100 current loss 1.009646, current_train_items 34304.
I0818 06:58:03.944507 131052307244544 run.py:727] (val) algo activity_selector step 1100: {'selected': 0.8828125, 'score': 0.8828125, 'examples_seen': 34304, 'step': 1100, 'algorithm': 'activity_selector'}
I0818 06:58:03.944656 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.904, current avg val score is 0.883, val scores are: activity_selector: 0.883
I0818 06:58:04.855621 131052307244544 run.py:692] Algo activity_selector step 1150 current loss 0.803386, current_train_items 35808.
I0818 06:58:04.879004 131052307244544 run.py:727] (val) algo activity_selector step 1150: {'selected': 0.9473684210526314, 'score': 0.9473684210526314, 'examples_seen': 35808, 'step': 1150, 'algorithm': 'activity_selector'}
I0818 06:58:04.879156 131052307244544 run.py:748] Checkpointing best model, best avg val score was 0.904, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0818 06:58:05.796812 131052307244544 run.py:692] Algo activity_selector step 1200 current loss 4.247774, current_train_items 37344.
I0818 06:58:05.821798 131052307244544 run.py:727] (val) algo activity_selector step 1200: {'selected': 0.9532710280373833, 'score': 0.9532710280373833, 'examples_seen': 37344, 'step': 1200, 'algorithm': 'activity_selector'}
I0818 06:58:05.821953 131052307244544 run.py:748] Checkpointing best model, best avg val score was 0.947, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0818 06:58:06.755191 131052307244544 run.py:692] Algo activity_selector step 1250 current loss 3.887336, current_train_items 38944.
I0818 06:58:06.783669 131052307244544 run.py:727] (val) algo activity_selector step 1250: {'selected': 0.8612836438923396, 'score': 0.8612836438923396, 'examples_seen': 38944, 'step': 1250, 'algorithm': 'activity_selector'}
I0818 06:58:06.783816 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.953, current avg val score is 0.861, val scores are: activity_selector: 0.861
I0818 06:58:07.698559 131052307244544 run.py:692] Algo activity_selector step 1300 current loss 3.917555, current_train_items 40448.
I0818 06:58:07.729776 131052307244544 run.py:727] (val) algo activity_selector step 1300: {'selected': 0.9062500000000001, 'score': 0.9062500000000001, 'examples_seen': 40448, 'step': 1300, 'algorithm': 'activity_selector'}
I0818 06:58:07.729922 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.953, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0818 06:58:08.664051 131052307244544 run.py:692] Algo activity_selector step 1350 current loss 0.406051, current_train_items 42048.
I0818 06:58:08.682699 131052307244544 run.py:727] (val) algo activity_selector step 1350: {'selected': 0.923611111111111, 'score': 0.923611111111111, 'examples_seen': 42048, 'step': 1350, 'algorithm': 'activity_selector'}
I0818 06:58:08.682846 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.953, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0818 06:58:09.604845 131052307244544 run.py:692] Algo activity_selector step 1400 current loss 2.705603, current_train_items 43616.
I0818 06:58:09.623174 131052307244544 run.py:727] (val) algo activity_selector step 1400: {'selected': 0.8117154811715481, 'score': 0.8117154811715481, 'examples_seen': 43616, 'step': 1400, 'algorithm': 'activity_selector'}
I0818 06:58:09.623320 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.953, current avg val score is 0.812, val scores are: activity_selector: 0.812
I0818 06:58:10.534709 131052307244544 run.py:692] Algo activity_selector step 1450 current loss 0.882699, current_train_items 45152.
I0818 06:58:10.554664 131052307244544 run.py:727] (val) algo activity_selector step 1450: {'selected': 0.8905380333951762, 'score': 0.8905380333951762, 'examples_seen': 45152, 'step': 1450, 'algorithm': 'activity_selector'}
I0818 06:58:10.554809 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.953, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0818 06:58:11.480876 131052307244544 run.py:692] Algo activity_selector step 1500 current loss 3.676976, current_train_items 46720.
I0818 06:58:11.503881 131052307244544 run.py:727] (val) algo activity_selector step 1500: {'selected': 0.9522058823529412, 'score': 0.9522058823529412, 'examples_seen': 46720, 'step': 1500, 'algorithm': 'activity_selector'}
I0818 06:58:11.504028 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.953, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0818 06:58:12.411255 131052307244544 run.py:692] Algo activity_selector step 1550 current loss 2.577802, current_train_items 48256.
I0818 06:58:12.435638 131052307244544 run.py:727] (val) algo activity_selector step 1550: {'selected': 0.8937875751503007, 'score': 0.8937875751503007, 'examples_seen': 48256, 'step': 1550, 'algorithm': 'activity_selector'}
I0818 06:58:12.435785 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.953, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0818 06:58:13.345409 131052307244544 run.py:692] Algo activity_selector step 1600 current loss 4.242136, current_train_items 49824.
I0818 06:58:13.373939 131052307244544 run.py:727] (val) algo activity_selector step 1600: {'selected': 0.8689655172413794, 'score': 0.8689655172413794, 'examples_seen': 49824, 'step': 1600, 'algorithm': 'activity_selector'}
I0818 06:58:13.374084 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.953, current avg val score is 0.869, val scores are: activity_selector: 0.869
I0818 06:58:14.305459 131052307244544 run.py:692] Algo activity_selector step 1650 current loss 6.906521, current_train_items 51360.
I0818 06:58:14.336064 131052307244544 run.py:727] (val) algo activity_selector step 1650: {'selected': 0.9188191881918819, 'score': 0.9188191881918819, 'examples_seen': 51360, 'step': 1650, 'algorithm': 'activity_selector'}
I0818 06:58:14.336225 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.953, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0818 06:58:15.254546 131052307244544 run.py:692] Algo activity_selector step 1700 current loss 0.323284, current_train_items 52928.
I0818 06:58:15.273513 131052307244544 run.py:727] (val) algo activity_selector step 1700: {'selected': 0.8453947368421053, 'score': 0.8453947368421053, 'examples_seen': 52928, 'step': 1700, 'algorithm': 'activity_selector'}
I0818 06:58:15.273657 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.953, current avg val score is 0.845, val scores are: activity_selector: 0.845
I0818 06:58:16.229918 131052307244544 run.py:692] Algo activity_selector step 1750 current loss 1.619321, current_train_items 54528.
I0818 06:58:16.248501 131052307244544 run.py:727] (val) algo activity_selector step 1750: {'selected': 0.8929219600725953, 'score': 0.8929219600725953, 'examples_seen': 54528, 'step': 1750, 'algorithm': 'activity_selector'}
I0818 06:58:16.248646 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.953, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0818 06:58:17.149856 131052307244544 run.py:692] Algo activity_selector step 1800 current loss 0.599903, current_train_items 56096.
I0818 06:58:17.170172 131052307244544 run.py:727] (val) algo activity_selector step 1800: {'selected': 0.8929889298892989, 'score': 0.8929889298892989, 'examples_seen': 56096, 'step': 1800, 'algorithm': 'activity_selector'}
I0818 06:58:17.170320 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.953, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0818 06:58:18.102279 131052307244544 run.py:692] Algo activity_selector step 1850 current loss 2.908865, current_train_items 57600.
I0818 06:58:18.125332 131052307244544 run.py:727] (val) algo activity_selector step 1850: {'selected': 0.9359223300970874, 'score': 0.9359223300970874, 'examples_seen': 57600, 'step': 1850, 'algorithm': 'activity_selector'}
I0818 06:58:18.125481 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.953, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0818 06:58:19.016312 131052307244544 run.py:692] Algo activity_selector step 1900 current loss 3.844909, current_train_items 59200.
I0818 06:58:19.040826 131052307244544 run.py:727] (val) algo activity_selector step 1900: {'selected': 0.899803536345776, 'score': 0.899803536345776, 'examples_seen': 59200, 'step': 1900, 'algorithm': 'activity_selector'}
I0818 06:58:19.041025 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.953, current avg val score is 0.900, val scores are: activity_selector: 0.900
I0818 06:58:19.968095 131052307244544 run.py:692] Algo activity_selector step 1950 current loss 3.740880, current_train_items 60736.
I0818 06:58:19.996437 131052307244544 run.py:727] (val) algo activity_selector step 1950: {'selected': 0.9592233009708738, 'score': 0.9592233009708738, 'examples_seen': 60736, 'step': 1950, 'algorithm': 'activity_selector'}
I0818 06:58:19.996633 131052307244544 run.py:748] Checkpointing best model, best avg val score was 0.953, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0818 06:58:20.956331 131052307244544 run.py:692] Algo activity_selector step 2000 current loss 3.820814, current_train_items 62272.
I0818 06:58:20.983340 131052307244544 run.py:727] (val) algo activity_selector step 2000: {'selected': 0.9076923076923077, 'score': 0.9076923076923077, 'examples_seen': 62272, 'step': 2000, 'algorithm': 'activity_selector'}
I0818 06:58:20.983486 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.959, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0818 06:58:21.881152 131052307244544 run.py:692] Algo activity_selector step 2050 current loss 0.366150, current_train_items 63872.
I0818 06:58:21.900490 131052307244544 run.py:727] (val) algo activity_selector step 2050: {'selected': 0.9538461538461539, 'score': 0.9538461538461539, 'examples_seen': 63872, 'step': 2050, 'algorithm': 'activity_selector'}
I0818 06:58:21.900634 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.959, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0818 06:58:22.828056 131052307244544 run.py:692] Algo activity_selector step 2100 current loss 1.892482, current_train_items 65408.
I0818 06:58:22.846888 131052307244544 run.py:727] (val) algo activity_selector step 2100: {'selected': 0.9224652087475149, 'score': 0.9224652087475149, 'examples_seen': 65408, 'step': 2100, 'algorithm': 'activity_selector'}
I0818 06:58:22.847038 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.959, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0818 06:58:23.753804 131052307244544 run.py:692] Algo activity_selector step 2150 current loss 1.701780, current_train_items 66976.
I0818 06:58:23.773967 131052307244544 run.py:727] (val) algo activity_selector step 2150: {'selected': 0.8857715430861725, 'score': 0.8857715430861725, 'examples_seen': 66976, 'step': 2150, 'algorithm': 'activity_selector'}
I0818 06:58:23.774135 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.959, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0818 06:58:24.702142 131052307244544 run.py:692] Algo activity_selector step 2200 current loss 0.476053, current_train_items 68512.
I0818 06:58:24.726552 131052307244544 run.py:727] (val) algo activity_selector step 2200: {'selected': 0.9420560747663552, 'score': 0.9420560747663552, 'examples_seen': 68512, 'step': 2200, 'algorithm': 'activity_selector'}
I0818 06:58:24.726698 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.959, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0818 06:58:25.638942 131052307244544 run.py:692] Algo activity_selector step 2250 current loss 0.529176, current_train_items 70048.
I0818 06:58:25.663584 131052307244544 run.py:727] (val) algo activity_selector step 2250: {'selected': 0.9343629343629344, 'score': 0.9343629343629344, 'examples_seen': 70048, 'step': 2250, 'algorithm': 'activity_selector'}
I0818 06:58:25.663740 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.959, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0818 06:58:26.559726 131052307244544 run.py:692] Algo activity_selector step 2300 current loss 3.539649, current_train_items 71616.
I0818 06:58:26.588423 131052307244544 run.py:727] (val) algo activity_selector step 2300: {'selected': 0.9523809523809523, 'score': 0.9523809523809523, 'examples_seen': 71616, 'step': 2300, 'algorithm': 'activity_selector'}
I0818 06:58:26.588572 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.959, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0818 06:58:27.527266 131052307244544 run.py:692] Algo activity_selector step 2350 current loss 6.628623, current_train_items 73120.
I0818 06:58:27.558660 131052307244544 run.py:727] (val) algo activity_selector step 2350: {'selected': 0.9586466165413534, 'score': 0.9586466165413534, 'examples_seen': 73120, 'step': 2350, 'algorithm': 'activity_selector'}
I0818 06:58:27.558811 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.959, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0818 06:58:28.475870 131052307244544 run.py:692] Algo activity_selector step 2400 current loss 0.371249, current_train_items 74720.
I0818 06:58:28.494211 131052307244544 run.py:727] (val) algo activity_selector step 2400: {'selected': 0.946153846153846, 'score': 0.946153846153846, 'examples_seen': 74720, 'step': 2400, 'algorithm': 'activity_selector'}
I0818 06:58:28.494355 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.959, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0818 06:58:29.438567 131052307244544 run.py:692] Algo activity_selector step 2450 current loss 1.984916, current_train_items 76320.
I0818 06:58:29.457712 131052307244544 run.py:727] (val) algo activity_selector step 2450: {'selected': 0.9833333333333333, 'score': 0.9833333333333333, 'examples_seen': 76320, 'step': 2450, 'algorithm': 'activity_selector'}
I0818 06:58:29.457858 131052307244544 run.py:748] Checkpointing best model, best avg val score was 0.959, current avg val score is 0.983, val scores are: activity_selector: 0.983
I0818 06:58:30.381860 131052307244544 run.py:692] Algo activity_selector step 2500 current loss 0.514256, current_train_items 77856.
I0818 06:58:30.403056 131052307244544 run.py:727] (val) algo activity_selector step 2500: {'selected': 0.9439071566731141, 'score': 0.9439071566731141, 'examples_seen': 77856, 'step': 2500, 'algorithm': 'activity_selector'}
I0818 06:58:30.403214 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0818 06:58:31.323726 131052307244544 run.py:692] Algo activity_selector step 2550 current loss 3.092600, current_train_items 79392.
I0818 06:58:31.349231 131052307244544 run.py:727] (val) algo activity_selector step 2550: {'selected': 0.9469696969696969, 'score': 0.9469696969696969, 'examples_seen': 79392, 'step': 2550, 'algorithm': 'activity_selector'}
I0818 06:58:31.349378 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0818 06:58:32.293352 131052307244544 run.py:692] Algo activity_selector step 2600 current loss 3.147691, current_train_items 80960.
I0818 06:58:32.317886 131052307244544 run.py:727] (val) algo activity_selector step 2600: {'selected': 0.9500924214417746, 'score': 0.9500924214417746, 'examples_seen': 80960, 'step': 2600, 'algorithm': 'activity_selector'}
I0818 06:58:32.318035 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0818 06:58:33.252584 131052307244544 run.py:692] Algo activity_selector step 2650 current loss 3.410999, current_train_items 82528.
I0818 06:58:33.282521 131052307244544 run.py:727] (val) algo activity_selector step 2650: {'selected': 0.9313543599257885, 'score': 0.9313543599257885, 'examples_seen': 82528, 'step': 2650, 'algorithm': 'activity_selector'}
I0818 06:58:33.282666 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0818 06:58:34.222410 131052307244544 run.py:692] Algo activity_selector step 2700 current loss 3.738785, current_train_items 84064.
I0818 06:58:34.249609 131052307244544 run.py:727] (val) algo activity_selector step 2700: {'selected': 0.9595588235294117, 'score': 0.9595588235294117, 'examples_seen': 84064, 'step': 2700, 'algorithm': 'activity_selector'}
I0818 06:58:34.249759 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0818 06:58:35.172313 131052307244544 run.py:692] Algo activity_selector step 2750 current loss 0.236597, current_train_items 85632.
I0818 06:58:35.190772 131052307244544 run.py:727] (val) algo activity_selector step 2750: {'selected': 0.9556840077071291, 'score': 0.9556840077071291, 'examples_seen': 85632, 'step': 2750, 'algorithm': 'activity_selector'}
I0818 06:58:35.190918 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0818 06:58:36.135115 131052307244544 run.py:692] Algo activity_selector step 2800 current loss 1.857936, current_train_items 87200.
I0818 06:58:36.153821 131052307244544 run.py:727] (val) algo activity_selector step 2800: {'selected': 0.9425742574257426, 'score': 0.9425742574257426, 'examples_seen': 87200, 'step': 2800, 'algorithm': 'activity_selector'}
I0818 06:58:36.153966 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0818 06:58:37.061315 131052307244544 run.py:692] Algo activity_selector step 2850 current loss 1.820693, current_train_items 88800.
I0818 06:58:37.082294 131052307244544 run.py:727] (val) algo activity_selector step 2850: {'selected': 0.935064935064935, 'score': 0.935064935064935, 'examples_seen': 88800, 'step': 2850, 'algorithm': 'activity_selector'}
I0818 06:58:37.082445 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0818 06:58:38.019763 131052307244544 run.py:692] Algo activity_selector step 2900 current loss 2.744794, current_train_items 90304.
I0818 06:58:38.043139 131052307244544 run.py:727] (val) algo activity_selector step 2900: {'selected': 0.9366602687140115, 'score': 0.9366602687140115, 'examples_seen': 90304, 'step': 2900, 'algorithm': 'activity_selector'}
I0818 06:58:38.043298 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0818 06:58:38.929915 131052307244544 run.py:692] Algo activity_selector step 2950 current loss 5.442274, current_train_items 91840.
I0818 06:58:38.954540 131052307244544 run.py:727] (val) algo activity_selector step 2950: {'selected': 0.9323308270676691, 'score': 0.9323308270676691, 'examples_seen': 91840, 'step': 2950, 'algorithm': 'activity_selector'}
I0818 06:58:38.954686 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0818 06:58:39.861072 131052307244544 run.py:692] Algo activity_selector step 3000 current loss 3.266961, current_train_items 93376.
I0818 06:58:39.890072 131052307244544 run.py:727] (val) algo activity_selector step 3000: {'selected': 0.9361702127659575, 'score': 0.9361702127659575, 'examples_seen': 93376, 'step': 3000, 'algorithm': 'activity_selector'}
I0818 06:58:39.890226 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0818 06:58:40.829000 131052307244544 run.py:692] Algo activity_selector step 3050 current loss 6.159970, current_train_items 94912.
I0818 06:58:40.860474 131052307244544 run.py:727] (val) algo activity_selector step 3050: {'selected': 0.964, 'score': 0.964, 'examples_seen': 94912, 'step': 3050, 'algorithm': 'activity_selector'}
I0818 06:58:40.860625 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0818 06:58:41.762794 131052307244544 run.py:692] Algo activity_selector step 3100 current loss 0.545614, current_train_items 96512.
I0818 06:58:41.781319 131052307244544 run.py:727] (val) algo activity_selector step 3100: {'selected': 0.9481765834932823, 'score': 0.9481765834932823, 'examples_seen': 96512, 'step': 3100, 'algorithm': 'activity_selector'}
I0818 06:58:41.781464 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0818 06:58:42.741085 131052307244544 run.py:692] Algo activity_selector step 3150 current loss 1.819940, current_train_items 98080.
I0818 06:58:42.759978 131052307244544 run.py:727] (val) algo activity_selector step 3150: {'selected': 0.9578544061302682, 'score': 0.9578544061302682, 'examples_seen': 98080, 'step': 3150, 'algorithm': 'activity_selector'}
I0818 06:58:42.760137 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0818 06:58:43.703627 131052307244544 run.py:692] Algo activity_selector step 3200 current loss 0.494347, current_train_items 99648.
I0818 06:58:43.724423 131052307244544 run.py:727] (val) algo activity_selector step 3200: {'selected': 0.9267399267399268, 'score': 0.9267399267399268, 'examples_seen': 99648, 'step': 3200, 'algorithm': 'activity_selector'}
I0818 06:58:43.724570 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0818 06:58:44.635481 131052307244544 run.py:692] Algo activity_selector step 3250 current loss 0.474596, current_train_items 101152.
I0818 06:58:44.657876 131052307244544 run.py:727] (val) algo activity_selector step 3250: {'selected': 0.9475728155339805, 'score': 0.9475728155339805, 'examples_seen': 101152, 'step': 3250, 'algorithm': 'activity_selector'}
I0818 06:58:44.658023 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0818 06:58:45.602138 131052307244544 run.py:692] Algo activity_selector step 3300 current loss 2.835009, current_train_items 102752.
I0818 06:58:45.626021 131052307244544 run.py:727] (val) algo activity_selector step 3300: {'selected': 0.9333333333333332, 'score': 0.9333333333333332, 'examples_seen': 102752, 'step': 3300, 'algorithm': 'activity_selector'}
I0818 06:58:45.626188 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0818 06:58:46.522598 131052307244544 run.py:692] Algo activity_selector step 3350 current loss 3.274961, current_train_items 104320.
I0818 06:58:46.550552 131052307244544 run.py:727] (val) algo activity_selector step 3350: {'selected': 0.9583333333333334, 'score': 0.9583333333333334, 'examples_seen': 104320, 'step': 3350, 'algorithm': 'activity_selector'}
I0818 06:58:46.550700 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0818 06:58:47.485947 131052307244544 run.py:692] Algo activity_selector step 3400 current loss 3.494561, current_train_items 105824.
I0818 06:58:47.512943 131052307244544 run.py:727] (val) algo activity_selector step 3400: {'selected': 0.8716094032549729, 'score': 0.8716094032549729, 'examples_seen': 105824, 'step': 3400, 'algorithm': 'activity_selector'}
I0818 06:58:47.513093 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.872, val scores are: activity_selector: 0.872
I0818 06:58:48.434802 131052307244544 run.py:692] Algo activity_selector step 3450 current loss 0.229878, current_train_items 107424.
I0818 06:58:48.452587 131052307244544 run.py:727] (val) algo activity_selector step 3450: {'selected': 0.9647495361781075, 'score': 0.9647495361781075, 'examples_seen': 107424, 'step': 3450, 'algorithm': 'activity_selector'}
I0818 06:58:48.452733 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0818 06:58:49.382396 131052307244544 run.py:692] Algo activity_selector step 3500 current loss 1.512471, current_train_items 108992.
I0818 06:58:49.401072 131052307244544 run.py:727] (val) algo activity_selector step 3500: {'selected': 0.9377431906614786, 'score': 0.9377431906614786, 'examples_seen': 108992, 'step': 3500, 'algorithm': 'activity_selector'}
I0818 06:58:49.401229 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0818 06:58:50.334737 131052307244544 run.py:692] Algo activity_selector step 3550 current loss 0.318525, current_train_items 110560.
I0818 06:58:50.355510 131052307244544 run.py:727] (val) algo activity_selector step 3550: {'selected': 0.9623762376237623, 'score': 0.9623762376237623, 'examples_seen': 110560, 'step': 3550, 'algorithm': 'activity_selector'}
I0818 06:58:50.355656 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0818 06:58:51.281648 131052307244544 run.py:692] Algo activity_selector step 3600 current loss 3.188025, current_train_items 112096.
I0818 06:58:51.305120 131052307244544 run.py:727] (val) algo activity_selector step 3600: {'selected': 0.9588014981273408, 'score': 0.9588014981273408, 'examples_seen': 112096, 'step': 3600, 'algorithm': 'activity_selector'}
I0818 06:58:51.305269 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0818 06:58:52.220277 131052307244544 run.py:692] Algo activity_selector step 3650 current loss 3.779708, current_train_items 113600.
I0818 06:58:52.245194 131052307244544 run.py:727] (val) algo activity_selector step 3650: {'selected': 0.9629629629629629, 'score': 0.9629629629629629, 'examples_seen': 113600, 'step': 3650, 'algorithm': 'activity_selector'}
I0818 06:58:52.245343 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.983, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0818 06:58:53.174929 131052307244544 run.py:692] Algo activity_selector step 3700 current loss 3.287862, current_train_items 115168.
I0818 06:58:53.203393 131052307244544 run.py:727] (val) algo activity_selector step 3700: {'selected': 0.9980506822612086, 'score': 0.9980506822612086, 'examples_seen': 115168, 'step': 3700, 'algorithm': 'activity_selector'}
I0818 06:58:53.203541 131052307244544 run.py:748] Checkpointing best model, best avg val score was 0.983, current avg val score is 0.998, val scores are: activity_selector: 0.998
I0818 06:58:54.156602 131052307244544 run.py:692] Algo activity_selector step 3750 current loss 5.365323, current_train_items 116704.
I0818 06:58:54.187733 131052307244544 run.py:727] (val) algo activity_selector step 3750: {'selected': 0.9153846153846155, 'score': 0.9153846153846155, 'examples_seen': 116704, 'step': 3750, 'algorithm': 'activity_selector'}
I0818 06:58:54.187880 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0818 06:58:55.107057 131052307244544 run.py:692] Algo activity_selector step 3800 current loss 0.306540, current_train_items 118304.
I0818 06:58:55.125160 131052307244544 run.py:727] (val) algo activity_selector step 3800: {'selected': 0.9122137404580153, 'score': 0.9122137404580153, 'examples_seen': 118304, 'step': 3800, 'algorithm': 'activity_selector'}
I0818 06:58:55.125336 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0818 06:58:56.077165 131052307244544 run.py:692] Algo activity_selector step 3850 current loss 1.720945, current_train_items 119872.
I0818 06:58:56.095890 131052307244544 run.py:727] (val) algo activity_selector step 3850: {'selected': 0.9186256781193489, 'score': 0.9186256781193489, 'examples_seen': 119872, 'step': 3850, 'algorithm': 'activity_selector'}
I0818 06:58:56.096036 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0818 06:58:56.993900 131052307244544 run.py:692] Algo activity_selector step 3900 current loss 0.807999, current_train_items 121440.
I0818 06:58:57.013941 131052307244544 run.py:727] (val) algo activity_selector step 3900: {'selected': 0.8988326848249028, 'score': 0.8988326848249028, 'examples_seen': 121440, 'step': 3900, 'algorithm': 'activity_selector'}
I0818 06:58:57.014109 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0818 06:58:57.936582 131052307244544 run.py:692] Algo activity_selector step 3950 current loss 2.347279, current_train_items 122944.
I0818 06:58:57.959474 131052307244544 run.py:727] (val) algo activity_selector step 3950: {'selected': 0.9608938547486033, 'score': 0.9608938547486033, 'examples_seen': 122944, 'step': 3950, 'algorithm': 'activity_selector'}
I0818 06:58:57.959629 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0818 06:58:58.883022 131052307244544 run.py:692] Algo activity_selector step 4000 current loss 2.057031, current_train_items 124544.
I0818 06:58:58.906924 131052307244544 run.py:727] (val) algo activity_selector step 4000: {'selected': 0.974757281553398, 'score': 0.974757281553398, 'examples_seen': 124544, 'step': 4000, 'algorithm': 'activity_selector'}
I0818 06:58:58.907082 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0818 06:58:59.821667 131052307244544 run.py:692] Algo activity_selector step 4050 current loss 3.693915, current_train_items 126080.
I0818 06:58:59.849482 131052307244544 run.py:727] (val) algo activity_selector step 4050: {'selected': 0.967741935483871, 'score': 0.967741935483871, 'examples_seen': 126080, 'step': 4050, 'algorithm': 'activity_selector'}
I0818 06:58:59.849662 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0818 06:59:00.790618 131052307244544 run.py:692] Algo activity_selector step 4100 current loss 2.945283, current_train_items 127616.
I0818 06:59:00.818173 131052307244544 run.py:727] (val) algo activity_selector step 4100: {'selected': 0.9521988527724665, 'score': 0.9521988527724665, 'examples_seen': 127616, 'step': 4100, 'algorithm': 'activity_selector'}
I0818 06:59:00.818317 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0818 06:59:01.723267 131052307244544 run.py:692] Algo activity_selector step 4150 current loss 0.285671, current_train_items 129216.
I0818 06:59:01.741121 131052307244544 run.py:727] (val) algo activity_selector step 4150: {'selected': 0.9407114624505929, 'score': 0.9407114624505929, 'examples_seen': 129216, 'step': 4150, 'algorithm': 'activity_selector'}
I0818 06:59:01.741267 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0818 06:59:02.673797 131052307244544 run.py:692] Algo activity_selector step 4200 current loss 1.460113, current_train_items 130752.
I0818 06:59:02.692309 131052307244544 run.py:727] (val) algo activity_selector step 4200: {'selected': 0.9418386491557224, 'score': 0.9418386491557224, 'examples_seen': 130752, 'step': 4200, 'algorithm': 'activity_selector'}
I0818 06:59:02.692459 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0818 06:59:03.629130 131052307244544 run.py:692] Algo activity_selector step 4250 current loss 0.496544, current_train_items 132352.
I0818 06:59:03.648972 131052307244544 run.py:727] (val) algo activity_selector step 4250: {'selected': 0.945179584120983, 'score': 0.945179584120983, 'examples_seen': 132352, 'step': 4250, 'algorithm': 'activity_selector'}
I0818 06:59:03.649124 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0818 06:59:04.556316 131052307244544 run.py:692] Algo activity_selector step 4300 current loss 0.558635, current_train_items 133856.
I0818 06:59:04.579292 131052307244544 run.py:727] (val) algo activity_selector step 4300: {'selected': 0.952191235059761, 'score': 0.952191235059761, 'examples_seen': 133856, 'step': 4300, 'algorithm': 'activity_selector'}
I0818 06:59:04.579436 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0818 06:59:05.490189 131052307244544 run.py:692] Algo activity_selector step 4350 current loss 3.653162, current_train_items 135424.
I0818 06:59:05.514493 131052307244544 run.py:727] (val) algo activity_selector step 4350: {'selected': 0.9921875, 'score': 0.9921875, 'examples_seen': 135424, 'step': 4350, 'algorithm': 'activity_selector'}
I0818 06:59:05.514642 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.992, val scores are: activity_selector: 0.992
I0818 06:59:06.424801 131052307244544 run.py:692] Algo activity_selector step 4400 current loss 3.446768, current_train_items 137024.
I0818 06:59:06.453131 131052307244544 run.py:727] (val) algo activity_selector step 4400: {'selected': 0.979757085020243, 'score': 0.979757085020243, 'examples_seen': 137024, 'step': 4400, 'algorithm': 'activity_selector'}
I0818 06:59:06.453278 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.980, val scores are: activity_selector: 0.980
I0818 06:59:07.393909 131052307244544 run.py:692] Algo activity_selector step 4450 current loss 4.288663, current_train_items 138496.
I0818 06:59:07.425163 131052307244544 run.py:727] (val) algo activity_selector step 4450: {'selected': 0.9496981891348089, 'score': 0.9496981891348089, 'examples_seen': 138496, 'step': 4450, 'algorithm': 'activity_selector'}
I0818 06:59:07.425309 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0818 06:59:08.361327 131052307244544 run.py:692] Algo activity_selector step 4500 current loss 0.235096, current_train_items 140128.
I0818 06:59:08.380007 131052307244544 run.py:727] (val) algo activity_selector step 4500: {'selected': 0.9649805447470816, 'score': 0.9649805447470816, 'examples_seen': 140128, 'step': 4500, 'algorithm': 'activity_selector'}
I0818 06:59:08.380163 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0818 06:59:09.301280 131052307244544 run.py:692] Algo activity_selector step 4550 current loss 1.429013, current_train_items 141696.
I0818 06:59:09.320229 131052307244544 run.py:727] (val) algo activity_selector step 4550: {'selected': 0.9699248120300752, 'score': 0.9699248120300752, 'examples_seen': 141696, 'step': 4550, 'algorithm': 'activity_selector'}
I0818 06:59:09.320375 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0818 06:59:10.231576 131052307244544 run.py:692] Algo activity_selector step 4600 current loss 0.289532, current_train_items 143232.
I0818 06:59:10.251786 131052307244544 run.py:727] (val) algo activity_selector step 4600: {'selected': 0.9448818897637795, 'score': 0.9448818897637795, 'examples_seen': 143232, 'step': 4600, 'algorithm': 'activity_selector'}
I0818 06:59:10.251931 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0818 06:59:11.168451 131052307244544 run.py:692] Algo activity_selector step 4650 current loss 3.306364, current_train_items 144768.
I0818 06:59:11.191361 131052307244544 run.py:727] (val) algo activity_selector step 4650: {'selected': 0.9590643274853802, 'score': 0.9590643274853802, 'examples_seen': 144768, 'step': 4650, 'algorithm': 'activity_selector'}
I0818 06:59:11.191505 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0818 06:59:12.124864 131052307244544 run.py:692] Algo activity_selector step 4700 current loss 0.372475, current_train_items 146304.
I0818 06:59:12.149433 131052307244544 run.py:727] (val) algo activity_selector step 4700: {'selected': 0.9606299212598425, 'score': 0.9606299212598425, 'examples_seen': 146304, 'step': 4700, 'algorithm': 'activity_selector'}
I0818 06:59:12.149580 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0818 06:59:13.071922 131052307244544 run.py:692] Algo activity_selector step 4750 current loss 3.384844, current_train_items 147872.
I0818 06:59:13.100654 131052307244544 run.py:727] (val) algo activity_selector step 4750: {'selected': 0.9826589595375722, 'score': 0.9826589595375722, 'examples_seen': 147872, 'step': 4750, 'algorithm': 'activity_selector'}
I0818 06:59:13.100799 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.983, val scores are: activity_selector: 0.983
I0818 06:59:14.027839 131052307244544 run.py:692] Algo activity_selector step 4800 current loss 3.416909, current_train_items 149408.
I0818 06:59:14.054881 131052307244544 run.py:727] (val) algo activity_selector step 4800: {'selected': 0.9606299212598425, 'score': 0.9606299212598425, 'examples_seen': 149408, 'step': 4800, 'algorithm': 'activity_selector'}
I0818 06:59:14.055029 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0818 06:59:14.977930 131052307244544 run.py:692] Algo activity_selector step 4850 current loss 0.364862, current_train_items 150976.
I0818 06:59:14.996168 131052307244544 run.py:727] (val) algo activity_selector step 4850: {'selected': 0.9484126984126984, 'score': 0.9484126984126984, 'examples_seen': 150976, 'step': 4850, 'algorithm': 'activity_selector'}
I0818 06:59:14.996314 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0818 06:59:15.934443 131052307244544 run.py:692] Algo activity_selector step 4900 current loss 1.661609, current_train_items 152544.
I0818 06:59:15.955605 131052307244544 run.py:727] (val) algo activity_selector step 4900: {'selected': 0.9618320610687022, 'score': 0.9618320610687022, 'examples_seen': 152544, 'step': 4900, 'algorithm': 'activity_selector'}
I0818 06:59:15.955768 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0818 06:59:16.877815 131052307244544 run.py:692] Algo activity_selector step 4950 current loss 0.374150, current_train_items 154144.
I0818 06:59:16.898196 131052307244544 run.py:727] (val) algo activity_selector step 4950: {'selected': 0.9361702127659575, 'score': 0.9361702127659575, 'examples_seen': 154144, 'step': 4950, 'algorithm': 'activity_selector'}
I0818 06:59:16.898344 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0818 06:59:17.826909 131052307244544 run.py:692] Algo activity_selector step 5000 current loss 2.665654, current_train_items 155648.
I0818 06:59:17.851142 131052307244544 run.py:727] (val) algo activity_selector step 5000: {'selected': 0.9673704414587332, 'score': 0.9673704414587332, 'examples_seen': 155648, 'step': 5000, 'algorithm': 'activity_selector'}
I0818 06:59:17.851288 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0818 06:59:18.764107 131052307244544 run.py:692] Algo activity_selector step 5050 current loss 2.986938, current_train_items 157216.
I0818 06:59:18.788269 131052307244544 run.py:727] (val) algo activity_selector step 5050: {'selected': 0.9575289575289575, 'score': 0.9575289575289575, 'examples_seen': 157216, 'step': 5050, 'algorithm': 'activity_selector'}
I0818 06:59:18.788416 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0818 06:59:19.720720 131052307244544 run.py:692] Algo activity_selector step 5100 current loss 3.587398, current_train_items 158784.
I0818 06:59:19.748739 131052307244544 run.py:727] (val) algo activity_selector step 5100: {'selected': 0.9617706237424548, 'score': 0.9617706237424548, 'examples_seen': 158784, 'step': 5100, 'algorithm': 'activity_selector'}
I0818 06:59:19.748884 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0818 06:59:20.665042 131052307244544 run.py:692] Algo activity_selector step 5150 current loss 3.776797, current_train_items 160288.
I0818 06:59:20.695999 131052307244544 run.py:727] (val) algo activity_selector step 5150: {'selected': 0.9601593625498007, 'score': 0.9601593625498007, 'examples_seen': 160288, 'step': 5150, 'algorithm': 'activity_selector'}
I0818 06:59:20.696154 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0818 06:59:21.615304 131052307244544 run.py:692] Algo activity_selector step 5200 current loss 0.259101, current_train_items 161920.
I0818 06:59:21.633511 131052307244544 run.py:727] (val) algo activity_selector step 5200: {'selected': 0.9553903345724907, 'score': 0.9553903345724907, 'examples_seen': 161920, 'step': 5200, 'algorithm': 'activity_selector'}
I0818 06:59:21.633669 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0818 06:59:22.562793 131052307244544 run.py:692] Algo activity_selector step 5250 current loss 1.689665, current_train_items 163456.
I0818 06:59:22.581437 131052307244544 run.py:727] (val) algo activity_selector step 5250: {'selected': 0.9398496240601503, 'score': 0.9398496240601503, 'examples_seen': 163456, 'step': 5250, 'algorithm': 'activity_selector'}
I0818 06:59:22.581583 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0818 06:59:23.493613 131052307244544 run.py:692] Algo activity_selector step 5300 current loss 0.289995, current_train_items 165024.
I0818 06:59:23.514399 131052307244544 run.py:727] (val) algo activity_selector step 5300: {'selected': 0.9613259668508287, 'score': 0.9613259668508287, 'examples_seen': 165024, 'step': 5300, 'algorithm': 'activity_selector'}
I0818 06:59:23.514545 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0818 06:59:24.420604 131052307244544 run.py:692] Algo activity_selector step 5350 current loss 0.374767, current_train_items 166560.
I0818 06:59:24.443827 131052307244544 run.py:727] (val) algo activity_selector step 5350: {'selected': 0.9551020408163264, 'score': 0.9551020408163264, 'examples_seen': 166560, 'step': 5350, 'algorithm': 'activity_selector'}
I0818 06:59:24.443973 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0818 06:59:25.356857 131052307244544 run.py:692] Algo activity_selector step 5400 current loss 6.040287, current_train_items 168096.
I0818 06:59:25.381314 131052307244544 run.py:727] (val) algo activity_selector step 5400: {'selected': 0.9632495164410056, 'score': 0.9632495164410056, 'examples_seen': 168096, 'step': 5400, 'algorithm': 'activity_selector'}
I0818 06:59:25.381461 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0818 06:59:26.280510 131052307244544 run.py:692] Algo activity_selector step 5450 current loss 3.592592, current_train_items 169664.
I0818 06:59:26.309123 131052307244544 run.py:727] (val) algo activity_selector step 5450: {'selected': 0.9595375722543352, 'score': 0.9595375722543352, 'examples_seen': 169664, 'step': 5450, 'algorithm': 'activity_selector'}
I0818 06:59:26.309273 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0818 06:59:27.239286 131052307244544 run.py:692] Algo activity_selector step 5500 current loss 2.149333, current_train_items 171168.
I0818 06:59:27.266542 131052307244544 run.py:727] (val) algo activity_selector step 5500: {'selected': 0.952561669829222, 'score': 0.952561669829222, 'examples_seen': 171168, 'step': 5500, 'algorithm': 'activity_selector'}
I0818 06:59:27.266693 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0818 06:59:28.192288 131052307244544 run.py:692] Algo activity_selector step 5550 current loss 0.216776, current_train_items 172768.
I0818 06:59:28.210645 131052307244544 run.py:727] (val) algo activity_selector step 5550: {'selected': 0.9069767441860465, 'score': 0.9069767441860465, 'examples_seen': 172768, 'step': 5550, 'algorithm': 'activity_selector'}
I0818 06:59:28.210803 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0818 06:59:29.127064 131052307244544 run.py:692] Algo activity_selector step 5600 current loss 1.712864, current_train_items 174336.
I0818 06:59:29.145516 131052307244544 run.py:727] (val) algo activity_selector step 5600: {'selected': 0.9660377358490567, 'score': 0.9660377358490567, 'examples_seen': 174336, 'step': 5600, 'algorithm': 'activity_selector'}
I0818 06:59:29.145662 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0818 06:59:30.075027 131052307244544 run.py:692] Algo activity_selector step 5650 current loss 0.192159, current_train_items 175904.
I0818 06:59:30.095422 131052307244544 run.py:727] (val) algo activity_selector step 5650: {'selected': 0.9722222222222222, 'score': 0.9722222222222222, 'examples_seen': 175904, 'step': 5650, 'algorithm': 'activity_selector'}
I0818 06:59:30.095570 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0818 06:59:31.016043 131052307244544 run.py:692] Algo activity_selector step 5700 current loss 3.222754, current_train_items 177440.
I0818 06:59:31.039512 131052307244544 run.py:727] (val) algo activity_selector step 5700: {'selected': 0.9720670391061451, 'score': 0.9720670391061451, 'examples_seen': 177440, 'step': 5700, 'algorithm': 'activity_selector'}
I0818 06:59:31.039658 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0818 06:59:31.948689 131052307244544 run.py:692] Algo activity_selector step 5750 current loss 2.791750, current_train_items 178976.
I0818 06:59:31.973431 131052307244544 run.py:727] (val) algo activity_selector step 5750: {'selected': 0.9769230769230769, 'score': 0.9769230769230769, 'examples_seen': 178976, 'step': 5750, 'algorithm': 'activity_selector'}
I0818 06:59:31.973577 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0818 06:59:32.909808 131052307244544 run.py:692] Algo activity_selector step 5800 current loss 3.603868, current_train_items 180576.
I0818 06:59:32.937767 131052307244544 run.py:727] (val) algo activity_selector step 5800: {'selected': 0.9742574257425742, 'score': 0.9742574257425742, 'examples_seen': 180576, 'step': 5800, 'algorithm': 'activity_selector'}
I0818 06:59:32.937913 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0818 06:59:33.843452 131052307244544 run.py:692] Algo activity_selector step 5850 current loss 3.718407, current_train_items 182080.
I0818 06:59:33.874651 131052307244544 run.py:727] (val) algo activity_selector step 5850: {'selected': 0.9636711281070746, 'score': 0.9636711281070746, 'examples_seen': 182080, 'step': 5850, 'algorithm': 'activity_selector'}
I0818 06:59:33.874798 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0818 06:59:34.820525 131052307244544 run.py:692] Algo activity_selector step 5900 current loss 0.157367, current_train_items 183680.
I0818 06:59:34.838594 131052307244544 run.py:727] (val) algo activity_selector step 5900: {'selected': 0.9574861367837338, 'score': 0.9574861367837338, 'examples_seen': 183680, 'step': 5900, 'algorithm': 'activity_selector'}
I0818 06:59:34.838741 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0818 06:59:35.782230 131052307244544 run.py:692] Algo activity_selector step 5950 current loss 1.569148, current_train_items 185248.
I0818 06:59:35.800501 131052307244544 run.py:727] (val) algo activity_selector step 5950: {'selected': 0.9463220675944335, 'score': 0.9463220675944335, 'examples_seen': 185248, 'step': 5950, 'algorithm': 'activity_selector'}
I0818 06:59:35.800661 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0818 06:59:36.709905 131052307244544 run.py:692] Algo activity_selector step 6000 current loss 0.289389, current_train_items 186816.
I0818 06:59:36.730407 131052307244544 run.py:727] (val) algo activity_selector step 6000: {'selected': 0.9606299212598426, 'score': 0.9606299212598426, 'examples_seen': 186816, 'step': 6000, 'algorithm': 'activity_selector'}
I0818 06:59:36.730556 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0818 06:59:37.679132 131052307244544 run.py:692] Algo activity_selector step 6050 current loss 2.509893, current_train_items 188352.
I0818 06:59:37.702706 131052307244544 run.py:727] (val) algo activity_selector step 6050: {'selected': 0.9608938547486033, 'score': 0.9608938547486033, 'examples_seen': 188352, 'step': 6050, 'algorithm': 'activity_selector'}
I0818 06:59:37.702854 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0818 06:59:38.594087 131052307244544 run.py:692] Algo activity_selector step 6100 current loss 3.821280, current_train_items 189888.
I0818 06:59:38.618749 131052307244544 run.py:727] (val) algo activity_selector step 6100: {'selected': 0.9498069498069497, 'score': 0.9498069498069497, 'examples_seen': 189888, 'step': 6100, 'algorithm': 'activity_selector'}
I0818 06:59:38.618897 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0818 06:59:39.540362 131052307244544 run.py:692] Algo activity_selector step 6150 current loss 3.652190, current_train_items 191424.
I0818 06:59:39.568419 131052307244544 run.py:727] (val) algo activity_selector step 6150: {'selected': 0.9821073558648111, 'score': 0.9821073558648111, 'examples_seen': 191424, 'step': 6150, 'algorithm': 'activity_selector'}
I0818 06:59:39.568566 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.982, val scores are: activity_selector: 0.982
I0818 06:59:40.514913 131052307244544 run.py:692] Algo activity_selector step 6200 current loss 1.939902, current_train_items 192960.
I0818 06:59:40.542467 131052307244544 run.py:727] (val) algo activity_selector step 6200: {'selected': 0.9651376146788991, 'score': 0.9651376146788991, 'examples_seen': 192960, 'step': 6200, 'algorithm': 'activity_selector'}
I0818 06:59:40.542614 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0818 06:59:41.461403 131052307244544 run.py:692] Algo activity_selector step 6250 current loss 0.135937, current_train_items 194560.
I0818 06:59:41.479521 131052307244544 run.py:727] (val) algo activity_selector step 6250: {'selected': 0.9418386491557224, 'score': 0.9418386491557224, 'examples_seen': 194560, 'step': 6250, 'algorithm': 'activity_selector'}
I0818 06:59:41.479666 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0818 06:59:42.420094 131052307244544 run.py:692] Algo activity_selector step 6300 current loss 1.476797, current_train_items 196128.
I0818 06:59:42.438369 131052307244544 run.py:727] (val) algo activity_selector step 6300: {'selected': 0.9820359281437125, 'score': 0.9820359281437125, 'examples_seen': 196128, 'step': 6300, 'algorithm': 'activity_selector'}
I0818 06:59:42.438514 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.982, val scores are: activity_selector: 0.982
I0818 06:59:43.373188 131052307244544 run.py:692] Algo activity_selector step 6350 current loss 0.259874, current_train_items 197696.
I0818 06:59:43.393447 131052307244544 run.py:727] (val) algo activity_selector step 6350: {'selected': 0.9407407407407408, 'score': 0.9407407407407408, 'examples_seen': 197696, 'step': 6350, 'algorithm': 'activity_selector'}
I0818 06:59:43.393592 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0818 06:59:44.306089 131052307244544 run.py:692] Algo activity_selector step 6400 current loss 0.550205, current_train_items 199200.
I0818 06:59:44.328601 131052307244544 run.py:727] (val) algo activity_selector step 6400: {'selected': 0.9434697855750488, 'score': 0.9434697855750488, 'examples_seen': 199200, 'step': 6400, 'algorithm': 'activity_selector'}
I0818 06:59:44.328752 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0818 06:59:45.247533 131052307244544 run.py:692] Algo activity_selector step 6450 current loss 1.965165, current_train_items 200768.
I0818 06:59:45.271340 131052307244544 run.py:727] (val) algo activity_selector step 6450: {'selected': 0.9453860640301317, 'score': 0.9453860640301317, 'examples_seen': 200768, 'step': 6450, 'algorithm': 'activity_selector'}
I0818 06:59:45.271485 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0818 06:59:46.201239 131052307244544 run.py:692] Algo activity_selector step 6500 current loss 3.279720, current_train_items 202368.
I0818 06:59:46.228411 131052307244544 run.py:727] (val) algo activity_selector step 6500: {'selected': 0.9650092081031307, 'score': 0.9650092081031307, 'examples_seen': 202368, 'step': 6500, 'algorithm': 'activity_selector'}
I0818 06:59:46.228558 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0818 06:59:47.153151 131052307244544 run.py:692] Algo activity_selector step 6550 current loss 3.601968, current_train_items 203840.
I0818 06:59:47.183758 131052307244544 run.py:727] (val) algo activity_selector step 6550: {'selected': 0.9568345323741007, 'score': 0.9568345323741007, 'examples_seen': 203840, 'step': 6550, 'algorithm': 'activity_selector'}
I0818 06:59:47.183904 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0818 06:59:48.134060 131052307244544 run.py:692] Algo activity_selector step 6600 current loss 0.135188, current_train_items 205472.
I0818 06:59:48.152316 131052307244544 run.py:727] (val) algo activity_selector step 6600: {'selected': 0.9449715370018976, 'score': 0.9449715370018976, 'examples_seen': 205472, 'step': 6600, 'algorithm': 'activity_selector'}
I0818 06:59:48.152462 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0818 06:59:49.075129 131052307244544 run.py:692] Algo activity_selector step 6650 current loss 1.502723, current_train_items 207040.
I0818 06:59:49.093735 131052307244544 run.py:727] (val) algo activity_selector step 6650: {'selected': 0.9705304518664047, 'score': 0.9705304518664047, 'examples_seen': 207040, 'step': 6650, 'algorithm': 'activity_selector'}
I0818 06:59:49.093881 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0818 06:59:50.002158 131052307244544 run.py:692] Algo activity_selector step 6700 current loss 0.709619, current_train_items 208576.
I0818 06:59:50.022365 131052307244544 run.py:727] (val) algo activity_selector step 6700: {'selected': 0.9236234458259324, 'score': 0.9236234458259324, 'examples_seen': 208576, 'step': 6700, 'algorithm': 'activity_selector'}
I0818 06:59:50.022514 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0818 06:59:50.958474 131052307244544 run.py:692] Algo activity_selector step 6750 current loss 3.189180, current_train_items 210144.
I0818 06:59:50.981371 131052307244544 run.py:727] (val) algo activity_selector step 6750: {'selected': 0.9562043795620437, 'score': 0.9562043795620437, 'examples_seen': 210144, 'step': 6750, 'algorithm': 'activity_selector'}
I0818 06:59:50.981518 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0818 06:59:51.873451 131052307244544 run.py:692] Algo activity_selector step 6800 current loss 3.240274, current_train_items 211680.
I0818 06:59:51.897905 131052307244544 run.py:727] (val) algo activity_selector step 6800: {'selected': 0.9449715370018975, 'score': 0.9449715370018975, 'examples_seen': 211680, 'step': 6800, 'algorithm': 'activity_selector'}
I0818 06:59:51.898053 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0818 06:59:52.814909 131052307244544 run.py:692] Algo activity_selector step 6850 current loss 3.597727, current_train_items 213248.
I0818 06:59:52.843243 131052307244544 run.py:727] (val) algo activity_selector step 6850: {'selected': 0.9652509652509652, 'score': 0.9652509652509652, 'examples_seen': 213248, 'step': 6850, 'algorithm': 'activity_selector'}
I0818 06:59:52.843391 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0818 06:59:53.759731 131052307244544 run.py:692] Algo activity_selector step 6900 current loss 0.404710, current_train_items 214784.
I0818 06:59:53.787480 131052307244544 run.py:727] (val) algo activity_selector step 6900: {'selected': 0.967741935483871, 'score': 0.967741935483871, 'examples_seen': 214784, 'step': 6900, 'algorithm': 'activity_selector'}
I0818 06:59:53.787628 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0818 06:59:54.700874 131052307244544 run.py:692] Algo activity_selector step 6950 current loss 0.395653, current_train_items 216352.
I0818 06:59:54.718981 131052307244544 run.py:727] (val) algo activity_selector step 6950: {'selected': 0.8835341365461846, 'score': 0.8835341365461846, 'examples_seen': 216352, 'step': 6950, 'algorithm': 'activity_selector'}
I0818 06:59:54.719138 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0818 06:59:55.679112 131052307244544 run.py:692] Algo activity_selector step 7000 current loss 1.522096, current_train_items 217952.
I0818 06:59:55.697854 131052307244544 run.py:727] (val) algo activity_selector step 7000: {'selected': 0.9294117647058823, 'score': 0.9294117647058823, 'examples_seen': 217952, 'step': 7000, 'algorithm': 'activity_selector'}
I0818 06:59:55.698019 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0818 06:59:56.599789 131052307244544 run.py:692] Algo activity_selector step 7050 current loss 0.257629, current_train_items 219520.
I0818 06:59:56.620620 131052307244544 run.py:727] (val) algo activity_selector step 7050: {'selected': 0.989816700610998, 'score': 0.989816700610998, 'examples_seen': 219520, 'step': 7050, 'algorithm': 'activity_selector'}
I0818 06:59:56.620768 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.990, val scores are: activity_selector: 0.990
I0818 06:59:57.549832 131052307244544 run.py:692] Algo activity_selector step 7100 current loss 2.525732, current_train_items 221024.
I0818 06:59:57.572607 131052307244544 run.py:727] (val) algo activity_selector step 7100: {'selected': 0.9582504970178927, 'score': 0.9582504970178927, 'examples_seen': 221024, 'step': 7100, 'algorithm': 'activity_selector'}
I0818 06:59:57.572768 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0818 06:59:58.473050 131052307244544 run.py:692] Algo activity_selector step 7150 current loss 0.457664, current_train_items 222560.
I0818 06:59:58.497216 131052307244544 run.py:727] (val) algo activity_selector step 7150: {'selected': 0.9425742574257425, 'score': 0.9425742574257425, 'examples_seen': 222560, 'step': 7150, 'algorithm': 'activity_selector'}
I0818 06:59:58.497363 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0818 06:59:59.433807 131052307244544 run.py:692] Algo activity_selector step 7200 current loss 3.272144, current_train_items 224128.
I0818 06:59:59.461766 131052307244544 run.py:727] (val) algo activity_selector step 7200: {'selected': 0.9774436090225564, 'score': 0.9774436090225564, 'examples_seen': 224128, 'step': 7200, 'algorithm': 'activity_selector'}
I0818 06:59:59.461913 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0818 07:00:00.395091 131052307244544 run.py:692] Algo activity_selector step 7250 current loss 3.426562, current_train_items 225664.
I0818 07:00:00.425904 131052307244544 run.py:727] (val) algo activity_selector step 7250: {'selected': 0.9814126394052045, 'score': 0.9814126394052045, 'examples_seen': 225664, 'step': 7250, 'algorithm': 'activity_selector'}
I0818 07:00:00.426050 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0818 07:00:01.360124 131052307244544 run.py:692] Algo activity_selector step 7300 current loss 0.169305, current_train_items 227264.
I0818 07:00:01.378648 131052307244544 run.py:727] (val) algo activity_selector step 7300: {'selected': 0.9604519774011299, 'score': 0.9604519774011299, 'examples_seen': 227264, 'step': 7300, 'algorithm': 'activity_selector'}
I0818 07:00:01.378795 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0818 07:00:02.321973 131052307244544 run.py:692] Algo activity_selector step 7350 current loss 1.921104, current_train_items 228800.
I0818 07:00:02.340171 131052307244544 run.py:727] (val) algo activity_selector step 7350: {'selected': 0.8801652892561982, 'score': 0.8801652892561982, 'examples_seen': 228800, 'step': 7350, 'algorithm': 'activity_selector'}
I0818 07:00:02.340321 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0818 07:00:03.254263 131052307244544 run.py:692] Algo activity_selector step 7400 current loss 0.212090, current_train_items 230368.
I0818 07:00:03.275183 131052307244544 run.py:727] (val) algo activity_selector step 7400: {'selected': 0.9669902912621358, 'score': 0.9669902912621358, 'examples_seen': 230368, 'step': 7400, 'algorithm': 'activity_selector'}
I0818 07:00:03.275328 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0818 07:00:04.202959 131052307244544 run.py:692] Algo activity_selector step 7450 current loss 0.297485, current_train_items 231904.
I0818 07:00:04.226291 131052307244544 run.py:727] (val) algo activity_selector step 7450: {'selected': 0.9698189134808854, 'score': 0.9698189134808854, 'examples_seen': 231904, 'step': 7450, 'algorithm': 'activity_selector'}
I0818 07:00:04.226439 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0818 07:00:05.139520 131052307244544 run.py:692] Algo activity_selector step 7500 current loss 3.021161, current_train_items 233472.
I0818 07:00:05.163337 131052307244544 run.py:727] (val) algo activity_selector step 7500: {'selected': 0.9868667917448405, 'score': 0.9868667917448405, 'examples_seen': 233472, 'step': 7500, 'algorithm': 'activity_selector'}
I0818 07:00:05.163485 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.987, val scores are: activity_selector: 0.987
I0818 07:00:06.059874 131052307244544 run.py:692] Algo activity_selector step 7550 current loss 3.267813, current_train_items 235040.
I0818 07:00:06.088273 131052307244544 run.py:727] (val) algo activity_selector step 7550: {'selected': 0.9801587301587301, 'score': 0.9801587301587301, 'examples_seen': 235040, 'step': 7550, 'algorithm': 'activity_selector'}
I0818 07:00:06.088430 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.980, val scores are: activity_selector: 0.980
I0818 07:00:07.028165 131052307244544 run.py:692] Algo activity_selector step 7600 current loss 6.868256, current_train_items 236544.
I0818 07:00:07.059318 131052307244544 run.py:727] (val) algo activity_selector step 7600: {'selected': 0.9765625, 'score': 0.9765625, 'examples_seen': 236544, 'step': 7600, 'algorithm': 'activity_selector'}
I0818 07:00:07.059464 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0818 07:00:07.976758 131052307244544 run.py:692] Algo activity_selector step 7650 current loss 0.183081, current_train_items 238144.
I0818 07:00:07.995609 131052307244544 run.py:727] (val) algo activity_selector step 7650: {'selected': 0.9685039370078741, 'score': 0.9685039370078741, 'examples_seen': 238144, 'step': 7650, 'algorithm': 'activity_selector'}
I0818 07:00:07.995757 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0818 07:00:08.931249 131052307244544 run.py:692] Algo activity_selector step 7700 current loss 1.320966, current_train_items 239744.
I0818 07:00:08.949951 131052307244544 run.py:727] (val) algo activity_selector step 7700: {'selected': 0.9659318637274549, 'score': 0.9659318637274549, 'examples_seen': 239744, 'step': 7700, 'algorithm': 'activity_selector'}
I0818 07:00:08.950112 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0818 07:00:09.860646 131052307244544 run.py:692] Algo activity_selector step 7750 current loss 0.206502, current_train_items 241280.
I0818 07:00:09.881093 131052307244544 run.py:727] (val) algo activity_selector step 7750: {'selected': 0.9608938547486034, 'score': 0.9608938547486034, 'examples_seen': 241280, 'step': 7750, 'algorithm': 'activity_selector'}
I0818 07:00:09.881244 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0818 07:00:10.800477 131052307244544 run.py:692] Algo activity_selector step 7800 current loss 3.032829, current_train_items 242816.
I0818 07:00:10.823889 131052307244544 run.py:727] (val) algo activity_selector step 7800: {'selected': 0.9674796747967479, 'score': 0.9674796747967479, 'examples_seen': 242816, 'step': 7800, 'algorithm': 'activity_selector'}
I0818 07:00:10.824035 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0818 07:00:11.728057 131052307244544 run.py:692] Algo activity_selector step 7850 current loss 4.900321, current_train_items 244352.
I0818 07:00:11.752790 131052307244544 run.py:727] (val) algo activity_selector step 7850: {'selected': 0.9586466165413534, 'score': 0.9586466165413534, 'examples_seen': 244352, 'step': 7850, 'algorithm': 'activity_selector'}
I0818 07:00:11.752951 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0818 07:00:12.688253 131052307244544 run.py:692] Algo activity_selector step 7900 current loss 3.378690, current_train_items 245920.
I0818 07:00:12.716409 131052307244544 run.py:727] (val) algo activity_selector step 7900: {'selected': 0.9626865671641791, 'score': 0.9626865671641791, 'examples_seen': 245920, 'step': 7900, 'algorithm': 'activity_selector'}
I0818 07:00:12.716558 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0818 07:00:13.646178 131052307244544 run.py:692] Algo activity_selector step 7950 current loss 3.463166, current_train_items 247456.
I0818 07:00:13.672940 131052307244544 run.py:727] (val) algo activity_selector step 7950: {'selected': 0.9710144927536232, 'score': 0.9710144927536232, 'examples_seen': 247456, 'step': 7950, 'algorithm': 'activity_selector'}
I0818 07:00:13.673085 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0818 07:00:14.599750 131052307244544 run.py:692] Algo activity_selector step 8000 current loss 0.289312, current_train_items 249024.
I0818 07:00:14.618885 131052307244544 run.py:727] (val) algo activity_selector step 8000: {'selected': 0.9709864603481624, 'score': 0.9709864603481624, 'examples_seen': 249024, 'step': 8000, 'algorithm': 'activity_selector'}
I0818 07:00:14.619035 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.998, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0818 07:00:15.559882 131052307244544 run.py:692] Algo activity_selector step 8050 current loss 1.118009, current_train_items 250592.
I0818 07:00:15.577924 131052307244544 run.py:727] (val) algo activity_selector step 8050: {'selected': 0.950884086444008, 'score': 0.950884086444008, 'examples_seen': 250592, 'step': 8050, 'algorithm': 'activity_selector'}
I0818 07:00:15.578070 131052307244544 run.py:748] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0818 07:00:16.495051 131052307244544 run.py:692] Algo activity_selector step 8100 current loss 0.228425, current_train_items 252160.
I0818 07:00:16.515767 131052307244544 run.py:727] (val) algo activity_selector step 8100: {'selected': 0.981203007518797, 'score': 0.981203007518797, 'examples_seen': 252160, 'step': 8100, 'algorithm': 'activity_selector'}
I0818 07:00:16.515914 131052307244544 run.py:748] Checkpointing best model, best avg val score was 0.951, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0818 07:00:17.478344 131052307244544 run.py:692] Algo activity_selector step 8150 current loss 2.271101, current_train_items 253696.
I0818 07:00:17.500949 131052307244544 run.py:727] (val) algo activity_selector step 8150: {'selected': 0.9702602230483272, 'score': 0.9702602230483272, 'examples_seen': 253696, 'step': 8150, 'algorithm': 'activity_selector'}
I0818 07:00:17.501097 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.981, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0818 07:00:18.409969 131052307244544 run.py:692] Algo activity_selector step 8200 current loss 2.616168, current_train_items 255264.
I0818 07:00:18.433764 131052307244544 run.py:727] (val) algo activity_selector step 8200: {'selected': 0.9751434034416827, 'score': 0.9751434034416827, 'examples_seen': 255264, 'step': 8200, 'algorithm': 'activity_selector'}
I0818 07:00:18.433909 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.981, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0818 07:00:19.347024 131052307244544 run.py:692] Algo activity_selector step 8250 current loss 3.275157, current_train_items 256800.
I0818 07:00:19.374804 131052307244544 run.py:727] (val) algo activity_selector step 8250: {'selected': 0.9674952198852772, 'score': 0.9674952198852772, 'examples_seen': 256800, 'step': 8250, 'algorithm': 'activity_selector'}
I0818 07:00:19.374954 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.981, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0818 07:00:20.319487 131052307244544 run.py:692] Algo activity_selector step 8300 current loss 5.996899, current_train_items 258336.
I0818 07:00:20.350576 131052307244544 run.py:727] (val) algo activity_selector step 8300: {'selected': 0.9706457925636007, 'score': 0.9706457925636007, 'examples_seen': 258336, 'step': 8300, 'algorithm': 'activity_selector'}
I0818 07:00:20.350724 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.981, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0818 07:00:21.265185 131052307244544 run.py:692] Algo activity_selector step 8350 current loss 0.169458, current_train_items 259936.
I0818 07:00:21.283540 131052307244544 run.py:727] (val) algo activity_selector step 8350: {'selected': 0.958904109589041, 'score': 0.958904109589041, 'examples_seen': 259936, 'step': 8350, 'algorithm': 'activity_selector'}
I0818 07:00:21.283688 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.981, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0818 07:00:22.243190 131052307244544 run.py:692] Algo activity_selector step 8400 current loss 1.517382, current_train_items 261504.
I0818 07:00:22.261260 131052307244544 run.py:727] (val) algo activity_selector step 8400: {'selected': 0.9645669291338581, 'score': 0.9645669291338581, 'examples_seen': 261504, 'step': 8400, 'algorithm': 'activity_selector'}
I0818 07:00:22.261399 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.981, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0818 07:00:23.176545 131052307244544 run.py:692] Algo activity_selector step 8450 current loss 0.246841, current_train_items 263072.
I0818 07:00:23.197048 131052307244544 run.py:727] (val) algo activity_selector step 8450: {'selected': 0.9613899613899614, 'score': 0.9613899613899614, 'examples_seen': 263072, 'step': 8450, 'algorithm': 'activity_selector'}
I0818 07:00:23.197205 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.981, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0818 07:00:24.113802 131052307244544 run.py:692] Algo activity_selector step 8500 current loss 0.204552, current_train_items 264576.
I0818 07:00:24.136684 131052307244544 run.py:727] (val) algo activity_selector step 8500: {'selected': 0.9607476635514018, 'score': 0.9607476635514018, 'examples_seen': 264576, 'step': 8500, 'algorithm': 'activity_selector'}
I0818 07:00:24.136834 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.981, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0818 07:00:25.065504 131052307244544 run.py:692] Algo activity_selector step 8550 current loss 3.924349, current_train_items 266144.
I0818 07:00:25.090229 131052307244544 run.py:727] (val) algo activity_selector step 8550: {'selected': 0.969258589511754, 'score': 0.969258589511754, 'examples_seen': 266144, 'step': 8550, 'algorithm': 'activity_selector'}
I0818 07:00:25.090376 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.981, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0818 07:00:25.992716 131052307244544 run.py:692] Algo activity_selector step 8600 current loss 3.127973, current_train_items 267712.
I0818 07:00:26.020801 131052307244544 run.py:727] (val) algo activity_selector step 8600: {'selected': 0.9636711281070746, 'score': 0.9636711281070746, 'examples_seen': 267712, 'step': 8600, 'algorithm': 'activity_selector'}
I0818 07:00:26.020946 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.981, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0818 07:00:26.965914 131052307244544 run.py:692] Algo activity_selector step 8650 current loss 3.666540, current_train_items 269216.
I0818 07:00:26.992781 131052307244544 run.py:727] (val) algo activity_selector step 8650: {'selected': 0.968, 'score': 0.968, 'examples_seen': 269216, 'step': 8650, 'algorithm': 'activity_selector'}
I0818 07:00:26.992928 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.981, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0818 07:00:27.916010 131052307244544 run.py:692] Algo activity_selector step 8700 current loss 0.133754, current_train_items 270816.
I0818 07:00:27.933619 131052307244544 run.py:727] (val) algo activity_selector step 8700: {'selected': 0.9583333333333334, 'score': 0.9583333333333334, 'examples_seen': 270816, 'step': 8700, 'algorithm': 'activity_selector'}
I0818 07:00:27.933767 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.981, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0818 07:00:28.860321 131052307244544 run.py:692] Algo activity_selector step 8750 current loss 1.187192, current_train_items 272384.
I0818 07:00:28.879440 131052307244544 run.py:727] (val) algo activity_selector step 8750: {'selected': 0.9622266401590457, 'score': 0.9622266401590457, 'examples_seen': 272384, 'step': 8750, 'algorithm': 'activity_selector'}
I0818 07:00:28.879603 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.981, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0818 07:00:29.794655 131052307244544 run.py:692] Algo activity_selector step 8800 current loss 0.269342, current_train_items 273952.
I0818 07:00:29.815115 131052307244544 run.py:727] (val) algo activity_selector step 8800: {'selected': 0.9841897233201581, 'score': 0.9841897233201581, 'examples_seen': 273952, 'step': 8800, 'algorithm': 'activity_selector'}
I0818 07:00:29.815267 131052307244544 run.py:748] Checkpointing best model, best avg val score was 0.981, current avg val score is 0.984, val scores are: activity_selector: 0.984
I0818 07:00:30.765976 131052307244544 run.py:692] Algo activity_selector step 8850 current loss 2.964771, current_train_items 275488.
I0818 07:00:30.788665 131052307244544 run.py:727] (val) algo activity_selector step 8850: {'selected': 0.9826589595375722, 'score': 0.9826589595375722, 'examples_seen': 275488, 'step': 8850, 'algorithm': 'activity_selector'}
I0818 07:00:30.788810 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.983, val scores are: activity_selector: 0.983
I0818 07:00:31.711081 131052307244544 run.py:692] Algo activity_selector step 8900 current loss 1.828961, current_train_items 277024.
I0818 07:00:31.735146 131052307244544 run.py:727] (val) algo activity_selector step 8900: {'selected': 0.9810606060606061, 'score': 0.9810606060606061, 'examples_seen': 277024, 'step': 8900, 'algorithm': 'activity_selector'}
I0818 07:00:31.735293 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0818 07:00:32.655236 131052307244544 run.py:692] Algo activity_selector step 8950 current loss 3.259886, current_train_items 278592.
I0818 07:00:32.683891 131052307244544 run.py:727] (val) algo activity_selector step 8950: {'selected': 0.96484375, 'score': 0.96484375, 'examples_seen': 278592, 'step': 8950, 'algorithm': 'activity_selector'}
I0818 07:00:32.684038 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0818 07:00:33.613808 131052307244544 run.py:692] Algo activity_selector step 9000 current loss 4.708715, current_train_items 280128.
I0818 07:00:33.644313 131052307244544 run.py:727] (val) algo activity_selector step 9000: {'selected': 0.9714285714285713, 'score': 0.9714285714285713, 'examples_seen': 280128, 'step': 9000, 'algorithm': 'activity_selector'}
I0818 07:00:33.644472 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0818 07:00:34.564687 131052307244544 run.py:692] Algo activity_selector step 9050 current loss 0.092185, current_train_items 281696.
I0818 07:00:34.582858 131052307244544 run.py:727] (val) algo activity_selector step 9050: {'selected': 0.9502982107355864, 'score': 0.9502982107355864, 'examples_seen': 281696, 'step': 9050, 'algorithm': 'activity_selector'}
I0818 07:00:34.583003 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0818 07:00:35.543977 131052307244544 run.py:692] Algo activity_selector step 9100 current loss 1.465015, current_train_items 283296.
I0818 07:00:35.562489 131052307244544 run.py:727] (val) algo activity_selector step 9100: {'selected': 0.9615384615384616, 'score': 0.9615384615384616, 'examples_seen': 283296, 'step': 9100, 'algorithm': 'activity_selector'}
I0818 07:00:35.562634 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0818 07:00:36.468386 131052307244544 run.py:692] Algo activity_selector step 9150 current loss 0.201058, current_train_items 284864.
I0818 07:00:36.488439 131052307244544 run.py:727] (val) algo activity_selector step 9150: {'selected': 0.9544554455445544, 'score': 0.9544554455445544, 'examples_seen': 284864, 'step': 9150, 'algorithm': 'activity_selector'}
I0818 07:00:36.488584 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0818 07:00:37.417766 131052307244544 run.py:692] Algo activity_selector step 9200 current loss 2.218533, current_train_items 286368.
I0818 07:00:37.440621 131052307244544 run.py:727] (val) algo activity_selector step 9200: {'selected': 0.9631067961165048, 'score': 0.9631067961165048, 'examples_seen': 286368, 'step': 9200, 'algorithm': 'activity_selector'}
I0818 07:00:37.440768 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0818 07:00:38.352764 131052307244544 run.py:692] Algo activity_selector step 9250 current loss 2.976747, current_train_items 287968.
I0818 07:00:38.377201 131052307244544 run.py:727] (val) algo activity_selector step 9250: {'selected': 0.9683794466403163, 'score': 0.9683794466403163, 'examples_seen': 287968, 'step': 9250, 'algorithm': 'activity_selector'}
I0818 07:00:38.377353 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0818 07:00:39.293285 131052307244544 run.py:692] Algo activity_selector step 9300 current loss 3.243756, current_train_items 289504.
I0818 07:00:39.321426 131052307244544 run.py:727] (val) algo activity_selector step 9300: {'selected': 0.9581749049429659, 'score': 0.9581749049429659, 'examples_seen': 289504, 'step': 9300, 'algorithm': 'activity_selector'}
I0818 07:00:39.321575 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0818 07:00:40.274703 131052307244544 run.py:692] Algo activity_selector step 9350 current loss 3.279355, current_train_items 291040.
I0818 07:00:40.301406 131052307244544 run.py:727] (val) algo activity_selector step 9350: {'selected': 0.9538461538461538, 'score': 0.9538461538461538, 'examples_seen': 291040, 'step': 9350, 'algorithm': 'activity_selector'}
I0818 07:00:40.301552 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0818 07:00:41.208576 131052307244544 run.py:692] Algo activity_selector step 9400 current loss 0.282958, current_train_items 292640.
I0818 07:00:41.226533 131052307244544 run.py:727] (val) algo activity_selector step 9400: {'selected': 0.9224652087475149, 'score': 0.9224652087475149, 'examples_seen': 292640, 'step': 9400, 'algorithm': 'activity_selector'}
I0818 07:00:41.226678 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0818 07:00:42.160888 131052307244544 run.py:692] Algo activity_selector step 9450 current loss 1.362544, current_train_items 294176.
I0818 07:00:42.178957 131052307244544 run.py:727] (val) algo activity_selector step 9450: {'selected': 0.9757914338919925, 'score': 0.9757914338919925, 'examples_seen': 294176, 'step': 9450, 'algorithm': 'activity_selector'}
I0818 07:00:42.179109 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0818 07:00:43.111455 131052307244544 run.py:692] Algo activity_selector step 9500 current loss 0.257205, current_train_items 295776.
I0818 07:00:43.131691 131052307244544 run.py:727] (val) algo activity_selector step 9500: {'selected': 0.9673704414587333, 'score': 0.9673704414587333, 'examples_seen': 295776, 'step': 9500, 'algorithm': 'activity_selector'}
I0818 07:00:43.131836 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0818 07:00:44.035961 131052307244544 run.py:692] Algo activity_selector step 9550 current loss 0.219799, current_train_items 297280.
I0818 07:00:44.058415 131052307244544 run.py:727] (val) algo activity_selector step 9550: {'selected': 0.953307392996109, 'score': 0.953307392996109, 'examples_seen': 297280, 'step': 9550, 'algorithm': 'activity_selector'}
I0818 07:00:44.058561 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0818 07:00:44.974735 131052307244544 run.py:692] Algo activity_selector step 9600 current loss 0.187641, current_train_items 298816.
I0818 07:00:44.998792 131052307244544 run.py:727] (val) algo activity_selector step 9600: {'selected': 0.9770114942528735, 'score': 0.9770114942528735, 'examples_seen': 298816, 'step': 9600, 'algorithm': 'activity_selector'}
I0818 07:00:44.998961 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0818 07:00:45.894873 131052307244544 run.py:692] Algo activity_selector step 9650 current loss 3.177539, current_train_items 300384.
I0818 07:00:45.922054 131052307244544 run.py:727] (val) algo activity_selector step 9650: {'selected': 0.9465346534653465, 'score': 0.9465346534653465, 'examples_seen': 300384, 'step': 9650, 'algorithm': 'activity_selector'}
I0818 07:00:45.922206 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0818 07:00:46.867163 131052307244544 run.py:692] Algo activity_selector step 9700 current loss 4.209543, current_train_items 301888.
I0818 07:00:46.897885 131052307244544 run.py:727] (val) algo activity_selector step 9700: {'selected': 0.9788867562380038, 'score': 0.9788867562380038, 'examples_seen': 301888, 'step': 9700, 'algorithm': 'activity_selector'}
I0818 07:00:46.898032 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.979, val scores are: activity_selector: 0.979
I0818 07:00:47.845629 131052307244544 run.py:692] Algo activity_selector step 9750 current loss 0.140274, current_train_items 303520.
I0818 07:00:47.864203 131052307244544 run.py:727] (val) algo activity_selector step 9750: {'selected': 0.9681050656660413, 'score': 0.9681050656660413, 'examples_seen': 303520, 'step': 9750, 'algorithm': 'activity_selector'}
I0818 07:00:47.864375 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0818 07:00:48.810804 131052307244544 run.py:692] Algo activity_selector step 9800 current loss 1.192867, current_train_items 305088.
I0818 07:00:48.829446 131052307244544 run.py:727] (val) algo activity_selector step 9800: {'selected': 0.9702602230483272, 'score': 0.9702602230483272, 'examples_seen': 305088, 'step': 9800, 'algorithm': 'activity_selector'}
I0818 07:00:48.829595 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0818 07:00:49.791533 131052307244544 run.py:692] Algo activity_selector step 9850 current loss 0.108192, current_train_items 306624.
I0818 07:00:49.811609 131052307244544 run.py:727] (val) algo activity_selector step 9850: {'selected': 0.9780439121756487, 'score': 0.9780439121756487, 'examples_seen': 306624, 'step': 9850, 'algorithm': 'activity_selector'}
I0818 07:00:49.811757 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.978, val scores are: activity_selector: 0.978
I0818 07:00:50.745921 131052307244544 run.py:692] Algo activity_selector step 9900 current loss 2.992783, current_train_items 308160.
I0818 07:00:50.768399 131052307244544 run.py:727] (val) algo activity_selector step 9900: {'selected': 0.9806949806949806, 'score': 0.9806949806949806, 'examples_seen': 308160, 'step': 9900, 'algorithm': 'activity_selector'}
I0818 07:00:50.768546 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0818 07:00:51.717745 131052307244544 run.py:692] Algo activity_selector step 9950 current loss 2.905252, current_train_items 309728.
I0818 07:00:51.741683 131052307244544 run.py:727] (val) algo activity_selector step 9950: {'selected': 0.9751434034416827, 'score': 0.9751434034416827, 'examples_seen': 309728, 'step': 9950, 'algorithm': 'activity_selector'}
I0818 07:00:51.741831 131052307244544 run.py:751] Not saving new best model, best avg val score was 0.984, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0818 07:00:52.664282 131052307244544 run.py:757] Restoring best model from checkpoint...
I0818 07:00:59.790268 131052307244544 run.py:772] (test) algo activity_selector : {'selected': 0.9168207024029575, 'score': 0.9168207024029575, 'examples_seen': 311264, 'step': 10000, 'algorithm': 'activity_selector'}
I0818 07:00:59.790451 131052307244544 run.py:774] Done!
