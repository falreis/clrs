I1007 20:38:36.609400 134831690958336 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I1007 20:38:36.612094 134831690958336 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I1007 20:38:36.943109 134831690958336 run.py:453] Model: f7 ['activity_selector']
I1007 20:38:36.943211 134831690958336 run.py:455] algorithms ['activity_selector']
I1007 20:38:36.943386 134831690958336 run.py:456] train_lengths ['4', '7', '11', '13', '16']
I1007 20:38:36.943423 134831690958336 run.py:457] train_batch_size 16
I1007 20:38:36.943520 134831690958336 run.py:458] val_batch_size 16
I1007 20:38:36.943553 134831690958336 run.py:459] test_batch_size 16
I1007 20:38:36.943583 134831690958336 run.py:460] chunked_training True
I1007 20:38:36.943712 134831690958336 run.py:461] chunk_length 16
I1007 20:38:36.943743 134831690958336 run.py:462] train_steps 10000
I1007 20:38:36.943773 134831690958336 run.py:463] eval_every 50
I1007 20:38:36.943802 134831690958336 run.py:464] test_every 500
I1007 20:38:36.943831 134831690958336 run.py:465] hidden_size 128
I1007 20:38:36.943861 134831690958336 run.py:466] nb_msg_passing_steps 1
I1007 20:38:36.943891 134831690958336 run.py:467] learning_rate 0.001
I1007 20:38:36.943980 134831690958336 run.py:468] grad_clip_max_norm 1.0
I1007 20:38:36.944013 134831690958336 run.py:469] dropout_prob 0.1
I1007 20:38:36.944043 134831690958336 run.py:470] hint_teacher_forcing 0.0
I1007 20:38:36.944072 134831690958336 run.py:471] hint_mode encoded_decoded
I1007 20:38:36.944174 134831690958336 run.py:472] hint_repred_mode soft
I1007 20:38:36.944205 134831690958336 run.py:473] use_ln True
I1007 20:38:36.944234 134831690958336 run.py:474] use_lstm True
I1007 20:38:36.944262 134831690958336 run.py:475] nb_triplet_fts 8
I1007 20:38:36.944291 134831690958336 run.py:476] encoder_init xavier_on_scalars
I1007 20:38:36.944319 134831690958336 run.py:477] processor_type f7
I1007 20:38:36.944348 134831690958336 run.py:478] checkpoint_path CLRS30
I1007 20:38:36.944380 134831690958336 run.py:479] dataset_path CLRS30
I1007 20:38:36.944409 134831690958336 run.py:480] freeze_processor False
I1007 20:38:36.944437 134831690958336 run.py:481] reduction min
I1007 20:38:36.944466 134831690958336 run.py:482] activation elu
I1007 20:38:36.944494 134831690958336 run.py:483] restore_model 
I1007 20:38:36.944524 134831690958336 run.py:484] gated True
I1007 20:38:36.944552 134831690958336 run.py:485] gated_activation tanh
I1007 20:38:36.947254 134831690958336 run.py:511] Creating samplers for algo activity_selector
W1007 20:38:36.947455 134831690958336 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1007 20:38:36.947722 134831690958336 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W1007 20:38:37.159311 134831690958336 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1007 20:38:37.407968 134831690958336 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1007 20:38:37.712075 134831690958336 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1007 20:38:38.050984 134831690958336 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1007 20:38:38.437432 134831690958336 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I1007 20:38:38.437737 134831690958336 samplers.py:124] Creating a dataset with 64 samples.
I1007 20:38:38.463970 134831690958336 run.py:297] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I1007 20:38:38.464749 134831690958336 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I1007 20:38:38.467875 134831690958336 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I1007 20:38:38.471220 134831690958336 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I1007 20:38:38.526539 134831690958336 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W1007 20:38:38.547708 134831690958336 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x7aa06e7d0ae0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I1007 20:39:10.660145 134831690958336 run.py:734] Algo activity_selector step 0 current loss 5.217439, current_train_items 32.
I1007 20:39:18.210732 134831690958336 run.py:769] (val) algo activity_selector step 0: {'selected': 0.0, 'score': 0.0, 'examples_seen': 32, 'step': 0, 'algorithm': 'activity_selector'}
I1007 20:39:18.210893 134831690958336 run.py:790] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.000, val scores are: activity_selector: 0.000
I1007 20:40:06.436094 134831690958336 run.py:734] Algo activity_selector step 50 current loss 3.710964, current_train_items 1408.
I1007 20:40:06.463842 134831690958336 run.py:769] (val) algo activity_selector step 50: {'selected': 0.6802443991853361, 'score': 0.6802443991853361, 'examples_seen': 1408, 'step': 50, 'algorithm': 'activity_selector'}
I1007 20:40:06.463999 134831690958336 run.py:790] Checkpointing best model, best avg val score was 0.000, current avg val score is 0.680, val scores are: activity_selector: 0.680
I1007 20:40:07.360622 134831690958336 run.py:734] Algo activity_selector step 100 current loss 3.291381, current_train_items 2800.
I1007 20:40:07.386778 134831690958336 run.py:769] (val) algo activity_selector step 100: {'selected': 0.7122736418511065, 'score': 0.7122736418511065, 'examples_seen': 2800, 'step': 100, 'algorithm': 'activity_selector'}
I1007 20:40:07.386960 134831690958336 run.py:790] Checkpointing best model, best avg val score was 0.680, current avg val score is 0.712, val scores are: activity_selector: 0.712
I1007 20:40:08.291791 134831690958336 run.py:734] Algo activity_selector step 150 current loss 3.014127, current_train_items 4176.
I1007 20:40:08.319173 134831690958336 run.py:769] (val) algo activity_selector step 150: {'selected': 0.6954643628509719, 'score': 0.6954643628509719, 'examples_seen': 4176, 'step': 150, 'algorithm': 'activity_selector'}
I1007 20:40:08.319321 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.712, current avg val score is 0.695, val scores are: activity_selector: 0.695
I1007 20:40:09.183450 134831690958336 run.py:734] Algo activity_selector step 200 current loss 2.980941, current_train_items 5536.
I1007 20:40:09.212506 134831690958336 run.py:769] (val) algo activity_selector step 200: {'selected': 0.6958250497017893, 'score': 0.6958250497017893, 'examples_seen': 5536, 'step': 200, 'algorithm': 'activity_selector'}
I1007 20:40:09.212672 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.712, current avg val score is 0.696, val scores are: activity_selector: 0.696
I1007 20:40:10.084535 134831690958336 run.py:734] Algo activity_selector step 250 current loss 2.682768, current_train_items 6944.
I1007 20:40:10.110871 134831690958336 run.py:769] (val) algo activity_selector step 250: {'selected': 0.7075098814229249, 'score': 0.7075098814229249, 'examples_seen': 6944, 'step': 250, 'algorithm': 'activity_selector'}
I1007 20:40:10.111018 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.712, current avg val score is 0.708, val scores are: activity_selector: 0.708
I1007 20:40:10.987876 134831690958336 run.py:734] Algo activity_selector step 300 current loss 2.444644, current_train_items 8304.
I1007 20:40:11.014553 134831690958336 run.py:769] (val) algo activity_selector step 300: {'selected': 0.7725040916530278, 'score': 0.7725040916530278, 'examples_seen': 8304, 'step': 300, 'algorithm': 'activity_selector'}
I1007 20:40:11.014707 134831690958336 run.py:790] Checkpointing best model, best avg val score was 0.712, current avg val score is 0.773, val scores are: activity_selector: 0.773
I1007 20:40:11.902036 134831690958336 run.py:734] Algo activity_selector step 350 current loss 2.416243, current_train_items 9680.
I1007 20:40:11.929322 134831690958336 run.py:769] (val) algo activity_selector step 350: {'selected': 0.7635658914728682, 'score': 0.7635658914728682, 'examples_seen': 9680, 'step': 350, 'algorithm': 'activity_selector'}
I1007 20:40:11.929478 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.773, current avg val score is 0.764, val scores are: activity_selector: 0.764
I1007 20:40:12.815000 134831690958336 run.py:734] Algo activity_selector step 400 current loss 2.365778, current_train_items 11072.
I1007 20:40:12.842162 134831690958336 run.py:769] (val) algo activity_selector step 400: {'selected': 0.7957746478873239, 'score': 0.7957746478873239, 'examples_seen': 11072, 'step': 400, 'algorithm': 'activity_selector'}
I1007 20:40:12.842307 134831690958336 run.py:790] Checkpointing best model, best avg val score was 0.773, current avg val score is 0.796, val scores are: activity_selector: 0.796
I1007 20:40:13.739930 134831690958336 run.py:734] Algo activity_selector step 450 current loss 2.095152, current_train_items 12448.
I1007 20:40:13.766416 134831690958336 run.py:769] (val) algo activity_selector step 450: {'selected': 0.8230912476722533, 'score': 0.8230912476722533, 'examples_seen': 12448, 'step': 450, 'algorithm': 'activity_selector'}
I1007 20:40:13.766566 134831690958336 run.py:790] Checkpointing best model, best avg val score was 0.796, current avg val score is 0.823, val scores are: activity_selector: 0.823
I1007 20:40:14.676870 134831690958336 run.py:734] Algo activity_selector step 500 current loss 2.560501, current_train_items 13824.
I1007 20:40:14.704198 134831690958336 run.py:769] (val) algo activity_selector step 500: {'selected': 0.7883211678832116, 'score': 0.7883211678832116, 'examples_seen': 13824, 'step': 500, 'algorithm': 'activity_selector'}
I1007 20:40:14.704347 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.823, current avg val score is 0.788, val scores are: activity_selector: 0.788
I1007 20:40:15.576412 134831690958336 run.py:734] Algo activity_selector step 550 current loss 1.842645, current_train_items 15200.
I1007 20:40:15.606454 134831690958336 run.py:769] (val) algo activity_selector step 550: {'selected': 0.8095238095238095, 'score': 0.8095238095238095, 'examples_seen': 15200, 'step': 550, 'algorithm': 'activity_selector'}
I1007 20:40:15.606617 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.823, current avg val score is 0.810, val scores are: activity_selector: 0.810
I1007 20:40:16.489156 134831690958336 run.py:734] Algo activity_selector step 600 current loss 1.780234, current_train_items 16576.
I1007 20:40:16.516056 134831690958336 run.py:769] (val) algo activity_selector step 600: {'selected': 0.7958477508650519, 'score': 0.7958477508650519, 'examples_seen': 16576, 'step': 600, 'algorithm': 'activity_selector'}
I1007 20:40:16.516206 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.823, current avg val score is 0.796, val scores are: activity_selector: 0.796
I1007 20:40:17.402255 134831690958336 run.py:734] Algo activity_selector step 650 current loss 1.740040, current_train_items 17952.
I1007 20:40:17.429359 134831690958336 run.py:769] (val) algo activity_selector step 650: {'selected': 0.879245283018868, 'score': 0.879245283018868, 'examples_seen': 17952, 'step': 650, 'algorithm': 'activity_selector'}
I1007 20:40:17.429522 134831690958336 run.py:790] Checkpointing best model, best avg val score was 0.823, current avg val score is 0.879, val scores are: activity_selector: 0.879
I1007 20:40:18.317859 134831690958336 run.py:734] Algo activity_selector step 700 current loss 1.917071, current_train_items 19344.
I1007 20:40:18.345147 134831690958336 run.py:769] (val) algo activity_selector step 700: {'selected': 0.8637992831541219, 'score': 0.8637992831541219, 'examples_seen': 19344, 'step': 700, 'algorithm': 'activity_selector'}
I1007 20:40:18.345303 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.879, current avg val score is 0.864, val scores are: activity_selector: 0.864
I1007 20:40:19.228669 134831690958336 run.py:734] Algo activity_selector step 750 current loss 1.793219, current_train_items 20720.
I1007 20:40:19.255838 134831690958336 run.py:769] (val) algo activity_selector step 750: {'selected': 0.9028571428571429, 'score': 0.9028571428571429, 'examples_seen': 20720, 'step': 750, 'algorithm': 'activity_selector'}
I1007 20:40:19.255987 134831690958336 run.py:790] Checkpointing best model, best avg val score was 0.879, current avg val score is 0.903, val scores are: activity_selector: 0.903
I1007 20:40:20.141789 134831690958336 run.py:734] Algo activity_selector step 800 current loss 1.734790, current_train_items 22096.
I1007 20:40:20.168465 134831690958336 run.py:769] (val) algo activity_selector step 800: {'selected': 0.9333333333333333, 'score': 0.9333333333333333, 'examples_seen': 22096, 'step': 800, 'algorithm': 'activity_selector'}
I1007 20:40:20.168633 134831690958336 run.py:790] Checkpointing best model, best avg val score was 0.903, current avg val score is 0.933, val scores are: activity_selector: 0.933
I1007 20:40:21.058774 134831690958336 run.py:734] Algo activity_selector step 850 current loss 1.638131, current_train_items 23472.
I1007 20:40:21.085667 134831690958336 run.py:769] (val) algo activity_selector step 850: {'selected': 0.8230452674897121, 'score': 0.8230452674897121, 'examples_seen': 23472, 'step': 850, 'algorithm': 'activity_selector'}
I1007 20:40:21.085848 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.823, val scores are: activity_selector: 0.823
I1007 20:40:21.972619 134831690958336 run.py:734] Algo activity_selector step 900 current loss 1.857116, current_train_items 24848.
I1007 20:40:21.999979 134831690958336 run.py:769] (val) algo activity_selector step 900: {'selected': 0.8648648648648648, 'score': 0.8648648648648648, 'examples_seen': 24848, 'step': 900, 'algorithm': 'activity_selector'}
I1007 20:40:22.000129 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.865, val scores are: activity_selector: 0.865
I1007 20:40:22.868992 134831690958336 run.py:734] Algo activity_selector step 950 current loss 1.570975, current_train_items 26224.
I1007 20:40:22.896003 134831690958336 run.py:769] (val) algo activity_selector step 950: {'selected': 0.895575221238938, 'score': 0.895575221238938, 'examples_seen': 26224, 'step': 950, 'algorithm': 'activity_selector'}
I1007 20:40:22.896153 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.896, val scores are: activity_selector: 0.896
I1007 20:40:23.769279 134831690958336 run.py:734] Algo activity_selector step 1000 current loss 1.842193, current_train_items 27616.
I1007 20:40:23.796423 134831690958336 run.py:769] (val) algo activity_selector step 1000: {'selected': 0.8850174216027875, 'score': 0.8850174216027875, 'examples_seen': 27616, 'step': 1000, 'algorithm': 'activity_selector'}
I1007 20:40:23.796569 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.885, val scores are: activity_selector: 0.885
I1007 20:40:24.676176 134831690958336 run.py:734] Algo activity_selector step 1050 current loss 1.748801, current_train_items 28992.
I1007 20:40:24.703340 134831690958336 run.py:769] (val) algo activity_selector step 1050: {'selected': 0.9149338374291115, 'score': 0.9149338374291115, 'examples_seen': 28992, 'step': 1050, 'algorithm': 'activity_selector'}
I1007 20:40:24.703494 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.915, val scores are: activity_selector: 0.915
I1007 20:40:25.568324 134831690958336 run.py:734] Algo activity_selector step 1100 current loss 1.588767, current_train_items 30368.
I1007 20:40:25.595022 134831690958336 run.py:769] (val) algo activity_selector step 1100: {'selected': 0.9215291750503017, 'score': 0.9215291750503017, 'examples_seen': 30368, 'step': 1100, 'algorithm': 'activity_selector'}
I1007 20:40:25.595179 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.922, val scores are: activity_selector: 0.922
I1007 20:40:26.472680 134831690958336 run.py:734] Algo activity_selector step 1150 current loss 1.632207, current_train_items 31760.
I1007 20:40:26.499805 134831690958336 run.py:769] (val) algo activity_selector step 1150: {'selected': 0.8690702087286528, 'score': 0.8690702087286528, 'examples_seen': 31760, 'step': 1150, 'algorithm': 'activity_selector'}
I1007 20:40:26.499954 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.869, val scores are: activity_selector: 0.869
I1007 20:40:27.378472 134831690958336 run.py:734] Algo activity_selector step 1200 current loss 1.310492, current_train_items 33120.
I1007 20:40:27.404842 134831690958336 run.py:769] (val) algo activity_selector step 1200: {'selected': 0.9230769230769231, 'score': 0.9230769230769231, 'examples_seen': 33120, 'step': 1200, 'algorithm': 'activity_selector'}
I1007 20:40:27.404989 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.923, val scores are: activity_selector: 0.923
I1007 20:40:28.282490 134831690958336 run.py:734] Algo activity_selector step 1250 current loss 1.605435, current_train_items 34496.
I1007 20:40:28.312124 134831690958336 run.py:769] (val) algo activity_selector step 1250: {'selected': 0.8864468864468863, 'score': 0.8864468864468863, 'examples_seen': 34496, 'step': 1250, 'algorithm': 'activity_selector'}
I1007 20:40:28.312278 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.886, val scores are: activity_selector: 0.886
I1007 20:40:29.183622 134831690958336 run.py:734] Algo activity_selector step 1300 current loss 1.475759, current_train_items 35888.
I1007 20:40:29.213902 134831690958336 run.py:769] (val) algo activity_selector step 1300: {'selected': 0.8815533980582524, 'score': 0.8815533980582524, 'examples_seen': 35888, 'step': 1300, 'algorithm': 'activity_selector'}
I1007 20:40:29.214054 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.882, val scores are: activity_selector: 0.882
I1007 20:40:30.093484 134831690958336 run.py:734] Algo activity_selector step 1350 current loss 1.592871, current_train_items 37264.
I1007 20:40:30.120619 134831690958336 run.py:769] (val) algo activity_selector step 1350: {'selected': 0.8792792792792793, 'score': 0.8792792792792793, 'examples_seen': 37264, 'step': 1350, 'algorithm': 'activity_selector'}
I1007 20:40:30.120771 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.879, val scores are: activity_selector: 0.879
I1007 20:40:30.992903 134831690958336 run.py:734] Algo activity_selector step 1400 current loss 1.360903, current_train_items 38640.
I1007 20:40:31.019686 134831690958336 run.py:769] (val) algo activity_selector step 1400: {'selected': 0.8814814814814814, 'score': 0.8814814814814814, 'examples_seen': 38640, 'step': 1400, 'algorithm': 'activity_selector'}
I1007 20:40:31.019835 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.881, val scores are: activity_selector: 0.881
I1007 20:40:31.880848 134831690958336 run.py:734] Algo activity_selector step 1450 current loss 1.382528, current_train_items 40016.
I1007 20:40:31.907930 134831690958336 run.py:769] (val) algo activity_selector step 1450: {'selected': 0.9130434782608696, 'score': 0.9130434782608696, 'examples_seen': 40016, 'step': 1450, 'algorithm': 'activity_selector'}
I1007 20:40:31.908078 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.913, val scores are: activity_selector: 0.913
I1007 20:40:32.789646 134831690958336 run.py:734] Algo activity_selector step 1500 current loss 1.392141, current_train_items 41408.
I1007 20:40:32.816861 134831690958336 run.py:769] (val) algo activity_selector step 1500: {'selected': 0.928030303030303, 'score': 0.928030303030303, 'examples_seen': 41408, 'step': 1500, 'algorithm': 'activity_selector'}
I1007 20:40:32.817010 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.928, val scores are: activity_selector: 0.928
I1007 20:40:33.694099 134831690958336 run.py:734] Algo activity_selector step 1550 current loss 1.402563, current_train_items 42768.
I1007 20:40:33.720737 134831690958336 run.py:769] (val) algo activity_selector step 1550: {'selected': 0.919847328244275, 'score': 0.919847328244275, 'examples_seen': 42768, 'step': 1550, 'algorithm': 'activity_selector'}
I1007 20:40:33.720905 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.920, val scores are: activity_selector: 0.920
I1007 20:40:34.610313 134831690958336 run.py:734] Algo activity_selector step 1600 current loss 1.379018, current_train_items 44160.
I1007 20:40:34.637795 134831690958336 run.py:769] (val) algo activity_selector step 1600: {'selected': 0.9111111111111111, 'score': 0.9111111111111111, 'examples_seen': 44160, 'step': 1600, 'algorithm': 'activity_selector'}
I1007 20:40:34.637957 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.911, val scores are: activity_selector: 0.911
I1007 20:40:35.518548 134831690958336 run.py:734] Algo activity_selector step 1650 current loss 1.370612, current_train_items 45536.
I1007 20:40:35.545742 134831690958336 run.py:769] (val) algo activity_selector step 1650: {'selected': 0.9101562500000001, 'score': 0.9101562500000001, 'examples_seen': 45536, 'step': 1650, 'algorithm': 'activity_selector'}
I1007 20:40:35.545909 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.910, val scores are: activity_selector: 0.910
I1007 20:40:36.414555 134831690958336 run.py:734] Algo activity_selector step 1700 current loss 1.159539, current_train_items 46896.
I1007 20:40:36.441209 134831690958336 run.py:769] (val) algo activity_selector step 1700: {'selected': 0.9212121212121211, 'score': 0.9212121212121211, 'examples_seen': 46896, 'step': 1700, 'algorithm': 'activity_selector'}
I1007 20:40:36.441375 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.921, val scores are: activity_selector: 0.921
I1007 20:40:37.329888 134831690958336 run.py:734] Algo activity_selector step 1750 current loss 1.458240, current_train_items 48304.
I1007 20:40:37.357249 134831690958336 run.py:769] (val) algo activity_selector step 1750: {'selected': 0.9318181818181819, 'score': 0.9318181818181819, 'examples_seen': 48304, 'step': 1750, 'algorithm': 'activity_selector'}
I1007 20:40:37.357412 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.932, val scores are: activity_selector: 0.932
I1007 20:40:38.235397 134831690958336 run.py:734] Algo activity_selector step 1800 current loss 1.324896, current_train_items 49664.
I1007 20:40:38.263328 134831690958336 run.py:769] (val) algo activity_selector step 1800: {'selected': 0.9122137404580153, 'score': 0.9122137404580153, 'examples_seen': 49664, 'step': 1800, 'algorithm': 'activity_selector'}
I1007 20:40:38.263525 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.912, val scores are: activity_selector: 0.912
I1007 20:40:39.140352 134831690958336 run.py:734] Algo activity_selector step 1850 current loss 1.179444, current_train_items 51056.
I1007 20:40:39.167465 134831690958336 run.py:769] (val) algo activity_selector step 1850: {'selected': 0.8651488616462347, 'score': 0.8651488616462347, 'examples_seen': 51056, 'step': 1850, 'algorithm': 'activity_selector'}
I1007 20:40:39.167662 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.865, val scores are: activity_selector: 0.865
I1007 20:40:40.037901 134831690958336 run.py:734] Algo activity_selector step 1900 current loss 1.019054, current_train_items 52432.
I1007 20:40:40.065100 134831690958336 run.py:769] (val) algo activity_selector step 1900: {'selected': 0.8610567514677103, 'score': 0.8610567514677103, 'examples_seen': 52432, 'step': 1900, 'algorithm': 'activity_selector'}
I1007 20:40:40.065245 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.861, val scores are: activity_selector: 0.861
I1007 20:40:40.940492 134831690958336 run.py:734] Algo activity_selector step 1950 current loss 1.347747, current_train_items 53808.
I1007 20:40:40.967428 134831690958336 run.py:769] (val) algo activity_selector step 1950: {'selected': 0.8838028169014085, 'score': 0.8838028169014085, 'examples_seen': 53808, 'step': 1950, 'algorithm': 'activity_selector'}
I1007 20:40:40.967576 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.884, val scores are: activity_selector: 0.884
I1007 20:40:41.860862 134831690958336 run.py:734] Algo activity_selector step 2000 current loss 1.359113, current_train_items 55184.
I1007 20:40:41.887710 134831690958336 run.py:769] (val) algo activity_selector step 2000: {'selected': 0.9258589511754068, 'score': 0.9258589511754068, 'examples_seen': 55184, 'step': 2000, 'algorithm': 'activity_selector'}
I1007 20:40:41.887895 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.926, val scores are: activity_selector: 0.926
I1007 20:40:42.753494 134831690958336 run.py:734] Algo activity_selector step 2050 current loss 1.129172, current_train_items 56560.
I1007 20:40:42.779971 134831690958336 run.py:769] (val) algo activity_selector step 2050: {'selected': 0.9266409266409267, 'score': 0.9266409266409267, 'examples_seen': 56560, 'step': 2050, 'algorithm': 'activity_selector'}
I1007 20:40:42.780120 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.927, val scores are: activity_selector: 0.927
I1007 20:40:43.672042 134831690958336 run.py:734] Algo activity_selector step 2100 current loss 1.095082, current_train_items 57952.
I1007 20:40:43.699493 134831690958336 run.py:769] (val) algo activity_selector step 2100: {'selected': 0.9147005444646098, 'score': 0.9147005444646098, 'examples_seen': 57952, 'step': 2100, 'algorithm': 'activity_selector'}
I1007 20:40:43.699655 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.915, val scores are: activity_selector: 0.915
I1007 20:40:44.572973 134831690958336 run.py:734] Algo activity_selector step 2150 current loss 1.562044, current_train_items 59312.
I1007 20:40:44.600105 134831690958336 run.py:769] (val) algo activity_selector step 2150: {'selected': 0.8921389396709324, 'score': 0.8921389396709324, 'examples_seen': 59312, 'step': 2150, 'algorithm': 'activity_selector'}
I1007 20:40:44.600257 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.892, val scores are: activity_selector: 0.892
I1007 20:40:45.479276 134831690958336 run.py:734] Algo activity_selector step 2200 current loss 1.390846, current_train_items 60720.
I1007 20:40:45.505794 134831690958336 run.py:769] (val) algo activity_selector step 2200: {'selected': 0.9053030303030303, 'score': 0.9053030303030303, 'examples_seen': 60720, 'step': 2200, 'algorithm': 'activity_selector'}
I1007 20:40:45.505942 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.905, val scores are: activity_selector: 0.905
I1007 20:40:46.378268 134831690958336 run.py:734] Algo activity_selector step 2250 current loss 1.028139, current_train_items 62080.
I1007 20:40:46.406098 134831690958336 run.py:769] (val) algo activity_selector step 2250: {'selected': 0.9230769230769231, 'score': 0.9230769230769231, 'examples_seen': 62080, 'step': 2250, 'algorithm': 'activity_selector'}
I1007 20:40:46.406247 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.923, val scores are: activity_selector: 0.923
I1007 20:40:47.271633 134831690958336 run.py:734] Algo activity_selector step 2300 current loss 1.440065, current_train_items 63440.
I1007 20:40:47.298257 134831690958336 run.py:769] (val) algo activity_selector step 2300: {'selected': 0.9379562043795621, 'score': 0.9379562043795621, 'examples_seen': 63440, 'step': 2300, 'algorithm': 'activity_selector'}
I1007 20:40:47.298405 134831690958336 run.py:790] Checkpointing best model, best avg val score was 0.933, current avg val score is 0.938, val scores are: activity_selector: 0.938
I1007 20:40:48.200769 134831690958336 run.py:734] Algo activity_selector step 2350 current loss 1.180432, current_train_items 64848.
I1007 20:40:48.228127 134831690958336 run.py:769] (val) algo activity_selector step 2350: {'selected': 0.9669117647058822, 'score': 0.9669117647058822, 'examples_seen': 64848, 'step': 2350, 'algorithm': 'activity_selector'}
I1007 20:40:48.228305 134831690958336 run.py:790] Checkpointing best model, best avg val score was 0.938, current avg val score is 0.967, val scores are: activity_selector: 0.967
I1007 20:40:49.116430 134831690958336 run.py:734] Algo activity_selector step 2400 current loss 1.180415, current_train_items 66208.
I1007 20:40:49.143209 134831690958336 run.py:769] (val) algo activity_selector step 2400: {'selected': 0.9379562043795622, 'score': 0.9379562043795622, 'examples_seen': 66208, 'step': 2400, 'algorithm': 'activity_selector'}
I1007 20:40:49.143357 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.938, val scores are: activity_selector: 0.938
I1007 20:40:50.024790 134831690958336 run.py:734] Algo activity_selector step 2450 current loss 1.497333, current_train_items 67600.
I1007 20:40:50.051694 134831690958336 run.py:769] (val) algo activity_selector step 2450: {'selected': 0.9345794392523364, 'score': 0.9345794392523364, 'examples_seen': 67600, 'step': 2450, 'algorithm': 'activity_selector'}
I1007 20:40:50.051839 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.935, val scores are: activity_selector: 0.935
I1007 20:40:50.918033 134831690958336 run.py:734] Algo activity_selector step 2500 current loss 1.301126, current_train_items 68976.
I1007 20:40:50.944991 134831690958336 run.py:769] (val) algo activity_selector step 2500: {'selected': 0.9084249084249085, 'score': 0.9084249084249085, 'examples_seen': 68976, 'step': 2500, 'algorithm': 'activity_selector'}
I1007 20:40:50.945140 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.908, val scores are: activity_selector: 0.908
I1007 20:40:51.814063 134831690958336 run.py:734] Algo activity_selector step 2550 current loss 1.143867, current_train_items 70352.
I1007 20:40:51.841385 134831690958336 run.py:769] (val) algo activity_selector step 2550: {'selected': 0.9227871939736347, 'score': 0.9227871939736347, 'examples_seen': 70352, 'step': 2550, 'algorithm': 'activity_selector'}
I1007 20:40:51.841536 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.923, val scores are: activity_selector: 0.923
I1007 20:40:52.730091 134831690958336 run.py:734] Algo activity_selector step 2600 current loss 0.841797, current_train_items 71728.
I1007 20:40:52.756628 134831690958336 run.py:769] (val) algo activity_selector step 2600: {'selected': 0.8814814814814814, 'score': 0.8814814814814814, 'examples_seen': 71728, 'step': 2600, 'algorithm': 'activity_selector'}
I1007 20:40:52.756776 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.881, val scores are: activity_selector: 0.881
I1007 20:40:53.631046 134831690958336 run.py:734] Algo activity_selector step 2650 current loss 0.835135, current_train_items 73104.
I1007 20:40:53.657608 134831690958336 run.py:769] (val) algo activity_selector step 2650: {'selected': 0.9416195856873824, 'score': 0.9416195856873824, 'examples_seen': 73104, 'step': 2650, 'algorithm': 'activity_selector'}
I1007 20:40:53.657753 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1007 20:40:54.560698 134831690958336 run.py:734] Algo activity_selector step 2700 current loss 1.039691, current_train_items 74496.
I1007 20:40:54.587400 134831690958336 run.py:769] (val) algo activity_selector step 2700: {'selected': 0.9497206703910615, 'score': 0.9497206703910615, 'examples_seen': 74496, 'step': 2700, 'algorithm': 'activity_selector'}
I1007 20:40:54.587549 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1007 20:40:55.460740 134831690958336 run.py:734] Algo activity_selector step 2750 current loss 0.800145, current_train_items 75856.
I1007 20:40:55.488258 134831690958336 run.py:769] (val) algo activity_selector step 2750: {'selected': 0.9502762430939227, 'score': 0.9502762430939227, 'examples_seen': 75856, 'step': 2750, 'algorithm': 'activity_selector'}
I1007 20:40:55.488412 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1007 20:40:56.367769 134831690958336 run.py:734] Algo activity_selector step 2800 current loss 1.054535, current_train_items 77264.
I1007 20:40:56.395446 134831690958336 run.py:769] (val) algo activity_selector step 2800: {'selected': 0.9261477045908184, 'score': 0.9261477045908184, 'examples_seen': 77264, 'step': 2800, 'algorithm': 'activity_selector'}
I1007 20:40:56.395603 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.926, val scores are: activity_selector: 0.926
I1007 20:40:57.281680 134831690958336 run.py:734] Algo activity_selector step 2850 current loss 1.073156, current_train_items 78624.
I1007 20:40:57.311832 134831690958336 run.py:769] (val) algo activity_selector step 2850: {'selected': 0.9582504970178927, 'score': 0.9582504970178927, 'examples_seen': 78624, 'step': 2850, 'algorithm': 'activity_selector'}
I1007 20:40:57.311983 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.958, val scores are: activity_selector: 0.958
I1007 20:40:58.180175 134831690958336 run.py:734] Algo activity_selector step 2900 current loss 1.286009, current_train_items 80000.
I1007 20:40:58.207741 134831690958336 run.py:769] (val) algo activity_selector step 2900: {'selected': 0.9034907597535933, 'score': 0.9034907597535933, 'examples_seen': 80000, 'step': 2900, 'algorithm': 'activity_selector'}
I1007 20:40:58.207890 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.903, val scores are: activity_selector: 0.903
I1007 20:40:59.090656 134831690958336 run.py:734] Algo activity_selector step 2950 current loss 1.091641, current_train_items 81392.
I1007 20:40:59.118017 134831690958336 run.py:769] (val) algo activity_selector step 2950: {'selected': 0.9320754716981133, 'score': 0.9320754716981133, 'examples_seen': 81392, 'step': 2950, 'algorithm': 'activity_selector'}
I1007 20:40:59.118176 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.932, val scores are: activity_selector: 0.932
I1007 20:40:59.991056 134831690958336 run.py:734] Algo activity_selector step 3000 current loss 1.153852, current_train_items 82752.
I1007 20:41:00.017888 134831690958336 run.py:769] (val) algo activity_selector step 3000: {'selected': 0.9263913824057451, 'score': 0.9263913824057451, 'examples_seen': 82752, 'step': 3000, 'algorithm': 'activity_selector'}
I1007 20:41:00.018039 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.926, val scores are: activity_selector: 0.926
I1007 20:41:00.903675 134831690958336 run.py:734] Algo activity_selector step 3050 current loss 1.158179, current_train_items 84144.
I1007 20:41:00.930559 134831690958336 run.py:769] (val) algo activity_selector step 3050: {'selected': 0.920892494929006, 'score': 0.920892494929006, 'examples_seen': 84144, 'step': 3050, 'algorithm': 'activity_selector'}
I1007 20:41:00.930724 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.921, val scores are: activity_selector: 0.921
I1007 20:41:01.799947 134831690958336 run.py:734] Algo activity_selector step 3100 current loss 1.136679, current_train_items 85520.
I1007 20:41:01.827131 134831690958336 run.py:769] (val) algo activity_selector step 3100: {'selected': 0.9503816793893131, 'score': 0.9503816793893131, 'examples_seen': 85520, 'step': 3100, 'algorithm': 'activity_selector'}
I1007 20:41:01.827282 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1007 20:41:02.706468 134831690958336 run.py:734] Algo activity_selector step 3150 current loss 0.849990, current_train_items 86896.
I1007 20:41:02.733040 134831690958336 run.py:769] (val) algo activity_selector step 3150: {'selected': 0.9636711281070746, 'score': 0.9636711281070746, 'examples_seen': 86896, 'step': 3150, 'algorithm': 'activity_selector'}
I1007 20:41:02.733188 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.964, val scores are: activity_selector: 0.964
I1007 20:41:03.614159 134831690958336 run.py:734] Algo activity_selector step 3200 current loss 0.895415, current_train_items 88272.
I1007 20:41:03.641571 134831690958336 run.py:769] (val) algo activity_selector step 3200: {'selected': 0.9490196078431372, 'score': 0.9490196078431372, 'examples_seen': 88272, 'step': 3200, 'algorithm': 'activity_selector'}
I1007 20:41:03.641732 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.949, val scores are: activity_selector: 0.949
I1007 20:41:04.510131 134831690958336 run.py:734] Algo activity_selector step 3250 current loss 1.031398, current_train_items 89664.
I1007 20:41:04.537041 134831690958336 run.py:769] (val) algo activity_selector step 3250: {'selected': 0.9361702127659575, 'score': 0.9361702127659575, 'examples_seen': 89664, 'step': 3250, 'algorithm': 'activity_selector'}
I1007 20:41:04.537190 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1007 20:41:05.432487 134831690958336 run.py:734] Algo activity_selector step 3300 current loss 0.839954, current_train_items 91040.
I1007 20:41:05.459401 134831690958336 run.py:769] (val) algo activity_selector step 3300: {'selected': 0.9551656920077973, 'score': 0.9551656920077973, 'examples_seen': 91040, 'step': 3300, 'algorithm': 'activity_selector'}
I1007 20:41:05.459548 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.955, val scores are: activity_selector: 0.955
I1007 20:41:06.325651 134831690958336 run.py:734] Algo activity_selector step 3350 current loss 1.145743, current_train_items 92400.
I1007 20:41:06.352213 134831690958336 run.py:769] (val) algo activity_selector step 3350: {'selected': 0.9259962049335863, 'score': 0.9259962049335863, 'examples_seen': 92400, 'step': 3350, 'algorithm': 'activity_selector'}
I1007 20:41:06.352366 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.926, val scores are: activity_selector: 0.926
I1007 20:41:07.227442 134831690958336 run.py:734] Algo activity_selector step 3400 current loss 1.398506, current_train_items 93792.
I1007 20:41:07.254237 134831690958336 run.py:769] (val) algo activity_selector step 3400: {'selected': 0.9343065693430657, 'score': 0.9343065693430657, 'examples_seen': 93792, 'step': 3400, 'algorithm': 'activity_selector'}
I1007 20:41:07.254385 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.934, val scores are: activity_selector: 0.934
I1007 20:41:08.140868 134831690958336 run.py:734] Algo activity_selector step 3450 current loss 1.163460, current_train_items 95168.
I1007 20:41:08.168087 134831690958336 run.py:769] (val) algo activity_selector step 3450: {'selected': 0.9157088122605364, 'score': 0.9157088122605364, 'examples_seen': 95168, 'step': 3450, 'algorithm': 'activity_selector'}
I1007 20:41:08.168239 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.916, val scores are: activity_selector: 0.916
I1007 20:41:09.047901 134831690958336 run.py:734] Algo activity_selector step 3500 current loss 0.997836, current_train_items 96544.
I1007 20:41:09.075148 134831690958336 run.py:769] (val) algo activity_selector step 3500: {'selected': 0.9359223300970874, 'score': 0.9359223300970874, 'examples_seen': 96544, 'step': 3500, 'algorithm': 'activity_selector'}
I1007 20:41:09.075297 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1007 20:41:09.958268 134831690958336 run.py:734] Algo activity_selector step 3550 current loss 0.938548, current_train_items 97936.
I1007 20:41:09.985859 134831690958336 run.py:769] (val) algo activity_selector step 3550: {'selected': 0.9674952198852772, 'score': 0.9674952198852772, 'examples_seen': 97936, 'step': 3550, 'algorithm': 'activity_selector'}
I1007 20:41:09.986015 134831690958336 run.py:790] Checkpointing best model, best avg val score was 0.967, current avg val score is 0.967, val scores are: activity_selector: 0.967
I1007 20:41:10.886387 134831690958336 run.py:734] Algo activity_selector step 3600 current loss 1.062882, current_train_items 99312.
I1007 20:41:10.913366 134831690958336 run.py:769] (val) algo activity_selector step 3600: {'selected': 0.9467213114754099, 'score': 0.9467213114754099, 'examples_seen': 99312, 'step': 3600, 'algorithm': 'activity_selector'}
I1007 20:41:10.913516 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.947, val scores are: activity_selector: 0.947
I1007 20:41:11.794782 134831690958336 run.py:734] Algo activity_selector step 3650 current loss 1.153901, current_train_items 100688.
I1007 20:41:11.821540 134831690958336 run.py:769] (val) algo activity_selector step 3650: {'selected': 0.936247723132969, 'score': 0.936247723132969, 'examples_seen': 100688, 'step': 3650, 'algorithm': 'activity_selector'}
I1007 20:41:11.821702 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1007 20:41:12.703773 134831690958336 run.py:734] Algo activity_selector step 3700 current loss 0.956362, current_train_items 102064.
I1007 20:41:12.730291 134831690958336 run.py:769] (val) algo activity_selector step 3700: {'selected': 0.9625246548323472, 'score': 0.9625246548323472, 'examples_seen': 102064, 'step': 3700, 'algorithm': 'activity_selector'}
I1007 20:41:12.730455 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.963, val scores are: activity_selector: 0.963
I1007 20:41:13.611956 134831690958336 run.py:734] Algo activity_selector step 3750 current loss 0.870105, current_train_items 103440.
I1007 20:41:13.638912 134831690958336 run.py:769] (val) algo activity_selector step 3750: {'selected': 0.9216757741347905, 'score': 0.9216757741347905, 'examples_seen': 103440, 'step': 3750, 'algorithm': 'activity_selector'}
I1007 20:41:13.639064 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.922, val scores are: activity_selector: 0.922
I1007 20:41:14.522966 134831690958336 run.py:734] Algo activity_selector step 3800 current loss 1.081710, current_train_items 104816.
I1007 20:41:14.549738 134831690958336 run.py:769] (val) algo activity_selector step 3800: {'selected': 0.9432485322896281, 'score': 0.9432485322896281, 'examples_seen': 104816, 'step': 3800, 'algorithm': 'activity_selector'}
I1007 20:41:14.549884 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1007 20:41:15.426798 134831690958336 run.py:734] Algo activity_selector step 3850 current loss 0.982539, current_train_items 106208.
I1007 20:41:15.453612 134831690958336 run.py:769] (val) algo activity_selector step 3850: {'selected': 0.9587426326129667, 'score': 0.9587426326129667, 'examples_seen': 106208, 'step': 3850, 'algorithm': 'activity_selector'}
I1007 20:41:15.453762 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.959, val scores are: activity_selector: 0.959
I1007 20:41:16.341477 134831690958336 run.py:734] Algo activity_selector step 3900 current loss 0.949521, current_train_items 107584.
I1007 20:41:16.368598 134831690958336 run.py:769] (val) algo activity_selector step 3900: {'selected': 0.9014598540145987, 'score': 0.9014598540145987, 'examples_seen': 107584, 'step': 3900, 'algorithm': 'activity_selector'}
I1007 20:41:16.368751 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.901, val scores are: activity_selector: 0.901
I1007 20:41:17.240230 134831690958336 run.py:734] Algo activity_selector step 3950 current loss 0.830755, current_train_items 108960.
I1007 20:41:17.270128 134831690958336 run.py:769] (val) algo activity_selector step 3950: {'selected': 0.9178571428571429, 'score': 0.9178571428571429, 'examples_seen': 108960, 'step': 3950, 'algorithm': 'activity_selector'}
I1007 20:41:17.270279 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.918, val scores are: activity_selector: 0.918
I1007 20:41:18.143573 134831690958336 run.py:734] Algo activity_selector step 4000 current loss 0.850869, current_train_items 110336.
I1007 20:41:18.171130 134831690958336 run.py:769] (val) algo activity_selector step 4000: {'selected': 0.9112426035502958, 'score': 0.9112426035502958, 'examples_seen': 110336, 'step': 4000, 'algorithm': 'activity_selector'}
I1007 20:41:18.171277 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.911, val scores are: activity_selector: 0.911
I1007 20:41:19.058765 134831690958336 run.py:734] Algo activity_selector step 4050 current loss 0.915531, current_train_items 111712.
I1007 20:41:19.086208 134831690958336 run.py:769] (val) algo activity_selector step 4050: {'selected': 0.9538461538461539, 'score': 0.9538461538461539, 'examples_seen': 111712, 'step': 4050, 'algorithm': 'activity_selector'}
I1007 20:41:19.086356 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.954, val scores are: activity_selector: 0.954
I1007 20:41:19.958288 134831690958336 run.py:734] Algo activity_selector step 4100 current loss 0.849244, current_train_items 113088.
I1007 20:41:19.985579 134831690958336 run.py:769] (val) algo activity_selector step 4100: {'selected': 0.9709090909090908, 'score': 0.9709090909090908, 'examples_seen': 113088, 'step': 4100, 'algorithm': 'activity_selector'}
I1007 20:41:19.985734 134831690958336 run.py:790] Checkpointing best model, best avg val score was 0.967, current avg val score is 0.971, val scores are: activity_selector: 0.971
I1007 20:41:20.885938 134831690958336 run.py:734] Algo activity_selector step 4150 current loss 0.806006, current_train_items 114480.
I1007 20:41:20.912790 134831690958336 run.py:769] (val) algo activity_selector step 4150: {'selected': 0.9720670391061453, 'score': 0.9720670391061453, 'examples_seen': 114480, 'step': 4150, 'algorithm': 'activity_selector'}
I1007 20:41:20.912940 134831690958336 run.py:790] Checkpointing best model, best avg val score was 0.971, current avg val score is 0.972, val scores are: activity_selector: 0.972
I1007 20:41:21.820903 134831690958336 run.py:734] Algo activity_selector step 4200 current loss 1.219014, current_train_items 115856.
I1007 20:41:21.847670 134831690958336 run.py:769] (val) algo activity_selector step 4200: {'selected': 0.931237721021611, 'score': 0.931237721021611, 'examples_seen': 115856, 'step': 4200, 'algorithm': 'activity_selector'}
I1007 20:41:21.847818 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1007 20:41:22.719341 134831690958336 run.py:734] Algo activity_selector step 4250 current loss 1.348010, current_train_items 117216.
I1007 20:41:22.746537 134831690958336 run.py:769] (val) algo activity_selector step 4250: {'selected': 0.911070780399274, 'score': 0.911070780399274, 'examples_seen': 117216, 'step': 4250, 'algorithm': 'activity_selector'}
I1007 20:41:22.746698 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.911, val scores are: activity_selector: 0.911
I1007 20:41:23.635797 134831690958336 run.py:734] Algo activity_selector step 4300 current loss 1.177654, current_train_items 118624.
I1007 20:41:23.663204 134831690958336 run.py:769] (val) algo activity_selector step 4300: {'selected': 0.9239332096474954, 'score': 0.9239332096474954, 'examples_seen': 118624, 'step': 4300, 'algorithm': 'activity_selector'}
I1007 20:41:23.663354 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.924, val scores are: activity_selector: 0.924
I1007 20:41:24.545686 134831690958336 run.py:734] Algo activity_selector step 4350 current loss 0.852665, current_train_items 119984.
I1007 20:41:24.572442 134831690958336 run.py:769] (val) algo activity_selector step 4350: {'selected': 0.9423076923076923, 'score': 0.9423076923076923, 'examples_seen': 119984, 'step': 4350, 'algorithm': 'activity_selector'}
I1007 20:41:24.572601 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1007 20:41:25.458139 134831690958336 run.py:734] Algo activity_selector step 4400 current loss 0.778085, current_train_items 121360.
I1007 20:41:25.485152 134831690958336 run.py:769] (val) algo activity_selector step 4400: {'selected': 0.969811320754717, 'score': 0.969811320754717, 'examples_seen': 121360, 'step': 4400, 'algorithm': 'activity_selector'}
I1007 20:41:25.485299 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.970, val scores are: activity_selector: 0.970
I1007 20:41:26.364109 134831690958336 run.py:734] Algo activity_selector step 4450 current loss 1.030787, current_train_items 122752.
I1007 20:41:26.390902 134831690958336 run.py:769] (val) algo activity_selector step 4450: {'selected': 0.9685039370078741, 'score': 0.9685039370078741, 'examples_seen': 122752, 'step': 4450, 'algorithm': 'activity_selector'}
I1007 20:41:26.391053 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.969, val scores are: activity_selector: 0.969
I1007 20:41:27.267390 134831690958336 run.py:734] Algo activity_selector step 4500 current loss 0.969207, current_train_items 124128.
I1007 20:41:27.293927 134831690958336 run.py:769] (val) algo activity_selector step 4500: {'selected': 0.9566929133858267, 'score': 0.9566929133858267, 'examples_seen': 124128, 'step': 4500, 'algorithm': 'activity_selector'}
I1007 20:41:27.294080 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.957, val scores are: activity_selector: 0.957
I1007 20:41:28.176743 134831690958336 run.py:734] Algo activity_selector step 4550 current loss 0.747468, current_train_items 125504.
I1007 20:41:28.204884 134831690958336 run.py:769] (val) algo activity_selector step 4550: {'selected': 0.9588477366255144, 'score': 0.9588477366255144, 'examples_seen': 125504, 'step': 4550, 'algorithm': 'activity_selector'}
I1007 20:41:28.205031 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.959, val scores are: activity_selector: 0.959
I1007 20:41:29.066672 134831690958336 run.py:734] Algo activity_selector step 4600 current loss 1.186943, current_train_items 126880.
I1007 20:41:29.093495 134831690958336 run.py:769] (val) algo activity_selector step 4600: {'selected': 0.953307392996109, 'score': 0.953307392996109, 'examples_seen': 126880, 'step': 4600, 'algorithm': 'activity_selector'}
I1007 20:41:29.093649 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1007 20:41:29.972816 134831690958336 run.py:734] Algo activity_selector step 4650 current loss 0.738204, current_train_items 128272.
I1007 20:41:29.999737 134831690958336 run.py:769] (val) algo activity_selector step 4650: {'selected': 0.9508840864440079, 'score': 0.9508840864440079, 'examples_seen': 128272, 'step': 4650, 'algorithm': 'activity_selector'}
I1007 20:41:29.999886 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.951, val scores are: activity_selector: 0.951
I1007 20:41:30.867897 134831690958336 run.py:734] Algo activity_selector step 4700 current loss 0.951057, current_train_items 129632.
I1007 20:41:30.894925 134831690958336 run.py:769] (val) algo activity_selector step 4700: {'selected': 0.9156193895870737, 'score': 0.9156193895870737, 'examples_seen': 129632, 'step': 4700, 'algorithm': 'activity_selector'}
I1007 20:41:30.895073 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.916, val scores are: activity_selector: 0.916
I1007 20:41:31.770773 134831690958336 run.py:734] Algo activity_selector step 4750 current loss 1.125878, current_train_items 131024.
I1007 20:41:31.798317 134831690958336 run.py:769] (val) algo activity_selector step 4750: {'selected': 0.9124087591240877, 'score': 0.9124087591240877, 'examples_seen': 131024, 'step': 4750, 'algorithm': 'activity_selector'}
I1007 20:41:31.798466 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.912, val scores are: activity_selector: 0.912
I1007 20:41:32.673799 134831690958336 run.py:734] Algo activity_selector step 4800 current loss 0.938212, current_train_items 132400.
I1007 20:41:32.701104 134831690958336 run.py:769] (val) algo activity_selector step 4800: {'selected': 0.9159999999999999, 'score': 0.9159999999999999, 'examples_seen': 132400, 'step': 4800, 'algorithm': 'activity_selector'}
I1007 20:41:32.701252 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.916, val scores are: activity_selector: 0.916
I1007 20:41:33.565241 134831690958336 run.py:734] Algo activity_selector step 4850 current loss 0.837693, current_train_items 133760.
I1007 20:41:33.595380 134831690958336 run.py:769] (val) algo activity_selector step 4850: {'selected': 0.9225092250922509, 'score': 0.9225092250922509, 'examples_seen': 133760, 'step': 4850, 'algorithm': 'activity_selector'}
I1007 20:41:33.595552 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.923, val scores are: activity_selector: 0.923
I1007 20:41:34.479772 134831690958336 run.py:734] Algo activity_selector step 4900 current loss 0.792965, current_train_items 135168.
I1007 20:41:34.506320 134831690958336 run.py:769] (val) algo activity_selector step 4900: {'selected': 0.9640287769784173, 'score': 0.9640287769784173, 'examples_seen': 135168, 'step': 4900, 'algorithm': 'activity_selector'}
I1007 20:41:34.506464 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.964, val scores are: activity_selector: 0.964
I1007 20:41:35.373345 134831690958336 run.py:734] Algo activity_selector step 4950 current loss 0.763681, current_train_items 136528.
I1007 20:41:35.400614 134831690958336 run.py:769] (val) algo activity_selector step 4950: {'selected': 0.9543726235741445, 'score': 0.9543726235741445, 'examples_seen': 136528, 'step': 4950, 'algorithm': 'activity_selector'}
I1007 20:41:35.400763 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.954, val scores are: activity_selector: 0.954
I1007 20:41:36.307426 134831690958336 run.py:734] Algo activity_selector step 5000 current loss 0.667691, current_train_items 137920.
I1007 20:41:36.334296 134831690958336 run.py:769] (val) algo activity_selector step 5000: {'selected': 0.9646182495344505, 'score': 0.9646182495344505, 'examples_seen': 137920, 'step': 5000, 'algorithm': 'activity_selector'}
I1007 20:41:36.334446 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.965, val scores are: activity_selector: 0.965
I1007 20:41:37.214904 134831690958336 run.py:734] Algo activity_selector step 5050 current loss 0.942462, current_train_items 139296.
I1007 20:41:37.241996 134831690958336 run.py:769] (val) algo activity_selector step 5050: {'selected': 0.9558232931726908, 'score': 0.9558232931726908, 'examples_seen': 139296, 'step': 5050, 'algorithm': 'activity_selector'}
I1007 20:41:37.242142 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1007 20:41:38.120497 134831690958336 run.py:734] Algo activity_selector step 5100 current loss 0.773424, current_train_items 140656.
I1007 20:41:38.147716 134831690958336 run.py:769] (val) algo activity_selector step 5100: {'selected': 0.9350180505415163, 'score': 0.9350180505415163, 'examples_seen': 140656, 'step': 5100, 'algorithm': 'activity_selector'}
I1007 20:41:38.147866 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.935, val scores are: activity_selector: 0.935
I1007 20:41:39.036598 134831690958336 run.py:734] Algo activity_selector step 5150 current loss 1.790131, current_train_items 142048.
I1007 20:41:39.063851 134831690958336 run.py:769] (val) algo activity_selector step 5150: {'selected': 0.9057377049180328, 'score': 0.9057377049180328, 'examples_seen': 142048, 'step': 5150, 'algorithm': 'activity_selector'}
I1007 20:41:39.064002 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.906, val scores are: activity_selector: 0.906
I1007 20:41:39.934488 134831690958336 run.py:734] Algo activity_selector step 5200 current loss 0.800983, current_train_items 143424.
I1007 20:41:39.961469 134831690958336 run.py:769] (val) algo activity_selector step 5200: {'selected': 0.9496124031007752, 'score': 0.9496124031007752, 'examples_seen': 143424, 'step': 5200, 'algorithm': 'activity_selector'}
I1007 20:41:39.961632 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1007 20:41:40.854926 134831690958336 run.py:734] Algo activity_selector step 5250 current loss 0.967358, current_train_items 144816.
I1007 20:41:40.882627 134831690958336 run.py:769] (val) algo activity_selector step 5250: {'selected': 0.8964285714285714, 'score': 0.8964285714285714, 'examples_seen': 144816, 'step': 5250, 'algorithm': 'activity_selector'}
I1007 20:41:40.882777 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.896, val scores are: activity_selector: 0.896
I1007 20:41:41.745161 134831690958336 run.py:734] Algo activity_selector step 5300 current loss 0.934729, current_train_items 146176.
I1007 20:41:41.772725 134831690958336 run.py:769] (val) algo activity_selector step 5300: {'selected': 0.9422718808193669, 'score': 0.9422718808193669, 'examples_seen': 146176, 'step': 5300, 'algorithm': 'activity_selector'}
I1007 20:41:41.772875 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1007 20:41:42.638416 134831690958336 run.py:734] Algo activity_selector step 5350 current loss 0.733480, current_train_items 147584.
I1007 20:41:42.665563 134831690958336 run.py:769] (val) algo activity_selector step 5350: {'selected': 0.9422382671480144, 'score': 0.9422382671480144, 'examples_seen': 147584, 'step': 5350, 'algorithm': 'activity_selector'}
I1007 20:41:42.665722 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1007 20:41:43.550190 134831690958336 run.py:734] Algo activity_selector step 5400 current loss 1.071393, current_train_items 148944.
I1007 20:41:43.576941 134831690958336 run.py:769] (val) algo activity_selector step 5400: {'selected': 0.9607843137254902, 'score': 0.9607843137254902, 'examples_seen': 148944, 'step': 5400, 'algorithm': 'activity_selector'}
I1007 20:41:43.577090 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.961, val scores are: activity_selector: 0.961
I1007 20:41:44.440114 134831690958336 run.py:734] Algo activity_selector step 5450 current loss 0.847736, current_train_items 150304.
I1007 20:41:44.467502 134831690958336 run.py:769] (val) algo activity_selector step 5450: {'selected': 0.9495327102803738, 'score': 0.9495327102803738, 'examples_seen': 150304, 'step': 5450, 'algorithm': 'activity_selector'}
I1007 20:41:44.467661 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1007 20:41:45.346599 134831690958336 run.py:734] Algo activity_selector step 5500 current loss 1.441635, current_train_items 151712.
I1007 20:41:45.373615 134831690958336 run.py:769] (val) algo activity_selector step 5500: {'selected': 0.94140625, 'score': 0.94140625, 'examples_seen': 151712, 'step': 5500, 'algorithm': 'activity_selector'}
I1007 20:41:45.373764 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.941, val scores are: activity_selector: 0.941
I1007 20:41:46.252302 134831690958336 run.py:734] Algo activity_selector step 5550 current loss 0.973932, current_train_items 153072.
I1007 20:41:46.279619 134831690958336 run.py:769] (val) algo activity_selector step 5550: {'selected': 0.9658886894075404, 'score': 0.9658886894075404, 'examples_seen': 153072, 'step': 5550, 'algorithm': 'activity_selector'}
I1007 20:41:46.279768 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.966, val scores are: activity_selector: 0.966
I1007 20:41:47.173614 134831690958336 run.py:734] Algo activity_selector step 5600 current loss 0.692166, current_train_items 154464.
I1007 20:41:47.200885 134831690958336 run.py:769] (val) algo activity_selector step 5600: {'selected': 0.9423868312757202, 'score': 0.9423868312757202, 'examples_seen': 154464, 'step': 5600, 'algorithm': 'activity_selector'}
I1007 20:41:47.201049 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1007 20:41:48.075282 134831690958336 run.py:734] Algo activity_selector step 5650 current loss 0.769638, current_train_items 155840.
I1007 20:41:48.102263 134831690958336 run.py:769] (val) algo activity_selector step 5650: {'selected': 0.9261261261261261, 'score': 0.9261261261261261, 'examples_seen': 155840, 'step': 5650, 'algorithm': 'activity_selector'}
I1007 20:41:48.102414 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.926, val scores are: activity_selector: 0.926
I1007 20:41:48.980112 134831690958336 run.py:734] Algo activity_selector step 5700 current loss 0.818646, current_train_items 157216.
I1007 20:41:49.007459 134831690958336 run.py:769] (val) algo activity_selector step 5700: {'selected': 0.9361702127659575, 'score': 0.9361702127659575, 'examples_seen': 157216, 'step': 5700, 'algorithm': 'activity_selector'}
I1007 20:41:49.007616 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1007 20:41:49.900769 134831690958336 run.py:734] Algo activity_selector step 5750 current loss 0.860535, current_train_items 158592.
I1007 20:41:49.927600 134831690958336 run.py:769] (val) algo activity_selector step 5750: {'selected': 0.9582504970178927, 'score': 0.9582504970178927, 'examples_seen': 158592, 'step': 5750, 'algorithm': 'activity_selector'}
I1007 20:41:49.927751 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.958, val scores are: activity_selector: 0.958
I1007 20:41:50.798643 134831690958336 run.py:734] Algo activity_selector step 5800 current loss 0.657702, current_train_items 159968.
I1007 20:41:50.826452 134831690958336 run.py:769] (val) algo activity_selector step 5800: {'selected': 0.9671179883945842, 'score': 0.9671179883945842, 'examples_seen': 159968, 'step': 5800, 'algorithm': 'activity_selector'}
I1007 20:41:50.826608 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.967, val scores are: activity_selector: 0.967
I1007 20:41:51.724054 134831690958336 run.py:734] Algo activity_selector step 5850 current loss 0.899657, current_train_items 161360.
I1007 20:41:51.750794 134831690958336 run.py:769] (val) algo activity_selector step 5850: {'selected': 0.9585798816568047, 'score': 0.9585798816568047, 'examples_seen': 161360, 'step': 5850, 'algorithm': 'activity_selector'}
I1007 20:41:51.750942 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.959, val scores are: activity_selector: 0.959
I1007 20:41:52.624618 134831690958336 run.py:734] Algo activity_selector step 5900 current loss 0.988489, current_train_items 162720.
I1007 20:41:52.654505 134831690958336 run.py:769] (val) algo activity_selector step 5900: {'selected': 0.9461966604823747, 'score': 0.9461966604823747, 'examples_seen': 162720, 'step': 5900, 'algorithm': 'activity_selector'}
I1007 20:41:52.654663 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.946, val scores are: activity_selector: 0.946
I1007 20:41:53.532890 134831690958336 run.py:734] Algo activity_selector step 5950 current loss 0.588669, current_train_items 164112.
I1007 20:41:53.559905 134831690958336 run.py:769] (val) algo activity_selector step 5950: {'selected': 0.9534883720930233, 'score': 0.9534883720930233, 'examples_seen': 164112, 'step': 5950, 'algorithm': 'activity_selector'}
I1007 20:41:53.560053 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1007 20:41:54.452931 134831690958336 run.py:734] Algo activity_selector step 6000 current loss 1.143994, current_train_items 165488.
I1007 20:41:54.482987 134831690958336 run.py:769] (val) algo activity_selector step 6000: {'selected': 0.9318600368324125, 'score': 0.9318600368324125, 'examples_seen': 165488, 'step': 6000, 'algorithm': 'activity_selector'}
I1007 20:41:54.483138 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.932, val scores are: activity_selector: 0.932
I1007 20:41:55.357370 134831690958336 run.py:734] Algo activity_selector step 6050 current loss 0.876879, current_train_items 166864.
I1007 20:41:55.384223 134831690958336 run.py:769] (val) algo activity_selector step 6050: {'selected': 0.9206349206349207, 'score': 0.9206349206349207, 'examples_seen': 166864, 'step': 6050, 'algorithm': 'activity_selector'}
I1007 20:41:55.384375 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.921, val scores are: activity_selector: 0.921
I1007 20:41:56.273366 134831690958336 run.py:734] Algo activity_selector step 6100 current loss 0.986633, current_train_items 168256.
I1007 20:41:56.300237 134831690958336 run.py:769] (val) algo activity_selector step 6100: {'selected': 0.9227557411273486, 'score': 0.9227557411273486, 'examples_seen': 168256, 'step': 6100, 'algorithm': 'activity_selector'}
I1007 20:41:56.300385 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.923, val scores are: activity_selector: 0.923
I1007 20:41:57.180042 134831690958336 run.py:734] Algo activity_selector step 6150 current loss 0.924204, current_train_items 169616.
I1007 20:41:57.206503 134831690958336 run.py:769] (val) algo activity_selector step 6150: {'selected': 0.9603340292275574, 'score': 0.9603340292275574, 'examples_seen': 169616, 'step': 6150, 'algorithm': 'activity_selector'}
I1007 20:41:57.206658 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.960, val scores are: activity_selector: 0.960
I1007 20:41:58.088932 134831690958336 run.py:734] Algo activity_selector step 6200 current loss 0.615051, current_train_items 171008.
I1007 20:41:58.115982 134831690958336 run.py:769] (val) algo activity_selector step 6200: {'selected': 0.9421841541755889, 'score': 0.9421841541755889, 'examples_seen': 171008, 'step': 6200, 'algorithm': 'activity_selector'}
I1007 20:41:58.116131 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.972, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1007 20:41:59.001445 134831690958336 run.py:734] Algo activity_selector step 6250 current loss 0.801316, current_train_items 172384.
I1007 20:41:59.028261 134831690958336 run.py:769] (val) algo activity_selector step 6250: {'selected': 0.9769230769230769, 'score': 0.9769230769230769, 'examples_seen': 172384, 'step': 6250, 'algorithm': 'activity_selector'}
I1007 20:41:59.028418 134831690958336 run.py:790] Checkpointing best model, best avg val score was 0.972, current avg val score is 0.977, val scores are: activity_selector: 0.977
I1007 20:41:59.935666 134831690958336 run.py:734] Algo activity_selector step 6300 current loss 0.554606, current_train_items 173760.
I1007 20:41:59.963312 134831690958336 run.py:769] (val) algo activity_selector step 6300: {'selected': 0.9727626459143969, 'score': 0.9727626459143969, 'examples_seen': 173760, 'step': 6300, 'algorithm': 'activity_selector'}
I1007 20:41:59.963458 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.973, val scores are: activity_selector: 0.973
I1007 20:42:00.860265 134831690958336 run.py:734] Algo activity_selector step 6350 current loss 0.791949, current_train_items 175136.
I1007 20:42:00.887748 134831690958336 run.py:769] (val) algo activity_selector step 6350: {'selected': 0.9304174950298211, 'score': 0.9304174950298211, 'examples_seen': 175136, 'step': 6350, 'algorithm': 'activity_selector'}
I1007 20:42:00.887904 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.930, val scores are: activity_selector: 0.930
I1007 20:42:01.759099 134831690958336 run.py:734] Algo activity_selector step 6400 current loss 0.699798, current_train_items 176528.
I1007 20:42:01.785725 134831690958336 run.py:769] (val) algo activity_selector step 6400: {'selected': 0.92578125, 'score': 0.92578125, 'examples_seen': 176528, 'step': 6400, 'algorithm': 'activity_selector'}
I1007 20:42:01.785872 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.926, val scores are: activity_selector: 0.926
I1007 20:42:02.674367 134831690958336 run.py:734] Algo activity_selector step 6450 current loss 0.548319, current_train_items 177904.
I1007 20:42:02.701205 134831690958336 run.py:769] (val) algo activity_selector step 6450: {'selected': 0.9595588235294118, 'score': 0.9595588235294118, 'examples_seen': 177904, 'step': 6450, 'algorithm': 'activity_selector'}
I1007 20:42:02.701357 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.960, val scores are: activity_selector: 0.960
I1007 20:42:03.568110 134831690958336 run.py:734] Algo activity_selector step 6500 current loss 0.574492, current_train_items 179264.
I1007 20:42:03.595183 134831690958336 run.py:769] (val) algo activity_selector step 6500: {'selected': 0.9539007092198581, 'score': 0.9539007092198581, 'examples_seen': 179264, 'step': 6500, 'algorithm': 'activity_selector'}
I1007 20:42:03.595331 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.954, val scores are: activity_selector: 0.954
I1007 20:42:04.471745 134831690958336 run.py:734] Algo activity_selector step 6550 current loss 0.645682, current_train_items 180656.
I1007 20:42:04.499028 134831690958336 run.py:769] (val) algo activity_selector step 6550: {'selected': 0.9213483146067416, 'score': 0.9213483146067416, 'examples_seen': 180656, 'step': 6550, 'algorithm': 'activity_selector'}
I1007 20:42:04.499226 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.921, val scores are: activity_selector: 0.921
I1007 20:42:05.384145 134831690958336 run.py:734] Algo activity_selector step 6600 current loss 0.858447, current_train_items 182032.
I1007 20:42:05.411387 134831690958336 run.py:769] (val) algo activity_selector step 6600: {'selected': 0.9525616698292221, 'score': 0.9525616698292221, 'examples_seen': 182032, 'step': 6600, 'algorithm': 'activity_selector'}
I1007 20:42:05.411548 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1007 20:42:06.284152 134831690958336 run.py:734] Algo activity_selector step 6650 current loss 1.126851, current_train_items 183408.
I1007 20:42:06.311286 134831690958336 run.py:769] (val) algo activity_selector step 6650: {'selected': 0.9105058365758755, 'score': 0.9105058365758755, 'examples_seen': 183408, 'step': 6650, 'algorithm': 'activity_selector'}
I1007 20:42:06.311451 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.911, val scores are: activity_selector: 0.911
I1007 20:42:07.190563 134831690958336 run.py:734] Algo activity_selector step 6700 current loss 0.602258, current_train_items 184800.
I1007 20:42:07.217826 134831690958336 run.py:769] (val) algo activity_selector step 6700: {'selected': 0.9660678642714571, 'score': 0.9660678642714571, 'examples_seen': 184800, 'step': 6700, 'algorithm': 'activity_selector'}
I1007 20:42:07.217987 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.966, val scores are: activity_selector: 0.966
I1007 20:42:08.087631 134831690958336 run.py:734] Algo activity_selector step 6750 current loss 0.561464, current_train_items 186176.
I1007 20:42:08.115063 134831690958336 run.py:769] (val) algo activity_selector step 6750: {'selected': 0.9722222222222223, 'score': 0.9722222222222223, 'examples_seen': 186176, 'step': 6750, 'algorithm': 'activity_selector'}
I1007 20:42:08.115236 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.972, val scores are: activity_selector: 0.972
I1007 20:42:08.983527 134831690958336 run.py:734] Algo activity_selector step 6800 current loss 0.796739, current_train_items 187536.
I1007 20:42:09.010653 134831690958336 run.py:769] (val) algo activity_selector step 6800: {'selected': 0.9439071566731142, 'score': 0.9439071566731142, 'examples_seen': 187536, 'step': 6800, 'algorithm': 'activity_selector'}
I1007 20:42:09.010816 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.944, val scores are: activity_selector: 0.944
I1007 20:42:09.893289 134831690958336 run.py:734] Algo activity_selector step 6850 current loss 0.906790, current_train_items 188928.
I1007 20:42:09.919970 134831690958336 run.py:769] (val) algo activity_selector step 6850: {'selected': 0.9269162210338682, 'score': 0.9269162210338682, 'examples_seen': 188928, 'step': 6850, 'algorithm': 'activity_selector'}
I1007 20:42:09.920133 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.927, val scores are: activity_selector: 0.927
I1007 20:42:10.799740 134831690958336 run.py:734] Algo activity_selector step 6900 current loss 0.639313, current_train_items 190304.
I1007 20:42:10.826814 134831690958336 run.py:769] (val) algo activity_selector step 6900: {'selected': 0.943609022556391, 'score': 0.943609022556391, 'examples_seen': 190304, 'step': 6900, 'algorithm': 'activity_selector'}
I1007 20:42:10.826963 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.944, val scores are: activity_selector: 0.944
I1007 20:42:11.700442 134831690958336 run.py:734] Algo activity_selector step 6950 current loss 0.707434, current_train_items 191680.
I1007 20:42:11.727731 134831690958336 run.py:769] (val) algo activity_selector step 6950: {'selected': 0.9320388349514563, 'score': 0.9320388349514563, 'examples_seen': 191680, 'step': 6950, 'algorithm': 'activity_selector'}
I1007 20:42:11.727916 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.932, val scores are: activity_selector: 0.932
I1007 20:42:12.600277 134831690958336 run.py:734] Algo activity_selector step 7000 current loss 0.825033, current_train_items 193072.
I1007 20:42:12.627619 134831690958336 run.py:769] (val) algo activity_selector step 7000: {'selected': 0.9453125000000001, 'score': 0.9453125000000001, 'examples_seen': 193072, 'step': 7000, 'algorithm': 'activity_selector'}
I1007 20:42:12.627770 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.945, val scores are: activity_selector: 0.945
I1007 20:42:13.499289 134831690958336 run.py:734] Algo activity_selector step 7050 current loss 0.595972, current_train_items 194448.
I1007 20:42:13.526007 134831690958336 run.py:769] (val) algo activity_selector step 7050: {'selected': 0.9563567362428843, 'score': 0.9563567362428843, 'examples_seen': 194448, 'step': 7050, 'algorithm': 'activity_selector'}
I1007 20:42:13.526155 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1007 20:42:14.403249 134831690958336 run.py:734] Algo activity_selector step 7100 current loss 1.012208, current_train_items 195824.
I1007 20:42:14.430772 134831690958336 run.py:769] (val) algo activity_selector step 7100: {'selected': 0.9666666666666667, 'score': 0.9666666666666667, 'examples_seen': 195824, 'step': 7100, 'algorithm': 'activity_selector'}
I1007 20:42:14.430918 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.967, val scores are: activity_selector: 0.967
I1007 20:42:15.299177 134831690958336 run.py:734] Algo activity_selector step 7150 current loss 0.783316, current_train_items 197200.
I1007 20:42:15.325894 134831690958336 run.py:769] (val) algo activity_selector step 7150: {'selected': 0.9555125725338492, 'score': 0.9555125725338492, 'examples_seen': 197200, 'step': 7150, 'algorithm': 'activity_selector'}
I1007 20:42:15.326042 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1007 20:42:16.209632 134831690958336 run.py:734] Algo activity_selector step 7200 current loss 0.920321, current_train_items 198576.
I1007 20:42:16.236784 134831690958336 run.py:769] (val) algo activity_selector step 7200: {'selected': 0.965376782077393, 'score': 0.965376782077393, 'examples_seen': 198576, 'step': 7200, 'algorithm': 'activity_selector'}
I1007 20:42:16.236933 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.965, val scores are: activity_selector: 0.965
I1007 20:42:17.118537 134831690958336 run.py:734] Algo activity_selector step 7250 current loss 0.687484, current_train_items 199952.
I1007 20:42:17.145760 134831690958336 run.py:769] (val) algo activity_selector step 7250: {'selected': 0.9843749999999999, 'score': 0.9843749999999999, 'examples_seen': 199952, 'step': 7250, 'algorithm': 'activity_selector'}
I1007 20:42:17.145909 134831690958336 run.py:790] Checkpointing best model, best avg val score was 0.977, current avg val score is 0.984, val scores are: activity_selector: 0.984
I1007 20:42:18.052851 134831690958336 run.py:734] Algo activity_selector step 7300 current loss 0.797575, current_train_items 201344.
I1007 20:42:18.079787 134831690958336 run.py:769] (val) algo activity_selector step 7300: {'selected': 0.9619771863117871, 'score': 0.9619771863117871, 'examples_seen': 201344, 'step': 7300, 'algorithm': 'activity_selector'}
I1007 20:42:18.079933 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.962, val scores are: activity_selector: 0.962
I1007 20:42:18.973992 134831690958336 run.py:734] Algo activity_selector step 7350 current loss 0.815107, current_train_items 202720.
I1007 20:42:19.001562 134831690958336 run.py:769] (val) algo activity_selector step 7350: {'selected': 0.9477911646586344, 'score': 0.9477911646586344, 'examples_seen': 202720, 'step': 7350, 'algorithm': 'activity_selector'}
I1007 20:42:19.001719 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1007 20:42:19.876872 134831690958336 run.py:734] Algo activity_selector step 7400 current loss 0.635633, current_train_items 204080.
I1007 20:42:19.903644 134831690958336 run.py:769] (val) algo activity_selector step 7400: {'selected': 0.9416498993963782, 'score': 0.9416498993963782, 'examples_seen': 204080, 'step': 7400, 'algorithm': 'activity_selector'}
I1007 20:42:19.903798 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1007 20:42:20.790885 134831690958336 run.py:734] Algo activity_selector step 7450 current loss 0.987318, current_train_items 205488.
I1007 20:42:20.818013 134831690958336 run.py:769] (val) algo activity_selector step 7450: {'selected': 0.950381679389313, 'score': 0.950381679389313, 'examples_seen': 205488, 'step': 7450, 'algorithm': 'activity_selector'}
I1007 20:42:20.818162 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1007 20:42:21.705818 134831690958336 run.py:734] Algo activity_selector step 7500 current loss 0.643579, current_train_items 206848.
I1007 20:42:21.732483 134831690958336 run.py:769] (val) algo activity_selector step 7500: {'selected': 0.9737827715355805, 'score': 0.9737827715355805, 'examples_seen': 206848, 'step': 7500, 'algorithm': 'activity_selector'}
I1007 20:42:21.732651 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.974, val scores are: activity_selector: 0.974
I1007 20:42:22.623321 134831690958336 run.py:734] Algo activity_selector step 7550 current loss 0.670263, current_train_items 208224.
I1007 20:42:22.650280 134831690958336 run.py:769] (val) algo activity_selector step 7550: {'selected': 0.9548133595284872, 'score': 0.9548133595284872, 'examples_seen': 208224, 'step': 7550, 'algorithm': 'activity_selector'}
I1007 20:42:22.650434 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.955, val scores are: activity_selector: 0.955
I1007 20:42:23.527129 134831690958336 run.py:734] Algo activity_selector step 7600 current loss 0.892513, current_train_items 209616.
I1007 20:42:23.553694 134831690958336 run.py:769] (val) algo activity_selector step 7600: {'selected': 0.9619771863117872, 'score': 0.9619771863117872, 'examples_seen': 209616, 'step': 7600, 'algorithm': 'activity_selector'}
I1007 20:42:23.553844 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.962, val scores are: activity_selector: 0.962
I1007 20:42:24.433525 134831690958336 run.py:734] Algo activity_selector step 7650 current loss 0.733915, current_train_items 210976.
I1007 20:42:24.460613 134831690958336 run.py:769] (val) algo activity_selector step 7650: {'selected': 0.8990825688073394, 'score': 0.8990825688073394, 'examples_seen': 210976, 'step': 7650, 'algorithm': 'activity_selector'}
I1007 20:42:24.460764 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.899, val scores are: activity_selector: 0.899
I1007 20:42:25.352386 134831690958336 run.py:734] Algo activity_selector step 7700 current loss 0.675645, current_train_items 212368.
I1007 20:42:25.379503 134831690958336 run.py:769] (val) algo activity_selector step 7700: {'selected': 0.9709864603481625, 'score': 0.9709864603481625, 'examples_seen': 212368, 'step': 7700, 'algorithm': 'activity_selector'}
I1007 20:42:25.379658 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.971, val scores are: activity_selector: 0.971
I1007 20:42:26.257900 134831690958336 run.py:734] Algo activity_selector step 7750 current loss 0.659562, current_train_items 213744.
I1007 20:42:26.285354 134831690958336 run.py:769] (val) algo activity_selector step 7750: {'selected': 0.9596928982725528, 'score': 0.9596928982725528, 'examples_seen': 213744, 'step': 7750, 'algorithm': 'activity_selector'}
I1007 20:42:26.285504 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.960, val scores are: activity_selector: 0.960
I1007 20:42:27.179353 134831690958336 run.py:734] Algo activity_selector step 7800 current loss 0.754613, current_train_items 215136.
I1007 20:42:27.206325 134831690958336 run.py:769] (val) algo activity_selector step 7800: {'selected': 0.97265625, 'score': 0.97265625, 'examples_seen': 215136, 'step': 7800, 'algorithm': 'activity_selector'}
I1007 20:42:27.206472 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.973, val scores are: activity_selector: 0.973
I1007 20:42:28.089328 134831690958336 run.py:734] Algo activity_selector step 7850 current loss 0.691730, current_train_items 216496.
I1007 20:42:28.116539 134831690958336 run.py:769] (val) algo activity_selector step 7850: {'selected': 0.9649805447470816, 'score': 0.9649805447470816, 'examples_seen': 216496, 'step': 7850, 'algorithm': 'activity_selector'}
I1007 20:42:28.116699 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.965, val scores are: activity_selector: 0.965
I1007 20:42:28.995297 134831690958336 run.py:734] Algo activity_selector step 7900 current loss 0.667475, current_train_items 217888.
I1007 20:42:29.022505 134831690958336 run.py:769] (val) algo activity_selector step 7900: {'selected': 0.9592592592592591, 'score': 0.9592592592592591, 'examples_seen': 217888, 'step': 7900, 'algorithm': 'activity_selector'}
I1007 20:42:29.022675 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.959, val scores are: activity_selector: 0.959
I1007 20:42:29.921859 134831690958336 run.py:734] Algo activity_selector step 7950 current loss 0.630041, current_train_items 219264.
I1007 20:42:29.949460 134831690958336 run.py:769] (val) algo activity_selector step 7950: {'selected': 0.96309963099631, 'score': 0.96309963099631, 'examples_seen': 219264, 'step': 7950, 'algorithm': 'activity_selector'}
I1007 20:42:29.949628 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.963, val scores are: activity_selector: 0.963
I1007 20:42:30.829702 134831690958336 run.py:734] Algo activity_selector step 8000 current loss 0.688919, current_train_items 220624.
I1007 20:42:30.856977 134831690958336 run.py:769] (val) algo activity_selector step 8000: {'selected': 0.9590643274853802, 'score': 0.9590643274853802, 'examples_seen': 220624, 'step': 8000, 'algorithm': 'activity_selector'}
I1007 20:42:30.857128 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.959, val scores are: activity_selector: 0.959
I1007 20:42:31.751668 134831690958336 run.py:734] Algo activity_selector step 8050 current loss 0.642312, current_train_items 222032.
I1007 20:42:31.779259 134831690958336 run.py:769] (val) algo activity_selector step 8050: {'selected': 0.9522058823529412, 'score': 0.9522058823529412, 'examples_seen': 222032, 'step': 8050, 'algorithm': 'activity_selector'}
I1007 20:42:31.779408 134831690958336 run.py:790] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.952, val scores are: activity_selector: 0.952
I1007 20:42:32.680730 134831690958336 run.py:734] Algo activity_selector step 8100 current loss 0.884068, current_train_items 223392.
I1007 20:42:32.708770 134831690958336 run.py:769] (val) algo activity_selector step 8100: {'selected': 0.9518072289156627, 'score': 0.9518072289156627, 'examples_seen': 223392, 'step': 8100, 'algorithm': 'activity_selector'}
I1007 20:42:32.708926 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.952, current avg val score is 0.952, val scores are: activity_selector: 0.952
I1007 20:42:33.593671 134831690958336 run.py:734] Algo activity_selector step 8150 current loss 0.884740, current_train_items 224784.
I1007 20:42:33.620479 134831690958336 run.py:769] (val) algo activity_selector step 8150: {'selected': 0.9579158316633266, 'score': 0.9579158316633266, 'examples_seen': 224784, 'step': 8150, 'algorithm': 'activity_selector'}
I1007 20:42:33.620641 134831690958336 run.py:790] Checkpointing best model, best avg val score was 0.952, current avg val score is 0.958, val scores are: activity_selector: 0.958
I1007 20:42:34.521815 134831690958336 run.py:734] Algo activity_selector step 8200 current loss 0.671136, current_train_items 226160.
I1007 20:42:34.547809 134831690958336 run.py:769] (val) algo activity_selector step 8200: {'selected': 0.9555555555555555, 'score': 0.9555555555555555, 'examples_seen': 226160, 'step': 8200, 'algorithm': 'activity_selector'}
I1007 20:42:34.547957 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.958, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1007 20:42:35.429624 134831690958336 run.py:734] Algo activity_selector step 8250 current loss 0.599017, current_train_items 227520.
I1007 20:42:35.456292 134831690958336 run.py:769] (val) algo activity_selector step 8250: {'selected': 0.9732824427480916, 'score': 0.9732824427480916, 'examples_seen': 227520, 'step': 8250, 'algorithm': 'activity_selector'}
I1007 20:42:35.456443 134831690958336 run.py:790] Checkpointing best model, best avg val score was 0.958, current avg val score is 0.973, val scores are: activity_selector: 0.973
I1007 20:42:36.366275 134831690958336 run.py:734] Algo activity_selector step 8300 current loss 0.764954, current_train_items 228912.
I1007 20:42:36.393714 134831690958336 run.py:769] (val) algo activity_selector step 8300: {'selected': 0.96045197740113, 'score': 0.96045197740113, 'examples_seen': 228912, 'step': 8300, 'algorithm': 'activity_selector'}
I1007 20:42:36.393865 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.960, val scores are: activity_selector: 0.960
I1007 20:42:37.261777 134831690958336 run.py:734] Algo activity_selector step 8350 current loss 0.645241, current_train_items 230288.
I1007 20:42:37.289188 134831690958336 run.py:769] (val) algo activity_selector step 8350: {'selected': 0.9402697495183046, 'score': 0.9402697495183046, 'examples_seen': 230288, 'step': 8350, 'algorithm': 'activity_selector'}
I1007 20:42:37.289336 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.940, val scores are: activity_selector: 0.940
I1007 20:42:38.180048 134831690958336 run.py:734] Algo activity_selector step 8400 current loss 0.571668, current_train_items 231680.
I1007 20:42:38.207278 134831690958336 run.py:769] (val) algo activity_selector step 8400: {'selected': 0.930417495029821, 'score': 0.930417495029821, 'examples_seen': 231680, 'step': 8400, 'algorithm': 'activity_selector'}
I1007 20:42:38.207431 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.930, val scores are: activity_selector: 0.930
I1007 20:42:39.082474 134831690958336 run.py:734] Algo activity_selector step 8450 current loss 0.583878, current_train_items 233040.
I1007 20:42:39.109881 134831690958336 run.py:769] (val) algo activity_selector step 8450: {'selected': 0.942528735632184, 'score': 0.942528735632184, 'examples_seen': 233040, 'step': 8450, 'algorithm': 'activity_selector'}
I1007 20:42:39.110032 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1007 20:42:39.986220 134831690958336 run.py:734] Algo activity_selector step 8500 current loss 0.818151, current_train_items 234432.
I1007 20:42:40.013744 134831690958336 run.py:769] (val) algo activity_selector step 8500: {'selected': 0.9503816793893131, 'score': 0.9503816793893131, 'examples_seen': 234432, 'step': 8500, 'algorithm': 'activity_selector'}
I1007 20:42:40.013896 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1007 20:42:40.912678 134831690958336 run.py:734] Algo activity_selector step 8550 current loss 0.616280, current_train_items 235808.
I1007 20:42:40.940365 134831690958336 run.py:769] (val) algo activity_selector step 8550: {'selected': 0.9210526315789473, 'score': 0.9210526315789473, 'examples_seen': 235808, 'step': 8550, 'algorithm': 'activity_selector'}
I1007 20:42:40.940514 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.921, val scores are: activity_selector: 0.921
I1007 20:42:41.818532 134831690958336 run.py:734] Algo activity_selector step 8600 current loss 0.691431, current_train_items 237168.
I1007 20:42:41.846390 134831690958336 run.py:769] (val) algo activity_selector step 8600: {'selected': 0.9531249999999999, 'score': 0.9531249999999999, 'examples_seen': 237168, 'step': 8600, 'algorithm': 'activity_selector'}
I1007 20:42:41.846541 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1007 20:42:42.744992 134831690958336 run.py:734] Algo activity_selector step 8650 current loss 0.632986, current_train_items 238576.
I1007 20:42:42.772023 134831690958336 run.py:769] (val) algo activity_selector step 8650: {'selected': 0.9338521400778211, 'score': 0.9338521400778211, 'examples_seen': 238576, 'step': 8650, 'algorithm': 'activity_selector'}
I1007 20:42:42.772187 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.934, val scores are: activity_selector: 0.934
I1007 20:42:43.651125 134831690958336 run.py:734] Algo activity_selector step 8700 current loss 0.838486, current_train_items 239936.
I1007 20:42:43.677942 134831690958336 run.py:769] (val) algo activity_selector step 8700: {'selected': 0.9132743362831859, 'score': 0.9132743362831859, 'examples_seen': 239936, 'step': 8700, 'algorithm': 'activity_selector'}
I1007 20:42:43.678093 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.913, val scores are: activity_selector: 0.913
I1007 20:42:44.558109 134831690958336 run.py:734] Algo activity_selector step 8750 current loss 1.153301, current_train_items 241328.
I1007 20:42:44.585448 134831690958336 run.py:769] (val) algo activity_selector step 8750: {'selected': 0.8880308880308881, 'score': 0.8880308880308881, 'examples_seen': 241328, 'step': 8750, 'algorithm': 'activity_selector'}
I1007 20:42:44.585608 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.888, val scores are: activity_selector: 0.888
I1007 20:42:45.464254 134831690958336 run.py:734] Algo activity_selector step 8800 current loss 0.768144, current_train_items 242704.
I1007 20:42:45.491577 134831690958336 run.py:769] (val) algo activity_selector step 8800: {'selected': 0.8825622775800712, 'score': 0.8825622775800712, 'examples_seen': 242704, 'step': 8800, 'algorithm': 'activity_selector'}
I1007 20:42:45.491734 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.883, val scores are: activity_selector: 0.883
I1007 20:42:46.364368 134831690958336 run.py:734] Algo activity_selector step 8850 current loss 0.915682, current_train_items 244080.
I1007 20:42:46.391808 134831690958336 run.py:769] (val) algo activity_selector step 8850: {'selected': 0.9427480916030533, 'score': 0.9427480916030533, 'examples_seen': 244080, 'step': 8850, 'algorithm': 'activity_selector'}
I1007 20:42:46.391957 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1007 20:42:47.279533 134831690958336 run.py:734] Algo activity_selector step 8900 current loss 0.762865, current_train_items 245456.
I1007 20:42:47.306790 134831690958336 run.py:769] (val) algo activity_selector step 8900: {'selected': 0.9242718446601942, 'score': 0.9242718446601942, 'examples_seen': 245456, 'step': 8900, 'algorithm': 'activity_selector'}
I1007 20:42:47.306936 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.924, val scores are: activity_selector: 0.924
I1007 20:42:48.172954 134831690958336 run.py:734] Algo activity_selector step 8950 current loss 0.829681, current_train_items 246832.
I1007 20:42:48.200038 134831690958336 run.py:769] (val) algo activity_selector step 8950: {'selected': 0.9641434262948207, 'score': 0.9641434262948207, 'examples_seen': 246832, 'step': 8950, 'algorithm': 'activity_selector'}
I1007 20:42:48.200186 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.964, val scores are: activity_selector: 0.964
I1007 20:42:49.090774 134831690958336 run.py:734] Algo activity_selector step 9000 current loss 0.640809, current_train_items 248224.
I1007 20:42:49.117552 134831690958336 run.py:769] (val) algo activity_selector step 9000: {'selected': 0.9313543599257885, 'score': 0.9313543599257885, 'examples_seen': 248224, 'step': 9000, 'algorithm': 'activity_selector'}
I1007 20:42:49.117710 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1007 20:42:49.989601 134831690958336 run.py:734] Algo activity_selector step 9050 current loss 0.848942, current_train_items 249584.
I1007 20:42:50.016464 134831690958336 run.py:769] (val) algo activity_selector step 9050: {'selected': 0.9368029739776952, 'score': 0.9368029739776952, 'examples_seen': 249584, 'step': 9050, 'algorithm': 'activity_selector'}
I1007 20:42:50.016622 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.937, val scores are: activity_selector: 0.937
I1007 20:42:50.890674 134831690958336 run.py:734] Algo activity_selector step 9100 current loss 0.649787, current_train_items 250976.
I1007 20:42:50.917233 134831690958336 run.py:769] (val) algo activity_selector step 9100: {'selected': 0.9368029739776952, 'score': 0.9368029739776952, 'examples_seen': 250976, 'step': 9100, 'algorithm': 'activity_selector'}
I1007 20:42:50.917385 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.937, val scores are: activity_selector: 0.937
I1007 20:42:51.805717 134831690958336 run.py:734] Algo activity_selector step 9150 current loss 0.649915, current_train_items 252352.
I1007 20:42:51.833576 134831690958336 run.py:769] (val) algo activity_selector step 9150: {'selected': 0.9493433395872419, 'score': 0.9493433395872419, 'examples_seen': 252352, 'step': 9150, 'algorithm': 'activity_selector'}
I1007 20:42:51.833830 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.949, val scores are: activity_selector: 0.949
I1007 20:42:52.709925 134831690958336 run.py:734] Algo activity_selector step 9200 current loss 0.636547, current_train_items 253728.
I1007 20:42:52.736879 134831690958336 run.py:769] (val) algo activity_selector step 9200: {'selected': 0.9398907103825136, 'score': 0.9398907103825136, 'examples_seen': 253728, 'step': 9200, 'algorithm': 'activity_selector'}
I1007 20:42:52.737029 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.940, val scores are: activity_selector: 0.940
I1007 20:42:53.640224 134831690958336 run.py:734] Algo activity_selector step 9250 current loss 0.691444, current_train_items 255120.
I1007 20:42:53.667117 134831690958336 run.py:769] (val) algo activity_selector step 9250: {'selected': 0.9479553903345724, 'score': 0.9479553903345724, 'examples_seen': 255120, 'step': 9250, 'algorithm': 'activity_selector'}
I1007 20:42:53.667266 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1007 20:42:54.555320 134831690958336 run.py:734] Algo activity_selector step 9300 current loss 0.652911, current_train_items 256480.
I1007 20:42:54.582139 134831690958336 run.py:769] (val) algo activity_selector step 9300: {'selected': 0.9233511586452763, 'score': 0.9233511586452763, 'examples_seen': 256480, 'step': 9300, 'algorithm': 'activity_selector'}
I1007 20:42:54.582289 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.923, val scores are: activity_selector: 0.923
I1007 20:42:55.466326 134831690958336 run.py:734] Algo activity_selector step 9350 current loss 0.865914, current_train_items 257856.
I1007 20:42:55.493887 134831690958336 run.py:769] (val) algo activity_selector step 9350: {'selected': 0.9650092081031308, 'score': 0.9650092081031308, 'examples_seen': 257856, 'step': 9350, 'algorithm': 'activity_selector'}
I1007 20:42:55.494041 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.965, val scores are: activity_selector: 0.965
I1007 20:42:56.384296 134831690958336 run.py:734] Algo activity_selector step 9400 current loss 0.725976, current_train_items 259248.
I1007 20:42:56.411226 134831690958336 run.py:769] (val) algo activity_selector step 9400: {'selected': 0.9376181474480151, 'score': 0.9376181474480151, 'examples_seen': 259248, 'step': 9400, 'algorithm': 'activity_selector'}
I1007 20:42:56.411377 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.938, val scores are: activity_selector: 0.938
I1007 20:42:57.299256 134831690958336 run.py:734] Algo activity_selector step 9450 current loss 0.619348, current_train_items 260624.
I1007 20:42:57.326021 134831690958336 run.py:769] (val) algo activity_selector step 9450: {'selected': 0.9482071713147411, 'score': 0.9482071713147411, 'examples_seen': 260624, 'step': 9450, 'algorithm': 'activity_selector'}
I1007 20:42:57.326170 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1007 20:42:58.212543 134831690958336 run.py:734] Algo activity_selector step 9500 current loss 0.705099, current_train_items 262000.
I1007 20:42:58.239424 134831690958336 run.py:769] (val) algo activity_selector step 9500: {'selected': 0.9333333333333332, 'score': 0.9333333333333332, 'examples_seen': 262000, 'step': 9500, 'algorithm': 'activity_selector'}
I1007 20:42:58.239574 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.933, val scores are: activity_selector: 0.933
I1007 20:42:59.116024 134831690958336 run.py:734] Algo activity_selector step 9550 current loss 0.489345, current_train_items 263392.
I1007 20:42:59.142703 134831690958336 run.py:769] (val) algo activity_selector step 9550: {'selected': 0.9218106995884775, 'score': 0.9218106995884775, 'examples_seen': 263392, 'step': 9550, 'algorithm': 'activity_selector'}
I1007 20:42:59.142854 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.922, val scores are: activity_selector: 0.922
I1007 20:43:00.027714 134831690958336 run.py:734] Algo activity_selector step 9600 current loss 0.855173, current_train_items 264768.
I1007 20:43:00.054601 134831690958336 run.py:769] (val) algo activity_selector step 9600: {'selected': 0.9446640316205535, 'score': 0.9446640316205535, 'examples_seen': 264768, 'step': 9600, 'algorithm': 'activity_selector'}
I1007 20:43:00.054752 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.945, val scores are: activity_selector: 0.945
I1007 20:43:00.939215 134831690958336 run.py:734] Algo activity_selector step 9650 current loss 0.705656, current_train_items 266128.
I1007 20:43:00.967711 134831690958336 run.py:769] (val) algo activity_selector step 9650: {'selected': 0.9438202247191011, 'score': 0.9438202247191011, 'examples_seen': 266128, 'step': 9650, 'algorithm': 'activity_selector'}
I1007 20:43:00.967866 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.944, val scores are: activity_selector: 0.944
I1007 20:43:01.852335 134831690958336 run.py:734] Algo activity_selector step 9700 current loss 0.759538, current_train_items 267520.
I1007 20:43:01.879596 134831690958336 run.py:769] (val) algo activity_selector step 9700: {'selected': 0.9502762430939227, 'score': 0.9502762430939227, 'examples_seen': 267520, 'step': 9700, 'algorithm': 'activity_selector'}
I1007 20:43:01.879748 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1007 20:43:02.770246 134831690958336 run.py:734] Algo activity_selector step 9750 current loss 0.756231, current_train_items 268896.
I1007 20:43:02.796991 134831690958336 run.py:769] (val) algo activity_selector step 9750: {'selected': 0.9378757515030061, 'score': 0.9378757515030061, 'examples_seen': 268896, 'step': 9750, 'algorithm': 'activity_selector'}
I1007 20:43:02.797143 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.938, val scores are: activity_selector: 0.938
I1007 20:43:03.679591 134831690958336 run.py:734] Algo activity_selector step 9800 current loss 0.606347, current_train_items 270272.
I1007 20:43:03.706389 134831690958336 run.py:769] (val) algo activity_selector step 9800: {'selected': 0.9561904761904763, 'score': 0.9561904761904763, 'examples_seen': 270272, 'step': 9800, 'algorithm': 'activity_selector'}
I1007 20:43:03.706550 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1007 20:43:04.592125 134831690958336 run.py:734] Algo activity_selector step 9850 current loss 0.689970, current_train_items 271664.
I1007 20:43:04.619308 134831690958336 run.py:769] (val) algo activity_selector step 9850: {'selected': 0.9718574108818012, 'score': 0.9718574108818012, 'examples_seen': 271664, 'step': 9850, 'algorithm': 'activity_selector'}
I1007 20:43:04.619459 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.972, val scores are: activity_selector: 0.972
I1007 20:43:05.498934 134831690958336 run.py:734] Algo activity_selector step 9900 current loss 0.945760, current_train_items 273040.
I1007 20:43:05.525829 134831690958336 run.py:769] (val) algo activity_selector step 9900: {'selected': 0.9033457249070632, 'score': 0.9033457249070632, 'examples_seen': 273040, 'step': 9900, 'algorithm': 'activity_selector'}
I1007 20:43:05.525977 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.903, val scores are: activity_selector: 0.903
I1007 20:43:06.398956 134831690958336 run.py:734] Algo activity_selector step 9950 current loss 0.507826, current_train_items 274400.
I1007 20:43:06.426148 134831690958336 run.py:769] (val) algo activity_selector step 9950: {'selected': 0.9537892791127541, 'score': 0.9537892791127541, 'examples_seen': 274400, 'step': 9950, 'algorithm': 'activity_selector'}
I1007 20:43:06.426300 134831690958336 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.954, val scores are: activity_selector: 0.954
I1007 20:43:07.290962 134831690958336 run.py:799] Restoring best model from checkpoint...
I1007 20:43:15.323791 134831690958336 run.py:814] (test) algo activity_selector : {'selected': 0.8402154398563734, 'score': 0.8402154398563734, 'examples_seen': 275760, 'step': 10000, 'algorithm': 'activity_selector'}
I1007 20:43:15.323972 134831690958336 run.py:816] Done!
