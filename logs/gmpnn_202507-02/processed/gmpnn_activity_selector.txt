I0715 13:06:01.618821 132101335414272 run.py:688] Algo activity_selector step 0 current loss 3.747048, current_train_items 64.
I0715 13:06:07.419240 132101335414272 run.py:723] (val) algo activity_selector step 0: {'selected': 0.18060200668896323, 'score': 0.18060200668896323, 'examples_seen': 64, 'step': 0, 'algorithm': 'activity_selector'}
I0715 13:06:07.419425 132101335414272 run.py:744] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.181, val scores are: activity_selector: 0.181
I0715 13:07:14.177291 132101335414272 run.py:688] Algo activity_selector step 50 current loss 3.635954, current_train_items 2080.
I0715 13:07:14.200545 132101335414272 run.py:723] (val) algo activity_selector step 50: {'selected': 0.6864686468646866, 'score': 0.6864686468646866, 'examples_seen': 2080, 'step': 50, 'algorithm': 'activity_selector'}
I0715 13:07:14.200703 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.181, current avg val score is 0.686, val scores are: activity_selector: 0.686
I0715 13:07:15.206725 132101335414272 run.py:688] Algo activity_selector step 100 current loss 3.338156, current_train_items 4064.
I0715 13:07:15.230837 132101335414272 run.py:723] (val) algo activity_selector step 100: {'selected': 0.696588868940754, 'score': 0.696588868940754, 'examples_seen': 4064, 'step': 100, 'algorithm': 'activity_selector'}
I0715 13:07:15.230992 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.686, current avg val score is 0.697, val scores are: activity_selector: 0.697
I0715 13:07:16.225713 132101335414272 run.py:688] Algo activity_selector step 150 current loss 4.985882, current_train_items 6016.
I0715 13:07:16.251784 132101335414272 run.py:723] (val) algo activity_selector step 150: {'selected': 0.6985645933014354, 'score': 0.6985645933014354, 'examples_seen': 6016, 'step': 150, 'algorithm': 'activity_selector'}
I0715 13:07:16.251938 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.697, current avg val score is 0.699, val scores are: activity_selector: 0.699
I0715 13:07:17.254320 132101335414272 run.py:688] Algo activity_selector step 200 current loss 3.933666, current_train_items 8016.
I0715 13:07:17.282950 132101335414272 run.py:723] (val) algo activity_selector step 200: {'selected': 0.6088794926004228, 'score': 0.6088794926004228, 'examples_seen': 8016, 'step': 200, 'algorithm': 'activity_selector'}
I0715 13:07:17.283112 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.699, current avg val score is 0.609, val scores are: activity_selector: 0.609
I0715 13:07:18.273538 132101335414272 run.py:688] Algo activity_selector step 250 current loss 5.809023, current_train_items 9952.
I0715 13:07:18.305311 132101335414272 run.py:723] (val) algo activity_selector step 250: {'selected': 0.6714285714285715, 'score': 0.6714285714285715, 'examples_seen': 9952, 'step': 250, 'algorithm': 'activity_selector'}
I0715 13:07:18.305474 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.699, current avg val score is 0.671, val scores are: activity_selector: 0.671
I0715 13:07:19.341390 132101335414272 run.py:688] Algo activity_selector step 300 current loss 1.677519, current_train_items 12000.
I0715 13:07:19.363972 132101335414272 run.py:723] (val) algo activity_selector step 300: {'selected': 0.7097902097902098, 'score': 0.7097902097902098, 'examples_seen': 12000, 'step': 300, 'algorithm': 'activity_selector'}
I0715 13:07:19.364131 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.699, current avg val score is 0.710, val scores are: activity_selector: 0.710
I0715 13:07:20.370212 132101335414272 run.py:688] Algo activity_selector step 350 current loss 1.272481, current_train_items 14032.
I0715 13:07:20.391734 132101335414272 run.py:723] (val) algo activity_selector step 350: {'selected': 0.7404580152671757, 'score': 0.7404580152671757, 'examples_seen': 14032, 'step': 350, 'algorithm': 'activity_selector'}
I0715 13:07:20.391886 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.710, current avg val score is 0.740, val scores are: activity_selector: 0.740
I0715 13:07:21.415159 132101335414272 run.py:688] Algo activity_selector step 400 current loss 2.359304, current_train_items 16000.
I0715 13:07:21.437958 132101335414272 run.py:723] (val) algo activity_selector step 400: {'selected': 0.7372881355932204, 'score': 0.7372881355932204, 'examples_seen': 16000, 'step': 400, 'algorithm': 'activity_selector'}
I0715 13:07:21.438112 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.740, current avg val score is 0.737, val scores are: activity_selector: 0.737
I0715 13:07:22.435940 132101335414272 run.py:688] Algo activity_selector step 450 current loss 2.321847, current_train_items 18000.
I0715 13:07:22.460329 132101335414272 run.py:723] (val) algo activity_selector step 450: {'selected': 0.7628083491461101, 'score': 0.7628083491461101, 'examples_seen': 18000, 'step': 450, 'algorithm': 'activity_selector'}
I0715 13:07:22.460489 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.740, current avg val score is 0.763, val scores are: activity_selector: 0.763
I0715 13:07:23.470561 132101335414272 run.py:688] Algo activity_selector step 500 current loss 3.100992, current_train_items 19952.
I0715 13:07:23.497053 132101335414272 run.py:723] (val) algo activity_selector step 500: {'selected': 0.7985739750445633, 'score': 0.7985739750445633, 'examples_seen': 19952, 'step': 500, 'algorithm': 'activity_selector'}
I0715 13:07:23.497206 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.763, current avg val score is 0.799, val scores are: activity_selector: 0.799
I0715 13:07:24.520682 132101335414272 run.py:688] Algo activity_selector step 550 current loss 3.281347, current_train_items 21920.
I0715 13:07:24.549353 132101335414272 run.py:723] (val) algo activity_selector step 550: {'selected': 0.7993527508090614, 'score': 0.7993527508090614, 'examples_seen': 21920, 'step': 550, 'algorithm': 'activity_selector'}
I0715 13:07:24.549516 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.799, current avg val score is 0.799, val scores are: activity_selector: 0.799
I0715 13:07:25.546295 132101335414272 run.py:688] Algo activity_selector step 600 current loss 3.471326, current_train_items 23904.
I0715 13:07:25.577430 132101335414272 run.py:723] (val) algo activity_selector step 600: {'selected': 0.8085106382978723, 'score': 0.8085106382978723, 'examples_seen': 23904, 'step': 600, 'algorithm': 'activity_selector'}
I0715 13:07:25.577594 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.799, current avg val score is 0.809, val scores are: activity_selector: 0.809
I0715 13:07:26.614405 132101335414272 run.py:688] Algo activity_selector step 650 current loss 1.292735, current_train_items 25920.
I0715 13:07:26.636140 132101335414272 run.py:723] (val) algo activity_selector step 650: {'selected': 0.8046744574290484, 'score': 0.8046744574290484, 'examples_seen': 25920, 'step': 650, 'algorithm': 'activity_selector'}
I0715 13:07:26.636293 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.809, current avg val score is 0.805, val scores are: activity_selector: 0.805
I0715 13:07:27.648753 132101335414272 run.py:688] Algo activity_selector step 700 current loss 0.713742, current_train_items 27952.
I0715 13:07:27.671030 132101335414272 run.py:723] (val) algo activity_selector step 700: {'selected': 0.8170940170940171, 'score': 0.8170940170940171, 'examples_seen': 27952, 'step': 700, 'algorithm': 'activity_selector'}
I0715 13:07:27.671186 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.809, current avg val score is 0.817, val scores are: activity_selector: 0.817
I0715 13:07:28.672983 132101335414272 run.py:688] Algo activity_selector step 750 current loss 0.975210, current_train_items 29936.
I0715 13:07:28.695917 132101335414272 run.py:723] (val) algo activity_selector step 750: {'selected': 0.8316498316498316, 'score': 0.8316498316498316, 'examples_seen': 29936, 'step': 750, 'algorithm': 'activity_selector'}
I0715 13:07:28.696067 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.817, current avg val score is 0.832, val scores are: activity_selector: 0.832
I0715 13:07:29.724672 132101335414272 run.py:688] Algo activity_selector step 800 current loss 1.275409, current_train_items 31920.
I0715 13:07:29.748434 132101335414272 run.py:723] (val) algo activity_selector step 800: {'selected': 0.813868613138686, 'score': 0.813868613138686, 'examples_seen': 31920, 'step': 800, 'algorithm': 'activity_selector'}
I0715 13:07:29.748593 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.832, current avg val score is 0.814, val scores are: activity_selector: 0.814
I0715 13:07:30.717757 132101335414272 run.py:688] Algo activity_selector step 850 current loss 2.778200, current_train_items 33904.
I0715 13:07:30.744253 132101335414272 run.py:723] (val) algo activity_selector step 850: {'selected': 0.8767123287671232, 'score': 0.8767123287671232, 'examples_seen': 33904, 'step': 850, 'algorithm': 'activity_selector'}
I0715 13:07:30.744406 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.832, current avg val score is 0.877, val scores are: activity_selector: 0.877
I0715 13:07:31.755750 132101335414272 run.py:688] Algo activity_selector step 900 current loss 2.683143, current_train_items 35856.
I0715 13:07:31.784247 132101335414272 run.py:723] (val) algo activity_selector step 900: {'selected': 0.8897058823529411, 'score': 0.8897058823529411, 'examples_seen': 35856, 'step': 900, 'algorithm': 'activity_selector'}
I0715 13:07:31.784402 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.877, current avg val score is 0.890, val scores are: activity_selector: 0.890
I0715 13:07:32.779180 132101335414272 run.py:688] Algo activity_selector step 950 current loss 2.117520, current_train_items 37808.
I0715 13:07:32.810393 132101335414272 run.py:723] (val) algo activity_selector step 950: {'selected': 0.8768115942028984, 'score': 0.8768115942028984, 'examples_seen': 37808, 'step': 950, 'algorithm': 'activity_selector'}
I0715 13:07:32.810554 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.890, current avg val score is 0.877, val scores are: activity_selector: 0.877
I0715 13:07:33.817146 132101335414272 run.py:688] Algo activity_selector step 1000 current loss 0.672810, current_train_items 39872.
I0715 13:07:33.838286 132101335414272 run.py:723] (val) algo activity_selector step 1000: {'selected': 0.8047538200339559, 'score': 0.8047538200339559, 'examples_seen': 39872, 'step': 1000, 'algorithm': 'activity_selector'}
I0715 13:07:33.838443 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.890, current avg val score is 0.805, val scores are: activity_selector: 0.805
I0715 13:07:34.870905 132101335414272 run.py:688] Algo activity_selector step 1050 current loss 0.471016, current_train_items 41872.
I0715 13:07:34.893059 132101335414272 run.py:723] (val) algo activity_selector step 1050: {'selected': 0.8944543828264758, 'score': 0.8944543828264758, 'examples_seen': 41872, 'step': 1050, 'algorithm': 'activity_selector'}
I0715 13:07:34.893210 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.890, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0715 13:07:35.902503 132101335414272 run.py:688] Algo activity_selector step 1100 current loss 1.595579, current_train_items 43872.
I0715 13:07:35.925731 132101335414272 run.py:723] (val) algo activity_selector step 1100: {'selected': 0.8791208791208791, 'score': 0.8791208791208791, 'examples_seen': 43872, 'step': 1100, 'algorithm': 'activity_selector'}
I0715 13:07:35.925885 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.894, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0715 13:07:36.928517 132101335414272 run.py:688] Algo activity_selector step 1150 current loss 1.003267, current_train_items 45856.
I0715 13:07:36.952732 132101335414272 run.py:723] (val) algo activity_selector step 1150: {'selected': 0.8858267716535434, 'score': 0.8858267716535434, 'examples_seen': 45856, 'step': 1150, 'algorithm': 'activity_selector'}
I0715 13:07:36.952890 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.894, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0715 13:07:37.946782 132101335414272 run.py:688] Algo activity_selector step 1200 current loss 2.425655, current_train_items 47808.
I0715 13:07:37.973216 132101335414272 run.py:723] (val) algo activity_selector step 1200: {'selected': 0.9389312977099238, 'score': 0.9389312977099238, 'examples_seen': 47808, 'step': 1200, 'algorithm': 'activity_selector'}
I0715 13:07:37.973374 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.894, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0715 13:07:38.982192 132101335414272 run.py:688] Algo activity_selector step 1250 current loss 2.491058, current_train_items 49808.
I0715 13:07:39.010598 132101335414272 run.py:723] (val) algo activity_selector step 1250: {'selected': 0.913131313131313, 'score': 0.913131313131313, 'examples_seen': 49808, 'step': 1250, 'algorithm': 'activity_selector'}
I0715 13:07:39.010754 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.939, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0715 13:07:40.016059 132101335414272 run.py:688] Algo activity_selector step 1300 current loss 4.212050, current_train_items 51760.
I0715 13:07:40.053289 132101335414272 run.py:723] (val) algo activity_selector step 1300: {'selected': 0.912280701754386, 'score': 0.912280701754386, 'examples_seen': 51760, 'step': 1300, 'algorithm': 'activity_selector'}
I0715 13:07:40.053447 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.939, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0715 13:07:41.068262 132101335414272 run.py:688] Algo activity_selector step 1350 current loss 0.761625, current_train_items 53792.
I0715 13:07:41.090348 132101335414272 run.py:723] (val) algo activity_selector step 1350: {'selected': 0.8902195608782435, 'score': 0.8902195608782435, 'examples_seen': 53792, 'step': 1350, 'algorithm': 'activity_selector'}
I0715 13:07:41.090505 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.939, current avg val score is 0.890, val scores are: activity_selector: 0.890
I0715 13:07:42.091664 132101335414272 run.py:688] Algo activity_selector step 1400 current loss 0.708308, current_train_items 55824.
I0715 13:07:42.113847 132101335414272 run.py:723] (val) algo activity_selector step 1400: {'selected': 0.8730158730158729, 'score': 0.8730158730158729, 'examples_seen': 55824, 'step': 1400, 'algorithm': 'activity_selector'}
I0715 13:07:42.114013 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.939, current avg val score is 0.873, val scores are: activity_selector: 0.873
I0715 13:07:43.112191 132101335414272 run.py:688] Algo activity_selector step 1450 current loss 1.303303, current_train_items 57792.
I0715 13:07:43.135617 132101335414272 run.py:723] (val) algo activity_selector step 1450: {'selected': 0.9439071566731142, 'score': 0.9439071566731142, 'examples_seen': 57792, 'step': 1450, 'algorithm': 'activity_selector'}
I0715 13:07:43.135771 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.939, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0715 13:07:44.149316 132101335414272 run.py:688] Algo activity_selector step 1500 current loss 0.441259, current_train_items 59792.
I0715 13:07:44.173603 132101335414272 run.py:723] (val) algo activity_selector step 1500: {'selected': 0.9136690647482014, 'score': 0.9136690647482014, 'examples_seen': 59792, 'step': 1500, 'algorithm': 'activity_selector'}
I0715 13:07:44.173764 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.944, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0715 13:07:45.175758 132101335414272 run.py:688] Algo activity_selector step 1550 current loss 0.851262, current_train_items 61744.
I0715 13:07:45.203169 132101335414272 run.py:723] (val) algo activity_selector step 1550: {'selected': 0.9215686274509803, 'score': 0.9215686274509803, 'examples_seen': 61744, 'step': 1550, 'algorithm': 'activity_selector'}
I0715 13:07:45.203339 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.944, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0715 13:07:46.210747 132101335414272 run.py:688] Algo activity_selector step 1600 current loss 2.114850, current_train_items 63712.
I0715 13:07:46.239553 132101335414272 run.py:723] (val) algo activity_selector step 1600: {'selected': 0.8646748681898067, 'score': 0.8646748681898067, 'examples_seen': 63712, 'step': 1600, 'algorithm': 'activity_selector'}
I0715 13:07:46.239720 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.944, current avg val score is 0.865, val scores are: activity_selector: 0.865
I0715 13:07:47.235233 132101335414272 run.py:688] Algo activity_selector step 1650 current loss 4.858393, current_train_items 65712.
I0715 13:07:47.266953 132101335414272 run.py:723] (val) algo activity_selector step 1650: {'selected': 0.9219600725952813, 'score': 0.9219600725952813, 'examples_seen': 65712, 'step': 1650, 'algorithm': 'activity_selector'}
I0715 13:07:47.267126 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.944, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0715 13:07:48.278124 132101335414272 run.py:688] Algo activity_selector step 1700 current loss 0.469646, current_train_items 67712.
I0715 13:07:48.300174 132101335414272 run.py:723] (val) algo activity_selector step 1700: {'selected': 0.9094339622641509, 'score': 0.9094339622641509, 'examples_seen': 67712, 'step': 1700, 'algorithm': 'activity_selector'}
I0715 13:07:48.300332 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.944, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0715 13:07:49.311580 132101335414272 run.py:688] Algo activity_selector step 1750 current loss 0.626155, current_train_items 69744.
I0715 13:07:49.333778 132101335414272 run.py:723] (val) algo activity_selector step 1750: {'selected': 0.9257142857142857, 'score': 0.9257142857142857, 'examples_seen': 69744, 'step': 1750, 'algorithm': 'activity_selector'}
I0715 13:07:49.333947 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.944, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0715 13:07:50.358814 132101335414272 run.py:688] Algo activity_selector step 1800 current loss 0.400344, current_train_items 71728.
I0715 13:07:50.382256 132101335414272 run.py:723] (val) algo activity_selector step 1800: {'selected': 0.8757170172084129, 'score': 0.8757170172084129, 'examples_seen': 71728, 'step': 1800, 'algorithm': 'activity_selector'}
I0715 13:07:50.382410 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.944, current avg val score is 0.876, val scores are: activity_selector: 0.876
I0715 13:07:51.390292 132101335414272 run.py:688] Algo activity_selector step 1850 current loss 0.585004, current_train_items 73712.
I0715 13:07:51.414911 132101335414272 run.py:723] (val) algo activity_selector step 1850: {'selected': 0.932, 'score': 0.932, 'examples_seen': 73712, 'step': 1850, 'algorithm': 'activity_selector'}
I0715 13:07:51.415071 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.944, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0715 13:07:52.398146 132101335414272 run.py:688] Algo activity_selector step 1900 current loss 1.838722, current_train_items 75712.
I0715 13:07:52.425019 132101335414272 run.py:723] (val) algo activity_selector step 1900: {'selected': 0.928030303030303, 'score': 0.928030303030303, 'examples_seen': 75712, 'step': 1900, 'algorithm': 'activity_selector'}
I0715 13:07:52.425174 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.944, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0715 13:07:53.438061 132101335414272 run.py:688] Algo activity_selector step 1950 current loss 1.835626, current_train_items 77664.
I0715 13:07:53.466383 132101335414272 run.py:723] (val) algo activity_selector step 1950: {'selected': 0.9788867562380039, 'score': 0.9788867562380039, 'examples_seen': 77664, 'step': 1950, 'algorithm': 'activity_selector'}
I0715 13:07:53.466545 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.944, current avg val score is 0.979, val scores are: activity_selector: 0.979
I0715 13:07:54.485822 132101335414272 run.py:688] Algo activity_selector step 2000 current loss 4.048597, current_train_items 79632.
I0715 13:07:54.517386 132101335414272 run.py:723] (val) algo activity_selector step 2000: {'selected': 0.9325396825396827, 'score': 0.9325396825396827, 'examples_seen': 79632, 'step': 2000, 'algorithm': 'activity_selector'}
I0715 13:07:54.517546 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0715 13:07:55.552633 132101335414272 run.py:688] Algo activity_selector step 2050 current loss 0.299272, current_train_items 81680.
I0715 13:07:55.575417 132101335414272 run.py:723] (val) algo activity_selector step 2050: {'selected': 0.928440366972477, 'score': 0.928440366972477, 'examples_seen': 81680, 'step': 2050, 'algorithm': 'activity_selector'}
I0715 13:07:55.575582 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0715 13:07:56.597419 132101335414272 run.py:688] Algo activity_selector step 2100 current loss 0.294119, current_train_items 83680.
I0715 13:07:56.619588 132101335414272 run.py:723] (val) algo activity_selector step 2100: {'selected': 0.9197651663405089, 'score': 0.9197651663405089, 'examples_seen': 83680, 'step': 2100, 'algorithm': 'activity_selector'}
I0715 13:07:56.619746 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0715 13:07:57.618693 132101335414272 run.py:688] Algo activity_selector step 2150 current loss 1.607806, current_train_items 85680.
I0715 13:07:57.641922 132101335414272 run.py:723] (val) algo activity_selector step 2150: {'selected': 0.9612403100775194, 'score': 0.9612403100775194, 'examples_seen': 85680, 'step': 2150, 'algorithm': 'activity_selector'}
I0715 13:07:57.642077 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0715 13:07:58.654061 132101335414272 run.py:688] Algo activity_selector step 2200 current loss 0.460491, current_train_items 87664.
I0715 13:07:58.678517 132101335414272 run.py:723] (val) algo activity_selector step 2200: {'selected': 0.9622641509433961, 'score': 0.9622641509433961, 'examples_seen': 87664, 'step': 2200, 'algorithm': 'activity_selector'}
I0715 13:07:58.678676 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0715 13:07:59.689429 132101335414272 run.py:688] Algo activity_selector step 2250 current loss 2.262346, current_train_items 89632.
I0715 13:07:59.716006 132101335414272 run.py:723] (val) algo activity_selector step 2250: {'selected': 0.9699248120300752, 'score': 0.9699248120300752, 'examples_seen': 89632, 'step': 2250, 'algorithm': 'activity_selector'}
I0715 13:07:59.716160 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0715 13:08:00.721819 132101335414272 run.py:688] Algo activity_selector step 2300 current loss 0.548236, current_train_items 91616.
I0715 13:08:00.750853 132101335414272 run.py:723] (val) algo activity_selector step 2300: {'selected': 0.9345794392523363, 'score': 0.9345794392523363, 'examples_seen': 91616, 'step': 2300, 'algorithm': 'activity_selector'}
I0715 13:08:00.751007 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0715 13:08:01.769197 132101335414272 run.py:688] Algo activity_selector step 2350 current loss 3.923624, current_train_items 93568.
I0715 13:08:01.801260 132101335414272 run.py:723] (val) algo activity_selector step 2350: {'selected': 0.935251798561151, 'score': 0.935251798561151, 'examples_seen': 93568, 'step': 2350, 'algorithm': 'activity_selector'}
I0715 13:08:01.801417 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0715 13:08:02.813682 132101335414272 run.py:688] Algo activity_selector step 2400 current loss 0.418848, current_train_items 95600.
I0715 13:08:02.835721 132101335414272 run.py:723] (val) algo activity_selector step 2400: {'selected': 0.9094412331406552, 'score': 0.9094412331406552, 'examples_seen': 95600, 'step': 2400, 'algorithm': 'activity_selector'}
I0715 13:08:02.835874 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0715 13:08:03.849676 132101335414272 run.py:688] Algo activity_selector step 2450 current loss 0.191666, current_train_items 97632.
I0715 13:08:03.871492 132101335414272 run.py:723] (val) algo activity_selector step 2450: {'selected': 0.97119341563786, 'score': 0.97119341563786, 'examples_seen': 97632, 'step': 2450, 'algorithm': 'activity_selector'}
I0715 13:08:03.871649 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0715 13:08:04.875044 132101335414272 run.py:688] Algo activity_selector step 2500 current loss 1.420111, current_train_items 99600.
I0715 13:08:04.898553 132101335414272 run.py:723] (val) algo activity_selector step 2500: {'selected': 0.9371196754563895, 'score': 0.9371196754563895, 'examples_seen': 99600, 'step': 2500, 'algorithm': 'activity_selector'}
I0715 13:08:04.898710 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0715 13:08:05.912956 132101335414272 run.py:688] Algo activity_selector step 2550 current loss 0.359894, current_train_items 101600.
I0715 13:08:05.937962 132101335414272 run.py:723] (val) algo activity_selector step 2550: {'selected': 0.9433962264150944, 'score': 0.9433962264150944, 'examples_seen': 101600, 'step': 2550, 'algorithm': 'activity_selector'}
I0715 13:08:05.938127 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0715 13:08:06.949964 132101335414272 run.py:688] Algo activity_selector step 2600 current loss 0.691742, current_train_items 103568.
I0715 13:08:06.976431 132101335414272 run.py:723] (val) algo activity_selector step 2600: {'selected': 0.9498069498069499, 'score': 0.9498069498069499, 'examples_seen': 103568, 'step': 2600, 'algorithm': 'activity_selector'}
I0715 13:08:06.976596 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0715 13:08:07.967620 132101335414272 run.py:688] Algo activity_selector step 2650 current loss 3.434052, current_train_items 105520.
I0715 13:08:07.996130 132101335414272 run.py:723] (val) algo activity_selector step 2650: {'selected': 0.9671532846715328, 'score': 0.9671532846715328, 'examples_seen': 105520, 'step': 2650, 'algorithm': 'activity_selector'}
I0715 13:08:07.996283 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0715 13:08:08.991640 132101335414272 run.py:688] Algo activity_selector step 2700 current loss 2.835835, current_train_items 107520.
I0715 13:08:09.023158 132101335414272 run.py:723] (val) algo activity_selector step 2700: {'selected': 0.9404990403071017, 'score': 0.9404990403071017, 'examples_seen': 107520, 'step': 2700, 'algorithm': 'activity_selector'}
I0715 13:08:09.023316 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0715 13:08:10.031874 132101335414272 run.py:688] Algo activity_selector step 2750 current loss 0.485218, current_train_items 109520.
I0715 13:08:10.053242 132101335414272 run.py:723] (val) algo activity_selector step 2750: {'selected': 0.9561904761904761, 'score': 0.9561904761904761, 'examples_seen': 109520, 'step': 2750, 'algorithm': 'activity_selector'}
I0715 13:08:10.053399 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0715 13:08:11.064459 132101335414272 run.py:688] Algo activity_selector step 2800 current loss 0.582168, current_train_items 111552.
I0715 13:08:11.085996 132101335414272 run.py:723] (val) algo activity_selector step 2800: {'selected': 0.9395711500974661, 'score': 0.9395711500974661, 'examples_seen': 111552, 'step': 2800, 'algorithm': 'activity_selector'}
I0715 13:08:11.086154 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0715 13:08:12.073667 132101335414272 run.py:688] Algo activity_selector step 2850 current loss 0.278262, current_train_items 113552.
I0715 13:08:12.097428 132101335414272 run.py:723] (val) algo activity_selector step 2850: {'selected': 0.9642184557438795, 'score': 0.9642184557438795, 'examples_seen': 113552, 'step': 2850, 'algorithm': 'activity_selector'}
I0715 13:08:12.097589 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0715 13:08:13.090558 132101335414272 run.py:688] Algo activity_selector step 2900 current loss 0.362463, current_train_items 115520.
I0715 13:08:13.116097 132101335414272 run.py:723] (val) algo activity_selector step 2900: {'selected': 0.9064748201438849, 'score': 0.9064748201438849, 'examples_seen': 115520, 'step': 2900, 'algorithm': 'activity_selector'}
I0715 13:08:13.116249 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0715 13:08:14.106858 132101335414272 run.py:688] Algo activity_selector step 2950 current loss 1.901522, current_train_items 117520.
I0715 13:08:14.133421 132101335414272 run.py:723] (val) algo activity_selector step 2950: {'selected': 0.9595375722543352, 'score': 0.9595375722543352, 'examples_seen': 117520, 'step': 2950, 'algorithm': 'activity_selector'}
I0715 13:08:14.133583 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0715 13:08:15.122350 132101335414272 run.py:688] Algo activity_selector step 3000 current loss 2.635692, current_train_items 119456.
I0715 13:08:15.150692 132101335414272 run.py:723] (val) algo activity_selector step 3000: {'selected': 0.9477477477477478, 'score': 0.9477477477477478, 'examples_seen': 119456, 'step': 3000, 'algorithm': 'activity_selector'}
I0715 13:08:15.150844 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0715 13:08:16.154157 132101335414272 run.py:688] Algo activity_selector step 3050 current loss 3.137339, current_train_items 121424.
I0715 13:08:16.185351 132101335414272 run.py:723] (val) algo activity_selector step 3050: {'selected': 0.9365671641791045, 'score': 0.9365671641791045, 'examples_seen': 121424, 'step': 3050, 'algorithm': 'activity_selector'}
I0715 13:08:16.185514 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0715 13:08:17.182133 132101335414272 run.py:688] Algo activity_selector step 3100 current loss 0.087835, current_train_items 123472.
I0715 13:08:17.204189 132101335414272 run.py:723] (val) algo activity_selector step 3100: {'selected': 0.9776876267748479, 'score': 0.9776876267748479, 'examples_seen': 123472, 'step': 3100, 'algorithm': 'activity_selector'}
I0715 13:08:17.204339 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.978, val scores are: activity_selector: 0.978
I0715 13:08:18.213994 132101335414272 run.py:688] Algo activity_selector step 3150 current loss 0.211972, current_train_items 125472.
I0715 13:08:18.236134 132101335414272 run.py:723] (val) algo activity_selector step 3150: {'selected': 0.9455252918287936, 'score': 0.9455252918287936, 'examples_seen': 125472, 'step': 3150, 'algorithm': 'activity_selector'}
I0715 13:08:18.236290 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0715 13:08:19.233424 132101335414272 run.py:688] Algo activity_selector step 3200 current loss 1.254712, current_train_items 127488.
I0715 13:08:19.257378 132101335414272 run.py:723] (val) algo activity_selector step 3200: {'selected': 0.9701492537313432, 'score': 0.9701492537313432, 'examples_seen': 127488, 'step': 3200, 'algorithm': 'activity_selector'}
I0715 13:08:19.257544 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0715 13:08:20.252391 132101335414272 run.py:688] Algo activity_selector step 3250 current loss 0.442572, current_train_items 129456.
I0715 13:08:20.277018 132101335414272 run.py:723] (val) algo activity_selector step 3250: {'selected': 0.9683794466403162, 'score': 0.9683794466403162, 'examples_seen': 129456, 'step': 3250, 'algorithm': 'activity_selector'}
I0715 13:08:20.277173 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0715 13:08:21.284258 132101335414272 run.py:688] Algo activity_selector step 3300 current loss 2.244700, current_train_items 131424.
I0715 13:08:21.310879 132101335414272 run.py:723] (val) algo activity_selector step 3300: {'selected': 0.9481765834932822, 'score': 0.9481765834932822, 'examples_seen': 131424, 'step': 3300, 'algorithm': 'activity_selector'}
I0715 13:08:21.311042 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0715 13:08:22.290150 132101335414272 run.py:688] Algo activity_selector step 3350 current loss 2.077188, current_train_items 133408.
I0715 13:08:22.319277 132101335414272 run.py:723] (val) algo activity_selector step 3350: {'selected': 0.9575289575289575, 'score': 0.9575289575289575, 'examples_seen': 133408, 'step': 3350, 'algorithm': 'activity_selector'}
I0715 13:08:22.319432 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0715 13:08:23.328321 132101335414272 run.py:688] Algo activity_selector step 3400 current loss 2.321154, current_train_items 135360.
I0715 13:08:23.359828 132101335414272 run.py:723] (val) algo activity_selector step 3400: {'selected': 0.9610894941634242, 'score': 0.9610894941634242, 'examples_seen': 135360, 'step': 3400, 'algorithm': 'activity_selector'}
I0715 13:08:23.359985 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0715 13:08:24.355738 132101335414272 run.py:688] Algo activity_selector step 3450 current loss 0.490450, current_train_items 137392.
I0715 13:08:24.378260 132101335414272 run.py:723] (val) algo activity_selector step 3450: {'selected': 0.9597069597069596, 'score': 0.9597069597069596, 'examples_seen': 137392, 'step': 3450, 'algorithm': 'activity_selector'}
I0715 13:08:24.378415 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0715 13:08:25.385534 132101335414272 run.py:688] Algo activity_selector step 3500 current loss 0.114301, current_train_items 139424.
I0715 13:08:25.407663 132101335414272 run.py:723] (val) algo activity_selector step 3500: {'selected': 0.9471544715447154, 'score': 0.9471544715447154, 'examples_seen': 139424, 'step': 3500, 'algorithm': 'activity_selector'}
I0715 13:08:25.407815 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0715 13:08:26.426354 132101335414272 run.py:688] Algo activity_selector step 3550 current loss 1.236209, current_train_items 141408.
I0715 13:08:26.448857 132101335414272 run.py:723] (val) algo activity_selector step 3550: {'selected': 0.9785575048732942, 'score': 0.9785575048732942, 'examples_seen': 141408, 'step': 3550, 'algorithm': 'activity_selector'}
I0715 13:08:26.449015 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.979, val scores are: activity_selector: 0.979
I0715 13:08:27.431438 132101335414272 run.py:688] Algo activity_selector step 3600 current loss 0.479278, current_train_items 143392.
I0715 13:08:27.455710 132101335414272 run.py:723] (val) algo activity_selector step 3600: {'selected': 0.9421157684630739, 'score': 0.9421157684630739, 'examples_seen': 143392, 'step': 3600, 'algorithm': 'activity_selector'}
I0715 13:08:27.455863 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0715 13:08:28.458677 132101335414272 run.py:688] Algo activity_selector step 3650 current loss 1.014469, current_train_items 145360.
I0715 13:08:28.485653 132101335414272 run.py:723] (val) algo activity_selector step 3650: {'selected': 0.9587426326129665, 'score': 0.9587426326129665, 'examples_seen': 145360, 'step': 3650, 'algorithm': 'activity_selector'}
I0715 13:08:28.485806 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0715 13:08:29.472883 132101335414272 run.py:688] Algo activity_selector step 3700 current loss 2.199266, current_train_items 147312.
I0715 13:08:29.501365 132101335414272 run.py:723] (val) algo activity_selector step 3700: {'selected': 0.9420849420849421, 'score': 0.9420849420849421, 'examples_seen': 147312, 'step': 3700, 'algorithm': 'activity_selector'}
I0715 13:08:29.501540 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0715 13:08:30.492358 132101335414272 run.py:688] Algo activity_selector step 3750 current loss 2.285333, current_train_items 149312.
I0715 13:08:30.523918 132101335414272 run.py:723] (val) algo activity_selector step 3750: {'selected': 0.9717514124293786, 'score': 0.9717514124293786, 'examples_seen': 149312, 'step': 3750, 'algorithm': 'activity_selector'}
I0715 13:08:30.524080 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0715 13:08:31.538456 132101335414272 run.py:688] Algo activity_selector step 3800 current loss 0.341142, current_train_items 151328.
I0715 13:08:31.559914 132101335414272 run.py:723] (val) algo activity_selector step 3800: {'selected': 0.9604743083003953, 'score': 0.9604743083003953, 'examples_seen': 151328, 'step': 3800, 'algorithm': 'activity_selector'}
I0715 13:08:31.560067 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0715 13:08:32.557111 132101335414272 run.py:688] Algo activity_selector step 3850 current loss 0.221627, current_train_items 153344.
I0715 13:08:32.578686 132101335414272 run.py:723] (val) algo activity_selector step 3850: {'selected': 0.9652650822669104, 'score': 0.9652650822669104, 'examples_seen': 153344, 'step': 3850, 'algorithm': 'activity_selector'}
I0715 13:08:32.578841 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0715 13:08:33.572077 132101335414272 run.py:688] Algo activity_selector step 3900 current loss 0.300203, current_train_items 155344.
I0715 13:08:33.594996 132101335414272 run.py:723] (val) algo activity_selector step 3900: {'selected': 0.9595375722543352, 'score': 0.9595375722543352, 'examples_seen': 155344, 'step': 3900, 'algorithm': 'activity_selector'}
I0715 13:08:33.595146 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0715 13:08:34.577590 132101335414272 run.py:688] Algo activity_selector step 3950 current loss 0.709847, current_train_items 157312.
I0715 13:08:34.601717 132101335414272 run.py:723] (val) algo activity_selector step 3950: {'selected': 0.9330855018587362, 'score': 0.9330855018587362, 'examples_seen': 157312, 'step': 3950, 'algorithm': 'activity_selector'}
I0715 13:08:34.601871 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0715 13:08:35.584017 132101335414272 run.py:688] Algo activity_selector step 4000 current loss 1.634857, current_train_items 159312.
I0715 13:08:35.612166 132101335414272 run.py:723] (val) algo activity_selector step 4000: {'selected': 0.9766536964980544, 'score': 0.9766536964980544, 'examples_seen': 159312, 'step': 4000, 'algorithm': 'activity_selector'}
I0715 13:08:35.612322 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0715 13:08:36.607897 132101335414272 run.py:688] Algo activity_selector step 4050 current loss 1.707969, current_train_items 161248.
I0715 13:08:36.636531 132101335414272 run.py:723] (val) algo activity_selector step 4050: {'selected': 0.9645669291338582, 'score': 0.9645669291338582, 'examples_seen': 161248, 'step': 4050, 'algorithm': 'activity_selector'}
I0715 13:08:36.636685 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.979, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0715 13:08:37.634956 132101335414272 run.py:688] Algo activity_selector step 4100 current loss 2.055760, current_train_items 163216.
I0715 13:08:37.666325 132101335414272 run.py:723] (val) algo activity_selector step 4100: {'selected': 0.9808429118773947, 'score': 0.9808429118773947, 'examples_seen': 163216, 'step': 4100, 'algorithm': 'activity_selector'}
I0715 13:08:37.666475 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.979, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0715 13:08:38.699839 132101335414272 run.py:688] Algo activity_selector step 4150 current loss 0.242186, current_train_items 165280.
I0715 13:08:38.721548 132101335414272 run.py:723] (val) algo activity_selector step 4150: {'selected': 0.9669902912621359, 'score': 0.9669902912621359, 'examples_seen': 165280, 'step': 4150, 'algorithm': 'activity_selector'}
I0715 13:08:38.721701 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.981, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0715 13:08:39.723664 132101335414272 run.py:688] Algo activity_selector step 4200 current loss 0.212425, current_train_items 167264.
I0715 13:08:39.745232 132101335414272 run.py:723] (val) algo activity_selector step 4200: {'selected': 0.9710982658959537, 'score': 0.9710982658959537, 'examples_seen': 167264, 'step': 4200, 'algorithm': 'activity_selector'}
I0715 13:08:39.745391 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.981, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0715 13:08:40.744704 132101335414272 run.py:688] Algo activity_selector step 4250 current loss 1.060361, current_train_items 169280.
I0715 13:08:40.767463 132101335414272 run.py:723] (val) algo activity_selector step 4250: {'selected': 0.9603024574669187, 'score': 0.9603024574669187, 'examples_seen': 169280, 'step': 4250, 'algorithm': 'activity_selector'}
I0715 13:08:40.767625 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.981, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0715 13:08:41.754920 132101335414272 run.py:688] Algo activity_selector step 4300 current loss 0.310070, current_train_items 171248.
I0715 13:08:41.778891 132101335414272 run.py:723] (val) algo activity_selector step 4300: {'selected': 0.967984934086629, 'score': 0.967984934086629, 'examples_seen': 171248, 'step': 4300, 'algorithm': 'activity_selector'}
I0715 13:08:41.779042 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.981, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0715 13:08:42.771987 132101335414272 run.py:688] Algo activity_selector step 4350 current loss 2.223823, current_train_items 173216.
I0715 13:08:42.798687 132101335414272 run.py:723] (val) algo activity_selector step 4350: {'selected': 0.9456740442655936, 'score': 0.9456740442655936, 'examples_seen': 173216, 'step': 4350, 'algorithm': 'activity_selector'}
I0715 13:08:42.798840 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.981, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0715 13:08:43.769800 132101335414272 run.py:688] Algo activity_selector step 4400 current loss 1.446438, current_train_items 175232.
I0715 13:08:43.800107 132101335414272 run.py:723] (val) algo activity_selector step 4400: {'selected': 0.9711934156378601, 'score': 0.9711934156378601, 'examples_seen': 175232, 'step': 4400, 'algorithm': 'activity_selector'}
I0715 13:08:43.800262 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.981, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0715 13:08:44.792358 132101335414272 run.py:688] Algo activity_selector step 4450 current loss 2.037934, current_train_items 177168.
I0715 13:08:44.824230 132101335414272 run.py:723] (val) algo activity_selector step 4450: {'selected': 0.9761904761904762, 'score': 0.9761904761904762, 'examples_seen': 177168, 'step': 4450, 'algorithm': 'activity_selector'}
I0715 13:08:44.824397 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.981, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0715 13:08:45.827735 132101335414272 run.py:688] Algo activity_selector step 4500 current loss 0.395969, current_train_items 179216.
I0715 13:08:45.849382 132101335414272 run.py:723] (val) algo activity_selector step 4500: {'selected': 0.9659318637274549, 'score': 0.9659318637274549, 'examples_seen': 179216, 'step': 4500, 'algorithm': 'activity_selector'}
I0715 13:08:45.849547 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.981, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0715 13:08:46.840855 132101335414272 run.py:688] Algo activity_selector step 4550 current loss 0.237343, current_train_items 181232.
I0715 13:08:46.862953 132101335414272 run.py:723] (val) algo activity_selector step 4550: {'selected': 0.9751434034416827, 'score': 0.9751434034416827, 'examples_seen': 181232, 'step': 4550, 'algorithm': 'activity_selector'}
I0715 13:08:46.863115 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.981, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0715 13:08:47.868855 132101335414272 run.py:688] Algo activity_selector step 4600 current loss 1.132187, current_train_items 183216.
I0715 13:08:47.892113 132101335414272 run.py:723] (val) algo activity_selector step 4600: {'selected': 0.9467680608365018, 'score': 0.9467680608365018, 'examples_seen': 183216, 'step': 4600, 'algorithm': 'activity_selector'}
I0715 13:08:47.892265 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.981, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0715 13:08:48.861515 132101335414272 run.py:688] Algo activity_selector step 4650 current loss 0.307428, current_train_items 185200.
I0715 13:08:48.886051 132101335414272 run.py:723] (val) algo activity_selector step 4650: {'selected': 0.9653846153846153, 'score': 0.9653846153846153, 'examples_seen': 185200, 'step': 4650, 'algorithm': 'activity_selector'}
I0715 13:08:48.886208 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.981, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0715 13:08:49.881647 132101335414272 run.py:688] Algo activity_selector step 4700 current loss 0.285867, current_train_items 187168.
I0715 13:08:49.908194 132101335414272 run.py:723] (val) algo activity_selector step 4700: {'selected': 0.9782178217821782, 'score': 0.9782178217821782, 'examples_seen': 187168, 'step': 4700, 'algorithm': 'activity_selector'}
I0715 13:08:49.908351 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.981, current avg val score is 0.978, val scores are: activity_selector: 0.978
I0715 13:08:50.899493 132101335414272 run.py:688] Algo activity_selector step 4750 current loss 0.528730, current_train_items 189136.
I0715 13:08:50.927804 132101335414272 run.py:723] (val) algo activity_selector step 4750: {'selected': 0.9563567362428843, 'score': 0.9563567362428843, 'examples_seen': 189136, 'step': 4750, 'algorithm': 'activity_selector'}
I0715 13:08:50.927957 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.981, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0715 13:08:51.902741 132101335414272 run.py:688] Algo activity_selector step 4800 current loss 1.804828, current_train_items 191120.
I0715 13:08:51.934671 132101335414272 run.py:723] (val) algo activity_selector step 4800: {'selected': 0.9487666034155599, 'score': 0.9487666034155599, 'examples_seen': 191120, 'step': 4800, 'algorithm': 'activity_selector'}
I0715 13:08:51.934825 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.981, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0715 13:08:52.949810 132101335414272 run.py:688] Algo activity_selector step 4850 current loss 0.307835, current_train_items 193136.
I0715 13:08:52.970827 132101335414272 run.py:723] (val) algo activity_selector step 4850: {'selected': 0.9736842105263158, 'score': 0.9736842105263158, 'examples_seen': 193136, 'step': 4850, 'algorithm': 'activity_selector'}
I0715 13:08:52.970979 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.981, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0715 13:08:53.960087 132101335414272 run.py:688] Algo activity_selector step 4900 current loss 0.129488, current_train_items 195152.
I0715 13:08:53.981693 132101335414272 run.py:723] (val) algo activity_selector step 4900: {'selected': 0.9512670565302145, 'score': 0.9512670565302145, 'examples_seen': 195152, 'step': 4900, 'algorithm': 'activity_selector'}
I0715 13:08:53.981842 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.981, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0715 13:08:54.971299 132101335414272 run.py:688] Algo activity_selector step 4950 current loss 0.370635, current_train_items 197152.
I0715 13:08:54.994416 132101335414272 run.py:723] (val) algo activity_selector step 4950: {'selected': 0.9763779527559056, 'score': 0.9763779527559056, 'examples_seen': 197152, 'step': 4950, 'algorithm': 'activity_selector'}
I0715 13:08:54.994583 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.981, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0715 13:08:55.980055 132101335414272 run.py:688] Algo activity_selector step 5000 current loss 0.215864, current_train_items 199120.
I0715 13:08:56.004398 132101335414272 run.py:723] (val) algo activity_selector step 5000: {'selected': 0.9606299212598425, 'score': 0.9606299212598425, 'examples_seen': 199120, 'step': 5000, 'algorithm': 'activity_selector'}
I0715 13:08:56.004559 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.981, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0715 13:08:56.986701 132101335414272 run.py:688] Algo activity_selector step 5050 current loss 1.399192, current_train_items 201120.
I0715 13:08:57.013332 132101335414272 run.py:723] (val) algo activity_selector step 5050: {'selected': 0.9553398058252428, 'score': 0.9553398058252428, 'examples_seen': 201120, 'step': 5050, 'algorithm': 'activity_selector'}
I0715 13:08:57.013495 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.981, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0715 13:08:58.009780 132101335414272 run.py:688] Algo activity_selector step 5100 current loss 2.619135, current_train_items 203072.
I0715 13:08:58.038043 132101335414272 run.py:723] (val) algo activity_selector step 5100: {'selected': 0.9847328244274809, 'score': 0.9847328244274809, 'examples_seen': 203072, 'step': 5100, 'algorithm': 'activity_selector'}
I0715 13:08:58.038198 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.981, current avg val score is 0.985, val scores are: activity_selector: 0.985
I0715 13:08:59.028604 132101335414272 run.py:688] Algo activity_selector step 5150 current loss 1.821041, current_train_items 205024.
I0715 13:08:59.059819 132101335414272 run.py:723] (val) algo activity_selector step 5150: {'selected': 0.9686274509803922, 'score': 0.9686274509803922, 'examples_seen': 205024, 'step': 5150, 'algorithm': 'activity_selector'}
I0715 13:08:59.059973 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0715 13:09:00.061845 132101335414272 run.py:688] Algo activity_selector step 5200 current loss 0.246662, current_train_items 207088.
I0715 13:09:00.083665 132101335414272 run.py:723] (val) algo activity_selector step 5200: {'selected': 0.9698189134808852, 'score': 0.9698189134808852, 'examples_seen': 207088, 'step': 5200, 'algorithm': 'activity_selector'}
I0715 13:09:00.083829 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0715 13:09:01.073715 132101335414272 run.py:688] Algo activity_selector step 5250 current loss 0.378931, current_train_items 209072.
I0715 13:09:01.095912 132101335414272 run.py:723] (val) algo activity_selector step 5250: {'selected': 0.9457943925233644, 'score': 0.9457943925233644, 'examples_seen': 209072, 'step': 5250, 'algorithm': 'activity_selector'}
I0715 13:09:01.096064 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0715 13:09:02.089414 132101335414272 run.py:688] Algo activity_selector step 5300 current loss 0.950121, current_train_items 211088.
I0715 13:09:02.111879 132101335414272 run.py:723] (val) algo activity_selector step 5300: {'selected': 0.9722222222222222, 'score': 0.9722222222222222, 'examples_seen': 211088, 'step': 5300, 'algorithm': 'activity_selector'}
I0715 13:09:02.112031 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0715 13:09:03.128308 132101335414272 run.py:688] Algo activity_selector step 5350 current loss 0.187202, current_train_items 213072.
I0715 13:09:03.155216 132101335414272 run.py:723] (val) algo activity_selector step 5350: {'selected': 0.9708737864077669, 'score': 0.9708737864077669, 'examples_seen': 213072, 'step': 5350, 'algorithm': 'activity_selector'}
I0715 13:09:03.155417 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0715 13:09:04.174734 132101335414272 run.py:688] Algo activity_selector step 5400 current loss 1.874929, current_train_items 215024.
I0715 13:09:04.201634 132101335414272 run.py:723] (val) algo activity_selector step 5400: {'selected': 0.9652509652509652, 'score': 0.9652509652509652, 'examples_seen': 215024, 'step': 5400, 'algorithm': 'activity_selector'}
I0715 13:09:04.201786 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0715 13:09:05.249694 132101335414272 run.py:688] Algo activity_selector step 5450 current loss 2.135098, current_train_items 217024.
I0715 13:09:05.282053 132101335414272 run.py:723] (val) algo activity_selector step 5450: {'selected': 0.9484126984126985, 'score': 0.9484126984126985, 'examples_seen': 217024, 'step': 5450, 'algorithm': 'activity_selector'}
I0715 13:09:05.282207 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0715 13:09:06.342964 132101335414272 run.py:688] Algo activity_selector step 5500 current loss 1.859573, current_train_items 218960.
I0715 13:09:06.374889 132101335414272 run.py:723] (val) algo activity_selector step 5500: {'selected': 0.9707602339181286, 'score': 0.9707602339181286, 'examples_seen': 218960, 'step': 5500, 'algorithm': 'activity_selector'}
I0715 13:09:06.375039 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0715 13:09:07.425590 132101335414272 run.py:688] Algo activity_selector step 5550 current loss 0.603785, current_train_items 221008.
I0715 13:09:07.446913 132101335414272 run.py:723] (val) algo activity_selector step 5550: {'selected': 0.9446640316205533, 'score': 0.9446640316205533, 'examples_seen': 221008, 'step': 5550, 'algorithm': 'activity_selector'}
I0715 13:09:07.447068 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0715 13:09:08.464788 132101335414272 run.py:688] Algo activity_selector step 5600 current loss 0.085872, current_train_items 223024.
I0715 13:09:08.486589 132101335414272 run.py:723] (val) algo activity_selector step 5600: {'selected': 0.9713193116634798, 'score': 0.9713193116634798, 'examples_seen': 223024, 'step': 5600, 'algorithm': 'activity_selector'}
I0715 13:09:08.486743 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0715 13:09:09.515847 132101335414272 run.py:688] Algo activity_selector step 5650 current loss 1.271243, current_train_items 225008.
I0715 13:09:09.539589 132101335414272 run.py:723] (val) algo activity_selector step 5650: {'selected': 0.9707602339181287, 'score': 0.9707602339181287, 'examples_seen': 225008, 'step': 5650, 'algorithm': 'activity_selector'}
I0715 13:09:09.539743 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0715 13:09:10.544322 132101335414272 run.py:688] Algo activity_selector step 5700 current loss 0.422608, current_train_items 227008.
I0715 13:09:10.569034 132101335414272 run.py:723] (val) algo activity_selector step 5700: {'selected': 0.9380863039399624, 'score': 0.9380863039399624, 'examples_seen': 227008, 'step': 5700, 'algorithm': 'activity_selector'}
I0715 13:09:10.569204 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0715 13:09:11.569605 132101335414272 run.py:688] Algo activity_selector step 5750 current loss 0.453867, current_train_items 228960.
I0715 13:09:11.597062 132101335414272 run.py:723] (val) algo activity_selector step 5750: {'selected': 0.9351669941060904, 'score': 0.9351669941060904, 'examples_seen': 228960, 'step': 5750, 'algorithm': 'activity_selector'}
I0715 13:09:11.597217 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0715 13:09:12.621132 132101335414272 run.py:688] Algo activity_selector step 5800 current loss 2.243250, current_train_items 230928.
I0715 13:09:12.649433 132101335414272 run.py:723] (val) algo activity_selector step 5800: {'selected': 0.9618320610687022, 'score': 0.9618320610687022, 'examples_seen': 230928, 'step': 5800, 'algorithm': 'activity_selector'}
I0715 13:09:12.649617 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0715 13:09:13.675855 132101335414272 run.py:688] Algo activity_selector step 5850 current loss 2.065889, current_train_items 232912.
I0715 13:09:13.707258 132101335414272 run.py:723] (val) algo activity_selector step 5850: {'selected': 0.939334637964775, 'score': 0.939334637964775, 'examples_seen': 232912, 'step': 5850, 'algorithm': 'activity_selector'}
I0715 13:09:13.707412 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0715 13:09:14.741178 132101335414272 run.py:688] Algo activity_selector step 5900 current loss 0.325314, current_train_items 234928.
I0715 13:09:14.762677 132101335414272 run.py:723] (val) algo activity_selector step 5900: {'selected': 0.9653846153846153, 'score': 0.9653846153846153, 'examples_seen': 234928, 'step': 5900, 'algorithm': 'activity_selector'}
I0715 13:09:14.762831 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0715 13:09:15.764351 132101335414272 run.py:688] Algo activity_selector step 5950 current loss 0.126890, current_train_items 236944.
I0715 13:09:15.786783 132101335414272 run.py:723] (val) algo activity_selector step 5950: {'selected': 0.9696969696969696, 'score': 0.9696969696969696, 'examples_seen': 236944, 'step': 5950, 'algorithm': 'activity_selector'}
I0715 13:09:15.786938 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0715 13:09:16.808728 132101335414272 run.py:688] Algo activity_selector step 6000 current loss 0.270150, current_train_items 238944.
I0715 13:09:16.833142 132101335414272 run.py:723] (val) algo activity_selector step 6000: {'selected': 0.9453125, 'score': 0.9453125, 'examples_seen': 238944, 'step': 6000, 'algorithm': 'activity_selector'}
I0715 13:09:16.833298 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0715 13:09:17.874395 132101335414272 run.py:688] Algo activity_selector step 6050 current loss 0.143841, current_train_items 240928.
I0715 13:09:17.900140 132101335414272 run.py:723] (val) algo activity_selector step 6050: {'selected': 0.965376782077393, 'score': 0.965376782077393, 'examples_seen': 240928, 'step': 6050, 'algorithm': 'activity_selector'}
I0715 13:09:17.900295 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0715 13:09:18.886112 132101335414272 run.py:688] Algo activity_selector step 6100 current loss 1.516218, current_train_items 242912.
I0715 13:09:18.912713 132101335414272 run.py:723] (val) algo activity_selector step 6100: {'selected': 0.9629629629629629, 'score': 0.9629629629629629, 'examples_seen': 242912, 'step': 6100, 'algorithm': 'activity_selector'}
I0715 13:09:18.912868 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0715 13:09:19.919006 132101335414272 run.py:688] Algo activity_selector step 6150 current loss 2.204020, current_train_items 244864.
I0715 13:09:19.947679 132101335414272 run.py:723] (val) algo activity_selector step 6150: {'selected': 0.9116465863453814, 'score': 0.9116465863453814, 'examples_seen': 244864, 'step': 6150, 'algorithm': 'activity_selector'}
I0715 13:09:19.947832 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0715 13:09:20.931388 132101335414272 run.py:688] Algo activity_selector step 6200 current loss 1.276401, current_train_items 246816.
I0715 13:09:20.962941 132101335414272 run.py:723] (val) algo activity_selector step 6200: {'selected': 0.9715370018975332, 'score': 0.9715370018975332, 'examples_seen': 246816, 'step': 6200, 'algorithm': 'activity_selector'}
I0715 13:09:20.963093 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0715 13:09:21.965342 132101335414272 run.py:688] Algo activity_selector step 6250 current loss 0.092325, current_train_items 248880.
I0715 13:09:21.987047 132101335414272 run.py:723] (val) algo activity_selector step 6250: {'selected': 0.9792843691148777, 'score': 0.9792843691148777, 'examples_seen': 248880, 'step': 6250, 'algorithm': 'activity_selector'}
I0715 13:09:21.987210 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.979, val scores are: activity_selector: 0.979
I0715 13:09:23.004395 132101335414272 run.py:688] Algo activity_selector step 6300 current loss 0.405100, current_train_items 250880.
I0715 13:09:23.026535 132101335414272 run.py:723] (val) algo activity_selector step 6300: {'selected': 0.963855421686747, 'score': 0.963855421686747, 'examples_seen': 250880, 'step': 6300, 'algorithm': 'activity_selector'}
I0715 13:09:23.026694 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0715 13:09:24.029952 132101335414272 run.py:688] Algo activity_selector step 6350 current loss 1.182871, current_train_items 252880.
I0715 13:09:24.052999 132101335414272 run.py:723] (val) algo activity_selector step 6350: {'selected': 0.9809160305343512, 'score': 0.9809160305343512, 'examples_seen': 252880, 'step': 6350, 'algorithm': 'activity_selector'}
I0715 13:09:24.053162 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0715 13:09:25.047399 132101335414272 run.py:688] Algo activity_selector step 6400 current loss 0.336580, current_train_items 254864.
I0715 13:09:25.071631 132101335414272 run.py:723] (val) algo activity_selector step 6400: {'selected': 0.9262295081967212, 'score': 0.9262295081967212, 'examples_seen': 254864, 'step': 6400, 'algorithm': 'activity_selector'}
I0715 13:09:25.071782 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0715 13:09:26.053889 132101335414272 run.py:688] Algo activity_selector step 6450 current loss 2.252472, current_train_items 256816.
I0715 13:09:26.081466 132101335414272 run.py:723] (val) algo activity_selector step 6450: {'selected': 0.9613899613899615, 'score': 0.9613899613899615, 'examples_seen': 256816, 'step': 6450, 'algorithm': 'activity_selector'}
I0715 13:09:26.081630 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0715 13:09:27.069313 132101335414272 run.py:688] Algo activity_selector step 6500 current loss 1.570632, current_train_items 258816.
I0715 13:09:27.098034 132101335414272 run.py:723] (val) algo activity_selector step 6500: {'selected': 0.9824561403508771, 'score': 0.9824561403508771, 'examples_seen': 258816, 'step': 6500, 'algorithm': 'activity_selector'}
I0715 13:09:27.098186 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.982, val scores are: activity_selector: 0.982
I0715 13:09:28.089495 132101335414272 run.py:688] Algo activity_selector step 6550 current loss 1.596180, current_train_items 260752.
I0715 13:09:28.124162 132101335414272 run.py:723] (val) algo activity_selector step 6550: {'selected': 0.9515260323159784, 'score': 0.9515260323159784, 'examples_seen': 260752, 'step': 6550, 'algorithm': 'activity_selector'}
I0715 13:09:28.124314 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0715 13:09:29.144088 132101335414272 run.py:688] Algo activity_selector step 6600 current loss 0.360534, current_train_items 262800.
I0715 13:09:29.167006 132101335414272 run.py:723] (val) algo activity_selector step 6600: {'selected': 0.925531914893617, 'score': 0.925531914893617, 'examples_seen': 262800, 'step': 6600, 'algorithm': 'activity_selector'}
I0715 13:09:29.167164 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0715 13:09:30.183148 132101335414272 run.py:688] Algo activity_selector step 6650 current loss 0.110001, current_train_items 264832.
I0715 13:09:30.205353 132101335414272 run.py:723] (val) algo activity_selector step 6650: {'selected': 0.9348659003831418, 'score': 0.9348659003831418, 'examples_seen': 264832, 'step': 6650, 'algorithm': 'activity_selector'}
I0715 13:09:30.205519 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0715 13:09:31.215691 132101335414272 run.py:688] Algo activity_selector step 6700 current loss 0.894983, current_train_items 266800.
I0715 13:09:31.238875 132101335414272 run.py:723] (val) algo activity_selector step 6700: {'selected': 0.9757085020242915, 'score': 0.9757085020242915, 'examples_seen': 266800, 'step': 6700, 'algorithm': 'activity_selector'}
I0715 13:09:31.239035 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0715 13:09:32.241414 132101335414272 run.py:688] Algo activity_selector step 6750 current loss 0.635144, current_train_items 268800.
I0715 13:09:32.265900 132101335414272 run.py:723] (val) algo activity_selector step 6750: {'selected': 0.9656419529837252, 'score': 0.9656419529837252, 'examples_seen': 268800, 'step': 6750, 'algorithm': 'activity_selector'}
I0715 13:09:32.266056 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0715 13:09:33.270359 132101335414272 run.py:688] Algo activity_selector step 6800 current loss 0.323547, current_train_items 270752.
I0715 13:09:33.297886 132101335414272 run.py:723] (val) algo activity_selector step 6800: {'selected': 0.9671179883945841, 'score': 0.9671179883945841, 'examples_seen': 270752, 'step': 6800, 'algorithm': 'activity_selector'}
I0715 13:09:33.298073 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0715 13:09:34.309864 132101335414272 run.py:688] Algo activity_selector step 6850 current loss 1.198365, current_train_items 272736.
I0715 13:09:34.338490 132101335414272 run.py:723] (val) algo activity_selector step 6850: {'selected': 0.9783037475345167, 'score': 0.9783037475345167, 'examples_seen': 272736, 'step': 6850, 'algorithm': 'activity_selector'}
I0715 13:09:34.338644 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.978, val scores are: activity_selector: 0.978
I0715 13:09:35.320462 132101335414272 run.py:688] Algo activity_selector step 6900 current loss 0.591872, current_train_items 274720.
I0715 13:09:35.353692 132101335414272 run.py:723] (val) algo activity_selector step 6900: {'selected': 0.9338521400778209, 'score': 0.9338521400778209, 'examples_seen': 274720, 'step': 6900, 'algorithm': 'activity_selector'}
I0715 13:09:35.353847 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0715 13:09:36.375899 132101335414272 run.py:688] Algo activity_selector step 6950 current loss 0.287616, current_train_items 276736.
I0715 13:09:36.397936 132101335414272 run.py:723] (val) algo activity_selector step 6950: {'selected': 0.9713193116634798, 'score': 0.9713193116634798, 'examples_seen': 276736, 'step': 6950, 'algorithm': 'activity_selector'}
I0715 13:09:36.398092 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0715 13:09:37.407244 132101335414272 run.py:688] Algo activity_selector step 7000 current loss 0.099442, current_train_items 278768.
I0715 13:09:37.429444 132101335414272 run.py:723] (val) algo activity_selector step 7000: {'selected': 0.9194499017681729, 'score': 0.9194499017681729, 'examples_seen': 278768, 'step': 7000, 'algorithm': 'activity_selector'}
I0715 13:09:37.429609 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0715 13:09:38.429374 132101335414272 run.py:688] Algo activity_selector step 7050 current loss 0.334364, current_train_items 280752.
I0715 13:09:38.452857 132101335414272 run.py:723] (val) algo activity_selector step 7050: {'selected': 0.959349593495935, 'score': 0.959349593495935, 'examples_seen': 280752, 'step': 7050, 'algorithm': 'activity_selector'}
I0715 13:09:38.453022 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0715 13:09:39.474944 132101335414272 run.py:688] Algo activity_selector step 7100 current loss 0.186120, current_train_items 282736.
I0715 13:09:39.500043 132101335414272 run.py:723] (val) algo activity_selector step 7100: {'selected': 0.9483747609942639, 'score': 0.9483747609942639, 'examples_seen': 282736, 'step': 7100, 'algorithm': 'activity_selector'}
I0715 13:09:39.500208 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0715 13:09:40.475932 132101335414272 run.py:688] Algo activity_selector step 7150 current loss 1.441969, current_train_items 284720.
I0715 13:09:40.504105 132101335414272 run.py:723] (val) algo activity_selector step 7150: {'selected': 0.9655172413793104, 'score': 0.9655172413793104, 'examples_seen': 284720, 'step': 7150, 'algorithm': 'activity_selector'}
I0715 13:09:40.504257 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0715 13:09:41.520367 132101335414272 run.py:688] Algo activity_selector step 7200 current loss 0.419653, current_train_items 286672.
I0715 13:09:41.549031 132101335414272 run.py:723] (val) algo activity_selector step 7200: {'selected': 0.9431818181818181, 'score': 0.9431818181818181, 'examples_seen': 286672, 'step': 7200, 'algorithm': 'activity_selector'}
I0715 13:09:41.549185 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0715 13:09:42.542179 132101335414272 run.py:688] Algo activity_selector step 7250 current loss 3.830518, current_train_items 288640.
I0715 13:09:42.580299 132101335414272 run.py:723] (val) algo activity_selector step 7250: {'selected': 0.9696969696969696, 'score': 0.9696969696969696, 'examples_seen': 288640, 'step': 7250, 'algorithm': 'activity_selector'}
I0715 13:09:42.580457 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0715 13:09:43.610657 132101335414272 run.py:688] Algo activity_selector step 7300 current loss 0.233287, current_train_items 290688.
I0715 13:09:43.635867 132101335414272 run.py:723] (val) algo activity_selector step 7300: {'selected': 0.9497206703910613, 'score': 0.9497206703910613, 'examples_seen': 290688, 'step': 7300, 'algorithm': 'activity_selector'}
I0715 13:09:43.636025 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0715 13:09:44.662368 132101335414272 run.py:688] Algo activity_selector step 7350 current loss 0.220049, current_train_items 292688.
I0715 13:09:44.684992 132101335414272 run.py:723] (val) algo activity_selector step 7350: {'selected': 0.9383177570093457, 'score': 0.9383177570093457, 'examples_seen': 292688, 'step': 7350, 'algorithm': 'activity_selector'}
I0715 13:09:44.685146 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0715 13:09:45.674925 132101335414272 run.py:688] Algo activity_selector step 7400 current loss 0.869644, current_train_items 294688.
I0715 13:09:45.698566 132101335414272 run.py:723] (val) algo activity_selector step 7400: {'selected': 0.9549180327868853, 'score': 0.9549180327868853, 'examples_seen': 294688, 'step': 7400, 'algorithm': 'activity_selector'}
I0715 13:09:45.698722 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0715 13:09:46.705970 132101335414272 run.py:688] Algo activity_selector step 7450 current loss 0.616557, current_train_items 296672.
I0715 13:09:46.730400 132101335414272 run.py:723] (val) algo activity_selector step 7450: {'selected': 0.9315589353612167, 'score': 0.9315589353612167, 'examples_seen': 296672, 'step': 7450, 'algorithm': 'activity_selector'}
I0715 13:09:46.730579 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.985, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0715 13:09:47.719125 132101335414272 run.py:688] Algo activity_selector step 7500 current loss 2.010168, current_train_items 298624.
I0715 13:09:47.746016 132101335414272 run.py:723] (val) algo activity_selector step 7500: {'selected': 0.9865125240847784, 'score': 0.9865125240847784, 'examples_seen': 298624, 'step': 7500, 'algorithm': 'activity_selector'}
I0715 13:09:47.746194 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.985, current avg val score is 0.987, val scores are: activity_selector: 0.987
I0715 13:09:48.762457 132101335414272 run.py:688] Algo activity_selector step 7550 current loss 4.500281, current_train_items 300624.
I0715 13:09:48.791024 132101335414272 run.py:723] (val) algo activity_selector step 7550: {'selected': 0.9775051124744376, 'score': 0.9775051124744376, 'examples_seen': 300624, 'step': 7550, 'algorithm': 'activity_selector'}
I0715 13:09:48.791195 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.978, val scores are: activity_selector: 0.978
I0715 13:09:49.821170 132101335414272 run.py:688] Algo activity_selector step 7600 current loss 3.607114, current_train_items 302576.
I0715 13:09:49.852783 132101335414272 run.py:723] (val) algo activity_selector step 7600: {'selected': 0.9613899613899615, 'score': 0.9613899613899615, 'examples_seen': 302576, 'step': 7600, 'algorithm': 'activity_selector'}
I0715 13:09:49.852952 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0715 13:09:50.861640 132101335414272 run.py:688] Algo activity_selector step 7650 current loss 0.330167, current_train_items 304608.
I0715 13:09:50.883400 132101335414272 run.py:723] (val) algo activity_selector step 7650: {'selected': 0.9486652977412731, 'score': 0.9486652977412731, 'examples_seen': 304608, 'step': 7650, 'algorithm': 'activity_selector'}
I0715 13:09:50.883575 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0715 13:09:51.895905 132101335414272 run.py:688] Algo activity_selector step 7700 current loss 0.272178, current_train_items 306640.
I0715 13:09:51.917927 132101335414272 run.py:723] (val) algo activity_selector step 7700: {'selected': 0.9556451612903225, 'score': 0.9556451612903225, 'examples_seen': 306640, 'step': 7700, 'algorithm': 'activity_selector'}
I0715 13:09:51.918095 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0715 13:09:52.918579 132101335414272 run.py:688] Algo activity_selector step 7750 current loss 0.800316, current_train_items 308608.
I0715 13:09:52.941476 132101335414272 run.py:723] (val) algo activity_selector step 7750: {'selected': 0.9495327102803738, 'score': 0.9495327102803738, 'examples_seen': 308608, 'step': 7750, 'algorithm': 'activity_selector'}
I0715 13:09:52.941645 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0715 13:09:53.950966 132101335414272 run.py:688] Algo activity_selector step 7800 current loss 0.166695, current_train_items 310608.
I0715 13:09:53.977798 132101335414272 run.py:723] (val) algo activity_selector step 7800: {'selected': 0.905349794238683, 'score': 0.905349794238683, 'examples_seen': 310608, 'step': 7800, 'algorithm': 'activity_selector'}
I0715 13:09:53.977955 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0715 13:09:54.980285 132101335414272 run.py:688] Algo activity_selector step 7850 current loss 0.437680, current_train_items 312576.
I0715 13:09:55.007523 132101335414272 run.py:723] (val) algo activity_selector step 7850: {'selected': 0.9716446124763706, 'score': 0.9716446124763706, 'examples_seen': 312576, 'step': 7850, 'algorithm': 'activity_selector'}
I0715 13:09:55.007679 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0715 13:09:56.006562 132101335414272 run.py:688] Algo activity_selector step 7900 current loss 2.292002, current_train_items 314528.
I0715 13:09:56.034754 132101335414272 run.py:723] (val) algo activity_selector step 7900: {'selected': 0.9844961240310077, 'score': 0.9844961240310077, 'examples_seen': 314528, 'step': 7900, 'algorithm': 'activity_selector'}
I0715 13:09:56.034910 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.984, val scores are: activity_selector: 0.984
I0715 13:09:57.028661 132101335414272 run.py:688] Algo activity_selector step 7950 current loss 3.483621, current_train_items 316528.
I0715 13:09:57.060346 132101335414272 run.py:723] (val) algo activity_selector step 7950: {'selected': 0.9766606822262118, 'score': 0.9766606822262118, 'examples_seen': 316528, 'step': 7950, 'algorithm': 'activity_selector'}
I0715 13:09:57.060508 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0715 13:09:58.081357 132101335414272 run.py:688] Algo activity_selector step 8000 current loss 0.378488, current_train_items 318528.
I0715 13:09:58.103097 132101335414272 run.py:723] (val) algo activity_selector step 8000: {'selected': 0.9753320683111953, 'score': 0.9753320683111953, 'examples_seen': 318528, 'step': 8000, 'algorithm': 'activity_selector'}
I0715 13:09:58.103255 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0715 13:09:59.120087 132101335414272 run.py:688] Algo activity_selector step 8050 current loss 0.195751, current_train_items 320560.
I0715 13:09:59.142279 132101335414272 run.py:723] (val) algo activity_selector step 8050: {'selected': 0.9606299212598426, 'score': 0.9606299212598426, 'examples_seen': 320560, 'step': 8050, 'algorithm': 'activity_selector'}
I0715 13:09:59.142435 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0715 13:10:00.138900 132101335414272 run.py:688] Algo activity_selector step 8100 current loss 0.422765, current_train_items 322544.
I0715 13:10:00.161852 132101335414272 run.py:723] (val) algo activity_selector step 8100: {'selected': 0.9753320683111955, 'score': 0.9753320683111955, 'examples_seen': 322544, 'step': 8100, 'algorithm': 'activity_selector'}
I0715 13:10:00.162008 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0715 13:10:01.169201 132101335414272 run.py:688] Algo activity_selector step 8150 current loss 0.176858, current_train_items 324528.
I0715 13:10:01.193364 132101335414272 run.py:723] (val) algo activity_selector step 8150: {'selected': 0.9647495361781077, 'score': 0.9647495361781077, 'examples_seen': 324528, 'step': 8150, 'algorithm': 'activity_selector'}
I0715 13:10:01.193525 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0715 13:10:02.184672 132101335414272 run.py:688] Algo activity_selector step 8200 current loss 2.456803, current_train_items 326528.
I0715 13:10:02.213319 132101335414272 run.py:723] (val) algo activity_selector step 8200: {'selected': 0.9678714859437751, 'score': 0.9678714859437751, 'examples_seen': 326528, 'step': 8200, 'algorithm': 'activity_selector'}
I0715 13:10:02.213474 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0715 13:10:03.208929 132101335414272 run.py:688] Algo activity_selector step 8250 current loss 2.501225, current_train_items 328464.
I0715 13:10:03.239038 132101335414272 run.py:723] (val) algo activity_selector step 8250: {'selected': 0.9216417910447761, 'score': 0.9216417910447761, 'examples_seen': 328464, 'step': 8250, 'algorithm': 'activity_selector'}
I0715 13:10:03.239205 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0715 13:10:04.252262 132101335414272 run.py:688] Algo activity_selector step 8300 current loss 3.016600, current_train_items 330432.
I0715 13:10:04.283558 132101335414272 run.py:723] (val) algo activity_selector step 8300: {'selected': 0.9725490196078432, 'score': 0.9725490196078432, 'examples_seen': 330432, 'step': 8300, 'algorithm': 'activity_selector'}
I0715 13:10:04.283713 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0715 13:10:05.296428 132101335414272 run.py:688] Algo activity_selector step 8350 current loss 0.016092, current_train_items 332480.
I0715 13:10:05.318295 132101335414272 run.py:723] (val) algo activity_selector step 8350: {'selected': 0.9287090558766861, 'score': 0.9287090558766861, 'examples_seen': 332480, 'step': 8350, 'algorithm': 'activity_selector'}
I0715 13:10:05.318451 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0715 13:10:06.329456 132101335414272 run.py:688] Algo activity_selector step 8400 current loss 0.111522, current_train_items 334480.
I0715 13:10:06.351090 132101335414272 run.py:723] (val) algo activity_selector step 8400: {'selected': 0.9631067961165048, 'score': 0.9631067961165048, 'examples_seen': 334480, 'step': 8400, 'algorithm': 'activity_selector'}
I0715 13:10:06.351243 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0715 13:10:07.335770 132101335414272 run.py:688] Algo activity_selector step 8450 current loss 0.924904, current_train_items 336480.
I0715 13:10:07.358844 132101335414272 run.py:723] (val) algo activity_selector step 8450: {'selected': 0.9841897233201581, 'score': 0.9841897233201581, 'examples_seen': 336480, 'step': 8450, 'algorithm': 'activity_selector'}
I0715 13:10:07.358998 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.984, val scores are: activity_selector: 0.984
I0715 13:10:08.358265 132101335414272 run.py:688] Algo activity_selector step 8500 current loss 0.167294, current_train_items 338464.
I0715 13:10:08.382284 132101335414272 run.py:723] (val) algo activity_selector step 8500: {'selected': 0.9455909943714822, 'score': 0.9455909943714822, 'examples_seen': 338464, 'step': 8500, 'algorithm': 'activity_selector'}
I0715 13:10:08.382441 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0715 13:10:09.382139 132101335414272 run.py:688] Algo activity_selector step 8550 current loss 2.074414, current_train_items 340432.
I0715 13:10:09.409004 132101335414272 run.py:723] (val) algo activity_selector step 8550: {'selected': 0.9855595667870035, 'score': 0.9855595667870035, 'examples_seen': 340432, 'step': 8550, 'algorithm': 'activity_selector'}
I0715 13:10:09.409159 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.986, val scores are: activity_selector: 0.986
I0715 13:10:10.390739 132101335414272 run.py:688] Algo activity_selector step 8600 current loss 1.686053, current_train_items 342416.
I0715 13:10:10.419372 132101335414272 run.py:723] (val) algo activity_selector step 8600: {'selected': 0.9869158878504672, 'score': 0.9869158878504672, 'examples_seen': 342416, 'step': 8600, 'algorithm': 'activity_selector'}
I0715 13:10:10.419535 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.987, current avg val score is 0.987, val scores are: activity_selector: 0.987
I0715 13:10:11.435815 132101335414272 run.py:688] Algo activity_selector step 8650 current loss 2.753791, current_train_items 344368.
I0715 13:10:11.467050 132101335414272 run.py:723] (val) algo activity_selector step 8650: {'selected': 0.968503937007874, 'score': 0.968503937007874, 'examples_seen': 344368, 'step': 8650, 'algorithm': 'activity_selector'}
I0715 13:10:11.467205 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0715 13:10:12.470266 132101335414272 run.py:688] Algo activity_selector step 8700 current loss 0.432028, current_train_items 346400.
I0715 13:10:12.491748 132101335414272 run.py:723] (val) algo activity_selector step 8700: {'selected': 0.9612403100775194, 'score': 0.9612403100775194, 'examples_seen': 346400, 'step': 8700, 'algorithm': 'activity_selector'}
I0715 13:10:12.491903 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0715 13:10:13.500704 132101335414272 run.py:688] Algo activity_selector step 8750 current loss 0.122978, current_train_items 348432.
I0715 13:10:13.523680 132101335414272 run.py:723] (val) algo activity_selector step 8750: {'selected': 0.9382239382239382, 'score': 0.9382239382239382, 'examples_seen': 348432, 'step': 8750, 'algorithm': 'activity_selector'}
I0715 13:10:13.523835 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0715 13:10:14.524732 132101335414272 run.py:688] Algo activity_selector step 8800 current loss 0.928653, current_train_items 350416.
I0715 13:10:14.547770 132101335414272 run.py:723] (val) algo activity_selector step 8800: {'selected': 0.956, 'score': 0.956, 'examples_seen': 350416, 'step': 8800, 'algorithm': 'activity_selector'}
I0715 13:10:14.547924 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0715 13:10:15.553035 132101335414272 run.py:688] Algo activity_selector step 8850 current loss 0.191155, current_train_items 352400.
I0715 13:10:15.577024 132101335414272 run.py:723] (val) algo activity_selector step 8850: {'selected': 0.9727626459143969, 'score': 0.9727626459143969, 'examples_seen': 352400, 'step': 8850, 'algorithm': 'activity_selector'}
I0715 13:10:15.577176 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0715 13:10:16.586300 132101335414272 run.py:688] Algo activity_selector step 8900 current loss 0.445488, current_train_items 354368.
I0715 13:10:16.613031 132101335414272 run.py:723] (val) algo activity_selector step 8900: {'selected': 0.9197651663405089, 'score': 0.9197651663405089, 'examples_seen': 354368, 'step': 8900, 'algorithm': 'activity_selector'}
I0715 13:10:16.613185 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0715 13:10:17.599410 132101335414272 run.py:688] Algo activity_selector step 8950 current loss 1.342040, current_train_items 356320.
I0715 13:10:17.628173 132101335414272 run.py:723] (val) algo activity_selector step 8950: {'selected': 0.9551656920077973, 'score': 0.9551656920077973, 'examples_seen': 356320, 'step': 8950, 'algorithm': 'activity_selector'}
I0715 13:10:17.628327 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0715 13:10:18.617711 132101335414272 run.py:688] Algo activity_selector step 9000 current loss 2.584828, current_train_items 358320.
I0715 13:10:18.649219 132101335414272 run.py:723] (val) algo activity_selector step 9000: {'selected': 0.9666011787819253, 'score': 0.9666011787819253, 'examples_seen': 358320, 'step': 9000, 'algorithm': 'activity_selector'}
I0715 13:10:18.649383 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0715 13:10:19.662696 132101335414272 run.py:688] Algo activity_selector step 9050 current loss 0.309003, current_train_items 360320.
I0715 13:10:19.683905 132101335414272 run.py:723] (val) algo activity_selector step 9050: {'selected': 0.9846153846153846, 'score': 0.9846153846153846, 'examples_seen': 360320, 'step': 9050, 'algorithm': 'activity_selector'}
I0715 13:10:19.684060 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.985, val scores are: activity_selector: 0.985
I0715 13:10:20.705189 132101335414272 run.py:688] Algo activity_selector step 9100 current loss 0.264850, current_train_items 362352.
I0715 13:10:20.727198 132101335414272 run.py:723] (val) algo activity_selector step 9100: {'selected': 0.9695740365111561, 'score': 0.9695740365111561, 'examples_seen': 362352, 'step': 9100, 'algorithm': 'activity_selector'}
I0715 13:10:20.727350 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0715 13:10:21.726162 132101335414272 run.py:688] Algo activity_selector step 9150 current loss 0.125259, current_train_items 364352.
I0715 13:10:21.749179 132101335414272 run.py:723] (val) algo activity_selector step 9150: {'selected': 0.9333333333333332, 'score': 0.9333333333333332, 'examples_seen': 364352, 'step': 9150, 'algorithm': 'activity_selector'}
I0715 13:10:21.749333 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0715 13:10:22.746835 132101335414272 run.py:688] Algo activity_selector step 9200 current loss 0.099850, current_train_items 366320.
I0715 13:10:22.770848 132101335414272 run.py:723] (val) algo activity_selector step 9200: {'selected': 0.9704142011834319, 'score': 0.9704142011834319, 'examples_seen': 366320, 'step': 9200, 'algorithm': 'activity_selector'}
I0715 13:10:22.771000 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0715 13:10:23.761504 132101335414272 run.py:688] Algo activity_selector step 9250 current loss 1.299497, current_train_items 368320.
I0715 13:10:23.787907 132101335414272 run.py:723] (val) algo activity_selector step 9250: {'selected': 0.9479768786127168, 'score': 0.9479768786127168, 'examples_seen': 368320, 'step': 9250, 'algorithm': 'activity_selector'}
I0715 13:10:23.788059 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0715 13:10:24.787497 132101335414272 run.py:688] Algo activity_selector step 9300 current loss 1.093022, current_train_items 370272.
I0715 13:10:24.816606 132101335414272 run.py:723] (val) algo activity_selector step 9300: {'selected': 0.9847908745247148, 'score': 0.9847908745247148, 'examples_seen': 370272, 'step': 9300, 'algorithm': 'activity_selector'}
I0715 13:10:24.816762 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.985, val scores are: activity_selector: 0.985
I0715 13:10:25.827121 132101335414272 run.py:688] Algo activity_selector step 9350 current loss 2.536532, current_train_items 372240.
I0715 13:10:25.860689 132101335414272 run.py:723] (val) algo activity_selector step 9350: {'selected': 0.9771863117870723, 'score': 0.9771863117870723, 'examples_seen': 372240, 'step': 9350, 'algorithm': 'activity_selector'}
I0715 13:10:25.860841 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0715 13:10:26.852406 132101335414272 run.py:688] Algo activity_selector step 9400 current loss 0.175722, current_train_items 374288.
I0715 13:10:26.873836 132101335414272 run.py:723] (val) algo activity_selector step 9400: {'selected': 0.96875, 'score': 0.96875, 'examples_seen': 374288, 'step': 9400, 'algorithm': 'activity_selector'}
I0715 13:10:26.874000 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0715 13:10:27.878674 132101335414272 run.py:688] Algo activity_selector step 9450 current loss 0.052440, current_train_items 376288.
I0715 13:10:27.901090 132101335414272 run.py:723] (val) algo activity_selector step 9450: {'selected': 0.9652509652509652, 'score': 0.9652509652509652, 'examples_seen': 376288, 'step': 9450, 'algorithm': 'activity_selector'}
I0715 13:10:27.901242 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0715 13:10:28.894216 132101335414272 run.py:688] Algo activity_selector step 9500 current loss 0.729957, current_train_items 378304.
I0715 13:10:28.917769 132101335414272 run.py:723] (val) algo activity_selector step 9500: {'selected': 0.9568480300187617, 'score': 0.9568480300187617, 'examples_seen': 378304, 'step': 9500, 'algorithm': 'activity_selector'}
I0715 13:10:28.917924 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0715 13:10:29.901285 132101335414272 run.py:688] Algo activity_selector step 9550 current loss 0.205910, current_train_items 380272.
I0715 13:10:29.925317 132101335414272 run.py:723] (val) algo activity_selector step 9550: {'selected': 0.942528735632184, 'score': 0.942528735632184, 'examples_seen': 380272, 'step': 9550, 'algorithm': 'activity_selector'}
I0715 13:10:29.925469 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0715 13:10:30.933068 132101335414272 run.py:688] Algo activity_selector step 9600 current loss 2.053772, current_train_items 382240.
I0715 13:10:30.959962 132101335414272 run.py:723] (val) algo activity_selector step 9600: {'selected': 0.9709864603481624, 'score': 0.9709864603481624, 'examples_seen': 382240, 'step': 9600, 'algorithm': 'activity_selector'}
I0715 13:10:30.960128 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0715 13:10:31.944310 132101335414272 run.py:688] Algo activity_selector step 9650 current loss 0.262430, current_train_items 384224.
I0715 13:10:31.972452 132101335414272 run.py:723] (val) algo activity_selector step 9650: {'selected': 0.967984934086629, 'score': 0.967984934086629, 'examples_seen': 384224, 'step': 9650, 'algorithm': 'activity_selector'}
I0715 13:10:31.972619 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0715 13:10:32.967578 132101335414272 run.py:688] Algo activity_selector step 9700 current loss 2.280107, current_train_items 386176.
I0715 13:10:32.999042 132101335414272 run.py:723] (val) algo activity_selector step 9700: {'selected': 0.9582504970178927, 'score': 0.9582504970178927, 'examples_seen': 386176, 'step': 9700, 'algorithm': 'activity_selector'}
I0715 13:10:32.999199 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0715 13:10:33.998402 132101335414272 run.py:688] Algo activity_selector step 9750 current loss 0.355947, current_train_items 388224.
I0715 13:10:34.019795 132101335414272 run.py:723] (val) algo activity_selector step 9750: {'selected': 0.9656488549618321, 'score': 0.9656488549618321, 'examples_seen': 388224, 'step': 9750, 'algorithm': 'activity_selector'}
I0715 13:10:34.019948 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0715 13:10:35.020035 132101335414272 run.py:688] Algo activity_selector step 9800 current loss 0.072187, current_train_items 390240.
I0715 13:10:35.042426 132101335414272 run.py:723] (val) algo activity_selector step 9800: {'selected': 0.9886363636363636, 'score': 0.9886363636363636, 'examples_seen': 390240, 'step': 9800, 'algorithm': 'activity_selector'}
I0715 13:10:35.042588 132101335414272 run.py:744] Checkpointing best model, best avg val score was 0.987, current avg val score is 0.989, val scores are: activity_selector: 0.989
I0715 13:10:36.088693 132101335414272 run.py:688] Algo activity_selector step 9850 current loss 0.706169, current_train_items 392224.
I0715 13:10:36.111967 132101335414272 run.py:723] (val) algo activity_selector step 9850: {'selected': 0.974757281553398, 'score': 0.974757281553398, 'examples_seen': 392224, 'step': 9850, 'algorithm': 'activity_selector'}
I0715 13:10:36.112122 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0715 13:10:37.090283 132101335414272 run.py:688] Algo activity_selector step 9900 current loss 0.262434, current_train_items 394208.
I0715 13:10:37.114865 132101335414272 run.py:723] (val) algo activity_selector step 9900: {'selected': 0.9676190476190475, 'score': 0.9676190476190475, 'examples_seen': 394208, 'step': 9900, 'algorithm': 'activity_selector'}
I0715 13:10:37.115020 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0715 13:10:38.127242 132101335414272 run.py:688] Algo activity_selector step 9950 current loss 0.208390, current_train_items 396176.
I0715 13:10:38.154381 132101335414272 run.py:723] (val) algo activity_selector step 9950: {'selected': 0.9666011787819254, 'score': 0.9666011787819254, 'examples_seen': 396176, 'step': 9950, 'algorithm': 'activity_selector'}
I0715 13:10:38.154544 132101335414272 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0715 13:10:39.128406 132101335414272 run.py:753] Restoring best model from checkpoint...
I0715 13:10:45.909276 132101335414272 run.py:768] (test) algo activity_selector : {'selected': 0.9143835616438356, 'score': 0.9143835616438356, 'examples_seen': 398112, 'step': 10000, 'algorithm': 'activity_selector'}
I0715 13:10:45.909521 132101335414272 run.py:770] Done!
