I1130 22:12:54.757584 130402719151616 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I1130 22:12:54.759985 130402719151616 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I1130 22:12:55.096489 130402719151616 run.py:453] Model: f7 ['activity_selector']
I1130 22:12:55.096588 130402719151616 run.py:455] algorithms ['activity_selector']
I1130 22:12:55.096765 130402719151616 run.py:456] train_lengths ['4', '7', '11', '13', '16']
I1130 22:12:55.096803 130402719151616 run.py:457] train_batch_size 16
I1130 22:12:55.096902 130402719151616 run.py:458] val_batch_size 16
I1130 22:12:55.096935 130402719151616 run.py:459] test_batch_size 16
I1130 22:12:55.096965 130402719151616 run.py:460] chunked_training True
I1130 22:12:55.097089 130402719151616 run.py:461] chunk_length 16
I1130 22:12:55.097120 130402719151616 run.py:462] train_steps 10000
I1130 22:12:55.097150 130402719151616 run.py:463] eval_every 50
I1130 22:12:55.097179 130402719151616 run.py:464] test_every 500
I1130 22:12:55.097211 130402719151616 run.py:465] hidden_size 256
I1130 22:12:55.097239 130402719151616 run.py:466] nb_msg_passing_steps 1
I1130 22:12:55.097268 130402719151616 run.py:467] learning_rate 0.001
I1130 22:12:55.097360 130402719151616 run.py:468] grad_clip_max_norm 1.0
I1130 22:12:55.097391 130402719151616 run.py:469] dropout_prob 0.0
I1130 22:12:55.097421 130402719151616 run.py:470] hint_teacher_forcing 0.0
I1130 22:12:55.097450 130402719151616 run.py:471] hint_mode encoded_decoded
I1130 22:12:55.097552 130402719151616 run.py:472] hint_repred_mode soft
I1130 22:12:55.097582 130402719151616 run.py:473] use_ln True
I1130 22:12:55.097610 130402719151616 run.py:474] use_lstm True
I1130 22:12:55.097639 130402719151616 run.py:475] nb_triplet_fts 16
I1130 22:12:55.097667 130402719151616 run.py:476] encoder_init xavier_on_scalars
I1130 22:12:55.097695 130402719151616 run.py:477] processor_type f7
I1130 22:12:55.097727 130402719151616 run.py:478] checkpoint_path CLRS30
I1130 22:12:55.097756 130402719151616 run.py:479] dataset_path CLRS30
I1130 22:12:55.097784 130402719151616 run.py:480] freeze_processor False
I1130 22:12:55.097811 130402719151616 run.py:481] reduction min
I1130 22:12:55.097839 130402719151616 run.py:482] activation elu
I1130 22:12:55.097875 130402719151616 run.py:483] restore_model 
I1130 22:12:55.097908 130402719151616 run.py:484] gated True
I1130 22:12:55.097936 130402719151616 run.py:485] gated_activation tanh
I1130 22:12:55.100657 130402719151616 run.py:511] Creating samplers for algo activity_selector
W1130 22:12:55.100875 130402719151616 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1130 22:12:55.101131 130402719151616 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W1130 22:12:55.309700 130402719151616 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1130 22:12:55.553661 130402719151616 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1130 22:12:55.858068 130402719151616 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1130 22:12:56.189419 130402719151616 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1130 22:12:56.574460 130402719151616 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I1130 22:12:56.574748 130402719151616 samplers.py:124] Creating a dataset with 64 samples.
I1130 22:12:56.600523 130402719151616 run.py:297] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I1130 22:12:56.601278 130402719151616 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I1130 22:12:56.604423 130402719151616 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I1130 22:12:56.607741 130402719151616 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I1130 22:12:56.664556 130402719151616 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W1130 22:12:56.699379 130402719151616 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x76993b3949a0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I1130 22:13:29.555268 130402719151616 run.py:734] Algo activity_selector step 0 current loss 5.716732, current_train_items 32.
I1130 22:13:39.402411 130402719151616 run.py:769] (val) algo activity_selector step 0: {'selected': 0.0425531914893617, 'score': 0.0425531914893617, 'examples_seen': 32, 'step': 0, 'algorithm': 'activity_selector'}
I1130 22:13:39.402571 130402719151616 run.py:790] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.043, val scores are: activity_selector: 0.043
I1130 22:14:32.148681 130402719151616 run.py:734] Algo activity_selector step 50 current loss 3.852361, current_train_items 1408.
I1130 22:14:32.283058 130402719151616 run.py:769] (val) algo activity_selector step 50: {'selected': 0.5985401459854015, 'score': 0.5985401459854015, 'examples_seen': 1408, 'step': 50, 'algorithm': 'activity_selector'}
I1130 22:14:32.283332 130402719151616 run.py:790] Checkpointing best model, best avg val score was 0.043, current avg val score is 0.599, val scores are: activity_selector: 0.599
I1130 22:14:33.393259 130402719151616 run.py:734] Algo activity_selector step 100 current loss 3.189101, current_train_items 2800.
I1130 22:14:33.526152 130402719151616 run.py:769] (val) algo activity_selector step 100: {'selected': 0.7412353923205341, 'score': 0.7412353923205341, 'examples_seen': 2800, 'step': 100, 'algorithm': 'activity_selector'}
I1130 22:14:33.526385 130402719151616 run.py:790] Checkpointing best model, best avg val score was 0.599, current avg val score is 0.741, val scores are: activity_selector: 0.741
I1130 22:14:34.653151 130402719151616 run.py:734] Algo activity_selector step 150 current loss 2.612864, current_train_items 4176.
I1130 22:14:34.784941 130402719151616 run.py:769] (val) algo activity_selector step 150: {'selected': 0.7977315689981096, 'score': 0.7977315689981096, 'examples_seen': 4176, 'step': 150, 'algorithm': 'activity_selector'}
I1130 22:14:34.785189 130402719151616 run.py:790] Checkpointing best model, best avg val score was 0.741, current avg val score is 0.798, val scores are: activity_selector: 0.798
I1130 22:14:35.885042 130402719151616 run.py:734] Algo activity_selector step 200 current loss 2.573565, current_train_items 5536.
I1130 22:14:36.031041 130402719151616 run.py:769] (val) algo activity_selector step 200: {'selected': 0.7650485436893203, 'score': 0.7650485436893203, 'examples_seen': 5536, 'step': 200, 'algorithm': 'activity_selector'}
I1130 22:14:36.031295 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.798, current avg val score is 0.765, val scores are: activity_selector: 0.765
I1130 22:14:37.076940 130402719151616 run.py:734] Algo activity_selector step 250 current loss 2.511237, current_train_items 6944.
I1130 22:14:37.208992 130402719151616 run.py:769] (val) algo activity_selector step 250: {'selected': 0.751968503937008, 'score': 0.751968503937008, 'examples_seen': 6944, 'step': 250, 'algorithm': 'activity_selector'}
I1130 22:14:37.209215 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.798, current avg val score is 0.752, val scores are: activity_selector: 0.752
I1130 22:14:38.262593 130402719151616 run.py:734] Algo activity_selector step 300 current loss 2.412866, current_train_items 8304.
I1130 22:14:38.396398 130402719151616 run.py:769] (val) algo activity_selector step 300: {'selected': 0.806083650190114, 'score': 0.806083650190114, 'examples_seen': 8304, 'step': 300, 'algorithm': 'activity_selector'}
I1130 22:14:38.396621 130402719151616 run.py:790] Checkpointing best model, best avg val score was 0.798, current avg val score is 0.806, val scores are: activity_selector: 0.806
I1130 22:14:39.489332 130402719151616 run.py:734] Algo activity_selector step 350 current loss 2.286084, current_train_items 9680.
I1130 22:14:39.635428 130402719151616 run.py:769] (val) algo activity_selector step 350: {'selected': 0.7922912205567453, 'score': 0.7922912205567453, 'examples_seen': 9680, 'step': 350, 'algorithm': 'activity_selector'}
I1130 22:14:39.635648 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.806, current avg val score is 0.792, val scores are: activity_selector: 0.792
I1130 22:14:40.680289 130402719151616 run.py:734] Algo activity_selector step 400 current loss 1.935655, current_train_items 11072.
I1130 22:14:40.811311 130402719151616 run.py:769] (val) algo activity_selector step 400: {'selected': 0.7864271457085827, 'score': 0.7864271457085827, 'examples_seen': 11072, 'step': 400, 'algorithm': 'activity_selector'}
I1130 22:14:40.811532 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.806, current avg val score is 0.786, val scores are: activity_selector: 0.786
I1130 22:14:41.865646 130402719151616 run.py:734] Algo activity_selector step 450 current loss 1.701292, current_train_items 12448.
I1130 22:14:41.995748 130402719151616 run.py:769] (val) algo activity_selector step 450: {'selected': 0.855072463768116, 'score': 0.855072463768116, 'examples_seen': 12448, 'step': 450, 'algorithm': 'activity_selector'}
I1130 22:14:41.995985 130402719151616 run.py:790] Checkpointing best model, best avg val score was 0.806, current avg val score is 0.855, val scores are: activity_selector: 0.855
I1130 22:14:43.102508 130402719151616 run.py:734] Algo activity_selector step 500 current loss 2.106358, current_train_items 13824.
I1130 22:14:43.233606 130402719151616 run.py:769] (val) algo activity_selector step 500: {'selected': 0.7285464098073554, 'score': 0.7285464098073554, 'examples_seen': 13824, 'step': 500, 'algorithm': 'activity_selector'}
I1130 22:14:43.233828 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.855, current avg val score is 0.729, val scores are: activity_selector: 0.729
I1130 22:14:44.268414 130402719151616 run.py:734] Algo activity_selector step 550 current loss 2.065537, current_train_items 15200.
I1130 22:14:44.415899 130402719151616 run.py:769] (val) algo activity_selector step 550: {'selected': 0.8737474949899801, 'score': 0.8737474949899801, 'examples_seen': 15200, 'step': 550, 'algorithm': 'activity_selector'}
I1130 22:14:44.416126 130402719151616 run.py:790] Checkpointing best model, best avg val score was 0.855, current avg val score is 0.874, val scores are: activity_selector: 0.874
I1130 22:14:45.510588 130402719151616 run.py:734] Algo activity_selector step 600 current loss 1.550729, current_train_items 16576.
I1130 22:14:45.655891 130402719151616 run.py:769] (val) algo activity_selector step 600: {'selected': 0.8469184890656064, 'score': 0.8469184890656064, 'examples_seen': 16576, 'step': 600, 'algorithm': 'activity_selector'}
I1130 22:14:45.656113 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.874, current avg val score is 0.847, val scores are: activity_selector: 0.847
I1130 22:14:46.685726 130402719151616 run.py:734] Algo activity_selector step 650 current loss 1.875319, current_train_items 17952.
I1130 22:14:46.831048 130402719151616 run.py:769] (val) algo activity_selector step 650: {'selected': 0.8441330998248687, 'score': 0.8441330998248687, 'examples_seen': 17952, 'step': 650, 'algorithm': 'activity_selector'}
I1130 22:14:46.831291 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.874, current avg val score is 0.844, val scores are: activity_selector: 0.844
I1130 22:14:47.875244 130402719151616 run.py:734] Algo activity_selector step 700 current loss 1.630916, current_train_items 19344.
I1130 22:14:48.006641 130402719151616 run.py:769] (val) algo activity_selector step 700: {'selected': 0.8688845401174169, 'score': 0.8688845401174169, 'examples_seen': 19344, 'step': 700, 'algorithm': 'activity_selector'}
I1130 22:14:48.006881 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.874, current avg val score is 0.869, val scores are: activity_selector: 0.869
I1130 22:14:49.061685 130402719151616 run.py:734] Algo activity_selector step 750 current loss 1.714641, current_train_items 20720.
I1130 22:14:49.192614 130402719151616 run.py:769] (val) algo activity_selector step 750: {'selected': 0.8706365503080082, 'score': 0.8706365503080082, 'examples_seen': 20720, 'step': 750, 'algorithm': 'activity_selector'}
I1130 22:14:49.192835 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.874, current avg val score is 0.871, val scores are: activity_selector: 0.871
I1130 22:14:50.228025 130402719151616 run.py:734] Algo activity_selector step 800 current loss 1.463639, current_train_items 22096.
I1130 22:14:50.374075 130402719151616 run.py:769] (val) algo activity_selector step 800: {'selected': 0.9221789883268483, 'score': 0.9221789883268483, 'examples_seen': 22096, 'step': 800, 'algorithm': 'activity_selector'}
I1130 22:14:50.374298 130402719151616 run.py:790] Checkpointing best model, best avg val score was 0.874, current avg val score is 0.922, val scores are: activity_selector: 0.922
I1130 22:14:51.479159 130402719151616 run.py:734] Algo activity_selector step 850 current loss 1.653554, current_train_items 23472.
I1130 22:14:51.610299 130402719151616 run.py:769] (val) algo activity_selector step 850: {'selected': 0.8198970840480275, 'score': 0.8198970840480275, 'examples_seen': 23472, 'step': 850, 'algorithm': 'activity_selector'}
I1130 22:14:51.610521 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.922, current avg val score is 0.820, val scores are: activity_selector: 0.820
I1130 22:14:52.665485 130402719151616 run.py:734] Algo activity_selector step 900 current loss 1.551550, current_train_items 24848.
I1130 22:14:52.795742 130402719151616 run.py:769] (val) algo activity_selector step 900: {'selected': 0.9129593810444875, 'score': 0.9129593810444875, 'examples_seen': 24848, 'step': 900, 'algorithm': 'activity_selector'}
I1130 22:14:52.795977 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.922, current avg val score is 0.913, val scores are: activity_selector: 0.913
I1130 22:14:53.839843 130402719151616 run.py:734] Algo activity_selector step 950 current loss 1.386633, current_train_items 26224.
I1130 22:14:53.971306 130402719151616 run.py:769] (val) algo activity_selector step 950: {'selected': 0.8927203065134101, 'score': 0.8927203065134101, 'examples_seen': 26224, 'step': 950, 'algorithm': 'activity_selector'}
I1130 22:14:53.971527 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.922, current avg val score is 0.893, val scores are: activity_selector: 0.893
I1130 22:14:55.007044 130402719151616 run.py:734] Algo activity_selector step 1000 current loss 1.506006, current_train_items 27616.
I1130 22:14:55.154762 130402719151616 run.py:769] (val) algo activity_selector step 1000: {'selected': 0.8761552680221811, 'score': 0.8761552680221811, 'examples_seen': 27616, 'step': 1000, 'algorithm': 'activity_selector'}
I1130 22:14:55.155005 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.922, current avg val score is 0.876, val scores are: activity_selector: 0.876
I1130 22:14:56.216198 130402719151616 run.py:734] Algo activity_selector step 1050 current loss 1.525636, current_train_items 28992.
I1130 22:14:56.343949 130402719151616 run.py:769] (val) algo activity_selector step 1050: {'selected': 0.8966861598440545, 'score': 0.8966861598440545, 'examples_seen': 28992, 'step': 1050, 'algorithm': 'activity_selector'}
I1130 22:14:56.344171 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.922, current avg val score is 0.897, val scores are: activity_selector: 0.897
I1130 22:14:57.390552 130402719151616 run.py:734] Algo activity_selector step 1100 current loss 1.557875, current_train_items 30368.
I1130 22:14:57.523520 130402719151616 run.py:769] (val) algo activity_selector step 1100: {'selected': 0.8435643564356435, 'score': 0.8435643564356435, 'examples_seen': 30368, 'step': 1100, 'algorithm': 'activity_selector'}
I1130 22:14:57.523738 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.922, current avg val score is 0.844, val scores are: activity_selector: 0.844
I1130 22:14:58.569775 130402719151616 run.py:734] Algo activity_selector step 1150 current loss 1.351094, current_train_items 31760.
I1130 22:14:58.701697 130402719151616 run.py:769] (val) algo activity_selector step 1150: {'selected': 0.8555956678700362, 'score': 0.8555956678700362, 'examples_seen': 31760, 'step': 1150, 'algorithm': 'activity_selector'}
I1130 22:14:58.701951 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.922, current avg val score is 0.856, val scores are: activity_selector: 0.856
I1130 22:14:59.762172 130402719151616 run.py:734] Algo activity_selector step 1200 current loss 1.120827, current_train_items 33120.
I1130 22:14:59.894331 130402719151616 run.py:769] (val) algo activity_selector step 1200: {'selected': 0.8788426763110307, 'score': 0.8788426763110307, 'examples_seen': 33120, 'step': 1200, 'algorithm': 'activity_selector'}
I1130 22:14:59.894555 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.922, current avg val score is 0.879, val scores are: activity_selector: 0.879
I1130 22:15:00.942314 130402719151616 run.py:734] Algo activity_selector step 1250 current loss 1.214207, current_train_items 34496.
I1130 22:15:01.074768 130402719151616 run.py:769] (val) algo activity_selector step 1250: {'selected': 0.9303201506591336, 'score': 0.9303201506591336, 'examples_seen': 34496, 'step': 1250, 'algorithm': 'activity_selector'}
I1130 22:15:01.075001 130402719151616 run.py:790] Checkpointing best model, best avg val score was 0.922, current avg val score is 0.930, val scores are: activity_selector: 0.930
I1130 22:15:02.181043 130402719151616 run.py:734] Algo activity_selector step 1300 current loss 1.425096, current_train_items 35888.
I1130 22:15:02.313550 130402719151616 run.py:769] (val) algo activity_selector step 1300: {'selected': 0.89453125, 'score': 0.89453125, 'examples_seen': 35888, 'step': 1300, 'algorithm': 'activity_selector'}
I1130 22:15:02.313776 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.930, current avg val score is 0.895, val scores are: activity_selector: 0.895
I1130 22:15:03.370391 130402719151616 run.py:734] Algo activity_selector step 1350 current loss 1.169963, current_train_items 37264.
I1130 22:15:03.502759 130402719151616 run.py:769] (val) algo activity_selector step 1350: {'selected': 0.8781362007168458, 'score': 0.8781362007168458, 'examples_seen': 37264, 'step': 1350, 'algorithm': 'activity_selector'}
I1130 22:15:03.503028 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.930, current avg val score is 0.878, val scores are: activity_selector: 0.878
I1130 22:15:04.536017 130402719151616 run.py:734] Algo activity_selector step 1400 current loss 1.421585, current_train_items 38640.
I1130 22:15:04.682542 130402719151616 run.py:769] (val) algo activity_selector step 1400: {'selected': 0.919020715630885, 'score': 0.919020715630885, 'examples_seen': 38640, 'step': 1400, 'algorithm': 'activity_selector'}
I1130 22:15:04.682764 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.930, current avg val score is 0.919, val scores are: activity_selector: 0.919
I1130 22:15:05.721654 130402719151616 run.py:734] Algo activity_selector step 1450 current loss 1.203088, current_train_items 40016.
I1130 22:15:05.867843 130402719151616 run.py:769] (val) algo activity_selector step 1450: {'selected': 0.9213051823416506, 'score': 0.9213051823416506, 'examples_seen': 40016, 'step': 1450, 'algorithm': 'activity_selector'}
I1130 22:15:05.868110 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.930, current avg val score is 0.921, val scores are: activity_selector: 0.921
I1130 22:15:06.926357 130402719151616 run.py:734] Algo activity_selector step 1500 current loss 1.353481, current_train_items 41408.
I1130 22:15:07.058116 130402719151616 run.py:769] (val) algo activity_selector step 1500: {'selected': 0.8597122302158274, 'score': 0.8597122302158274, 'examples_seen': 41408, 'step': 1500, 'algorithm': 'activity_selector'}
I1130 22:15:07.058339 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.930, current avg val score is 0.860, val scores are: activity_selector: 0.860
I1130 22:15:08.108920 130402719151616 run.py:734] Algo activity_selector step 1550 current loss 1.506241, current_train_items 42768.
I1130 22:15:08.247962 130402719151616 run.py:769] (val) algo activity_selector step 1550: {'selected': 0.9125475285171102, 'score': 0.9125475285171102, 'examples_seen': 42768, 'step': 1550, 'algorithm': 'activity_selector'}
I1130 22:15:08.248202 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.930, current avg val score is 0.913, val scores are: activity_selector: 0.913
I1130 22:15:09.294316 130402719151616 run.py:734] Algo activity_selector step 1600 current loss 1.068136, current_train_items 44160.
I1130 22:15:09.428119 130402719151616 run.py:769] (val) algo activity_selector step 1600: {'selected': 0.8703703703703703, 'score': 0.8703703703703703, 'examples_seen': 44160, 'step': 1600, 'algorithm': 'activity_selector'}
I1130 22:15:09.428341 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.930, current avg val score is 0.870, val scores are: activity_selector: 0.870
I1130 22:15:10.490701 130402719151616 run.py:734] Algo activity_selector step 1650 current loss 0.966637, current_train_items 45536.
I1130 22:15:10.623579 130402719151616 run.py:769] (val) algo activity_selector step 1650: {'selected': 0.9284332688588007, 'score': 0.9284332688588007, 'examples_seen': 45536, 'step': 1650, 'algorithm': 'activity_selector'}
I1130 22:15:10.623820 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.930, current avg val score is 0.928, val scores are: activity_selector: 0.928
I1130 22:15:11.669887 130402719151616 run.py:734] Algo activity_selector step 1700 current loss 1.057312, current_train_items 46896.
I1130 22:15:11.804213 130402719151616 run.py:769] (val) algo activity_selector step 1700: {'selected': 0.9323017408123792, 'score': 0.9323017408123792, 'examples_seen': 46896, 'step': 1700, 'algorithm': 'activity_selector'}
I1130 22:15:11.804434 130402719151616 run.py:790] Checkpointing best model, best avg val score was 0.930, current avg val score is 0.932, val scores are: activity_selector: 0.932
I1130 22:15:12.914192 130402719151616 run.py:734] Algo activity_selector step 1750 current loss 1.274592, current_train_items 48304.
I1130 22:15:13.047119 130402719151616 run.py:769] (val) algo activity_selector step 1750: {'selected': 0.9043824701195218, 'score': 0.9043824701195218, 'examples_seen': 48304, 'step': 1750, 'algorithm': 'activity_selector'}
I1130 22:15:13.047343 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.932, current avg val score is 0.904, val scores are: activity_selector: 0.904
I1130 22:15:14.119008 130402719151616 run.py:734] Algo activity_selector step 1800 current loss 1.142446, current_train_items 49664.
I1130 22:15:14.236572 130402719151616 run.py:769] (val) algo activity_selector step 1800: {'selected': 0.9134438305709023, 'score': 0.9134438305709023, 'examples_seen': 49664, 'step': 1800, 'algorithm': 'activity_selector'}
I1130 22:15:14.236813 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.932, current avg val score is 0.913, val scores are: activity_selector: 0.913
I1130 22:15:15.286539 130402719151616 run.py:734] Algo activity_selector step 1850 current loss 1.159863, current_train_items 51056.
I1130 22:15:15.419968 130402719151616 run.py:769] (val) algo activity_selector step 1850: {'selected': 0.8392857142857142, 'score': 0.8392857142857142, 'examples_seen': 51056, 'step': 1850, 'algorithm': 'activity_selector'}
I1130 22:15:15.420196 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.932, current avg val score is 0.839, val scores are: activity_selector: 0.839
I1130 22:15:16.471781 130402719151616 run.py:734] Algo activity_selector step 1900 current loss 0.976338, current_train_items 52432.
I1130 22:15:16.603582 130402719151616 run.py:769] (val) algo activity_selector step 1900: {'selected': 0.8726003490401396, 'score': 0.8726003490401396, 'examples_seen': 52432, 'step': 1900, 'algorithm': 'activity_selector'}
I1130 22:15:16.603803 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.932, current avg val score is 0.873, val scores are: activity_selector: 0.873
I1130 22:15:17.661123 130402719151616 run.py:734] Algo activity_selector step 1950 current loss 1.069332, current_train_items 53808.
I1130 22:15:17.792152 130402719151616 run.py:769] (val) algo activity_selector step 1950: {'selected': 0.9306569343065694, 'score': 0.9306569343065694, 'examples_seen': 53808, 'step': 1950, 'algorithm': 'activity_selector'}
I1130 22:15:17.792372 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.932, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1130 22:15:18.838613 130402719151616 run.py:734] Algo activity_selector step 2000 current loss 0.943337, current_train_items 55184.
I1130 22:15:18.970696 130402719151616 run.py:769] (val) algo activity_selector step 2000: {'selected': 0.9292543021032504, 'score': 0.9292543021032504, 'examples_seen': 55184, 'step': 2000, 'algorithm': 'activity_selector'}
I1130 22:15:18.970932 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.932, current avg val score is 0.929, val scores are: activity_selector: 0.929
I1130 22:15:20.003540 130402719151616 run.py:734] Algo activity_selector step 2050 current loss 0.861423, current_train_items 56560.
I1130 22:15:20.150632 130402719151616 run.py:769] (val) algo activity_selector step 2050: {'selected': 0.914179104477612, 'score': 0.914179104477612, 'examples_seen': 56560, 'step': 2050, 'algorithm': 'activity_selector'}
I1130 22:15:20.150895 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.932, current avg val score is 0.914, val scores are: activity_selector: 0.914
I1130 22:15:21.214962 130402719151616 run.py:734] Algo activity_selector step 2100 current loss 1.126847, current_train_items 57952.
I1130 22:15:21.346963 130402719151616 run.py:769] (val) algo activity_selector step 2100: {'selected': 0.84765625, 'score': 0.84765625, 'examples_seen': 57952, 'step': 2100, 'algorithm': 'activity_selector'}
I1130 22:15:21.347182 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.932, current avg val score is 0.848, val scores are: activity_selector: 0.848
I1130 22:15:22.393952 130402719151616 run.py:734] Algo activity_selector step 2150 current loss 1.124333, current_train_items 59312.
I1130 22:15:22.526949 130402719151616 run.py:769] (val) algo activity_selector step 2150: {'selected': 0.9118773946360152, 'score': 0.9118773946360152, 'examples_seen': 59312, 'step': 2150, 'algorithm': 'activity_selector'}
I1130 22:15:22.527096 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.932, current avg val score is 0.912, val scores are: activity_selector: 0.912
I1130 22:15:23.565516 130402719151616 run.py:734] Algo activity_selector step 2200 current loss 1.185067, current_train_items 60720.
I1130 22:15:23.697718 130402719151616 run.py:769] (val) algo activity_selector step 2200: {'selected': 0.9083820662768033, 'score': 0.9083820662768033, 'examples_seen': 60720, 'step': 2200, 'algorithm': 'activity_selector'}
I1130 22:15:23.697951 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.932, current avg val score is 0.908, val scores are: activity_selector: 0.908
I1130 22:15:24.742084 130402719151616 run.py:734] Algo activity_selector step 2250 current loss 0.822694, current_train_items 62080.
I1130 22:15:24.887854 130402719151616 run.py:769] (val) algo activity_selector step 2250: {'selected': 0.8816029143897997, 'score': 0.8816029143897997, 'examples_seen': 62080, 'step': 2250, 'algorithm': 'activity_selector'}
I1130 22:15:24.888088 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.932, current avg val score is 0.882, val scores are: activity_selector: 0.882
I1130 22:15:25.940395 130402719151616 run.py:734] Algo activity_selector step 2300 current loss 0.840026, current_train_items 63440.
I1130 22:15:26.071851 130402719151616 run.py:769] (val) algo activity_selector step 2300: {'selected': 0.9338374291115312, 'score': 0.9338374291115312, 'examples_seen': 63440, 'step': 2300, 'algorithm': 'activity_selector'}
I1130 22:15:26.072105 130402719151616 run.py:790] Checkpointing best model, best avg val score was 0.932, current avg val score is 0.934, val scores are: activity_selector: 0.934
I1130 22:15:27.189134 130402719151616 run.py:734] Algo activity_selector step 2350 current loss 0.868083, current_train_items 64848.
I1130 22:15:27.319797 130402719151616 run.py:769] (val) algo activity_selector step 2350: {'selected': 0.9375, 'score': 0.9375, 'examples_seen': 64848, 'step': 2350, 'algorithm': 'activity_selector'}
I1130 22:15:27.319952 130402719151616 run.py:790] Checkpointing best model, best avg val score was 0.934, current avg val score is 0.938, val scores are: activity_selector: 0.938
I1130 22:15:28.423193 130402719151616 run.py:734] Algo activity_selector step 2400 current loss 0.996793, current_train_items 66208.
I1130 22:15:28.555466 130402719151616 run.py:769] (val) algo activity_selector step 2400: {'selected': 0.9274809160305344, 'score': 0.9274809160305344, 'examples_seen': 66208, 'step': 2400, 'algorithm': 'activity_selector'}
I1130 22:15:28.555685 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.938, current avg val score is 0.927, val scores are: activity_selector: 0.927
I1130 22:15:29.607419 130402719151616 run.py:734] Algo activity_selector step 2450 current loss 1.105093, current_train_items 67600.
I1130 22:15:29.740952 130402719151616 run.py:769] (val) algo activity_selector step 2450: {'selected': 0.9461538461538462, 'score': 0.9461538461538462, 'examples_seen': 67600, 'step': 2450, 'algorithm': 'activity_selector'}
I1130 22:15:29.741174 130402719151616 run.py:790] Checkpointing best model, best avg val score was 0.938, current avg val score is 0.946, val scores are: activity_selector: 0.946
I1130 22:15:30.840414 130402719151616 run.py:734] Algo activity_selector step 2500 current loss 1.073445, current_train_items 68976.
I1130 22:15:30.987870 130402719151616 run.py:769] (val) algo activity_selector step 2500: {'selected': 0.9245647969052224, 'score': 0.9245647969052224, 'examples_seen': 68976, 'step': 2500, 'algorithm': 'activity_selector'}
I1130 22:15:30.988019 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.946, current avg val score is 0.925, val scores are: activity_selector: 0.925
I1130 22:15:32.034740 130402719151616 run.py:734] Algo activity_selector step 2550 current loss 0.873328, current_train_items 70352.
I1130 22:15:32.165297 130402719151616 run.py:769] (val) algo activity_selector step 2550: {'selected': 0.9076923076923077, 'score': 0.9076923076923077, 'examples_seen': 70352, 'step': 2550, 'algorithm': 'activity_selector'}
I1130 22:15:32.165446 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.946, current avg val score is 0.908, val scores are: activity_selector: 0.908
I1130 22:15:33.211097 130402719151616 run.py:734] Algo activity_selector step 2600 current loss 0.737614, current_train_items 71728.
I1130 22:15:33.341334 130402719151616 run.py:769] (val) algo activity_selector step 2600: {'selected': 0.9275929549902152, 'score': 0.9275929549902152, 'examples_seen': 71728, 'step': 2600, 'algorithm': 'activity_selector'}
I1130 22:15:33.341479 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.946, current avg val score is 0.928, val scores are: activity_selector: 0.928
I1130 22:15:34.382500 130402719151616 run.py:734] Algo activity_selector step 2650 current loss 0.908098, current_train_items 73104.
I1130 22:15:34.513390 130402719151616 run.py:769] (val) algo activity_selector step 2650: {'selected': 0.9477756286266924, 'score': 0.9477756286266924, 'examples_seen': 73104, 'step': 2650, 'algorithm': 'activity_selector'}
I1130 22:15:34.513536 130402719151616 run.py:790] Checkpointing best model, best avg val score was 0.946, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1130 22:15:35.624119 130402719151616 run.py:734] Algo activity_selector step 2700 current loss 0.829928, current_train_items 74496.
I1130 22:15:35.752783 130402719151616 run.py:769] (val) algo activity_selector step 2700: {'selected': 0.9387755102040817, 'score': 0.9387755102040817, 'examples_seen': 74496, 'step': 2700, 'algorithm': 'activity_selector'}
I1130 22:15:35.752966 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.948, current avg val score is 0.939, val scores are: activity_selector: 0.939
I1130 22:15:36.798797 130402719151616 run.py:734] Algo activity_selector step 2750 current loss 0.965546, current_train_items 75856.
I1130 22:15:36.930579 130402719151616 run.py:769] (val) algo activity_selector step 2750: {'selected': 0.9400749063670413, 'score': 0.9400749063670413, 'examples_seen': 75856, 'step': 2750, 'algorithm': 'activity_selector'}
I1130 22:15:36.930725 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.948, current avg val score is 0.940, val scores are: activity_selector: 0.940
I1130 22:15:37.971001 130402719151616 run.py:734] Algo activity_selector step 2800 current loss 0.958484, current_train_items 77264.
I1130 22:15:38.101187 130402719151616 run.py:769] (val) algo activity_selector step 2800: {'selected': 0.8719008264462811, 'score': 0.8719008264462811, 'examples_seen': 77264, 'step': 2800, 'algorithm': 'activity_selector'}
I1130 22:15:38.101333 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.948, current avg val score is 0.872, val scores are: activity_selector: 0.872
I1130 22:15:39.148841 130402719151616 run.py:734] Algo activity_selector step 2850 current loss 1.005034, current_train_items 78624.
I1130 22:15:39.280451 130402719151616 run.py:769] (val) algo activity_selector step 2850: {'selected': 0.96484375, 'score': 0.96484375, 'examples_seen': 78624, 'step': 2850, 'algorithm': 'activity_selector'}
I1130 22:15:39.280597 130402719151616 run.py:790] Checkpointing best model, best avg val score was 0.948, current avg val score is 0.965, val scores are: activity_selector: 0.965
I1130 22:15:40.383742 130402719151616 run.py:734] Algo activity_selector step 2900 current loss 1.005843, current_train_items 80000.
I1130 22:15:40.514877 130402719151616 run.py:769] (val) algo activity_selector step 2900: {'selected': 0.9149797570850201, 'score': 0.9149797570850201, 'examples_seen': 80000, 'step': 2900, 'algorithm': 'activity_selector'}
I1130 22:15:40.515024 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.915, val scores are: activity_selector: 0.915
I1130 22:15:41.549763 130402719151616 run.py:734] Algo activity_selector step 2950 current loss 0.793577, current_train_items 81392.
I1130 22:15:41.695935 130402719151616 run.py:769] (val) algo activity_selector step 2950: {'selected': 0.9469548133595286, 'score': 0.9469548133595286, 'examples_seen': 81392, 'step': 2950, 'algorithm': 'activity_selector'}
I1130 22:15:41.696094 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.947, val scores are: activity_selector: 0.947
I1130 22:15:42.742733 130402719151616 run.py:734] Algo activity_selector step 3000 current loss 1.056816, current_train_items 82752.
I1130 22:15:42.873733 130402719151616 run.py:769] (val) algo activity_selector step 3000: {'selected': 0.9111111111111112, 'score': 0.9111111111111112, 'examples_seen': 82752, 'step': 3000, 'algorithm': 'activity_selector'}
I1130 22:15:42.873969 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.911, val scores are: activity_selector: 0.911
I1130 22:15:43.925020 130402719151616 run.py:734] Algo activity_selector step 3050 current loss 0.808697, current_train_items 84144.
I1130 22:15:44.057932 130402719151616 run.py:769] (val) algo activity_selector step 3050: {'selected': 0.9308176100628932, 'score': 0.9308176100628932, 'examples_seen': 84144, 'step': 3050, 'algorithm': 'activity_selector'}
I1130 22:15:44.058156 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1130 22:15:45.109655 130402719151616 run.py:734] Algo activity_selector step 3100 current loss 0.784043, current_train_items 85520.
I1130 22:15:45.240834 130402719151616 run.py:769] (val) algo activity_selector step 3100: {'selected': 0.9492187500000001, 'score': 0.9492187500000001, 'examples_seen': 85520, 'step': 3100, 'algorithm': 'activity_selector'}
I1130 22:15:45.240990 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.949, val scores are: activity_selector: 0.949
I1130 22:15:46.299684 130402719151616 run.py:734] Algo activity_selector step 3150 current loss 0.649263, current_train_items 86896.
I1130 22:15:46.432818 130402719151616 run.py:769] (val) algo activity_selector step 3150: {'selected': 0.9418386491557222, 'score': 0.9418386491557222, 'examples_seen': 86896, 'step': 3150, 'algorithm': 'activity_selector'}
I1130 22:15:46.432973 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1130 22:15:47.473976 130402719151616 run.py:734] Algo activity_selector step 3200 current loss 0.887488, current_train_items 88272.
I1130 22:15:47.604303 130402719151616 run.py:769] (val) algo activity_selector step 3200: {'selected': 0.9375, 'score': 0.9375, 'examples_seen': 88272, 'step': 3200, 'algorithm': 'activity_selector'}
I1130 22:15:47.604448 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.938, val scores are: activity_selector: 0.938
I1130 22:15:48.646028 130402719151616 run.py:734] Algo activity_selector step 3250 current loss 0.916529, current_train_items 89664.
I1130 22:15:48.775691 130402719151616 run.py:769] (val) algo activity_selector step 3250: {'selected': 0.953307392996109, 'score': 0.953307392996109, 'examples_seen': 89664, 'step': 3250, 'algorithm': 'activity_selector'}
I1130 22:15:48.775842 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1130 22:15:49.826602 130402719151616 run.py:734] Algo activity_selector step 3300 current loss 1.013628, current_train_items 91040.
I1130 22:15:49.957391 130402719151616 run.py:769] (val) algo activity_selector step 3300: {'selected': 0.9463220675944335, 'score': 0.9463220675944335, 'examples_seen': 91040, 'step': 3300, 'algorithm': 'activity_selector'}
I1130 22:15:49.957614 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.946, val scores are: activity_selector: 0.946
I1130 22:15:51.005084 130402719151616 run.py:734] Algo activity_selector step 3350 current loss 0.792430, current_train_items 92400.
I1130 22:15:51.140279 130402719151616 run.py:769] (val) algo activity_selector step 3350: {'selected': 0.9618320610687023, 'score': 0.9618320610687023, 'examples_seen': 92400, 'step': 3350, 'algorithm': 'activity_selector'}
I1130 22:15:51.140528 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.962, val scores are: activity_selector: 0.962
I1130 22:15:52.197255 130402719151616 run.py:734] Algo activity_selector step 3400 current loss 1.071137, current_train_items 93792.
I1130 22:15:52.330477 130402719151616 run.py:769] (val) algo activity_selector step 3400: {'selected': 0.9571694599627562, 'score': 0.9571694599627562, 'examples_seen': 93792, 'step': 3400, 'algorithm': 'activity_selector'}
I1130 22:15:52.330701 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.957, val scores are: activity_selector: 0.957
I1130 22:15:53.378126 130402719151616 run.py:734] Algo activity_selector step 3450 current loss 0.723304, current_train_items 95168.
I1130 22:15:53.525121 130402719151616 run.py:769] (val) algo activity_selector step 3450: {'selected': 0.9411764705882354, 'score': 0.9411764705882354, 'examples_seen': 95168, 'step': 3450, 'algorithm': 'activity_selector'}
I1130 22:15:53.525343 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.941, val scores are: activity_selector: 0.941
I1130 22:15:54.561439 130402719151616 run.py:734] Algo activity_selector step 3500 current loss 0.848916, current_train_items 96544.
I1130 22:15:54.709481 130402719151616 run.py:769] (val) algo activity_selector step 3500: {'selected': 0.9335863377609108, 'score': 0.9335863377609108, 'examples_seen': 96544, 'step': 3500, 'algorithm': 'activity_selector'}
I1130 22:15:54.709701 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.934, val scores are: activity_selector: 0.934
I1130 22:15:55.746123 130402719151616 run.py:734] Algo activity_selector step 3550 current loss 0.948994, current_train_items 97936.
I1130 22:15:55.891967 130402719151616 run.py:769] (val) algo activity_selector step 3550: {'selected': 0.9359223300970875, 'score': 0.9359223300970875, 'examples_seen': 97936, 'step': 3550, 'algorithm': 'activity_selector'}
I1130 22:15:55.892188 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1130 22:15:56.957631 130402719151616 run.py:734] Algo activity_selector step 3600 current loss 1.133147, current_train_items 99312.
I1130 22:15:57.091715 130402719151616 run.py:769] (val) algo activity_selector step 3600: {'selected': 0.944558521560575, 'score': 0.944558521560575, 'examples_seen': 99312, 'step': 3600, 'algorithm': 'activity_selector'}
I1130 22:15:57.091951 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.945, val scores are: activity_selector: 0.945
I1130 22:15:58.147590 130402719151616 run.py:734] Algo activity_selector step 3650 current loss 1.076532, current_train_items 100688.
I1130 22:15:58.279047 130402719151616 run.py:769] (val) algo activity_selector step 3650: {'selected': 0.9646182495344506, 'score': 0.9646182495344506, 'examples_seen': 100688, 'step': 3650, 'algorithm': 'activity_selector'}
I1130 22:15:58.279268 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.965, val scores are: activity_selector: 0.965
I1130 22:15:59.330083 130402719151616 run.py:734] Algo activity_selector step 3700 current loss 0.678902, current_train_items 102064.
I1130 22:15:59.463299 130402719151616 run.py:769] (val) algo activity_selector step 3700: {'selected': 0.937007874015748, 'score': 0.937007874015748, 'examples_seen': 102064, 'step': 3700, 'algorithm': 'activity_selector'}
I1130 22:15:59.463524 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.937, val scores are: activity_selector: 0.937
I1130 22:16:00.525879 130402719151616 run.py:734] Algo activity_selector step 3750 current loss 0.799233, current_train_items 103440.
I1130 22:16:00.657760 130402719151616 run.py:769] (val) algo activity_selector step 3750: {'selected': 0.9168207024029575, 'score': 0.9168207024029575, 'examples_seen': 103440, 'step': 3750, 'algorithm': 'activity_selector'}
I1130 22:16:00.658001 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.917, val scores are: activity_selector: 0.917
I1130 22:16:01.700624 130402719151616 run.py:734] Algo activity_selector step 3800 current loss 0.652211, current_train_items 104816.
I1130 22:16:01.843522 130402719151616 run.py:769] (val) algo activity_selector step 3800: {'selected': 0.9481765834932822, 'score': 0.9481765834932822, 'examples_seen': 104816, 'step': 3800, 'algorithm': 'activity_selector'}
I1130 22:16:01.843745 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1130 22:16:02.904217 130402719151616 run.py:734] Algo activity_selector step 3850 current loss 0.967296, current_train_items 106208.
I1130 22:16:03.029921 130402719151616 run.py:769] (val) algo activity_selector step 3850: {'selected': 0.93359375, 'score': 0.93359375, 'examples_seen': 106208, 'step': 3850, 'algorithm': 'activity_selector'}
I1130 22:16:03.030166 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.934, val scores are: activity_selector: 0.934
I1130 22:16:04.092231 130402719151616 run.py:734] Algo activity_selector step 3900 current loss 0.797242, current_train_items 107584.
I1130 22:16:04.221590 130402719151616 run.py:769] (val) algo activity_selector step 3900: {'selected': 0.9104204753199269, 'score': 0.9104204753199269, 'examples_seen': 107584, 'step': 3900, 'algorithm': 'activity_selector'}
I1130 22:16:04.221839 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.910, val scores are: activity_selector: 0.910
I1130 22:16:05.258049 130402719151616 run.py:734] Algo activity_selector step 3950 current loss 0.925910, current_train_items 108960.
I1130 22:16:05.405197 130402719151616 run.py:769] (val) algo activity_selector step 3950: {'selected': 0.9514925373134329, 'score': 0.9514925373134329, 'examples_seen': 108960, 'step': 3950, 'algorithm': 'activity_selector'}
I1130 22:16:05.405442 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.951, val scores are: activity_selector: 0.951
I1130 22:16:06.447032 130402719151616 run.py:734] Algo activity_selector step 4000 current loss 0.911005, current_train_items 110336.
I1130 22:16:06.594648 130402719151616 run.py:769] (val) algo activity_selector step 4000: {'selected': 0.8809073724007561, 'score': 0.8809073724007561, 'examples_seen': 110336, 'step': 4000, 'algorithm': 'activity_selector'}
I1130 22:16:06.594902 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.881, val scores are: activity_selector: 0.881
I1130 22:16:07.655929 130402719151616 run.py:734] Algo activity_selector step 4050 current loss 0.866429, current_train_items 111712.
I1130 22:16:07.801403 130402719151616 run.py:769] (val) algo activity_selector step 4050: {'selected': 0.9481765834932822, 'score': 0.9481765834932822, 'examples_seen': 111712, 'step': 4050, 'algorithm': 'activity_selector'}
I1130 22:16:07.801659 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1130 22:16:08.852524 130402719151616 run.py:734] Algo activity_selector step 4100 current loss 0.633729, current_train_items 113088.
I1130 22:16:08.984587 130402719151616 run.py:769] (val) algo activity_selector step 4100: {'selected': 0.929889298892989, 'score': 0.929889298892989, 'examples_seen': 113088, 'step': 4100, 'algorithm': 'activity_selector'}
I1130 22:16:08.984825 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.930, val scores are: activity_selector: 0.930
I1130 22:16:10.036100 130402719151616 run.py:734] Algo activity_selector step 4150 current loss 0.696004, current_train_items 114480.
I1130 22:16:10.167382 130402719151616 run.py:769] (val) algo activity_selector step 4150: {'selected': 0.9557195571955719, 'score': 0.9557195571955719, 'examples_seen': 114480, 'step': 4150, 'algorithm': 'activity_selector'}
I1130 22:16:10.167603 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1130 22:16:11.218709 130402719151616 run.py:734] Algo activity_selector step 4200 current loss 1.101204, current_train_items 115856.
I1130 22:16:11.362130 130402719151616 run.py:769] (val) algo activity_selector step 4200: {'selected': 0.9288537549407114, 'score': 0.9288537549407114, 'examples_seen': 115856, 'step': 4200, 'algorithm': 'activity_selector'}
I1130 22:16:11.362354 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.929, val scores are: activity_selector: 0.929
I1130 22:16:12.406302 130402719151616 run.py:734] Algo activity_selector step 4250 current loss 0.881094, current_train_items 117216.
I1130 22:16:12.551029 130402719151616 run.py:769] (val) algo activity_selector step 4250: {'selected': 0.9363295880149812, 'score': 0.9363295880149812, 'examples_seen': 117216, 'step': 4250, 'algorithm': 'activity_selector'}
I1130 22:16:12.551247 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.965, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1130 22:16:13.588177 130402719151616 run.py:734] Algo activity_selector step 4300 current loss 1.014843, current_train_items 118624.
I1130 22:16:13.735772 130402719151616 run.py:769] (val) algo activity_selector step 4300: {'selected': 0.9853479853479853, 'score': 0.9853479853479853, 'examples_seen': 118624, 'step': 4300, 'algorithm': 'activity_selector'}
I1130 22:16:13.736010 130402719151616 run.py:790] Checkpointing best model, best avg val score was 0.965, current avg val score is 0.985, val scores are: activity_selector: 0.985
I1130 22:16:14.857222 130402719151616 run.py:734] Algo activity_selector step 4350 current loss 0.618668, current_train_items 119984.
I1130 22:16:14.989609 130402719151616 run.py:769] (val) algo activity_selector step 4350: {'selected': 0.9076923076923077, 'score': 0.9076923076923077, 'examples_seen': 119984, 'step': 4350, 'algorithm': 'activity_selector'}
I1130 22:16:14.989829 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.908, val scores are: activity_selector: 0.908
I1130 22:16:16.040805 130402719151616 run.py:734] Algo activity_selector step 4400 current loss 0.734354, current_train_items 121360.
I1130 22:16:16.174249 130402719151616 run.py:769] (val) algo activity_selector step 4400: {'selected': 0.9592592592592593, 'score': 0.9592592592592593, 'examples_seen': 121360, 'step': 4400, 'algorithm': 'activity_selector'}
I1130 22:16:16.174496 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.959, val scores are: activity_selector: 0.959
I1130 22:16:17.229160 130402719151616 run.py:734] Algo activity_selector step 4450 current loss 1.071960, current_train_items 122752.
I1130 22:16:17.362515 130402719151616 run.py:769] (val) algo activity_selector step 4450: {'selected': 0.9404990403071017, 'score': 0.9404990403071017, 'examples_seen': 122752, 'step': 4450, 'algorithm': 'activity_selector'}
I1130 22:16:17.362737 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.940, val scores are: activity_selector: 0.940
I1130 22:16:18.412623 130402719151616 run.py:734] Algo activity_selector step 4500 current loss 0.787801, current_train_items 124128.
I1130 22:16:18.559340 130402719151616 run.py:769] (val) algo activity_selector step 4500: {'selected': 0.9578544061302683, 'score': 0.9578544061302683, 'examples_seen': 124128, 'step': 4500, 'algorithm': 'activity_selector'}
I1130 22:16:18.559560 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.958, val scores are: activity_selector: 0.958
I1130 22:16:19.611253 130402719151616 run.py:734] Algo activity_selector step 4550 current loss 0.749969, current_train_items 125504.
I1130 22:16:19.744624 130402719151616 run.py:769] (val) algo activity_selector step 4550: {'selected': 0.9430894308943089, 'score': 0.9430894308943089, 'examples_seen': 125504, 'step': 4550, 'algorithm': 'activity_selector'}
I1130 22:16:19.744845 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1130 22:16:20.797569 130402719151616 run.py:734] Algo activity_selector step 4600 current loss 0.786102, current_train_items 126880.
I1130 22:16:20.928729 130402719151616 run.py:769] (val) algo activity_selector step 4600: {'selected': 0.9502982107355865, 'score': 0.9502982107355865, 'examples_seen': 126880, 'step': 4600, 'algorithm': 'activity_selector'}
I1130 22:16:20.928967 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1130 22:16:22.005935 130402719151616 run.py:734] Algo activity_selector step 4650 current loss 0.652948, current_train_items 128272.
I1130 22:16:22.123295 130402719151616 run.py:769] (val) algo activity_selector step 4650: {'selected': 0.9402985074626866, 'score': 0.9402985074626866, 'examples_seen': 128272, 'step': 4650, 'algorithm': 'activity_selector'}
I1130 22:16:22.123467 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.940, val scores are: activity_selector: 0.940
I1130 22:16:23.180113 130402719151616 run.py:734] Algo activity_selector step 4700 current loss 0.634172, current_train_items 129632.
I1130 22:16:23.314033 130402719151616 run.py:769] (val) algo activity_selector step 4700: {'selected': 0.9377289377289377, 'score': 0.9377289377289377, 'examples_seen': 129632, 'step': 4700, 'algorithm': 'activity_selector'}
I1130 22:16:23.314254 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.938, val scores are: activity_selector: 0.938
I1130 22:16:24.365641 130402719151616 run.py:734] Algo activity_selector step 4750 current loss 0.837350, current_train_items 131024.
I1130 22:16:24.499089 130402719151616 run.py:769] (val) algo activity_selector step 4750: {'selected': 0.96045197740113, 'score': 0.96045197740113, 'examples_seen': 131024, 'step': 4750, 'algorithm': 'activity_selector'}
I1130 22:16:24.499308 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.960, val scores are: activity_selector: 0.960
I1130 22:16:25.561131 130402719151616 run.py:734] Algo activity_selector step 4800 current loss 0.654217, current_train_items 132400.
I1130 22:16:25.693651 130402719151616 run.py:769] (val) algo activity_selector step 4800: {'selected': 0.9496124031007752, 'score': 0.9496124031007752, 'examples_seen': 132400, 'step': 4800, 'algorithm': 'activity_selector'}
I1130 22:16:25.693889 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1130 22:16:26.731511 130402719151616 run.py:734] Algo activity_selector step 4850 current loss 0.745699, current_train_items 133760.
I1130 22:16:26.878352 130402719151616 run.py:769] (val) algo activity_selector step 4850: {'selected': 0.9435336976320584, 'score': 0.9435336976320584, 'examples_seen': 133760, 'step': 4850, 'algorithm': 'activity_selector'}
I1130 22:16:26.878591 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.944, val scores are: activity_selector: 0.944
I1130 22:16:27.936084 130402719151616 run.py:734] Algo activity_selector step 4900 current loss 0.575112, current_train_items 135168.
I1130 22:16:28.069393 130402719151616 run.py:769] (val) algo activity_selector step 4900: {'selected': 0.9387755102040816, 'score': 0.9387755102040816, 'examples_seen': 135168, 'step': 4900, 'algorithm': 'activity_selector'}
I1130 22:16:28.069613 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.939, val scores are: activity_selector: 0.939
I1130 22:16:29.118414 130402719151616 run.py:734] Algo activity_selector step 4950 current loss 0.711468, current_train_items 136528.
I1130 22:16:29.264971 130402719151616 run.py:769] (val) algo activity_selector step 4950: {'selected': 0.9272030651340997, 'score': 0.9272030651340997, 'examples_seen': 136528, 'step': 4950, 'algorithm': 'activity_selector'}
I1130 22:16:29.265198 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.927, val scores are: activity_selector: 0.927
I1130 22:16:30.316570 130402719151616 run.py:734] Algo activity_selector step 5000 current loss 0.579461, current_train_items 137920.
I1130 22:16:30.448282 130402719151616 run.py:769] (val) algo activity_selector step 5000: {'selected': 0.9463955637707949, 'score': 0.9463955637707949, 'examples_seen': 137920, 'step': 5000, 'algorithm': 'activity_selector'}
I1130 22:16:30.448511 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.946, val scores are: activity_selector: 0.946
I1130 22:16:31.504584 130402719151616 run.py:734] Algo activity_selector step 5050 current loss 0.722947, current_train_items 139296.
I1130 22:16:31.636676 130402719151616 run.py:769] (val) algo activity_selector step 5050: {'selected': 0.9461077844311377, 'score': 0.9461077844311377, 'examples_seen': 139296, 'step': 5050, 'algorithm': 'activity_selector'}
I1130 22:16:31.636917 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.946, val scores are: activity_selector: 0.946
I1130 22:16:32.685141 130402719151616 run.py:734] Algo activity_selector step 5100 current loss 0.724882, current_train_items 140656.
I1130 22:16:32.835078 130402719151616 run.py:769] (val) algo activity_selector step 5100: {'selected': 0.9630996309963099, 'score': 0.9630996309963099, 'examples_seen': 140656, 'step': 5100, 'algorithm': 'activity_selector'}
I1130 22:16:32.835299 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.963, val scores are: activity_selector: 0.963
I1130 22:16:33.874911 130402719151616 run.py:734] Algo activity_selector step 5150 current loss 0.952296, current_train_items 142048.
I1130 22:16:34.021362 130402719151616 run.py:769] (val) algo activity_selector step 5150: {'selected': 0.9057377049180328, 'score': 0.9057377049180328, 'examples_seen': 142048, 'step': 5150, 'algorithm': 'activity_selector'}
I1130 22:16:34.021585 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.906, val scores are: activity_selector: 0.906
I1130 22:16:35.093167 130402719151616 run.py:734] Algo activity_selector step 5200 current loss 0.590917, current_train_items 143424.
I1130 22:16:35.205767 130402719151616 run.py:769] (val) algo activity_selector step 5200: {'selected': 0.9510763209393347, 'score': 0.9510763209393347, 'examples_seen': 143424, 'step': 5200, 'algorithm': 'activity_selector'}
I1130 22:16:35.206003 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.951, val scores are: activity_selector: 0.951
I1130 22:16:36.267419 130402719151616 run.py:734] Algo activity_selector step 5250 current loss 0.563658, current_train_items 144816.
I1130 22:16:36.401129 130402719151616 run.py:769] (val) algo activity_selector step 5250: {'selected': 0.9730769230769231, 'score': 0.9730769230769231, 'examples_seen': 144816, 'step': 5250, 'algorithm': 'activity_selector'}
I1130 22:16:36.401352 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.973, val scores are: activity_selector: 0.973
I1130 22:16:37.453057 130402719151616 run.py:734] Algo activity_selector step 5300 current loss 0.977094, current_train_items 146176.
I1130 22:16:37.586555 130402719151616 run.py:769] (val) algo activity_selector step 5300: {'selected': 0.9366602687140115, 'score': 0.9366602687140115, 'examples_seen': 146176, 'step': 5300, 'algorithm': 'activity_selector'}
I1130 22:16:37.586783 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.937, val scores are: activity_selector: 0.937
I1130 22:16:38.644072 130402719151616 run.py:734] Algo activity_selector step 5350 current loss 0.684133, current_train_items 147584.
I1130 22:16:38.777309 130402719151616 run.py:769] (val) algo activity_selector step 5350: {'selected': 0.9313543599257885, 'score': 0.9313543599257885, 'examples_seen': 147584, 'step': 5350, 'algorithm': 'activity_selector'}
I1130 22:16:38.777533 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1130 22:16:39.825759 130402719151616 run.py:734] Algo activity_selector step 5400 current loss 0.734395, current_train_items 148944.
I1130 22:16:39.971920 130402719151616 run.py:769] (val) algo activity_selector step 5400: {'selected': 0.952191235059761, 'score': 0.952191235059761, 'examples_seen': 148944, 'step': 5400, 'algorithm': 'activity_selector'}
I1130 22:16:39.972146 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.952, val scores are: activity_selector: 0.952
I1130 22:16:41.022277 130402719151616 run.py:734] Algo activity_selector step 5450 current loss 0.706533, current_train_items 150304.
I1130 22:16:41.156014 130402719151616 run.py:769] (val) algo activity_selector step 5450: {'selected': 0.9501915708812262, 'score': 0.9501915708812262, 'examples_seen': 150304, 'step': 5450, 'algorithm': 'activity_selector'}
I1130 22:16:41.156238 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1130 22:16:42.207331 130402719151616 run.py:734] Algo activity_selector step 5500 current loss 0.883153, current_train_items 151712.
I1130 22:16:42.340601 130402719151616 run.py:769] (val) algo activity_selector step 5500: {'selected': 0.9488188976377954, 'score': 0.9488188976377954, 'examples_seen': 151712, 'step': 5500, 'algorithm': 'activity_selector'}
I1130 22:16:42.340821 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.949, val scores are: activity_selector: 0.949
I1130 22:16:43.408141 130402719151616 run.py:734] Algo activity_selector step 5550 current loss 0.662604, current_train_items 153072.
I1130 22:16:43.543348 130402719151616 run.py:769] (val) algo activity_selector step 5550: {'selected': 0.9528985507246377, 'score': 0.9528985507246377, 'examples_seen': 153072, 'step': 5550, 'algorithm': 'activity_selector'}
I1130 22:16:43.543573 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1130 22:16:44.594703 130402719151616 run.py:734] Algo activity_selector step 5600 current loss 0.695886, current_train_items 154464.
I1130 22:16:44.727582 130402719151616 run.py:769] (val) algo activity_selector step 5600: {'selected': 0.9301310043668122, 'score': 0.9301310043668122, 'examples_seen': 154464, 'step': 5600, 'algorithm': 'activity_selector'}
I1130 22:16:44.727804 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.930, val scores are: activity_selector: 0.930
I1130 22:16:45.764957 130402719151616 run.py:734] Algo activity_selector step 5650 current loss 0.527586, current_train_items 155840.
I1130 22:16:45.912104 130402719151616 run.py:769] (val) algo activity_selector step 5650: {'selected': 0.9348230912476724, 'score': 0.9348230912476724, 'examples_seen': 155840, 'step': 5650, 'algorithm': 'activity_selector'}
I1130 22:16:45.912340 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.935, val scores are: activity_selector: 0.935
I1130 22:16:46.974674 130402719151616 run.py:734] Algo activity_selector step 5700 current loss 0.624173, current_train_items 157216.
I1130 22:16:47.107235 130402719151616 run.py:769] (val) algo activity_selector step 5700: {'selected': 0.9350649350649352, 'score': 0.9350649350649352, 'examples_seen': 157216, 'step': 5700, 'algorithm': 'activity_selector'}
I1130 22:16:47.107456 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.935, val scores are: activity_selector: 0.935
I1130 22:16:48.163505 130402719151616 run.py:734] Algo activity_selector step 5750 current loss 0.759601, current_train_items 158592.
I1130 22:16:48.300668 130402719151616 run.py:769] (val) algo activity_selector step 5750: {'selected': 0.948207171314741, 'score': 0.948207171314741, 'examples_seen': 158592, 'step': 5750, 'algorithm': 'activity_selector'}
I1130 22:16:48.300909 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1130 22:16:49.354155 130402719151616 run.py:734] Algo activity_selector step 5800 current loss 0.712298, current_train_items 159968.
I1130 22:16:49.486914 130402719151616 run.py:769] (val) algo activity_selector step 5800: {'selected': 0.9523809523809523, 'score': 0.9523809523809523, 'examples_seen': 159968, 'step': 5800, 'algorithm': 'activity_selector'}
I1130 22:16:49.487137 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.952, val scores are: activity_selector: 0.952
I1130 22:16:50.549305 130402719151616 run.py:734] Algo activity_selector step 5850 current loss 0.954059, current_train_items 161360.
I1130 22:16:50.682159 130402719151616 run.py:769] (val) algo activity_selector step 5850: {'selected': 0.9288537549407114, 'score': 0.9288537549407114, 'examples_seen': 161360, 'step': 5850, 'algorithm': 'activity_selector'}
I1130 22:16:50.682337 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.929, val scores are: activity_selector: 0.929
I1130 22:16:51.737240 130402719151616 run.py:734] Algo activity_selector step 5900 current loss 0.721924, current_train_items 162720.
I1130 22:16:51.858820 130402719151616 run.py:769] (val) algo activity_selector step 5900: {'selected': 0.9157088122605364, 'score': 0.9157088122605364, 'examples_seen': 162720, 'step': 5900, 'algorithm': 'activity_selector'}
I1130 22:16:51.859062 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.916, val scores are: activity_selector: 0.916
I1130 22:16:52.911618 130402719151616 run.py:734] Algo activity_selector step 5950 current loss 0.572460, current_train_items 164112.
I1130 22:16:53.042821 130402719151616 run.py:769] (val) algo activity_selector step 5950: {'selected': 0.921875, 'score': 0.921875, 'examples_seen': 164112, 'step': 5950, 'algorithm': 'activity_selector'}
I1130 22:16:53.043058 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.922, val scores are: activity_selector: 0.922
I1130 22:16:54.096793 130402719151616 run.py:734] Algo activity_selector step 6000 current loss 0.600648, current_train_items 165488.
I1130 22:16:54.243364 130402719151616 run.py:769] (val) algo activity_selector step 6000: {'selected': 0.9765765765765766, 'score': 0.9765765765765766, 'examples_seen': 165488, 'step': 6000, 'algorithm': 'activity_selector'}
I1130 22:16:54.243605 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.977, val scores are: activity_selector: 0.977
I1130 22:16:55.294888 130402719151616 run.py:734] Algo activity_selector step 6050 current loss 1.091011, current_train_items 166864.
I1130 22:16:55.426484 130402719151616 run.py:769] (val) algo activity_selector step 6050: {'selected': 0.9098039215686274, 'score': 0.9098039215686274, 'examples_seen': 166864, 'step': 6050, 'algorithm': 'activity_selector'}
I1130 22:16:55.426706 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.910, val scores are: activity_selector: 0.910
I1130 22:16:56.482745 130402719151616 run.py:734] Algo activity_selector step 6100 current loss 0.684362, current_train_items 168256.
I1130 22:16:56.616235 130402719151616 run.py:769] (val) algo activity_selector step 6100: {'selected': 0.9372549019607842, 'score': 0.9372549019607842, 'examples_seen': 168256, 'step': 6100, 'algorithm': 'activity_selector'}
I1130 22:16:56.616458 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.937, val scores are: activity_selector: 0.937
I1130 22:16:57.678421 130402719151616 run.py:734] Algo activity_selector step 6150 current loss 0.982059, current_train_items 169616.
I1130 22:16:57.810445 130402719151616 run.py:769] (val) algo activity_selector step 6150: {'selected': 0.9511677282377919, 'score': 0.9511677282377919, 'examples_seen': 169616, 'step': 6150, 'algorithm': 'activity_selector'}
I1130 22:16:57.810663 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.951, val scores are: activity_selector: 0.951
I1130 22:16:58.865798 130402719151616 run.py:734] Algo activity_selector step 6200 current loss 0.612271, current_train_items 171008.
I1130 22:16:59.001623 130402719151616 run.py:769] (val) algo activity_selector step 6200: {'selected': 0.9262295081967213, 'score': 0.9262295081967213, 'examples_seen': 171008, 'step': 6200, 'algorithm': 'activity_selector'}
I1130 22:16:59.001846 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.926, val scores are: activity_selector: 0.926
I1130 22:17:00.039449 130402719151616 run.py:734] Algo activity_selector step 6250 current loss 0.991713, current_train_items 172384.
I1130 22:17:00.186965 130402719151616 run.py:769] (val) algo activity_selector step 6250: {'selected': 0.9500000000000001, 'score': 0.9500000000000001, 'examples_seen': 172384, 'step': 6250, 'algorithm': 'activity_selector'}
I1130 22:17:00.187213 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1130 22:17:01.238256 130402719151616 run.py:734] Algo activity_selector step 6300 current loss 0.457974, current_train_items 173760.
I1130 22:17:01.382015 130402719151616 run.py:769] (val) algo activity_selector step 6300: {'selected': 0.9323308270676692, 'score': 0.9323308270676692, 'examples_seen': 173760, 'step': 6300, 'algorithm': 'activity_selector'}
I1130 22:17:01.382235 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.932, val scores are: activity_selector: 0.932
I1130 22:17:02.433399 130402719151616 run.py:734] Algo activity_selector step 6350 current loss 0.582828, current_train_items 175136.
I1130 22:17:02.567400 130402719151616 run.py:769] (val) algo activity_selector step 6350: {'selected': 0.9584158415841583, 'score': 0.9584158415841583, 'examples_seen': 175136, 'step': 6350, 'algorithm': 'activity_selector'}
I1130 22:17:02.567625 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.958, val scores are: activity_selector: 0.958
I1130 22:17:03.619059 130402719151616 run.py:734] Algo activity_selector step 6400 current loss 0.927215, current_train_items 176528.
I1130 22:17:03.752078 130402719151616 run.py:769] (val) algo activity_selector step 6400: {'selected': 0.9367588932806323, 'score': 0.9367588932806323, 'examples_seen': 176528, 'step': 6400, 'algorithm': 'activity_selector'}
I1130 22:17:03.752242 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.937, val scores are: activity_selector: 0.937
I1130 22:17:04.807349 130402719151616 run.py:734] Algo activity_selector step 6450 current loss 0.539073, current_train_items 177904.
I1130 22:17:04.937752 130402719151616 run.py:769] (val) algo activity_selector step 6450: {'selected': 0.927689594356261, 'score': 0.927689594356261, 'examples_seen': 177904, 'step': 6450, 'algorithm': 'activity_selector'}
I1130 22:17:04.937907 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.928, val scores are: activity_selector: 0.928
I1130 22:17:05.980098 130402719151616 run.py:734] Algo activity_selector step 6500 current loss 0.654325, current_train_items 179264.
I1130 22:17:06.108288 130402719151616 run.py:769] (val) algo activity_selector step 6500: {'selected': 0.9312714776632303, 'score': 0.9312714776632303, 'examples_seen': 179264, 'step': 6500, 'algorithm': 'activity_selector'}
I1130 22:17:06.108435 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1130 22:17:07.150290 130402719151616 run.py:734] Algo activity_selector step 6550 current loss 0.558272, current_train_items 180656.
I1130 22:17:07.281013 130402719151616 run.py:769] (val) algo activity_selector step 6550: {'selected': 0.9628252788104089, 'score': 0.9628252788104089, 'examples_seen': 180656, 'step': 6550, 'algorithm': 'activity_selector'}
I1130 22:17:07.281161 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.963, val scores are: activity_selector: 0.963
I1130 22:17:08.327969 130402719151616 run.py:734] Algo activity_selector step 6600 current loss 1.041229, current_train_items 182032.
I1130 22:17:08.459004 130402719151616 run.py:769] (val) algo activity_selector step 6600: {'selected': 0.9433962264150944, 'score': 0.9433962264150944, 'examples_seen': 182032, 'step': 6600, 'algorithm': 'activity_selector'}
I1130 22:17:08.459230 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1130 22:17:09.511598 130402719151616 run.py:734] Algo activity_selector step 6650 current loss 1.079732, current_train_items 183408.
I1130 22:17:09.642174 130402719151616 run.py:769] (val) algo activity_selector step 6650: {'selected': 0.919449901768173, 'score': 0.919449901768173, 'examples_seen': 183408, 'step': 6650, 'algorithm': 'activity_selector'}
I1130 22:17:09.642402 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.919, val scores are: activity_selector: 0.919
I1130 22:17:10.693594 130402719151616 run.py:734] Algo activity_selector step 6700 current loss 0.592340, current_train_items 184800.
I1130 22:17:10.826985 130402719151616 run.py:769] (val) algo activity_selector step 6700: {'selected': 0.942528735632184, 'score': 0.942528735632184, 'examples_seen': 184800, 'step': 6700, 'algorithm': 'activity_selector'}
I1130 22:17:10.827215 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1130 22:17:11.889554 130402719151616 run.py:734] Algo activity_selector step 6750 current loss 0.630279, current_train_items 186176.
I1130 22:17:12.021884 130402719151616 run.py:769] (val) algo activity_selector step 6750: {'selected': 0.9508196721311476, 'score': 0.9508196721311476, 'examples_seen': 186176, 'step': 6750, 'algorithm': 'activity_selector'}
I1130 22:17:12.022125 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.951, val scores are: activity_selector: 0.951
I1130 22:17:13.077753 130402719151616 run.py:734] Algo activity_selector step 6800 current loss 0.576372, current_train_items 187536.
I1130 22:17:13.207219 130402719151616 run.py:769] (val) algo activity_selector step 6800: {'selected': 0.9264705882352942, 'score': 0.9264705882352942, 'examples_seen': 187536, 'step': 6800, 'algorithm': 'activity_selector'}
I1130 22:17:13.207367 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.926, val scores are: activity_selector: 0.926
I1130 22:17:14.252599 130402719151616 run.py:734] Algo activity_selector step 6850 current loss 0.756904, current_train_items 188928.
I1130 22:17:14.386949 130402719151616 run.py:769] (val) algo activity_selector step 6850: {'selected': 0.9097345132743363, 'score': 0.9097345132743363, 'examples_seen': 188928, 'step': 6850, 'algorithm': 'activity_selector'}
I1130 22:17:14.387171 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.910, val scores are: activity_selector: 0.910
I1130 22:17:15.448954 130402719151616 run.py:734] Algo activity_selector step 6900 current loss 0.536176, current_train_items 190304.
I1130 22:17:15.584951 130402719151616 run.py:769] (val) algo activity_selector step 6900: {'selected': 0.9074074074074073, 'score': 0.9074074074074073, 'examples_seen': 190304, 'step': 6900, 'algorithm': 'activity_selector'}
I1130 22:17:15.585172 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.907, val scores are: activity_selector: 0.907
I1130 22:17:16.636658 130402719151616 run.py:734] Algo activity_selector step 6950 current loss 0.770996, current_train_items 191680.
I1130 22:17:16.769963 130402719151616 run.py:769] (val) algo activity_selector step 6950: {'selected': 0.9333333333333333, 'score': 0.9333333333333333, 'examples_seen': 191680, 'step': 6950, 'algorithm': 'activity_selector'}
I1130 22:17:16.770183 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.933, val scores are: activity_selector: 0.933
I1130 22:17:17.807304 130402719151616 run.py:734] Algo activity_selector step 7000 current loss 0.913041, current_train_items 193072.
I1130 22:17:17.953333 130402719151616 run.py:769] (val) algo activity_selector step 7000: {'selected': 0.9395161290322581, 'score': 0.9395161290322581, 'examples_seen': 193072, 'step': 7000, 'algorithm': 'activity_selector'}
I1130 22:17:17.953551 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.940, val scores are: activity_selector: 0.940
I1130 22:17:19.016296 130402719151616 run.py:734] Algo activity_selector step 7050 current loss 0.509304, current_train_items 194448.
I1130 22:17:19.149253 130402719151616 run.py:769] (val) algo activity_selector step 7050: {'selected': 0.930841121495327, 'score': 0.930841121495327, 'examples_seen': 194448, 'step': 7050, 'algorithm': 'activity_selector'}
I1130 22:17:19.149475 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1130 22:17:20.206110 130402719151616 run.py:734] Algo activity_selector step 7100 current loss 0.834686, current_train_items 195824.
I1130 22:17:20.340819 130402719151616 run.py:769] (val) algo activity_selector step 7100: {'selected': 0.9297912713472486, 'score': 0.9297912713472486, 'examples_seen': 195824, 'step': 7100, 'algorithm': 'activity_selector'}
I1130 22:17:20.341055 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.930, val scores are: activity_selector: 0.930
I1130 22:17:21.397135 130402719151616 run.py:734] Algo activity_selector step 7150 current loss 0.774483, current_train_items 197200.
I1130 22:17:21.530396 130402719151616 run.py:769] (val) algo activity_selector step 7150: {'selected': 0.9309090909090909, 'score': 0.9309090909090909, 'examples_seen': 197200, 'step': 7150, 'algorithm': 'activity_selector'}
I1130 22:17:21.530621 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1130 22:17:22.608533 130402719151616 run.py:734] Algo activity_selector step 7200 current loss 0.903965, current_train_items 198576.
I1130 22:17:22.726335 130402719151616 run.py:769] (val) algo activity_selector step 7200: {'selected': 0.9452332657200812, 'score': 0.9452332657200812, 'examples_seen': 198576, 'step': 7200, 'algorithm': 'activity_selector'}
I1130 22:17:22.726557 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.945, val scores are: activity_selector: 0.945
I1130 22:17:23.778202 130402719151616 run.py:734] Algo activity_selector step 7250 current loss 0.783678, current_train_items 199952.
I1130 22:17:23.910586 130402719151616 run.py:769] (val) algo activity_selector step 7250: {'selected': 0.9653846153846153, 'score': 0.9653846153846153, 'examples_seen': 199952, 'step': 7250, 'algorithm': 'activity_selector'}
I1130 22:17:23.910806 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.965, val scores are: activity_selector: 0.965
I1130 22:17:24.967889 130402719151616 run.py:734] Algo activity_selector step 7300 current loss 0.646467, current_train_items 201344.
I1130 22:17:25.100425 130402719151616 run.py:769] (val) algo activity_selector step 7300: {'selected': 0.952561669829222, 'score': 0.952561669829222, 'examples_seen': 201344, 'step': 7300, 'algorithm': 'activity_selector'}
I1130 22:17:25.100651 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1130 22:17:26.149530 130402719151616 run.py:734] Algo activity_selector step 7350 current loss 0.713097, current_train_items 202720.
I1130 22:17:26.279762 130402719151616 run.py:769] (val) algo activity_selector step 7350: {'selected': 0.9395711500974661, 'score': 0.9395711500974661, 'examples_seen': 202720, 'step': 7350, 'algorithm': 'activity_selector'}
I1130 22:17:26.279997 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.940, val scores are: activity_selector: 0.940
I1130 22:17:27.331777 130402719151616 run.py:734] Algo activity_selector step 7400 current loss 0.777937, current_train_items 204080.
I1130 22:17:27.464430 130402719151616 run.py:769] (val) algo activity_selector step 7400: {'selected': 0.9318181818181818, 'score': 0.9318181818181818, 'examples_seen': 204080, 'step': 7400, 'algorithm': 'activity_selector'}
I1130 22:17:27.464652 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.932, val scores are: activity_selector: 0.932
I1130 22:17:28.515218 130402719151616 run.py:734] Algo activity_selector step 7450 current loss 0.657481, current_train_items 205488.
I1130 22:17:28.647924 130402719151616 run.py:769] (val) algo activity_selector step 7450: {'selected': 0.9200710479573713, 'score': 0.9200710479573713, 'examples_seen': 205488, 'step': 7450, 'algorithm': 'activity_selector'}
I1130 22:17:28.648113 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.920, val scores are: activity_selector: 0.920
I1130 22:17:29.687005 130402719151616 run.py:734] Algo activity_selector step 7500 current loss 0.501165, current_train_items 206848.
I1130 22:17:29.830455 130402719151616 run.py:769] (val) algo activity_selector step 7500: {'selected': 0.9661654135338346, 'score': 0.9661654135338346, 'examples_seen': 206848, 'step': 7500, 'algorithm': 'activity_selector'}
I1130 22:17:29.830601 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.966, val scores are: activity_selector: 0.966
I1130 22:17:30.858872 130402719151616 run.py:734] Algo activity_selector step 7550 current loss 0.536373, current_train_items 208224.
I1130 22:17:31.002455 130402719151616 run.py:769] (val) algo activity_selector step 7550: {'selected': 0.9529411764705882, 'score': 0.9529411764705882, 'examples_seen': 208224, 'step': 7550, 'algorithm': 'activity_selector'}
I1130 22:17:31.002601 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1130 22:17:32.044141 130402719151616 run.py:734] Algo activity_selector step 7600 current loss 0.837757, current_train_items 209616.
I1130 22:17:32.174631 130402719151616 run.py:769] (val) algo activity_selector step 7600: {'selected': 0.9709864603481624, 'score': 0.9709864603481624, 'examples_seen': 209616, 'step': 7600, 'algorithm': 'activity_selector'}
I1130 22:17:32.174777 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.971, val scores are: activity_selector: 0.971
I1130 22:17:33.220816 130402719151616 run.py:734] Algo activity_selector step 7650 current loss 0.731615, current_train_items 210976.
I1130 22:17:33.351392 130402719151616 run.py:769] (val) algo activity_selector step 7650: {'selected': 0.8925318761384335, 'score': 0.8925318761384335, 'examples_seen': 210976, 'step': 7650, 'algorithm': 'activity_selector'}
I1130 22:17:33.351544 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.893, val scores are: activity_selector: 0.893
I1130 22:17:34.392328 130402719151616 run.py:734] Algo activity_selector step 7700 current loss 0.795593, current_train_items 212368.
I1130 22:17:34.525141 130402719151616 run.py:769] (val) algo activity_selector step 7700: {'selected': 0.9620758483033931, 'score': 0.9620758483033931, 'examples_seen': 212368, 'step': 7700, 'algorithm': 'activity_selector'}
I1130 22:17:34.525338 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.962, val scores are: activity_selector: 0.962
I1130 22:17:35.575033 130402719151616 run.py:734] Algo activity_selector step 7750 current loss 0.524086, current_train_items 213744.
I1130 22:17:35.707299 130402719151616 run.py:769] (val) algo activity_selector step 7750: {'selected': 0.9418386491557224, 'score': 0.9418386491557224, 'examples_seen': 213744, 'step': 7750, 'algorithm': 'activity_selector'}
I1130 22:17:35.707519 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1130 22:17:36.755663 130402719151616 run.py:734] Algo activity_selector step 7800 current loss 0.719154, current_train_items 215136.
I1130 22:17:36.902699 130402719151616 run.py:769] (val) algo activity_selector step 7800: {'selected': 0.9272030651340996, 'score': 0.9272030651340996, 'examples_seen': 215136, 'step': 7800, 'algorithm': 'activity_selector'}
I1130 22:17:36.902934 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.927, val scores are: activity_selector: 0.927
I1130 22:17:37.958326 130402719151616 run.py:734] Algo activity_selector step 7850 current loss 0.517673, current_train_items 216496.
I1130 22:17:38.089892 130402719151616 run.py:769] (val) algo activity_selector step 7850: {'selected': 0.9521988527724666, 'score': 0.9521988527724666, 'examples_seen': 216496, 'step': 7850, 'algorithm': 'activity_selector'}
I1130 22:17:38.090038 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.952, val scores are: activity_selector: 0.952
I1130 22:17:39.132905 130402719151616 run.py:734] Algo activity_selector step 7900 current loss 0.581278, current_train_items 217888.
I1130 22:17:39.264476 130402719151616 run.py:769] (val) algo activity_selector step 7900: {'selected': 0.9720670391061451, 'score': 0.9720670391061451, 'examples_seen': 217888, 'step': 7900, 'algorithm': 'activity_selector'}
I1130 22:17:39.264714 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.972, val scores are: activity_selector: 0.972
I1130 22:17:40.333846 130402719151616 run.py:734] Algo activity_selector step 7950 current loss 0.655143, current_train_items 219264.
I1130 22:17:40.464184 130402719151616 run.py:769] (val) algo activity_selector step 7950: {'selected': 0.9776119402985074, 'score': 0.9776119402985074, 'examples_seen': 219264, 'step': 7950, 'algorithm': 'activity_selector'}
I1130 22:17:40.464406 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.978, val scores are: activity_selector: 0.978
I1130 22:17:41.515633 130402719151616 run.py:734] Algo activity_selector step 8000 current loss 0.698869, current_train_items 220624.
I1130 22:17:41.649941 130402719151616 run.py:769] (val) algo activity_selector step 8000: {'selected': 0.9363295880149812, 'score': 0.9363295880149812, 'examples_seen': 220624, 'step': 8000, 'algorithm': 'activity_selector'}
I1130 22:17:41.650164 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.985, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1130 22:17:42.691604 130402719151616 run.py:734] Algo activity_selector step 8050 current loss 0.654340, current_train_items 222032.
I1130 22:17:42.837810 130402719151616 run.py:769] (val) algo activity_selector step 8050: {'selected': 0.9625468164794008, 'score': 0.9625468164794008, 'examples_seen': 222032, 'step': 8050, 'algorithm': 'activity_selector'}
I1130 22:17:42.838042 130402719151616 run.py:790] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.963, val scores are: activity_selector: 0.963
I1130 22:17:43.959683 130402719151616 run.py:734] Algo activity_selector step 8100 current loss 0.785298, current_train_items 223392.
I1130 22:17:44.093791 130402719151616 run.py:769] (val) algo activity_selector step 8100: {'selected': 0.9516441005802707, 'score': 0.9516441005802707, 'examples_seen': 223392, 'step': 8100, 'algorithm': 'activity_selector'}
I1130 22:17:44.094024 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.963, current avg val score is 0.952, val scores are: activity_selector: 0.952
I1130 22:17:45.131763 130402719151616 run.py:734] Algo activity_selector step 8150 current loss 0.648186, current_train_items 224784.
I1130 22:17:45.283374 130402719151616 run.py:769] (val) algo activity_selector step 8150: {'selected': 0.9632495164410058, 'score': 0.9632495164410058, 'examples_seen': 224784, 'step': 8150, 'algorithm': 'activity_selector'}
I1130 22:17:45.283603 130402719151616 run.py:790] Checkpointing best model, best avg val score was 0.963, current avg val score is 0.963, val scores are: activity_selector: 0.963
I1130 22:17:46.397468 130402719151616 run.py:734] Algo activity_selector step 8200 current loss 0.610319, current_train_items 226160.
I1130 22:17:46.529595 130402719151616 run.py:769] (val) algo activity_selector step 8200: {'selected': 0.9659090909090909, 'score': 0.9659090909090909, 'examples_seen': 226160, 'step': 8200, 'algorithm': 'activity_selector'}
I1130 22:17:46.529817 130402719151616 run.py:790] Checkpointing best model, best avg val score was 0.963, current avg val score is 0.966, val scores are: activity_selector: 0.966
I1130 22:17:47.634898 130402719151616 run.py:734] Algo activity_selector step 8250 current loss 0.616112, current_train_items 227520.
I1130 22:17:47.781341 130402719151616 run.py:769] (val) algo activity_selector step 8250: {'selected': 0.9251968503937008, 'score': 0.9251968503937008, 'examples_seen': 227520, 'step': 8250, 'algorithm': 'activity_selector'}
I1130 22:17:47.781568 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.966, current avg val score is 0.925, val scores are: activity_selector: 0.925
I1130 22:17:48.818819 130402719151616 run.py:734] Algo activity_selector step 8300 current loss 0.659491, current_train_items 228912.
I1130 22:17:48.965484 130402719151616 run.py:769] (val) algo activity_selector step 8300: {'selected': 0.9520153550863724, 'score': 0.9520153550863724, 'examples_seen': 228912, 'step': 8300, 'algorithm': 'activity_selector'}
I1130 22:17:48.965710 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.966, current avg val score is 0.952, val scores are: activity_selector: 0.952
I1130 22:17:50.016351 130402719151616 run.py:734] Algo activity_selector step 8350 current loss 0.568032, current_train_items 230288.
I1130 22:17:50.147622 130402719151616 run.py:769] (val) algo activity_selector step 8350: {'selected': 0.9513108614232211, 'score': 0.9513108614232211, 'examples_seen': 230288, 'step': 8350, 'algorithm': 'activity_selector'}
I1130 22:17:50.147870 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.966, current avg val score is 0.951, val scores are: activity_selector: 0.951
I1130 22:17:51.216031 130402719151616 run.py:734] Algo activity_selector step 8400 current loss 0.529648, current_train_items 231680.
I1130 22:17:51.347514 130402719151616 run.py:769] (val) algo activity_selector step 8400: {'selected': 0.9436090225563909, 'score': 0.9436090225563909, 'examples_seen': 231680, 'step': 8400, 'algorithm': 'activity_selector'}
I1130 22:17:51.347737 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.966, current avg val score is 0.944, val scores are: activity_selector: 0.944
I1130 22:17:52.397962 130402719151616 run.py:734] Algo activity_selector step 8450 current loss 0.598052, current_train_items 233040.
I1130 22:17:52.530287 130402719151616 run.py:769] (val) algo activity_selector step 8450: {'selected': 0.9375, 'score': 0.9375, 'examples_seen': 233040, 'step': 8450, 'algorithm': 'activity_selector'}
I1130 22:17:52.530508 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.966, current avg val score is 0.938, val scores are: activity_selector: 0.938
I1130 22:17:53.580071 130402719151616 run.py:734] Algo activity_selector step 8500 current loss 0.533681, current_train_items 234432.
I1130 22:17:53.712796 130402719151616 run.py:769] (val) algo activity_selector step 8500: {'selected': 0.953095684803002, 'score': 0.953095684803002, 'examples_seen': 234432, 'step': 8500, 'algorithm': 'activity_selector'}
I1130 22:17:53.713035 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.966, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1130 22:17:54.759411 130402719151616 run.py:734] Algo activity_selector step 8550 current loss 0.465477, current_train_items 235808.
I1130 22:17:54.907678 130402719151616 run.py:769] (val) algo activity_selector step 8550: {'selected': 0.9461538461538462, 'score': 0.9461538461538462, 'examples_seen': 235808, 'step': 8550, 'algorithm': 'activity_selector'}
I1130 22:17:54.907913 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.966, current avg val score is 0.946, val scores are: activity_selector: 0.946
I1130 22:17:55.969852 130402719151616 run.py:734] Algo activity_selector step 8600 current loss 0.550843, current_train_items 237168.
I1130 22:17:56.112831 130402719151616 run.py:769] (val) algo activity_selector step 8600: {'selected': 0.943089430894309, 'score': 0.943089430894309, 'examples_seen': 237168, 'step': 8600, 'algorithm': 'activity_selector'}
I1130 22:17:56.113070 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.966, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1130 22:17:57.152208 130402719151616 run.py:734] Algo activity_selector step 8650 current loss 0.530723, current_train_items 238576.
I1130 22:17:57.297316 130402719151616 run.py:769] (val) algo activity_selector step 8650: {'selected': 0.9133858267716536, 'score': 0.9133858267716536, 'examples_seen': 238576, 'step': 8650, 'algorithm': 'activity_selector'}
I1130 22:17:57.297556 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.966, current avg val score is 0.913, val scores are: activity_selector: 0.913
I1130 22:17:58.361766 130402719151616 run.py:734] Algo activity_selector step 8700 current loss 0.557703, current_train_items 239936.
I1130 22:17:58.494626 130402719151616 run.py:769] (val) algo activity_selector step 8700: {'selected': 0.9735849056603774, 'score': 0.9735849056603774, 'examples_seen': 239936, 'step': 8700, 'algorithm': 'activity_selector'}
I1130 22:17:58.494890 130402719151616 run.py:790] Checkpointing best model, best avg val score was 0.966, current avg val score is 0.974, val scores are: activity_selector: 0.974
I1130 22:17:59.613863 130402719151616 run.py:734] Algo activity_selector step 8750 current loss 0.631419, current_train_items 241328.
I1130 22:17:59.746734 130402719151616 run.py:769] (val) algo activity_selector step 8750: {'selected': 0.9700374531835205, 'score': 0.9700374531835205, 'examples_seen': 241328, 'step': 8750, 'algorithm': 'activity_selector'}
I1130 22:17:59.746978 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.970, val scores are: activity_selector: 0.970
I1130 22:18:00.795040 130402719151616 run.py:734] Algo activity_selector step 8800 current loss 0.505245, current_train_items 242704.
I1130 22:18:00.941154 130402719151616 run.py:769] (val) algo activity_selector step 8800: {'selected': 0.9593810444874276, 'score': 0.9593810444874276, 'examples_seen': 242704, 'step': 8800, 'algorithm': 'activity_selector'}
I1130 22:18:00.941378 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.959, val scores are: activity_selector: 0.959
I1130 22:18:02.012604 130402719151616 run.py:734] Algo activity_selector step 8850 current loss 0.640523, current_train_items 244080.
I1130 22:18:02.144798 130402719151616 run.py:769] (val) algo activity_selector step 8850: {'selected': 0.942084942084942, 'score': 0.942084942084942, 'examples_seen': 244080, 'step': 8850, 'algorithm': 'activity_selector'}
I1130 22:18:02.144960 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1130 22:18:03.181081 130402719151616 run.py:734] Algo activity_selector step 8900 current loss 0.530910, current_train_items 245456.
I1130 22:18:03.324833 130402719151616 run.py:769] (val) algo activity_selector step 8900: {'selected': 0.8859813084112149, 'score': 0.8859813084112149, 'examples_seen': 245456, 'step': 8900, 'algorithm': 'activity_selector'}
I1130 22:18:03.324986 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.886, val scores are: activity_selector: 0.886
I1130 22:18:04.373756 130402719151616 run.py:734] Algo activity_selector step 8950 current loss 0.680567, current_train_items 246832.
I1130 22:18:04.504578 130402719151616 run.py:769] (val) algo activity_selector step 8950: {'selected': 0.8901303538175047, 'score': 0.8901303538175047, 'examples_seen': 246832, 'step': 8950, 'algorithm': 'activity_selector'}
I1130 22:18:04.504724 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.890, val scores are: activity_selector: 0.890
I1130 22:18:05.560704 130402719151616 run.py:734] Algo activity_selector step 9000 current loss 1.336716, current_train_items 248224.
I1130 22:18:05.689747 130402719151616 run.py:769] (val) algo activity_selector step 9000: {'selected': 0.9727626459143969, 'score': 0.9727626459143969, 'examples_seen': 248224, 'step': 9000, 'algorithm': 'activity_selector'}
I1130 22:18:05.689904 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.973, val scores are: activity_selector: 0.973
I1130 22:18:06.739338 130402719151616 run.py:734] Algo activity_selector step 9050 current loss 0.751662, current_train_items 249584.
I1130 22:18:06.871163 130402719151616 run.py:769] (val) algo activity_selector step 9050: {'selected': 0.9674952198852772, 'score': 0.9674952198852772, 'examples_seen': 249584, 'step': 9050, 'algorithm': 'activity_selector'}
I1130 22:18:06.871323 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.967, val scores are: activity_selector: 0.967
I1130 22:18:07.914303 130402719151616 run.py:734] Algo activity_selector step 9100 current loss 0.847986, current_train_items 250976.
I1130 22:18:08.045630 130402719151616 run.py:769] (val) algo activity_selector step 9100: {'selected': 0.9657794676806084, 'score': 0.9657794676806084, 'examples_seen': 250976, 'step': 9100, 'algorithm': 'activity_selector'}
I1130 22:18:08.045870 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.966, val scores are: activity_selector: 0.966
I1130 22:18:09.137511 130402719151616 run.py:734] Algo activity_selector step 9150 current loss 0.499626, current_train_items 252352.
I1130 22:18:09.252107 130402719151616 run.py:769] (val) algo activity_selector step 9150: {'selected': 0.9345794392523363, 'score': 0.9345794392523363, 'examples_seen': 252352, 'step': 9150, 'algorithm': 'activity_selector'}
I1130 22:18:09.252264 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.935, val scores are: activity_selector: 0.935
I1130 22:18:10.299421 130402719151616 run.py:734] Algo activity_selector step 9200 current loss 0.611790, current_train_items 253728.
I1130 22:18:10.432942 130402719151616 run.py:769] (val) algo activity_selector step 9200: {'selected': 0.9584905660377359, 'score': 0.9584905660377359, 'examples_seen': 253728, 'step': 9200, 'algorithm': 'activity_selector'}
I1130 22:18:10.433165 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.958, val scores are: activity_selector: 0.958
I1130 22:18:11.509067 130402719151616 run.py:734] Algo activity_selector step 9250 current loss 0.551792, current_train_items 255120.
I1130 22:18:11.634388 130402719151616 run.py:769] (val) algo activity_selector step 9250: {'selected': 0.9496124031007752, 'score': 0.9496124031007752, 'examples_seen': 255120, 'step': 9250, 'algorithm': 'activity_selector'}
I1130 22:18:11.634611 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1130 22:18:12.714422 130402719151616 run.py:734] Algo activity_selector step 9300 current loss 0.825237, current_train_items 256480.
I1130 22:18:12.846208 130402719151616 run.py:769] (val) algo activity_selector step 9300: {'selected': 0.9390018484288355, 'score': 0.9390018484288355, 'examples_seen': 256480, 'step': 9300, 'algorithm': 'activity_selector'}
I1130 22:18:12.846437 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.939, val scores are: activity_selector: 0.939
I1130 22:18:13.913546 130402719151616 run.py:734] Algo activity_selector step 9350 current loss 0.633789, current_train_items 257856.
I1130 22:18:14.045258 130402719151616 run.py:769] (val) algo activity_selector step 9350: {'selected': 0.9592592592592593, 'score': 0.9592592592592593, 'examples_seen': 257856, 'step': 9350, 'algorithm': 'activity_selector'}
I1130 22:18:14.045480 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.959, val scores are: activity_selector: 0.959
I1130 22:18:15.112777 130402719151616 run.py:734] Algo activity_selector step 9400 current loss 0.491593, current_train_items 259248.
I1130 22:18:15.244465 130402719151616 run.py:769] (val) algo activity_selector step 9400: {'selected': 0.9222222222222222, 'score': 0.9222222222222222, 'examples_seen': 259248, 'step': 9400, 'algorithm': 'activity_selector'}
I1130 22:18:15.244614 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.922, val scores are: activity_selector: 0.922
I1130 22:18:16.293764 130402719151616 run.py:734] Algo activity_selector step 9450 current loss 0.552143, current_train_items 260624.
I1130 22:18:16.434618 130402719151616 run.py:769] (val) algo activity_selector step 9450: {'selected': 0.9246435845213848, 'score': 0.9246435845213848, 'examples_seen': 260624, 'step': 9450, 'algorithm': 'activity_selector'}
I1130 22:18:16.434813 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.925, val scores are: activity_selector: 0.925
I1130 22:18:17.488929 130402719151616 run.py:734] Algo activity_selector step 9500 current loss 0.606202, current_train_items 262000.
I1130 22:18:17.620002 130402719151616 run.py:769] (val) algo activity_selector step 9500: {'selected': 0.9307692307692308, 'score': 0.9307692307692308, 'examples_seen': 262000, 'step': 9500, 'algorithm': 'activity_selector'}
I1130 22:18:17.620153 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1130 22:18:18.660283 130402719151616 run.py:734] Algo activity_selector step 9550 current loss 0.475122, current_train_items 263392.
I1130 22:18:18.807363 130402719151616 run.py:769] (val) algo activity_selector step 9550: {'selected': 0.9608247422680413, 'score': 0.9608247422680413, 'examples_seen': 263392, 'step': 9550, 'algorithm': 'activity_selector'}
I1130 22:18:18.807588 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.961, val scores are: activity_selector: 0.961
I1130 22:18:19.879703 130402719151616 run.py:734] Algo activity_selector step 9600 current loss 0.862948, current_train_items 264768.
I1130 22:18:20.011136 130402719151616 run.py:769] (val) algo activity_selector step 9600: {'selected': 0.9540918163672655, 'score': 0.9540918163672655, 'examples_seen': 264768, 'step': 9600, 'algorithm': 'activity_selector'}
I1130 22:18:20.011358 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.954, val scores are: activity_selector: 0.954
I1130 22:18:21.071779 130402719151616 run.py:734] Algo activity_selector step 9650 current loss 0.635933, current_train_items 266128.
I1130 22:18:21.203881 130402719151616 run.py:769] (val) algo activity_selector step 9650: {'selected': 0.9380863039399625, 'score': 0.9380863039399625, 'examples_seen': 266128, 'step': 9650, 'algorithm': 'activity_selector'}
I1130 22:18:21.204102 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.938, val scores are: activity_selector: 0.938
I1130 22:18:22.265164 130402719151616 run.py:734] Algo activity_selector step 9700 current loss 0.669935, current_train_items 267520.
I1130 22:18:22.398185 130402719151616 run.py:769] (val) algo activity_selector step 9700: {'selected': 0.9633911368015415, 'score': 0.9633911368015415, 'examples_seen': 267520, 'step': 9700, 'algorithm': 'activity_selector'}
I1130 22:18:22.398407 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.963, val scores are: activity_selector: 0.963
I1130 22:18:23.470478 130402719151616 run.py:734] Algo activity_selector step 9750 current loss 0.636557, current_train_items 268896.
I1130 22:18:23.600847 130402719151616 run.py:769] (val) algo activity_selector step 9750: {'selected': 0.9421157684630739, 'score': 0.9421157684630739, 'examples_seen': 268896, 'step': 9750, 'algorithm': 'activity_selector'}
I1130 22:18:23.601085 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1130 22:18:24.662082 130402719151616 run.py:734] Algo activity_selector step 9800 current loss 0.847924, current_train_items 270272.
I1130 22:18:24.792281 130402719151616 run.py:769] (val) algo activity_selector step 9800: {'selected': 0.9657947686116699, 'score': 0.9657947686116699, 'examples_seen': 270272, 'step': 9800, 'algorithm': 'activity_selector'}
I1130 22:18:24.792519 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.966, val scores are: activity_selector: 0.966
I1130 22:18:25.853511 130402719151616 run.py:734] Algo activity_selector step 9850 current loss 0.483990, current_train_items 271664.
I1130 22:18:25.987049 130402719151616 run.py:769] (val) algo activity_selector step 9850: {'selected': 0.9681050656660414, 'score': 0.9681050656660414, 'examples_seen': 271664, 'step': 9850, 'algorithm': 'activity_selector'}
I1130 22:18:25.987281 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.968, val scores are: activity_selector: 0.968
I1130 22:18:27.057632 130402719151616 run.py:734] Algo activity_selector step 9900 current loss 0.445947, current_train_items 273040.
I1130 22:18:27.189764 130402719151616 run.py:769] (val) algo activity_selector step 9900: {'selected': 0.9548133595284873, 'score': 0.9548133595284873, 'examples_seen': 273040, 'step': 9900, 'algorithm': 'activity_selector'}
I1130 22:18:27.190002 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.955, val scores are: activity_selector: 0.955
I1130 22:18:28.255178 130402719151616 run.py:734] Algo activity_selector step 9950 current loss 0.517707, current_train_items 274400.
I1130 22:18:28.388563 130402719151616 run.py:769] (val) algo activity_selector step 9950: {'selected': 0.9540229885057472, 'score': 0.9540229885057472, 'examples_seen': 274400, 'step': 9950, 'algorithm': 'activity_selector'}
I1130 22:18:28.388784 130402719151616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.954, val scores are: activity_selector: 0.954
I1130 22:18:29.439843 130402719151616 run.py:799] Restoring best model from checkpoint...
I1130 22:18:40.618926 130402719151616 run.py:814] (test) algo activity_selector : {'selected': 0.8905109489051095, 'score': 0.8905109489051095, 'examples_seen': 275760, 'step': 10000, 'algorithm': 'activity_selector'}
I1130 22:18:40.619107 130402719151616 run.py:816] Done!
