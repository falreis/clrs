I0831 22:39:01.323149 135974886344192 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0831 22:39:01.323863 135974886344192 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0831 22:39:01.547889 135974886344192 run.py:443] Model: f4 ['activity_selector', 'task_scheduling']
I0831 22:39:01.548002 135974886344192 run.py:445] algorithms ['activity_selector', 'task_scheduling']
I0831 22:39:01.548173 135974886344192 run.py:446] train_lengths ['4', '7', '11', '13', '16']
I0831 22:39:01.548209 135974886344192 run.py:447] train_batch_size 16
I0831 22:39:01.548299 135974886344192 run.py:448] val_batch_size 16
I0831 22:39:01.548331 135974886344192 run.py:449] test_batch_size 16
I0831 22:39:01.548360 135974886344192 run.py:450] chunked_training True
I0831 22:39:01.548483 135974886344192 run.py:451] chunk_length 8
I0831 22:39:01.548513 135974886344192 run.py:452] train_steps 10000
I0831 22:39:01.548542 135974886344192 run.py:453] eval_every 50
I0831 22:39:01.548570 135974886344192 run.py:454] test_every 500
I0831 22:39:01.548598 135974886344192 run.py:455] hidden_size 128
I0831 22:39:01.548628 135974886344192 run.py:456] nb_msg_passing_steps 1
I0831 22:39:01.548656 135974886344192 run.py:457] learning_rate 0.001
I0831 22:39:01.548743 135974886344192 run.py:458] grad_clip_max_norm 1.0
I0831 22:39:01.548773 135974886344192 run.py:459] dropout_prob 0.0
I0831 22:39:01.548803 135974886344192 run.py:460] hint_teacher_forcing 0.0
I0831 22:39:01.548831 135974886344192 run.py:461] hint_mode encoded_decoded
I0831 22:39:01.548939 135974886344192 run.py:462] hint_repred_mode soft
I0831 22:39:01.548969 135974886344192 run.py:463] use_ln False
I0831 22:39:01.549000 135974886344192 run.py:464] use_lstm True
I0831 22:39:01.549027 135974886344192 run.py:465] nb_triplet_fts 8
I0831 22:39:01.549055 135974886344192 run.py:466] encoder_init xavier_on_scalars
I0831 22:39:01.549082 135974886344192 run.py:467] processor_type f4
I0831 22:39:01.549110 135974886344192 run.py:468] checkpoint_path CLRS30
I0831 22:39:01.549138 135974886344192 run.py:469] dataset_path CLRS30
I0831 22:39:01.549165 135974886344192 run.py:470] freeze_processor False
I0831 22:39:01.549195 135974886344192 run.py:471] reduction min
I0831 22:39:01.549224 135974886344192 run.py:472] activation elu
I0831 22:39:01.549251 135974886344192 run.py:473] restore_model 
I0831 22:39:01.549278 135974886344192 run.py:474] gated False
I0831 22:39:01.549305 135974886344192 run.py:475] gated_activation sigmoid
I0831 22:39:01.551859 135974886344192 run.py:501] Creating samplers for algo activity_selector
W0831 22:39:01.552049 135974886344192 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0831 22:39:01.552300 135974886344192 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0831 22:39:01.756602 135974886344192 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0831 22:39:01.996328 135974886344192 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0831 22:39:02.296071 135974886344192 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0831 22:39:02.625686 135974886344192 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0831 22:39:03.008072 135974886344192 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0831 22:39:03.008315 135974886344192 samplers.py:124] Creating a dataset with 64 samples.
I0831 22:39:03.034150 135974886344192 run.py:287] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0831 22:39:03.034852 135974886344192 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0831 22:39:03.038442 135974886344192 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0831 22:39:03.041443 135974886344192 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0831 22:39:03.092237 135974886344192 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W0831 22:39:03.112863 135974886344192 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x7baa9a4979c0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0831 22:39:03.189019 135974886344192 run.py:501] Creating samplers for algo task_scheduling
W0831 22:39:03.189255 135974886344192 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.TaskSampler'>
W0831 22:39:03.383387 135974886344192 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.TaskSampler'>
W0831 22:39:03.609568 135974886344192 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.TaskSampler'>
W0831 22:39:03.890742 135974886344192 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.TaskSampler'>
W0831 22:39:04.200322 135974886344192 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.TaskSampler'>
W0831 22:39:04.560297 135974886344192 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.TaskSampler'>
I0831 22:39:04.560559 135974886344192 samplers.py:124] Creating a dataset with 64 samples.
I0831 22:39:04.585164 135974886344192 run.py:287] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0831 22:39:04.585743 135974886344192 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/task_scheduling_test/1.0.0
I0831 22:39:04.588346 135974886344192 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/task_scheduling_test/1.0.0
I0831 22:39:04.590461 135974886344192 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/task_scheduling_test/1.0.0.
I0831 22:39:04.623781 135974886344192 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/task_scheduling_test/1.0.0
I0831 22:39:27.491735 135974886344192 run.py:724] Algo activity_selector step 0 current loss 5.601090, current_train_items 16.
I0831 22:39:32.576084 135974886344192 run.py:724] Algo task_scheduling step 0 current loss 5.921507, current_train_items 16.
I0831 22:39:34.906394 135974886344192 run.py:759] (val) algo activity_selector step 0: {'selected': 0.0, 'score': 0.0, 'examples_seen': 16, 'step': 0, 'algorithm': 'activity_selector'}
I0831 22:39:36.260973 135974886344192 run.py:759] (val) algo task_scheduling step 0: {'selected': 0.7888823181549379, 'score': 0.7888823181549379, 'examples_seen': 16, 'step': 0, 'algorithm': 'task_scheduling'}
I0831 22:39:36.261138 135974886344192 run.py:780] Checkpointing best model, best avg val score was -0.500, current avg val score is 0.394, val scores are: activity_selector: 0.000, task_scheduling: 0.789
I0831 22:40:25.196525 135974886344192 run.py:724] Algo activity_selector step 50 current loss 4.114857, current_train_items 720.
I0831 22:40:25.201564 135974886344192 run.py:724] Algo task_scheduling step 50 current loss 3.842433, current_train_items 720.
I0831 22:40:25.217748 135974886344192 run.py:759] (val) algo activity_selector step 50: {'selected': 0.7297297297297298, 'score': 0.7297297297297298, 'examples_seen': 720, 'step': 50, 'algorithm': 'activity_selector'}
I0831 22:40:25.225577 135974886344192 run.py:759] (val) algo task_scheduling step 50: {'selected': 0.856036152356359, 'score': 0.856036152356359, 'examples_seen': 720, 'step': 50, 'algorithm': 'task_scheduling'}
I0831 22:40:25.225731 135974886344192 run.py:780] Checkpointing best model, best avg val score was 0.394, current avg val score is 0.793, val scores are: activity_selector: 0.730, task_scheduling: 0.856
I0831 22:40:26.234571 135974886344192 run.py:724] Algo activity_selector step 100 current loss 3.566791, current_train_items 1408.
I0831 22:40:26.239229 135974886344192 run.py:724] Algo task_scheduling step 100 current loss 3.184778, current_train_items 1408.
I0831 22:40:26.255970 135974886344192 run.py:759] (val) algo activity_selector step 100: {'selected': 0.7163695299837926, 'score': 0.7163695299837926, 'examples_seen': 1408, 'step': 100, 'algorithm': 'activity_selector'}
I0831 22:40:26.263582 135974886344192 run.py:759] (val) algo task_scheduling step 100: {'selected': 0.8740157480314962, 'score': 0.8740157480314962, 'examples_seen': 1408, 'step': 100, 'algorithm': 'task_scheduling'}
I0831 22:40:26.263740 135974886344192 run.py:780] Checkpointing best model, best avg val score was 0.793, current avg val score is 0.795, val scores are: activity_selector: 0.716, task_scheduling: 0.874
I0831 22:40:27.315919 135974886344192 run.py:724] Algo activity_selector step 150 current loss 3.176674, current_train_items 2080.
I0831 22:40:27.320381 135974886344192 run.py:724] Algo task_scheduling step 150 current loss 4.004107, current_train_items 2080.
I0831 22:40:27.337138 135974886344192 run.py:759] (val) algo activity_selector step 150: {'selected': 0.7658730158730159, 'score': 0.7658730158730159, 'examples_seen': 2080, 'step': 150, 'algorithm': 'activity_selector'}
I0831 22:40:27.344678 135974886344192 run.py:759] (val) algo task_scheduling step 150: {'selected': 0.8798955613577023, 'score': 0.8798955613577023, 'examples_seen': 2080, 'step': 150, 'algorithm': 'task_scheduling'}
I0831 22:40:27.344828 135974886344192 run.py:780] Checkpointing best model, best avg val score was 0.795, current avg val score is 0.823, val scores are: activity_selector: 0.766, task_scheduling: 0.880
I0831 22:40:28.397974 135974886344192 run.py:724] Algo activity_selector step 200 current loss 2.519332, current_train_items 2784.
I0831 22:40:28.402307 135974886344192 run.py:724] Algo task_scheduling step 200 current loss 2.922800, current_train_items 2784.
I0831 22:40:28.418201 135974886344192 run.py:759] (val) algo activity_selector step 200: {'selected': 0.6746506986027944, 'score': 0.6746506986027944, 'examples_seen': 2784, 'step': 200, 'algorithm': 'activity_selector'}
I0831 22:40:28.425729 135974886344192 run.py:759] (val) algo task_scheduling step 200: {'selected': 0.908321579689704, 'score': 0.908321579689704, 'examples_seen': 2784, 'step': 200, 'algorithm': 'task_scheduling'}
I0831 22:40:28.425872 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.823, current avg val score is 0.791, val scores are: activity_selector: 0.675, task_scheduling: 0.908
I0831 22:40:29.431849 135974886344192 run.py:724] Algo activity_selector step 250 current loss 2.758042, current_train_items 3488.
I0831 22:40:29.436426 135974886344192 run.py:724] Algo task_scheduling step 250 current loss 3.102689, current_train_items 3488.
I0831 22:40:29.453361 135974886344192 run.py:759] (val) algo activity_selector step 250: {'selected': 0.7212020033388983, 'score': 0.7212020033388983, 'examples_seen': 3488, 'step': 250, 'algorithm': 'activity_selector'}
I0831 22:40:29.460954 135974886344192 run.py:759] (val) algo task_scheduling step 250: {'selected': 0.9047619047619048, 'score': 0.9047619047619048, 'examples_seen': 3488, 'step': 250, 'algorithm': 'task_scheduling'}
I0831 22:40:29.461107 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.823, current avg val score is 0.813, val scores are: activity_selector: 0.721, task_scheduling: 0.905
I0831 22:40:30.480502 135974886344192 run.py:724] Algo activity_selector step 300 current loss 2.838559, current_train_items 4144.
I0831 22:40:30.485005 135974886344192 run.py:724] Algo task_scheduling step 300 current loss 3.061611, current_train_items 4144.
I0831 22:40:30.500627 135974886344192 run.py:759] (val) algo activity_selector step 300: {'selected': 0.7244701348747592, 'score': 0.7244701348747592, 'examples_seen': 4144, 'step': 300, 'algorithm': 'activity_selector'}
I0831 22:40:30.508164 135974886344192 run.py:759] (val) algo task_scheduling step 300: {'selected': 0.890059249506254, 'score': 0.890059249506254, 'examples_seen': 4144, 'step': 300, 'algorithm': 'task_scheduling'}
I0831 22:40:30.508308 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.823, current avg val score is 0.807, val scores are: activity_selector: 0.724, task_scheduling: 0.890
I0831 22:40:31.552211 135974886344192 run.py:724] Algo activity_selector step 350 current loss 2.864492, current_train_items 4848.
I0831 22:40:31.556635 135974886344192 run.py:724] Algo task_scheduling step 350 current loss 3.600516, current_train_items 4848.
I0831 22:40:31.572207 135974886344192 run.py:759] (val) algo activity_selector step 350: {'selected': 0.6939655172413793, 'score': 0.6939655172413793, 'examples_seen': 4848, 'step': 350, 'algorithm': 'activity_selector'}
I0831 22:40:31.579856 135974886344192 run.py:759] (val) algo task_scheduling step 350: {'selected': 0.8902038132807364, 'score': 0.8902038132807364, 'examples_seen': 4848, 'step': 350, 'algorithm': 'task_scheduling'}
I0831 22:40:31.580002 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.823, current avg val score is 0.792, val scores are: activity_selector: 0.694, task_scheduling: 0.890
I0831 22:40:32.611385 135974886344192 run.py:724] Algo activity_selector step 400 current loss 1.998406, current_train_items 5552.
I0831 22:40:32.616312 135974886344192 run.py:724] Algo task_scheduling step 400 current loss 2.609293, current_train_items 5552.
I0831 22:40:32.634478 135974886344192 run.py:759] (val) algo activity_selector step 400: {'selected': 0.75, 'score': 0.75, 'examples_seen': 5552, 'step': 400, 'algorithm': 'activity_selector'}
I0831 22:40:32.642103 135974886344192 run.py:759] (val) algo task_scheduling step 400: {'selected': 0.8903654485049833, 'score': 0.8903654485049833, 'examples_seen': 5552, 'step': 400, 'algorithm': 'task_scheduling'}
I0831 22:40:32.642249 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.823, current avg val score is 0.820, val scores are: activity_selector: 0.750, task_scheduling: 0.890
I0831 22:40:33.650681 135974886344192 run.py:724] Algo activity_selector step 450 current loss 2.129024, current_train_items 6224.
I0831 22:40:33.655222 135974886344192 run.py:724] Algo task_scheduling step 450 current loss 2.959007, current_train_items 6224.
I0831 22:40:33.671714 135974886344192 run.py:759] (val) algo activity_selector step 450: {'selected': 0.7848101265822786, 'score': 0.7848101265822786, 'examples_seen': 6224, 'step': 450, 'algorithm': 'activity_selector'}
I0831 22:40:33.679275 135974886344192 run.py:759] (val) algo task_scheduling step 450: {'selected': 0.8828229027962716, 'score': 0.8828229027962716, 'examples_seen': 6224, 'step': 450, 'algorithm': 'task_scheduling'}
I0831 22:40:33.679417 135974886344192 run.py:780] Checkpointing best model, best avg val score was 0.823, current avg val score is 0.834, val scores are: activity_selector: 0.785, task_scheduling: 0.883
I0831 22:40:34.739331 135974886344192 run.py:724] Algo activity_selector step 500 current loss 2.181932, current_train_items 6912.
I0831 22:40:34.743845 135974886344192 run.py:724] Algo task_scheduling step 500 current loss 2.809968, current_train_items 6912.
I0831 22:40:34.760092 135974886344192 run.py:759] (val) algo activity_selector step 500: {'selected': 0.7650485436893203, 'score': 0.7650485436893203, 'examples_seen': 6912, 'step': 500, 'algorithm': 'activity_selector'}
I0831 22:40:34.767689 135974886344192 run.py:759] (val) algo task_scheduling step 500: {'selected': 0.9098712446351931, 'score': 0.9098712446351931, 'examples_seen': 6912, 'step': 500, 'algorithm': 'task_scheduling'}
I0831 22:40:34.767834 135974886344192 run.py:780] Checkpointing best model, best avg val score was 0.834, current avg val score is 0.837, val scores are: activity_selector: 0.765, task_scheduling: 0.910
I0831 22:40:35.811959 135974886344192 run.py:724] Algo activity_selector step 550 current loss 1.843343, current_train_items 7616.
I0831 22:40:35.816454 135974886344192 run.py:724] Algo task_scheduling step 550 current loss 2.887836, current_train_items 7616.
I0831 22:40:35.834824 135974886344192 run.py:759] (val) algo activity_selector step 550: {'selected': 0.7870036101083031, 'score': 0.7870036101083031, 'examples_seen': 7616, 'step': 550, 'algorithm': 'activity_selector'}
I0831 22:40:35.842460 135974886344192 run.py:759] (val) algo task_scheduling step 550: {'selected': 0.9120879120879121, 'score': 0.9120879120879121, 'examples_seen': 7616, 'step': 550, 'algorithm': 'task_scheduling'}
I0831 22:40:35.842602 135974886344192 run.py:780] Checkpointing best model, best avg val score was 0.837, current avg val score is 0.850, val scores are: activity_selector: 0.787, task_scheduling: 0.912
I0831 22:40:36.876482 135974886344192 run.py:724] Algo activity_selector step 600 current loss 2.285902, current_train_items 8288.
I0831 22:40:36.880902 135974886344192 run.py:724] Algo task_scheduling step 600 current loss 2.647661, current_train_items 8288.
I0831 22:40:36.896626 135974886344192 run.py:759] (val) algo activity_selector step 600: {'selected': 0.7736185383244206, 'score': 0.7736185383244206, 'examples_seen': 8288, 'step': 600, 'algorithm': 'activity_selector'}
I0831 22:40:36.904191 135974886344192 run.py:759] (val) algo task_scheduling step 600: {'selected': 0.9118279569892473, 'score': 0.9118279569892473, 'examples_seen': 8288, 'step': 600, 'algorithm': 'task_scheduling'}
I0831 22:40:36.904331 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.850, current avg val score is 0.843, val scores are: activity_selector: 0.774, task_scheduling: 0.912
I0831 22:40:37.937539 135974886344192 run.py:724] Algo activity_selector step 650 current loss 1.742104, current_train_items 8976.
I0831 22:40:37.941966 135974886344192 run.py:724] Algo task_scheduling step 650 current loss 3.310400, current_train_items 8976.
I0831 22:40:37.957494 135974886344192 run.py:759] (val) algo activity_selector step 650: {'selected': 0.8037735849056604, 'score': 0.8037735849056604, 'examples_seen': 8976, 'step': 650, 'algorithm': 'activity_selector'}
I0831 22:40:37.965079 135974886344192 run.py:759] (val) algo task_scheduling step 650: {'selected': 0.8793935217091661, 'score': 0.8793935217091661, 'examples_seen': 8976, 'step': 650, 'algorithm': 'task_scheduling'}
I0831 22:40:37.965222 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.850, current avg val score is 0.842, val scores are: activity_selector: 0.804, task_scheduling: 0.879
I0831 22:40:38.988408 135974886344192 run.py:724] Algo activity_selector step 700 current loss 1.363887, current_train_items 9680.
I0831 22:40:38.992713 135974886344192 run.py:724] Algo task_scheduling step 700 current loss 2.456381, current_train_items 9680.
I0831 22:40:39.008816 135974886344192 run.py:759] (val) algo activity_selector step 700: {'selected': 0.7722772277227723, 'score': 0.7722772277227723, 'examples_seen': 9680, 'step': 700, 'algorithm': 'activity_selector'}
I0831 22:40:39.016471 135974886344192 run.py:759] (val) algo task_scheduling step 700: {'selected': 0.8980978260869564, 'score': 0.8980978260869564, 'examples_seen': 9680, 'step': 700, 'algorithm': 'task_scheduling'}
I0831 22:40:39.016610 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.850, current avg val score is 0.835, val scores are: activity_selector: 0.772, task_scheduling: 0.898
I0831 22:40:40.059798 135974886344192 run.py:724] Algo activity_selector step 750 current loss 1.764804, current_train_items 10368.
I0831 22:40:40.064120 135974886344192 run.py:724] Algo task_scheduling step 750 current loss 2.946808, current_train_items 10368.
I0831 22:40:40.080032 135974886344192 run.py:759] (val) algo activity_selector step 750: {'selected': 0.7865612648221345, 'score': 0.7865612648221345, 'examples_seen': 10368, 'step': 750, 'algorithm': 'activity_selector'}
I0831 22:40:40.087593 135974886344192 run.py:759] (val) algo task_scheduling step 750: {'selected': 0.8956007879185818, 'score': 0.8956007879185818, 'examples_seen': 10368, 'step': 750, 'algorithm': 'task_scheduling'}
I0831 22:40:40.087735 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.850, current avg val score is 0.841, val scores are: activity_selector: 0.787, task_scheduling: 0.896
I0831 22:40:41.106388 135974886344192 run.py:724] Algo activity_selector step 800 current loss 1.692343, current_train_items 11056.
I0831 22:40:41.110815 135974886344192 run.py:724] Algo task_scheduling step 800 current loss 3.232047, current_train_items 11056.
I0831 22:40:41.126090 135974886344192 run.py:759] (val) algo activity_selector step 800: {'selected': 0.8102564102564103, 'score': 0.8102564102564103, 'examples_seen': 11056, 'step': 800, 'algorithm': 'activity_selector'}
I0831 22:40:41.133680 135974886344192 run.py:759] (val) algo task_scheduling step 800: {'selected': 0.9215822345593337, 'score': 0.9215822345593337, 'examples_seen': 11056, 'step': 800, 'algorithm': 'task_scheduling'}
I0831 22:40:41.133823 135974886344192 run.py:780] Checkpointing best model, best avg val score was 0.850, current avg val score is 0.866, val scores are: activity_selector: 0.810, task_scheduling: 0.922
I0831 22:40:42.174062 135974886344192 run.py:724] Algo activity_selector step 850 current loss 1.693005, current_train_items 11744.
I0831 22:40:42.179060 135974886344192 run.py:724] Algo task_scheduling step 850 current loss 2.351223, current_train_items 11744.
I0831 22:40:42.194573 135974886344192 run.py:759] (val) algo activity_selector step 850: {'selected': 0.7814814814814814, 'score': 0.7814814814814814, 'examples_seen': 11744, 'step': 850, 'algorithm': 'activity_selector'}
I0831 22:40:42.202135 135974886344192 run.py:759] (val) algo task_scheduling step 850: {'selected': 0.9118046132971507, 'score': 0.9118046132971507, 'examples_seen': 11744, 'step': 850, 'algorithm': 'task_scheduling'}
I0831 22:40:42.202280 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.866, current avg val score is 0.847, val scores are: activity_selector: 0.781, task_scheduling: 0.912
I0831 22:40:43.254022 135974886344192 run.py:724] Algo activity_selector step 900 current loss 1.258687, current_train_items 12432.
I0831 22:40:43.258447 135974886344192 run.py:724] Algo task_scheduling step 900 current loss 3.155689, current_train_items 12432.
I0831 22:40:43.274554 135974886344192 run.py:759] (val) algo activity_selector step 900: {'selected': 0.7740667976424361, 'score': 0.7740667976424361, 'examples_seen': 12432, 'step': 900, 'algorithm': 'activity_selector'}
I0831 22:40:43.282303 135974886344192 run.py:759] (val) algo task_scheduling step 900: {'selected': 0.9126637554585153, 'score': 0.9126637554585153, 'examples_seen': 12432, 'step': 900, 'algorithm': 'task_scheduling'}
I0831 22:40:43.282483 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.866, current avg val score is 0.843, val scores are: activity_selector: 0.774, task_scheduling: 0.913
I0831 22:40:44.307131 135974886344192 run.py:724] Algo activity_selector step 950 current loss 1.443542, current_train_items 13120.
I0831 22:40:44.311338 135974886344192 run.py:724] Algo task_scheduling step 950 current loss 3.522553, current_train_items 13120.
I0831 22:40:44.327357 135974886344192 run.py:759] (val) algo activity_selector step 950: {'selected': 0.7833935018050541, 'score': 0.7833935018050541, 'examples_seen': 13120, 'step': 950, 'algorithm': 'activity_selector'}
I0831 22:40:44.335090 135974886344192 run.py:759] (val) algo task_scheduling step 950: {'selected': 0.9064039408866994, 'score': 0.9064039408866994, 'examples_seen': 13120, 'step': 950, 'algorithm': 'task_scheduling'}
I0831 22:40:44.335232 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.866, current avg val score is 0.845, val scores are: activity_selector: 0.783, task_scheduling: 0.906
I0831 22:40:45.355838 135974886344192 run.py:724] Algo activity_selector step 1000 current loss 2.508978, current_train_items 13808.
I0831 22:40:45.360303 135974886344192 run.py:724] Algo task_scheduling step 1000 current loss 3.754201, current_train_items 13808.
I0831 22:40:45.376091 135974886344192 run.py:759] (val) algo activity_selector step 1000: {'selected': 0.7665615141955837, 'score': 0.7665615141955837, 'examples_seen': 13808, 'step': 1000, 'algorithm': 'activity_selector'}
I0831 22:40:45.383729 135974886344192 run.py:759] (val) algo task_scheduling step 1000: {'selected': 0.8734261100066268, 'score': 0.8734261100066268, 'examples_seen': 13808, 'step': 1000, 'algorithm': 'task_scheduling'}
I0831 22:40:45.383874 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.866, current avg val score is 0.820, val scores are: activity_selector: 0.767, task_scheduling: 0.873
I0831 22:40:46.419229 135974886344192 run.py:724] Algo activity_selector step 1050 current loss 1.727636, current_train_items 14496.
I0831 22:40:46.424224 135974886344192 run.py:724] Algo task_scheduling step 1050 current loss 2.625289, current_train_items 14496.
I0831 22:40:46.440053 135974886344192 run.py:759] (val) algo activity_selector step 1050: {'selected': 0.8134328358208953, 'score': 0.8134328358208953, 'examples_seen': 14496, 'step': 1050, 'algorithm': 'activity_selector'}
I0831 22:40:46.447693 135974886344192 run.py:759] (val) algo task_scheduling step 1050: {'selected': 0.9319826338639653, 'score': 0.9319826338639653, 'examples_seen': 14496, 'step': 1050, 'algorithm': 'task_scheduling'}
I0831 22:40:46.447838 135974886344192 run.py:780] Checkpointing best model, best avg val score was 0.866, current avg val score is 0.873, val scores are: activity_selector: 0.813, task_scheduling: 0.932
I0831 22:40:47.490963 135974886344192 run.py:724] Algo activity_selector step 1100 current loss 1.418952, current_train_items 15200.
I0831 22:40:47.495458 135974886344192 run.py:724] Algo task_scheduling step 1100 current loss 2.684806, current_train_items 15200.
I0831 22:40:47.511849 135974886344192 run.py:759] (val) algo activity_selector step 1100: {'selected': 0.8208955223880597, 'score': 0.8208955223880597, 'examples_seen': 15200, 'step': 1100, 'algorithm': 'activity_selector'}
I0831 22:40:47.519395 135974886344192 run.py:759] (val) algo task_scheduling step 1100: {'selected': 0.902332361516035, 'score': 0.902332361516035, 'examples_seen': 15200, 'step': 1100, 'algorithm': 'task_scheduling'}
I0831 22:40:47.519532 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.873, current avg val score is 0.862, val scores are: activity_selector: 0.821, task_scheduling: 0.902
I0831 22:40:48.528708 135974886344192 run.py:724] Algo activity_selector step 1150 current loss 1.659233, current_train_items 15888.
I0831 22:40:48.533125 135974886344192 run.py:724] Algo task_scheduling step 1150 current loss 2.610333, current_train_items 15888.
I0831 22:40:48.549236 135974886344192 run.py:759] (val) algo activity_selector step 1150: {'selected': 0.793162393162393, 'score': 0.793162393162393, 'examples_seen': 15888, 'step': 1150, 'algorithm': 'activity_selector'}
I0831 22:40:48.556812 135974886344192 run.py:759] (val) algo task_scheduling step 1150: {'selected': 0.9457917261055635, 'score': 0.9457917261055635, 'examples_seen': 15888, 'step': 1150, 'algorithm': 'task_scheduling'}
I0831 22:40:48.556961 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.873, current avg val score is 0.869, val scores are: activity_selector: 0.793, task_scheduling: 0.946
I0831 22:40:49.599671 135974886344192 run.py:724] Algo activity_selector step 1200 current loss 1.289779, current_train_items 16560.
I0831 22:40:49.604205 135974886344192 run.py:724] Algo task_scheduling step 1200 current loss 3.315455, current_train_items 16560.
I0831 22:40:49.619919 135974886344192 run.py:759] (val) algo activity_selector step 1200: {'selected': 0.8263473053892216, 'score': 0.8263473053892216, 'examples_seen': 16560, 'step': 1200, 'algorithm': 'activity_selector'}
I0831 22:40:49.627512 135974886344192 run.py:759] (val) algo task_scheduling step 1200: {'selected': 0.9105691056910569, 'score': 0.9105691056910569, 'examples_seen': 16560, 'step': 1200, 'algorithm': 'task_scheduling'}
I0831 22:40:49.627655 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.873, current avg val score is 0.868, val scores are: activity_selector: 0.826, task_scheduling: 0.911
I0831 22:40:50.684631 135974886344192 run.py:724] Algo activity_selector step 1250 current loss 1.165817, current_train_items 17264.
I0831 22:40:50.689047 135974886344192 run.py:724] Algo task_scheduling step 1250 current loss 2.264395, current_train_items 17264.
I0831 22:40:50.705268 135974886344192 run.py:759] (val) algo activity_selector step 1250: {'selected': 0.8344827586206897, 'score': 0.8344827586206897, 'examples_seen': 17264, 'step': 1250, 'algorithm': 'activity_selector'}
I0831 22:40:50.712991 135974886344192 run.py:759] (val) algo task_scheduling step 1250: {'selected': 0.9350463954318343, 'score': 0.9350463954318343, 'examples_seen': 17264, 'step': 1250, 'algorithm': 'task_scheduling'}
I0831 22:40:50.713132 135974886344192 run.py:780] Checkpointing best model, best avg val score was 0.873, current avg val score is 0.885, val scores are: activity_selector: 0.834, task_scheduling: 0.935
I0831 22:40:51.740834 135974886344192 run.py:724] Algo activity_selector step 1300 current loss 1.634628, current_train_items 17952.
I0831 22:40:51.745161 135974886344192 run.py:724] Algo task_scheduling step 1300 current loss 2.362664, current_train_items 17952.
I0831 22:40:51.761750 135974886344192 run.py:759] (val) algo activity_selector step 1300: {'selected': 0.7928286852589641, 'score': 0.7928286852589641, 'examples_seen': 17952, 'step': 1300, 'algorithm': 'activity_selector'}
I0831 22:40:51.769390 135974886344192 run.py:759] (val) algo task_scheduling step 1300: {'selected': 0.9223300970873786, 'score': 0.9223300970873786, 'examples_seen': 17952, 'step': 1300, 'algorithm': 'task_scheduling'}
I0831 22:40:51.769533 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.885, current avg val score is 0.858, val scores are: activity_selector: 0.793, task_scheduling: 0.922
I0831 22:40:52.798769 135974886344192 run.py:724] Algo activity_selector step 1350 current loss 1.320923, current_train_items 18624.
I0831 22:40:52.803323 135974886344192 run.py:724] Algo task_scheduling step 1350 current loss 1.815236, current_train_items 18624.
I0831 22:40:52.819703 135974886344192 run.py:759] (val) algo activity_selector step 1350: {'selected': 0.7785234899328859, 'score': 0.7785234899328859, 'examples_seen': 18624, 'step': 1350, 'algorithm': 'activity_selector'}
I0831 22:40:52.827694 135974886344192 run.py:759] (val) algo task_scheduling step 1350: {'selected': 0.9371688115064345, 'score': 0.9371688115064345, 'examples_seen': 18624, 'step': 1350, 'algorithm': 'task_scheduling'}
I0831 22:40:52.827839 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.885, current avg val score is 0.858, val scores are: activity_selector: 0.779, task_scheduling: 0.937
I0831 22:40:53.865237 135974886344192 run.py:724] Algo activity_selector step 1400 current loss 0.970346, current_train_items 19328.
I0831 22:40:53.869807 135974886344192 run.py:724] Algo task_scheduling step 1400 current loss 2.212596, current_train_items 19328.
I0831 22:40:53.885509 135974886344192 run.py:759] (val) algo activity_selector step 1400: {'selected': 0.792982456140351, 'score': 0.792982456140351, 'examples_seen': 19328, 'step': 1400, 'algorithm': 'activity_selector'}
I0831 22:40:53.893104 135974886344192 run.py:759] (val) algo task_scheduling step 1400: {'selected': 0.9417543859649123, 'score': 0.9417543859649123, 'examples_seen': 19328, 'step': 1400, 'algorithm': 'task_scheduling'}
I0831 22:40:53.893244 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.885, current avg val score is 0.867, val scores are: activity_selector: 0.793, task_scheduling: 0.942
I0831 22:40:54.901962 135974886344192 run.py:724] Algo activity_selector step 1450 current loss 1.277184, current_train_items 20016.
I0831 22:40:54.906413 135974886344192 run.py:724] Algo task_scheduling step 1450 current loss 3.628469, current_train_items 20016.
I0831 22:40:54.922508 135974886344192 run.py:759] (val) algo activity_selector step 1450: {'selected': 0.8576850094876659, 'score': 0.8576850094876659, 'examples_seen': 20016, 'step': 1450, 'algorithm': 'activity_selector'}
I0831 22:40:54.930164 135974886344192 run.py:759] (val) algo task_scheduling step 1450: {'selected': 0.9402560455192034, 'score': 0.9402560455192034, 'examples_seen': 20016, 'step': 1450, 'algorithm': 'task_scheduling'}
I0831 22:40:54.930322 135974886344192 run.py:780] Checkpointing best model, best avg val score was 0.885, current avg val score is 0.899, val scores are: activity_selector: 0.858, task_scheduling: 0.940
I0831 22:40:55.975273 135974886344192 run.py:724] Algo activity_selector step 1500 current loss 1.099954, current_train_items 20704.
I0831 22:40:55.979656 135974886344192 run.py:724] Algo task_scheduling step 1500 current loss 2.148909, current_train_items 20704.
I0831 22:40:55.995549 135974886344192 run.py:759] (val) algo activity_selector step 1500: {'selected': 0.8488160291438981, 'score': 0.8488160291438981, 'examples_seen': 20704, 'step': 1500, 'algorithm': 'activity_selector'}
I0831 22:40:56.003210 135974886344192 run.py:759] (val) algo task_scheduling step 1500: {'selected': 0.9159261790840738, 'score': 0.9159261790840738, 'examples_seen': 20704, 'step': 1500, 'algorithm': 'task_scheduling'}
I0831 22:40:56.003365 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.899, current avg val score is 0.882, val scores are: activity_selector: 0.849, task_scheduling: 0.916
I0831 22:40:57.050311 135974886344192 run.py:724] Algo activity_selector step 1550 current loss 1.001554, current_train_items 21392.
I0831 22:40:57.054872 135974886344192 run.py:724] Algo task_scheduling step 1550 current loss 2.175770, current_train_items 21392.
I0831 22:40:57.070618 135974886344192 run.py:759] (val) algo activity_selector step 1550: {'selected': 0.8333333333333334, 'score': 0.8333333333333334, 'examples_seen': 21392, 'step': 1550, 'algorithm': 'activity_selector'}
I0831 22:40:57.078232 135974886344192 run.py:759] (val) algo task_scheduling step 1550: {'selected': 0.9396872673119882, 'score': 0.9396872673119882, 'examples_seen': 21392, 'step': 1550, 'algorithm': 'task_scheduling'}
I0831 22:40:57.078388 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.899, current avg val score is 0.887, val scores are: activity_selector: 0.833, task_scheduling: 0.940
I0831 22:40:58.108207 135974886344192 run.py:724] Algo activity_selector step 1600 current loss 0.894727, current_train_items 22096.
I0831 22:40:58.112665 135974886344192 run.py:724] Algo task_scheduling step 1600 current loss 2.144490, current_train_items 22096.
I0831 22:40:58.128038 135974886344192 run.py:759] (val) algo activity_selector step 1600: {'selected': 0.8484848484848484, 'score': 0.8484848484848484, 'examples_seen': 22096, 'step': 1600, 'algorithm': 'activity_selector'}
I0831 22:40:58.135599 135974886344192 run.py:759] (val) algo task_scheduling step 1600: {'selected': 0.9142033165104542, 'score': 0.9142033165104542, 'examples_seen': 22096, 'step': 1600, 'algorithm': 'task_scheduling'}
I0831 22:40:58.135742 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.899, current avg val score is 0.881, val scores are: activity_selector: 0.848, task_scheduling: 0.914
I0831 22:40:59.146397 135974886344192 run.py:724] Algo activity_selector step 1650 current loss 1.203034, current_train_items 22768.
I0831 22:40:59.150756 135974886344192 run.py:724] Algo task_scheduling step 1650 current loss 2.043125, current_train_items 22768.
I0831 22:40:59.166616 135974886344192 run.py:759] (val) algo activity_selector step 1650: {'selected': 0.8453237410071942, 'score': 0.8453237410071942, 'examples_seen': 22768, 'step': 1650, 'algorithm': 'activity_selector'}
I0831 22:40:59.174352 135974886344192 run.py:759] (val) algo task_scheduling step 1650: {'selected': 0.9438202247191011, 'score': 0.9438202247191011, 'examples_seen': 22768, 'step': 1650, 'algorithm': 'task_scheduling'}
I0831 22:40:59.174496 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.899, current avg val score is 0.895, val scores are: activity_selector: 0.845, task_scheduling: 0.944
I0831 22:41:00.198759 135974886344192 run.py:724] Algo activity_selector step 1700 current loss 0.883801, current_train_items 23456.
I0831 22:41:00.203211 135974886344192 run.py:724] Algo task_scheduling step 1700 current loss 2.526565, current_train_items 23456.
I0831 22:41:00.219034 135974886344192 run.py:759] (val) algo activity_selector step 1700: {'selected': 0.8822429906542057, 'score': 0.8822429906542057, 'examples_seen': 23456, 'step': 1700, 'algorithm': 'activity_selector'}
I0831 22:41:00.226678 135974886344192 run.py:759] (val) algo task_scheduling step 1700: {'selected': 0.8940092165898618, 'score': 0.8940092165898618, 'examples_seen': 23456, 'step': 1700, 'algorithm': 'task_scheduling'}
I0831 22:41:00.226839 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.899, current avg val score is 0.888, val scores are: activity_selector: 0.882, task_scheduling: 0.894
I0831 22:41:01.248669 135974886344192 run.py:724] Algo activity_selector step 1750 current loss 1.226157, current_train_items 24160.
I0831 22:41:01.253050 135974886344192 run.py:724] Algo task_scheduling step 1750 current loss 2.077615, current_train_items 24160.
I0831 22:41:01.269052 135974886344192 run.py:759] (val) algo activity_selector step 1750: {'selected': 0.8681898066783832, 'score': 0.8681898066783832, 'examples_seen': 24160, 'step': 1750, 'algorithm': 'activity_selector'}
I0831 22:41:01.276578 135974886344192 run.py:759] (val) algo task_scheduling step 1750: {'selected': 0.938622754491018, 'score': 0.938622754491018, 'examples_seen': 24160, 'step': 1750, 'algorithm': 'task_scheduling'}
I0831 22:41:01.276717 135974886344192 run.py:780] Checkpointing best model, best avg val score was 0.899, current avg val score is 0.903, val scores are: activity_selector: 0.868, task_scheduling: 0.939
I0831 22:41:02.301160 135974886344192 run.py:724] Algo activity_selector step 1800 current loss 1.162634, current_train_items 24832.
I0831 22:41:02.305613 135974886344192 run.py:724] Algo task_scheduling step 1800 current loss 1.764378, current_train_items 24832.
I0831 22:41:02.321033 135974886344192 run.py:759] (val) algo activity_selector step 1800: {'selected': 0.8341880341880342, 'score': 0.8341880341880342, 'examples_seen': 24832, 'step': 1800, 'algorithm': 'activity_selector'}
I0831 22:41:02.328563 135974886344192 run.py:759] (val) algo task_scheduling step 1800: {'selected': 0.9382352941176471, 'score': 0.9382352941176471, 'examples_seen': 24832, 'step': 1800, 'algorithm': 'task_scheduling'}
I0831 22:41:02.328718 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.903, current avg val score is 0.886, val scores are: activity_selector: 0.834, task_scheduling: 0.938
I0831 22:41:03.361287 135974886344192 run.py:724] Algo activity_selector step 1850 current loss 0.852387, current_train_items 25536.
I0831 22:41:03.365777 135974886344192 run.py:724] Algo task_scheduling step 1850 current loss 2.179780, current_train_items 25536.
I0831 22:41:03.382152 135974886344192 run.py:759] (val) algo activity_selector step 1850: {'selected': 0.8185328185328185, 'score': 0.8185328185328185, 'examples_seen': 25536, 'step': 1850, 'algorithm': 'activity_selector'}
I0831 22:41:03.389686 135974886344192 run.py:759] (val) algo task_scheduling step 1850: {'selected': 0.9013513513513514, 'score': 0.9013513513513514, 'examples_seen': 25536, 'step': 1850, 'algorithm': 'task_scheduling'}
I0831 22:41:03.389826 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.903, current avg val score is 0.860, val scores are: activity_selector: 0.819, task_scheduling: 0.901
I0831 22:41:04.421864 135974886344192 run.py:724] Algo activity_selector step 1900 current loss 1.154801, current_train_items 26224.
I0831 22:41:04.426301 135974886344192 run.py:724] Algo task_scheduling step 1900 current loss 2.351153, current_train_items 26224.
I0831 22:41:04.442184 135974886344192 run.py:759] (val) algo activity_selector step 1900: {'selected': 0.8402777777777778, 'score': 0.8402777777777778, 'examples_seen': 26224, 'step': 1900, 'algorithm': 'activity_selector'}
I0831 22:41:04.449751 135974886344192 run.py:759] (val) algo task_scheduling step 1900: {'selected': 0.9201520912547528, 'score': 0.9201520912547528, 'examples_seen': 26224, 'step': 1900, 'algorithm': 'task_scheduling'}
I0831 22:41:04.449901 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.903, current avg val score is 0.880, val scores are: activity_selector: 0.840, task_scheduling: 0.920
I0831 22:41:05.468323 135974886344192 run.py:724] Algo activity_selector step 1950 current loss 0.884938, current_train_items 26912.
I0831 22:41:05.472645 135974886344192 run.py:724] Algo task_scheduling step 1950 current loss 2.069199, current_train_items 26912.
I0831 22:41:05.488337 135974886344192 run.py:759] (val) algo activity_selector step 1950: {'selected': 0.8410256410256409, 'score': 0.8410256410256409, 'examples_seen': 26912, 'step': 1950, 'algorithm': 'activity_selector'}
I0831 22:41:05.495866 135974886344192 run.py:759] (val) algo task_scheduling step 1950: {'selected': 0.9383954154727794, 'score': 0.9383954154727794, 'examples_seen': 26912, 'step': 1950, 'algorithm': 'task_scheduling'}
I0831 22:41:05.496027 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.903, current avg val score is 0.890, val scores are: activity_selector: 0.841, task_scheduling: 0.938
I0831 22:41:06.529543 135974886344192 run.py:724] Algo activity_selector step 2000 current loss 0.789073, current_train_items 27600.
I0831 22:41:06.534330 135974886344192 run.py:724] Algo task_scheduling step 2000 current loss 3.503279, current_train_items 27600.
I0831 22:41:06.550108 135974886344192 run.py:759] (val) algo activity_selector step 2000: {'selected': 0.8765652951699463, 'score': 0.8765652951699463, 'examples_seen': 27600, 'step': 2000, 'algorithm': 'activity_selector'}
I0831 22:41:06.557743 135974886344192 run.py:759] (val) algo task_scheduling step 2000: {'selected': 0.9201680672268907, 'score': 0.9201680672268907, 'examples_seen': 27600, 'step': 2000, 'algorithm': 'task_scheduling'}
I0831 22:41:06.557902 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.903, current avg val score is 0.898, val scores are: activity_selector: 0.877, task_scheduling: 0.920
I0831 22:41:07.577252 135974886344192 run.py:724] Algo activity_selector step 2050 current loss 1.108647, current_train_items 28288.
I0831 22:41:07.581615 135974886344192 run.py:724] Algo task_scheduling step 2050 current loss 2.133993, current_train_items 28288.
I0831 22:41:07.599755 135974886344192 run.py:759] (val) algo activity_selector step 2050: {'selected': 0.8307155322862129, 'score': 0.8307155322862129, 'examples_seen': 28288, 'step': 2050, 'algorithm': 'activity_selector'}
I0831 22:41:07.607520 135974886344192 run.py:759] (val) algo task_scheduling step 2050: {'selected': 0.9396914446002805, 'score': 0.9396914446002805, 'examples_seen': 28288, 'step': 2050, 'algorithm': 'task_scheduling'}
I0831 22:41:07.607663 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.903, current avg val score is 0.885, val scores are: activity_selector: 0.831, task_scheduling: 0.940
I0831 22:41:08.656362 135974886344192 run.py:724] Algo activity_selector step 2100 current loss 1.209195, current_train_items 28976.
I0831 22:41:08.660684 135974886344192 run.py:724] Algo task_scheduling step 2100 current loss 1.738442, current_train_items 28976.
I0831 22:41:08.676081 135974886344192 run.py:759] (val) algo activity_selector step 2100: {'selected': 0.8636363636363636, 'score': 0.8636363636363636, 'examples_seen': 28976, 'step': 2100, 'algorithm': 'activity_selector'}
I0831 22:41:08.683662 135974886344192 run.py:759] (val) algo task_scheduling step 2100: {'selected': 0.9535864978902954, 'score': 0.9535864978902954, 'examples_seen': 28976, 'step': 2100, 'algorithm': 'task_scheduling'}
I0831 22:41:08.683802 135974886344192 run.py:780] Checkpointing best model, best avg val score was 0.903, current avg val score is 0.909, val scores are: activity_selector: 0.864, task_scheduling: 0.954
I0831 22:41:09.729970 135974886344192 run.py:724] Algo activity_selector step 2150 current loss 0.955144, current_train_items 29664.
I0831 22:41:09.734304 135974886344192 run.py:724] Algo task_scheduling step 2150 current loss 2.998361, current_train_items 29664.
I0831 22:41:09.751513 135974886344192 run.py:759] (val) algo activity_selector step 2150: {'selected': 0.8674242424242424, 'score': 0.8674242424242424, 'examples_seen': 29664, 'step': 2150, 'algorithm': 'activity_selector'}
I0831 22:41:09.759238 135974886344192 run.py:759] (val) algo task_scheduling step 2150: {'selected': 0.9106666666666667, 'score': 0.9106666666666667, 'examples_seen': 29664, 'step': 2150, 'algorithm': 'task_scheduling'}
I0831 22:41:09.759403 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.909, current avg val score is 0.889, val scores are: activity_selector: 0.867, task_scheduling: 0.911
I0831 22:41:10.777611 135974886344192 run.py:724] Algo activity_selector step 2200 current loss 1.226168, current_train_items 30368.
I0831 22:41:10.781955 135974886344192 run.py:724] Algo task_scheduling step 2200 current loss 2.095867, current_train_items 30368.
I0831 22:41:10.797704 135974886344192 run.py:759] (val) algo activity_selector step 2200: {'selected': 0.8623853211009174, 'score': 0.8623853211009174, 'examples_seen': 30368, 'step': 2200, 'algorithm': 'activity_selector'}
I0831 22:41:10.805274 135974886344192 run.py:759] (val) algo task_scheduling step 2200: {'selected': 0.9497450837581938, 'score': 0.9497450837581938, 'examples_seen': 30368, 'step': 2200, 'algorithm': 'task_scheduling'}
I0831 22:41:10.805413 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.909, current avg val score is 0.906, val scores are: activity_selector: 0.862, task_scheduling: 0.950
I0831 22:41:11.835680 135974886344192 run.py:724] Algo activity_selector step 2250 current loss 0.675986, current_train_items 31040.
I0831 22:41:11.840003 135974886344192 run.py:724] Algo task_scheduling step 2250 current loss 2.521006, current_train_items 31040.
I0831 22:41:11.855621 135974886344192 run.py:759] (val) algo activity_selector step 2250: {'selected': 0.8406909788867563, 'score': 0.8406909788867563, 'examples_seen': 31040, 'step': 2250, 'algorithm': 'activity_selector'}
I0831 22:41:11.863176 135974886344192 run.py:759] (val) algo task_scheduling step 2250: {'selected': 0.9261559696342305, 'score': 0.9261559696342305, 'examples_seen': 31040, 'step': 2250, 'algorithm': 'task_scheduling'}
I0831 22:41:11.863314 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.909, current avg val score is 0.883, val scores are: activity_selector: 0.841, task_scheduling: 0.926
I0831 22:41:12.884942 135974886344192 run.py:724] Algo activity_selector step 2300 current loss 0.691318, current_train_items 31728.
I0831 22:41:12.889433 135974886344192 run.py:724] Algo task_scheduling step 2300 current loss 3.490515, current_train_items 31728.
I0831 22:41:12.905693 135974886344192 run.py:759] (val) algo activity_selector step 2300: {'selected': 0.8764044943820225, 'score': 0.8764044943820225, 'examples_seen': 31728, 'step': 2300, 'algorithm': 'activity_selector'}
I0831 22:41:12.913263 135974886344192 run.py:759] (val) algo task_scheduling step 2300: {'selected': 0.8638956805215974, 'score': 0.8638956805215974, 'examples_seen': 31728, 'step': 2300, 'algorithm': 'task_scheduling'}
I0831 22:41:12.913405 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.909, current avg val score is 0.870, val scores are: activity_selector: 0.876, task_scheduling: 0.864
I0831 22:41:13.939355 135974886344192 run.py:724] Algo activity_selector step 2350 current loss 1.033071, current_train_items 32432.
I0831 22:41:13.943843 135974886344192 run.py:724] Algo task_scheduling step 2350 current loss 1.565795, current_train_items 32432.
I0831 22:41:13.959982 135974886344192 run.py:759] (val) algo activity_selector step 2350: {'selected': 0.862876254180602, 'score': 0.862876254180602, 'examples_seen': 32432, 'step': 2350, 'algorithm': 'activity_selector'}
I0831 22:41:13.967560 135974886344192 run.py:759] (val) algo task_scheduling step 2350: {'selected': 0.9342857142857144, 'score': 0.9342857142857144, 'examples_seen': 32432, 'step': 2350, 'algorithm': 'task_scheduling'}
I0831 22:41:13.967700 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.909, current avg val score is 0.899, val scores are: activity_selector: 0.863, task_scheduling: 0.934
I0831 22:41:14.995448 135974886344192 run.py:724] Algo activity_selector step 2400 current loss 1.242462, current_train_items 33104.
I0831 22:41:15.000053 135974886344192 run.py:724] Algo task_scheduling step 2400 current loss 2.067666, current_train_items 33104.
I0831 22:41:15.015635 135974886344192 run.py:759] (val) algo activity_selector step 2400: {'selected': 0.8391866913123844, 'score': 0.8391866913123844, 'examples_seen': 33104, 'step': 2400, 'algorithm': 'activity_selector'}
I0831 22:41:15.023224 135974886344192 run.py:759] (val) algo task_scheduling step 2400: {'selected': 0.9348441926345608, 'score': 0.9348441926345608, 'examples_seen': 33104, 'step': 2400, 'algorithm': 'task_scheduling'}
I0831 22:41:15.023366 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.909, current avg val score is 0.887, val scores are: activity_selector: 0.839, task_scheduling: 0.935
I0831 22:41:16.068514 135974886344192 run.py:724] Algo activity_selector step 2450 current loss 0.883109, current_train_items 33808.
I0831 22:41:16.072937 135974886344192 run.py:724] Algo task_scheduling step 2450 current loss 1.657891, current_train_items 33808.
I0831 22:41:16.089356 135974886344192 run.py:759] (val) algo activity_selector step 2450: {'selected': 0.8754448398576513, 'score': 0.8754448398576513, 'examples_seen': 33808, 'step': 2450, 'algorithm': 'activity_selector'}
I0831 22:41:16.097086 135974886344192 run.py:759] (val) algo task_scheduling step 2450: {'selected': 0.9351389878831077, 'score': 0.9351389878831077, 'examples_seen': 33808, 'step': 2450, 'algorithm': 'task_scheduling'}
I0831 22:41:16.097228 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.909, current avg val score is 0.905, val scores are: activity_selector: 0.875, task_scheduling: 0.935
I0831 22:41:17.110089 135974886344192 run.py:724] Algo activity_selector step 2500 current loss 0.739150, current_train_items 34496.
I0831 22:41:17.114557 135974886344192 run.py:724] Algo task_scheduling step 2500 current loss 2.523598, current_train_items 34496.
I0831 22:41:17.130165 135974886344192 run.py:759] (val) algo activity_selector step 2500: {'selected': 0.8986615678776291, 'score': 0.8986615678776291, 'examples_seen': 34496, 'step': 2500, 'algorithm': 'activity_selector'}
I0831 22:41:17.137774 135974886344192 run.py:759] (val) algo task_scheduling step 2500: {'selected': 0.9082321187584345, 'score': 0.9082321187584345, 'examples_seen': 34496, 'step': 2500, 'algorithm': 'task_scheduling'}
I0831 22:41:17.137918 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.909, current avg val score is 0.903, val scores are: activity_selector: 0.899, task_scheduling: 0.908
I0831 22:41:18.174293 135974886344192 run.py:724] Algo activity_selector step 2550 current loss 0.701139, current_train_items 35184.
I0831 22:41:18.179295 135974886344192 run.py:724] Algo task_scheduling step 2550 current loss 2.441812, current_train_items 35184.
I0831 22:41:18.195101 135974886344192 run.py:759] (val) algo activity_selector step 2550: {'selected': 0.84765625, 'score': 0.84765625, 'examples_seen': 35184, 'step': 2550, 'algorithm': 'activity_selector'}
I0831 22:41:18.202716 135974886344192 run.py:759] (val) algo task_scheduling step 2550: {'selected': 0.9402447804175667, 'score': 0.9402447804175667, 'examples_seen': 35184, 'step': 2550, 'algorithm': 'task_scheduling'}
I0831 22:41:18.202863 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.909, current avg val score is 0.894, val scores are: activity_selector: 0.848, task_scheduling: 0.940
I0831 22:41:19.248707 135974886344192 run.py:724] Algo activity_selector step 2600 current loss 0.755160, current_train_items 35872.
I0831 22:41:19.253306 135974886344192 run.py:724] Algo task_scheduling step 2600 current loss 2.285045, current_train_items 35872.
I0831 22:41:19.269782 135974886344192 run.py:759] (val) algo activity_selector step 2600: {'selected': 0.8718929254302104, 'score': 0.8718929254302104, 'examples_seen': 35872, 'step': 2600, 'algorithm': 'activity_selector'}
I0831 22:41:19.277394 135974886344192 run.py:759] (val) algo task_scheduling step 2600: {'selected': 0.9081404032860343, 'score': 0.9081404032860343, 'examples_seen': 35872, 'step': 2600, 'algorithm': 'task_scheduling'}
I0831 22:41:19.277535 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.909, current avg val score is 0.890, val scores are: activity_selector: 0.872, task_scheduling: 0.908
I0831 22:41:20.292855 135974886344192 run.py:724] Algo activity_selector step 2650 current loss 0.878505, current_train_items 36560.
I0831 22:41:20.297179 135974886344192 run.py:724] Algo task_scheduling step 2650 current loss 2.010422, current_train_items 36560.
I0831 22:41:20.313922 135974886344192 run.py:759] (val) algo activity_selector step 2650: {'selected': 0.8824593128390598, 'score': 0.8824593128390598, 'examples_seen': 36560, 'step': 2650, 'algorithm': 'activity_selector'}
I0831 22:41:20.321620 135974886344192 run.py:759] (val) algo task_scheduling step 2650: {'selected': 0.9444444444444444, 'score': 0.9444444444444444, 'examples_seen': 36560, 'step': 2650, 'algorithm': 'task_scheduling'}
I0831 22:41:20.321803 135974886344192 run.py:780] Checkpointing best model, best avg val score was 0.909, current avg val score is 0.913, val scores are: activity_selector: 0.882, task_scheduling: 0.944
I0831 22:41:21.378786 135974886344192 run.py:724] Algo activity_selector step 2700 current loss 0.822514, current_train_items 37248.
I0831 22:41:21.383231 135974886344192 run.py:724] Algo task_scheduling step 2700 current loss 1.763253, current_train_items 37248.
I0831 22:41:21.399408 135974886344192 run.py:759] (val) algo activity_selector step 2700: {'selected': 0.875886524822695, 'score': 0.875886524822695, 'examples_seen': 37248, 'step': 2700, 'algorithm': 'activity_selector'}
I0831 22:41:21.406996 135974886344192 run.py:759] (val) algo task_scheduling step 2700: {'selected': 0.9280469897209985, 'score': 0.9280469897209985, 'examples_seen': 37248, 'step': 2700, 'algorithm': 'task_scheduling'}
I0831 22:41:21.407138 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.913, current avg val score is 0.902, val scores are: activity_selector: 0.876, task_scheduling: 0.928
I0831 22:41:22.437555 135974886344192 run.py:724] Algo activity_selector step 2750 current loss 0.966762, current_train_items 37936.
I0831 22:41:22.442045 135974886344192 run.py:724] Algo task_scheduling step 2750 current loss 1.869968, current_train_items 37936.
I0831 22:41:22.457948 135974886344192 run.py:759] (val) algo activity_selector step 2750: {'selected': 0.8455008488964346, 'score': 0.8455008488964346, 'examples_seen': 37936, 'step': 2750, 'algorithm': 'activity_selector'}
I0831 22:41:22.465529 135974886344192 run.py:759] (val) algo task_scheduling step 2750: {'selected': 0.9390581717451523, 'score': 0.9390581717451523, 'examples_seen': 37936, 'step': 2750, 'algorithm': 'task_scheduling'}
I0831 22:41:22.465670 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.913, current avg val score is 0.892, val scores are: activity_selector: 0.846, task_scheduling: 0.939
I0831 22:41:23.479865 135974886344192 run.py:724] Algo activity_selector step 2800 current loss 0.459370, current_train_items 38640.
I0831 22:41:23.484321 135974886344192 run.py:724] Algo task_scheduling step 2800 current loss 2.270790, current_train_items 38640.
I0831 22:41:23.500321 135974886344192 run.py:759] (val) algo activity_selector step 2800: {'selected': 0.8638838475499092, 'score': 0.8638838475499092, 'examples_seen': 38640, 'step': 2800, 'algorithm': 'activity_selector'}
I0831 22:41:23.507917 135974886344192 run.py:759] (val) algo task_scheduling step 2800: {'selected': 0.9348837209302325, 'score': 0.9348837209302325, 'examples_seen': 38640, 'step': 2800, 'algorithm': 'task_scheduling'}
I0831 22:41:23.508066 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.913, current avg val score is 0.899, val scores are: activity_selector: 0.864, task_scheduling: 0.935
I0831 22:41:24.548668 135974886344192 run.py:724] Algo activity_selector step 2850 current loss 0.537570, current_train_items 39312.
I0831 22:41:24.552987 135974886344192 run.py:724] Algo task_scheduling step 2850 current loss 1.627174, current_train_items 39312.
I0831 22:41:24.568657 135974886344192 run.py:759] (val) algo activity_selector step 2850: {'selected': 0.9165120593692022, 'score': 0.9165120593692022, 'examples_seen': 39312, 'step': 2850, 'algorithm': 'activity_selector'}
I0831 22:41:24.576205 135974886344192 run.py:759] (val) algo task_scheduling step 2850: {'selected': 0.9353023909985936, 'score': 0.9353023909985936, 'examples_seen': 39312, 'step': 2850, 'algorithm': 'task_scheduling'}
I0831 22:41:24.576344 135974886344192 run.py:780] Checkpointing best model, best avg val score was 0.913, current avg val score is 0.926, val scores are: activity_selector: 0.917, task_scheduling: 0.935
I0831 22:41:25.616377 135974886344192 run.py:724] Algo activity_selector step 2900 current loss 1.007123, current_train_items 40016.
I0831 22:41:25.620758 135974886344192 run.py:724] Algo task_scheduling step 2900 current loss 1.849307, current_train_items 40016.
I0831 22:41:25.636567 135974886344192 run.py:759] (val) algo activity_selector step 2900: {'selected': 0.8444444444444444, 'score': 0.8444444444444444, 'examples_seen': 40016, 'step': 2900, 'algorithm': 'activity_selector'}
I0831 22:41:25.644170 135974886344192 run.py:759] (val) algo task_scheduling step 2900: {'selected': 0.9305949008498583, 'score': 0.9305949008498583, 'examples_seen': 40016, 'step': 2900, 'algorithm': 'task_scheduling'}
I0831 22:41:25.644314 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.888, val scores are: activity_selector: 0.844, task_scheduling: 0.931
I0831 22:41:26.674736 135974886344192 run.py:724] Algo activity_selector step 2950 current loss 0.764807, current_train_items 40704.
I0831 22:41:26.679110 135974886344192 run.py:724] Algo task_scheduling step 2950 current loss 1.962447, current_train_items 40704.
I0831 22:41:26.694770 135974886344192 run.py:759] (val) algo activity_selector step 2950: {'selected': 0.9028571428571429, 'score': 0.9028571428571429, 'examples_seen': 40704, 'step': 2950, 'algorithm': 'activity_selector'}
I0831 22:41:26.702318 135974886344192 run.py:759] (val) algo task_scheduling step 2950: {'selected': 0.9472924187725631, 'score': 0.9472924187725631, 'examples_seen': 40704, 'step': 2950, 'algorithm': 'task_scheduling'}
I0831 22:41:26.702461 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.925, val scores are: activity_selector: 0.903, task_scheduling: 0.947
I0831 22:41:27.720713 135974886344192 run.py:724] Algo activity_selector step 3000 current loss 0.872421, current_train_items 41376.
I0831 22:41:27.725099 135974886344192 run.py:724] Algo task_scheduling step 3000 current loss 1.615958, current_train_items 41376.
I0831 22:41:27.740723 135974886344192 run.py:759] (val) algo activity_selector step 3000: {'selected': 0.8941605839416059, 'score': 0.8941605839416059, 'examples_seen': 41376, 'step': 3000, 'algorithm': 'activity_selector'}
I0831 22:41:27.748252 135974886344192 run.py:759] (val) algo task_scheduling step 3000: {'selected': 0.9433691756272401, 'score': 0.9433691756272401, 'examples_seen': 41376, 'step': 3000, 'algorithm': 'task_scheduling'}
I0831 22:41:27.748395 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.919, val scores are: activity_selector: 0.894, task_scheduling: 0.943
I0831 22:41:28.784238 135974886344192 run.py:724] Algo activity_selector step 3050 current loss 1.348536, current_train_items 42080.
I0831 22:41:28.788667 135974886344192 run.py:724] Algo task_scheduling step 3050 current loss 3.034717, current_train_items 42080.
I0831 22:41:28.804813 135974886344192 run.py:759] (val) algo activity_selector step 3050: {'selected': 0.8845401174168297, 'score': 0.8845401174168297, 'examples_seen': 42080, 'step': 3050, 'algorithm': 'activity_selector'}
I0831 22:41:28.812455 135974886344192 run.py:759] (val) algo task_scheduling step 3050: {'selected': 0.8884615384615385, 'score': 0.8884615384615385, 'examples_seen': 42080, 'step': 3050, 'algorithm': 'task_scheduling'}
I0831 22:41:28.812597 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.887, val scores are: activity_selector: 0.885, task_scheduling: 0.888
I0831 22:41:29.820261 135974886344192 run.py:724] Algo activity_selector step 3100 current loss 0.976574, current_train_items 42768.
I0831 22:41:29.824620 135974886344192 run.py:724] Algo task_scheduling step 3100 current loss 2.050642, current_train_items 42768.
I0831 22:41:29.840595 135974886344192 run.py:759] (val) algo activity_selector step 3100: {'selected': 0.8500881834215167, 'score': 0.8500881834215167, 'examples_seen': 42768, 'step': 3100, 'algorithm': 'activity_selector'}
I0831 22:41:29.848174 135974886344192 run.py:759] (val) algo task_scheduling step 3100: {'selected': 0.9222065063649222, 'score': 0.9222065063649222, 'examples_seen': 42768, 'step': 3100, 'algorithm': 'task_scheduling'}
I0831 22:41:29.848320 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.886, val scores are: activity_selector: 0.850, task_scheduling: 0.922
I0831 22:41:30.867972 135974886344192 run.py:724] Algo activity_selector step 3150 current loss 0.660757, current_train_items 43440.
I0831 22:41:30.872568 135974886344192 run.py:724] Algo task_scheduling step 3150 current loss 2.240227, current_train_items 43440.
I0831 22:41:30.888529 135974886344192 run.py:759] (val) algo activity_selector step 3150: {'selected': 0.8333333333333334, 'score': 0.8333333333333334, 'examples_seen': 43440, 'step': 3150, 'algorithm': 'activity_selector'}
I0831 22:41:30.896127 135974886344192 run.py:759] (val) algo task_scheduling step 3150: {'selected': 0.8826291079812207, 'score': 0.8826291079812207, 'examples_seen': 43440, 'step': 3150, 'algorithm': 'task_scheduling'}
I0831 22:41:30.896268 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.858, val scores are: activity_selector: 0.833, task_scheduling: 0.883
I0831 22:41:31.949524 135974886344192 run.py:724] Algo activity_selector step 3200 current loss 1.076791, current_train_items 44144.
I0831 22:41:31.954066 135974886344192 run.py:724] Algo task_scheduling step 3200 current loss 1.968217, current_train_items 44144.
I0831 22:41:31.970403 135974886344192 run.py:759] (val) algo activity_selector step 3200: {'selected': 0.8350515463917525, 'score': 0.8350515463917525, 'examples_seen': 44144, 'step': 3200, 'algorithm': 'activity_selector'}
I0831 22:41:31.978038 135974886344192 run.py:759] (val) algo task_scheduling step 3200: {'selected': 0.9425605536332179, 'score': 0.9425605536332179, 'examples_seen': 44144, 'step': 3200, 'algorithm': 'task_scheduling'}
I0831 22:41:31.978180 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.889, val scores are: activity_selector: 0.835, task_scheduling: 0.943
I0831 22:41:32.992536 135974886344192 run.py:724] Algo activity_selector step 3250 current loss 1.060230, current_train_items 44848.
I0831 22:41:32.997018 135974886344192 run.py:724] Algo task_scheduling step 3250 current loss 2.691141, current_train_items 44848.
I0831 22:41:33.013545 135974886344192 run.py:759] (val) algo activity_selector step 3250: {'selected': 0.8860294117647058, 'score': 0.8860294117647058, 'examples_seen': 44848, 'step': 3250, 'algorithm': 'activity_selector'}
I0831 22:41:33.021111 135974886344192 run.py:759] (val) algo task_scheduling step 3250: {'selected': 0.9328621908127209, 'score': 0.9328621908127209, 'examples_seen': 44848, 'step': 3250, 'algorithm': 'task_scheduling'}
I0831 22:41:33.021252 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.909, val scores are: activity_selector: 0.886, task_scheduling: 0.933
I0831 22:41:34.059777 135974886344192 run.py:724] Algo activity_selector step 3300 current loss 0.861546, current_train_items 45520.
I0831 22:41:34.064357 135974886344192 run.py:724] Algo task_scheduling step 3300 current loss 1.849579, current_train_items 45520.
I0831 22:41:34.080397 135974886344192 run.py:759] (val) algo activity_selector step 3300: {'selected': 0.8517745302713987, 'score': 0.8517745302713987, 'examples_seen': 45520, 'step': 3300, 'algorithm': 'activity_selector'}
I0831 22:41:34.087990 135974886344192 run.py:759] (val) algo task_scheduling step 3300: {'selected': 0.9472182596291013, 'score': 0.9472182596291013, 'examples_seen': 45520, 'step': 3300, 'algorithm': 'task_scheduling'}
I0831 22:41:34.088130 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.899, val scores are: activity_selector: 0.852, task_scheduling: 0.947
I0831 22:41:35.123347 135974886344192 run.py:724] Algo activity_selector step 3350 current loss 0.859995, current_train_items 46208.
I0831 22:41:35.127865 135974886344192 run.py:724] Algo task_scheduling step 3350 current loss 1.472566, current_train_items 46208.
I0831 22:41:35.144306 135974886344192 run.py:759] (val) algo activity_selector step 3350: {'selected': 0.860759493670886, 'score': 0.860759493670886, 'examples_seen': 46208, 'step': 3350, 'algorithm': 'activity_selector'}
I0831 22:41:35.151982 135974886344192 run.py:759] (val) algo task_scheduling step 3350: {'selected': 0.9470013947001394, 'score': 0.9470013947001394, 'examples_seen': 46208, 'step': 3350, 'algorithm': 'task_scheduling'}
I0831 22:41:35.152130 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.904, val scores are: activity_selector: 0.861, task_scheduling: 0.947
I0831 22:41:36.185713 135974886344192 run.py:724] Algo activity_selector step 3400 current loss 1.040492, current_train_items 46912.
I0831 22:41:36.190073 135974886344192 run.py:724] Algo task_scheduling step 3400 current loss 1.824240, current_train_items 46912.
I0831 22:41:36.206197 135974886344192 run.py:759] (val) algo activity_selector step 3400: {'selected': 0.8978102189781021, 'score': 0.8978102189781021, 'examples_seen': 46912, 'step': 3400, 'algorithm': 'activity_selector'}
I0831 22:41:36.213777 135974886344192 run.py:759] (val) algo task_scheduling step 3400: {'selected': 0.9238227146814405, 'score': 0.9238227146814405, 'examples_seen': 46912, 'step': 3400, 'algorithm': 'task_scheduling'}
I0831 22:41:36.213918 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.911, val scores are: activity_selector: 0.898, task_scheduling: 0.924
I0831 22:41:37.242042 135974886344192 run.py:724] Algo activity_selector step 3450 current loss 0.514190, current_train_items 47584.
I0831 22:41:37.246560 135974886344192 run.py:724] Algo task_scheduling step 3450 current loss 1.751186, current_train_items 47584.
I0831 22:41:37.262976 135974886344192 run.py:759] (val) algo activity_selector step 3450: {'selected': 0.8897485493230175, 'score': 0.8897485493230175, 'examples_seen': 47584, 'step': 3450, 'algorithm': 'activity_selector'}
I0831 22:41:37.270569 135974886344192 run.py:759] (val) algo task_scheduling step 3450: {'selected': 0.9356890459363958, 'score': 0.9356890459363958, 'examples_seen': 47584, 'step': 3450, 'algorithm': 'task_scheduling'}
I0831 22:41:37.270725 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.913, val scores are: activity_selector: 0.890, task_scheduling: 0.936
I0831 22:41:38.288778 135974886344192 run.py:724] Algo activity_selector step 3500 current loss 0.831152, current_train_items 48272.
I0831 22:41:38.293289 135974886344192 run.py:724] Algo task_scheduling step 3500 current loss 1.595739, current_train_items 48272.
I0831 22:41:38.308857 135974886344192 run.py:759] (val) algo activity_selector step 3500: {'selected': 0.9077212806026366, 'score': 0.9077212806026366, 'examples_seen': 48272, 'step': 3500, 'algorithm': 'activity_selector'}
I0831 22:41:38.316499 135974886344192 run.py:759] (val) algo task_scheduling step 3500: {'selected': 0.941678520625889, 'score': 0.941678520625889, 'examples_seen': 48272, 'step': 3500, 'algorithm': 'task_scheduling'}
I0831 22:41:38.316639 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.925, val scores are: activity_selector: 0.908, task_scheduling: 0.942
I0831 22:41:39.344083 135974886344192 run.py:724] Algo activity_selector step 3550 current loss 0.686156, current_train_items 48976.
I0831 22:41:39.348631 135974886344192 run.py:724] Algo task_scheduling step 3550 current loss 1.891262, current_train_items 48976.
I0831 22:41:39.364495 135974886344192 run.py:759] (val) algo activity_selector step 3550: {'selected': 0.8813559322033899, 'score': 0.8813559322033899, 'examples_seen': 48976, 'step': 3550, 'algorithm': 'activity_selector'}
I0831 22:41:39.372146 135974886344192 run.py:759] (val) algo task_scheduling step 3550: {'selected': 0.9403973509933775, 'score': 0.9403973509933775, 'examples_seen': 48976, 'step': 3550, 'algorithm': 'task_scheduling'}
I0831 22:41:39.372288 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.911, val scores are: activity_selector: 0.881, task_scheduling: 0.940
I0831 22:41:40.397753 135974886344192 run.py:724] Algo activity_selector step 3600 current loss 0.747900, current_train_items 49664.
I0831 22:41:40.402076 135974886344192 run.py:724] Algo task_scheduling step 3600 current loss 1.994216, current_train_items 49664.
I0831 22:41:40.417713 135974886344192 run.py:759] (val) algo activity_selector step 3600: {'selected': 0.9046728971962616, 'score': 0.9046728971962616, 'examples_seen': 49664, 'step': 3600, 'algorithm': 'activity_selector'}
I0831 22:41:40.425290 135974886344192 run.py:759] (val) algo task_scheduling step 3600: {'selected': 0.9466192170818505, 'score': 0.9466192170818505, 'examples_seen': 49664, 'step': 3600, 'algorithm': 'task_scheduling'}
I0831 22:41:40.425434 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.926, val scores are: activity_selector: 0.905, task_scheduling: 0.947
I0831 22:41:41.449485 135974886344192 run.py:724] Algo activity_selector step 3650 current loss 0.797138, current_train_items 50352.
I0831 22:41:41.453975 135974886344192 run.py:724] Algo task_scheduling step 3650 current loss 1.554964, current_train_items 50352.
I0831 22:41:41.469678 135974886344192 run.py:759] (val) algo activity_selector step 3650: {'selected': 0.9117117117117117, 'score': 0.9117117117117117, 'examples_seen': 50352, 'step': 3650, 'algorithm': 'activity_selector'}
I0831 22:41:41.477270 135974886344192 run.py:759] (val) algo task_scheduling step 3650: {'selected': 0.9339752407152683, 'score': 0.9339752407152683, 'examples_seen': 50352, 'step': 3650, 'algorithm': 'task_scheduling'}
I0831 22:41:41.477412 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.923, val scores are: activity_selector: 0.912, task_scheduling: 0.934
I0831 22:41:42.508807 135974886344192 run.py:724] Algo activity_selector step 3700 current loss 1.278419, current_train_items 51040.
I0831 22:41:42.513220 135974886344192 run.py:724] Algo task_scheduling step 3700 current loss 1.691701, current_train_items 51040.
I0831 22:41:42.528676 135974886344192 run.py:759] (val) algo activity_selector step 3700: {'selected': 0.859344894026975, 'score': 0.859344894026975, 'examples_seen': 51040, 'step': 3700, 'algorithm': 'activity_selector'}
I0831 22:41:42.536287 135974886344192 run.py:759] (val) algo task_scheduling step 3700: {'selected': 0.9425287356321839, 'score': 0.9425287356321839, 'examples_seen': 51040, 'step': 3700, 'algorithm': 'task_scheduling'}
I0831 22:41:42.536427 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.901, val scores are: activity_selector: 0.859, task_scheduling: 0.943
I0831 22:41:43.575110 135974886344192 run.py:724] Algo activity_selector step 3750 current loss 0.960267, current_train_items 51728.
I0831 22:41:43.579489 135974886344192 run.py:724] Algo task_scheduling step 3750 current loss 1.307330, current_train_items 51728.
I0831 22:41:43.595330 135974886344192 run.py:759] (val) algo activity_selector step 3750: {'selected': 0.8571428571428571, 'score': 0.8571428571428571, 'examples_seen': 51728, 'step': 3750, 'algorithm': 'activity_selector'}
I0831 22:41:43.602884 135974886344192 run.py:759] (val) algo task_scheduling step 3750: {'selected': 0.9395484340859432, 'score': 0.9395484340859432, 'examples_seen': 51728, 'step': 3750, 'algorithm': 'task_scheduling'}
I0831 22:41:43.603034 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.898, val scores are: activity_selector: 0.857, task_scheduling: 0.940
I0831 22:41:44.633297 135974886344192 run.py:724] Algo activity_selector step 3800 current loss 0.884872, current_train_items 52416.
I0831 22:41:44.637895 135974886344192 run.py:724] Algo task_scheduling step 3800 current loss 1.901738, current_train_items 52416.
I0831 22:41:44.654414 135974886344192 run.py:759] (val) algo activity_selector step 3800: {'selected': 0.88, 'score': 0.88, 'examples_seen': 52416, 'step': 3800, 'algorithm': 'activity_selector'}
I0831 22:41:44.661938 135974886344192 run.py:759] (val) algo task_scheduling step 3800: {'selected': 0.9154160982264665, 'score': 0.9154160982264665, 'examples_seen': 52416, 'step': 3800, 'algorithm': 'task_scheduling'}
I0831 22:41:44.662082 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.898, val scores are: activity_selector: 0.880, task_scheduling: 0.915
I0831 22:41:45.678134 135974886344192 run.py:724] Algo activity_selector step 3850 current loss 1.369174, current_train_items 53104.
I0831 22:41:45.682727 135974886344192 run.py:724] Algo task_scheduling step 3850 current loss 1.350690, current_train_items 53104.
I0831 22:41:45.698560 135974886344192 run.py:759] (val) algo activity_selector step 3850: {'selected': 0.8130360205831904, 'score': 0.8130360205831904, 'examples_seen': 53104, 'step': 3850, 'algorithm': 'activity_selector'}
I0831 22:41:45.706106 135974886344192 run.py:759] (val) algo task_scheduling step 3850: {'selected': 0.9220338983050846, 'score': 0.9220338983050846, 'examples_seen': 53104, 'step': 3850, 'algorithm': 'task_scheduling'}
I0831 22:41:45.706244 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.868, val scores are: activity_selector: 0.813, task_scheduling: 0.922
I0831 22:41:46.744460 135974886344192 run.py:724] Algo activity_selector step 3900 current loss 0.492000, current_train_items 53792.
I0831 22:41:46.748897 135974886344192 run.py:724] Algo task_scheduling step 3900 current loss 3.334085, current_train_items 53792.
I0831 22:41:46.764481 135974886344192 run.py:759] (val) algo activity_selector step 3900: {'selected': 0.8719851576994433, 'score': 0.8719851576994433, 'examples_seen': 53792, 'step': 3900, 'algorithm': 'activity_selector'}
I0831 22:41:46.772080 135974886344192 run.py:759] (val) algo task_scheduling step 3900: {'selected': 0.8907782864617397, 'score': 0.8907782864617397, 'examples_seen': 53792, 'step': 3900, 'algorithm': 'task_scheduling'}
I0831 22:41:46.772220 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.881, val scores are: activity_selector: 0.872, task_scheduling: 0.891
I0831 22:41:47.803133 135974886344192 run.py:724] Algo activity_selector step 3950 current loss 0.659930, current_train_items 54496.
I0831 22:41:47.807765 135974886344192 run.py:724] Algo task_scheduling step 3950 current loss 1.650577, current_train_items 54496.
I0831 22:41:47.823771 135974886344192 run.py:759] (val) algo activity_selector step 3950: {'selected': 0.9080675422138837, 'score': 0.9080675422138837, 'examples_seen': 54496, 'step': 3950, 'algorithm': 'activity_selector'}
I0831 22:41:47.831349 135974886344192 run.py:759] (val) algo task_scheduling step 3950: {'selected': 0.9282296650717704, 'score': 0.9282296650717704, 'examples_seen': 54496, 'step': 3950, 'algorithm': 'task_scheduling'}
I0831 22:41:47.831489 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.918, val scores are: activity_selector: 0.908, task_scheduling: 0.928
I0831 22:41:48.836374 135974886344192 run.py:724] Algo activity_selector step 4000 current loss 0.603262, current_train_items 55168.
I0831 22:41:48.840669 135974886344192 run.py:724] Algo task_scheduling step 4000 current loss 1.501092, current_train_items 55168.
I0831 22:41:48.856151 135974886344192 run.py:759] (val) algo activity_selector step 4000: {'selected': 0.9062500000000001, 'score': 0.9062500000000001, 'examples_seen': 55168, 'step': 4000, 'algorithm': 'activity_selector'}
I0831 22:41:48.863912 135974886344192 run.py:759] (val) algo task_scheduling step 4000: {'selected': 0.9327671620665251, 'score': 0.9327671620665251, 'examples_seen': 55168, 'step': 4000, 'algorithm': 'task_scheduling'}
I0831 22:41:48.864059 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.920, val scores are: activity_selector: 0.906, task_scheduling: 0.933
I0831 22:41:49.905097 135974886344192 run.py:724] Algo activity_selector step 4050 current loss 0.842516, current_train_items 55856.
I0831 22:41:49.909492 135974886344192 run.py:724] Algo task_scheduling step 4050 current loss 2.025624, current_train_items 55856.
I0831 22:41:49.925698 135974886344192 run.py:759] (val) algo activity_selector step 4050: {'selected': 0.8884688090737239, 'score': 0.8884688090737239, 'examples_seen': 55856, 'step': 4050, 'algorithm': 'activity_selector'}
I0831 22:41:49.933298 135974886344192 run.py:759] (val) algo task_scheduling step 4050: {'selected': 0.8945205479452054, 'score': 0.8945205479452054, 'examples_seen': 55856, 'step': 4050, 'algorithm': 'task_scheduling'}
I0831 22:41:49.933442 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.891, val scores are: activity_selector: 0.888, task_scheduling: 0.895
I0831 22:41:50.966997 135974886344192 run.py:724] Algo activity_selector step 4100 current loss 0.888800, current_train_items 56560.
I0831 22:41:50.971561 135974886344192 run.py:724] Algo task_scheduling step 4100 current loss 1.457696, current_train_items 56560.
I0831 22:41:50.988641 135974886344192 run.py:759] (val) algo activity_selector step 4100: {'selected': 0.8639705882352942, 'score': 0.8639705882352942, 'examples_seen': 56560, 'step': 4100, 'algorithm': 'activity_selector'}
I0831 22:41:50.996191 135974886344192 run.py:759] (val) algo task_scheduling step 4100: {'selected': 0.937456078706957, 'score': 0.937456078706957, 'examples_seen': 56560, 'step': 4100, 'algorithm': 'task_scheduling'}
I0831 22:41:50.996331 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.901, val scores are: activity_selector: 0.864, task_scheduling: 0.937
I0831 22:41:52.013080 135974886344192 run.py:724] Algo activity_selector step 4150 current loss 1.457743, current_train_items 57248.
I0831 22:41:52.017733 135974886344192 run.py:724] Algo task_scheduling step 4150 current loss 1.299812, current_train_items 57248.
I0831 22:41:52.033741 135974886344192 run.py:759] (val) algo activity_selector step 4150: {'selected': 0.8820512820512819, 'score': 0.8820512820512819, 'examples_seen': 57248, 'step': 4150, 'algorithm': 'activity_selector'}
I0831 22:41:52.041360 135974886344192 run.py:759] (val) algo task_scheduling step 4150: {'selected': 0.931865106675843, 'score': 0.931865106675843, 'examples_seen': 57248, 'step': 4150, 'algorithm': 'task_scheduling'}
I0831 22:41:52.041501 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.907, val scores are: activity_selector: 0.882, task_scheduling: 0.932
I0831 22:41:53.086070 135974886344192 run.py:724] Algo activity_selector step 4200 current loss 1.081133, current_train_items 57920.
I0831 22:41:53.090481 135974886344192 run.py:724] Algo task_scheduling step 4200 current loss 1.572097, current_train_items 57920.
I0831 22:41:53.106821 135974886344192 run.py:759] (val) algo activity_selector step 4200: {'selected': 0.8329809725158562, 'score': 0.8329809725158562, 'examples_seen': 57920, 'step': 4200, 'algorithm': 'activity_selector'}
I0831 22:41:53.114389 135974886344192 run.py:759] (val) algo task_scheduling step 4200: {'selected': 0.9195876288659793, 'score': 0.9195876288659793, 'examples_seen': 57920, 'step': 4200, 'algorithm': 'task_scheduling'}
I0831 22:41:53.114534 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.876, val scores are: activity_selector: 0.833, task_scheduling: 0.920
I0831 22:41:54.157466 135974886344192 run.py:724] Algo activity_selector step 4250 current loss 0.821194, current_train_items 58624.
I0831 22:41:54.162101 135974886344192 run.py:724] Algo task_scheduling step 4250 current loss 1.648407, current_train_items 58624.
I0831 22:41:54.177593 135974886344192 run.py:759] (val) algo activity_selector step 4250: {'selected': 0.8773234200743494, 'score': 0.8773234200743494, 'examples_seen': 58624, 'step': 4250, 'algorithm': 'activity_selector'}
I0831 22:41:54.185181 135974886344192 run.py:759] (val) algo task_scheduling step 4250: {'selected': 0.9438521677327647, 'score': 0.9438521677327647, 'examples_seen': 58624, 'step': 4250, 'algorithm': 'task_scheduling'}
I0831 22:41:54.185325 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.911, val scores are: activity_selector: 0.877, task_scheduling: 0.944
I0831 22:41:55.205389 135974886344192 run.py:724] Algo activity_selector step 4300 current loss 0.826176, current_train_items 59328.
I0831 22:41:55.209859 135974886344192 run.py:724] Algo task_scheduling step 4300 current loss 1.935719, current_train_items 59328.
I0831 22:41:55.226175 135974886344192 run.py:759] (val) algo activity_selector step 4300: {'selected': 0.9068541300527241, 'score': 0.9068541300527241, 'examples_seen': 59328, 'step': 4300, 'algorithm': 'activity_selector'}
I0831 22:41:55.233731 135974886344192 run.py:759] (val) algo task_scheduling step 4300: {'selected': 0.9342010122921186, 'score': 0.9342010122921186, 'examples_seen': 59328, 'step': 4300, 'algorithm': 'task_scheduling'}
I0831 22:41:55.233873 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.921, val scores are: activity_selector: 0.907, task_scheduling: 0.934
I0831 22:41:56.247168 135974886344192 run.py:724] Algo activity_selector step 4350 current loss 0.702903, current_train_items 59984.
I0831 22:41:56.251559 135974886344192 run.py:724] Algo task_scheduling step 4350 current loss 1.791229, current_train_items 59984.
I0831 22:41:56.267234 135974886344192 run.py:759] (val) algo activity_selector step 4350: {'selected': 0.8976377952755906, 'score': 0.8976377952755906, 'examples_seen': 59984, 'step': 4350, 'algorithm': 'activity_selector'}
I0831 22:41:56.274815 135974886344192 run.py:759] (val) algo task_scheduling step 4350: {'selected': 0.9340735600277584, 'score': 0.9340735600277584, 'examples_seen': 59984, 'step': 4350, 'algorithm': 'task_scheduling'}
I0831 22:41:56.274962 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.916, val scores are: activity_selector: 0.898, task_scheduling: 0.934
I0831 22:41:57.327186 135974886344192 run.py:724] Algo activity_selector step 4400 current loss 0.950840, current_train_items 60688.
I0831 22:41:57.331696 135974886344192 run.py:724] Algo task_scheduling step 4400 current loss 1.566820, current_train_items 60688.
I0831 22:41:57.347521 135974886344192 run.py:759] (val) algo activity_selector step 4400: {'selected': 0.8974358974358975, 'score': 0.8974358974358975, 'examples_seen': 60688, 'step': 4400, 'algorithm': 'activity_selector'}
I0831 22:41:57.355144 135974886344192 run.py:759] (val) algo task_scheduling step 4400: {'selected': 0.9346590909090909, 'score': 0.9346590909090909, 'examples_seen': 60688, 'step': 4400, 'algorithm': 'task_scheduling'}
I0831 22:41:57.355286 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.916, val scores are: activity_selector: 0.897, task_scheduling: 0.935
I0831 22:41:58.379819 135974886344192 run.py:724] Algo activity_selector step 4450 current loss 0.872174, current_train_items 61392.
I0831 22:41:58.384636 135974886344192 run.py:724] Algo task_scheduling step 4450 current loss 1.894019, current_train_items 61392.
I0831 22:41:58.400374 135974886344192 run.py:759] (val) algo activity_selector step 4450: {'selected': 0.8775894538606402, 'score': 0.8775894538606402, 'examples_seen': 61392, 'step': 4450, 'algorithm': 'activity_selector'}
I0831 22:41:58.407861 135974886344192 run.py:759] (val) algo task_scheduling step 4450: {'selected': 0.9370021723388848, 'score': 0.9370021723388848, 'examples_seen': 61392, 'step': 4450, 'algorithm': 'task_scheduling'}
I0831 22:41:58.408012 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.907, val scores are: activity_selector: 0.878, task_scheduling: 0.937
I0831 22:41:59.421490 135974886344192 run.py:724] Algo activity_selector step 4500 current loss 0.665513, current_train_items 62064.
I0831 22:41:59.426043 135974886344192 run.py:724] Algo task_scheduling step 4500 current loss 1.645674, current_train_items 62064.
I0831 22:41:59.441588 135974886344192 run.py:759] (val) algo activity_selector step 4500: {'selected': 0.9076923076923077, 'score': 0.9076923076923077, 'examples_seen': 62064, 'step': 4500, 'algorithm': 'activity_selector'}
I0831 22:41:59.449151 135974886344192 run.py:759] (val) algo task_scheduling step 4500: {'selected': 0.9400584795321638, 'score': 0.9400584795321638, 'examples_seen': 62064, 'step': 4500, 'algorithm': 'task_scheduling'}
I0831 22:41:59.449291 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.924, val scores are: activity_selector: 0.908, task_scheduling: 0.940
I0831 22:42:00.493804 135974886344192 run.py:724] Algo activity_selector step 4550 current loss 0.926896, current_train_items 62752.
I0831 22:42:00.498431 135974886344192 run.py:724] Algo task_scheduling step 4550 current loss 1.399374, current_train_items 62752.
I0831 22:42:00.514707 135974886344192 run.py:759] (val) algo activity_selector step 4550: {'selected': 0.8610038610038611, 'score': 0.8610038610038611, 'examples_seen': 62752, 'step': 4550, 'algorithm': 'activity_selector'}
I0831 22:42:00.522336 135974886344192 run.py:759] (val) algo task_scheduling step 4550: {'selected': 0.9263759828448892, 'score': 0.9263759828448892, 'examples_seen': 62752, 'step': 4550, 'algorithm': 'task_scheduling'}
I0831 22:42:00.522498 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.894, val scores are: activity_selector: 0.861, task_scheduling: 0.926
I0831 22:42:01.550664 135974886344192 run.py:724] Algo activity_selector step 4600 current loss 0.672703, current_train_items 63456.
I0831 22:42:01.555134 135974886344192 run.py:724] Algo task_scheduling step 4600 current loss 1.401122, current_train_items 63456.
I0831 22:42:01.571425 135974886344192 run.py:759] (val) algo activity_selector step 4600: {'selected': 0.8901960784313725, 'score': 0.8901960784313725, 'examples_seen': 63456, 'step': 4600, 'algorithm': 'activity_selector'}
I0831 22:42:01.579015 135974886344192 run.py:759] (val) algo task_scheduling step 4600: {'selected': 0.9344608879492601, 'score': 0.9344608879492601, 'examples_seen': 63456, 'step': 4600, 'algorithm': 'task_scheduling'}
I0831 22:42:01.579174 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.912, val scores are: activity_selector: 0.890, task_scheduling: 0.934
I0831 22:42:02.613403 135974886344192 run.py:724] Algo activity_selector step 4650 current loss 0.792083, current_train_items 64144.
I0831 22:42:02.617760 135974886344192 run.py:724] Algo task_scheduling step 4650 current loss 1.548099, current_train_items 64144.
I0831 22:42:02.633396 135974886344192 run.py:759] (val) algo activity_selector step 4650: {'selected': 0.8981818181818181, 'score': 0.8981818181818181, 'examples_seen': 64144, 'step': 4650, 'algorithm': 'activity_selector'}
I0831 22:42:02.640941 135974886344192 run.py:759] (val) algo task_scheduling step 4650: {'selected': 0.902787219578518, 'score': 0.902787219578518, 'examples_seen': 64144, 'step': 4650, 'algorithm': 'task_scheduling'}
I0831 22:42:02.641083 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.926, current avg val score is 0.900, val scores are: activity_selector: 0.898, task_scheduling: 0.903
I0831 22:42:03.662306 135974886344192 run.py:724] Algo activity_selector step 4700 current loss 0.862030, current_train_items 64816.
I0831 22:42:03.666763 135974886344192 run.py:724] Algo task_scheduling step 4700 current loss 1.466130, current_train_items 64816.
I0831 22:42:03.682299 135974886344192 run.py:759] (val) algo activity_selector step 4700: {'selected': 0.9172661870503598, 'score': 0.9172661870503598, 'examples_seen': 64816, 'step': 4700, 'algorithm': 'activity_selector'}
I0831 22:42:03.689879 135974886344192 run.py:759] (val) algo task_scheduling step 4700: {'selected': 0.9387186629526462, 'score': 0.9387186629526462, 'examples_seen': 64816, 'step': 4700, 'algorithm': 'task_scheduling'}
I0831 22:42:03.690030 135974886344192 run.py:780] Checkpointing best model, best avg val score was 0.926, current avg val score is 0.928, val scores are: activity_selector: 0.917, task_scheduling: 0.939
I0831 22:42:04.736095 135974886344192 run.py:724] Algo activity_selector step 4750 current loss 0.961699, current_train_items 65520.
I0831 22:42:04.740552 135974886344192 run.py:724] Algo task_scheduling step 4750 current loss 2.492837, current_train_items 65520.
I0831 22:42:04.756444 135974886344192 run.py:759] (val) algo activity_selector step 4750: {'selected': 0.915129151291513, 'score': 0.915129151291513, 'examples_seen': 65520, 'step': 4750, 'algorithm': 'activity_selector'}
I0831 22:42:04.763992 135974886344192 run.py:759] (val) algo task_scheduling step 4750: {'selected': 0.8669201520912547, 'score': 0.8669201520912547, 'examples_seen': 65520, 'step': 4750, 'algorithm': 'task_scheduling'}
I0831 22:42:04.764130 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.891, val scores are: activity_selector: 0.915, task_scheduling: 0.867
I0831 22:42:05.801957 135974886344192 run.py:724] Algo activity_selector step 4800 current loss 0.484177, current_train_items 66208.
I0831 22:42:05.806342 135974886344192 run.py:724] Algo task_scheduling step 4800 current loss 2.101686, current_train_items 66208.
I0831 22:42:05.822212 135974886344192 run.py:759] (val) algo activity_selector step 4800: {'selected': 0.8749999999999999, 'score': 0.8749999999999999, 'examples_seen': 66208, 'step': 4800, 'algorithm': 'activity_selector'}
I0831 22:42:05.829876 135974886344192 run.py:759] (val) algo task_scheduling step 4800: {'selected': 0.9196675900277008, 'score': 0.9196675900277008, 'examples_seen': 66208, 'step': 4800, 'algorithm': 'task_scheduling'}
I0831 22:42:05.830044 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.897, val scores are: activity_selector: 0.875, task_scheduling: 0.920
I0831 22:42:06.837064 135974886344192 run.py:724] Algo activity_selector step 4850 current loss 0.709968, current_train_items 66880.
I0831 22:42:06.841628 135974886344192 run.py:724] Algo task_scheduling step 4850 current loss 1.490403, current_train_items 66880.
I0831 22:42:06.857799 135974886344192 run.py:759] (val) algo activity_selector step 4850: {'selected': 0.9063032367972742, 'score': 0.9063032367972742, 'examples_seen': 66880, 'step': 4850, 'algorithm': 'activity_selector'}
I0831 22:42:06.865428 135974886344192 run.py:759] (val) algo task_scheduling step 4850: {'selected': 0.940517844646606, 'score': 0.940517844646606, 'examples_seen': 66880, 'step': 4850, 'algorithm': 'task_scheduling'}
I0831 22:42:06.865585 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.923, val scores are: activity_selector: 0.906, task_scheduling: 0.941
I0831 22:42:07.891277 135974886344192 run.py:724] Algo activity_selector step 4900 current loss 0.455340, current_train_items 67584.
I0831 22:42:07.895622 135974886344192 run.py:724] Algo task_scheduling step 4900 current loss 1.320514, current_train_items 67584.
I0831 22:42:07.911342 135974886344192 run.py:759] (val) algo activity_selector step 4900: {'selected': 0.9065255731922399, 'score': 0.9065255731922399, 'examples_seen': 67584, 'step': 4900, 'algorithm': 'activity_selector'}
I0831 22:42:07.919026 135974886344192 run.py:759] (val) algo task_scheduling step 4900: {'selected': 0.934065934065934, 'score': 0.934065934065934, 'examples_seen': 67584, 'step': 4900, 'algorithm': 'task_scheduling'}
I0831 22:42:07.919212 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.920, val scores are: activity_selector: 0.907, task_scheduling: 0.934
I0831 22:42:08.969762 135974886344192 run.py:724] Algo activity_selector step 4950 current loss 0.498327, current_train_items 68272.
I0831 22:42:08.974240 135974886344192 run.py:724] Algo task_scheduling step 4950 current loss 1.632694, current_train_items 68272.
I0831 22:42:08.989892 135974886344192 run.py:759] (val) algo activity_selector step 4950: {'selected': 0.8856624319419238, 'score': 0.8856624319419238, 'examples_seen': 68272, 'step': 4950, 'algorithm': 'activity_selector'}
I0831 22:42:08.997557 135974886344192 run.py:759] (val) algo task_scheduling step 4950: {'selected': 0.9294605809128631, 'score': 0.9294605809128631, 'examples_seen': 68272, 'step': 4950, 'algorithm': 'task_scheduling'}
I0831 22:42:08.997735 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.908, val scores are: activity_selector: 0.886, task_scheduling: 0.929
I0831 22:42:10.029896 135974886344192 run.py:724] Algo activity_selector step 5000 current loss 0.756111, current_train_items 68976.
I0831 22:42:10.034238 135974886344192 run.py:724] Algo task_scheduling step 5000 current loss 1.601014, current_train_items 68976.
I0831 22:42:10.049913 135974886344192 run.py:759] (val) algo activity_selector step 5000: {'selected': 0.8942486085343228, 'score': 0.8942486085343228, 'examples_seen': 68976, 'step': 5000, 'algorithm': 'activity_selector'}
I0831 22:42:10.057520 135974886344192 run.py:759] (val) algo task_scheduling step 5000: {'selected': 0.9224489795918368, 'score': 0.9224489795918368, 'examples_seen': 68976, 'step': 5000, 'algorithm': 'task_scheduling'}
I0831 22:42:10.057663 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.908, val scores are: activity_selector: 0.894, task_scheduling: 0.922
I0831 22:42:11.065730 135974886344192 run.py:724] Algo activity_selector step 5050 current loss 1.177722, current_train_items 69648.
I0831 22:42:11.070215 135974886344192 run.py:724] Algo task_scheduling step 5050 current loss 1.615561, current_train_items 69648.
I0831 22:42:11.087352 135974886344192 run.py:759] (val) algo activity_selector step 5050: {'selected': 0.9051383399209486, 'score': 0.9051383399209486, 'examples_seen': 69648, 'step': 5050, 'algorithm': 'activity_selector'}
I0831 22:42:11.094955 135974886344192 run.py:759] (val) algo task_scheduling step 5050: {'selected': 0.9307207837648706, 'score': 0.9307207837648706, 'examples_seen': 69648, 'step': 5050, 'algorithm': 'task_scheduling'}
I0831 22:42:11.095107 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.918, val scores are: activity_selector: 0.905, task_scheduling: 0.931
I0831 22:42:12.135823 135974886344192 run.py:724] Algo activity_selector step 5100 current loss 0.833075, current_train_items 70336.
I0831 22:42:12.140174 135974886344192 run.py:724] Algo task_scheduling step 5100 current loss 1.494731, current_train_items 70336.
I0831 22:42:12.155700 135974886344192 run.py:759] (val) algo activity_selector step 5100: {'selected': 0.8947368421052632, 'score': 0.8947368421052632, 'examples_seen': 70336, 'step': 5100, 'algorithm': 'activity_selector'}
I0831 22:42:12.163131 135974886344192 run.py:759] (val) algo task_scheduling step 5100: {'selected': 0.9072715143428953, 'score': 0.9072715143428953, 'examples_seen': 70336, 'step': 5100, 'algorithm': 'task_scheduling'}
I0831 22:42:12.163270 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.901, val scores are: activity_selector: 0.895, task_scheduling: 0.907
I0831 22:42:13.210408 135974886344192 run.py:724] Algo activity_selector step 5150 current loss 0.622651, current_train_items 71040.
I0831 22:42:13.215100 135974886344192 run.py:724] Algo task_scheduling step 5150 current loss 1.391173, current_train_items 71040.
I0831 22:42:13.231249 135974886344192 run.py:759] (val) algo activity_selector step 5150: {'selected': 0.859375, 'score': 0.859375, 'examples_seen': 71040, 'step': 5150, 'algorithm': 'activity_selector'}
I0831 22:42:13.238828 135974886344192 run.py:759] (val) algo task_scheduling step 5150: {'selected': 0.9181692094313454, 'score': 0.9181692094313454, 'examples_seen': 71040, 'step': 5150, 'algorithm': 'task_scheduling'}
I0831 22:42:13.238979 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.889, val scores are: activity_selector: 0.859, task_scheduling: 0.918
I0831 22:42:14.233116 135974886344192 run.py:724] Algo activity_selector step 5200 current loss 1.347600, current_train_items 71712.
I0831 22:42:14.237684 135974886344192 run.py:724] Algo task_scheduling step 5200 current loss 1.634804, current_train_items 71712.
I0831 22:42:14.253312 135974886344192 run.py:759] (val) algo activity_selector step 5200: {'selected': 0.8678500986193294, 'score': 0.8678500986193294, 'examples_seen': 71712, 'step': 5200, 'algorithm': 'activity_selector'}
I0831 22:42:14.260957 135974886344192 run.py:759] (val) algo task_scheduling step 5200: {'selected': 0.9074818986323411, 'score': 0.9074818986323411, 'examples_seen': 71712, 'step': 5200, 'algorithm': 'task_scheduling'}
I0831 22:42:14.261116 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.888, val scores are: activity_selector: 0.868, task_scheduling: 0.907
I0831 22:42:15.299823 135974886344192 run.py:724] Algo activity_selector step 5250 current loss 0.920444, current_train_items 72400.
I0831 22:42:15.304266 135974886344192 run.py:724] Algo task_scheduling step 5250 current loss 1.435220, current_train_items 72400.
I0831 22:42:15.319544 135974886344192 run.py:759] (val) algo activity_selector step 5250: {'selected': 0.8935361216730038, 'score': 0.8935361216730038, 'examples_seen': 72400, 'step': 5250, 'algorithm': 'activity_selector'}
I0831 22:42:15.327134 135974886344192 run.py:759] (val) algo task_scheduling step 5250: {'selected': 0.9423631123919309, 'score': 0.9423631123919309, 'examples_seen': 72400, 'step': 5250, 'algorithm': 'task_scheduling'}
I0831 22:42:15.327289 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.918, val scores are: activity_selector: 0.894, task_scheduling: 0.942
I0831 22:42:16.372320 135974886344192 run.py:724] Algo activity_selector step 5300 current loss 0.717306, current_train_items 73104.
I0831 22:42:16.376984 135974886344192 run.py:724] Algo task_scheduling step 5300 current loss 1.424582, current_train_items 73104.
I0831 22:42:16.392995 135974886344192 run.py:759] (val) algo activity_selector step 5300: {'selected': 0.8937875751503006, 'score': 0.8937875751503006, 'examples_seen': 73104, 'step': 5300, 'algorithm': 'activity_selector'}
I0831 22:42:16.400580 135974886344192 run.py:759] (val) algo task_scheduling step 5300: {'selected': 0.9335219236209336, 'score': 0.9335219236209336, 'examples_seen': 73104, 'step': 5300, 'algorithm': 'task_scheduling'}
I0831 22:42:16.400720 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.914, val scores are: activity_selector: 0.894, task_scheduling: 0.934
I0831 22:42:17.388741 135974886344192 run.py:724] Algo activity_selector step 5350 current loss 0.793675, current_train_items 73808.
I0831 22:42:17.393133 135974886344192 run.py:724] Algo task_scheduling step 5350 current loss 1.772007, current_train_items 73808.
I0831 22:42:17.409024 135974886344192 run.py:759] (val) algo activity_selector step 5350: {'selected': 0.9104477611940298, 'score': 0.9104477611940298, 'examples_seen': 73808, 'step': 5350, 'algorithm': 'activity_selector'}
I0831 22:42:17.416598 135974886344192 run.py:759] (val) algo task_scheduling step 5350: {'selected': 0.9407566024268381, 'score': 0.9407566024268381, 'examples_seen': 73808, 'step': 5350, 'algorithm': 'task_scheduling'}
I0831 22:42:17.416738 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.926, val scores are: activity_selector: 0.910, task_scheduling: 0.941
I0831 22:42:18.443975 135974886344192 run.py:724] Algo activity_selector step 5400 current loss 1.038921, current_train_items 74464.
I0831 22:42:18.448429 135974886344192 run.py:724] Algo task_scheduling step 5400 current loss 1.094538, current_train_items 74464.
I0831 22:42:18.464209 135974886344192 run.py:759] (val) algo activity_selector step 5400: {'selected': 0.9031007751937984, 'score': 0.9031007751937984, 'examples_seen': 74464, 'step': 5400, 'algorithm': 'activity_selector'}
I0831 22:42:18.471850 135974886344192 run.py:759] (val) algo task_scheduling step 5400: {'selected': 0.9328467153284673, 'score': 0.9328467153284673, 'examples_seen': 74464, 'step': 5400, 'algorithm': 'task_scheduling'}
I0831 22:42:18.472019 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.918, val scores are: activity_selector: 0.903, task_scheduling: 0.933
I0831 22:42:19.513894 135974886344192 run.py:724] Algo activity_selector step 5450 current loss 0.649277, current_train_items 75168.
I0831 22:42:19.518470 135974886344192 run.py:724] Algo task_scheduling step 5450 current loss 1.347381, current_train_items 75168.
I0831 22:42:19.533921 135974886344192 run.py:759] (val) algo activity_selector step 5450: {'selected': 0.876, 'score': 0.876, 'examples_seen': 75168, 'step': 5450, 'algorithm': 'activity_selector'}
I0831 22:42:19.541527 135974886344192 run.py:759] (val) algo task_scheduling step 5450: {'selected': 0.9322990126939352, 'score': 0.9322990126939352, 'examples_seen': 75168, 'step': 5450, 'algorithm': 'task_scheduling'}
I0831 22:42:19.541684 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.904, val scores are: activity_selector: 0.876, task_scheduling: 0.932
I0831 22:42:20.566667 135974886344192 run.py:724] Algo activity_selector step 5500 current loss 0.957134, current_train_items 75872.
I0831 22:42:20.571320 135974886344192 run.py:724] Algo task_scheduling step 5500 current loss 1.998255, current_train_items 75872.
I0831 22:42:20.587425 135974886344192 run.py:759] (val) algo activity_selector step 5500: {'selected': 0.8625954198473282, 'score': 0.8625954198473282, 'examples_seen': 75872, 'step': 5500, 'algorithm': 'activity_selector'}
I0831 22:42:20.594971 135974886344192 run.py:759] (val) algo task_scheduling step 5500: {'selected': 0.9423487544483986, 'score': 0.9423487544483986, 'examples_seen': 75872, 'step': 5500, 'algorithm': 'task_scheduling'}
I0831 22:42:20.595121 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.902, val scores are: activity_selector: 0.863, task_scheduling: 0.942
I0831 22:42:21.600038 135974886344192 run.py:724] Algo activity_selector step 5550 current loss 0.778557, current_train_items 76528.
I0831 22:42:21.604478 135974886344192 run.py:724] Algo task_scheduling step 5550 current loss 1.870763, current_train_items 76528.
I0831 22:42:21.620446 135974886344192 run.py:759] (val) algo activity_selector step 5550: {'selected': 0.9252173913043478, 'score': 0.9252173913043478, 'examples_seen': 76528, 'step': 5550, 'algorithm': 'activity_selector'}
I0831 22:42:21.628021 135974886344192 run.py:759] (val) algo task_scheduling step 5550: {'selected': 0.9114441416893733, 'score': 0.9114441416893733, 'examples_seen': 76528, 'step': 5550, 'algorithm': 'task_scheduling'}
I0831 22:42:21.628160 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.918, val scores are: activity_selector: 0.925, task_scheduling: 0.911
I0831 22:42:22.669103 135974886344192 run.py:724] Algo activity_selector step 5600 current loss 1.143729, current_train_items 77232.
I0831 22:42:22.673334 135974886344192 run.py:724] Algo task_scheduling step 5600 current loss 1.897932, current_train_items 77232.
I0831 22:42:22.689298 135974886344192 run.py:759] (val) algo activity_selector step 5600: {'selected': 0.8693957115009746, 'score': 0.8693957115009746, 'examples_seen': 77232, 'step': 5600, 'algorithm': 'activity_selector'}
I0831 22:42:22.696921 135974886344192 run.py:759] (val) algo task_scheduling step 5600: {'selected': 0.9056347589952478, 'score': 0.9056347589952478, 'examples_seen': 77232, 'step': 5600, 'algorithm': 'task_scheduling'}
I0831 22:42:22.697073 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.888, val scores are: activity_selector: 0.869, task_scheduling: 0.906
I0831 22:42:23.728487 135974886344192 run.py:724] Algo activity_selector step 5650 current loss 0.893229, current_train_items 77936.
I0831 22:42:23.732911 135974886344192 run.py:724] Algo task_scheduling step 5650 current loss 1.272779, current_train_items 77936.
I0831 22:42:23.751304 135974886344192 run.py:759] (val) algo activity_selector step 5650: {'selected': 0.8817204301075269, 'score': 0.8817204301075269, 'examples_seen': 77936, 'step': 5650, 'algorithm': 'activity_selector'}
I0831 22:42:23.758888 135974886344192 run.py:759] (val) algo task_scheduling step 5650: {'selected': 0.914951989026063, 'score': 0.914951989026063, 'examples_seen': 77936, 'step': 5650, 'algorithm': 'task_scheduling'}
I0831 22:42:23.759040 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.898, val scores are: activity_selector: 0.882, task_scheduling: 0.915
I0831 22:42:24.768481 135974886344192 run.py:724] Algo activity_selector step 5700 current loss 1.044243, current_train_items 78608.
I0831 22:42:24.772876 135974886344192 run.py:724] Algo task_scheduling step 5700 current loss 1.140392, current_train_items 78608.
I0831 22:42:24.788863 135974886344192 run.py:759] (val) algo activity_selector step 5700: {'selected': 0.8542914171656686, 'score': 0.8542914171656686, 'examples_seen': 78608, 'step': 5700, 'algorithm': 'activity_selector'}
I0831 22:42:24.796415 135974886344192 run.py:759] (val) algo task_scheduling step 5700: {'selected': 0.9291121816930489, 'score': 0.9291121816930489, 'examples_seen': 78608, 'step': 5700, 'algorithm': 'task_scheduling'}
I0831 22:42:24.796555 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.892, val scores are: activity_selector: 0.854, task_scheduling: 0.929
I0831 22:42:25.851601 135974886344192 run.py:724] Algo activity_selector step 5750 current loss 0.630261, current_train_items 79296.
I0831 22:42:25.855874 135974886344192 run.py:724] Algo task_scheduling step 5750 current loss 1.130611, current_train_items 79296.
I0831 22:42:25.871240 135974886344192 run.py:759] (val) algo activity_selector step 5750: {'selected': 0.8870636550308008, 'score': 0.8870636550308008, 'examples_seen': 79296, 'step': 5750, 'algorithm': 'activity_selector'}
I0831 22:42:25.878781 135974886344192 run.py:759] (val) algo task_scheduling step 5750: {'selected': 0.9276773296244784, 'score': 0.9276773296244784, 'examples_seen': 79296, 'step': 5750, 'algorithm': 'task_scheduling'}
I0831 22:42:25.878920 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.907, val scores are: activity_selector: 0.887, task_scheduling: 0.928
I0831 22:42:26.907265 135974886344192 run.py:724] Algo activity_selector step 5800 current loss 1.159783, current_train_items 80000.
I0831 22:42:26.911378 135974886344192 run.py:724] Algo task_scheduling step 5800 current loss 2.479075, current_train_items 80000.
I0831 22:42:26.929935 135974886344192 run.py:759] (val) algo activity_selector step 5800: {'selected': 0.8686131386861313, 'score': 0.8686131386861313, 'examples_seen': 80000, 'step': 5800, 'algorithm': 'activity_selector'}
I0831 22:42:26.937608 135974886344192 run.py:759] (val) algo task_scheduling step 5800: {'selected': 0.9190839694656489, 'score': 0.9190839694656489, 'examples_seen': 80000, 'step': 5800, 'algorithm': 'task_scheduling'}
I0831 22:42:26.937747 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.894, val scores are: activity_selector: 0.869, task_scheduling: 0.919
I0831 22:42:28.011655 135974886344192 run.py:724] Algo activity_selector step 5850 current loss 0.606286, current_train_items 80688.
I0831 22:42:28.016049 135974886344192 run.py:724] Algo task_scheduling step 5850 current loss 1.443116, current_train_items 80688.
I0831 22:42:28.031692 135974886344192 run.py:759] (val) algo activity_selector step 5850: {'selected': 0.904, 'score': 0.904, 'examples_seen': 80688, 'step': 5850, 'algorithm': 'activity_selector'}
I0831 22:42:28.039270 135974886344192 run.py:759] (val) algo task_scheduling step 5850: {'selected': 0.9348604151753759, 'score': 0.9348604151753759, 'examples_seen': 80688, 'step': 5850, 'algorithm': 'task_scheduling'}
I0831 22:42:28.039414 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.919, val scores are: activity_selector: 0.904, task_scheduling: 0.935
I0831 22:42:29.068378 135974886344192 run.py:724] Algo activity_selector step 5900 current loss 0.621883, current_train_items 81360.
I0831 22:42:29.072882 135974886344192 run.py:724] Algo task_scheduling step 5900 current loss 1.468566, current_train_items 81360.
I0831 22:42:29.090115 135974886344192 run.py:759] (val) algo activity_selector step 5900: {'selected': 0.9012567324955116, 'score': 0.9012567324955116, 'examples_seen': 81360, 'step': 5900, 'algorithm': 'activity_selector'}
I0831 22:42:29.097900 135974886344192 run.py:759] (val) algo task_scheduling step 5900: {'selected': 0.9360505973295854, 'score': 0.9360505973295854, 'examples_seen': 81360, 'step': 5900, 'algorithm': 'task_scheduling'}
I0831 22:42:29.098051 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.919, val scores are: activity_selector: 0.901, task_scheduling: 0.936
I0831 22:42:30.125966 135974886344192 run.py:724] Algo activity_selector step 5950 current loss 0.793461, current_train_items 82064.
I0831 22:42:30.130672 135974886344192 run.py:724] Algo task_scheduling step 5950 current loss 1.180152, current_train_items 82064.
I0831 22:42:30.146826 135974886344192 run.py:759] (val) algo activity_selector step 5950: {'selected': 0.8759398496240601, 'score': 0.8759398496240601, 'examples_seen': 82064, 'step': 5950, 'algorithm': 'activity_selector'}
I0831 22:42:30.154423 135974886344192 run.py:759] (val) algo task_scheduling step 5950: {'selected': 0.9347496206373294, 'score': 0.9347496206373294, 'examples_seen': 82064, 'step': 5950, 'algorithm': 'task_scheduling'}
I0831 22:42:30.154566 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.905, val scores are: activity_selector: 0.876, task_scheduling: 0.935
I0831 22:42:31.204181 135974886344192 run.py:724] Algo activity_selector step 6000 current loss 0.482545, current_train_items 82752.
I0831 22:42:31.208548 135974886344192 run.py:724] Algo task_scheduling step 6000 current loss 1.949847, current_train_items 82752.
I0831 22:42:31.224854 135974886344192 run.py:759] (val) algo activity_selector step 6000: {'selected': 0.9090909090909092, 'score': 0.9090909090909092, 'examples_seen': 82752, 'step': 6000, 'algorithm': 'activity_selector'}
I0831 22:42:31.232489 135974886344192 run.py:759] (val) algo task_scheduling step 6000: {'selected': 0.938712179984484, 'score': 0.938712179984484, 'examples_seen': 82752, 'step': 6000, 'algorithm': 'task_scheduling'}
I0831 22:42:31.232631 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.924, val scores are: activity_selector: 0.909, task_scheduling: 0.939
I0831 22:42:32.239032 135974886344192 run.py:724] Algo activity_selector step 6050 current loss 0.642888, current_train_items 83440.
I0831 22:42:32.243478 135974886344192 run.py:724] Algo task_scheduling step 6050 current loss 1.966178, current_train_items 83440.
I0831 22:42:32.262411 135974886344192 run.py:759] (val) algo activity_selector step 6050: {'selected': 0.8677042801556419, 'score': 0.8677042801556419, 'examples_seen': 83440, 'step': 6050, 'algorithm': 'activity_selector'}
I0831 22:42:32.270029 135974886344192 run.py:759] (val) algo task_scheduling step 6050: {'selected': 0.8868778280542986, 'score': 0.8868778280542986, 'examples_seen': 83440, 'step': 6050, 'algorithm': 'task_scheduling'}
I0831 22:42:32.270170 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.877, val scores are: activity_selector: 0.868, task_scheduling: 0.887
I0831 22:42:33.298750 135974886344192 run.py:724] Algo activity_selector step 6100 current loss 0.800731, current_train_items 84128.
I0831 22:42:33.303096 135974886344192 run.py:724] Algo task_scheduling step 6100 current loss 1.098115, current_train_items 84128.
I0831 22:42:33.319023 135974886344192 run.py:759] (val) algo activity_selector step 6100: {'selected': 0.8718929254302104, 'score': 0.8718929254302104, 'examples_seen': 84128, 'step': 6100, 'algorithm': 'activity_selector'}
I0831 22:42:33.326588 135974886344192 run.py:759] (val) algo task_scheduling step 6100: {'selected': 0.9165526675786593, 'score': 0.9165526675786593, 'examples_seen': 84128, 'step': 6100, 'algorithm': 'task_scheduling'}
I0831 22:42:33.326731 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.894, val scores are: activity_selector: 0.872, task_scheduling: 0.917
I0831 22:42:34.364886 135974886344192 run.py:724] Algo activity_selector step 6150 current loss 0.869303, current_train_items 84816.
I0831 22:42:34.369433 135974886344192 run.py:724] Algo task_scheduling step 6150 current loss 2.035542, current_train_items 84816.
I0831 22:42:34.385887 135974886344192 run.py:759] (val) algo activity_selector step 6150: {'selected': 0.8485981308411213, 'score': 0.8485981308411213, 'examples_seen': 84816, 'step': 6150, 'algorithm': 'activity_selector'}
I0831 22:42:34.393527 135974886344192 run.py:759] (val) algo task_scheduling step 6150: {'selected': 0.9426399447131998, 'score': 0.9426399447131998, 'examples_seen': 84816, 'step': 6150, 'algorithm': 'task_scheduling'}
I0831 22:42:34.393669 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.896, val scores are: activity_selector: 0.849, task_scheduling: 0.943
I0831 22:42:35.421427 135974886344192 run.py:724] Algo activity_selector step 6200 current loss 0.672070, current_train_items 85520.
I0831 22:42:35.425753 135974886344192 run.py:724] Algo task_scheduling step 6200 current loss 1.543529, current_train_items 85520.
I0831 22:42:35.441437 135974886344192 run.py:759] (val) algo activity_selector step 6200: {'selected': 0.8742004264392325, 'score': 0.8742004264392325, 'examples_seen': 85520, 'step': 6200, 'algorithm': 'activity_selector'}
I0831 22:42:35.449013 135974886344192 run.py:759] (val) algo task_scheduling step 6200: {'selected': 0.8956228956228957, 'score': 0.8956228956228957, 'examples_seen': 85520, 'step': 6200, 'algorithm': 'task_scheduling'}
I0831 22:42:35.449155 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.885, val scores are: activity_selector: 0.874, task_scheduling: 0.896
I0831 22:42:36.464143 135974886344192 run.py:724] Algo activity_selector step 6250 current loss 0.717497, current_train_items 86192.
I0831 22:42:36.468758 135974886344192 run.py:724] Algo task_scheduling step 6250 current loss 1.868977, current_train_items 86192.
I0831 22:42:36.484572 135974886344192 run.py:759] (val) algo activity_selector step 6250: {'selected': 0.8954128440366973, 'score': 0.8954128440366973, 'examples_seen': 86192, 'step': 6250, 'algorithm': 'activity_selector'}
I0831 22:42:36.492151 135974886344192 run.py:759] (val) algo task_scheduling step 6250: {'selected': 0.9328519855595667, 'score': 0.9328519855595667, 'examples_seen': 86192, 'step': 6250, 'algorithm': 'task_scheduling'}
I0831 22:42:36.492293 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.914, val scores are: activity_selector: 0.895, task_scheduling: 0.933
I0831 22:42:37.531001 135974886344192 run.py:724] Algo activity_selector step 6300 current loss 0.757420, current_train_items 86880.
I0831 22:42:37.535811 135974886344192 run.py:724] Algo task_scheduling step 6300 current loss 1.466951, current_train_items 86880.
I0831 22:42:37.551449 135974886344192 run.py:759] (val) algo activity_selector step 6300: {'selected': 0.9131238447319777, 'score': 0.9131238447319777, 'examples_seen': 86880, 'step': 6300, 'algorithm': 'activity_selector'}
I0831 22:42:37.559073 135974886344192 run.py:759] (val) algo task_scheduling step 6300: {'selected': 0.9158751696065129, 'score': 0.9158751696065129, 'examples_seen': 86880, 'step': 6300, 'algorithm': 'task_scheduling'}
I0831 22:42:37.559218 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.914, val scores are: activity_selector: 0.913, task_scheduling: 0.916
I0831 22:42:38.609786 135974886344192 run.py:724] Algo activity_selector step 6350 current loss 0.378877, current_train_items 87584.
I0831 22:42:38.614164 135974886344192 run.py:724] Algo task_scheduling step 6350 current loss 0.959139, current_train_items 87584.
I0831 22:42:38.631958 135974886344192 run.py:759] (val) algo activity_selector step 6350: {'selected': 0.8897485493230174, 'score': 0.8897485493230174, 'examples_seen': 87584, 'step': 6350, 'algorithm': 'activity_selector'}
I0831 22:42:38.639511 135974886344192 run.py:759] (val) algo task_scheduling step 6350: {'selected': 0.9290495314591699, 'score': 0.9290495314591699, 'examples_seen': 87584, 'step': 6350, 'algorithm': 'task_scheduling'}
I0831 22:42:38.639651 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.909, val scores are: activity_selector: 0.890, task_scheduling: 0.929
I0831 22:42:39.635635 135974886344192 run.py:724] Algo activity_selector step 6400 current loss 0.831907, current_train_items 88272.
I0831 22:42:39.640070 135974886344192 run.py:724] Algo task_scheduling step 6400 current loss 1.202406, current_train_items 88272.
I0831 22:42:39.655909 135974886344192 run.py:759] (val) algo activity_selector step 6400: {'selected': 0.9066147859922179, 'score': 0.9066147859922179, 'examples_seen': 88272, 'step': 6400, 'algorithm': 'activity_selector'}
I0831 22:42:39.663456 135974886344192 run.py:759] (val) algo task_scheduling step 6400: {'selected': 0.9300699300699299, 'score': 0.9300699300699299, 'examples_seen': 88272, 'step': 6400, 'algorithm': 'task_scheduling'}
I0831 22:42:39.663597 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.918, val scores are: activity_selector: 0.907, task_scheduling: 0.930
I0831 22:42:40.700664 135974886344192 run.py:724] Algo activity_selector step 6450 current loss 0.817887, current_train_items 88944.
I0831 22:42:40.705122 135974886344192 run.py:724] Algo task_scheduling step 6450 current loss 1.678165, current_train_items 88944.
I0831 22:42:40.720325 135974886344192 run.py:759] (val) algo activity_selector step 6450: {'selected': 0.8790786948176583, 'score': 0.8790786948176583, 'examples_seen': 88944, 'step': 6450, 'algorithm': 'activity_selector'}
I0831 22:42:40.727858 135974886344192 run.py:759] (val) algo task_scheduling step 6450: {'selected': 0.9336219336219336, 'score': 0.9336219336219336, 'examples_seen': 88944, 'step': 6450, 'algorithm': 'task_scheduling'}
I0831 22:42:40.728006 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.906, val scores are: activity_selector: 0.879, task_scheduling: 0.934
I0831 22:42:41.770647 135974886344192 run.py:724] Algo activity_selector step 6500 current loss 0.930493, current_train_items 89648.
I0831 22:42:41.775300 135974886344192 run.py:724] Algo task_scheduling step 6500 current loss 1.383787, current_train_items 89648.
I0831 22:42:41.791213 135974886344192 run.py:759] (val) algo activity_selector step 6500: {'selected': 0.8489932885906041, 'score': 0.8489932885906041, 'examples_seen': 89648, 'step': 6500, 'algorithm': 'activity_selector'}
I0831 22:42:41.798778 135974886344192 run.py:759] (val) algo task_scheduling step 6500: {'selected': 0.9431137724550899, 'score': 0.9431137724550899, 'examples_seen': 89648, 'step': 6500, 'algorithm': 'task_scheduling'}
I0831 22:42:41.798918 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.896, val scores are: activity_selector: 0.849, task_scheduling: 0.943
I0831 22:42:42.807231 135974886344192 run.py:724] Algo activity_selector step 6550 current loss 0.862436, current_train_items 90336.
I0831 22:42:42.811633 135974886344192 run.py:724] Algo task_scheduling step 6550 current loss 1.156320, current_train_items 90336.
I0831 22:42:42.827322 135974886344192 run.py:759] (val) algo activity_selector step 6550: {'selected': 0.878228782287823, 'score': 0.878228782287823, 'examples_seen': 90336, 'step': 6550, 'algorithm': 'activity_selector'}
I0831 22:42:42.834842 135974886344192 run.py:759] (val) algo task_scheduling step 6550: {'selected': 0.9397923875432526, 'score': 0.9397923875432526, 'examples_seen': 90336, 'step': 6550, 'algorithm': 'task_scheduling'}
I0831 22:42:42.834989 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.909, val scores are: activity_selector: 0.878, task_scheduling: 0.940
I0831 22:42:43.867014 135974886344192 run.py:724] Algo activity_selector step 6600 current loss 0.441270, current_train_items 91008.
I0831 22:42:43.871518 135974886344192 run.py:724] Algo task_scheduling step 6600 current loss 1.496309, current_train_items 91008.
I0831 22:42:43.887096 135974886344192 run.py:759] (val) algo activity_selector step 6600: {'selected': 0.9097744360902255, 'score': 0.9097744360902255, 'examples_seen': 91008, 'step': 6600, 'algorithm': 'activity_selector'}
I0831 22:42:43.894643 135974886344192 run.py:759] (val) algo task_scheduling step 6600: {'selected': 0.9263157894736843, 'score': 0.9263157894736843, 'examples_seen': 91008, 'step': 6600, 'algorithm': 'task_scheduling'}
I0831 22:42:43.894787 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.918, val scores are: activity_selector: 0.910, task_scheduling: 0.926
I0831 22:42:44.938993 135974886344192 run.py:724] Algo activity_selector step 6650 current loss 0.464375, current_train_items 91712.
I0831 22:42:44.943452 135974886344192 run.py:724] Algo task_scheduling step 6650 current loss 1.254385, current_train_items 91712.
I0831 22:42:44.959069 135974886344192 run.py:759] (val) algo activity_selector step 6650: {'selected': 0.8808080808080808, 'score': 0.8808080808080808, 'examples_seen': 91712, 'step': 6650, 'algorithm': 'activity_selector'}
I0831 22:42:44.966630 135974886344192 run.py:759] (val) algo task_scheduling step 6650: {'selected': 0.9408147578785551, 'score': 0.9408147578785551, 'examples_seen': 91712, 'step': 6650, 'algorithm': 'task_scheduling'}
I0831 22:42:44.966773 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.911, val scores are: activity_selector: 0.881, task_scheduling: 0.941
I0831 22:42:46.004619 135974886344192 run.py:724] Algo activity_selector step 6700 current loss 0.729380, current_train_items 92416.
I0831 22:42:46.009296 135974886344192 run.py:724] Algo task_scheduling step 6700 current loss 1.081043, current_train_items 92416.
I0831 22:42:46.024792 135974886344192 run.py:759] (val) algo activity_selector step 6700: {'selected': 0.9186046511627907, 'score': 0.9186046511627907, 'examples_seen': 92416, 'step': 6700, 'algorithm': 'activity_selector'}
I0831 22:42:46.032406 135974886344192 run.py:759] (val) algo task_scheduling step 6700: {'selected': 0.9373297002724795, 'score': 0.9373297002724795, 'examples_seen': 92416, 'step': 6700, 'algorithm': 'task_scheduling'}
I0831 22:42:46.032550 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.928, val scores are: activity_selector: 0.919, task_scheduling: 0.937
I0831 22:42:47.044785 135974886344192 run.py:724] Algo activity_selector step 6750 current loss 0.963063, current_train_items 93088.
I0831 22:42:47.049243 135974886344192 run.py:724] Algo task_scheduling step 6750 current loss 1.012794, current_train_items 93088.
I0831 22:42:47.065545 135974886344192 run.py:759] (val) algo activity_selector step 6750: {'selected': 0.8893360160965795, 'score': 0.8893360160965795, 'examples_seen': 93088, 'step': 6750, 'algorithm': 'activity_selector'}
I0831 22:42:47.073119 135974886344192 run.py:759] (val) algo task_scheduling step 6750: {'selected': 0.9318341531974701, 'score': 0.9318341531974701, 'examples_seen': 93088, 'step': 6750, 'algorithm': 'task_scheduling'}
I0831 22:42:47.073262 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.911, val scores are: activity_selector: 0.889, task_scheduling: 0.932
I0831 22:42:48.119414 135974886344192 run.py:724] Algo activity_selector step 6800 current loss 0.516310, current_train_items 93776.
I0831 22:42:48.123949 135974886344192 run.py:724] Algo task_scheduling step 6800 current loss 1.466620, current_train_items 93776.
I0831 22:42:48.139237 135974886344192 run.py:759] (val) algo activity_selector step 6800: {'selected': 0.8846153846153847, 'score': 0.8846153846153847, 'examples_seen': 93776, 'step': 6800, 'algorithm': 'activity_selector'}
I0831 22:42:48.146785 135974886344192 run.py:759] (val) algo task_scheduling step 6800: {'selected': 0.9494661921708184, 'score': 0.9494661921708184, 'examples_seen': 93776, 'step': 6800, 'algorithm': 'task_scheduling'}
I0831 22:42:48.146925 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.917, val scores are: activity_selector: 0.885, task_scheduling: 0.949
I0831 22:42:49.181303 135974886344192 run.py:724] Algo activity_selector step 6850 current loss 0.494987, current_train_items 94480.
I0831 22:42:49.185750 135974886344192 run.py:724] Algo task_scheduling step 6850 current loss 0.902645, current_train_items 94480.
I0831 22:42:49.202266 135974886344192 run.py:759] (val) algo activity_selector step 6850: {'selected': 0.9053803339517625, 'score': 0.9053803339517625, 'examples_seen': 94480, 'step': 6850, 'algorithm': 'activity_selector'}
I0831 22:42:49.209873 135974886344192 run.py:759] (val) algo task_scheduling step 6850: {'selected': 0.8991315965263861, 'score': 0.8991315965263861, 'examples_seen': 94480, 'step': 6850, 'algorithm': 'task_scheduling'}
I0831 22:42:49.210022 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.902, val scores are: activity_selector: 0.905, task_scheduling: 0.899
I0831 22:42:50.233647 135974886344192 run.py:724] Algo activity_selector step 6900 current loss 0.477394, current_train_items 95152.
I0831 22:42:50.238584 135974886344192 run.py:724] Algo task_scheduling step 6900 current loss 1.315720, current_train_items 95152.
I0831 22:42:50.253693 135974886344192 run.py:759] (val) algo activity_selector step 6900: {'selected': 0.9026217228464419, 'score': 0.9026217228464419, 'examples_seen': 95152, 'step': 6900, 'algorithm': 'activity_selector'}
I0831 22:42:50.261254 135974886344192 run.py:759] (val) algo task_scheduling step 6900: {'selected': 0.902834008097166, 'score': 0.902834008097166, 'examples_seen': 95152, 'step': 6900, 'algorithm': 'task_scheduling'}
I0831 22:42:50.261398 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.903, val scores are: activity_selector: 0.903, task_scheduling: 0.903
I0831 22:42:51.289225 135974886344192 run.py:724] Algo activity_selector step 6950 current loss 0.859807, current_train_items 95840.
I0831 22:42:51.293579 135974886344192 run.py:724] Algo task_scheduling step 6950 current loss 1.893100, current_train_items 95840.
I0831 22:42:51.309688 135974886344192 run.py:759] (val) algo activity_selector step 6950: {'selected': 0.8943396226415095, 'score': 0.8943396226415095, 'examples_seen': 95840, 'step': 6950, 'algorithm': 'activity_selector'}
I0831 22:42:51.317259 135974886344192 run.py:759] (val) algo task_scheduling step 6950: {'selected': 0.9397590361445785, 'score': 0.9397590361445785, 'examples_seen': 95840, 'step': 6950, 'algorithm': 'task_scheduling'}
I0831 22:42:51.317398 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.917, val scores are: activity_selector: 0.894, task_scheduling: 0.940
I0831 22:42:52.341421 135974886344192 run.py:724] Algo activity_selector step 7000 current loss 0.486979, current_train_items 96544.
I0831 22:42:52.345908 135974886344192 run.py:724] Algo task_scheduling step 7000 current loss 1.389020, current_train_items 96544.
I0831 22:42:52.361485 135974886344192 run.py:759] (val) algo activity_selector step 7000: {'selected': 0.920892494929006, 'score': 0.920892494929006, 'examples_seen': 96544, 'step': 7000, 'algorithm': 'activity_selector'}
I0831 22:42:52.369153 135974886344192 run.py:759] (val) algo task_scheduling step 7000: {'selected': 0.94018296973962, 'score': 0.94018296973962, 'examples_seen': 96544, 'step': 7000, 'algorithm': 'task_scheduling'}
I0831 22:42:52.369294 135974886344192 run.py:780] Checkpointing best model, best avg val score was 0.928, current avg val score is 0.931, val scores are: activity_selector: 0.921, task_scheduling: 0.940
I0831 22:42:53.413543 135974886344192 run.py:724] Algo activity_selector step 7050 current loss 0.525005, current_train_items 97232.
I0831 22:42:53.417943 135974886344192 run.py:724] Algo task_scheduling step 7050 current loss 1.802290, current_train_items 97232.
I0831 22:42:53.433227 135974886344192 run.py:759] (val) algo activity_selector step 7050: {'selected': 0.9029850746268656, 'score': 0.9029850746268656, 'examples_seen': 97232, 'step': 7050, 'algorithm': 'activity_selector'}
I0831 22:42:53.440801 135974886344192 run.py:759] (val) algo task_scheduling step 7050: {'selected': 0.9150237933378653, 'score': 0.9150237933378653, 'examples_seen': 97232, 'step': 7050, 'algorithm': 'task_scheduling'}
I0831 22:42:53.440948 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.909, val scores are: activity_selector: 0.903, task_scheduling: 0.915
I0831 22:42:54.471180 135974886344192 run.py:724] Algo activity_selector step 7100 current loss 0.549657, current_train_items 97920.
I0831 22:42:54.475524 135974886344192 run.py:724] Algo task_scheduling step 7100 current loss 2.345315, current_train_items 97920.
I0831 22:42:54.491364 135974886344192 run.py:759] (val) algo activity_selector step 7100: {'selected': 0.8804159445407279, 'score': 0.8804159445407279, 'examples_seen': 97920, 'step': 7100, 'algorithm': 'activity_selector'}
I0831 22:42:54.498954 135974886344192 run.py:759] (val) algo task_scheduling step 7100: {'selected': 0.914780292942743, 'score': 0.914780292942743, 'examples_seen': 97920, 'step': 7100, 'algorithm': 'task_scheduling'}
I0831 22:42:54.499097 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.898, val scores are: activity_selector: 0.880, task_scheduling: 0.915
I0831 22:42:55.524435 135974886344192 run.py:724] Algo activity_selector step 7150 current loss 0.732834, current_train_items 98608.
I0831 22:42:55.528858 135974886344192 run.py:724] Algo task_scheduling step 7150 current loss 1.459681, current_train_items 98608.
I0831 22:42:55.544620 135974886344192 run.py:759] (val) algo activity_selector step 7150: {'selected': 0.8593448940269749, 'score': 0.8593448940269749, 'examples_seen': 98608, 'step': 7150, 'algorithm': 'activity_selector'}
I0831 22:42:55.552280 135974886344192 run.py:759] (val) algo task_scheduling step 7150: {'selected': 0.9504249291784702, 'score': 0.9504249291784702, 'examples_seen': 98608, 'step': 7150, 'algorithm': 'task_scheduling'}
I0831 22:42:55.552437 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.905, val scores are: activity_selector: 0.859, task_scheduling: 0.950
I0831 22:42:56.601918 135974886344192 run.py:724] Algo activity_selector step 7200 current loss 0.578504, current_train_items 99296.
I0831 22:42:56.606338 135974886344192 run.py:724] Algo task_scheduling step 7200 current loss 1.052355, current_train_items 99296.
I0831 22:42:56.621666 135974886344192 run.py:759] (val) algo activity_selector step 7200: {'selected': 0.8902195608782435, 'score': 0.8902195608782435, 'examples_seen': 99296, 'step': 7200, 'algorithm': 'activity_selector'}
I0831 22:42:56.629269 135974886344192 run.py:759] (val) algo task_scheduling step 7200: {'selected': 0.9411764705882354, 'score': 0.9411764705882354, 'examples_seen': 99296, 'step': 7200, 'algorithm': 'task_scheduling'}
I0831 22:42:56.629426 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.916, val scores are: activity_selector: 0.890, task_scheduling: 0.941
I0831 22:42:57.655735 135974886344192 run.py:724] Algo activity_selector step 7250 current loss 0.458013, current_train_items 99984.
I0831 22:42:57.660249 135974886344192 run.py:724] Algo task_scheduling step 7250 current loss 2.297250, current_train_items 99984.
I0831 22:42:57.676023 135974886344192 run.py:759] (val) algo activity_selector step 7250: {'selected': 0.8992537313432836, 'score': 0.8992537313432836, 'examples_seen': 99984, 'step': 7250, 'algorithm': 'activity_selector'}
I0831 22:42:57.683613 135974886344192 run.py:759] (val) algo task_scheduling step 7250: {'selected': 0.8985313751668892, 'score': 0.8985313751668892, 'examples_seen': 99984, 'step': 7250, 'algorithm': 'task_scheduling'}
I0831 22:42:57.683767 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.899, val scores are: activity_selector: 0.899, task_scheduling: 0.899
I0831 22:42:58.698311 135974886344192 run.py:724] Algo activity_selector step 7300 current loss 0.687627, current_train_items 100672.
I0831 22:42:58.702505 135974886344192 run.py:724] Algo task_scheduling step 7300 current loss 0.930094, current_train_items 100672.
I0831 22:42:58.718679 135974886344192 run.py:759] (val) algo activity_selector step 7300: {'selected': 0.8867924528301887, 'score': 0.8867924528301887, 'examples_seen': 100672, 'step': 7300, 'algorithm': 'activity_selector'}
I0831 22:42:58.726408 135974886344192 run.py:759] (val) algo task_scheduling step 7300: {'selected': 0.9368863955119217, 'score': 0.9368863955119217, 'examples_seen': 100672, 'step': 7300, 'algorithm': 'task_scheduling'}
I0831 22:42:58.726560 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.912, val scores are: activity_selector: 0.887, task_scheduling: 0.937
I0831 22:42:59.765761 135974886344192 run.py:724] Algo activity_selector step 7350 current loss 1.296720, current_train_items 101360.
I0831 22:42:59.770051 135974886344192 run.py:724] Algo task_scheduling step 7350 current loss 1.296953, current_train_items 101360.
I0831 22:42:59.785407 135974886344192 run.py:759] (val) algo activity_selector step 7350: {'selected': 0.896551724137931, 'score': 0.896551724137931, 'examples_seen': 101360, 'step': 7350, 'algorithm': 'activity_selector'}
I0831 22:42:59.793020 135974886344192 run.py:759] (val) algo task_scheduling step 7350: {'selected': 0.9074074074074074, 'score': 0.9074074074074074, 'examples_seen': 101360, 'step': 7350, 'algorithm': 'task_scheduling'}
I0831 22:42:59.793174 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.902, val scores are: activity_selector: 0.897, task_scheduling: 0.907
I0831 22:43:00.812657 135974886344192 run.py:724] Algo activity_selector step 7400 current loss 0.660323, current_train_items 102048.
I0831 22:43:00.817045 135974886344192 run.py:724] Algo task_scheduling step 7400 current loss 1.321632, current_train_items 102048.
I0831 22:43:00.832778 135974886344192 run.py:759] (val) algo activity_selector step 7400: {'selected': 0.8710280373831777, 'score': 0.8710280373831777, 'examples_seen': 102048, 'step': 7400, 'algorithm': 'activity_selector'}
I0831 22:43:00.840290 135974886344192 run.py:759] (val) algo task_scheduling step 7400: {'selected': 0.925575101488498, 'score': 0.925575101488498, 'examples_seen': 102048, 'step': 7400, 'algorithm': 'task_scheduling'}
I0831 22:43:00.840432 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.898, val scores are: activity_selector: 0.871, task_scheduling: 0.926
I0831 22:43:01.854840 135974886344192 run.py:724] Algo activity_selector step 7450 current loss 0.619486, current_train_items 102752.
I0831 22:43:01.859286 135974886344192 run.py:724] Algo task_scheduling step 7450 current loss 1.049030, current_train_items 102752.
I0831 22:43:01.874516 135974886344192 run.py:759] (val) algo activity_selector step 7450: {'selected': 0.8877192982456141, 'score': 0.8877192982456141, 'examples_seen': 102752, 'step': 7450, 'algorithm': 'activity_selector'}
I0831 22:43:01.882082 135974886344192 run.py:759] (val) algo task_scheduling step 7450: {'selected': 0.9372325249643367, 'score': 0.9372325249643367, 'examples_seen': 102752, 'step': 7450, 'algorithm': 'task_scheduling'}
I0831 22:43:01.882225 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.912, val scores are: activity_selector: 0.888, task_scheduling: 0.937
I0831 22:43:02.916378 135974886344192 run.py:724] Algo activity_selector step 7500 current loss 0.728713, current_train_items 103424.
I0831 22:43:02.920852 135974886344192 run.py:724] Algo task_scheduling step 7500 current loss 1.363451, current_train_items 103424.
I0831 22:43:02.937334 135974886344192 run.py:759] (val) algo activity_selector step 7500: {'selected': 0.903914590747331, 'score': 0.903914590747331, 'examples_seen': 103424, 'step': 7500, 'algorithm': 'activity_selector'}
I0831 22:43:02.945073 135974886344192 run.py:759] (val) algo task_scheduling step 7500: {'selected': 0.9433962264150942, 'score': 0.9433962264150942, 'examples_seen': 103424, 'step': 7500, 'algorithm': 'task_scheduling'}
I0831 22:43:02.945218 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.924, val scores are: activity_selector: 0.904, task_scheduling: 0.943
I0831 22:43:03.990261 135974886344192 run.py:724] Algo activity_selector step 7550 current loss 0.635514, current_train_items 104128.
I0831 22:43:03.994688 135974886344192 run.py:724] Algo task_scheduling step 7550 current loss 1.367402, current_train_items 104128.
I0831 22:43:04.010591 135974886344192 run.py:759] (val) algo activity_selector step 7550: {'selected': 0.872865275142315, 'score': 0.872865275142315, 'examples_seen': 104128, 'step': 7550, 'algorithm': 'activity_selector'}
I0831 22:43:04.018163 135974886344192 run.py:759] (val) algo task_scheduling step 7550: {'selected': 0.9441696113074205, 'score': 0.9441696113074205, 'examples_seen': 104128, 'step': 7550, 'algorithm': 'task_scheduling'}
I0831 22:43:04.018318 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.909, val scores are: activity_selector: 0.873, task_scheduling: 0.944
I0831 22:43:05.048265 135974886344192 run.py:724] Algo activity_selector step 7600 current loss 0.669697, current_train_items 104816.
I0831 22:43:05.052811 135974886344192 run.py:724] Algo task_scheduling step 7600 current loss 0.702925, current_train_items 104816.
I0831 22:43:05.068374 135974886344192 run.py:759] (val) algo activity_selector step 7600: {'selected': 0.8985507246376812, 'score': 0.8985507246376812, 'examples_seen': 104816, 'step': 7600, 'algorithm': 'activity_selector'}
I0831 22:43:05.075967 135974886344192 run.py:759] (val) algo task_scheduling step 7600: {'selected': 0.9415904292751583, 'score': 0.9415904292751583, 'examples_seen': 104816, 'step': 7600, 'algorithm': 'task_scheduling'}
I0831 22:43:05.076113 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.920, val scores are: activity_selector: 0.899, task_scheduling: 0.942
I0831 22:43:06.106178 135974886344192 run.py:724] Algo activity_selector step 7650 current loss 0.549155, current_train_items 105488.
I0831 22:43:06.110807 135974886344192 run.py:724] Algo task_scheduling step 7650 current loss 1.373556, current_train_items 105488.
I0831 22:43:06.129399 135974886344192 run.py:759] (val) algo activity_selector step 7650: {'selected': 0.9029850746268657, 'score': 0.9029850746268657, 'examples_seen': 105488, 'step': 7650, 'algorithm': 'activity_selector'}
I0831 22:43:06.136949 135974886344192 run.py:759] (val) algo task_scheduling step 7650: {'selected': 0.9505376344086022, 'score': 0.9505376344086022, 'examples_seen': 105488, 'step': 7650, 'algorithm': 'task_scheduling'}
I0831 22:43:06.137091 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.927, val scores are: activity_selector: 0.903, task_scheduling: 0.951
I0831 22:43:07.184633 135974886344192 run.py:724] Algo activity_selector step 7700 current loss 0.432994, current_train_items 106192.
I0831 22:43:07.189123 135974886344192 run.py:724] Algo task_scheduling step 7700 current loss 1.146839, current_train_items 106192.
I0831 22:43:07.204813 135974886344192 run.py:759] (val) algo activity_selector step 7700: {'selected': 0.9015151515151516, 'score': 0.9015151515151516, 'examples_seen': 106192, 'step': 7700, 'algorithm': 'activity_selector'}
I0831 22:43:07.212409 135974886344192 run.py:759] (val) algo task_scheduling step 7700: {'selected': 0.9538904899135446, 'score': 0.9538904899135446, 'examples_seen': 106192, 'step': 7700, 'algorithm': 'task_scheduling'}
I0831 22:43:07.212552 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.928, val scores are: activity_selector: 0.902, task_scheduling: 0.954
I0831 22:43:08.213035 135974886344192 run.py:724] Algo activity_selector step 7750 current loss 1.445187, current_train_items 106880.
I0831 22:43:08.217520 135974886344192 run.py:724] Algo task_scheduling step 7750 current loss 1.510206, current_train_items 106880.
I0831 22:43:08.233587 135974886344192 run.py:759] (val) algo activity_selector step 7750: {'selected': 0.876, 'score': 0.876, 'examples_seen': 106880, 'step': 7750, 'algorithm': 'activity_selector'}
I0831 22:43:08.241181 135974886344192 run.py:759] (val) algo task_scheduling step 7750: {'selected': 0.887434554973822, 'score': 0.887434554973822, 'examples_seen': 106880, 'step': 7750, 'algorithm': 'task_scheduling'}
I0831 22:43:08.241325 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.882, val scores are: activity_selector: 0.876, task_scheduling: 0.887
I0831 22:43:09.276547 135974886344192 run.py:724] Algo activity_selector step 7800 current loss 0.731998, current_train_items 107568.
I0831 22:43:09.280903 135974886344192 run.py:724] Algo task_scheduling step 7800 current loss 1.658957, current_train_items 107568.
I0831 22:43:09.297189 135974886344192 run.py:759] (val) algo activity_selector step 7800: {'selected': 0.8528864059590318, 'score': 0.8528864059590318, 'examples_seen': 107568, 'step': 7800, 'algorithm': 'activity_selector'}
I0831 22:43:09.304730 135974886344192 run.py:759] (val) algo task_scheduling step 7800: {'selected': 0.9516245487364621, 'score': 0.9516245487364621, 'examples_seen': 107568, 'step': 7800, 'algorithm': 'task_scheduling'}
I0831 22:43:09.304871 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.902, val scores are: activity_selector: 0.853, task_scheduling: 0.952
I0831 22:43:10.349885 135974886344192 run.py:724] Algo activity_selector step 7850 current loss 0.727285, current_train_items 108256.
I0831 22:43:10.354504 135974886344192 run.py:724] Algo task_scheduling step 7850 current loss 1.325759, current_train_items 108256.
I0831 22:43:10.370040 135974886344192 run.py:759] (val) algo activity_selector step 7850: {'selected': 0.9045801526717557, 'score': 0.9045801526717557, 'examples_seen': 108256, 'step': 7850, 'algorithm': 'activity_selector'}
I0831 22:43:10.377537 135974886344192 run.py:759] (val) algo task_scheduling step 7850: {'selected': 0.9247168554297135, 'score': 0.9247168554297135, 'examples_seen': 108256, 'step': 7850, 'algorithm': 'task_scheduling'}
I0831 22:43:10.377678 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.915, val scores are: activity_selector: 0.905, task_scheduling: 0.925
I0831 22:43:11.401266 135974886344192 run.py:724] Algo activity_selector step 7900 current loss 1.312392, current_train_items 108960.
I0831 22:43:11.405673 135974886344192 run.py:724] Algo task_scheduling step 7900 current loss 0.942693, current_train_items 108960.
I0831 22:43:11.421492 135974886344192 run.py:759] (val) algo activity_selector step 7900: {'selected': 0.8597122302158273, 'score': 0.8597122302158273, 'examples_seen': 108960, 'step': 7900, 'algorithm': 'activity_selector'}
I0831 22:43:11.429097 135974886344192 run.py:759] (val) algo task_scheduling step 7900: {'selected': 0.930035335689046, 'score': 0.930035335689046, 'examples_seen': 108960, 'step': 7900, 'algorithm': 'task_scheduling'}
I0831 22:43:11.429241 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.895, val scores are: activity_selector: 0.860, task_scheduling: 0.930
I0831 22:43:12.471888 135974886344192 run.py:724] Algo activity_selector step 7950 current loss 1.214282, current_train_items 109632.
I0831 22:43:12.476382 135974886344192 run.py:724] Algo task_scheduling step 7950 current loss 1.079895, current_train_items 109632.
I0831 22:43:12.495108 135974886344192 run.py:759] (val) algo activity_selector step 7950: {'selected': 0.8884955752212389, 'score': 0.8884955752212389, 'examples_seen': 109632, 'step': 7950, 'algorithm': 'activity_selector'}
I0831 22:43:12.502739 135974886344192 run.py:759] (val) algo task_scheduling step 7950: {'selected': 0.9126607989167231, 'score': 0.9126607989167231, 'examples_seen': 109632, 'step': 7950, 'algorithm': 'task_scheduling'}
I0831 22:43:12.502881 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.901, val scores are: activity_selector: 0.888, task_scheduling: 0.913
I0831 22:43:13.532023 135974886344192 run.py:724] Algo activity_selector step 8000 current loss 0.811855, current_train_items 110320.
I0831 22:43:13.536318 135974886344192 run.py:724] Algo task_scheduling step 8000 current loss 1.008092, current_train_items 110320.
I0831 22:43:13.552146 135974886344192 run.py:759] (val) algo activity_selector step 8000: {'selected': 0.8586387434554973, 'score': 0.8586387434554973, 'examples_seen': 110320, 'step': 8000, 'algorithm': 'activity_selector'}
I0831 22:43:13.559682 135974886344192 run.py:759] (val) algo task_scheduling step 8000: {'selected': 0.9213639526791929, 'score': 0.9213639526791929, 'examples_seen': 110320, 'step': 8000, 'algorithm': 'task_scheduling'}
I0831 22:43:13.559823 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.931, current avg val score is 0.890, val scores are: activity_selector: 0.859, task_scheduling: 0.921
I0831 22:43:14.591922 135974886344192 run.py:724] Algo activity_selector step 8050 current loss 0.312381, current_train_items 111024.
I0831 22:43:14.596693 135974886344192 run.py:724] Algo task_scheduling step 8050 current loss 0.954917, current_train_items 111024.
I0831 22:43:14.612923 135974886344192 run.py:759] (val) algo activity_selector step 8050: {'selected': 0.9077757685352621, 'score': 0.9077757685352621, 'examples_seen': 111024, 'step': 8050, 'algorithm': 'activity_selector'}
I0831 22:43:14.620627 135974886344192 run.py:759] (val) algo task_scheduling step 8050: {'selected': 0.911242603550296, 'score': 0.911242603550296, 'examples_seen': 111024, 'step': 8050, 'algorithm': 'task_scheduling'}
I0831 22:43:14.620774 135974886344192 run.py:780] Checkpointing best model, best avg val score was -0.500, current avg val score is 0.910, val scores are: activity_selector: 0.908, task_scheduling: 0.911
I0831 22:43:15.661219 135974886344192 run.py:724] Algo activity_selector step 8100 current loss 0.400821, current_train_items 111696.
I0831 22:43:15.665584 135974886344192 run.py:724] Algo task_scheduling step 8100 current loss 1.520531, current_train_items 111696.
I0831 22:43:15.681415 135974886344192 run.py:759] (val) algo activity_selector step 8100: {'selected': 0.8662900188323917, 'score': 0.8662900188323917, 'examples_seen': 111696, 'step': 8100, 'algorithm': 'activity_selector'}
I0831 22:43:15.688958 135974886344192 run.py:759] (val) algo task_scheduling step 8100: {'selected': 0.9372384937238494, 'score': 0.9372384937238494, 'examples_seen': 111696, 'step': 8100, 'algorithm': 'task_scheduling'}
I0831 22:43:15.689100 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.910, current avg val score is 0.902, val scores are: activity_selector: 0.866, task_scheduling: 0.937
I0831 22:43:16.714344 135974886344192 run.py:724] Algo activity_selector step 8150 current loss 0.886357, current_train_items 112400.
I0831 22:43:16.718692 135974886344192 run.py:724] Algo task_scheduling step 8150 current loss 0.886313, current_train_items 112400.
I0831 22:43:16.734919 135974886344192 run.py:759] (val) algo activity_selector step 8150: {'selected': 0.8491228070175438, 'score': 0.8491228070175438, 'examples_seen': 112400, 'step': 8150, 'algorithm': 'activity_selector'}
I0831 22:43:16.742486 135974886344192 run.py:759] (val) algo task_scheduling step 8150: {'selected': 0.9453781512605043, 'score': 0.9453781512605043, 'examples_seen': 112400, 'step': 8150, 'algorithm': 'task_scheduling'}
I0831 22:43:16.742627 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.910, current avg val score is 0.897, val scores are: activity_selector: 0.849, task_scheduling: 0.945
I0831 22:43:17.763541 135974886344192 run.py:724] Algo activity_selector step 8200 current loss 0.819455, current_train_items 113088.
I0831 22:43:17.768249 135974886344192 run.py:724] Algo task_scheduling step 8200 current loss 0.760494, current_train_items 113088.
I0831 22:43:17.783763 135974886344192 run.py:759] (val) algo activity_selector step 8200: {'selected': 0.9239332096474954, 'score': 0.9239332096474954, 'examples_seen': 113088, 'step': 8200, 'algorithm': 'activity_selector'}
I0831 22:43:17.791264 135974886344192 run.py:759] (val) algo task_scheduling step 8200: {'selected': 0.9169960474308301, 'score': 0.9169960474308301, 'examples_seen': 113088, 'step': 8200, 'algorithm': 'task_scheduling'}
I0831 22:43:17.791406 135974886344192 run.py:780] Checkpointing best model, best avg val score was 0.910, current avg val score is 0.920, val scores are: activity_selector: 0.924, task_scheduling: 0.917
I0831 22:43:18.826370 135974886344192 run.py:724] Algo activity_selector step 8250 current loss 0.429343, current_train_items 113760.
I0831 22:43:18.830512 135974886344192 run.py:724] Algo task_scheduling step 8250 current loss 1.038544, current_train_items 113760.
I0831 22:43:18.847511 135974886344192 run.py:759] (val) algo activity_selector step 8250: {'selected': 0.8931297709923665, 'score': 0.8931297709923665, 'examples_seen': 113760, 'step': 8250, 'algorithm': 'activity_selector'}
I0831 22:43:18.855174 135974886344192 run.py:759] (val) algo task_scheduling step 8250: {'selected': 0.942756183745583, 'score': 0.942756183745583, 'examples_seen': 113760, 'step': 8250, 'algorithm': 'task_scheduling'}
I0831 22:43:18.855326 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.920, current avg val score is 0.918, val scores are: activity_selector: 0.893, task_scheduling: 0.943
I0831 22:43:19.899808 135974886344192 run.py:724] Algo activity_selector step 8300 current loss 0.769376, current_train_items 114464.
I0831 22:43:19.904183 135974886344192 run.py:724] Algo task_scheduling step 8300 current loss 2.496030, current_train_items 114464.
I0831 22:43:19.919614 135974886344192 run.py:759] (val) algo activity_selector step 8300: {'selected': 0.8541300527240774, 'score': 0.8541300527240774, 'examples_seen': 114464, 'step': 8300, 'algorithm': 'activity_selector'}
I0831 22:43:19.927142 135974886344192 run.py:759] (val) algo task_scheduling step 8300: {'selected': 0.8908238446081714, 'score': 0.8908238446081714, 'examples_seen': 114464, 'step': 8300, 'algorithm': 'task_scheduling'}
I0831 22:43:19.927284 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.920, current avg val score is 0.872, val scores are: activity_selector: 0.854, task_scheduling: 0.891
I0831 22:43:20.939524 135974886344192 run.py:724] Algo activity_selector step 8350 current loss 1.159849, current_train_items 115152.
I0831 22:43:20.943912 135974886344192 run.py:724] Algo task_scheduling step 8350 current loss 1.034525, current_train_items 115152.
I0831 22:43:20.959343 135974886344192 run.py:759] (val) algo activity_selector step 8350: {'selected': 0.8957528957528959, 'score': 0.8957528957528959, 'examples_seen': 115152, 'step': 8350, 'algorithm': 'activity_selector'}
I0831 22:43:20.967005 135974886344192 run.py:759] (val) algo task_scheduling step 8350: {'selected': 0.938861560084329, 'score': 0.938861560084329, 'examples_seen': 115152, 'step': 8350, 'algorithm': 'task_scheduling'}
I0831 22:43:20.967148 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.920, current avg val score is 0.917, val scores are: activity_selector: 0.896, task_scheduling: 0.939
I0831 22:43:21.999531 135974886344192 run.py:724] Algo activity_selector step 8400 current loss 0.412042, current_train_items 115840.
I0831 22:43:22.003751 135974886344192 run.py:724] Algo task_scheduling step 8400 current loss 1.463558, current_train_items 115840.
I0831 22:43:22.019249 135974886344192 run.py:759] (val) algo activity_selector step 8400: {'selected': 0.8731884057971013, 'score': 0.8731884057971013, 'examples_seen': 115840, 'step': 8400, 'algorithm': 'activity_selector'}
I0831 22:43:22.026713 135974886344192 run.py:759] (val) algo task_scheduling step 8400: {'selected': 0.9353507565337001, 'score': 0.9353507565337001, 'examples_seen': 115840, 'step': 8400, 'algorithm': 'task_scheduling'}
I0831 22:43:22.026854 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.920, current avg val score is 0.904, val scores are: activity_selector: 0.873, task_scheduling: 0.935
I0831 22:43:23.040936 135974886344192 run.py:724] Algo activity_selector step 8450 current loss 0.481628, current_train_items 116528.
I0831 22:43:23.045378 135974886344192 run.py:724] Algo task_scheduling step 8450 current loss 1.368418, current_train_items 116528.
I0831 22:43:23.061408 135974886344192 run.py:759] (val) algo activity_selector step 8450: {'selected': 0.8819188191881919, 'score': 0.8819188191881919, 'examples_seen': 116528, 'step': 8450, 'algorithm': 'activity_selector'}
I0831 22:43:23.068905 135974886344192 run.py:759] (val) algo task_scheduling step 8450: {'selected': 0.9422936449963477, 'score': 0.9422936449963477, 'examples_seen': 116528, 'step': 8450, 'algorithm': 'task_scheduling'}
I0831 22:43:23.069057 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.920, current avg val score is 0.912, val scores are: activity_selector: 0.882, task_scheduling: 0.942
I0831 22:43:24.077305 135974886344192 run.py:724] Algo activity_selector step 8500 current loss 0.872965, current_train_items 117232.
I0831 22:43:24.081274 135974886344192 run.py:724] Algo task_scheduling step 8500 current loss 1.521006, current_train_items 117232.
I0831 22:43:24.097134 135974886344192 run.py:759] (val) algo activity_selector step 8500: {'selected': 0.9021739130434783, 'score': 0.9021739130434783, 'examples_seen': 117232, 'step': 8500, 'algorithm': 'activity_selector'}
I0831 22:43:24.104693 135974886344192 run.py:759] (val) algo task_scheduling step 8500: {'selected': 0.9346451159522137, 'score': 0.9346451159522137, 'examples_seen': 117232, 'step': 8500, 'algorithm': 'task_scheduling'}
I0831 22:43:24.104835 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.920, current avg val score is 0.918, val scores are: activity_selector: 0.902, task_scheduling: 0.935
I0831 22:43:25.141713 135974886344192 run.py:724] Algo activity_selector step 8550 current loss 0.674749, current_train_items 117904.
I0831 22:43:25.146126 135974886344192 run.py:724] Algo task_scheduling step 8550 current loss 1.939417, current_train_items 117904.
I0831 22:43:25.162293 135974886344192 run.py:759] (val) algo activity_selector step 8550: {'selected': 0.9043151969981238, 'score': 0.9043151969981238, 'examples_seen': 117904, 'step': 8550, 'algorithm': 'activity_selector'}
I0831 22:43:25.169948 135974886344192 run.py:759] (val) algo task_scheduling step 8550: {'selected': 0.9518248175182482, 'score': 0.9518248175182482, 'examples_seen': 117904, 'step': 8550, 'algorithm': 'task_scheduling'}
I0831 22:43:25.170090 135974886344192 run.py:780] Checkpointing best model, best avg val score was 0.920, current avg val score is 0.928, val scores are: activity_selector: 0.904, task_scheduling: 0.952
I0831 22:43:26.206385 135974886344192 run.py:724] Algo activity_selector step 8600 current loss 0.870052, current_train_items 118592.
I0831 22:43:26.210761 135974886344192 run.py:724] Algo task_scheduling step 8600 current loss 0.731431, current_train_items 118592.
I0831 22:43:26.226553 135974886344192 run.py:759] (val) algo activity_selector step 8600: {'selected': 0.8893280632411067, 'score': 0.8893280632411067, 'examples_seen': 118592, 'step': 8600, 'algorithm': 'activity_selector'}
I0831 22:43:26.234197 135974886344192 run.py:759] (val) algo task_scheduling step 8600: {'selected': 0.9255172413793102, 'score': 0.9255172413793102, 'examples_seen': 118592, 'step': 8600, 'algorithm': 'task_scheduling'}
I0831 22:43:26.234336 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.907, val scores are: activity_selector: 0.889, task_scheduling: 0.926
I0831 22:43:27.259811 135974886344192 run.py:724] Algo activity_selector step 8650 current loss 0.481279, current_train_items 119296.
I0831 22:43:27.264254 135974886344192 run.py:724] Algo task_scheduling step 8650 current loss 1.454736, current_train_items 119296.
I0831 22:43:27.280284 135974886344192 run.py:759] (val) algo activity_selector step 8650: {'selected': 0.8716981132075472, 'score': 0.8716981132075472, 'examples_seen': 119296, 'step': 8650, 'algorithm': 'activity_selector'}
I0831 22:43:27.287780 135974886344192 run.py:759] (val) algo task_scheduling step 8650: {'selected': 0.9258997882851094, 'score': 0.9258997882851094, 'examples_seen': 119296, 'step': 8650, 'algorithm': 'task_scheduling'}
I0831 22:43:27.287920 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.899, val scores are: activity_selector: 0.872, task_scheduling: 0.926
I0831 22:43:28.311554 135974886344192 run.py:724] Algo activity_selector step 8700 current loss 1.021209, current_train_items 119968.
I0831 22:43:28.316127 135974886344192 run.py:724] Algo task_scheduling step 8700 current loss 0.804079, current_train_items 119968.
I0831 22:43:28.335024 135974886344192 run.py:759] (val) algo activity_selector step 8700: {'selected': 0.873394495412844, 'score': 0.873394495412844, 'examples_seen': 119968, 'step': 8700, 'algorithm': 'activity_selector'}
I0831 22:43:28.342595 135974886344192 run.py:759] (val) algo task_scheduling step 8700: {'selected': 0.9333333333333333, 'score': 0.9333333333333333, 'examples_seen': 119968, 'step': 8700, 'algorithm': 'task_scheduling'}
I0831 22:43:28.342736 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.903, val scores are: activity_selector: 0.873, task_scheduling: 0.933
I0831 22:43:29.380277 135974886344192 run.py:724] Algo activity_selector step 8750 current loss 0.616385, current_train_items 120672.
I0831 22:43:29.384751 135974886344192 run.py:724] Algo task_scheduling step 8750 current loss 0.893196, current_train_items 120672.
I0831 22:43:29.400769 135974886344192 run.py:759] (val) algo activity_selector step 8750: {'selected': 0.9216417910447762, 'score': 0.9216417910447762, 'examples_seen': 120672, 'step': 8750, 'algorithm': 'activity_selector'}
I0831 22:43:29.408409 135974886344192 run.py:759] (val) algo task_scheduling step 8750: {'selected': 0.9007936507936507, 'score': 0.9007936507936507, 'examples_seen': 120672, 'step': 8750, 'algorithm': 'task_scheduling'}
I0831 22:43:29.408552 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.911, val scores are: activity_selector: 0.922, task_scheduling: 0.901
I0831 22:43:30.450119 135974886344192 run.py:724] Algo activity_selector step 8800 current loss 1.101344, current_train_items 121360.
I0831 22:43:30.454696 135974886344192 run.py:724] Algo task_scheduling step 8800 current loss 1.484335, current_train_items 121360.
I0831 22:43:30.473489 135974886344192 run.py:759] (val) algo activity_selector step 8800: {'selected': 0.9101123595505618, 'score': 0.9101123595505618, 'examples_seen': 121360, 'step': 8800, 'algorithm': 'activity_selector'}
I0831 22:43:30.481049 135974886344192 run.py:759] (val) algo task_scheduling step 8800: {'selected': 0.9430336307481125, 'score': 0.9430336307481125, 'examples_seen': 121360, 'step': 8800, 'algorithm': 'task_scheduling'}
I0831 22:43:30.481208 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.927, val scores are: activity_selector: 0.910, task_scheduling: 0.943
I0831 22:43:31.503926 135974886344192 run.py:724] Algo activity_selector step 8850 current loss 1.015687, current_train_items 122048.
I0831 22:43:31.508429 135974886344192 run.py:724] Algo task_scheduling step 8850 current loss 1.299238, current_train_items 122048.
I0831 22:43:31.523912 135974886344192 run.py:759] (val) algo activity_selector step 8850: {'selected': 0.9018867924528301, 'score': 0.9018867924528301, 'examples_seen': 122048, 'step': 8850, 'algorithm': 'activity_selector'}
I0831 22:43:31.531539 135974886344192 run.py:759] (val) algo task_scheduling step 8850: {'selected': 0.9004739336492892, 'score': 0.9004739336492892, 'examples_seen': 122048, 'step': 8850, 'algorithm': 'task_scheduling'}
I0831 22:43:31.531680 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.901, val scores are: activity_selector: 0.902, task_scheduling: 0.900
I0831 22:43:32.569838 135974886344192 run.py:724] Algo activity_selector step 8900 current loss 0.520041, current_train_items 122736.
I0831 22:43:32.574220 135974886344192 run.py:724] Algo task_scheduling step 8900 current loss 1.055507, current_train_items 122736.
I0831 22:43:32.589692 135974886344192 run.py:759] (val) algo activity_selector step 8900: {'selected': 0.9296875, 'score': 0.9296875, 'examples_seen': 122736, 'step': 8900, 'algorithm': 'activity_selector'}
I0831 22:43:32.597272 135974886344192 run.py:759] (val) algo task_scheduling step 8900: {'selected': 0.921302578018996, 'score': 0.921302578018996, 'examples_seen': 122736, 'step': 8900, 'algorithm': 'task_scheduling'}
I0831 22:43:32.597411 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.925, val scores are: activity_selector: 0.930, task_scheduling: 0.921
I0831 22:43:33.607171 135974886344192 run.py:724] Algo activity_selector step 8950 current loss 0.825517, current_train_items 123424.
I0831 22:43:33.611921 135974886344192 run.py:724] Algo task_scheduling step 8950 current loss 0.768554, current_train_items 123424.
I0831 22:43:33.627566 135974886344192 run.py:759] (val) algo activity_selector step 8950: {'selected': 0.8986083499005965, 'score': 0.8986083499005965, 'examples_seen': 123424, 'step': 8950, 'algorithm': 'activity_selector'}
I0831 22:43:33.635165 135974886344192 run.py:759] (val) algo task_scheduling step 8950: {'selected': 0.9263888888888889, 'score': 0.9263888888888889, 'examples_seen': 123424, 'step': 8950, 'algorithm': 'task_scheduling'}
I0831 22:43:33.635305 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.912, val scores are: activity_selector: 0.899, task_scheduling: 0.926
I0831 22:43:34.673717 135974886344192 run.py:724] Algo activity_selector step 9000 current loss 0.860862, current_train_items 124112.
I0831 22:43:34.678201 135974886344192 run.py:724] Algo task_scheduling step 9000 current loss 0.899389, current_train_items 124112.
I0831 22:43:34.694356 135974886344192 run.py:759] (val) algo activity_selector step 9000: {'selected': 0.8718929254302105, 'score': 0.8718929254302105, 'examples_seen': 124112, 'step': 9000, 'algorithm': 'activity_selector'}
I0831 22:43:34.701978 135974886344192 run.py:759] (val) algo task_scheduling step 9000: {'selected': 0.9256198347107438, 'score': 0.9256198347107438, 'examples_seen': 124112, 'step': 9000, 'algorithm': 'task_scheduling'}
I0831 22:43:34.702121 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.899, val scores are: activity_selector: 0.872, task_scheduling: 0.926
I0831 22:43:35.735250 135974886344192 run.py:724] Algo activity_selector step 9050 current loss 0.304532, current_train_items 124800.
I0831 22:43:35.739606 135974886344192 run.py:724] Algo task_scheduling step 9050 current loss 1.000183, current_train_items 124800.
I0831 22:43:35.755714 135974886344192 run.py:759] (val) algo activity_selector step 9050: {'selected': 0.8921933085501857, 'score': 0.8921933085501857, 'examples_seen': 124800, 'step': 9050, 'algorithm': 'activity_selector'}
I0831 22:43:35.763198 135974886344192 run.py:759] (val) algo task_scheduling step 9050: {'selected': 0.9411764705882354, 'score': 0.9411764705882354, 'examples_seen': 124800, 'step': 9050, 'algorithm': 'task_scheduling'}
I0831 22:43:35.763339 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.917, val scores are: activity_selector: 0.892, task_scheduling: 0.941
I0831 22:43:36.769153 135974886344192 run.py:724] Algo activity_selector step 9100 current loss 0.456494, current_train_items 125488.
I0831 22:43:36.773689 135974886344192 run.py:724] Algo task_scheduling step 9100 current loss 1.032672, current_train_items 125488.
I0831 22:43:36.789623 135974886344192 run.py:759] (val) algo activity_selector step 9100: {'selected': 0.8945454545454545, 'score': 0.8945454545454545, 'examples_seen': 125488, 'step': 9100, 'algorithm': 'activity_selector'}
I0831 22:43:36.797174 135974886344192 run.py:759] (val) algo task_scheduling step 9100: {'selected': 0.9272727272727274, 'score': 0.9272727272727274, 'examples_seen': 125488, 'step': 9100, 'algorithm': 'task_scheduling'}
I0831 22:43:36.797316 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.911, val scores are: activity_selector: 0.895, task_scheduling: 0.927
I0831 22:43:37.836976 135974886344192 run.py:724] Algo activity_selector step 9150 current loss 0.759747, current_train_items 126176.
I0831 22:43:37.841477 135974886344192 run.py:724] Algo task_scheduling step 9150 current loss 0.843716, current_train_items 126176.
I0831 22:43:37.857423 135974886344192 run.py:759] (val) algo activity_selector step 9150: {'selected': 0.9259962049335864, 'score': 0.9259962049335864, 'examples_seen': 126176, 'step': 9150, 'algorithm': 'activity_selector'}
I0831 22:43:37.865010 135974886344192 run.py:759] (val) algo task_scheduling step 9150: {'selected': 0.9196488858879135, 'score': 0.9196488858879135, 'examples_seen': 126176, 'step': 9150, 'algorithm': 'task_scheduling'}
I0831 22:43:37.865150 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.923, val scores are: activity_selector: 0.926, task_scheduling: 0.920
I0831 22:43:38.888258 135974886344192 run.py:724] Algo activity_selector step 9200 current loss 1.042343, current_train_items 126880.
I0831 22:43:38.892877 135974886344192 run.py:724] Algo task_scheduling step 9200 current loss 1.287056, current_train_items 126880.
I0831 22:43:38.909147 135974886344192 run.py:759] (val) algo activity_selector step 9200: {'selected': 0.9293680297397768, 'score': 0.9293680297397768, 'examples_seen': 126880, 'step': 9200, 'algorithm': 'activity_selector'}
I0831 22:43:38.916837 135974886344192 run.py:759] (val) algo task_scheduling step 9200: {'selected': 0.9195402298850575, 'score': 0.9195402298850575, 'examples_seen': 126880, 'step': 9200, 'algorithm': 'task_scheduling'}
I0831 22:43:38.916986 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.924, val scores are: activity_selector: 0.929, task_scheduling: 0.920
I0831 22:43:39.949300 135974886344192 run.py:724] Algo activity_selector step 9250 current loss 1.120989, current_train_items 127568.
I0831 22:43:39.953907 135974886344192 run.py:724] Algo task_scheduling step 9250 current loss 1.790396, current_train_items 127568.
I0831 22:43:39.969774 135974886344192 run.py:759] (val) algo activity_selector step 9250: {'selected': 0.9129593810444874, 'score': 0.9129593810444874, 'examples_seen': 127568, 'step': 9250, 'algorithm': 'activity_selector'}
I0831 22:43:39.977279 135974886344192 run.py:759] (val) algo task_scheduling step 9250: {'selected': 0.9320388349514563, 'score': 0.9320388349514563, 'examples_seen': 127568, 'step': 9250, 'algorithm': 'task_scheduling'}
I0831 22:43:39.977434 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.922, val scores are: activity_selector: 0.913, task_scheduling: 0.932
I0831 22:43:41.002265 135974886344192 run.py:724] Algo activity_selector step 9300 current loss 1.110443, current_train_items 128240.
I0831 22:43:41.006623 135974886344192 run.py:724] Algo task_scheduling step 9300 current loss 0.736104, current_train_items 128240.
I0831 22:43:41.022346 135974886344192 run.py:759] (val) algo activity_selector step 9300: {'selected': 0.8698752228163993, 'score': 0.8698752228163993, 'examples_seen': 128240, 'step': 9300, 'algorithm': 'activity_selector'}
I0831 22:43:41.029897 135974886344192 run.py:759] (val) algo task_scheduling step 9300: {'selected': 0.9434482758620689, 'score': 0.9434482758620689, 'examples_seen': 128240, 'step': 9300, 'algorithm': 'task_scheduling'}
I0831 22:43:41.030047 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.907, val scores are: activity_selector: 0.870, task_scheduling: 0.943
I0831 22:43:42.068192 135974886344192 run.py:724] Algo activity_selector step 9350 current loss 0.578409, current_train_items 128944.
I0831 22:43:42.072621 135974886344192 run.py:724] Algo task_scheduling step 9350 current loss 0.696735, current_train_items 128944.
I0831 22:43:42.088231 135974886344192 run.py:759] (val) algo activity_selector step 9350: {'selected': 0.9034608378870674, 'score': 0.9034608378870674, 'examples_seen': 128944, 'step': 9350, 'algorithm': 'activity_selector'}
I0831 22:43:42.095788 135974886344192 run.py:759] (val) algo task_scheduling step 9350: {'selected': 0.9031396125584502, 'score': 0.9031396125584502, 'examples_seen': 128944, 'step': 9350, 'algorithm': 'task_scheduling'}
I0831 22:43:42.095939 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.903, val scores are: activity_selector: 0.903, task_scheduling: 0.903
I0831 22:43:43.111732 135974886344192 run.py:724] Algo activity_selector step 9400 current loss 0.741415, current_train_items 129632.
I0831 22:43:43.115882 135974886344192 run.py:724] Algo task_scheduling step 9400 current loss 0.904522, current_train_items 129632.
I0831 22:43:43.132041 135974886344192 run.py:759] (val) algo activity_selector step 9400: {'selected': 0.8629629629629629, 'score': 0.8629629629629629, 'examples_seen': 129632, 'step': 9400, 'algorithm': 'activity_selector'}
I0831 22:43:43.139585 135974886344192 run.py:759] (val) algo task_scheduling step 9400: {'selected': 0.9232839838492597, 'score': 0.9232839838492597, 'examples_seen': 129632, 'step': 9400, 'algorithm': 'task_scheduling'}
I0831 22:43:43.139727 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.928, current avg val score is 0.893, val scores are: activity_selector: 0.863, task_scheduling: 0.923
I0831 22:43:44.157413 135974886344192 run.py:724] Algo activity_selector step 9450 current loss 1.133854, current_train_items 130304.
I0831 22:43:44.161791 135974886344192 run.py:724] Algo task_scheduling step 9450 current loss 1.189827, current_train_items 130304.
I0831 22:43:44.177402 135974886344192 run.py:759] (val) algo activity_selector step 9450: {'selected': 0.9251968503937008, 'score': 0.9251968503937008, 'examples_seen': 130304, 'step': 9450, 'algorithm': 'activity_selector'}
I0831 22:43:44.184998 135974886344192 run.py:759] (val) algo task_scheduling step 9450: {'selected': 0.9389473684210525, 'score': 0.9389473684210525, 'examples_seen': 130304, 'step': 9450, 'algorithm': 'task_scheduling'}
I0831 22:43:44.185139 135974886344192 run.py:780] Checkpointing best model, best avg val score was 0.928, current avg val score is 0.932, val scores are: activity_selector: 0.925, task_scheduling: 0.939
I0831 22:43:45.239386 135974886344192 run.py:724] Algo activity_selector step 9500 current loss 0.764940, current_train_items 131008.
I0831 22:43:45.243756 135974886344192 run.py:724] Algo task_scheduling step 9500 current loss 0.856945, current_train_items 131008.
I0831 22:43:45.259180 135974886344192 run.py:759] (val) algo activity_selector step 9500: {'selected': 0.8588007736943907, 'score': 0.8588007736943907, 'examples_seen': 131008, 'step': 9500, 'algorithm': 'activity_selector'}
I0831 22:43:45.266779 135974886344192 run.py:759] (val) algo task_scheduling step 9500: {'selected': 0.929936305732484, 'score': 0.929936305732484, 'examples_seen': 131008, 'step': 9500, 'algorithm': 'task_scheduling'}
I0831 22:43:45.266920 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.932, current avg val score is 0.894, val scores are: activity_selector: 0.859, task_scheduling: 0.930
I0831 22:43:46.285193 135974886344192 run.py:724] Algo activity_selector step 9550 current loss 0.526467, current_train_items 131712.
I0831 22:43:46.289602 135974886344192 run.py:724] Algo task_scheduling step 9550 current loss 1.025536, current_train_items 131712.
I0831 22:43:46.305451 135974886344192 run.py:759] (val) algo activity_selector step 9550: {'selected': 0.8625235404896423, 'score': 0.8625235404896423, 'examples_seen': 131712, 'step': 9550, 'algorithm': 'activity_selector'}
I0831 22:43:46.312963 135974886344192 run.py:759] (val) algo task_scheduling step 9550: {'selected': 0.9096945551128818, 'score': 0.9096945551128818, 'examples_seen': 131712, 'step': 9550, 'algorithm': 'task_scheduling'}
I0831 22:43:46.313104 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.932, current avg val score is 0.886, val scores are: activity_selector: 0.863, task_scheduling: 0.910
I0831 22:43:47.331803 135974886344192 run.py:724] Algo activity_selector step 9600 current loss 0.358665, current_train_items 132384.
I0831 22:43:47.336359 135974886344192 run.py:724] Algo task_scheduling step 9600 current loss 0.780116, current_train_items 132384.
I0831 22:43:47.352146 135974886344192 run.py:759] (val) algo activity_selector step 9600: {'selected': 0.8958742632612967, 'score': 0.8958742632612967, 'examples_seen': 132384, 'step': 9600, 'algorithm': 'activity_selector'}
I0831 22:43:47.359657 135974886344192 run.py:759] (val) algo task_scheduling step 9600: {'selected': 0.9212121212121213, 'score': 0.9212121212121213, 'examples_seen': 132384, 'step': 9600, 'algorithm': 'task_scheduling'}
I0831 22:43:47.359801 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.932, current avg val score is 0.909, val scores are: activity_selector: 0.896, task_scheduling: 0.921
I0831 22:43:48.405974 135974886344192 run.py:724] Algo activity_selector step 9650 current loss 0.830846, current_train_items 133072.
I0831 22:43:48.410250 135974886344192 run.py:724] Algo task_scheduling step 9650 current loss 1.174284, current_train_items 133072.
I0831 22:43:48.426243 135974886344192 run.py:759] (val) algo activity_selector step 9650: {'selected': 0.9281553398058252, 'score': 0.9281553398058252, 'examples_seen': 133072, 'step': 9650, 'algorithm': 'activity_selector'}
I0831 22:43:48.433856 135974886344192 run.py:759] (val) algo task_scheduling step 9650: {'selected': 0.9260539046302695, 'score': 0.9260539046302695, 'examples_seen': 133072, 'step': 9650, 'algorithm': 'task_scheduling'}
I0831 22:43:48.434008 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.932, current avg val score is 0.927, val scores are: activity_selector: 0.928, task_scheduling: 0.926
I0831 22:43:49.462711 135974886344192 run.py:724] Algo activity_selector step 9700 current loss 0.611182, current_train_items 133776.
I0831 22:43:49.467488 135974886344192 run.py:724] Algo task_scheduling step 9700 current loss 1.244875, current_train_items 133776.
I0831 22:43:49.483967 135974886344192 run.py:759] (val) algo activity_selector step 9700: {'selected': 0.920754716981132, 'score': 0.920754716981132, 'examples_seen': 133776, 'step': 9700, 'algorithm': 'activity_selector'}
I0831 22:43:49.491644 135974886344192 run.py:759] (val) algo task_scheduling step 9700: {'selected': 0.911062906724512, 'score': 0.911062906724512, 'examples_seen': 133776, 'step': 9700, 'algorithm': 'task_scheduling'}
I0831 22:43:49.491799 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.932, current avg val score is 0.916, val scores are: activity_selector: 0.921, task_scheduling: 0.911
I0831 22:43:50.524329 135974886344192 run.py:724] Algo activity_selector step 9750 current loss 1.263200, current_train_items 134448.
I0831 22:43:50.528972 135974886344192 run.py:724] Algo task_scheduling step 9750 current loss 0.829884, current_train_items 134448.
I0831 22:43:50.545303 135974886344192 run.py:759] (val) algo activity_selector step 9750: {'selected': 0.8727272727272729, 'score': 0.8727272727272729, 'examples_seen': 134448, 'step': 9750, 'algorithm': 'activity_selector'}
I0831 22:43:50.553097 135974886344192 run.py:759] (val) algo task_scheduling step 9750: {'selected': 0.9414285714285715, 'score': 0.9414285714285715, 'examples_seen': 134448, 'step': 9750, 'algorithm': 'task_scheduling'}
I0831 22:43:50.553238 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.932, current avg val score is 0.907, val scores are: activity_selector: 0.873, task_scheduling: 0.941
I0831 22:43:51.572844 135974886344192 run.py:724] Algo activity_selector step 9800 current loss 0.345236, current_train_items 135136.
I0831 22:43:51.577329 135974886344192 run.py:724] Algo task_scheduling step 9800 current loss 1.039416, current_train_items 135136.
I0831 22:43:51.593125 135974886344192 run.py:759] (val) algo activity_selector step 9800: {'selected': 0.8786764705882352, 'score': 0.8786764705882352, 'examples_seen': 135136, 'step': 9800, 'algorithm': 'activity_selector'}
I0831 22:43:51.600778 135974886344192 run.py:759] (val) algo task_scheduling step 9800: {'selected': 0.933697881066302, 'score': 0.933697881066302, 'examples_seen': 135136, 'step': 9800, 'algorithm': 'task_scheduling'}
I0831 22:43:51.600919 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.932, current avg val score is 0.906, val scores are: activity_selector: 0.879, task_scheduling: 0.934
I0831 22:43:52.632855 135974886344192 run.py:724] Algo activity_selector step 9850 current loss 0.604054, current_train_items 135840.
I0831 22:43:52.637384 135974886344192 run.py:724] Algo task_scheduling step 9850 current loss 0.978530, current_train_items 135840.
I0831 22:43:52.652827 135974886344192 run.py:759] (val) algo activity_selector step 9850: {'selected': 0.8659793814432989, 'score': 0.8659793814432989, 'examples_seen': 135840, 'step': 9850, 'algorithm': 'activity_selector'}
I0831 22:43:52.660396 135974886344192 run.py:759] (val) algo task_scheduling step 9850: {'selected': 0.9365303244005642, 'score': 0.9365303244005642, 'examples_seen': 135840, 'step': 9850, 'algorithm': 'task_scheduling'}
I0831 22:43:52.660536 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.932, current avg val score is 0.901, val scores are: activity_selector: 0.866, task_scheduling: 0.937
I0831 22:43:53.689047 135974886344192 run.py:724] Algo activity_selector step 9900 current loss 0.386594, current_train_items 136528.
I0831 22:43:53.693431 135974886344192 run.py:724] Algo task_scheduling step 9900 current loss 2.192487, current_train_items 136528.
I0831 22:43:53.710146 135974886344192 run.py:759] (val) algo activity_selector step 9900: {'selected': 0.9233716475095786, 'score': 0.9233716475095786, 'examples_seen': 136528, 'step': 9900, 'algorithm': 'activity_selector'}
I0831 22:43:53.717675 135974886344192 run.py:759] (val) algo task_scheduling step 9900: {'selected': 0.8668373879641486, 'score': 0.8668373879641486, 'examples_seen': 136528, 'step': 9900, 'algorithm': 'task_scheduling'}
I0831 22:43:53.717816 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.932, current avg val score is 0.895, val scores are: activity_selector: 0.923, task_scheduling: 0.867
I0831 22:43:54.740365 135974886344192 run.py:724] Algo activity_selector step 9950 current loss 0.898016, current_train_items 137200.
I0831 22:43:54.744895 135974886344192 run.py:724] Algo task_scheduling step 9950 current loss 0.852413, current_train_items 137200.
I0831 22:43:54.760405 135974886344192 run.py:759] (val) algo activity_selector step 9950: {'selected': 0.8701754385964913, 'score': 0.8701754385964913, 'examples_seen': 137200, 'step': 9950, 'algorithm': 'activity_selector'}
I0831 22:43:54.767960 135974886344192 run.py:759] (val) algo task_scheduling step 9950: {'selected': 0.94151212553495, 'score': 0.94151212553495, 'examples_seen': 137200, 'step': 9950, 'algorithm': 'task_scheduling'}
I0831 22:43:54.768098 135974886344192 run.py:783] Not saving new best model, best avg val score was 0.932, current avg val score is 0.906, val scores are: activity_selector: 0.870, task_scheduling: 0.942
I0831 22:43:55.787774 135974886344192 run.py:789] Restoring best model from checkpoint...
I0831 22:43:58.847407 135974886344192 run.py:804] (test) algo activity_selector : {'selected': 0.7475409836065574, 'score': 0.7475409836065574, 'examples_seen': 137888, 'step': 10000, 'algorithm': 'activity_selector'}
I0831 22:44:00.374024 135974886344192 run.py:804] (test) algo task_scheduling : {'selected': 0.8223350253807107, 'score': 0.8223350253807107, 'examples_seen': 137888, 'step': 10000, 'algorithm': 'task_scheduling'}
I0831 22:44:00.374138 135974886344192 run.py:806] Done!
