I0221 13:53:12.605580 137302230619648 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0221 13:53:12.607932 137302230619648 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0221 13:53:12.983670 137302230619648 run.py:443] Model: f10 ['activity_selector']
I0221 13:53:12.983786 137302230619648 run.py:445] algorithms ['activity_selector']
I0221 13:53:12.984015 137302230619648 run.py:446] train_lengths ['4', '7', '11', '13', '16']
I0221 13:53:12.984064 137302230619648 run.py:447] train_batch_size 16
I0221 13:53:12.984198 137302230619648 run.py:448] val_batch_size 16
I0221 13:53:12.984257 137302230619648 run.py:449] test_batch_size 16
I0221 13:53:12.984298 137302230619648 run.py:450] chunked_training True
I0221 13:53:12.984458 137302230619648 run.py:451] chunk_length 16
I0221 13:53:12.984502 137302230619648 run.py:452] train_steps 8001
I0221 13:53:12.984544 137302230619648 run.py:453] eval_every 50
I0221 13:53:12.984584 137302230619648 run.py:454] test_every 500
I0221 13:53:12.984624 137302230619648 run.py:455] hidden_size 256
I0221 13:53:12.984665 137302230619648 run.py:456] nb_msg_passing_steps 1
I0221 13:53:12.984704 137302230619648 run.py:457] learning_rate 0.001
I0221 13:53:12.984833 137302230619648 run.py:458] grad_clip_max_norm 1.0
I0221 13:53:12.984874 137302230619648 run.py:459] dropout_prob 0.0
I0221 13:53:12.984915 137302230619648 run.py:460] hint_teacher_forcing 0.0
I0221 13:53:12.984954 137302230619648 run.py:461] hint_mode encoded_decoded
I0221 13:53:12.985096 137302230619648 run.py:462] hint_repred_mode soft
I0221 13:53:12.985137 137302230619648 run.py:463] use_ln True
I0221 13:53:12.985178 137302230619648 run.py:464] use_lstm True
I0221 13:53:12.985225 137302230619648 run.py:465] nb_triplet_fts 16
I0221 13:53:12.985269 137302230619648 run.py:466] encoder_init xavier_on_scalars
I0221 13:53:12.985311 137302230619648 run.py:467] processor_type f10
I0221 13:53:12.985351 137302230619648 run.py:468] checkpoint_path CLRS30
I0221 13:53:12.985390 137302230619648 run.py:469] dataset_path CLRS30
I0221 13:53:12.985432 137302230619648 run.py:470] freeze_processor False
I0221 13:53:12.985471 137302230619648 run.py:471] reduction min
I0221 13:53:12.985510 137302230619648 run.py:472] activation elu
I0221 13:53:12.985552 137302230619648 run.py:473] restore_model 
I0221 13:53:12.985590 137302230619648 run.py:474] gated True
I0221 13:53:12.985629 137302230619648 run.py:475] gated_activation sigmoid
I0221 13:53:12.985671 137302230619648 run.py:476] memory_type mha
I0221 13:53:12.985720 137302230619648 run.py:477] memory_size 16
I0221 13:53:12.989307 137302230619648 run.py:503] Creating samplers for algo activity_selector
W0221 13:53:12.989573 137302230619648 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0221 13:53:12.989951 137302230619648 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0221 13:53:13.207819 137302230619648 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0221 13:53:13.456269 137302230619648 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0221 13:53:13.770358 137302230619648 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0221 13:53:14.105536 137302230619648 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0221 13:53:14.505546 137302230619648 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0221 13:53:14.505836 137302230619648 samplers.py:124] Creating a dataset with 64 samples.
I0221 13:53:14.531567 137302230619648 run.py:287] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0221 13:53:14.532333 137302230619648 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0221 13:53:14.535304 137302230619648 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0221 13:53:14.539178 137302230619648 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0221 13:53:14.593363 137302230619648 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W0221 13:53:14.614242 137302230619648 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x7cdfa61ba160> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0221 13:53:51.028151 137302230619648 run.py:729] Algo activity_selector step 0 current loss 5.169611, current_train_items 32.
I0221 13:54:01.329071 137302230619648 run.py:764] (val) algo activity_selector step 0: {'selected': 0.6187245590230666, 'score': 0.6187245590230666, 'examples_seen': 32, 'step': 0, 'algorithm': 'activity_selector'}
I0221 13:54:01.329262 137302230619648 run.py:785] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.619, val scores are: activity_selector: 0.619
I0221 13:54:57.336923 137302230619648 run.py:729] Algo activity_selector step 50 current loss 3.639387, current_train_items 1408.
I0221 13:54:57.473872 137302230619648 run.py:764] (val) algo activity_selector step 50: {'selected': 0.6810344827586207, 'score': 0.6810344827586207, 'examples_seen': 1408, 'step': 50, 'algorithm': 'activity_selector'}
I0221 13:54:57.474110 137302230619648 run.py:785] Checkpointing best model, best avg val score was 0.619, current avg val score is 0.681, val scores are: activity_selector: 0.681
I0221 13:54:58.691091 137302230619648 run.py:729] Algo activity_selector step 100 current loss 3.865747, current_train_items 2800.
I0221 13:54:58.831601 137302230619648 run.py:764] (val) algo activity_selector step 100: {'selected': 0.7145877378435518, 'score': 0.7145877378435518, 'examples_seen': 2800, 'step': 100, 'algorithm': 'activity_selector'}
I0221 13:54:58.831821 137302230619648 run.py:785] Checkpointing best model, best avg val score was 0.681, current avg val score is 0.715, val scores are: activity_selector: 0.715
I0221 13:55:00.062685 137302230619648 run.py:729] Algo activity_selector step 150 current loss 2.748516, current_train_items 4176.
I0221 13:55:00.206251 137302230619648 run.py:764] (val) algo activity_selector step 150: {'selected': 0.7445887445887446, 'score': 0.7445887445887446, 'examples_seen': 4176, 'step': 150, 'algorithm': 'activity_selector'}
I0221 13:55:00.206482 137302230619648 run.py:785] Checkpointing best model, best avg val score was 0.715, current avg val score is 0.745, val scores are: activity_selector: 0.745
I0221 13:55:01.420779 137302230619648 run.py:729] Algo activity_selector step 200 current loss 2.710573, current_train_items 5536.
I0221 13:55:01.560451 137302230619648 run.py:764] (val) algo activity_selector step 200: {'selected': 0.7392197125256673, 'score': 0.7392197125256673, 'examples_seen': 5536, 'step': 200, 'algorithm': 'activity_selector'}
I0221 13:55:01.560698 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.745, current avg val score is 0.739, val scores are: activity_selector: 0.739
I0221 13:55:02.619718 137302230619648 run.py:729] Algo activity_selector step 250 current loss 2.299407, current_train_items 6944.
I0221 13:55:02.762474 137302230619648 run.py:764] (val) algo activity_selector step 250: {'selected': 0.6784140969162995, 'score': 0.6784140969162995, 'examples_seen': 6944, 'step': 250, 'algorithm': 'activity_selector'}
I0221 13:55:02.762723 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.745, current avg val score is 0.678, val scores are: activity_selector: 0.678
I0221 13:55:03.832716 137302230619648 run.py:729] Algo activity_selector step 300 current loss 1.935454, current_train_items 8304.
I0221 13:55:03.972814 137302230619648 run.py:764] (val) algo activity_selector step 300: {'selected': 0.8201438848920864, 'score': 0.8201438848920864, 'examples_seen': 8304, 'step': 300, 'algorithm': 'activity_selector'}
I0221 13:55:03.973050 137302230619648 run.py:785] Checkpointing best model, best avg val score was 0.745, current avg val score is 0.820, val scores are: activity_selector: 0.820
I0221 13:55:05.196216 137302230619648 run.py:729] Algo activity_selector step 350 current loss 1.925687, current_train_items 9680.
I0221 13:55:05.337342 137302230619648 run.py:764] (val) algo activity_selector step 350: {'selected': 0.8428571428571429, 'score': 0.8428571428571429, 'examples_seen': 9680, 'step': 350, 'algorithm': 'activity_selector'}
I0221 13:55:05.337585 137302230619648 run.py:785] Checkpointing best model, best avg val score was 0.820, current avg val score is 0.843, val scores are: activity_selector: 0.843
I0221 13:55:06.550333 137302230619648 run.py:729] Algo activity_selector step 400 current loss 2.016950, current_train_items 11072.
I0221 13:55:06.692935 137302230619648 run.py:764] (val) algo activity_selector step 400: {'selected': 0.8227194492254734, 'score': 0.8227194492254734, 'examples_seen': 11072, 'step': 400, 'algorithm': 'activity_selector'}
I0221 13:55:06.693170 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.843, current avg val score is 0.823, val scores are: activity_selector: 0.823
I0221 13:55:07.762642 137302230619648 run.py:729] Algo activity_selector step 450 current loss 1.739830, current_train_items 12448.
I0221 13:55:07.901478 137302230619648 run.py:764] (val) algo activity_selector step 450: {'selected': 0.802065404475043, 'score': 0.802065404475043, 'examples_seen': 12448, 'step': 450, 'algorithm': 'activity_selector'}
I0221 13:55:07.901702 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.843, current avg val score is 0.802, val scores are: activity_selector: 0.802
I0221 13:55:08.965551 137302230619648 run.py:729] Algo activity_selector step 500 current loss 2.548255, current_train_items 13824.
I0221 13:55:09.105896 137302230619648 run.py:764] (val) algo activity_selector step 500: {'selected': 0.7866108786610879, 'score': 0.7866108786610879, 'examples_seen': 13824, 'step': 500, 'algorithm': 'activity_selector'}
I0221 13:55:09.106132 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.843, current avg val score is 0.787, val scores are: activity_selector: 0.787
I0221 13:55:10.156851 137302230619648 run.py:729] Algo activity_selector step 550 current loss 1.651230, current_train_items 15200.
I0221 13:55:10.311884 137302230619648 run.py:764] (val) algo activity_selector step 550: {'selected': 0.8853118712273642, 'score': 0.8853118712273642, 'examples_seen': 15200, 'step': 550, 'algorithm': 'activity_selector'}
I0221 13:55:10.312107 137302230619648 run.py:785] Checkpointing best model, best avg val score was 0.843, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0221 13:55:11.533709 137302230619648 run.py:729] Algo activity_selector step 600 current loss 1.777554, current_train_items 16576.
I0221 13:55:11.673289 137302230619648 run.py:764] (val) algo activity_selector step 600: {'selected': 0.862962962962963, 'score': 0.862962962962963, 'examples_seen': 16576, 'step': 600, 'algorithm': 'activity_selector'}
I0221 13:55:11.673479 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.885, current avg val score is 0.863, val scores are: activity_selector: 0.863
I0221 13:55:12.725000 137302230619648 run.py:729] Algo activity_selector step 650 current loss 1.754537, current_train_items 17952.
I0221 13:55:12.862883 137302230619648 run.py:764] (val) algo activity_selector step 650: {'selected': 0.8613138686131387, 'score': 0.8613138686131387, 'examples_seen': 17952, 'step': 650, 'algorithm': 'activity_selector'}
I0221 13:55:12.863109 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.885, current avg val score is 0.861, val scores are: activity_selector: 0.861
I0221 13:55:13.909409 137302230619648 run.py:729] Algo activity_selector step 700 current loss 1.650470, current_train_items 19344.
I0221 13:55:14.061238 137302230619648 run.py:764] (val) algo activity_selector step 700: {'selected': 0.8784313725490196, 'score': 0.8784313725490196, 'examples_seen': 19344, 'step': 700, 'algorithm': 'activity_selector'}
I0221 13:55:14.061460 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.885, current avg val score is 0.878, val scores are: activity_selector: 0.878
I0221 13:55:15.137407 137302230619648 run.py:729] Algo activity_selector step 750 current loss 1.777886, current_train_items 20720.
I0221 13:55:15.278731 137302230619648 run.py:764] (val) algo activity_selector step 750: {'selected': 0.8804780876494023, 'score': 0.8804780876494023, 'examples_seen': 20720, 'step': 750, 'algorithm': 'activity_selector'}
I0221 13:55:15.278954 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.885, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0221 13:55:16.324781 137302230619648 run.py:729] Algo activity_selector step 800 current loss 1.557136, current_train_items 22096.
I0221 13:55:16.474445 137302230619648 run.py:764] (val) algo activity_selector step 800: {'selected': 0.9142857142857143, 'score': 0.9142857142857143, 'examples_seen': 22096, 'step': 800, 'algorithm': 'activity_selector'}
I0221 13:55:16.474594 137302230619648 run.py:785] Checkpointing best model, best avg val score was 0.885, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0221 13:55:17.697478 137302230619648 run.py:729] Algo activity_selector step 850 current loss 1.573665, current_train_items 23472.
I0221 13:55:17.837071 137302230619648 run.py:764] (val) algo activity_selector step 850: {'selected': 0.8253358925143954, 'score': 0.8253358925143954, 'examples_seen': 23472, 'step': 850, 'algorithm': 'activity_selector'}
I0221 13:55:17.837311 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.914, current avg val score is 0.825, val scores are: activity_selector: 0.825
I0221 13:55:18.907130 137302230619648 run.py:729] Algo activity_selector step 900 current loss 1.940459, current_train_items 24848.
I0221 13:55:19.046112 137302230619648 run.py:764] (val) algo activity_selector step 900: {'selected': 0.8700787401574803, 'score': 0.8700787401574803, 'examples_seen': 24848, 'step': 900, 'algorithm': 'activity_selector'}
I0221 13:55:19.046349 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.914, current avg val score is 0.870, val scores are: activity_selector: 0.870
I0221 13:55:20.110939 137302230619648 run.py:729] Algo activity_selector step 950 current loss 1.703527, current_train_items 26224.
I0221 13:55:20.250922 137302230619648 run.py:764] (val) algo activity_selector step 950: {'selected': 0.8288288288288289, 'score': 0.8288288288288289, 'examples_seen': 26224, 'step': 950, 'algorithm': 'activity_selector'}
I0221 13:55:20.251145 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.914, current avg val score is 0.829, val scores are: activity_selector: 0.829
I0221 13:55:21.310125 137302230619648 run.py:729] Algo activity_selector step 1000 current loss 1.585470, current_train_items 27616.
I0221 13:55:21.449966 137302230619648 run.py:764] (val) algo activity_selector step 1000: {'selected': 0.8913857677902622, 'score': 0.8913857677902622, 'examples_seen': 27616, 'step': 1000, 'algorithm': 'activity_selector'}
I0221 13:55:21.450188 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.914, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0221 13:55:22.519798 137302230619648 run.py:729] Algo activity_selector step 1050 current loss 1.628428, current_train_items 28992.
I0221 13:55:22.660557 137302230619648 run.py:764] (val) algo activity_selector step 1050: {'selected': 0.9242424242424243, 'score': 0.9242424242424243, 'examples_seen': 28992, 'step': 1050, 'algorithm': 'activity_selector'}
I0221 13:55:22.660840 137302230619648 run.py:785] Checkpointing best model, best avg val score was 0.914, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0221 13:55:23.880326 137302230619648 run.py:729] Algo activity_selector step 1100 current loss 1.580821, current_train_items 30368.
I0221 13:55:24.018989 137302230619648 run.py:764] (val) algo activity_selector step 1100: {'selected': 0.895910780669145, 'score': 0.895910780669145, 'examples_seen': 30368, 'step': 1100, 'algorithm': 'activity_selector'}
I0221 13:55:24.019229 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.924, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0221 13:55:25.066922 137302230619648 run.py:729] Algo activity_selector step 1150 current loss 1.290293, current_train_items 31760.
I0221 13:55:25.224281 137302230619648 run.py:764] (val) algo activity_selector step 1150: {'selected': 0.8969258589511755, 'score': 0.8969258589511755, 'examples_seen': 31760, 'step': 1150, 'algorithm': 'activity_selector'}
I0221 13:55:25.224542 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.924, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0221 13:55:26.295986 137302230619648 run.py:729] Algo activity_selector step 1200 current loss 1.360487, current_train_items 33120.
I0221 13:55:26.432815 137302230619648 run.py:764] (val) algo activity_selector step 1200: {'selected': 0.8863636363636364, 'score': 0.8863636363636364, 'examples_seen': 33120, 'step': 1200, 'algorithm': 'activity_selector'}
I0221 13:55:26.432965 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.924, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0221 13:55:27.482998 137302230619648 run.py:729] Algo activity_selector step 1250 current loss 1.593363, current_train_items 34496.
I0221 13:55:27.618093 137302230619648 run.py:764] (val) algo activity_selector step 1250: {'selected': 0.8844765342960288, 'score': 0.8844765342960288, 'examples_seen': 34496, 'step': 1250, 'algorithm': 'activity_selector'}
I0221 13:55:27.618254 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.924, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0221 13:55:28.667474 137302230619648 run.py:729] Algo activity_selector step 1300 current loss 1.490034, current_train_items 35888.
I0221 13:55:28.804862 137302230619648 run.py:764] (val) algo activity_selector step 1300: {'selected': 0.9140625, 'score': 0.9140625, 'examples_seen': 35888, 'step': 1300, 'algorithm': 'activity_selector'}
I0221 13:55:28.805011 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.924, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0221 13:55:29.863420 137302230619648 run.py:729] Algo activity_selector step 1350 current loss 1.333970, current_train_items 37264.
I0221 13:55:29.997714 137302230619648 run.py:764] (val) algo activity_selector step 1350: {'selected': 0.9152542372881355, 'score': 0.9152542372881355, 'examples_seen': 37264, 'step': 1350, 'algorithm': 'activity_selector'}
I0221 13:55:29.997891 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.924, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0221 13:55:31.061441 137302230619648 run.py:729] Algo activity_selector step 1400 current loss 1.147830, current_train_items 38640.
I0221 13:55:31.200289 137302230619648 run.py:764] (val) algo activity_selector step 1400: {'selected': 0.9139579349904398, 'score': 0.9139579349904398, 'examples_seen': 38640, 'step': 1400, 'algorithm': 'activity_selector'}
I0221 13:55:31.200453 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.924, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0221 13:55:32.250721 137302230619648 run.py:729] Algo activity_selector step 1450 current loss 1.103099, current_train_items 40016.
I0221 13:55:32.389438 137302230619648 run.py:764] (val) algo activity_selector step 1450: {'selected': 0.9278752436647173, 'score': 0.9278752436647173, 'examples_seen': 40016, 'step': 1450, 'algorithm': 'activity_selector'}
I0221 13:55:32.389669 137302230619648 run.py:785] Checkpointing best model, best avg val score was 0.924, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0221 13:55:33.611530 137302230619648 run.py:729] Algo activity_selector step 1500 current loss 1.289900, current_train_items 41408.
I0221 13:55:33.753729 137302230619648 run.py:764] (val) algo activity_selector step 1500: {'selected': 0.9115913555992141, 'score': 0.9115913555992141, 'examples_seen': 41408, 'step': 1500, 'algorithm': 'activity_selector'}
I0221 13:55:33.753961 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.928, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0221 13:55:34.815870 137302230619648 run.py:729] Algo activity_selector step 1550 current loss 1.423541, current_train_items 42768.
I0221 13:55:34.954789 137302230619648 run.py:764] (val) algo activity_selector step 1550: {'selected': 0.9409660107334525, 'score': 0.9409660107334525, 'examples_seen': 42768, 'step': 1550, 'algorithm': 'activity_selector'}
I0221 13:55:34.955013 137302230619648 run.py:785] Checkpointing best model, best avg val score was 0.928, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0221 13:55:36.182188 137302230619648 run.py:729] Algo activity_selector step 1600 current loss 1.269087, current_train_items 44160.
I0221 13:55:36.323138 137302230619648 run.py:764] (val) algo activity_selector step 1600: {'selected': 0.9166666666666666, 'score': 0.9166666666666666, 'examples_seen': 44160, 'step': 1600, 'algorithm': 'activity_selector'}
I0221 13:55:36.323382 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.941, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0221 13:55:37.379156 137302230619648 run.py:729] Algo activity_selector step 1650 current loss 1.202384, current_train_items 45536.
I0221 13:55:37.532797 137302230619648 run.py:764] (val) algo activity_selector step 1650: {'selected': 0.8801652892561984, 'score': 0.8801652892561984, 'examples_seen': 45536, 'step': 1650, 'algorithm': 'activity_selector'}
I0221 13:55:37.533020 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.941, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0221 13:55:38.592680 137302230619648 run.py:729] Algo activity_selector step 1700 current loss 1.016483, current_train_items 46896.
I0221 13:55:38.733293 137302230619648 run.py:764] (val) algo activity_selector step 1700: {'selected': 0.944, 'score': 0.944, 'examples_seen': 46896, 'step': 1700, 'algorithm': 'activity_selector'}
I0221 13:55:38.733517 137302230619648 run.py:785] Checkpointing best model, best avg val score was 0.941, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0221 13:55:39.948588 137302230619648 run.py:729] Algo activity_selector step 1750 current loss 1.330752, current_train_items 48304.
I0221 13:55:40.089507 137302230619648 run.py:764] (val) algo activity_selector step 1750: {'selected': 0.8702010968921389, 'score': 0.8702010968921389, 'examples_seen': 48304, 'step': 1750, 'algorithm': 'activity_selector'}
I0221 13:55:40.089735 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.944, current avg val score is 0.870, val scores are: activity_selector: 0.870
I0221 13:55:41.217504 137302230619648 run.py:729] Algo activity_selector step 1800 current loss 1.324598, current_train_items 49664.
I0221 13:55:41.303145 137302230619648 run.py:764] (val) algo activity_selector step 1800: {'selected': 0.8741007194244604, 'score': 0.8741007194244604, 'examples_seen': 49664, 'step': 1800, 'algorithm': 'activity_selector'}
I0221 13:55:41.303351 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.944, current avg val score is 0.874, val scores are: activity_selector: 0.874
I0221 13:55:42.342359 137302230619648 run.py:729] Algo activity_selector step 1850 current loss 1.028160, current_train_items 51056.
I0221 13:55:42.495512 137302230619648 run.py:764] (val) algo activity_selector step 1850: {'selected': 0.9134438305709024, 'score': 0.9134438305709024, 'examples_seen': 51056, 'step': 1850, 'algorithm': 'activity_selector'}
I0221 13:55:42.495732 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.944, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0221 13:55:43.558717 137302230619648 run.py:729] Algo activity_selector step 1900 current loss 0.875370, current_train_items 52432.
I0221 13:55:43.700593 137302230619648 run.py:764] (val) algo activity_selector step 1900: {'selected': 0.9236363636363636, 'score': 0.9236363636363636, 'examples_seen': 52432, 'step': 1900, 'algorithm': 'activity_selector'}
I0221 13:55:43.700813 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.944, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0221 13:55:44.775304 137302230619648 run.py:729] Algo activity_selector step 1950 current loss 1.223516, current_train_items 53808.
I0221 13:55:44.918359 137302230619648 run.py:764] (val) algo activity_selector step 1950: {'selected': 0.9380863039399624, 'score': 0.9380863039399624, 'examples_seen': 53808, 'step': 1950, 'algorithm': 'activity_selector'}
I0221 13:55:44.918582 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.944, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0221 13:55:45.985925 137302230619648 run.py:729] Algo activity_selector step 2000 current loss 1.285280, current_train_items 55184.
I0221 13:55:46.126297 137302230619648 run.py:764] (val) algo activity_selector step 2000: {'selected': 0.9411764705882352, 'score': 0.9411764705882352, 'examples_seen': 55184, 'step': 2000, 'algorithm': 'activity_selector'}
I0221 13:55:46.126518 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.944, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0221 13:55:47.190858 137302230619648 run.py:729] Algo activity_selector step 2050 current loss 0.949123, current_train_items 56560.
I0221 13:55:47.330199 137302230619648 run.py:764] (val) algo activity_selector step 2050: {'selected': 0.939622641509434, 'score': 0.939622641509434, 'examples_seen': 56560, 'step': 2050, 'algorithm': 'activity_selector'}
I0221 13:55:47.330441 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.944, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0221 13:55:48.405319 137302230619648 run.py:729] Algo activity_selector step 2100 current loss 1.291525, current_train_items 57952.
I0221 13:55:48.545787 137302230619648 run.py:764] (val) algo activity_selector step 2100: {'selected': 0.9356060606060606, 'score': 0.9356060606060606, 'examples_seen': 57952, 'step': 2100, 'algorithm': 'activity_selector'}
I0221 13:55:48.546024 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.944, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0221 13:55:49.610151 137302230619648 run.py:729] Algo activity_selector step 2150 current loss 1.358035, current_train_items 59312.
I0221 13:55:49.751629 137302230619648 run.py:764] (val) algo activity_selector step 2150: {'selected': 0.9295238095238095, 'score': 0.9295238095238095, 'examples_seen': 59312, 'step': 2150, 'algorithm': 'activity_selector'}
I0221 13:55:49.751852 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.944, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0221 13:55:50.815655 137302230619648 run.py:729] Algo activity_selector step 2200 current loss 1.224592, current_train_items 60720.
I0221 13:55:50.959524 137302230619648 run.py:764] (val) algo activity_selector step 2200: {'selected': 0.9083820662768033, 'score': 0.9083820662768033, 'examples_seen': 60720, 'step': 2200, 'algorithm': 'activity_selector'}
I0221 13:55:50.959750 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.944, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0221 13:55:52.023006 137302230619648 run.py:729] Algo activity_selector step 2250 current loss 1.114034, current_train_items 62080.
I0221 13:55:52.161425 137302230619648 run.py:764] (val) algo activity_selector step 2250: {'selected': 0.8970873786407766, 'score': 0.8970873786407766, 'examples_seen': 62080, 'step': 2250, 'algorithm': 'activity_selector'}
I0221 13:55:52.161650 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.944, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0221 13:55:53.211624 137302230619648 run.py:729] Algo activity_selector step 2300 current loss 0.947856, current_train_items 63440.
I0221 13:55:53.367241 137302230619648 run.py:764] (val) algo activity_selector step 2300: {'selected': 0.9034749034749034, 'score': 0.9034749034749034, 'examples_seen': 63440, 'step': 2300, 'algorithm': 'activity_selector'}
I0221 13:55:53.367476 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.944, current avg val score is 0.903, val scores are: activity_selector: 0.903
I0221 13:55:54.417571 137302230619648 run.py:729] Algo activity_selector step 2350 current loss 0.904123, current_train_items 64848.
I0221 13:55:54.571990 137302230619648 run.py:764] (val) algo activity_selector step 2350: {'selected': 0.9611829944547134, 'score': 0.9611829944547134, 'examples_seen': 64848, 'step': 2350, 'algorithm': 'activity_selector'}
I0221 13:55:54.572227 137302230619648 run.py:785] Checkpointing best model, best avg val score was 0.944, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0221 13:55:55.811524 137302230619648 run.py:729] Algo activity_selector step 2400 current loss 1.148737, current_train_items 66208.
I0221 13:55:55.945378 137302230619648 run.py:764] (val) algo activity_selector step 2400: {'selected': 0.8909774436090225, 'score': 0.8909774436090225, 'examples_seen': 66208, 'step': 2400, 'algorithm': 'activity_selector'}
I0221 13:55:55.945600 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0221 13:55:56.999843 137302230619648 run.py:729] Algo activity_selector step 2450 current loss 1.063067, current_train_items 67600.
I0221 13:55:57.153110 137302230619648 run.py:764] (val) algo activity_selector step 2450: {'selected': 0.9479768786127167, 'score': 0.9479768786127167, 'examples_seen': 67600, 'step': 2450, 'algorithm': 'activity_selector'}
I0221 13:55:57.153348 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0221 13:55:58.217725 137302230619648 run.py:729] Algo activity_selector step 2500 current loss 0.950076, current_train_items 68976.
I0221 13:55:58.358522 137302230619648 run.py:764] (val) algo activity_selector step 2500: {'selected': 0.93359375, 'score': 0.93359375, 'examples_seen': 68976, 'step': 2500, 'algorithm': 'activity_selector'}
I0221 13:55:58.358741 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0221 13:55:59.432855 137302230619648 run.py:729] Algo activity_selector step 2550 current loss 1.215406, current_train_items 70352.
I0221 13:55:59.572939 137302230619648 run.py:764] (val) algo activity_selector step 2550: {'selected': 0.9261992619926198, 'score': 0.9261992619926198, 'examples_seen': 70352, 'step': 2550, 'algorithm': 'activity_selector'}
I0221 13:55:59.573177 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0221 13:56:00.641053 137302230619648 run.py:729] Algo activity_selector step 2600 current loss 0.737683, current_train_items 71728.
I0221 13:56:00.784528 137302230619648 run.py:764] (val) algo activity_selector step 2600: {'selected': 0.9383697813121272, 'score': 0.9383697813121272, 'examples_seen': 71728, 'step': 2600, 'algorithm': 'activity_selector'}
I0221 13:56:00.784749 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0221 13:56:01.840298 137302230619648 run.py:729] Algo activity_selector step 2650 current loss 0.761812, current_train_items 73104.
I0221 13:56:01.992707 137302230619648 run.py:764] (val) algo activity_selector step 2650: {'selected': 0.920892494929006, 'score': 0.920892494929006, 'examples_seen': 73104, 'step': 2650, 'algorithm': 'activity_selector'}
I0221 13:56:01.992955 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0221 13:56:03.070389 137302230619648 run.py:729] Algo activity_selector step 2700 current loss 0.980763, current_train_items 74496.
I0221 13:56:03.209259 137302230619648 run.py:764] (val) algo activity_selector step 2700: {'selected': 0.9244935543278084, 'score': 0.9244935543278084, 'examples_seen': 74496, 'step': 2700, 'algorithm': 'activity_selector'}
I0221 13:56:03.209520 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0221 13:56:04.275883 137302230619648 run.py:729] Algo activity_selector step 2750 current loss 1.000808, current_train_items 75856.
I0221 13:56:04.413528 137302230619648 run.py:764] (val) algo activity_selector step 2750: {'selected': 0.8736059479553904, 'score': 0.8736059479553904, 'examples_seen': 75856, 'step': 2750, 'algorithm': 'activity_selector'}
I0221 13:56:04.413755 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.874, val scores are: activity_selector: 0.874
I0221 13:56:05.485655 137302230619648 run.py:729] Algo activity_selector step 2800 current loss 0.989642, current_train_items 77264.
I0221 13:56:05.616887 137302230619648 run.py:764] (val) algo activity_selector step 2800: {'selected': 0.83991683991684, 'score': 0.83991683991684, 'examples_seen': 77264, 'step': 2800, 'algorithm': 'activity_selector'}
I0221 13:56:05.617127 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.840, val scores are: activity_selector: 0.840
I0221 13:56:06.695070 137302230619648 run.py:729] Algo activity_selector step 2850 current loss 1.137797, current_train_items 78624.
I0221 13:56:06.836397 137302230619648 run.py:764] (val) algo activity_selector step 2850: {'selected': 0.9301397205588823, 'score': 0.9301397205588823, 'examples_seen': 78624, 'step': 2850, 'algorithm': 'activity_selector'}
I0221 13:56:06.836653 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0221 13:56:07.899976 137302230619648 run.py:729] Algo activity_selector step 2900 current loss 0.906066, current_train_items 80000.
I0221 13:56:08.037470 137302230619648 run.py:764] (val) algo activity_selector step 2900: {'selected': 0.8709055876685935, 'score': 0.8709055876685935, 'examples_seen': 80000, 'step': 2900, 'algorithm': 'activity_selector'}
I0221 13:56:08.037618 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.871, val scores are: activity_selector: 0.871
I0221 13:56:09.091301 137302230619648 run.py:729] Algo activity_selector step 2950 current loss 0.930011, current_train_items 81392.
I0221 13:56:09.231505 137302230619648 run.py:764] (val) algo activity_selector step 2950: {'selected': 0.961089494163424, 'score': 0.961089494163424, 'examples_seen': 81392, 'step': 2950, 'algorithm': 'activity_selector'}
I0221 13:56:09.231652 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0221 13:56:10.276551 137302230619648 run.py:729] Algo activity_selector step 3000 current loss 1.080587, current_train_items 82752.
I0221 13:56:10.428812 137302230619648 run.py:764] (val) algo activity_selector step 3000: {'selected': 0.9245283018867925, 'score': 0.9245283018867925, 'examples_seen': 82752, 'step': 3000, 'algorithm': 'activity_selector'}
I0221 13:56:10.428960 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0221 13:56:11.483782 137302230619648 run.py:729] Algo activity_selector step 3050 current loss 0.893296, current_train_items 84144.
I0221 13:56:11.626024 137302230619648 run.py:764] (val) algo activity_selector step 3050: {'selected': 0.9404761904761906, 'score': 0.9404761904761906, 'examples_seen': 84144, 'step': 3050, 'algorithm': 'activity_selector'}
I0221 13:56:11.626260 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0221 13:56:12.695827 137302230619648 run.py:729] Algo activity_selector step 3100 current loss 1.030013, current_train_items 85520.
I0221 13:56:12.832967 137302230619648 run.py:764] (val) algo activity_selector step 3100: {'selected': 0.9275929549902153, 'score': 0.9275929549902153, 'examples_seen': 85520, 'step': 3100, 'algorithm': 'activity_selector'}
I0221 13:56:12.833242 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0221 13:56:13.909232 137302230619648 run.py:729] Algo activity_selector step 3150 current loss 0.713651, current_train_items 86896.
I0221 13:56:14.049351 137302230619648 run.py:764] (val) algo activity_selector step 3150: {'selected': 0.9405204460966542, 'score': 0.9405204460966542, 'examples_seen': 86896, 'step': 3150, 'algorithm': 'activity_selector'}
I0221 13:56:14.049587 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0221 13:56:15.114326 137302230619648 run.py:729] Algo activity_selector step 3200 current loss 0.750470, current_train_items 88272.
I0221 13:56:15.256223 137302230619648 run.py:764] (val) algo activity_selector step 3200: {'selected': 0.9169811320754718, 'score': 0.9169811320754718, 'examples_seen': 88272, 'step': 3200, 'algorithm': 'activity_selector'}
I0221 13:56:15.256446 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0221 13:56:16.307481 137302230619648 run.py:729] Algo activity_selector step 3250 current loss 1.011411, current_train_items 89664.
I0221 13:56:16.462061 137302230619648 run.py:764] (val) algo activity_selector step 3250: {'selected': 0.9340866290018833, 'score': 0.9340866290018833, 'examples_seen': 89664, 'step': 3250, 'algorithm': 'activity_selector'}
I0221 13:56:16.462303 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0221 13:56:17.542790 137302230619648 run.py:729] Algo activity_selector step 3300 current loss 0.939245, current_train_items 91040.
I0221 13:56:17.684601 137302230619648 run.py:764] (val) algo activity_selector step 3300: {'selected': 0.8955223880597014, 'score': 0.8955223880597014, 'examples_seen': 91040, 'step': 3300, 'algorithm': 'activity_selector'}
I0221 13:56:17.684847 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0221 13:56:18.750174 137302230619648 run.py:729] Algo activity_selector step 3350 current loss 0.976402, current_train_items 92400.
I0221 13:56:18.890579 137302230619648 run.py:764] (val) algo activity_selector step 3350: {'selected': 0.9219330855018587, 'score': 0.9219330855018587, 'examples_seen': 92400, 'step': 3350, 'algorithm': 'activity_selector'}
I0221 13:56:18.890817 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0221 13:56:19.954824 137302230619648 run.py:729] Algo activity_selector step 3400 current loss 1.060810, current_train_items 93792.
I0221 13:56:20.094370 137302230619648 run.py:764] (val) algo activity_selector step 3400: {'selected': 0.9418604651162791, 'score': 0.9418604651162791, 'examples_seen': 93792, 'step': 3400, 'algorithm': 'activity_selector'}
I0221 13:56:20.094596 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0221 13:56:21.155407 137302230619648 run.py:729] Algo activity_selector step 3450 current loss 0.932298, current_train_items 95168.
I0221 13:56:21.312039 137302230619648 run.py:764] (val) algo activity_selector step 3450: {'selected': 0.8948374760994264, 'score': 0.8948374760994264, 'examples_seen': 95168, 'step': 3450, 'algorithm': 'activity_selector'}
I0221 13:56:21.312279 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.895, val scores are: activity_selector: 0.895
I0221 13:56:22.380198 137302230619648 run.py:729] Algo activity_selector step 3500 current loss 0.854319, current_train_items 96544.
I0221 13:56:22.518847 137302230619648 run.py:764] (val) algo activity_selector step 3500: {'selected': 0.8926553672316384, 'score': 0.8926553672316384, 'examples_seen': 96544, 'step': 3500, 'algorithm': 'activity_selector'}
I0221 13:56:22.519074 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0221 13:56:23.582773 137302230619648 run.py:729] Algo activity_selector step 3550 current loss 0.632548, current_train_items 97936.
I0221 13:56:23.724704 137302230619648 run.py:764] (val) algo activity_selector step 3550: {'selected': 0.9712092130518234, 'score': 0.9712092130518234, 'examples_seen': 97936, 'step': 3550, 'algorithm': 'activity_selector'}
I0221 13:56:23.724926 137302230619648 run.py:785] Checkpointing best model, best avg val score was 0.961, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0221 13:56:24.939472 137302230619648 run.py:729] Algo activity_selector step 3600 current loss 0.753822, current_train_items 99312.
I0221 13:56:25.094165 137302230619648 run.py:764] (val) algo activity_selector step 3600: {'selected': 0.9641434262948207, 'score': 0.9641434262948207, 'examples_seen': 99312, 'step': 3600, 'algorithm': 'activity_selector'}
I0221 13:56:25.094403 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0221 13:56:26.162552 137302230619648 run.py:729] Algo activity_selector step 3650 current loss 0.884381, current_train_items 100688.
I0221 13:56:26.304441 137302230619648 run.py:764] (val) algo activity_selector step 3650: {'selected': 0.9492753623188406, 'score': 0.9492753623188406, 'examples_seen': 100688, 'step': 3650, 'algorithm': 'activity_selector'}
I0221 13:56:26.304659 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0221 13:56:27.371802 137302230619648 run.py:729] Algo activity_selector step 3700 current loss 0.869382, current_train_items 102064.
I0221 13:56:27.512966 137302230619648 run.py:764] (val) algo activity_selector step 3700: {'selected': 0.952191235059761, 'score': 0.952191235059761, 'examples_seen': 102064, 'step': 3700, 'algorithm': 'activity_selector'}
I0221 13:56:27.513203 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0221 13:56:28.587903 137302230619648 run.py:729] Algo activity_selector step 3750 current loss 0.717788, current_train_items 103440.
I0221 13:56:28.727251 137302230619648 run.py:764] (val) algo activity_selector step 3750: {'selected': 0.9248554913294798, 'score': 0.9248554913294798, 'examples_seen': 103440, 'step': 3750, 'algorithm': 'activity_selector'}
I0221 13:56:28.727472 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0221 13:56:29.791895 137302230619648 run.py:729] Algo activity_selector step 3800 current loss 0.800772, current_train_items 104816.
I0221 13:56:29.929273 137302230619648 run.py:764] (val) algo activity_selector step 3800: {'selected': 0.9359999999999999, 'score': 0.9359999999999999, 'examples_seen': 104816, 'step': 3800, 'algorithm': 'activity_selector'}
I0221 13:56:29.929498 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0221 13:56:30.993075 137302230619648 run.py:729] Algo activity_selector step 3850 current loss 1.036747, current_train_items 106208.
I0221 13:56:31.132919 137302230619648 run.py:764] (val) algo activity_selector step 3850: {'selected': 0.9378531073446327, 'score': 0.9378531073446327, 'examples_seen': 106208, 'step': 3850, 'algorithm': 'activity_selector'}
I0221 13:56:31.133137 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0221 13:56:32.193634 137302230619648 run.py:729] Algo activity_selector step 3900 current loss 0.767912, current_train_items 107584.
I0221 13:56:32.349768 137302230619648 run.py:764] (val) algo activity_selector step 3900: {'selected': 0.9516441005802707, 'score': 0.9516441005802707, 'examples_seen': 107584, 'step': 3900, 'algorithm': 'activity_selector'}
I0221 13:56:32.349989 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0221 13:56:33.417252 137302230619648 run.py:729] Algo activity_selector step 3950 current loss 1.055946, current_train_items 108960.
I0221 13:56:33.557290 137302230619648 run.py:764] (val) algo activity_selector step 3950: {'selected': 0.9640831758034027, 'score': 0.9640831758034027, 'examples_seen': 108960, 'step': 3950, 'algorithm': 'activity_selector'}
I0221 13:56:33.557515 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0221 13:56:34.624787 137302230619648 run.py:729] Algo activity_selector step 4000 current loss 0.964142, current_train_items 110336.
I0221 13:56:34.766086 137302230619648 run.py:764] (val) algo activity_selector step 4000: {'selected': 0.8937875751503007, 'score': 0.8937875751503007, 'examples_seen': 110336, 'step': 4000, 'algorithm': 'activity_selector'}
I0221 13:56:34.766364 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0221 13:56:35.825547 137302230619648 run.py:729] Algo activity_selector step 4050 current loss 0.803841, current_train_items 111712.
I0221 13:56:35.979158 137302230619648 run.py:764] (val) algo activity_selector step 4050: {'selected': 0.9351145038167938, 'score': 0.9351145038167938, 'examples_seen': 111712, 'step': 4050, 'algorithm': 'activity_selector'}
I0221 13:56:35.979402 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0221 13:56:37.042520 137302230619648 run.py:729] Algo activity_selector step 4100 current loss 0.814384, current_train_items 113088.
I0221 13:56:37.186580 137302230619648 run.py:764] (val) algo activity_selector step 4100: {'selected': 0.9437386569872959, 'score': 0.9437386569872959, 'examples_seen': 113088, 'step': 4100, 'algorithm': 'activity_selector'}
I0221 13:56:37.186807 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0221 13:56:38.255219 137302230619648 run.py:729] Algo activity_selector step 4150 current loss 0.822716, current_train_items 114480.
I0221 13:56:38.395496 137302230619648 run.py:764] (val) algo activity_selector step 4150: {'selected': 0.9283018867924528, 'score': 0.9283018867924528, 'examples_seen': 114480, 'step': 4150, 'algorithm': 'activity_selector'}
I0221 13:56:38.395746 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0221 13:56:39.469892 137302230619648 run.py:729] Algo activity_selector step 4200 current loss 1.055827, current_train_items 115856.
I0221 13:56:39.612085 137302230619648 run.py:764] (val) algo activity_selector step 4200: {'selected': 0.9011406844106464, 'score': 0.9011406844106464, 'examples_seen': 115856, 'step': 4200, 'algorithm': 'activity_selector'}
I0221 13:56:39.612350 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.901, val scores are: activity_selector: 0.901
I0221 13:56:40.684483 137302230619648 run.py:729] Algo activity_selector step 4250 current loss 0.992499, current_train_items 117216.
I0221 13:56:40.818366 137302230619648 run.py:764] (val) algo activity_selector step 4250: {'selected': 0.933579335793358, 'score': 0.933579335793358, 'examples_seen': 117216, 'step': 4250, 'algorithm': 'activity_selector'}
I0221 13:56:40.818613 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0221 13:56:41.868791 137302230619648 run.py:729] Algo activity_selector step 4300 current loss 1.026139, current_train_items 118624.
I0221 13:56:42.019434 137302230619648 run.py:764] (val) algo activity_selector step 4300: {'selected': 0.9614678899082569, 'score': 0.9614678899082569, 'examples_seen': 118624, 'step': 4300, 'algorithm': 'activity_selector'}
I0221 13:56:42.019655 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0221 13:56:43.098440 137302230619648 run.py:729] Algo activity_selector step 4350 current loss 0.644262, current_train_items 119984.
I0221 13:56:43.239930 137302230619648 run.py:764] (val) algo activity_selector step 4350: {'selected': 0.9593810444874273, 'score': 0.9593810444874273, 'examples_seen': 119984, 'step': 4350, 'algorithm': 'activity_selector'}
I0221 13:56:43.240153 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0221 13:56:44.302809 137302230619648 run.py:729] Algo activity_selector step 4400 current loss 0.734542, current_train_items 121360.
I0221 13:56:44.443472 137302230619648 run.py:764] (val) algo activity_selector step 4400: {'selected': 0.9398907103825136, 'score': 0.9398907103825136, 'examples_seen': 121360, 'step': 4400, 'algorithm': 'activity_selector'}
I0221 13:56:44.443697 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0221 13:56:45.523126 137302230619648 run.py:729] Algo activity_selector step 4450 current loss 0.817226, current_train_items 122752.
I0221 13:56:45.646795 137302230619648 run.py:764] (val) algo activity_selector step 4450: {'selected': 0.9259962049335864, 'score': 0.9259962049335864, 'examples_seen': 122752, 'step': 4450, 'algorithm': 'activity_selector'}
I0221 13:56:45.647037 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0221 13:56:46.720337 137302230619648 run.py:729] Algo activity_selector step 4500 current loss 1.052635, current_train_items 124128.
I0221 13:56:46.861964 137302230619648 run.py:764] (val) algo activity_selector step 4500: {'selected': 0.9686274509803922, 'score': 0.9686274509803922, 'examples_seen': 124128, 'step': 4500, 'algorithm': 'activity_selector'}
I0221 13:56:46.862189 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0221 13:56:47.927469 137302230619648 run.py:729] Algo activity_selector step 4550 current loss 0.737919, current_train_items 125504.
I0221 13:56:48.070334 137302230619648 run.py:764] (val) algo activity_selector step 4550: {'selected': 0.9248554913294798, 'score': 0.9248554913294798, 'examples_seen': 125504, 'step': 4550, 'algorithm': 'activity_selector'}
I0221 13:56:48.070558 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0221 13:56:49.134449 137302230619648 run.py:729] Algo activity_selector step 4600 current loss 0.921057, current_train_items 126880.
I0221 13:56:49.276055 137302230619648 run.py:764] (val) algo activity_selector step 4600: {'selected': 0.932562620423892, 'score': 0.932562620423892, 'examples_seen': 126880, 'step': 4600, 'algorithm': 'activity_selector'}
I0221 13:56:49.276324 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0221 13:56:50.350805 137302230619648 run.py:729] Algo activity_selector step 4650 current loss 0.714360, current_train_items 128272.
I0221 13:56:50.489455 137302230619648 run.py:764] (val) algo activity_selector step 4650: {'selected': 0.9424860853432281, 'score': 0.9424860853432281, 'examples_seen': 128272, 'step': 4650, 'algorithm': 'activity_selector'}
I0221 13:56:50.489703 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0221 13:56:51.543340 137302230619648 run.py:729] Algo activity_selector step 4700 current loss 0.843546, current_train_items 129632.
I0221 13:56:51.697478 137302230619648 run.py:764] (val) algo activity_selector step 4700: {'selected': 0.9291044776119403, 'score': 0.9291044776119403, 'examples_seen': 129632, 'step': 4700, 'algorithm': 'activity_selector'}
I0221 13:56:51.697631 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0221 13:56:52.753504 137302230619648 run.py:729] Algo activity_selector step 4750 current loss 1.089266, current_train_items 131024.
I0221 13:56:52.888678 137302230619648 run.py:764] (val) algo activity_selector step 4750: {'selected': 0.9328358208955224, 'score': 0.9328358208955224, 'examples_seen': 131024, 'step': 4750, 'algorithm': 'activity_selector'}
I0221 13:56:52.888899 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0221 13:56:53.966688 137302230619648 run.py:729] Algo activity_selector step 4800 current loss 0.683893, current_train_items 132400.
I0221 13:56:54.105935 137302230619648 run.py:764] (val) algo activity_selector step 4800: {'selected': 0.9277566539923956, 'score': 0.9277566539923956, 'examples_seen': 132400, 'step': 4800, 'algorithm': 'activity_selector'}
I0221 13:56:54.106155 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0221 13:56:55.170800 137302230619648 run.py:729] Algo activity_selector step 4850 current loss 0.813700, current_train_items 133760.
I0221 13:56:55.312076 137302230619648 run.py:764] (val) algo activity_selector step 4850: {'selected': 0.9238578680203046, 'score': 0.9238578680203046, 'examples_seen': 133760, 'step': 4850, 'algorithm': 'activity_selector'}
I0221 13:56:55.312317 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0221 13:56:56.376430 137302230619648 run.py:729] Algo activity_selector step 4900 current loss 0.859016, current_train_items 135168.
I0221 13:56:56.517054 137302230619648 run.py:764] (val) algo activity_selector step 4900: {'selected': 0.9411764705882353, 'score': 0.9411764705882353, 'examples_seen': 135168, 'step': 4900, 'algorithm': 'activity_selector'}
I0221 13:56:56.517290 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0221 13:56:57.577606 137302230619648 run.py:729] Algo activity_selector step 4950 current loss 0.937201, current_train_items 136528.
I0221 13:56:57.732842 137302230619648 run.py:764] (val) algo activity_selector step 4950: {'selected': 0.9266409266409267, 'score': 0.9266409266409267, 'examples_seen': 136528, 'step': 4950, 'algorithm': 'activity_selector'}
I0221 13:56:57.733069 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0221 13:56:58.802278 137302230619648 run.py:729] Algo activity_selector step 5000 current loss 0.729991, current_train_items 137920.
I0221 13:56:58.942541 137302230619648 run.py:764] (val) algo activity_selector step 5000: {'selected': 0.9552238805970149, 'score': 0.9552238805970149, 'examples_seen': 137920, 'step': 5000, 'algorithm': 'activity_selector'}
I0221 13:56:58.942763 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0221 13:57:00.010897 137302230619648 run.py:729] Algo activity_selector step 5050 current loss 0.807652, current_train_items 139296.
I0221 13:57:00.151359 137302230619648 run.py:764] (val) algo activity_selector step 5050: {'selected': 0.9523809523809523, 'score': 0.9523809523809523, 'examples_seen': 139296, 'step': 5050, 'algorithm': 'activity_selector'}
I0221 13:57:00.151581 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0221 13:57:01.212329 137302230619648 run.py:729] Algo activity_selector step 5100 current loss 0.708404, current_train_items 140656.
I0221 13:57:01.366342 137302230619648 run.py:764] (val) algo activity_selector step 5100: {'selected': 0.9074733096085409, 'score': 0.9074733096085409, 'examples_seen': 140656, 'step': 5100, 'algorithm': 'activity_selector'}
I0221 13:57:01.366567 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0221 13:57:02.416396 137302230619648 run.py:729] Algo activity_selector step 5150 current loss 0.868110, current_train_items 142048.
I0221 13:57:02.569757 137302230619648 run.py:764] (val) algo activity_selector step 5150: {'selected': 0.9724409448818898, 'score': 0.9724409448818898, 'examples_seen': 142048, 'step': 5150, 'algorithm': 'activity_selector'}
I0221 13:57:02.569980 137302230619648 run.py:785] Checkpointing best model, best avg val score was 0.971, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0221 13:57:03.776557 137302230619648 run.py:729] Algo activity_selector step 5200 current loss 0.627151, current_train_items 143424.
I0221 13:57:03.929731 137302230619648 run.py:764] (val) algo activity_selector step 5200: {'selected': 0.970873786407767, 'score': 0.970873786407767, 'examples_seen': 143424, 'step': 5200, 'algorithm': 'activity_selector'}
I0221 13:57:03.929955 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0221 13:57:05.003542 137302230619648 run.py:729] Algo activity_selector step 5250 current loss 0.707037, current_train_items 144816.
I0221 13:57:05.141664 137302230619648 run.py:764] (val) algo activity_selector step 5250: {'selected': 0.9236363636363636, 'score': 0.9236363636363636, 'examples_seen': 144816, 'step': 5250, 'algorithm': 'activity_selector'}
I0221 13:57:05.141888 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0221 13:57:06.205670 137302230619648 run.py:729] Algo activity_selector step 5300 current loss 0.913932, current_train_items 146176.
I0221 13:57:06.348072 137302230619648 run.py:764] (val) algo activity_selector step 5300: {'selected': 0.9601518026565464, 'score': 0.9601518026565464, 'examples_seen': 146176, 'step': 5300, 'algorithm': 'activity_selector'}
I0221 13:57:06.348309 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0221 13:57:07.411659 137302230619648 run.py:729] Algo activity_selector step 5350 current loss 0.753368, current_train_items 147584.
I0221 13:57:07.552833 137302230619648 run.py:764] (val) algo activity_selector step 5350: {'selected': 0.9355432780847146, 'score': 0.9355432780847146, 'examples_seen': 147584, 'step': 5350, 'algorithm': 'activity_selector'}
I0221 13:57:07.553070 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0221 13:57:08.614240 137302230619648 run.py:729] Algo activity_selector step 5400 current loss 0.726240, current_train_items 148944.
I0221 13:57:08.772497 137302230619648 run.py:764] (val) algo activity_selector step 5400: {'selected': 0.9292543021032506, 'score': 0.9292543021032506, 'examples_seen': 148944, 'step': 5400, 'algorithm': 'activity_selector'}
I0221 13:57:08.772723 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0221 13:57:09.836901 137302230619648 run.py:729] Algo activity_selector step 5450 current loss 0.797910, current_train_items 150304.
I0221 13:57:09.977202 137302230619648 run.py:764] (val) algo activity_selector step 5450: {'selected': 0.9073724007561437, 'score': 0.9073724007561437, 'examples_seen': 150304, 'step': 5450, 'algorithm': 'activity_selector'}
I0221 13:57:09.977442 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0221 13:57:11.040846 137302230619648 run.py:729] Algo activity_selector step 5500 current loss 0.956087, current_train_items 151712.
I0221 13:57:11.179753 137302230619648 run.py:764] (val) algo activity_selector step 5500: {'selected': 0.8866396761133601, 'score': 0.8866396761133601, 'examples_seen': 151712, 'step': 5500, 'algorithm': 'activity_selector'}
I0221 13:57:11.179981 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.887, val scores are: activity_selector: 0.887
I0221 13:57:12.239092 137302230619648 run.py:729] Algo activity_selector step 5550 current loss 1.003425, current_train_items 153072.
I0221 13:57:12.395417 137302230619648 run.py:764] (val) algo activity_selector step 5550: {'selected': 0.928030303030303, 'score': 0.928030303030303, 'examples_seen': 153072, 'step': 5550, 'algorithm': 'activity_selector'}
I0221 13:57:12.395645 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0221 13:57:13.445800 137302230619648 run.py:729] Algo activity_selector step 5600 current loss 0.574735, current_train_items 154464.
I0221 13:57:13.598180 137302230619648 run.py:764] (val) algo activity_selector step 5600: {'selected': 0.9635974304068523, 'score': 0.9635974304068523, 'examples_seen': 154464, 'step': 5600, 'algorithm': 'activity_selector'}
I0221 13:57:13.598445 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0221 13:57:14.651787 137302230619648 run.py:729] Algo activity_selector step 5650 current loss 0.630431, current_train_items 155840.
I0221 13:57:14.808156 137302230619648 run.py:764] (val) algo activity_selector step 5650: {'selected': 0.9385474860335196, 'score': 0.9385474860335196, 'examples_seen': 155840, 'step': 5650, 'algorithm': 'activity_selector'}
I0221 13:57:14.808398 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0221 13:57:15.882240 137302230619648 run.py:729] Algo activity_selector step 5700 current loss 0.659743, current_train_items 157216.
I0221 13:57:16.021145 137302230619648 run.py:764] (val) algo activity_selector step 5700: {'selected': 0.952991452991453, 'score': 0.952991452991453, 'examples_seen': 157216, 'step': 5700, 'algorithm': 'activity_selector'}
I0221 13:57:16.021382 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0221 13:57:17.074417 137302230619648 run.py:729] Algo activity_selector step 5750 current loss 0.669376, current_train_items 158592.
I0221 13:57:17.230019 137302230619648 run.py:764] (val) algo activity_selector step 5750: {'selected': 0.9386138613861386, 'score': 0.9386138613861386, 'examples_seen': 158592, 'step': 5750, 'algorithm': 'activity_selector'}
I0221 13:57:17.230266 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0221 13:57:18.294175 137302230619648 run.py:729] Algo activity_selector step 5800 current loss 0.768114, current_train_items 159968.
I0221 13:57:18.433522 137302230619648 run.py:764] (val) algo activity_selector step 5800: {'selected': 0.9210526315789475, 'score': 0.9210526315789475, 'examples_seen': 159968, 'step': 5800, 'algorithm': 'activity_selector'}
I0221 13:57:18.433745 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0221 13:57:19.499090 137302230619648 run.py:729] Algo activity_selector step 5850 current loss 0.959770, current_train_items 161360.
I0221 13:57:19.653232 137302230619648 run.py:764] (val) algo activity_selector step 5850: {'selected': 0.9575757575757576, 'score': 0.9575757575757576, 'examples_seen': 161360, 'step': 5850, 'algorithm': 'activity_selector'}
I0221 13:57:19.653455 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0221 13:57:20.716612 137302230619648 run.py:729] Algo activity_selector step 5900 current loss 0.730249, current_train_items 162720.
I0221 13:57:20.857305 137302230619648 run.py:764] (val) algo activity_selector step 5900: {'selected': 0.9586466165413534, 'score': 0.9586466165413534, 'examples_seen': 162720, 'step': 5900, 'algorithm': 'activity_selector'}
I0221 13:57:20.857528 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0221 13:57:21.921590 137302230619648 run.py:729] Algo activity_selector step 5950 current loss 0.462339, current_train_items 164112.
I0221 13:57:22.063200 137302230619648 run.py:764] (val) algo activity_selector step 5950: {'selected': 0.9391634980988595, 'score': 0.9391634980988595, 'examples_seen': 164112, 'step': 5950, 'algorithm': 'activity_selector'}
I0221 13:57:22.063437 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0221 13:57:23.138275 137302230619648 run.py:729] Algo activity_selector step 6000 current loss 0.843163, current_train_items 165488.
I0221 13:57:23.279850 137302230619648 run.py:764] (val) algo activity_selector step 6000: {'selected': 0.9340866290018832, 'score': 0.9340866290018832, 'examples_seen': 165488, 'step': 6000, 'algorithm': 'activity_selector'}
I0221 13:57:23.280076 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0221 13:57:24.334134 137302230619648 run.py:729] Algo activity_selector step 6050 current loss 0.981176, current_train_items 166864.
I0221 13:57:24.489227 137302230619648 run.py:764] (val) algo activity_selector step 6050: {'selected': 0.9197651663405088, 'score': 0.9197651663405088, 'examples_seen': 166864, 'step': 6050, 'algorithm': 'activity_selector'}
I0221 13:57:24.489468 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0221 13:57:25.542582 137302230619648 run.py:729] Algo activity_selector step 6100 current loss 0.713924, current_train_items 168256.
I0221 13:57:25.698677 137302230619648 run.py:764] (val) algo activity_selector step 6100: {'selected': 0.9316770186335404, 'score': 0.9316770186335404, 'examples_seen': 168256, 'step': 6100, 'algorithm': 'activity_selector'}
I0221 13:57:25.698905 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0221 13:57:26.758892 137302230619648 run.py:729] Algo activity_selector step 6150 current loss 0.851485, current_train_items 169616.
I0221 13:57:26.911856 137302230619648 run.py:764] (val) algo activity_selector step 6150: {'selected': 0.9260869565217391, 'score': 0.9260869565217391, 'examples_seen': 169616, 'step': 6150, 'algorithm': 'activity_selector'}
I0221 13:57:26.912081 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0221 13:57:27.976227 137302230619648 run.py:729] Algo activity_selector step 6200 current loss 0.826762, current_train_items 171008.
I0221 13:57:28.115892 137302230619648 run.py:764] (val) algo activity_selector step 6200: {'selected': 0.9252525252525252, 'score': 0.9252525252525252, 'examples_seen': 171008, 'step': 6200, 'algorithm': 'activity_selector'}
I0221 13:57:28.116116 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0221 13:57:29.179660 137302230619648 run.py:729] Algo activity_selector step 6250 current loss 0.688241, current_train_items 172384.
I0221 13:57:29.321912 137302230619648 run.py:764] (val) algo activity_selector step 6250: {'selected': 0.9512670565302144, 'score': 0.9512670565302144, 'examples_seen': 172384, 'step': 6250, 'algorithm': 'activity_selector'}
I0221 13:57:29.322139 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0221 13:57:30.384820 137302230619648 run.py:729] Algo activity_selector step 6300 current loss 0.444732, current_train_items 173760.
I0221 13:57:30.537933 137302230619648 run.py:764] (val) algo activity_selector step 6300: {'selected': 0.9592233009708738, 'score': 0.9592233009708738, 'examples_seen': 173760, 'step': 6300, 'algorithm': 'activity_selector'}
I0221 13:57:30.538155 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0221 13:57:31.600801 137302230619648 run.py:729] Algo activity_selector step 6350 current loss 0.701103, current_train_items 175136.
I0221 13:57:31.743752 137302230619648 run.py:764] (val) algo activity_selector step 6350: {'selected': 0.9409368635437881, 'score': 0.9409368635437881, 'examples_seen': 175136, 'step': 6350, 'algorithm': 'activity_selector'}
I0221 13:57:31.743995 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0221 13:57:32.807199 137302230619648 run.py:729] Algo activity_selector step 6400 current loss 0.728127, current_train_items 176528.
I0221 13:57:32.949062 137302230619648 run.py:764] (val) algo activity_selector step 6400: {'selected': 0.9362549800796813, 'score': 0.9362549800796813, 'examples_seen': 176528, 'step': 6400, 'algorithm': 'activity_selector'}
I0221 13:57:32.949303 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0221 13:57:34.064788 137302230619648 run.py:729] Algo activity_selector step 6450 current loss 0.518719, current_train_items 177904.
I0221 13:57:34.214407 137302230619648 run.py:764] (val) algo activity_selector step 6450: {'selected': 0.9492753623188405, 'score': 0.9492753623188405, 'examples_seen': 177904, 'step': 6450, 'algorithm': 'activity_selector'}
I0221 13:57:34.214667 137302230619648 run.py:785] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0221 13:57:35.426704 137302230619648 run.py:729] Algo activity_selector step 6500 current loss 0.476144, current_train_items 179264.
I0221 13:57:35.567968 137302230619648 run.py:764] (val) algo activity_selector step 6500: {'selected': 0.9464285714285714, 'score': 0.9464285714285714, 'examples_seen': 179264, 'step': 6500, 'algorithm': 'activity_selector'}
I0221 13:57:35.568189 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.949, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0221 13:57:36.631420 137302230619648 run.py:729] Algo activity_selector step 6550 current loss 0.562553, current_train_items 180656.
I0221 13:57:36.772876 137302230619648 run.py:764] (val) algo activity_selector step 6550: {'selected': 0.9442379182156134, 'score': 0.9442379182156134, 'examples_seen': 180656, 'step': 6550, 'algorithm': 'activity_selector'}
I0221 13:57:36.773099 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.949, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0221 13:57:37.846866 137302230619648 run.py:729] Algo activity_selector step 6600 current loss 0.984062, current_train_items 182032.
I0221 13:57:37.985581 137302230619648 run.py:764] (val) algo activity_selector step 6600: {'selected': 0.9523809523809524, 'score': 0.9523809523809524, 'examples_seen': 182032, 'step': 6600, 'algorithm': 'activity_selector'}
I0221 13:57:37.985803 137302230619648 run.py:785] Checkpointing best model, best avg val score was 0.949, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0221 13:57:39.205617 137302230619648 run.py:729] Algo activity_selector step 6650 current loss 0.929578, current_train_items 183408.
I0221 13:57:39.348062 137302230619648 run.py:764] (val) algo activity_selector step 6650: {'selected': 0.934131736526946, 'score': 0.934131736526946, 'examples_seen': 183408, 'step': 6650, 'algorithm': 'activity_selector'}
I0221 13:57:39.348309 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0221 13:57:40.402699 137302230619648 run.py:729] Algo activity_selector step 6700 current loss 0.775562, current_train_items 184800.
I0221 13:57:40.558237 137302230619648 run.py:764] (val) algo activity_selector step 6700: {'selected': 0.9465346534653465, 'score': 0.9465346534653465, 'examples_seen': 184800, 'step': 6700, 'algorithm': 'activity_selector'}
I0221 13:57:40.558461 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0221 13:57:41.632694 137302230619648 run.py:729] Algo activity_selector step 6750 current loss 0.672760, current_train_items 186176.
I0221 13:57:41.774859 137302230619648 run.py:764] (val) algo activity_selector step 6750: {'selected': 0.9255533199195172, 'score': 0.9255533199195172, 'examples_seen': 186176, 'step': 6750, 'algorithm': 'activity_selector'}
I0221 13:57:41.775086 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0221 13:57:42.826501 137302230619648 run.py:729] Algo activity_selector step 6800 current loss 0.590352, current_train_items 187536.
I0221 13:57:42.980422 137302230619648 run.py:764] (val) algo activity_selector step 6800: {'selected': 0.9467455621301776, 'score': 0.9467455621301776, 'examples_seen': 187536, 'step': 6800, 'algorithm': 'activity_selector'}
I0221 13:57:42.980649 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0221 13:57:44.044515 137302230619648 run.py:729] Algo activity_selector step 6850 current loss 0.763560, current_train_items 188928.
I0221 13:57:44.184418 137302230619648 run.py:764] (val) algo activity_selector step 6850: {'selected': 0.9267399267399268, 'score': 0.9267399267399268, 'examples_seen': 188928, 'step': 6850, 'algorithm': 'activity_selector'}
I0221 13:57:44.184646 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0221 13:57:45.263251 137302230619648 run.py:729] Algo activity_selector step 6900 current loss 0.683533, current_train_items 190304.
I0221 13:57:45.404332 137302230619648 run.py:764] (val) algo activity_selector step 6900: {'selected': 0.9521988527724666, 'score': 0.9521988527724666, 'examples_seen': 190304, 'step': 6900, 'algorithm': 'activity_selector'}
I0221 13:57:45.404586 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0221 13:57:46.467889 137302230619648 run.py:729] Algo activity_selector step 6950 current loss 0.667458, current_train_items 191680.
I0221 13:57:46.606406 137302230619648 run.py:764] (val) algo activity_selector step 6950: {'selected': 0.9467455621301776, 'score': 0.9467455621301776, 'examples_seen': 191680, 'step': 6950, 'algorithm': 'activity_selector'}
I0221 13:57:46.606652 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0221 13:57:47.672713 137302230619648 run.py:729] Algo activity_selector step 7000 current loss 0.947259, current_train_items 193072.
I0221 13:57:47.811780 137302230619648 run.py:764] (val) algo activity_selector step 7000: {'selected': 0.9579158316633267, 'score': 0.9579158316633267, 'examples_seen': 193072, 'step': 7000, 'algorithm': 'activity_selector'}
I0221 13:57:47.812037 137302230619648 run.py:785] Checkpointing best model, best avg val score was 0.952, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0221 13:57:49.039913 137302230619648 run.py:729] Algo activity_selector step 7050 current loss 0.473273, current_train_items 194448.
I0221 13:57:49.182061 137302230619648 run.py:764] (val) algo activity_selector step 7050: {'selected': 0.9424460431654677, 'score': 0.9424460431654677, 'examples_seen': 194448, 'step': 7050, 'algorithm': 'activity_selector'}
I0221 13:57:49.182304 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.958, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0221 13:57:50.251024 137302230619648 run.py:729] Algo activity_selector step 7100 current loss 0.552860, current_train_items 195824.
I0221 13:57:50.390481 137302230619648 run.py:764] (val) algo activity_selector step 7100: {'selected': 0.9548872180451128, 'score': 0.9548872180451128, 'examples_seen': 195824, 'step': 7100, 'algorithm': 'activity_selector'}
I0221 13:57:50.390700 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.958, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0221 13:57:51.458292 137302230619648 run.py:729] Algo activity_selector step 7150 current loss 0.649330, current_train_items 197200.
I0221 13:57:51.599178 137302230619648 run.py:764] (val) algo activity_selector step 7150: {'selected': 0.9660377358490566, 'score': 0.9660377358490566, 'examples_seen': 197200, 'step': 7150, 'algorithm': 'activity_selector'}
I0221 13:57:51.599419 137302230619648 run.py:785] Checkpointing best model, best avg val score was 0.958, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0221 13:57:52.820706 137302230619648 run.py:729] Algo activity_selector step 7200 current loss 0.739662, current_train_items 198576.
I0221 13:57:52.960953 137302230619648 run.py:764] (val) algo activity_selector step 7200: {'selected': 0.9409448818897638, 'score': 0.9409448818897638, 'examples_seen': 198576, 'step': 7200, 'algorithm': 'activity_selector'}
I0221 13:57:52.961177 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.966, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0221 13:57:54.025644 137302230619648 run.py:729] Algo activity_selector step 7250 current loss 0.579492, current_train_items 199952.
I0221 13:57:54.165584 137302230619648 run.py:764] (val) algo activity_selector step 7250: {'selected': 0.9563492063492063, 'score': 0.9563492063492063, 'examples_seen': 199952, 'step': 7250, 'algorithm': 'activity_selector'}
I0221 13:57:54.165818 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.966, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0221 13:57:55.234420 137302230619648 run.py:729] Algo activity_selector step 7300 current loss 0.694563, current_train_items 201344.
I0221 13:57:55.375283 137302230619648 run.py:764] (val) algo activity_selector step 7300: {'selected': 0.9616858237547892, 'score': 0.9616858237547892, 'examples_seen': 201344, 'step': 7300, 'algorithm': 'activity_selector'}
I0221 13:57:55.375508 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.966, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0221 13:57:56.439032 137302230619648 run.py:729] Algo activity_selector step 7350 current loss 0.915255, current_train_items 202720.
I0221 13:57:56.590261 137302230619648 run.py:764] (val) algo activity_selector step 7350: {'selected': 0.9377593360995851, 'score': 0.9377593360995851, 'examples_seen': 202720, 'step': 7350, 'algorithm': 'activity_selector'}
I0221 13:57:56.590487 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.966, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0221 13:57:57.654573 137302230619648 run.py:729] Algo activity_selector step 7400 current loss 0.907926, current_train_items 204080.
I0221 13:57:57.796090 137302230619648 run.py:764] (val) algo activity_selector step 7400: {'selected': 0.9169811320754717, 'score': 0.9169811320754717, 'examples_seen': 204080, 'step': 7400, 'algorithm': 'activity_selector'}
I0221 13:57:57.796333 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.966, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0221 13:57:58.847797 137302230619648 run.py:729] Algo activity_selector step 7450 current loss 0.810912, current_train_items 205488.
I0221 13:57:58.999945 137302230619648 run.py:764] (val) algo activity_selector step 7450: {'selected': 0.940952380952381, 'score': 0.940952380952381, 'examples_seen': 205488, 'step': 7450, 'algorithm': 'activity_selector'}
I0221 13:57:59.000169 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.966, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0221 13:58:00.075806 137302230619648 run.py:729] Algo activity_selector step 7500 current loss 0.504846, current_train_items 206848.
I0221 13:58:00.214895 137302230619648 run.py:764] (val) algo activity_selector step 7500: {'selected': 0.9606003752345215, 'score': 0.9606003752345215, 'examples_seen': 206848, 'step': 7500, 'algorithm': 'activity_selector'}
I0221 13:58:00.215142 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.966, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0221 13:58:01.286994 137302230619648 run.py:729] Algo activity_selector step 7550 current loss 0.709898, current_train_items 208224.
I0221 13:58:01.425899 137302230619648 run.py:764] (val) algo activity_selector step 7550: {'selected': 0.9430255402750491, 'score': 0.9430255402750491, 'examples_seen': 208224, 'step': 7550, 'algorithm': 'activity_selector'}
I0221 13:58:01.426121 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.966, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0221 13:58:02.476803 137302230619648 run.py:729] Algo activity_selector step 7600 current loss 1.056445, current_train_items 209616.
I0221 13:58:02.630001 137302230619648 run.py:764] (val) algo activity_selector step 7600: {'selected': 0.9584905660377357, 'score': 0.9584905660377357, 'examples_seen': 209616, 'step': 7600, 'algorithm': 'activity_selector'}
I0221 13:58:02.630240 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.966, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0221 13:58:03.690684 137302230619648 run.py:729] Algo activity_selector step 7650 current loss 0.661029, current_train_items 210976.
I0221 13:58:03.845787 137302230619648 run.py:764] (val) algo activity_selector step 7650: {'selected': 0.9013035381750466, 'score': 0.9013035381750466, 'examples_seen': 210976, 'step': 7650, 'algorithm': 'activity_selector'}
I0221 13:58:03.846009 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.966, current avg val score is 0.901, val scores are: activity_selector: 0.901
I0221 13:58:04.909935 137302230619648 run.py:729] Algo activity_selector step 7700 current loss 0.606247, current_train_items 212368.
I0221 13:58:05.050588 137302230619648 run.py:764] (val) algo activity_selector step 7700: {'selected': 0.9678714859437751, 'score': 0.9678714859437751, 'examples_seen': 212368, 'step': 7700, 'algorithm': 'activity_selector'}
I0221 13:58:05.050812 137302230619648 run.py:785] Checkpointing best model, best avg val score was 0.966, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0221 13:58:06.278021 137302230619648 run.py:729] Algo activity_selector step 7750 current loss 0.587103, current_train_items 213744.
I0221 13:58:06.418119 137302230619648 run.py:764] (val) algo activity_selector step 7750: {'selected': 0.9420560747663552, 'score': 0.9420560747663552, 'examples_seen': 213744, 'step': 7750, 'algorithm': 'activity_selector'}
I0221 13:58:06.418358 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.968, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0221 13:58:07.478831 137302230619648 run.py:729] Algo activity_selector step 7800 current loss 0.742887, current_train_items 215136.
I0221 13:58:07.632369 137302230619648 run.py:764] (val) algo activity_selector step 7800: {'selected': 0.9243027888446216, 'score': 0.9243027888446216, 'examples_seen': 215136, 'step': 7800, 'algorithm': 'activity_selector'}
I0221 13:58:07.632593 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.968, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0221 13:58:08.686389 137302230619648 run.py:729] Algo activity_selector step 7850 current loss 0.471391, current_train_items 216496.
I0221 13:58:08.839935 137302230619648 run.py:764] (val) algo activity_selector step 7850: {'selected': 0.9725490196078431, 'score': 0.9725490196078431, 'examples_seen': 216496, 'step': 7850, 'algorithm': 'activity_selector'}
I0221 13:58:08.840161 137302230619648 run.py:785] Checkpointing best model, best avg val score was 0.968, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0221 13:58:10.046333 137302230619648 run.py:729] Algo activity_selector step 7900 current loss 0.607478, current_train_items 217888.
I0221 13:58:10.203467 137302230619648 run.py:764] (val) algo activity_selector step 7900: {'selected': 0.9471698113207548, 'score': 0.9471698113207548, 'examples_seen': 217888, 'step': 7900, 'algorithm': 'activity_selector'}
I0221 13:58:10.203697 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.973, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0221 13:58:11.290839 137302230619648 run.py:729] Algo activity_selector step 7950 current loss 0.590387, current_train_items 219264.
I0221 13:58:11.422534 137302230619648 run.py:764] (val) algo activity_selector step 7950: {'selected': 0.9669117647058824, 'score': 0.9669117647058824, 'examples_seen': 219264, 'step': 7950, 'algorithm': 'activity_selector'}
I0221 13:58:11.422757 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.973, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0221 13:58:12.501917 137302230619648 run.py:729] Algo activity_selector step 8000 current loss 0.598761, current_train_items 220624.
I0221 13:58:12.641009 137302230619648 run.py:764] (val) algo activity_selector step 8000: {'selected': 0.9687500000000001, 'score': 0.9687500000000001, 'examples_seen': 220624, 'step': 8000, 'algorithm': 'activity_selector'}
I0221 13:58:12.641258 137302230619648 run.py:788] Not saving new best model, best avg val score was 0.973, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0221 13:58:12.641358 137302230619648 run.py:794] Restoring best model from checkpoint...
I0221 13:58:23.918096 137302230619648 run.py:809] (test) algo activity_selector : {'selected': 0.9017543859649123, 'score': 0.9017543859649123, 'examples_seen': 220624, 'step': 8001, 'algorithm': 'activity_selector'}
I0221 13:58:23.918295 137302230619648 run.py:811] Done!
