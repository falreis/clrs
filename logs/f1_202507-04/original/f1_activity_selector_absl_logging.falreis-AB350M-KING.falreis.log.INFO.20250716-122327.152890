I0716 12:23:29.517333 140714243360256 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0716 12:23:29.517994 140714243360256 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0716 12:23:29.757271 140714243360256 run.py:415] Model: falreis ['activity_selector']
I0716 12:23:29.757370 140714243360256 run.py:417] algorithms ['activity_selector']
I0716 12:23:29.757551 140714243360256 run.py:418] train_lengths ['2', '3', '5', '7', '11', '13', '16']
I0716 12:23:29.757589 140714243360256 run.py:419] train_batch_size 16
I0716 12:23:29.757679 140714243360256 run.py:420] val_batch_size 8
I0716 12:23:29.757711 140714243360256 run.py:421] test_batch_size 8
I0716 12:23:29.757741 140714243360256 run.py:422] chunked_training True
I0716 12:23:29.757864 140714243360256 run.py:423] chunk_length 16
I0716 12:23:29.757894 140714243360256 run.py:424] train_steps 10000
I0716 12:23:29.757924 140714243360256 run.py:425] eval_every 50
I0716 12:23:29.757953 140714243360256 run.py:426] test_every 500
I0716 12:23:29.757982 140714243360256 run.py:427] learning_rate 0.001
I0716 12:23:29.758072 140714243360256 run.py:428] grad_clip_max_norm 1.0
I0716 12:23:29.758102 140714243360256 run.py:429] dropout_prob 0.1
I0716 12:23:29.758132 140714243360256 run.py:430] hint_teacher_forcing 0.0
I0716 12:23:29.758160 140714243360256 run.py:431] hint_mode encoded_decoded
I0716 12:23:29.758260 140714243360256 run.py:432] hint_repred_mode hard_on_eval
I0716 12:23:29.758289 140714243360256 run.py:433] use_ln False
I0716 12:23:29.758317 140714243360256 run.py:434] use_lstm True
I0716 12:23:29.758345 140714243360256 run.py:435] nb_triplet_fts 8
I0716 12:23:29.758373 140714243360256 run.py:436] encoder_init xavier_on_scalars
I0716 12:23:29.758400 140714243360256 run.py:437] processor_type falreis
I0716 12:23:29.758428 140714243360256 run.py:438] checkpoint_path CLRS30
I0716 12:23:29.758456 140714243360256 run.py:439] dataset_path CLRS30
I0716 12:23:29.758485 140714243360256 run.py:440] freeze_processor False
I0716 12:23:29.758513 140714243360256 run.py:441] reduction min
I0716 12:23:29.758551 140714243360256 run.py:442] activation elu
I0716 12:23:29.758581 140714243360256 run.py:443] algorithm_models ['F1', 'F2']
I0716 12:23:29.758610 140714243360256 run.py:444] restore_model 
I0716 12:23:29.758638 140714243360256 run.py:445] gated True
I0716 12:23:29.758665 140714243360256 run.py:446] gated_activation sigmoid
I0716 12:23:29.761234 140714243360256 run.py:472] Creating samplers for algo activity_selector
W0716 12:23:29.761422 140714243360256 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0716 12:23:29.761686 140714243360256 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0716 12:23:29.944128 140714243360256 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0716 12:23:30.136079 140714243360256 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0716 12:23:30.351849 140714243360256 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0716 12:23:30.592687 140714243360256 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0716 12:23:30.891731 140714243360256 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0716 12:23:31.223086 140714243360256 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0716 12:23:31.606437 140714243360256 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0716 12:23:31.606730 140714243360256 samplers.py:124] Creating a dataset with 64 samples.
I0716 12:23:31.632534 140714243360256 run.py:259] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0716 12:23:31.633244 140714243360256 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0716 12:23:31.636040 140714243360256 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0716 12:23:31.639112 140714243360256 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0716 12:23:31.689874 140714243360256 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W0716 12:23:31.710428 140714243360256 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x7ffa11eb2c00> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0716 12:24:03.691353 140714243360256 run.py:687] Algo activity_selector step 0 current loss 3.757482, current_train_items 64.
I0716 12:24:08.881639 140714243360256 run.py:722] (val) algo activity_selector step 0: {'selected': 0.42130365659777425, 'score': 0.42130365659777425, 'examples_seen': 64, 'step': 0, 'algorithm': 'activity_selector'}
I0716 12:24:08.881801 140714243360256 run.py:743] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.421, val scores are: activity_selector: 0.421
I0716 12:25:16.016659 140714243360256 run.py:687] Algo activity_selector step 50 current loss 3.602963, current_train_items 2080.
I0716 12:25:16.040423 140714243360256 run.py:722] (val) algo activity_selector step 50: {'selected': 0.6666666666666667, 'score': 0.6666666666666667, 'examples_seen': 2080, 'step': 50, 'algorithm': 'activity_selector'}
I0716 12:25:16.040593 140714243360256 run.py:743] Checkpointing best model, best avg val score was 0.421, current avg val score is 0.667, val scores are: activity_selector: 0.667
I0716 12:25:17.046024 140714243360256 run.py:687] Algo activity_selector step 100 current loss 3.495319, current_train_items 4064.
I0716 12:25:17.071470 140714243360256 run.py:722] (val) algo activity_selector step 100: {'selected': 0.682261208576998, 'score': 0.682261208576998, 'examples_seen': 4064, 'step': 100, 'algorithm': 'activity_selector'}
I0716 12:25:17.071630 140714243360256 run.py:743] Checkpointing best model, best avg val score was 0.667, current avg val score is 0.682, val scores are: activity_selector: 0.682
I0716 12:25:18.068552 140714243360256 run.py:687] Algo activity_selector step 150 current loss 4.151411, current_train_items 6016.
I0716 12:25:18.096574 140714243360256 run.py:722] (val) algo activity_selector step 150: {'selected': 0.7321131447587355, 'score': 0.7321131447587355, 'examples_seen': 6016, 'step': 150, 'algorithm': 'activity_selector'}
I0716 12:25:18.096722 140714243360256 run.py:743] Checkpointing best model, best avg val score was 0.682, current avg val score is 0.732, val scores are: activity_selector: 0.732
I0716 12:25:19.094922 140714243360256 run.py:687] Algo activity_selector step 200 current loss 4.621675, current_train_items 8016.
I0716 12:25:19.124045 140714243360256 run.py:722] (val) algo activity_selector step 200: {'selected': 0.7895652173913044, 'score': 0.7895652173913044, 'examples_seen': 8016, 'step': 200, 'algorithm': 'activity_selector'}
I0716 12:25:19.124198 140714243360256 run.py:743] Checkpointing best model, best avg val score was 0.732, current avg val score is 0.790, val scores are: activity_selector: 0.790
I0716 12:25:20.124727 140714243360256 run.py:687] Algo activity_selector step 250 current loss 4.252985, current_train_items 9952.
I0716 12:25:20.157580 140714243360256 run.py:722] (val) algo activity_selector step 250: {'selected': 0.7561436672967865, 'score': 0.7561436672967865, 'examples_seen': 9952, 'step': 250, 'algorithm': 'activity_selector'}
I0716 12:25:20.157747 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.790, current avg val score is 0.756, val scores are: activity_selector: 0.756
I0716 12:25:21.166514 140714243360256 run.py:687] Algo activity_selector step 300 current loss 1.995694, current_train_items 12000.
I0716 12:25:21.188338 140714243360256 run.py:722] (val) algo activity_selector step 300: {'selected': 0.7458866544789763, 'score': 0.7458866544789763, 'examples_seen': 12000, 'step': 300, 'algorithm': 'activity_selector'}
I0716 12:25:21.188492 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.790, current avg val score is 0.746, val scores are: activity_selector: 0.746
I0716 12:25:22.184762 140714243360256 run.py:687] Algo activity_selector step 350 current loss 2.271715, current_train_items 14032.
I0716 12:25:22.207243 140714243360256 run.py:722] (val) algo activity_selector step 350: {'selected': 0.49035812672176304, 'score': 0.49035812672176304, 'examples_seen': 14032, 'step': 350, 'algorithm': 'activity_selector'}
I0716 12:25:22.207395 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.790, current avg val score is 0.490, val scores are: activity_selector: 0.490
I0716 12:25:23.212751 140714243360256 run.py:687] Algo activity_selector step 400 current loss 2.089739, current_train_items 16000.
I0716 12:25:23.236341 140714243360256 run.py:722] (val) algo activity_selector step 400: {'selected': 0.8446069469835465, 'score': 0.8446069469835465, 'examples_seen': 16000, 'step': 400, 'algorithm': 'activity_selector'}
I0716 12:25:23.236489 140714243360256 run.py:743] Checkpointing best model, best avg val score was 0.790, current avg val score is 0.845, val scores are: activity_selector: 0.845
I0716 12:25:24.238943 140714243360256 run.py:687] Algo activity_selector step 450 current loss 1.542427, current_train_items 18000.
I0716 12:25:24.264102 140714243360256 run.py:722] (val) algo activity_selector step 450: {'selected': 0.8666666666666667, 'score': 0.8666666666666667, 'examples_seen': 18000, 'step': 450, 'algorithm': 'activity_selector'}
I0716 12:25:24.264250 140714243360256 run.py:743] Checkpointing best model, best avg val score was 0.845, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0716 12:25:25.264283 140714243360256 run.py:687] Algo activity_selector step 500 current loss 1.886800, current_train_items 19952.
I0716 12:25:25.291946 140714243360256 run.py:722] (val) algo activity_selector step 500: {'selected': 0.8298611111111112, 'score': 0.8298611111111112, 'examples_seen': 19952, 'step': 500, 'algorithm': 'activity_selector'}
I0716 12:25:25.292093 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.867, current avg val score is 0.830, val scores are: activity_selector: 0.830
I0716 12:25:26.281399 140714243360256 run.py:687] Algo activity_selector step 550 current loss 2.991909, current_train_items 21920.
I0716 12:25:26.311699 140714243360256 run.py:722] (val) algo activity_selector step 550: {'selected': 0.8013816925734024, 'score': 0.8013816925734024, 'examples_seen': 21920, 'step': 550, 'algorithm': 'activity_selector'}
I0716 12:25:26.311869 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.867, current avg val score is 0.801, val scores are: activity_selector: 0.801
I0716 12:25:27.301631 140714243360256 run.py:687] Algo activity_selector step 600 current loss 3.472069, current_train_items 23904.
I0716 12:25:27.335815 140714243360256 run.py:722] (val) algo activity_selector step 600: {'selected': 0.8832684824902725, 'score': 0.8832684824902725, 'examples_seen': 23904, 'step': 600, 'algorithm': 'activity_selector'}
I0716 12:25:27.335982 140714243360256 run.py:743] Checkpointing best model, best avg val score was 0.867, current avg val score is 0.883, val scores are: activity_selector: 0.883
I0716 12:25:28.380278 140714243360256 run.py:687] Algo activity_selector step 650 current loss 1.013439, current_train_items 25920.
I0716 12:25:28.402491 140714243360256 run.py:722] (val) algo activity_selector step 650: {'selected': 0.8476357267950964, 'score': 0.8476357267950964, 'examples_seen': 25920, 'step': 650, 'algorithm': 'activity_selector'}
I0716 12:25:28.402646 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.883, current avg val score is 0.848, val scores are: activity_selector: 0.848
I0716 12:25:29.403793 140714243360256 run.py:687] Algo activity_selector step 700 current loss 0.603461, current_train_items 27952.
I0716 12:25:29.428071 140714243360256 run.py:722] (val) algo activity_selector step 700: {'selected': 0.8341880341880342, 'score': 0.8341880341880342, 'examples_seen': 27952, 'step': 700, 'algorithm': 'activity_selector'}
I0716 12:25:29.428217 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.883, current avg val score is 0.834, val scores are: activity_selector: 0.834
I0716 12:25:30.411401 140714243360256 run.py:687] Algo activity_selector step 750 current loss 0.860236, current_train_items 29936.
I0716 12:25:30.434750 140714243360256 run.py:722] (val) algo activity_selector step 750: {'selected': 0.8759124087591241, 'score': 0.8759124087591241, 'examples_seen': 29936, 'step': 750, 'algorithm': 'activity_selector'}
I0716 12:25:30.434898 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.883, current avg val score is 0.876, val scores are: activity_selector: 0.876
I0716 12:25:31.438911 140714243360256 run.py:687] Algo activity_selector step 800 current loss 0.998949, current_train_items 31920.
I0716 12:25:31.464227 140714243360256 run.py:722] (val) algo activity_selector step 800: {'selected': 0.7973856209150326, 'score': 0.7973856209150326, 'examples_seen': 31920, 'step': 800, 'algorithm': 'activity_selector'}
I0716 12:25:31.464375 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.883, current avg val score is 0.797, val scores are: activity_selector: 0.797
I0716 12:25:32.452021 140714243360256 run.py:687] Algo activity_selector step 850 current loss 2.764890, current_train_items 33904.
I0716 12:25:32.479323 140714243360256 run.py:722] (val) algo activity_selector step 850: {'selected': 0.9080459770114943, 'score': 0.9080459770114943, 'examples_seen': 33904, 'step': 850, 'algorithm': 'activity_selector'}
I0716 12:25:32.479472 140714243360256 run.py:743] Checkpointing best model, best avg val score was 0.883, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0716 12:25:33.502998 140714243360256 run.py:687] Algo activity_selector step 900 current loss 2.900555, current_train_items 35856.
I0716 12:25:33.532292 140714243360256 run.py:722] (val) algo activity_selector step 900: {'selected': 0.8702290076335878, 'score': 0.8702290076335878, 'examples_seen': 35856, 'step': 900, 'algorithm': 'activity_selector'}
I0716 12:25:33.532443 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.908, current avg val score is 0.870, val scores are: activity_selector: 0.870
I0716 12:25:34.523538 140714243360256 run.py:687] Algo activity_selector step 950 current loss 2.252478, current_train_items 37808.
I0716 12:25:34.555908 140714243360256 run.py:722] (val) algo activity_selector step 950: {'selected': 0.8660194174757281, 'score': 0.8660194174757281, 'examples_seen': 37808, 'step': 950, 'algorithm': 'activity_selector'}
I0716 12:25:34.556055 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.908, current avg val score is 0.866, val scores are: activity_selector: 0.866
I0716 12:25:35.574685 140714243360256 run.py:687] Algo activity_selector step 1000 current loss 0.216223, current_train_items 39872.
I0716 12:25:35.596905 140714243360256 run.py:722] (val) algo activity_selector step 1000: {'selected': 0.8664259927797834, 'score': 0.8664259927797834, 'examples_seen': 39872, 'step': 1000, 'algorithm': 'activity_selector'}
I0716 12:25:35.597057 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.908, current avg val score is 0.866, val scores are: activity_selector: 0.866
I0716 12:25:36.615855 140714243360256 run.py:687] Algo activity_selector step 1050 current loss 0.613390, current_train_items 41872.
I0716 12:25:36.639875 140714243360256 run.py:722] (val) algo activity_selector step 1050: {'selected': 0.8721804511278195, 'score': 0.8721804511278195, 'examples_seen': 41872, 'step': 1050, 'algorithm': 'activity_selector'}
I0716 12:25:36.640029 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.908, current avg val score is 0.872, val scores are: activity_selector: 0.872
I0716 12:25:37.640021 140714243360256 run.py:687] Algo activity_selector step 1100 current loss 1.443239, current_train_items 43872.
I0716 12:25:37.663531 140714243360256 run.py:722] (val) algo activity_selector step 1100: {'selected': 0.8587570621468927, 'score': 0.8587570621468927, 'examples_seen': 43872, 'step': 1100, 'algorithm': 'activity_selector'}
I0716 12:25:37.663684 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.908, current avg val score is 0.859, val scores are: activity_selector: 0.859
I0716 12:25:38.667953 140714243360256 run.py:687] Algo activity_selector step 1150 current loss 1.174316, current_train_items 45856.
I0716 12:25:38.693013 140714243360256 run.py:722] (val) algo activity_selector step 1150: {'selected': 0.9197080291970804, 'score': 0.9197080291970804, 'examples_seen': 45856, 'step': 1150, 'algorithm': 'activity_selector'}
I0716 12:25:38.693163 140714243360256 run.py:743] Checkpointing best model, best avg val score was 0.908, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0716 12:25:39.693841 140714243360256 run.py:687] Algo activity_selector step 1200 current loss 2.781763, current_train_items 47808.
I0716 12:25:39.721016 140714243360256 run.py:722] (val) algo activity_selector step 1200: {'selected': 0.9398496240601504, 'score': 0.9398496240601504, 'examples_seen': 47808, 'step': 1200, 'algorithm': 'activity_selector'}
I0716 12:25:39.721162 140714243360256 run.py:743] Checkpointing best model, best avg val score was 0.920, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0716 12:25:40.718670 140714243360256 run.py:687] Algo activity_selector step 1250 current loss 2.327109, current_train_items 49808.
I0716 12:25:40.749565 140714243360256 run.py:722] (val) algo activity_selector step 1250: {'selected': 0.8649789029535866, 'score': 0.8649789029535866, 'examples_seen': 49808, 'step': 1250, 'algorithm': 'activity_selector'}
I0716 12:25:40.749713 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.940, current avg val score is 0.865, val scores are: activity_selector: 0.865
I0716 12:25:41.734810 140714243360256 run.py:687] Algo activity_selector step 1300 current loss 5.054097, current_train_items 51760.
I0716 12:25:41.774018 140714243360256 run.py:722] (val) algo activity_selector step 1300: {'selected': 0.87984496124031, 'score': 0.87984496124031, 'examples_seen': 51760, 'step': 1300, 'algorithm': 'activity_selector'}
I0716 12:25:41.774165 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.940, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0716 12:25:42.784925 140714243360256 run.py:687] Algo activity_selector step 1350 current loss 0.591722, current_train_items 53792.
I0716 12:25:42.806727 140714243360256 run.py:722] (val) algo activity_selector step 1350: {'selected': 0.9016100178890876, 'score': 0.9016100178890876, 'examples_seen': 53792, 'step': 1350, 'algorithm': 'activity_selector'}
I0716 12:25:42.806875 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.940, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0716 12:25:43.807357 140714243360256 run.py:687] Algo activity_selector step 1400 current loss 0.482290, current_train_items 55824.
I0716 12:25:43.830403 140714243360256 run.py:722] (val) algo activity_selector step 1400: {'selected': 0.8854368932038835, 'score': 0.8854368932038835, 'examples_seen': 55824, 'step': 1400, 'algorithm': 'activity_selector'}
I0716 12:25:43.830579 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.940, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0716 12:25:44.829769 140714243360256 run.py:687] Algo activity_selector step 1450 current loss 1.272775, current_train_items 57792.
I0716 12:25:44.853246 140714243360256 run.py:722] (val) algo activity_selector step 1450: {'selected': 0.9304174950298212, 'score': 0.9304174950298212, 'examples_seen': 57792, 'step': 1450, 'algorithm': 'activity_selector'}
I0716 12:25:44.853393 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.940, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0716 12:25:45.841239 140714243360256 run.py:687] Algo activity_selector step 1500 current loss 0.438699, current_train_items 59792.
I0716 12:25:45.866167 140714243360256 run.py:722] (val) algo activity_selector step 1500: {'selected': 0.9294755877034359, 'score': 0.9294755877034359, 'examples_seen': 59792, 'step': 1500, 'algorithm': 'activity_selector'}
I0716 12:25:45.866315 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.940, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0716 12:25:46.852316 140714243360256 run.py:687] Algo activity_selector step 1550 current loss 0.827751, current_train_items 61744.
I0716 12:25:46.879812 140714243360256 run.py:722] (val) algo activity_selector step 1550: {'selected': 0.8953488372093024, 'score': 0.8953488372093024, 'examples_seen': 61744, 'step': 1550, 'algorithm': 'activity_selector'}
I0716 12:25:46.879966 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.940, current avg val score is 0.895, val scores are: activity_selector: 0.895
I0716 12:25:47.883640 140714243360256 run.py:687] Algo activity_selector step 1600 current loss 1.725278, current_train_items 63712.
I0716 12:25:47.912806 140714243360256 run.py:722] (val) algo activity_selector step 1600: {'selected': 0.8793774319066148, 'score': 0.8793774319066148, 'examples_seen': 63712, 'step': 1600, 'algorithm': 'activity_selector'}
I0716 12:25:47.912958 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.940, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0716 12:25:48.904247 140714243360256 run.py:687] Algo activity_selector step 1650 current loss 4.407915, current_train_items 65712.
I0716 12:25:48.936861 140714243360256 run.py:722] (val) algo activity_selector step 1650: {'selected': 0.9245647969052225, 'score': 0.9245647969052225, 'examples_seen': 65712, 'step': 1650, 'algorithm': 'activity_selector'}
I0716 12:25:48.937013 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.940, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0716 12:25:49.941189 140714243360256 run.py:687] Algo activity_selector step 1700 current loss 0.369484, current_train_items 67712.
I0716 12:25:49.963445 140714243360256 run.py:722] (val) algo activity_selector step 1700: {'selected': 0.9228007181328546, 'score': 0.9228007181328546, 'examples_seen': 67712, 'step': 1700, 'algorithm': 'activity_selector'}
I0716 12:25:49.963612 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.940, current avg val score is 0.923, val scores are: activity_selector: 0.923
I0716 12:25:50.965846 140714243360256 run.py:687] Algo activity_selector step 1750 current loss 0.315884, current_train_items 69744.
I0716 12:25:50.988163 140714243360256 run.py:722] (val) algo activity_selector step 1750: {'selected': 0.8972972972972973, 'score': 0.8972972972972973, 'examples_seen': 69744, 'step': 1750, 'algorithm': 'activity_selector'}
I0716 12:25:50.988312 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.940, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0716 12:25:51.970049 140714243360256 run.py:687] Algo activity_selector step 1800 current loss 0.486306, current_train_items 71728.
I0716 12:25:51.993846 140714243360256 run.py:722] (val) algo activity_selector step 1800: {'selected': 0.8983364140480592, 'score': 0.8983364140480592, 'examples_seen': 71728, 'step': 1800, 'algorithm': 'activity_selector'}
I0716 12:25:51.993995 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.940, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0716 12:25:53.000157 140714243360256 run.py:687] Algo activity_selector step 1850 current loss 0.472217, current_train_items 73712.
I0716 12:25:53.025213 140714243360256 run.py:722] (val) algo activity_selector step 1850: {'selected': 0.9158512720156555, 'score': 0.9158512720156555, 'examples_seen': 73712, 'step': 1850, 'algorithm': 'activity_selector'}
I0716 12:25:53.025398 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.940, current avg val score is 0.916, val scores are: activity_selector: 0.916
I0716 12:25:54.006114 140714243360256 run.py:687] Algo activity_selector step 1900 current loss 1.881051, current_train_items 75712.
I0716 12:25:54.033285 140714243360256 run.py:722] (val) algo activity_selector step 1900: {'selected': 0.9413988657844992, 'score': 0.9413988657844992, 'examples_seen': 75712, 'step': 1900, 'algorithm': 'activity_selector'}
I0716 12:25:54.033432 140714243360256 run.py:743] Checkpointing best model, best avg val score was 0.940, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0716 12:25:55.055720 140714243360256 run.py:687] Algo activity_selector step 1950 current loss 1.757288, current_train_items 77664.
I0716 12:25:55.084351 140714243360256 run.py:722] (val) algo activity_selector step 1950: {'selected': 0.9613899613899615, 'score': 0.9613899613899615, 'examples_seen': 77664, 'step': 1950, 'algorithm': 'activity_selector'}
I0716 12:25:55.084515 140714243360256 run.py:743] Checkpointing best model, best avg val score was 0.941, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0716 12:25:56.099885 140714243360256 run.py:687] Algo activity_selector step 2000 current loss 3.890304, current_train_items 79632.
I0716 12:25:56.132603 140714243360256 run.py:722] (val) algo activity_selector step 2000: {'selected': 0.9576923076923077, 'score': 0.9576923076923077, 'examples_seen': 79632, 'step': 2000, 'algorithm': 'activity_selector'}
I0716 12:25:56.132768 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0716 12:25:57.137235 140714243360256 run.py:687] Algo activity_selector step 2050 current loss 0.198164, current_train_items 81680.
I0716 12:25:57.159026 140714243360256 run.py:722] (val) algo activity_selector step 2050: {'selected': 0.9242424242424241, 'score': 0.9242424242424241, 'examples_seen': 81680, 'step': 2050, 'algorithm': 'activity_selector'}
I0716 12:25:57.159190 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0716 12:25:58.181840 140714243360256 run.py:687] Algo activity_selector step 2100 current loss 0.494410, current_train_items 83680.
I0716 12:25:58.204027 140714243360256 run.py:722] (val) algo activity_selector step 2100: {'selected': 0.8710359408033826, 'score': 0.8710359408033826, 'examples_seen': 83680, 'step': 2100, 'algorithm': 'activity_selector'}
I0716 12:25:58.204193 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.871, val scores are: activity_selector: 0.871
I0716 12:25:59.202035 140714243360256 run.py:687] Algo activity_selector step 2150 current loss 1.709862, current_train_items 85680.
I0716 12:25:59.225760 140714243360256 run.py:722] (val) algo activity_selector step 2150: {'selected': 0.8637992831541218, 'score': 0.8637992831541218, 'examples_seen': 85680, 'step': 2150, 'algorithm': 'activity_selector'}
I0716 12:25:59.225908 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.864, val scores are: activity_selector: 0.864
I0716 12:26:00.230922 140714243360256 run.py:687] Algo activity_selector step 2200 current loss 0.432188, current_train_items 87664.
I0716 12:26:00.255751 140714243360256 run.py:722] (val) algo activity_selector step 2200: {'selected': 0.9236641221374047, 'score': 0.9236641221374047, 'examples_seen': 87664, 'step': 2200, 'algorithm': 'activity_selector'}
I0716 12:26:00.255904 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0716 12:26:01.263161 140714243360256 run.py:687] Algo activity_selector step 2250 current loss 2.129349, current_train_items 89632.
I0716 12:26:01.290812 140714243360256 run.py:722] (val) algo activity_selector step 2250: {'selected': 0.95703125, 'score': 0.95703125, 'examples_seen': 89632, 'step': 2250, 'algorithm': 'activity_selector'}
I0716 12:26:01.290960 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0716 12:26:02.283775 140714243360256 run.py:687] Algo activity_selector step 2300 current loss 0.621234, current_train_items 91616.
I0716 12:26:02.313217 140714243360256 run.py:722] (val) algo activity_selector step 2300: {'selected': 0.9577981651376147, 'score': 0.9577981651376147, 'examples_seen': 91616, 'step': 2300, 'algorithm': 'activity_selector'}
I0716 12:26:02.313365 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0716 12:26:03.330351 140714243360256 run.py:687] Algo activity_selector step 2350 current loss 3.135126, current_train_items 93568.
I0716 12:26:03.364953 140714243360256 run.py:722] (val) algo activity_selector step 2350: {'selected': 0.9570093457943926, 'score': 0.9570093457943926, 'examples_seen': 93568, 'step': 2350, 'algorithm': 'activity_selector'}
I0716 12:26:03.365110 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0716 12:26:04.379613 140714243360256 run.py:687] Algo activity_selector step 2400 current loss 0.399165, current_train_items 95600.
I0716 12:26:04.401807 140714243360256 run.py:722] (val) algo activity_selector step 2400: {'selected': 0.9359223300970874, 'score': 0.9359223300970874, 'examples_seen': 95600, 'step': 2400, 'algorithm': 'activity_selector'}
I0716 12:26:04.401955 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0716 12:26:05.413464 140714243360256 run.py:687] Algo activity_selector step 2450 current loss 0.166764, current_train_items 97632.
I0716 12:26:05.436210 140714243360256 run.py:722] (val) algo activity_selector step 2450: {'selected': 0.9063829787234042, 'score': 0.9063829787234042, 'examples_seen': 97632, 'step': 2450, 'algorithm': 'activity_selector'}
I0716 12:26:05.436358 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0716 12:26:06.437039 140714243360256 run.py:687] Algo activity_selector step 2500 current loss 1.303942, current_train_items 99600.
I0716 12:26:06.460413 140714243360256 run.py:722] (val) algo activity_selector step 2500: {'selected': 0.9252525252525251, 'score': 0.9252525252525251, 'examples_seen': 99600, 'step': 2500, 'algorithm': 'activity_selector'}
I0716 12:26:06.460569 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0716 12:26:07.458026 140714243360256 run.py:687] Algo activity_selector step 2550 current loss 0.262556, current_train_items 101600.
I0716 12:26:07.482659 140714243360256 run.py:722] (val) algo activity_selector step 2550: {'selected': 0.9340866290018832, 'score': 0.9340866290018832, 'examples_seen': 101600, 'step': 2550, 'algorithm': 'activity_selector'}
I0716 12:26:07.482820 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0716 12:26:08.486872 140714243360256 run.py:687] Algo activity_selector step 2600 current loss 0.731478, current_train_items 103568.
I0716 12:26:08.514301 140714243360256 run.py:722] (val) algo activity_selector step 2600: {'selected': 0.9483747609942638, 'score': 0.9483747609942638, 'examples_seen': 103568, 'step': 2600, 'algorithm': 'activity_selector'}
I0716 12:26:08.514451 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0716 12:26:09.497957 140714243360256 run.py:687] Algo activity_selector step 2650 current loss 4.499874, current_train_items 105520.
I0716 12:26:09.526783 140714243360256 run.py:722] (val) algo activity_selector step 2650: {'selected': 0.9581056466302368, 'score': 0.9581056466302368, 'examples_seen': 105520, 'step': 2650, 'algorithm': 'activity_selector'}
I0716 12:26:09.526931 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0716 12:26:10.514925 140714243360256 run.py:687] Algo activity_selector step 2700 current loss 2.839456, current_train_items 107520.
I0716 12:26:10.549480 140714243360256 run.py:722] (val) algo activity_selector step 2700: {'selected': 0.9, 'score': 0.9, 'examples_seen': 107520, 'step': 2700, 'algorithm': 'activity_selector'}
I0716 12:26:10.549634 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.900, val scores are: activity_selector: 0.900
I0716 12:26:11.554856 140714243360256 run.py:687] Algo activity_selector step 2750 current loss 0.725511, current_train_items 109520.
I0716 12:26:11.577268 140714243360256 run.py:722] (val) algo activity_selector step 2750: {'selected': 0.9104477611940298, 'score': 0.9104477611940298, 'examples_seen': 109520, 'step': 2750, 'algorithm': 'activity_selector'}
I0716 12:26:11.577415 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0716 12:26:12.580393 140714243360256 run.py:687] Algo activity_selector step 2800 current loss 0.224316, current_train_items 111552.
I0716 12:26:12.604617 140714243360256 run.py:722] (val) algo activity_selector step 2800: {'selected': 0.9540229885057471, 'score': 0.9540229885057471, 'examples_seen': 111552, 'step': 2800, 'algorithm': 'activity_selector'}
I0716 12:26:12.604769 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0716 12:26:13.590132 140714243360256 run.py:687] Algo activity_selector step 2850 current loss 0.391629, current_train_items 113552.
I0716 12:26:13.613803 140714243360256 run.py:722] (val) algo activity_selector step 2850: {'selected': 0.9251968503937008, 'score': 0.9251968503937008, 'examples_seen': 113552, 'step': 2850, 'algorithm': 'activity_selector'}
I0716 12:26:13.613956 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0716 12:26:14.620665 140714243360256 run.py:687] Algo activity_selector step 2900 current loss 0.396643, current_train_items 115520.
I0716 12:26:14.645433 140714243360256 run.py:722] (val) algo activity_selector step 2900: {'selected': 0.9548872180451128, 'score': 0.9548872180451128, 'examples_seen': 115520, 'step': 2900, 'algorithm': 'activity_selector'}
I0716 12:26:14.645591 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0716 12:26:15.632825 140714243360256 run.py:687] Algo activity_selector step 2950 current loss 2.038787, current_train_items 117520.
I0716 12:26:15.660953 140714243360256 run.py:722] (val) algo activity_selector step 2950: {'selected': 0.9169960474308301, 'score': 0.9169960474308301, 'examples_seen': 117520, 'step': 2950, 'algorithm': 'activity_selector'}
I0716 12:26:15.661108 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0716 12:26:16.657749 140714243360256 run.py:687] Algo activity_selector step 3000 current loss 2.505035, current_train_items 119456.
I0716 12:26:16.686807 140714243360256 run.py:722] (val) algo activity_selector step 3000: {'selected': 0.933572710951526, 'score': 0.933572710951526, 'examples_seen': 119456, 'step': 3000, 'algorithm': 'activity_selector'}
I0716 12:26:16.686951 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0716 12:26:17.689883 140714243360256 run.py:687] Algo activity_selector step 3050 current loss 3.172225, current_train_items 121424.
I0716 12:26:17.722957 140714243360256 run.py:722] (val) algo activity_selector step 3050: {'selected': 0.9340866290018833, 'score': 0.9340866290018833, 'examples_seen': 121424, 'step': 3050, 'algorithm': 'activity_selector'}
I0716 12:26:17.723106 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0716 12:26:18.727513 140714243360256 run.py:687] Algo activity_selector step 3100 current loss 0.297044, current_train_items 123472.
I0716 12:26:18.751219 140714243360256 run.py:722] (val) algo activity_selector step 3100: {'selected': 0.8791208791208791, 'score': 0.8791208791208791, 'examples_seen': 123472, 'step': 3100, 'algorithm': 'activity_selector'}
I0716 12:26:18.751371 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0716 12:26:19.770510 140714243360256 run.py:687] Algo activity_selector step 3150 current loss 0.132069, current_train_items 125472.
I0716 12:26:19.792950 140714243360256 run.py:722] (val) algo activity_selector step 3150: {'selected': 0.9328214971209213, 'score': 0.9328214971209213, 'examples_seen': 125472, 'step': 3150, 'algorithm': 'activity_selector'}
I0716 12:26:19.793099 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0716 12:26:20.792431 140714243360256 run.py:687] Algo activity_selector step 3200 current loss 1.318638, current_train_items 127488.
I0716 12:26:20.816388 140714243360256 run.py:722] (val) algo activity_selector step 3200: {'selected': 0.9828571428571429, 'score': 0.9828571428571429, 'examples_seen': 127488, 'step': 3200, 'algorithm': 'activity_selector'}
I0716 12:26:20.816548 140714243360256 run.py:743] Checkpointing best model, best avg val score was 0.961, current avg val score is 0.983, val scores are: activity_selector: 0.983
I0716 12:26:21.821007 140714243360256 run.py:687] Algo activity_selector step 3250 current loss 0.422136, current_train_items 129456.
I0716 12:26:21.846019 140714243360256 run.py:722] (val) algo activity_selector step 3250: {'selected': 0.9645669291338581, 'score': 0.9645669291338581, 'examples_seen': 129456, 'step': 3250, 'algorithm': 'activity_selector'}
I0716 12:26:21.846169 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0716 12:26:22.843736 140714243360256 run.py:687] Algo activity_selector step 3300 current loss 1.907411, current_train_items 131424.
I0716 12:26:22.871891 140714243360256 run.py:722] (val) algo activity_selector step 3300: {'selected': 0.9638095238095239, 'score': 0.9638095238095239, 'examples_seen': 131424, 'step': 3300, 'algorithm': 'activity_selector'}
I0716 12:26:22.872053 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0716 12:26:23.849081 140714243360256 run.py:687] Algo activity_selector step 3350 current loss 2.167222, current_train_items 133408.
I0716 12:26:23.879387 140714243360256 run.py:722] (val) algo activity_selector step 3350: {'selected': 0.9545454545454545, 'score': 0.9545454545454545, 'examples_seen': 133408, 'step': 3350, 'algorithm': 'activity_selector'}
I0716 12:26:23.879561 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0716 12:26:24.900640 140714243360256 run.py:687] Algo activity_selector step 3400 current loss 2.476492, current_train_items 135360.
I0716 12:26:24.933432 140714243360256 run.py:722] (val) algo activity_selector step 3400: {'selected': 0.9333333333333335, 'score': 0.9333333333333335, 'examples_seen': 135360, 'step': 3400, 'algorithm': 'activity_selector'}
I0716 12:26:24.933590 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0716 12:26:25.935615 140714243360256 run.py:687] Algo activity_selector step 3450 current loss 0.478828, current_train_items 137392.
I0716 12:26:25.958262 140714243360256 run.py:722] (val) algo activity_selector step 3450: {'selected': 0.9539594843462247, 'score': 0.9539594843462247, 'examples_seen': 137392, 'step': 3450, 'algorithm': 'activity_selector'}
I0716 12:26:25.958414 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0716 12:26:26.962902 140714243360256 run.py:687] Algo activity_selector step 3500 current loss 0.101503, current_train_items 139424.
I0716 12:26:26.985198 140714243360256 run.py:722] (val) algo activity_selector step 3500: {'selected': 0.965931863727455, 'score': 0.965931863727455, 'examples_seen': 139424, 'step': 3500, 'algorithm': 'activity_selector'}
I0716 12:26:26.985347 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0716 12:26:27.994213 140714243360256 run.py:687] Algo activity_selector step 3550 current loss 1.303756, current_train_items 141408.
I0716 12:26:28.018111 140714243360256 run.py:722] (val) algo activity_selector step 3550: {'selected': 0.953125, 'score': 0.953125, 'examples_seen': 141408, 'step': 3550, 'algorithm': 'activity_selector'}
I0716 12:26:28.018270 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0716 12:26:29.001422 140714243360256 run.py:687] Algo activity_selector step 3600 current loss 0.273337, current_train_items 143392.
I0716 12:26:29.026417 140714243360256 run.py:722] (val) algo activity_selector step 3600: {'selected': 0.9633911368015413, 'score': 0.9633911368015413, 'examples_seen': 143392, 'step': 3600, 'algorithm': 'activity_selector'}
I0716 12:26:29.026577 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0716 12:26:30.039093 140714243360256 run.py:687] Algo activity_selector step 3650 current loss 1.028784, current_train_items 145360.
I0716 12:26:30.067082 140714243360256 run.py:722] (val) algo activity_selector step 3650: {'selected': 0.9636711281070744, 'score': 0.9636711281070744, 'examples_seen': 145360, 'step': 3650, 'algorithm': 'activity_selector'}
I0716 12:26:30.067233 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0716 12:26:31.051160 140714243360256 run.py:687] Algo activity_selector step 3700 current loss 1.940882, current_train_items 147312.
I0716 12:26:31.080627 140714243360256 run.py:722] (val) algo activity_selector step 3700: {'selected': 0.9592233009708738, 'score': 0.9592233009708738, 'examples_seen': 147312, 'step': 3700, 'algorithm': 'activity_selector'}
I0716 12:26:31.080780 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0716 12:26:32.077056 140714243360256 run.py:687] Algo activity_selector step 3750 current loss 2.241028, current_train_items 149312.
I0716 12:26:32.109852 140714243360256 run.py:722] (val) algo activity_selector step 3750: {'selected': 0.9773584905660377, 'score': 0.9773584905660377, 'examples_seen': 149312, 'step': 3750, 'algorithm': 'activity_selector'}
I0716 12:26:32.110010 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0716 12:26:33.130209 140714243360256 run.py:687] Algo activity_selector step 3800 current loss 0.380090, current_train_items 151328.
I0716 12:26:33.152452 140714243360256 run.py:722] (val) algo activity_selector step 3800: {'selected': 0.9604743083003953, 'score': 0.9604743083003953, 'examples_seen': 151328, 'step': 3800, 'algorithm': 'activity_selector'}
I0716 12:26:33.152611 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0716 12:26:34.174696 140714243360256 run.py:687] Algo activity_selector step 3850 current loss 0.156175, current_train_items 153344.
I0716 12:26:34.197244 140714243360256 run.py:722] (val) algo activity_selector step 3850: {'selected': 0.9401088929219601, 'score': 0.9401088929219601, 'examples_seen': 153344, 'step': 3850, 'algorithm': 'activity_selector'}
I0716 12:26:34.197407 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0716 12:26:35.226357 140714243360256 run.py:687] Algo activity_selector step 3900 current loss 0.234100, current_train_items 155344.
I0716 12:26:35.250043 140714243360256 run.py:722] (val) algo activity_selector step 3900: {'selected': 0.9561904761904763, 'score': 0.9561904761904763, 'examples_seen': 155344, 'step': 3900, 'algorithm': 'activity_selector'}
I0716 12:26:35.250191 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0716 12:26:36.246173 140714243360256 run.py:687] Algo activity_selector step 3950 current loss 0.380575, current_train_items 157312.
I0716 12:26:36.271261 140714243360256 run.py:722] (val) algo activity_selector step 3950: {'selected': 0.946983546617916, 'score': 0.946983546617916, 'examples_seen': 157312, 'step': 3950, 'algorithm': 'activity_selector'}
I0716 12:26:36.271408 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0716 12:26:37.271820 140714243360256 run.py:687] Algo activity_selector step 4000 current loss 1.711285, current_train_items 159312.
I0716 12:26:37.299444 140714243360256 run.py:722] (val) algo activity_selector step 4000: {'selected': 0.9521988527724665, 'score': 0.9521988527724665, 'examples_seen': 159312, 'step': 4000, 'algorithm': 'activity_selector'}
I0716 12:26:37.299602 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0716 12:26:38.298156 140714243360256 run.py:687] Algo activity_selector step 4050 current loss 1.623202, current_train_items 161248.
I0716 12:26:38.328128 140714243360256 run.py:722] (val) algo activity_selector step 4050: {'selected': 0.9502982107355865, 'score': 0.9502982107355865, 'examples_seen': 161248, 'step': 4050, 'algorithm': 'activity_selector'}
I0716 12:26:38.328288 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0716 12:26:39.336885 140714243360256 run.py:687] Algo activity_selector step 4100 current loss 2.039271, current_train_items 163216.
I0716 12:26:39.369964 140714243360256 run.py:722] (val) algo activity_selector step 4100: {'selected': 0.9638095238095238, 'score': 0.9638095238095238, 'examples_seen': 163216, 'step': 4100, 'algorithm': 'activity_selector'}
I0716 12:26:39.370116 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0716 12:26:40.392757 140714243360256 run.py:687] Algo activity_selector step 4150 current loss 0.157510, current_train_items 165280.
I0716 12:26:40.415216 140714243360256 run.py:722] (val) algo activity_selector step 4150: {'selected': 0.9710982658959537, 'score': 0.9710982658959537, 'examples_seen': 165280, 'step': 4150, 'algorithm': 'activity_selector'}
I0716 12:26:40.415366 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0716 12:26:41.425530 140714243360256 run.py:687] Algo activity_selector step 4200 current loss 0.156819, current_train_items 167264.
I0716 12:26:41.448053 140714243360256 run.py:722] (val) algo activity_selector step 4200: {'selected': 0.9277566539923954, 'score': 0.9277566539923954, 'examples_seen': 167264, 'step': 4200, 'algorithm': 'activity_selector'}
I0716 12:26:41.448205 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0716 12:26:42.458558 140714243360256 run.py:687] Algo activity_selector step 4250 current loss 1.064465, current_train_items 169280.
I0716 12:26:42.484085 140714243360256 run.py:722] (val) algo activity_selector step 4250: {'selected': 0.9558541266794626, 'score': 0.9558541266794626, 'examples_seen': 169280, 'step': 4250, 'algorithm': 'activity_selector'}
I0716 12:26:42.484236 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0716 12:26:43.482263 140714243360256 run.py:687] Algo activity_selector step 4300 current loss 0.306049, current_train_items 171248.
I0716 12:26:43.507299 140714243360256 run.py:722] (val) algo activity_selector step 4300: {'selected': 0.9300567107750473, 'score': 0.9300567107750473, 'examples_seen': 171248, 'step': 4300, 'algorithm': 'activity_selector'}
I0716 12:26:43.507449 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0716 12:26:44.518404 140714243360256 run.py:687] Algo activity_selector step 4350 current loss 2.164043, current_train_items 173216.
I0716 12:26:44.545923 140714243360256 run.py:722] (val) algo activity_selector step 4350: {'selected': 0.9368635437881874, 'score': 0.9368635437881874, 'examples_seen': 173216, 'step': 4350, 'algorithm': 'activity_selector'}
I0716 12:26:44.546073 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0716 12:26:45.540271 140714243360256 run.py:687] Algo activity_selector step 4400 current loss 1.124546, current_train_items 175232.
I0716 12:26:45.570306 140714243360256 run.py:722] (val) algo activity_selector step 4400: {'selected': 0.9611451942740287, 'score': 0.9611451942740287, 'examples_seen': 175232, 'step': 4400, 'algorithm': 'activity_selector'}
I0716 12:26:45.570456 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0716 12:26:46.577721 140714243360256 run.py:687] Algo activity_selector step 4450 current loss 1.890187, current_train_items 177168.
I0716 12:26:46.610926 140714243360256 run.py:722] (val) algo activity_selector step 4450: {'selected': 0.9461538461538461, 'score': 0.9461538461538461, 'examples_seen': 177168, 'step': 4450, 'algorithm': 'activity_selector'}
I0716 12:26:46.611089 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0716 12:26:47.631414 140714243360256 run.py:687] Algo activity_selector step 4500 current loss 0.400093, current_train_items 179216.
I0716 12:26:47.653409 140714243360256 run.py:722] (val) algo activity_selector step 4500: {'selected': 0.9246435845213848, 'score': 0.9246435845213848, 'examples_seen': 179216, 'step': 4500, 'algorithm': 'activity_selector'}
I0716 12:26:47.653564 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0716 12:26:48.653589 140714243360256 run.py:687] Algo activity_selector step 4550 current loss 0.503312, current_train_items 181232.
I0716 12:26:48.676785 140714243360256 run.py:722] (val) algo activity_selector step 4550: {'selected': 0.9330783938814532, 'score': 0.9330783938814532, 'examples_seen': 181232, 'step': 4550, 'algorithm': 'activity_selector'}
I0716 12:26:48.676935 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0716 12:26:49.691453 140714243360256 run.py:687] Algo activity_selector step 4600 current loss 1.163095, current_train_items 183216.
I0716 12:26:49.715256 140714243360256 run.py:722] (val) algo activity_selector step 4600: {'selected': 0.9510763209393346, 'score': 0.9510763209393346, 'examples_seen': 183216, 'step': 4600, 'algorithm': 'activity_selector'}
I0716 12:26:49.715406 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0716 12:26:50.705828 140714243360256 run.py:687] Algo activity_selector step 4650 current loss 0.260854, current_train_items 185200.
I0716 12:26:50.730801 140714243360256 run.py:722] (val) algo activity_selector step 4650: {'selected': 0.9471698113207547, 'score': 0.9471698113207547, 'examples_seen': 185200, 'step': 4650, 'algorithm': 'activity_selector'}
I0716 12:26:50.730952 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0716 12:26:51.739201 140714243360256 run.py:687] Algo activity_selector step 4700 current loss 0.358780, current_train_items 187168.
I0716 12:26:51.766891 140714243360256 run.py:722] (val) algo activity_selector step 4700: {'selected': 0.9644268774703557, 'score': 0.9644268774703557, 'examples_seen': 187168, 'step': 4700, 'algorithm': 'activity_selector'}
I0716 12:26:51.767042 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0716 12:26:52.772679 140714243360256 run.py:687] Algo activity_selector step 4750 current loss 0.431142, current_train_items 189136.
I0716 12:26:52.803549 140714243360256 run.py:722] (val) algo activity_selector step 4750: {'selected': 0.9467680608365018, 'score': 0.9467680608365018, 'examples_seen': 189136, 'step': 4750, 'algorithm': 'activity_selector'}
I0716 12:26:52.803704 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0716 12:26:53.796810 140714243360256 run.py:687] Algo activity_selector step 4800 current loss 2.095086, current_train_items 191120.
I0716 12:26:53.830374 140714243360256 run.py:722] (val) algo activity_selector step 4800: {'selected': 0.980544747081712, 'score': 0.980544747081712, 'examples_seen': 191120, 'step': 4800, 'algorithm': 'activity_selector'}
I0716 12:26:53.830534 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0716 12:26:54.860229 140714243360256 run.py:687] Algo activity_selector step 4850 current loss 0.291387, current_train_items 193136.
I0716 12:26:54.882851 140714243360256 run.py:722] (val) algo activity_selector step 4850: {'selected': 0.9704797047970479, 'score': 0.9704797047970479, 'examples_seen': 193136, 'step': 4850, 'algorithm': 'activity_selector'}
I0716 12:26:54.883003 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0716 12:26:55.912772 140714243360256 run.py:687] Algo activity_selector step 4900 current loss 0.226465, current_train_items 195152.
I0716 12:26:55.935961 140714243360256 run.py:722] (val) algo activity_selector step 4900: {'selected': 0.9585798816568047, 'score': 0.9585798816568047, 'examples_seen': 195152, 'step': 4900, 'algorithm': 'activity_selector'}
I0716 12:26:55.936113 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0716 12:26:56.959888 140714243360256 run.py:687] Algo activity_selector step 4950 current loss 0.111555, current_train_items 197152.
I0716 12:26:56.983634 140714243360256 run.py:722] (val) algo activity_selector step 4950: {'selected': 0.9633911368015414, 'score': 0.9633911368015414, 'examples_seen': 197152, 'step': 4950, 'algorithm': 'activity_selector'}
I0716 12:26:56.983791 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0716 12:26:57.992556 140714243360256 run.py:687] Algo activity_selector step 5000 current loss 0.326755, current_train_items 199120.
I0716 12:26:58.018385 140714243360256 run.py:722] (val) algo activity_selector step 5000: {'selected': 0.9603174603174603, 'score': 0.9603174603174603, 'examples_seen': 199120, 'step': 5000, 'algorithm': 'activity_selector'}
I0716 12:26:58.018545 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0716 12:26:59.020507 140714243360256 run.py:687] Algo activity_selector step 5050 current loss 1.390432, current_train_items 201120.
I0716 12:26:59.048707 140714243360256 run.py:722] (val) algo activity_selector step 5050: {'selected': 0.9568627450980391, 'score': 0.9568627450980391, 'examples_seen': 201120, 'step': 5050, 'algorithm': 'activity_selector'}
I0716 12:26:59.048871 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0716 12:27:00.049795 140714243360256 run.py:687] Algo activity_selector step 5100 current loss 2.622713, current_train_items 203072.
I0716 12:27:00.080134 140714243360256 run.py:722] (val) algo activity_selector step 5100: {'selected': 0.9639468690702088, 'score': 0.9639468690702088, 'examples_seen': 203072, 'step': 5100, 'algorithm': 'activity_selector'}
I0716 12:27:00.080291 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0716 12:27:01.083613 140714243360256 run.py:687] Algo activity_selector step 5150 current loss 1.939517, current_train_items 205024.
I0716 12:27:01.116418 140714243360256 run.py:722] (val) algo activity_selector step 5150: {'selected': 0.9663366336633663, 'score': 0.9663366336633663, 'examples_seen': 205024, 'step': 5150, 'algorithm': 'activity_selector'}
I0716 12:27:01.116594 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0716 12:27:02.132630 140714243360256 run.py:687] Algo activity_selector step 5200 current loss 0.117580, current_train_items 207088.
I0716 12:27:02.154323 140714243360256 run.py:722] (val) algo activity_selector step 5200: {'selected': 0.9275929549902151, 'score': 0.9275929549902151, 'examples_seen': 207088, 'step': 5200, 'algorithm': 'activity_selector'}
I0716 12:27:02.154488 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0716 12:27:03.161264 140714243360256 run.py:687] Algo activity_selector step 5250 current loss 0.270539, current_train_items 209072.
I0716 12:27:03.183732 140714243360256 run.py:722] (val) algo activity_selector step 5250: {'selected': 0.9570093457943926, 'score': 0.9570093457943926, 'examples_seen': 209072, 'step': 5250, 'algorithm': 'activity_selector'}
I0716 12:27:03.183881 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0716 12:27:04.191770 140714243360256 run.py:687] Algo activity_selector step 5300 current loss 1.021392, current_train_items 211088.
I0716 12:27:04.215351 140714243360256 run.py:722] (val) algo activity_selector step 5300: {'selected': 0.9437751004016064, 'score': 0.9437751004016064, 'examples_seen': 211088, 'step': 5300, 'algorithm': 'activity_selector'}
I0716 12:27:04.215502 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0716 12:27:05.213670 140714243360256 run.py:687] Algo activity_selector step 5350 current loss 0.572640, current_train_items 213072.
I0716 12:27:05.239172 140714243360256 run.py:722] (val) algo activity_selector step 5350: {'selected': 0.9593810444874274, 'score': 0.9593810444874274, 'examples_seen': 213072, 'step': 5350, 'algorithm': 'activity_selector'}
I0716 12:27:05.239326 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0716 12:27:06.259727 140714243360256 run.py:687] Algo activity_selector step 5400 current loss 1.787658, current_train_items 215024.
I0716 12:27:06.287876 140714243360256 run.py:722] (val) algo activity_selector step 5400: {'selected': 0.9728682170542635, 'score': 0.9728682170542635, 'examples_seen': 215024, 'step': 5400, 'algorithm': 'activity_selector'}
I0716 12:27:06.288029 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0716 12:27:07.285997 140714243360256 run.py:687] Algo activity_selector step 5450 current loss 2.568288, current_train_items 217024.
I0716 12:27:07.315226 140714243360256 run.py:722] (val) algo activity_selector step 5450: {'selected': 0.9743589743589745, 'score': 0.9743589743589745, 'examples_seen': 217024, 'step': 5450, 'algorithm': 'activity_selector'}
I0716 12:27:07.315381 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0716 12:27:08.319467 140714243360256 run.py:687] Algo activity_selector step 5500 current loss 2.060253, current_train_items 218960.
I0716 12:27:08.352232 140714243360256 run.py:722] (val) algo activity_selector step 5500: {'selected': 0.9692307692307692, 'score': 0.9692307692307692, 'examples_seen': 218960, 'step': 5500, 'algorithm': 'activity_selector'}
I0716 12:27:08.352383 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0716 12:27:09.373807 140714243360256 run.py:687] Algo activity_selector step 5550 current loss 0.322024, current_train_items 221008.
I0716 12:27:09.396548 140714243360256 run.py:722] (val) algo activity_selector step 5550: {'selected': 0.9354207436399217, 'score': 0.9354207436399217, 'examples_seen': 221008, 'step': 5550, 'algorithm': 'activity_selector'}
I0716 12:27:09.396697 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0716 12:27:10.400005 140714243360256 run.py:687] Algo activity_selector step 5600 current loss 0.048079, current_train_items 223024.
I0716 12:27:10.422964 140714243360256 run.py:722] (val) algo activity_selector step 5600: {'selected': 0.953125, 'score': 0.953125, 'examples_seen': 223024, 'step': 5600, 'algorithm': 'activity_selector'}
I0716 12:27:10.423116 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0716 12:27:11.441788 140714243360256 run.py:687] Algo activity_selector step 5650 current loss 1.081412, current_train_items 225008.
I0716 12:27:11.465731 140714243360256 run.py:722] (val) algo activity_selector step 5650: {'selected': 0.9579158316633266, 'score': 0.9579158316633266, 'examples_seen': 225008, 'step': 5650, 'algorithm': 'activity_selector'}
I0716 12:27:11.465882 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0716 12:27:12.458739 140714243360256 run.py:687] Algo activity_selector step 5700 current loss 0.595425, current_train_items 227008.
I0716 12:27:12.483735 140714243360256 run.py:722] (val) algo activity_selector step 5700: {'selected': 0.9368029739776951, 'score': 0.9368029739776951, 'examples_seen': 227008, 'step': 5700, 'algorithm': 'activity_selector'}
I0716 12:27:12.483885 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0716 12:27:13.483930 140714243360256 run.py:687] Algo activity_selector step 5750 current loss 0.274291, current_train_items 228960.
I0716 12:27:13.512020 140714243360256 run.py:722] (val) algo activity_selector step 5750: {'selected': 0.9589041095890412, 'score': 0.9589041095890412, 'examples_seen': 228960, 'step': 5750, 'algorithm': 'activity_selector'}
I0716 12:27:13.512176 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0716 12:27:14.521605 140714243360256 run.py:687] Algo activity_selector step 5800 current loss 2.339509, current_train_items 230928.
I0716 12:27:14.550934 140714243360256 run.py:722] (val) algo activity_selector step 5800: {'selected': 0.9655172413793104, 'score': 0.9655172413793104, 'examples_seen': 230928, 'step': 5800, 'algorithm': 'activity_selector'}
I0716 12:27:14.551120 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0716 12:27:15.543608 140714243360256 run.py:687] Algo activity_selector step 5850 current loss 1.955054, current_train_items 232912.
I0716 12:27:15.576431 140714243360256 run.py:722] (val) algo activity_selector step 5850: {'selected': 0.9338677354709419, 'score': 0.9338677354709419, 'examples_seen': 232912, 'step': 5850, 'algorithm': 'activity_selector'}
I0716 12:27:15.576592 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0716 12:27:16.615531 140714243360256 run.py:687] Algo activity_selector step 5900 current loss 0.257488, current_train_items 234928.
I0716 12:27:16.637352 140714243360256 run.py:722] (val) algo activity_selector step 5900: {'selected': 0.9354207436399218, 'score': 0.9354207436399218, 'examples_seen': 234928, 'step': 5900, 'algorithm': 'activity_selector'}
I0716 12:27:16.637506 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0716 12:27:17.648126 140714243360256 run.py:687] Algo activity_selector step 5950 current loss 0.079556, current_train_items 236944.
I0716 12:27:17.670764 140714243360256 run.py:722] (val) algo activity_selector step 5950: {'selected': 0.9423076923076923, 'score': 0.9423076923076923, 'examples_seen': 236944, 'step': 5950, 'algorithm': 'activity_selector'}
I0716 12:27:17.670915 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0716 12:27:18.680063 140714243360256 run.py:687] Algo activity_selector step 6000 current loss 0.133059, current_train_items 238944.
I0716 12:27:18.703630 140714243360256 run.py:722] (val) algo activity_selector step 6000: {'selected': 0.934108527131783, 'score': 0.934108527131783, 'examples_seen': 238944, 'step': 6000, 'algorithm': 'activity_selector'}
I0716 12:27:18.703782 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0716 12:27:19.707706 140714243360256 run.py:687] Algo activity_selector step 6050 current loss 0.314025, current_train_items 240928.
I0716 12:27:19.732743 140714243360256 run.py:722] (val) algo activity_selector step 6050: {'selected': 0.9820359281437125, 'score': 0.9820359281437125, 'examples_seen': 240928, 'step': 6050, 'algorithm': 'activity_selector'}
I0716 12:27:19.732893 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.982, val scores are: activity_selector: 0.982
I0716 12:27:20.710203 140714243360256 run.py:687] Algo activity_selector step 6100 current loss 1.488287, current_train_items 242912.
I0716 12:27:20.737926 140714243360256 run.py:722] (val) algo activity_selector step 6100: {'selected': 0.969258589511754, 'score': 0.969258589511754, 'examples_seen': 242912, 'step': 6100, 'algorithm': 'activity_selector'}
I0716 12:27:20.738077 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0716 12:27:21.745698 140714243360256 run.py:687] Algo activity_selector step 6150 current loss 1.834126, current_train_items 244864.
I0716 12:27:21.775146 140714243360256 run.py:722] (val) algo activity_selector step 6150: {'selected': 0.952741020793951, 'score': 0.952741020793951, 'examples_seen': 244864, 'step': 6150, 'algorithm': 'activity_selector'}
I0716 12:27:21.775295 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0716 12:27:22.764347 140714243360256 run.py:687] Algo activity_selector step 6200 current loss 1.279645, current_train_items 246816.
I0716 12:27:22.797246 140714243360256 run.py:722] (val) algo activity_selector step 6200: {'selected': 0.9942857142857142, 'score': 0.9942857142857142, 'examples_seen': 246816, 'step': 6200, 'algorithm': 'activity_selector'}
I0716 12:27:22.797397 140714243360256 run.py:743] Checkpointing best model, best avg val score was 0.983, current avg val score is 0.994, val scores are: activity_selector: 0.994
I0716 12:27:23.835765 140714243360256 run.py:687] Algo activity_selector step 6250 current loss 0.083140, current_train_items 248880.
I0716 12:27:23.858297 140714243360256 run.py:722] (val) algo activity_selector step 6250: {'selected': 0.9643527204502814, 'score': 0.9643527204502814, 'examples_seen': 248880, 'step': 6250, 'algorithm': 'activity_selector'}
I0716 12:27:23.858448 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0716 12:27:24.871627 140714243360256 run.py:687] Algo activity_selector step 6300 current loss 0.190998, current_train_items 250880.
I0716 12:27:24.894382 140714243360256 run.py:722] (val) algo activity_selector step 6300: {'selected': 0.9646569646569646, 'score': 0.9646569646569646, 'examples_seen': 250880, 'step': 6300, 'algorithm': 'activity_selector'}
I0716 12:27:24.894543 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0716 12:27:25.899646 140714243360256 run.py:687] Algo activity_selector step 6350 current loss 1.170333, current_train_items 252880.
I0716 12:27:25.923154 140714243360256 run.py:722] (val) algo activity_selector step 6350: {'selected': 0.9774436090225563, 'score': 0.9774436090225563, 'examples_seen': 252880, 'step': 6350, 'algorithm': 'activity_selector'}
I0716 12:27:25.923320 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0716 12:27:26.930989 140714243360256 run.py:687] Algo activity_selector step 6400 current loss 0.288261, current_train_items 254864.
I0716 12:27:26.959636 140714243360256 run.py:722] (val) algo activity_selector step 6400: {'selected': 0.9480000000000001, 'score': 0.9480000000000001, 'examples_seen': 254864, 'step': 6400, 'algorithm': 'activity_selector'}
I0716 12:27:26.959788 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0716 12:27:27.956627 140714243360256 run.py:687] Algo activity_selector step 6450 current loss 2.277421, current_train_items 256816.
I0716 12:27:27.984808 140714243360256 run.py:722] (val) algo activity_selector step 6450: {'selected': 0.960747663551402, 'score': 0.960747663551402, 'examples_seen': 256816, 'step': 6450, 'algorithm': 'activity_selector'}
I0716 12:27:27.984958 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0716 12:27:28.978811 140714243360256 run.py:687] Algo activity_selector step 6500 current loss 1.751346, current_train_items 258816.
I0716 12:27:29.008228 140714243360256 run.py:722] (val) algo activity_selector step 6500: {'selected': 0.9824561403508771, 'score': 0.9824561403508771, 'examples_seen': 258816, 'step': 6500, 'algorithm': 'activity_selector'}
I0716 12:27:29.008373 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.982, val scores are: activity_selector: 0.982
I0716 12:27:30.006290 140714243360256 run.py:687] Algo activity_selector step 6550 current loss 1.527916, current_train_items 260752.
I0716 12:27:30.039153 140714243360256 run.py:722] (val) algo activity_selector step 6550: {'selected': 0.9621621621621622, 'score': 0.9621621621621622, 'examples_seen': 260752, 'step': 6550, 'algorithm': 'activity_selector'}
I0716 12:27:30.039301 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0716 12:27:31.051815 140714243360256 run.py:687] Algo activity_selector step 6600 current loss 0.349699, current_train_items 262800.
I0716 12:27:31.074040 140714243360256 run.py:722] (val) algo activity_selector step 6600: {'selected': 0.9788053949903661, 'score': 0.9788053949903661, 'examples_seen': 262800, 'step': 6600, 'algorithm': 'activity_selector'}
I0716 12:27:31.074191 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.979, val scores are: activity_selector: 0.979
I0716 12:27:32.083665 140714243360256 run.py:687] Algo activity_selector step 6650 current loss 0.059920, current_train_items 264832.
I0716 12:27:32.106766 140714243360256 run.py:722] (val) algo activity_selector step 6650: {'selected': 0.9766536964980544, 'score': 0.9766536964980544, 'examples_seen': 264832, 'step': 6650, 'algorithm': 'activity_selector'}
I0716 12:27:32.106922 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0716 12:27:33.116684 140714243360256 run.py:687] Algo activity_selector step 6700 current loss 0.919024, current_train_items 266800.
I0716 12:27:33.140188 140714243360256 run.py:722] (val) algo activity_selector step 6700: {'selected': 0.984, 'score': 0.984, 'examples_seen': 266800, 'step': 6700, 'algorithm': 'activity_selector'}
I0716 12:27:33.140336 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.984, val scores are: activity_selector: 0.984
I0716 12:27:34.138030 140714243360256 run.py:687] Algo activity_selector step 6750 current loss 0.280589, current_train_items 268800.
I0716 12:27:34.163244 140714243360256 run.py:722] (val) algo activity_selector step 6750: {'selected': 0.9611307420494699, 'score': 0.9611307420494699, 'examples_seen': 268800, 'step': 6750, 'algorithm': 'activity_selector'}
I0716 12:27:34.163394 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0716 12:27:35.161115 140714243360256 run.py:687] Algo activity_selector step 6800 current loss 0.233656, current_train_items 270752.
I0716 12:27:35.188540 140714243360256 run.py:722] (val) algo activity_selector step 6800: {'selected': 0.9730769230769232, 'score': 0.9730769230769232, 'examples_seen': 270752, 'step': 6800, 'algorithm': 'activity_selector'}
I0716 12:27:35.188690 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0716 12:27:36.189564 140714243360256 run.py:687] Algo activity_selector step 6850 current loss 1.168132, current_train_items 272736.
I0716 12:27:36.219289 140714243360256 run.py:722] (val) algo activity_selector step 6850: {'selected': 0.9727626459143969, 'score': 0.9727626459143969, 'examples_seen': 272736, 'step': 6850, 'algorithm': 'activity_selector'}
I0716 12:27:36.219439 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0716 12:27:37.208567 140714243360256 run.py:687] Algo activity_selector step 6900 current loss 0.453382, current_train_items 274720.
I0716 12:27:37.241003 140714243360256 run.py:722] (val) algo activity_selector step 6900: {'selected': 0.9396226415094341, 'score': 0.9396226415094341, 'examples_seen': 274720, 'step': 6900, 'algorithm': 'activity_selector'}
I0716 12:27:37.241153 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0716 12:27:38.271284 140714243360256 run.py:687] Algo activity_selector step 6950 current loss 0.290324, current_train_items 276736.
I0716 12:27:38.293483 140714243360256 run.py:722] (val) algo activity_selector step 6950: {'selected': 0.942084942084942, 'score': 0.942084942084942, 'examples_seen': 276736, 'step': 6950, 'algorithm': 'activity_selector'}
I0716 12:27:38.293640 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0716 12:27:39.309095 140714243360256 run.py:687] Algo activity_selector step 7000 current loss 0.152881, current_train_items 278768.
I0716 12:27:39.331237 140714243360256 run.py:722] (val) algo activity_selector step 7000: {'selected': 0.9674952198852772, 'score': 0.9674952198852772, 'examples_seen': 278768, 'step': 7000, 'algorithm': 'activity_selector'}
I0716 12:27:39.331386 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0716 12:27:40.327137 140714243360256 run.py:687] Algo activity_selector step 7050 current loss 0.362195, current_train_items 280752.
I0716 12:27:40.350528 140714243360256 run.py:722] (val) algo activity_selector step 7050: {'selected': 0.9565217391304348, 'score': 0.9565217391304348, 'examples_seen': 280752, 'step': 7050, 'algorithm': 'activity_selector'}
I0716 12:27:40.350683 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0716 12:27:41.359682 140714243360256 run.py:687] Algo activity_selector step 7100 current loss 0.256860, current_train_items 282736.
I0716 12:27:41.385093 140714243360256 run.py:722] (val) algo activity_selector step 7100: {'selected': 0.89811320754717, 'score': 0.89811320754717, 'examples_seen': 282736, 'step': 7100, 'algorithm': 'activity_selector'}
I0716 12:27:41.385251 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0716 12:27:42.371624 140714243360256 run.py:687] Algo activity_selector step 7150 current loss 1.791632, current_train_items 284720.
I0716 12:27:42.399905 140714243360256 run.py:722] (val) algo activity_selector step 7150: {'selected': 0.9411764705882353, 'score': 0.9411764705882353, 'examples_seen': 284720, 'step': 7150, 'algorithm': 'activity_selector'}
I0716 12:27:42.400055 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0716 12:27:43.421638 140714243360256 run.py:687] Algo activity_selector step 7200 current loss 0.179015, current_train_items 286672.
I0716 12:27:43.451379 140714243360256 run.py:722] (val) algo activity_selector step 7200: {'selected': 0.9632495164410056, 'score': 0.9632495164410056, 'examples_seen': 286672, 'step': 7200, 'algorithm': 'activity_selector'}
I0716 12:27:43.451538 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0716 12:27:44.449226 140714243360256 run.py:687] Algo activity_selector step 7250 current loss 3.765054, current_train_items 288640.
I0716 12:27:44.488833 140714243360256 run.py:722] (val) algo activity_selector step 7250: {'selected': 0.9518518518518518, 'score': 0.9518518518518518, 'examples_seen': 288640, 'step': 7250, 'algorithm': 'activity_selector'}
I0716 12:27:44.488985 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0716 12:27:45.505092 140714243360256 run.py:687] Algo activity_selector step 7300 current loss 0.245654, current_train_items 290688.
I0716 12:27:45.527104 140714243360256 run.py:722] (val) algo activity_selector step 7300: {'selected': 0.9850187265917603, 'score': 0.9850187265917603, 'examples_seen': 290688, 'step': 7300, 'algorithm': 'activity_selector'}
I0716 12:27:45.527258 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.985, val scores are: activity_selector: 0.985
I0716 12:27:46.544321 140714243360256 run.py:687] Algo activity_selector step 7350 current loss 0.146805, current_train_items 292688.
I0716 12:27:46.566623 140714243360256 run.py:722] (val) algo activity_selector step 7350: {'selected': 0.9669902912621359, 'score': 0.9669902912621359, 'examples_seen': 292688, 'step': 7350, 'algorithm': 'activity_selector'}
I0716 12:27:46.566774 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0716 12:27:47.562765 140714243360256 run.py:687] Algo activity_selector step 7400 current loss 1.020704, current_train_items 294688.
I0716 12:27:47.585963 140714243360256 run.py:722] (val) algo activity_selector step 7400: {'selected': 0.974155069582505, 'score': 0.974155069582505, 'examples_seen': 294688, 'step': 7400, 'algorithm': 'activity_selector'}
I0716 12:27:47.586114 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0716 12:27:48.600609 140714243360256 run.py:687] Algo activity_selector step 7450 current loss 0.500601, current_train_items 296672.
I0716 12:27:48.626130 140714243360256 run.py:722] (val) algo activity_selector step 7450: {'selected': 0.955684007707129, 'score': 0.955684007707129, 'examples_seen': 296672, 'step': 7450, 'algorithm': 'activity_selector'}
I0716 12:27:48.626282 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0716 12:27:49.624921 140714243360256 run.py:687] Algo activity_selector step 7500 current loss 1.918997, current_train_items 298624.
I0716 12:27:49.652850 140714243360256 run.py:722] (val) algo activity_selector step 7500: {'selected': 0.9751434034416827, 'score': 0.9751434034416827, 'examples_seen': 298624, 'step': 7500, 'algorithm': 'activity_selector'}
I0716 12:27:49.653023 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0716 12:27:50.656624 140714243360256 run.py:687] Algo activity_selector step 7550 current loss 4.822297, current_train_items 300624.
I0716 12:27:50.686903 140714243360256 run.py:722] (val) algo activity_selector step 7550: {'selected': 0.9717741935483871, 'score': 0.9717741935483871, 'examples_seen': 300624, 'step': 7550, 'algorithm': 'activity_selector'}
I0716 12:27:50.687058 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0716 12:27:51.689541 140714243360256 run.py:687] Algo activity_selector step 7600 current loss 3.540052, current_train_items 302576.
I0716 12:27:51.722308 140714243360256 run.py:722] (val) algo activity_selector step 7600: {'selected': 0.9674952198852772, 'score': 0.9674952198852772, 'examples_seen': 302576, 'step': 7600, 'algorithm': 'activity_selector'}
I0716 12:27:51.722459 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0716 12:27:52.735079 140714243360256 run.py:687] Algo activity_selector step 7650 current loss 0.396296, current_train_items 304608.
I0716 12:27:52.757421 140714243360256 run.py:722] (val) algo activity_selector step 7650: {'selected': 0.9755102040816327, 'score': 0.9755102040816327, 'examples_seen': 304608, 'step': 7650, 'algorithm': 'activity_selector'}
I0716 12:27:52.757583 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0716 12:27:53.782279 140714243360256 run.py:687] Algo activity_selector step 7700 current loss 0.117141, current_train_items 306640.
I0716 12:27:53.804440 140714243360256 run.py:722] (val) algo activity_selector step 7700: {'selected': 0.969939879759519, 'score': 0.969939879759519, 'examples_seen': 306640, 'step': 7700, 'algorithm': 'activity_selector'}
I0716 12:27:53.804614 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0716 12:27:54.817160 140714243360256 run.py:687] Algo activity_selector step 7750 current loss 0.832470, current_train_items 308608.
I0716 12:27:54.841178 140714243360256 run.py:722] (val) algo activity_selector step 7750: {'selected': 0.96, 'score': 0.96, 'examples_seen': 308608, 'step': 7750, 'algorithm': 'activity_selector'}
I0716 12:27:54.841330 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0716 12:27:55.847574 140714243360256 run.py:687] Algo activity_selector step 7800 current loss 0.140320, current_train_items 310608.
I0716 12:27:55.874788 140714243360256 run.py:722] (val) algo activity_selector step 7800: {'selected': 0.9117043121149897, 'score': 0.9117043121149897, 'examples_seen': 310608, 'step': 7800, 'algorithm': 'activity_selector'}
I0716 12:27:55.874942 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0716 12:27:56.883723 140714243360256 run.py:687] Algo activity_selector step 7850 current loss 0.624583, current_train_items 312576.
I0716 12:27:56.911272 140714243360256 run.py:722] (val) algo activity_selector step 7850: {'selected': 0.9750479846449136, 'score': 0.9750479846449136, 'examples_seen': 312576, 'step': 7850, 'algorithm': 'activity_selector'}
I0716 12:27:56.911425 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0716 12:27:57.920853 140714243360256 run.py:687] Algo activity_selector step 7900 current loss 2.472516, current_train_items 314528.
I0716 12:27:57.952216 140714243360256 run.py:722] (val) algo activity_selector step 7900: {'selected': 0.9628180039138944, 'score': 0.9628180039138944, 'examples_seen': 314528, 'step': 7900, 'algorithm': 'activity_selector'}
I0716 12:27:57.952365 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0716 12:27:58.957901 140714243360256 run.py:687] Algo activity_selector step 7950 current loss 3.535213, current_train_items 316528.
I0716 12:27:58.991095 140714243360256 run.py:722] (val) algo activity_selector step 7950: {'selected': 0.9769094138543517, 'score': 0.9769094138543517, 'examples_seen': 316528, 'step': 7950, 'algorithm': 'activity_selector'}
I0716 12:27:58.991248 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0716 12:28:00.010137 140714243360256 run.py:687] Algo activity_selector step 8000 current loss 0.662902, current_train_items 318528.
I0716 12:28:00.032103 140714243360256 run.py:722] (val) algo activity_selector step 8000: {'selected': 0.9583333333333334, 'score': 0.9583333333333334, 'examples_seen': 318528, 'step': 8000, 'algorithm': 'activity_selector'}
I0716 12:28:00.032253 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0716 12:28:01.050416 140714243360256 run.py:687] Algo activity_selector step 8050 current loss 0.204979, current_train_items 320560.
I0716 12:28:01.072707 140714243360256 run.py:722] (val) algo activity_selector step 8050: {'selected': 0.9607843137254902, 'score': 0.9607843137254902, 'examples_seen': 320560, 'step': 8050, 'algorithm': 'activity_selector'}
I0716 12:28:01.072857 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0716 12:28:02.070838 140714243360256 run.py:687] Algo activity_selector step 8100 current loss 0.230628, current_train_items 322544.
I0716 12:28:02.094008 140714243360256 run.py:722] (val) algo activity_selector step 8100: {'selected': 0.9681050656660412, 'score': 0.9681050656660412, 'examples_seen': 322544, 'step': 8100, 'algorithm': 'activity_selector'}
I0716 12:28:02.094156 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0716 12:28:03.114423 140714243360256 run.py:687] Algo activity_selector step 8150 current loss 0.180023, current_train_items 324528.
I0716 12:28:03.139486 140714243360256 run.py:722] (val) algo activity_selector step 8150: {'selected': 0.9603024574669187, 'score': 0.9603024574669187, 'examples_seen': 324528, 'step': 8150, 'algorithm': 'activity_selector'}
I0716 12:28:03.139651 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0716 12:28:04.145284 140714243360256 run.py:687] Algo activity_selector step 8200 current loss 1.664940, current_train_items 326528.
I0716 12:28:04.172865 140714243360256 run.py:722] (val) algo activity_selector step 8200: {'selected': 0.95703125, 'score': 0.95703125, 'examples_seen': 326528, 'step': 8200, 'algorithm': 'activity_selector'}
I0716 12:28:04.173027 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0716 12:28:05.179336 140714243360256 run.py:687] Algo activity_selector step 8250 current loss 2.048384, current_train_items 328464.
I0716 12:28:05.208686 140714243360256 run.py:722] (val) algo activity_selector step 8250: {'selected': 0.9423076923076923, 'score': 0.9423076923076923, 'examples_seen': 328464, 'step': 8250, 'algorithm': 'activity_selector'}
I0716 12:28:05.208850 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0716 12:28:06.218106 140714243360256 run.py:687] Algo activity_selector step 8300 current loss 3.075154, current_train_items 330432.
I0716 12:28:06.250867 140714243360256 run.py:722] (val) algo activity_selector step 8300: {'selected': 0.9521988527724665, 'score': 0.9521988527724665, 'examples_seen': 330432, 'step': 8300, 'algorithm': 'activity_selector'}
I0716 12:28:06.251017 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0716 12:28:07.266428 140714243360256 run.py:687] Algo activity_selector step 8350 current loss 0.041312, current_train_items 332480.
I0716 12:28:07.288767 140714243360256 run.py:722] (val) algo activity_selector step 8350: {'selected': 0.9632495164410059, 'score': 0.9632495164410059, 'examples_seen': 332480, 'step': 8350, 'algorithm': 'activity_selector'}
I0716 12:28:07.288920 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0716 12:28:08.314744 140714243360256 run.py:687] Algo activity_selector step 8400 current loss 0.050871, current_train_items 334480.
I0716 12:28:08.337835 140714243360256 run.py:722] (val) algo activity_selector step 8400: {'selected': 0.9536679536679536, 'score': 0.9536679536679536, 'examples_seen': 334480, 'step': 8400, 'algorithm': 'activity_selector'}
I0716 12:28:08.337985 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0716 12:28:09.333957 140714243360256 run.py:687] Algo activity_selector step 8450 current loss 1.165556, current_train_items 336480.
I0716 12:28:09.359853 140714243360256 run.py:722] (val) algo activity_selector step 8450: {'selected': 0.9596774193548387, 'score': 0.9596774193548387, 'examples_seen': 336480, 'step': 8450, 'algorithm': 'activity_selector'}
I0716 12:28:09.360004 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0716 12:28:10.364164 140714243360256 run.py:687] Algo activity_selector step 8500 current loss 0.171660, current_train_items 338464.
I0716 12:28:10.388683 140714243360256 run.py:722] (val) algo activity_selector step 8500: {'selected': 0.9482071713147411, 'score': 0.9482071713147411, 'examples_seen': 338464, 'step': 8500, 'algorithm': 'activity_selector'}
I0716 12:28:10.388834 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0716 12:28:11.390742 140714243360256 run.py:687] Algo activity_selector step 8550 current loss 2.060720, current_train_items 340432.
I0716 12:28:11.417976 140714243360256 run.py:722] (val) algo activity_selector step 8550: {'selected': 0.97632058287796, 'score': 0.97632058287796, 'examples_seen': 340432, 'step': 8550, 'algorithm': 'activity_selector'}
I0716 12:28:11.418124 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0716 12:28:12.397638 140714243360256 run.py:687] Algo activity_selector step 8600 current loss 1.857495, current_train_items 342416.
I0716 12:28:12.426810 140714243360256 run.py:722] (val) algo activity_selector step 8600: {'selected': 0.9869158878504672, 'score': 0.9869158878504672, 'examples_seen': 342416, 'step': 8600, 'algorithm': 'activity_selector'}
I0716 12:28:12.426958 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.987, val scores are: activity_selector: 0.987
I0716 12:28:13.433827 140714243360256 run.py:687] Algo activity_selector step 8650 current loss 2.846689, current_train_items 344368.
I0716 12:28:13.466794 140714243360256 run.py:722] (val) algo activity_selector step 8650: {'selected': 0.9683794466403163, 'score': 0.9683794466403163, 'examples_seen': 344368, 'step': 8650, 'algorithm': 'activity_selector'}
I0716 12:28:13.466941 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0716 12:28:14.478232 140714243360256 run.py:687] Algo activity_selector step 8700 current loss 0.345365, current_train_items 346400.
I0716 12:28:14.500422 140714243360256 run.py:722] (val) algo activity_selector step 8700: {'selected': 0.952741020793951, 'score': 0.952741020793951, 'examples_seen': 346400, 'step': 8700, 'algorithm': 'activity_selector'}
I0716 12:28:14.500586 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0716 12:28:15.516056 140714243360256 run.py:687] Algo activity_selector step 8750 current loss 0.031306, current_train_items 348432.
I0716 12:28:15.537810 140714243360256 run.py:722] (val) algo activity_selector step 8750: {'selected': 0.970873786407767, 'score': 0.970873786407767, 'examples_seen': 348432, 'step': 8750, 'algorithm': 'activity_selector'}
I0716 12:28:15.537960 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0716 12:28:16.545365 140714243360256 run.py:687] Algo activity_selector step 8800 current loss 0.788003, current_train_items 350416.
I0716 12:28:16.569159 140714243360256 run.py:722] (val) algo activity_selector step 8800: {'selected': 0.9693251533742331, 'score': 0.9693251533742331, 'examples_seen': 350416, 'step': 8800, 'algorithm': 'activity_selector'}
I0716 12:28:16.569309 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0716 12:28:17.568415 140714243360256 run.py:687] Algo activity_selector step 8850 current loss 0.288233, current_train_items 352400.
I0716 12:28:17.593202 140714243360256 run.py:722] (val) algo activity_selector step 8850: {'selected': 0.9808429118773947, 'score': 0.9808429118773947, 'examples_seen': 352400, 'step': 8850, 'algorithm': 'activity_selector'}
I0716 12:28:17.593352 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0716 12:28:18.603115 140714243360256 run.py:687] Algo activity_selector step 8900 current loss 0.394205, current_train_items 354368.
I0716 12:28:18.630856 140714243360256 run.py:722] (val) algo activity_selector step 8900: {'selected': 0.9552238805970148, 'score': 0.9552238805970148, 'examples_seen': 354368, 'step': 8900, 'algorithm': 'activity_selector'}
I0716 12:28:18.631008 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0716 12:28:19.622325 140714243360256 run.py:687] Algo activity_selector step 8950 current loss 1.697219, current_train_items 356320.
I0716 12:28:19.651997 140714243360256 run.py:722] (val) algo activity_selector step 8950: {'selected': 0.9540229885057471, 'score': 0.9540229885057471, 'examples_seen': 356320, 'step': 8950, 'algorithm': 'activity_selector'}
I0716 12:28:19.652152 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0716 12:28:20.645059 140714243360256 run.py:687] Algo activity_selector step 9000 current loss 2.488201, current_train_items 358320.
I0716 12:28:20.677473 140714243360256 run.py:722] (val) algo activity_selector step 9000: {'selected': 0.99609375, 'score': 0.99609375, 'examples_seen': 358320, 'step': 9000, 'algorithm': 'activity_selector'}
I0716 12:28:20.677636 140714243360256 run.py:743] Checkpointing best model, best avg val score was 0.994, current avg val score is 0.996, val scores are: activity_selector: 0.996
I0716 12:28:21.705561 140714243360256 run.py:687] Algo activity_selector step 9050 current loss 0.286660, current_train_items 360320.
I0716 12:28:21.727979 140714243360256 run.py:722] (val) algo activity_selector step 9050: {'selected': 0.9402985074626865, 'score': 0.9402985074626865, 'examples_seen': 360320, 'step': 9050, 'algorithm': 'activity_selector'}
I0716 12:28:21.728128 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.996, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0716 12:28:22.743480 140714243360256 run.py:687] Algo activity_selector step 9100 current loss 0.072624, current_train_items 362352.
I0716 12:28:22.766329 140714243360256 run.py:722] (val) algo activity_selector step 9100: {'selected': 0.9443298969072165, 'score': 0.9443298969072165, 'examples_seen': 362352, 'step': 9100, 'algorithm': 'activity_selector'}
I0716 12:28:22.766478 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.996, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0716 12:28:23.771146 140714243360256 run.py:687] Algo activity_selector step 9150 current loss 0.182329, current_train_items 364352.
I0716 12:28:23.795018 140714243360256 run.py:722] (val) algo activity_selector step 9150: {'selected': 0.9565217391304348, 'score': 0.9565217391304348, 'examples_seen': 364352, 'step': 9150, 'algorithm': 'activity_selector'}
I0716 12:28:23.795176 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.996, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0716 12:28:24.794474 140714243360256 run.py:687] Algo activity_selector step 9200 current loss 0.131949, current_train_items 366320.
I0716 12:28:24.819247 140714243360256 run.py:722] (val) algo activity_selector step 9200: {'selected': 0.9760956175298804, 'score': 0.9760956175298804, 'examples_seen': 366320, 'step': 9200, 'algorithm': 'activity_selector'}
I0716 12:28:24.819401 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.996, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0716 12:28:25.808866 140714243360256 run.py:687] Algo activity_selector step 9250 current loss 1.565643, current_train_items 368320.
I0716 12:28:25.836616 140714243360256 run.py:722] (val) algo activity_selector step 9250: {'selected': 0.9900199600798404, 'score': 0.9900199600798404, 'examples_seen': 368320, 'step': 9250, 'algorithm': 'activity_selector'}
I0716 12:28:25.836768 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.996, current avg val score is 0.990, val scores are: activity_selector: 0.990
I0716 12:28:26.838638 140714243360256 run.py:687] Algo activity_selector step 9300 current loss 1.312118, current_train_items 370272.
I0716 12:28:26.867998 140714243360256 run.py:722] (val) algo activity_selector step 9300: {'selected': 0.9575289575289575, 'score': 0.9575289575289575, 'examples_seen': 370272, 'step': 9300, 'algorithm': 'activity_selector'}
I0716 12:28:26.868150 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.996, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0716 12:28:27.890241 140714243360256 run.py:687] Algo activity_selector step 9350 current loss 2.487696, current_train_items 372240.
I0716 12:28:27.923831 140714243360256 run.py:722] (val) algo activity_selector step 9350: {'selected': 0.9600000000000001, 'score': 0.9600000000000001, 'examples_seen': 372240, 'step': 9350, 'algorithm': 'activity_selector'}
I0716 12:28:27.923989 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.996, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0716 12:28:28.939744 140714243360256 run.py:687] Algo activity_selector step 9400 current loss 0.134102, current_train_items 374288.
I0716 12:28:28.961526 140714243360256 run.py:722] (val) algo activity_selector step 9400: {'selected': 0.9606299212598426, 'score': 0.9606299212598426, 'examples_seen': 374288, 'step': 9400, 'algorithm': 'activity_selector'}
I0716 12:28:28.961688 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.996, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0716 12:28:29.985102 140714243360256 run.py:687] Algo activity_selector step 9450 current loss 0.049765, current_train_items 376288.
I0716 12:28:30.007119 140714243360256 run.py:722] (val) algo activity_selector step 9450: {'selected': 0.9671179883945842, 'score': 0.9671179883945842, 'examples_seen': 376288, 'step': 9450, 'algorithm': 'activity_selector'}
I0716 12:28:30.007272 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.996, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0716 12:28:31.014240 140714243360256 run.py:687] Algo activity_selector step 9500 current loss 0.717318, current_train_items 378304.
I0716 12:28:31.037695 140714243360256 run.py:722] (val) algo activity_selector step 9500: {'selected': 0.9566854990583804, 'score': 0.9566854990583804, 'examples_seen': 378304, 'step': 9500, 'algorithm': 'activity_selector'}
I0716 12:28:31.037849 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.996, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0716 12:28:32.034642 140714243360256 run.py:687] Algo activity_selector step 9550 current loss 0.183938, current_train_items 380272.
I0716 12:28:32.060824 140714243360256 run.py:722] (val) algo activity_selector step 9550: {'selected': 0.928030303030303, 'score': 0.928030303030303, 'examples_seen': 380272, 'step': 9550, 'algorithm': 'activity_selector'}
I0716 12:28:32.060975 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.996, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0716 12:28:33.072969 140714243360256 run.py:687] Algo activity_selector step 9600 current loss 2.227486, current_train_items 382240.
I0716 12:28:33.103094 140714243360256 run.py:722] (val) algo activity_selector step 9600: {'selected': 0.9656488549618321, 'score': 0.9656488549618321, 'examples_seen': 382240, 'step': 9600, 'algorithm': 'activity_selector'}
I0716 12:28:33.103242 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.996, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0716 12:28:34.094810 140714243360256 run.py:687] Algo activity_selector step 9650 current loss 0.526868, current_train_items 384224.
I0716 12:28:34.123950 140714243360256 run.py:722] (val) algo activity_selector step 9650: {'selected': 0.9657794676806084, 'score': 0.9657794676806084, 'examples_seen': 384224, 'step': 9650, 'algorithm': 'activity_selector'}
I0716 12:28:34.124099 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.996, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0716 12:28:35.138284 140714243360256 run.py:687] Algo activity_selector step 9700 current loss 2.538365, current_train_items 386176.
I0716 12:28:35.171317 140714243360256 run.py:722] (val) algo activity_selector step 9700: {'selected': 0.9316770186335405, 'score': 0.9316770186335405, 'examples_seen': 386176, 'step': 9700, 'algorithm': 'activity_selector'}
I0716 12:28:35.171466 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.996, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0716 12:28:36.184485 140714243360256 run.py:687] Algo activity_selector step 9750 current loss 0.335115, current_train_items 388224.
I0716 12:28:36.206217 140714243360256 run.py:722] (val) algo activity_selector step 9750: {'selected': 0.9757009345794392, 'score': 0.9757009345794392, 'examples_seen': 388224, 'step': 9750, 'algorithm': 'activity_selector'}
I0716 12:28:36.206366 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.996, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0716 12:28:37.225717 140714243360256 run.py:687] Algo activity_selector step 9800 current loss 0.100084, current_train_items 390240.
I0716 12:28:37.248044 140714243360256 run.py:722] (val) algo activity_selector step 9800: {'selected': 0.9632495164410056, 'score': 0.9632495164410056, 'examples_seen': 390240, 'step': 9800, 'algorithm': 'activity_selector'}
I0716 12:28:37.248195 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.996, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0716 12:28:38.266783 140714243360256 run.py:687] Algo activity_selector step 9850 current loss 0.747667, current_train_items 392224.
I0716 12:28:38.290592 140714243360256 run.py:722] (val) algo activity_selector step 9850: {'selected': 0.97265625, 'score': 0.97265625, 'examples_seen': 392224, 'step': 9850, 'algorithm': 'activity_selector'}
I0716 12:28:38.290754 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.996, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0716 12:28:39.284880 140714243360256 run.py:687] Algo activity_selector step 9900 current loss 0.175001, current_train_items 394208.
I0716 12:28:39.310023 140714243360256 run.py:722] (val) algo activity_selector step 9900: {'selected': 0.9714285714285714, 'score': 0.9714285714285714, 'examples_seen': 394208, 'step': 9900, 'algorithm': 'activity_selector'}
I0716 12:28:39.310183 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.996, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0716 12:28:40.329018 140714243360256 run.py:687] Algo activity_selector step 9950 current loss 0.287072, current_train_items 396176.
I0716 12:28:40.357367 140714243360256 run.py:722] (val) algo activity_selector step 9950: {'selected': 0.9641434262948209, 'score': 0.9641434262948209, 'examples_seen': 396176, 'step': 9950, 'algorithm': 'activity_selector'}
I0716 12:28:40.357527 140714243360256 run.py:746] Not saving new best model, best avg val score was 0.996, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0716 12:28:41.329905 140714243360256 run.py:752] Restoring best model from checkpoint...
I0716 12:28:46.894928 140714243360256 run.py:767] (test) algo activity_selector : {'selected': 0.9077212806026366, 'score': 0.9077212806026366, 'examples_seen': 398112, 'step': 10000, 'algorithm': 'activity_selector'}
I0716 12:28:46.895071 140714243360256 run.py:769] Done!
