I0216 21:53:21.624637 132073186858496 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0216 21:53:21.628222 132073186858496 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0216 21:53:22.031019 132073186858496 run.py:443] Model: f7 ['activity_selector']
I0216 21:53:22.031118 132073186858496 run.py:445] algorithms ['activity_selector']
I0216 21:53:22.031296 132073186858496 run.py:446] train_lengths ['4', '7', '11', '13', '16']
I0216 21:53:22.031338 132073186858496 run.py:447] train_batch_size 16
I0216 21:53:22.031437 132073186858496 run.py:448] val_batch_size 16
I0216 21:53:22.031469 132073186858496 run.py:449] test_batch_size 16
I0216 21:53:22.031499 132073186858496 run.py:450] chunked_training True
I0216 21:53:22.031619 132073186858496 run.py:451] chunk_length 16
I0216 21:53:22.031651 132073186858496 run.py:452] train_steps 5001
I0216 21:53:22.031681 132073186858496 run.py:453] eval_every 50
I0216 21:53:22.031712 132073186858496 run.py:454] test_every 500
I0216 21:53:22.031744 132073186858496 run.py:455] hidden_size 256
I0216 21:53:22.031773 132073186858496 run.py:456] nb_msg_passing_steps 1
I0216 21:53:22.031802 132073186858496 run.py:457] learning_rate 0.001
I0216 21:53:22.031889 132073186858496 run.py:458] grad_clip_max_norm 1.0
I0216 21:53:22.031922 132073186858496 run.py:459] dropout_prob 0.0
I0216 21:53:22.031955 132073186858496 run.py:460] hint_teacher_forcing 0.0
I0216 21:53:22.031984 132073186858496 run.py:461] hint_mode encoded_decoded
I0216 21:53:22.032088 132073186858496 run.py:462] hint_repred_mode soft
I0216 21:53:22.032119 132073186858496 run.py:463] use_ln True
I0216 21:53:22.032147 132073186858496 run.py:464] use_lstm True
I0216 21:53:22.032175 132073186858496 run.py:465] nb_triplet_fts 16
I0216 21:53:22.032211 132073186858496 run.py:466] encoder_init xavier_on_scalars
I0216 21:53:22.032241 132073186858496 run.py:467] processor_type f7
I0216 21:53:22.032273 132073186858496 run.py:468] checkpoint_path CLRS30
I0216 21:53:22.032302 132073186858496 run.py:469] dataset_path CLRS30
I0216 21:53:22.032330 132073186858496 run.py:470] freeze_processor False
I0216 21:53:22.032359 132073186858496 run.py:471] reduction min
I0216 21:53:22.032387 132073186858496 run.py:472] activation elu
I0216 21:53:22.032415 132073186858496 run.py:473] restore_model 
I0216 21:53:22.032446 132073186858496 run.py:474] gated True
I0216 21:53:22.032475 132073186858496 run.py:475] gated_activation tanh
I0216 21:53:22.032503 132073186858496 run.py:476] memory_type None
I0216 21:53:22.032587 132073186858496 run.py:477] memory_size None
I0216 21:53:22.035275 132073186858496 run.py:503] Creating samplers for algo activity_selector
W0216 21:53:22.035461 132073186858496 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0216 21:53:22.035711 132073186858496 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0216 21:53:22.255766 132073186858496 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0216 21:53:22.500734 132073186858496 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0216 21:53:22.802741 132073186858496 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0216 21:53:23.136396 132073186858496 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0216 21:53:23.519231 132073186858496 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0216 21:53:23.519518 132073186858496 samplers.py:124] Creating a dataset with 64 samples.
I0216 21:53:23.544952 132073186858496 run.py:287] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0216 21:53:23.545728 132073186858496 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0216 21:53:23.548891 132073186858496 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0216 21:53:23.552276 132073186858496 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0216 21:53:23.605545 132073186858496 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W0216 21:53:23.626305 132073186858496 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x781e2ad9a020> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0216 21:53:56.628062 132073186858496 run.py:729] Algo activity_selector step 0 current loss 5.716732, current_train_items 32.
I0216 21:54:06.587558 132073186858496 run.py:764] (val) algo activity_selector step 0: {'selected': 0.0425531914893617, 'score': 0.0425531914893617, 'examples_seen': 32, 'step': 0, 'algorithm': 'activity_selector'}
I0216 21:54:06.587723 132073186858496 run.py:785] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.043, val scores are: activity_selector: 0.043
I0216 21:54:59.370156 132073186858496 run.py:729] Algo activity_selector step 50 current loss 4.054956, current_train_items 1408.
I0216 21:54:59.488263 132073186858496 run.py:764] (val) algo activity_selector step 50: {'selected': 0.6198547215496368, 'score': 0.6198547215496368, 'examples_seen': 1408, 'step': 50, 'algorithm': 'activity_selector'}
I0216 21:54:59.488502 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.043, current avg val score is 0.620, val scores are: activity_selector: 0.620
I0216 21:55:00.598074 132073186858496 run.py:729] Algo activity_selector step 100 current loss 3.111643, current_train_items 2800.
I0216 21:55:00.731417 132073186858496 run.py:764] (val) algo activity_selector step 100: {'selected': 0.7212543554006969, 'score': 0.7212543554006969, 'examples_seen': 2800, 'step': 100, 'algorithm': 'activity_selector'}
I0216 21:55:00.731647 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.620, current avg val score is 0.721, val scores are: activity_selector: 0.721
I0216 21:55:01.840411 132073186858496 run.py:729] Algo activity_selector step 150 current loss 2.675466, current_train_items 4176.
I0216 21:55:01.988235 132073186858496 run.py:764] (val) algo activity_selector step 150: {'selected': 0.7872340425531915, 'score': 0.7872340425531915, 'examples_seen': 4176, 'step': 150, 'algorithm': 'activity_selector'}
I0216 21:55:01.988461 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.721, current avg val score is 0.787, val scores are: activity_selector: 0.787
I0216 21:55:03.089783 132073186858496 run.py:729] Algo activity_selector step 200 current loss 2.466208, current_train_items 5536.
I0216 21:55:03.220363 132073186858496 run.py:764] (val) algo activity_selector step 200: {'selected': 0.7667342799188641, 'score': 0.7667342799188641, 'examples_seen': 5536, 'step': 200, 'algorithm': 'activity_selector'}
I0216 21:55:03.220513 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.787, current avg val score is 0.767, val scores are: activity_selector: 0.767
I0216 21:55:04.257234 132073186858496 run.py:729] Algo activity_selector step 250 current loss 2.862742, current_train_items 6944.
I0216 21:55:04.394818 132073186858496 run.py:764] (val) algo activity_selector step 250: {'selected': 0.6755555555555555, 'score': 0.6755555555555555, 'examples_seen': 6944, 'step': 250, 'algorithm': 'activity_selector'}
I0216 21:55:04.395060 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.787, current avg val score is 0.676, val scores are: activity_selector: 0.676
I0216 21:55:05.452724 132073186858496 run.py:729] Algo activity_selector step 300 current loss 2.202757, current_train_items 8304.
I0216 21:55:05.586985 132073186858496 run.py:764] (val) algo activity_selector step 300: {'selected': 0.7733333333333334, 'score': 0.7733333333333334, 'examples_seen': 8304, 'step': 300, 'algorithm': 'activity_selector'}
I0216 21:55:05.587222 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.787, current avg val score is 0.773, val scores are: activity_selector: 0.773
I0216 21:55:06.639741 132073186858496 run.py:729] Algo activity_selector step 350 current loss 2.090270, current_train_items 9680.
I0216 21:55:06.770143 132073186858496 run.py:764] (val) algo activity_selector step 350: {'selected': 0.7999999999999999, 'score': 0.7999999999999999, 'examples_seen': 9680, 'step': 350, 'algorithm': 'activity_selector'}
I0216 21:55:06.770300 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.787, current avg val score is 0.800, val scores are: activity_selector: 0.800
I0216 21:55:07.883628 132073186858496 run.py:729] Algo activity_selector step 400 current loss 1.790446, current_train_items 11072.
I0216 21:55:07.999950 132073186858496 run.py:764] (val) algo activity_selector step 400: {'selected': 0.8263254113345521, 'score': 0.8263254113345521, 'examples_seen': 11072, 'step': 400, 'algorithm': 'activity_selector'}
I0216 21:55:08.000096 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.800, current avg val score is 0.826, val scores are: activity_selector: 0.826
I0216 21:55:09.102285 132073186858496 run.py:729] Algo activity_selector step 450 current loss 1.741990, current_train_items 12448.
I0216 21:55:09.234729 132073186858496 run.py:764] (val) algo activity_selector step 450: {'selected': 0.8241563055062167, 'score': 0.8241563055062167, 'examples_seen': 12448, 'step': 450, 'algorithm': 'activity_selector'}
I0216 21:55:09.234914 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.826, current avg val score is 0.824, val scores are: activity_selector: 0.824
I0216 21:55:10.258148 132073186858496 run.py:729] Algo activity_selector step 500 current loss 2.145336, current_train_items 13824.
I0216 21:55:10.405837 132073186858496 run.py:764] (val) algo activity_selector step 500: {'selected': 0.8252788104089219, 'score': 0.8252788104089219, 'examples_seen': 13824, 'step': 500, 'algorithm': 'activity_selector'}
I0216 21:55:10.406061 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.826, current avg val score is 0.825, val scores are: activity_selector: 0.825
I0216 21:55:11.442286 132073186858496 run.py:729] Algo activity_selector step 550 current loss 1.886375, current_train_items 15200.
I0216 21:55:11.590662 132073186858496 run.py:764] (val) algo activity_selector step 550: {'selected': 0.8657314629258518, 'score': 0.8657314629258518, 'examples_seen': 15200, 'step': 550, 'algorithm': 'activity_selector'}
I0216 21:55:11.590890 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.826, current avg val score is 0.866, val scores are: activity_selector: 0.866
I0216 21:55:12.703907 132073186858496 run.py:729] Algo activity_selector step 600 current loss 1.966045, current_train_items 16576.
I0216 21:55:12.837314 132073186858496 run.py:764] (val) algo activity_selector step 600: {'selected': 0.8765432098765433, 'score': 0.8765432098765433, 'examples_seen': 16576, 'step': 600, 'algorithm': 'activity_selector'}
I0216 21:55:12.837539 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.866, current avg val score is 0.877, val scores are: activity_selector: 0.877
I0216 21:55:13.951132 132073186858496 run.py:729] Algo activity_selector step 650 current loss 1.818569, current_train_items 17952.
I0216 21:55:14.078291 132073186858496 run.py:764] (val) algo activity_selector step 650: {'selected': 0.8502581755593803, 'score': 0.8502581755593803, 'examples_seen': 17952, 'step': 650, 'algorithm': 'activity_selector'}
I0216 21:55:14.078514 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.877, current avg val score is 0.850, val scores are: activity_selector: 0.850
I0216 21:55:15.125594 132073186858496 run.py:729] Algo activity_selector step 700 current loss 1.745121, current_train_items 19344.
I0216 21:55:15.260787 132073186858496 run.py:764] (val) algo activity_selector step 700: {'selected': 0.8582089552238807, 'score': 0.8582089552238807, 'examples_seen': 19344, 'step': 700, 'algorithm': 'activity_selector'}
I0216 21:55:15.261007 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.877, current avg val score is 0.858, val scores are: activity_selector: 0.858
I0216 21:55:16.305633 132073186858496 run.py:729] Algo activity_selector step 750 current loss 1.600809, current_train_items 20720.
I0216 21:55:16.453072 132073186858496 run.py:764] (val) algo activity_selector step 750: {'selected': 0.88715953307393, 'score': 0.88715953307393, 'examples_seen': 20720, 'step': 750, 'algorithm': 'activity_selector'}
I0216 21:55:16.453313 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.877, current avg val score is 0.887, val scores are: activity_selector: 0.887
I0216 21:55:17.547618 132073186858496 run.py:729] Algo activity_selector step 800 current loss 1.409488, current_train_items 22096.
I0216 21:55:17.693193 132073186858496 run.py:764] (val) algo activity_selector step 800: {'selected': 0.8935361216730038, 'score': 0.8935361216730038, 'examples_seen': 22096, 'step': 800, 'algorithm': 'activity_selector'}
I0216 21:55:17.693349 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.887, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0216 21:55:18.772718 132073186858496 run.py:729] Algo activity_selector step 850 current loss 1.427946, current_train_items 23472.
I0216 21:55:18.921581 132073186858496 run.py:764] (val) algo activity_selector step 850: {'selected': 0.8909774436090225, 'score': 0.8909774436090225, 'examples_seen': 23472, 'step': 850, 'algorithm': 'activity_selector'}
I0216 21:55:18.921804 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.894, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0216 21:55:19.978922 132073186858496 run.py:729] Algo activity_selector step 900 current loss 1.761002, current_train_items 24848.
I0216 21:55:20.111784 132073186858496 run.py:764] (val) algo activity_selector step 900: {'selected': 0.9009345794392523, 'score': 0.9009345794392523, 'examples_seen': 24848, 'step': 900, 'algorithm': 'activity_selector'}
I0216 21:55:20.111931 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.894, current avg val score is 0.901, val scores are: activity_selector: 0.901
I0216 21:55:21.251799 132073186858496 run.py:729] Algo activity_selector step 950 current loss 1.448349, current_train_items 26224.
I0216 21:55:21.391409 132073186858496 run.py:764] (val) algo activity_selector step 950: {'selected': 0.8277227722772278, 'score': 0.8277227722772278, 'examples_seen': 26224, 'step': 950, 'algorithm': 'activity_selector'}
I0216 21:55:21.391637 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.901, current avg val score is 0.828, val scores are: activity_selector: 0.828
I0216 21:55:22.444707 132073186858496 run.py:729] Algo activity_selector step 1000 current loss 1.534006, current_train_items 27616.
I0216 21:55:22.577986 132073186858496 run.py:764] (val) algo activity_selector step 1000: {'selected': 0.8651685393258427, 'score': 0.8651685393258427, 'examples_seen': 27616, 'step': 1000, 'algorithm': 'activity_selector'}
I0216 21:55:22.578224 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.901, current avg val score is 0.865, val scores are: activity_selector: 0.865
I0216 21:55:23.635879 132073186858496 run.py:729] Algo activity_selector step 1050 current loss 1.562653, current_train_items 28992.
I0216 21:55:23.768046 132073186858496 run.py:764] (val) algo activity_selector step 1050: {'selected': 0.9141716566866267, 'score': 0.9141716566866267, 'examples_seen': 28992, 'step': 1050, 'algorithm': 'activity_selector'}
I0216 21:55:23.768282 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.901, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0216 21:55:24.879685 132073186858496 run.py:729] Algo activity_selector step 1100 current loss 1.278857, current_train_items 30368.
I0216 21:55:25.014808 132073186858496 run.py:764] (val) algo activity_selector step 1100: {'selected': 0.8752556237218814, 'score': 0.8752556237218814, 'examples_seen': 30368, 'step': 1100, 'algorithm': 'activity_selector'}
I0216 21:55:25.015028 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.914, current avg val score is 0.875, val scores are: activity_selector: 0.875
I0216 21:55:26.062175 132073186858496 run.py:729] Algo activity_selector step 1150 current loss 1.413410, current_train_items 31760.
I0216 21:55:26.197226 132073186858496 run.py:764] (val) algo activity_selector step 1150: {'selected': 0.87593984962406, 'score': 0.87593984962406, 'examples_seen': 31760, 'step': 1150, 'algorithm': 'activity_selector'}
I0216 21:55:26.197448 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.914, current avg val score is 0.876, val scores are: activity_selector: 0.876
I0216 21:55:27.262125 132073186858496 run.py:729] Algo activity_selector step 1200 current loss 1.005752, current_train_items 33120.
I0216 21:55:27.396034 132073186858496 run.py:764] (val) algo activity_selector step 1200: {'selected': 0.8947368421052632, 'score': 0.8947368421052632, 'examples_seen': 33120, 'step': 1200, 'algorithm': 'activity_selector'}
I0216 21:55:27.396277 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.914, current avg val score is 0.895, val scores are: activity_selector: 0.895
I0216 21:55:28.446672 132073186858496 run.py:729] Algo activity_selector step 1250 current loss 1.408556, current_train_items 34496.
I0216 21:55:28.580767 132073186858496 run.py:764] (val) algo activity_selector step 1250: {'selected': 0.946969696969697, 'score': 0.946969696969697, 'examples_seen': 34496, 'step': 1250, 'algorithm': 'activity_selector'}
I0216 21:55:28.580988 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.914, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0216 21:55:29.690759 132073186858496 run.py:729] Algo activity_selector step 1300 current loss 1.291986, current_train_items 35888.
I0216 21:55:29.823891 132073186858496 run.py:764] (val) algo activity_selector step 1300: {'selected': 0.8456913827655309, 'score': 0.8456913827655309, 'examples_seen': 35888, 'step': 1300, 'algorithm': 'activity_selector'}
I0216 21:55:29.824116 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.846, val scores are: activity_selector: 0.846
I0216 21:55:30.883580 132073186858496 run.py:729] Algo activity_selector step 1350 current loss 1.315382, current_train_items 37264.
I0216 21:55:31.014323 132073186858496 run.py:764] (val) algo activity_selector step 1350: {'selected': 0.9137254901960785, 'score': 0.9137254901960785, 'examples_seen': 37264, 'step': 1350, 'algorithm': 'activity_selector'}
I0216 21:55:31.014545 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0216 21:55:32.064429 132073186858496 run.py:729] Algo activity_selector step 1400 current loss 1.462265, current_train_items 38640.
I0216 21:55:32.199987 132073186858496 run.py:764] (val) algo activity_selector step 1400: {'selected': 0.8498023715415021, 'score': 0.8498023715415021, 'examples_seen': 38640, 'step': 1400, 'algorithm': 'activity_selector'}
I0216 21:55:32.200240 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.850, val scores are: activity_selector: 0.850
I0216 21:55:33.253708 132073186858496 run.py:729] Algo activity_selector step 1450 current loss 0.995992, current_train_items 40016.
I0216 21:55:33.385551 132073186858496 run.py:764] (val) algo activity_selector step 1450: {'selected': 0.9073724007561437, 'score': 0.9073724007561437, 'examples_seen': 40016, 'step': 1450, 'algorithm': 'activity_selector'}
I0216 21:55:33.385772 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0216 21:55:34.446827 132073186858496 run.py:729] Algo activity_selector step 1500 current loss 1.317809, current_train_items 41408.
I0216 21:55:34.581023 132073186858496 run.py:764] (val) algo activity_selector step 1500: {'selected': 0.9354207436399218, 'score': 0.9354207436399218, 'examples_seen': 41408, 'step': 1500, 'algorithm': 'activity_selector'}
I0216 21:55:34.581261 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0216 21:55:35.635293 132073186858496 run.py:729] Algo activity_selector step 1550 current loss 1.115658, current_train_items 42768.
I0216 21:55:35.770698 132073186858496 run.py:764] (val) algo activity_selector step 1550: {'selected': 0.937037037037037, 'score': 0.937037037037037, 'examples_seen': 42768, 'step': 1550, 'algorithm': 'activity_selector'}
I0216 21:55:35.770916 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0216 21:55:36.821273 132073186858496 run.py:729] Algo activity_selector step 1600 current loss 1.141198, current_train_items 44160.
I0216 21:55:36.955770 132073186858496 run.py:764] (val) algo activity_selector step 1600: {'selected': 0.8644400785854618, 'score': 0.8644400785854618, 'examples_seen': 44160, 'step': 1600, 'algorithm': 'activity_selector'}
I0216 21:55:36.955998 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.864, val scores are: activity_selector: 0.864
I0216 21:55:38.021712 132073186858496 run.py:729] Algo activity_selector step 1650 current loss 1.275871, current_train_items 45536.
I0216 21:55:38.155679 132073186858496 run.py:764] (val) algo activity_selector step 1650: {'selected': 0.9161793372319688, 'score': 0.9161793372319688, 'examples_seen': 45536, 'step': 1650, 'algorithm': 'activity_selector'}
I0216 21:55:38.155927 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.916, val scores are: activity_selector: 0.916
I0216 21:55:39.191888 132073186858496 run.py:729] Algo activity_selector step 1700 current loss 0.987311, current_train_items 46896.
I0216 21:55:39.339540 132073186858496 run.py:764] (val) algo activity_selector step 1700: {'selected': 0.9221556886227545, 'score': 0.9221556886227545, 'examples_seen': 46896, 'step': 1700, 'algorithm': 'activity_selector'}
I0216 21:55:39.339786 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0216 21:55:40.389788 132073186858496 run.py:729] Algo activity_selector step 1750 current loss 1.026927, current_train_items 48304.
I0216 21:55:40.523918 132073186858496 run.py:764] (val) algo activity_selector step 1750: {'selected': 0.8723809523809524, 'score': 0.8723809523809524, 'examples_seen': 48304, 'step': 1750, 'algorithm': 'activity_selector'}
I0216 21:55:40.524165 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.872, val scores are: activity_selector: 0.872
I0216 21:55:41.585226 132073186858496 run.py:729] Algo activity_selector step 1800 current loss 1.468224, current_train_items 49664.
I0216 21:55:41.719908 132073186858496 run.py:764] (val) algo activity_selector step 1800: {'selected': 0.8709055876685935, 'score': 0.8709055876685935, 'examples_seen': 49664, 'step': 1800, 'algorithm': 'activity_selector'}
I0216 21:55:41.720130 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.871, val scores are: activity_selector: 0.871
I0216 21:55:42.777156 132073186858496 run.py:729] Algo activity_selector step 1850 current loss 1.022876, current_train_items 51056.
I0216 21:55:42.911664 132073186858496 run.py:764] (val) algo activity_selector step 1850: {'selected': 0.8727272727272727, 'score': 0.8727272727272727, 'examples_seen': 51056, 'step': 1850, 'algorithm': 'activity_selector'}
I0216 21:55:42.911884 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.873, val scores are: activity_selector: 0.873
I0216 21:55:43.965262 132073186858496 run.py:729] Algo activity_selector step 1900 current loss 0.901882, current_train_items 52432.
I0216 21:55:44.098486 132073186858496 run.py:764] (val) algo activity_selector step 1900: {'selected': 0.9110707803992741, 'score': 0.9110707803992741, 'examples_seen': 52432, 'step': 1900, 'algorithm': 'activity_selector'}
I0216 21:55:44.098730 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0216 21:55:45.160033 132073186858496 run.py:729] Algo activity_selector step 1950 current loss 1.101616, current_train_items 53808.
I0216 21:55:45.292958 132073186858496 run.py:764] (val) algo activity_selector step 1950: {'selected': 0.9222011385199241, 'score': 0.9222011385199241, 'examples_seen': 53808, 'step': 1950, 'algorithm': 'activity_selector'}
I0216 21:55:45.293221 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0216 21:55:46.343266 132073186858496 run.py:729] Algo activity_selector step 2000 current loss 1.062581, current_train_items 55184.
I0216 21:55:46.476476 132073186858496 run.py:764] (val) algo activity_selector step 2000: {'selected': 0.9201520912547528, 'score': 0.9201520912547528, 'examples_seen': 55184, 'step': 2000, 'algorithm': 'activity_selector'}
I0216 21:55:46.476653 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0216 21:55:47.515980 132073186858496 run.py:729] Algo activity_selector step 2050 current loss 0.850534, current_train_items 56560.
I0216 21:55:47.650856 132073186858496 run.py:764] (val) algo activity_selector step 2050: {'selected': 0.9261477045908183, 'score': 0.9261477045908183, 'examples_seen': 56560, 'step': 2050, 'algorithm': 'activity_selector'}
I0216 21:55:47.651005 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0216 21:55:48.698975 132073186858496 run.py:729] Algo activity_selector step 2100 current loss 1.328454, current_train_items 57952.
I0216 21:55:48.832993 132073186858496 run.py:764] (val) algo activity_selector step 2100: {'selected': 0.8639053254437871, 'score': 0.8639053254437871, 'examples_seen': 57952, 'step': 2100, 'algorithm': 'activity_selector'}
I0216 21:55:48.833254 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.864, val scores are: activity_selector: 0.864
I0216 21:55:49.890678 132073186858496 run.py:729] Algo activity_selector step 2150 current loss 1.399924, current_train_items 59312.
I0216 21:55:50.015080 132073186858496 run.py:764] (val) algo activity_selector step 2150: {'selected': 0.9221556886227545, 'score': 0.9221556886227545, 'examples_seen': 59312, 'step': 2150, 'algorithm': 'activity_selector'}
I0216 21:55:50.015350 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0216 21:55:51.064773 132073186858496 run.py:729] Algo activity_selector step 2200 current loss 0.982790, current_train_items 60720.
I0216 21:55:51.197700 132073186858496 run.py:764] (val) algo activity_selector step 2200: {'selected': 0.9126984126984127, 'score': 0.9126984126984127, 'examples_seen': 60720, 'step': 2200, 'algorithm': 'activity_selector'}
I0216 21:55:51.197849 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0216 21:55:52.246668 132073186858496 run.py:729] Algo activity_selector step 2250 current loss 0.799911, current_train_items 62080.
I0216 21:55:52.378566 132073186858496 run.py:764] (val) algo activity_selector step 2250: {'selected': 0.895910780669145, 'score': 0.895910780669145, 'examples_seen': 62080, 'step': 2250, 'algorithm': 'activity_selector'}
I0216 21:55:52.378716 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0216 21:55:53.424195 132073186858496 run.py:729] Algo activity_selector step 2300 current loss 0.888622, current_train_items 63440.
I0216 21:55:53.557956 132073186858496 run.py:764] (val) algo activity_selector step 2300: {'selected': 0.9129593810444875, 'score': 0.9129593810444875, 'examples_seen': 63440, 'step': 2300, 'algorithm': 'activity_selector'}
I0216 21:55:53.558177 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0216 21:55:54.606883 132073186858496 run.py:729] Algo activity_selector step 2350 current loss 1.144947, current_train_items 64848.
I0216 21:55:54.741308 132073186858496 run.py:764] (val) algo activity_selector step 2350: {'selected': 0.9061946902654867, 'score': 0.9061946902654867, 'examples_seen': 64848, 'step': 2350, 'algorithm': 'activity_selector'}
I0216 21:55:54.741544 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0216 21:55:55.801887 132073186858496 run.py:729] Algo activity_selector step 2400 current loss 1.128029, current_train_items 66208.
I0216 21:55:55.934146 132073186858496 run.py:764] (val) algo activity_selector step 2400: {'selected': 0.9127272727272727, 'score': 0.9127272727272727, 'examples_seen': 66208, 'step': 2400, 'algorithm': 'activity_selector'}
I0216 21:55:55.934386 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0216 21:55:56.984258 132073186858496 run.py:729] Algo activity_selector step 2450 current loss 1.004520, current_train_items 67600.
I0216 21:55:57.118069 132073186858496 run.py:764] (val) algo activity_selector step 2450: {'selected': 0.9402697495183044, 'score': 0.9402697495183044, 'examples_seen': 67600, 'step': 2450, 'algorithm': 'activity_selector'}
I0216 21:55:57.118317 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0216 21:55:58.171994 132073186858496 run.py:729] Algo activity_selector step 2500 current loss 0.911423, current_train_items 68976.
I0216 21:55:58.307133 132073186858496 run.py:764] (val) algo activity_selector step 2500: {'selected': 0.9213051823416507, 'score': 0.9213051823416507, 'examples_seen': 68976, 'step': 2500, 'algorithm': 'activity_selector'}
I0216 21:55:58.307375 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0216 21:55:59.366595 132073186858496 run.py:729] Algo activity_selector step 2550 current loss 1.096667, current_train_items 70352.
I0216 21:55:59.501301 132073186858496 run.py:764] (val) algo activity_selector step 2550: {'selected': 0.8657243816254417, 'score': 0.8657243816254417, 'examples_seen': 70352, 'step': 2550, 'algorithm': 'activity_selector'}
I0216 21:55:59.501538 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.866, val scores are: activity_selector: 0.866
I0216 21:56:00.555099 132073186858496 run.py:729] Algo activity_selector step 2600 current loss 0.942728, current_train_items 71728.
I0216 21:56:00.686037 132073186858496 run.py:764] (val) algo activity_selector step 2600: {'selected': 0.89272030651341, 'score': 0.89272030651341, 'examples_seen': 71728, 'step': 2600, 'algorithm': 'activity_selector'}
I0216 21:56:00.686271 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0216 21:56:01.734873 132073186858496 run.py:729] Algo activity_selector step 2650 current loss 0.628805, current_train_items 73104.
I0216 21:56:01.868978 132073186858496 run.py:764] (val) algo activity_selector step 2650: {'selected': 0.9236947791164658, 'score': 0.9236947791164658, 'examples_seen': 73104, 'step': 2650, 'algorithm': 'activity_selector'}
I0216 21:56:01.869241 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.947, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0216 21:56:02.929695 132073186858496 run.py:729] Algo activity_selector step 2700 current loss 0.866926, current_train_items 74496.
I0216 21:56:03.063025 132073186858496 run.py:764] (val) algo activity_selector step 2700: {'selected': 0.9518518518518518, 'score': 0.9518518518518518, 'examples_seen': 74496, 'step': 2700, 'algorithm': 'activity_selector'}
I0216 21:56:03.063266 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.947, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0216 21:56:04.176689 132073186858496 run.py:729] Algo activity_selector step 2750 current loss 0.706349, current_train_items 75856.
I0216 21:56:04.310794 132073186858496 run.py:764] (val) algo activity_selector step 2750: {'selected': 0.8849557522123894, 'score': 0.8849557522123894, 'examples_seen': 75856, 'step': 2750, 'algorithm': 'activity_selector'}
I0216 21:56:04.311017 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0216 21:56:05.360853 132073186858496 run.py:729] Algo activity_selector step 2800 current loss 0.916992, current_train_items 77264.
I0216 21:56:05.494334 132073186858496 run.py:764] (val) algo activity_selector step 2800: {'selected': 0.9206963249516441, 'score': 0.9206963249516441, 'examples_seen': 77264, 'step': 2800, 'algorithm': 'activity_selector'}
I0216 21:56:05.494556 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0216 21:56:06.570538 132073186858496 run.py:729] Algo activity_selector step 2850 current loss 0.864239, current_train_items 78624.
I0216 21:56:06.688140 132073186858496 run.py:764] (val) algo activity_selector step 2850: {'selected': 0.9508840864440079, 'score': 0.9508840864440079, 'examples_seen': 78624, 'step': 2850, 'algorithm': 'activity_selector'}
I0216 21:56:06.688380 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0216 21:56:07.739849 132073186858496 run.py:729] Algo activity_selector step 2900 current loss 0.839558, current_train_items 80000.
I0216 21:56:07.872811 132073186858496 run.py:764] (val) algo activity_selector step 2900: {'selected': 0.9351145038167938, 'score': 0.9351145038167938, 'examples_seen': 80000, 'step': 2900, 'algorithm': 'activity_selector'}
I0216 21:56:07.873067 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0216 21:56:08.920560 132073186858496 run.py:729] Algo activity_selector step 2950 current loss 0.876055, current_train_items 81392.
I0216 21:56:09.067973 132073186858496 run.py:764] (val) algo activity_selector step 2950: {'selected': 0.9020332717190389, 'score': 0.9020332717190389, 'examples_seen': 81392, 'step': 2950, 'algorithm': 'activity_selector'}
I0216 21:56:09.068212 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0216 21:56:10.129078 132073186858496 run.py:729] Algo activity_selector step 3000 current loss 1.011597, current_train_items 82752.
I0216 21:56:10.260123 132073186858496 run.py:764] (val) algo activity_selector step 3000: {'selected': 0.8821428571428571, 'score': 0.8821428571428571, 'examples_seen': 82752, 'step': 3000, 'algorithm': 'activity_selector'}
I0216 21:56:10.260309 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.882, val scores are: activity_selector: 0.882
I0216 21:56:11.285564 132073186858496 run.py:729] Algo activity_selector step 3050 current loss 0.757309, current_train_items 84144.
I0216 21:56:11.434185 132073186858496 run.py:764] (val) algo activity_selector step 3050: {'selected': 0.9242718446601942, 'score': 0.9242718446601942, 'examples_seen': 84144, 'step': 3050, 'algorithm': 'activity_selector'}
I0216 21:56:11.434419 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0216 21:56:12.484544 132073186858496 run.py:729] Algo activity_selector step 3100 current loss 0.867438, current_train_items 85520.
I0216 21:56:12.619470 132073186858496 run.py:764] (val) algo activity_selector step 3100: {'selected': 0.942800788954635, 'score': 0.942800788954635, 'examples_seen': 85520, 'step': 3100, 'algorithm': 'activity_selector'}
I0216 21:56:12.619691 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0216 21:56:13.690393 132073186858496 run.py:729] Algo activity_selector step 3150 current loss 0.626377, current_train_items 86896.
I0216 21:56:13.820741 132073186858496 run.py:764] (val) algo activity_selector step 3150: {'selected': 0.9423076923076923, 'score': 0.9423076923076923, 'examples_seen': 86896, 'step': 3150, 'algorithm': 'activity_selector'}
I0216 21:56:13.820961 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0216 21:56:14.871069 132073186858496 run.py:729] Algo activity_selector step 3200 current loss 1.075126, current_train_items 88272.
I0216 21:56:15.004647 132073186858496 run.py:764] (val) algo activity_selector step 3200: {'selected': 0.9333333333333333, 'score': 0.9333333333333333, 'examples_seen': 88272, 'step': 3200, 'algorithm': 'activity_selector'}
I0216 21:56:15.004875 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0216 21:56:16.054759 132073186858496 run.py:729] Algo activity_selector step 3250 current loss 0.865747, current_train_items 89664.
I0216 21:56:16.190488 132073186858496 run.py:764] (val) algo activity_selector step 3250: {'selected': 0.9115384615384616, 'score': 0.9115384615384616, 'examples_seen': 89664, 'step': 3250, 'algorithm': 'activity_selector'}
I0216 21:56:16.190706 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0216 21:56:17.237675 132073186858496 run.py:729] Algo activity_selector step 3300 current loss 1.010985, current_train_items 91040.
I0216 21:56:17.386187 132073186858496 run.py:764] (val) algo activity_selector step 3300: {'selected': 0.9536679536679536, 'score': 0.9536679536679536, 'examples_seen': 91040, 'step': 3300, 'algorithm': 'activity_selector'}
I0216 21:56:17.386436 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.952, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0216 21:56:18.508219 132073186858496 run.py:729] Algo activity_selector step 3350 current loss 0.910792, current_train_items 92400.
I0216 21:56:18.642379 132073186858496 run.py:764] (val) algo activity_selector step 3350: {'selected': 0.9210526315789473, 'score': 0.9210526315789473, 'examples_seen': 92400, 'step': 3350, 'algorithm': 'activity_selector'}
I0216 21:56:18.642604 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.954, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0216 21:56:19.682652 132073186858496 run.py:729] Algo activity_selector step 3400 current loss 0.965330, current_train_items 93792.
I0216 21:56:19.829747 132073186858496 run.py:764] (val) algo activity_selector step 3400: {'selected': 0.9581749049429658, 'score': 0.9581749049429658, 'examples_seen': 93792, 'step': 3400, 'algorithm': 'activity_selector'}
I0216 21:56:19.829969 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.954, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0216 21:56:20.946017 132073186858496 run.py:729] Algo activity_selector step 3450 current loss 0.703266, current_train_items 95168.
I0216 21:56:21.080098 132073186858496 run.py:764] (val) algo activity_selector step 3450: {'selected': 0.9678714859437751, 'score': 0.9678714859437751, 'examples_seen': 95168, 'step': 3450, 'algorithm': 'activity_selector'}
I0216 21:56:21.080335 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.958, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0216 21:56:22.182039 132073186858496 run.py:729] Algo activity_selector step 3500 current loss 0.983869, current_train_items 96544.
I0216 21:56:22.328371 132073186858496 run.py:764] (val) algo activity_selector step 3500: {'selected': 0.9384615384615385, 'score': 0.9384615384615385, 'examples_seen': 96544, 'step': 3500, 'algorithm': 'activity_selector'}
I0216 21:56:22.328524 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.968, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0216 21:56:23.376525 132073186858496 run.py:729] Algo activity_selector step 3550 current loss 0.910711, current_train_items 97936.
I0216 21:56:23.512303 132073186858496 run.py:764] (val) algo activity_selector step 3550: {'selected': 0.8937007874015749, 'score': 0.8937007874015749, 'examples_seen': 97936, 'step': 3550, 'algorithm': 'activity_selector'}
I0216 21:56:23.512542 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.968, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0216 21:56:24.564216 132073186858496 run.py:729] Algo activity_selector step 3600 current loss 0.839383, current_train_items 99312.
I0216 21:56:24.712986 132073186858496 run.py:764] (val) algo activity_selector step 3600: {'selected': 0.9682539682539683, 'score': 0.9682539682539683, 'examples_seen': 99312, 'step': 3600, 'algorithm': 'activity_selector'}
I0216 21:56:24.713222 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.968, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0216 21:56:25.824978 132073186858496 run.py:729] Algo activity_selector step 3650 current loss 1.232242, current_train_items 100688.
I0216 21:56:25.959970 132073186858496 run.py:764] (val) algo activity_selector step 3650: {'selected': 0.9527410207939508, 'score': 0.9527410207939508, 'examples_seen': 100688, 'step': 3650, 'algorithm': 'activity_selector'}
I0216 21:56:25.960191 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.968, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0216 21:56:27.008966 132073186858496 run.py:729] Algo activity_selector step 3700 current loss 0.629646, current_train_items 102064.
I0216 21:56:27.142756 132073186858496 run.py:764] (val) algo activity_selector step 3700: {'selected': 0.9540918163672655, 'score': 0.9540918163672655, 'examples_seen': 102064, 'step': 3700, 'algorithm': 'activity_selector'}
I0216 21:56:27.142995 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.968, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0216 21:56:28.202216 132073186858496 run.py:729] Algo activity_selector step 3750 current loss 0.768999, current_train_items 103440.
I0216 21:56:28.335405 132073186858496 run.py:764] (val) algo activity_selector step 3750: {'selected': 0.9377431906614787, 'score': 0.9377431906614787, 'examples_seen': 103440, 'step': 3750, 'algorithm': 'activity_selector'}
I0216 21:56:28.335631 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.968, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0216 21:56:29.390700 132073186858496 run.py:729] Algo activity_selector step 3800 current loss 0.626261, current_train_items 104816.
I0216 21:56:29.522995 132073186858496 run.py:764] (val) algo activity_selector step 3800: {'selected': 0.9389312977099238, 'score': 0.9389312977099238, 'examples_seen': 104816, 'step': 3800, 'algorithm': 'activity_selector'}
I0216 21:56:29.523233 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.968, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0216 21:56:30.572368 132073186858496 run.py:729] Algo activity_selector step 3850 current loss 0.855187, current_train_items 106208.
I0216 21:56:30.705103 132073186858496 run.py:764] (val) algo activity_selector step 3850: {'selected': 0.9418604651162791, 'score': 0.9418604651162791, 'examples_seen': 106208, 'step': 3850, 'algorithm': 'activity_selector'}
I0216 21:56:30.705365 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.968, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0216 21:56:31.764957 132073186858496 run.py:729] Algo activity_selector step 3900 current loss 0.654273, current_train_items 107584.
I0216 21:56:31.899301 132073186858496 run.py:764] (val) algo activity_selector step 3900: {'selected': 0.9551656920077972, 'score': 0.9551656920077972, 'examples_seen': 107584, 'step': 3900, 'algorithm': 'activity_selector'}
I0216 21:56:31.899547 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.968, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0216 21:56:32.948569 132073186858496 run.py:729] Algo activity_selector step 3950 current loss 0.715695, current_train_items 108960.
I0216 21:56:33.081522 132073186858496 run.py:764] (val) algo activity_selector step 3950: {'selected': 0.9391634980988592, 'score': 0.9391634980988592, 'examples_seen': 108960, 'step': 3950, 'algorithm': 'activity_selector'}
I0216 21:56:33.081741 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.968, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0216 21:56:34.122730 132073186858496 run.py:729] Algo activity_selector step 4000 current loss 0.847899, current_train_items 110336.
I0216 21:56:34.272836 132073186858496 run.py:764] (val) algo activity_selector step 4000: {'selected': 0.8893203883495145, 'score': 0.8893203883495145, 'examples_seen': 110336, 'step': 4000, 'algorithm': 'activity_selector'}
I0216 21:56:34.273062 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.968, current avg val score is 0.889, val scores are: activity_selector: 0.889
I0216 21:56:35.377005 132073186858496 run.py:729] Algo activity_selector step 4050 current loss 0.729538, current_train_items 111712.
I0216 21:56:35.520913 132073186858496 run.py:764] (val) algo activity_selector step 4050: {'selected': 0.9552845528455285, 'score': 0.9552845528455285, 'examples_seen': 111712, 'step': 4050, 'algorithm': 'activity_selector'}
I0216 21:56:35.521142 132073186858496 run.py:785] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0216 21:56:36.632166 132073186858496 run.py:729] Algo activity_selector step 4100 current loss 0.634147, current_train_items 113088.
I0216 21:56:36.764619 132073186858496 run.py:764] (val) algo activity_selector step 4100: {'selected': 0.9591078066914499, 'score': 0.9591078066914499, 'examples_seen': 113088, 'step': 4100, 'algorithm': 'activity_selector'}
I0216 21:56:36.764845 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.955, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0216 21:56:37.873578 132073186858496 run.py:729] Algo activity_selector step 4150 current loss 0.764725, current_train_items 114480.
I0216 21:56:38.006464 132073186858496 run.py:764] (val) algo activity_selector step 4150: {'selected': 0.9394495412844036, 'score': 0.9394495412844036, 'examples_seen': 114480, 'step': 4150, 'algorithm': 'activity_selector'}
I0216 21:56:38.006690 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.959, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0216 21:56:39.054491 132073186858496 run.py:729] Algo activity_selector step 4200 current loss 1.075789, current_train_items 115856.
I0216 21:56:39.201375 132073186858496 run.py:764] (val) algo activity_selector step 4200: {'selected': 0.9533468559837728, 'score': 0.9533468559837728, 'examples_seen': 115856, 'step': 4200, 'algorithm': 'activity_selector'}
I0216 21:56:39.201630 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.959, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0216 21:56:40.242839 132073186858496 run.py:729] Algo activity_selector step 4250 current loss 0.751207, current_train_items 117216.
I0216 21:56:40.393111 132073186858496 run.py:764] (val) algo activity_selector step 4250: {'selected': 0.9277108433734939, 'score': 0.9277108433734939, 'examples_seen': 117216, 'step': 4250, 'algorithm': 'activity_selector'}
I0216 21:56:40.393372 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.959, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0216 21:56:41.450348 132073186858496 run.py:729] Algo activity_selector step 4300 current loss 0.896491, current_train_items 118624.
I0216 21:56:41.577289 132073186858496 run.py:764] (val) algo activity_selector step 4300: {'selected': 0.947935368043088, 'score': 0.947935368043088, 'examples_seen': 118624, 'step': 4300, 'algorithm': 'activity_selector'}
I0216 21:56:41.577543 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.959, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0216 21:56:42.636940 132073186858496 run.py:729] Algo activity_selector step 4350 current loss 0.573656, current_train_items 119984.
I0216 21:56:42.771435 132073186858496 run.py:764] (val) algo activity_selector step 4350: {'selected': 0.9371428571428573, 'score': 0.9371428571428573, 'examples_seen': 119984, 'step': 4350, 'algorithm': 'activity_selector'}
I0216 21:56:42.771682 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.959, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0216 21:56:43.807535 132073186858496 run.py:729] Algo activity_selector step 4400 current loss 0.802864, current_train_items 121360.
I0216 21:56:43.953925 132073186858496 run.py:764] (val) algo activity_selector step 4400: {'selected': 0.9416195856873822, 'score': 0.9416195856873822, 'examples_seen': 121360, 'step': 4400, 'algorithm': 'activity_selector'}
I0216 21:56:43.954177 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.959, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0216 21:56:45.009897 132073186858496 run.py:729] Algo activity_selector step 4450 current loss 0.970142, current_train_items 122752.
I0216 21:56:45.142678 132073186858496 run.py:764] (val) algo activity_selector step 4450: {'selected': 0.9453125, 'score': 0.9453125, 'examples_seen': 122752, 'step': 4450, 'algorithm': 'activity_selector'}
I0216 21:56:45.142919 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.959, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0216 21:56:46.189050 132073186858496 run.py:729] Algo activity_selector step 4500 current loss 0.683179, current_train_items 124128.
I0216 21:56:46.337064 132073186858496 run.py:764] (val) algo activity_selector step 4500: {'selected': 0.9604743083003954, 'score': 0.9604743083003954, 'examples_seen': 124128, 'step': 4500, 'algorithm': 'activity_selector'}
I0216 21:56:46.337309 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.959, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0216 21:56:47.453366 132073186858496 run.py:729] Algo activity_selector step 4550 current loss 0.883639, current_train_items 125504.
I0216 21:56:47.584754 132073186858496 run.py:764] (val) algo activity_selector step 4550: {'selected': 0.8910891089108912, 'score': 0.8910891089108912, 'examples_seen': 125504, 'step': 4550, 'algorithm': 'activity_selector'}
I0216 21:56:47.584976 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.960, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0216 21:56:48.620620 132073186858496 run.py:729] Algo activity_selector step 4600 current loss 0.707224, current_train_items 126880.
I0216 21:56:48.769308 132073186858496 run.py:764] (val) algo activity_selector step 4600: {'selected': 0.944, 'score': 0.944, 'examples_seen': 126880, 'step': 4600, 'algorithm': 'activity_selector'}
I0216 21:56:48.769528 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.960, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0216 21:56:49.833059 132073186858496 run.py:729] Algo activity_selector step 4650 current loss 0.639206, current_train_items 128272.
I0216 21:56:49.968454 132073186858496 run.py:764] (val) algo activity_selector step 4650: {'selected': 0.9606003752345216, 'score': 0.9606003752345216, 'examples_seen': 128272, 'step': 4650, 'algorithm': 'activity_selector'}
I0216 21:56:49.968675 132073186858496 run.py:785] Checkpointing best model, best avg val score was 0.960, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0216 21:56:51.063604 132073186858496 run.py:729] Algo activity_selector step 4700 current loss 0.685014, current_train_items 129632.
I0216 21:56:51.211534 132073186858496 run.py:764] (val) algo activity_selector step 4700: {'selected': 0.9522058823529412, 'score': 0.9522058823529412, 'examples_seen': 129632, 'step': 4700, 'algorithm': 'activity_selector'}
I0216 21:56:51.211757 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0216 21:56:52.247850 132073186858496 run.py:729] Algo activity_selector step 4750 current loss 1.203812, current_train_items 131024.
I0216 21:56:52.397433 132073186858496 run.py:764] (val) algo activity_selector step 4750: {'selected': 0.8924731182795699, 'score': 0.8924731182795699, 'examples_seen': 131024, 'step': 4750, 'algorithm': 'activity_selector'}
I0216 21:56:52.397660 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.892, val scores are: activity_selector: 0.892
I0216 21:56:53.458018 132073186858496 run.py:729] Algo activity_selector step 4800 current loss 0.806580, current_train_items 132400.
I0216 21:56:53.589667 132073186858496 run.py:764] (val) algo activity_selector step 4800: {'selected': 0.9467455621301776, 'score': 0.9467455621301776, 'examples_seen': 132400, 'step': 4800, 'algorithm': 'activity_selector'}
I0216 21:56:53.589891 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0216 21:56:54.648179 132073186858496 run.py:729] Algo activity_selector step 4850 current loss 0.778181, current_train_items 133760.
I0216 21:56:54.764062 132073186858496 run.py:764] (val) algo activity_selector step 4850: {'selected': 0.9097605893186005, 'score': 0.9097605893186005, 'examples_seen': 133760, 'step': 4850, 'algorithm': 'activity_selector'}
I0216 21:56:54.764306 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0216 21:56:55.806094 132073186858496 run.py:729] Algo activity_selector step 4900 current loss 0.635796, current_train_items 135168.
I0216 21:56:55.955442 132073186858496 run.py:764] (val) algo activity_selector step 4900: {'selected': 0.9360146252285192, 'score': 0.9360146252285192, 'examples_seen': 135168, 'step': 4900, 'algorithm': 'activity_selector'}
I0216 21:56:55.955663 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0216 21:56:57.016515 132073186858496 run.py:729] Algo activity_selector step 4950 current loss 0.749613, current_train_items 136528.
I0216 21:56:57.151388 132073186858496 run.py:764] (val) algo activity_selector step 4950: {'selected': 0.9587426326129665, 'score': 0.9587426326129665, 'examples_seen': 136528, 'step': 4950, 'algorithm': 'activity_selector'}
I0216 21:56:57.151611 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0216 21:56:58.191874 132073186858496 run.py:729] Algo activity_selector step 5000 current loss 0.571649, current_train_items 137920.
I0216 21:56:58.333230 132073186858496 run.py:764] (val) algo activity_selector step 5000: {'selected': 0.9365671641791045, 'score': 0.9365671641791045, 'examples_seen': 137920, 'step': 5000, 'algorithm': 'activity_selector'}
I0216 21:56:58.333416 132073186858496 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0216 21:56:58.333483 132073186858496 run.py:794] Restoring best model from checkpoint...
I0216 21:57:09.231794 132073186858496 run.py:809] (test) algo activity_selector : {'selected': 0.8706293706293705, 'score': 0.8706293706293705, 'examples_seen': 137920, 'step': 5001, 'algorithm': 'activity_selector'}
I0216 21:57:09.231972 132073186858496 run.py:811] Done!
