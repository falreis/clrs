I0810 14:05:05.047404 134355385849344 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0810 14:05:05.048139 134355385849344 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0810 14:05:05.279704 134355385849344 run.py:410] Model: f2 ['quickselect']
I0810 14:05:05.279810 134355385849344 run.py:412] algorithms ['quickselect']
I0810 14:05:05.279998 134355385849344 run.py:413] train_lengths [-1]
I0810 14:05:05.280036 134355385849344 run.py:414] train_batch_size 16
I0810 14:05:05.280132 134355385849344 run.py:415] val_batch_size 8
I0810 14:05:05.280164 134355385849344 run.py:416] test_batch_size 8
I0810 14:05:05.280193 134355385849344 run.py:417] chunked_training True
I0810 14:05:05.280313 134355385849344 run.py:418] chunk_length 16
I0810 14:05:05.280344 134355385849344 run.py:419] train_steps 10000
I0810 14:05:05.280374 134355385849344 run.py:420] eval_every 50
I0810 14:05:05.280405 134355385849344 run.py:421] test_every 500
I0810 14:05:05.280436 134355385849344 run.py:422] learning_rate 0.001
I0810 14:05:05.280539 134355385849344 run.py:423] grad_clip_max_norm 1.0
I0810 14:05:05.280570 134355385849344 run.py:424] dropout_prob 0.1
I0810 14:05:05.280602 134355385849344 run.py:425] hint_teacher_forcing 0.0
I0810 14:05:05.280632 134355385849344 run.py:426] hint_mode encoded_decoded
I0810 14:05:05.280738 134355385849344 run.py:427] hint_repred_mode hard_on_eval
I0810 14:05:05.280769 134355385849344 run.py:428] use_ln False
I0810 14:05:05.280797 134355385849344 run.py:429] use_lstm True
I0810 14:05:05.280825 134355385849344 run.py:430] nb_triplet_fts 8
I0810 14:05:05.280853 134355385849344 run.py:431] encoder_init xavier_on_scalars
I0810 14:05:05.280880 134355385849344 run.py:432] processor_type f2
I0810 14:05:05.280908 134355385849344 run.py:433] checkpoint_path CLRS30
I0810 14:05:05.280936 134355385849344 run.py:434] dataset_path CLRS30
I0810 14:05:05.280967 134355385849344 run.py:435] freeze_processor False
I0810 14:05:05.281015 134355385849344 run.py:436] reduction max
I0810 14:05:05.281063 134355385849344 run.py:437] activation elu
I0810 14:05:05.281098 134355385849344 run.py:438] restore_model 
I0810 14:05:05.281127 134355385849344 run.py:439] gated True
I0810 14:05:05.281158 134355385849344 run.py:440] gated_activation sigmoid
I0810 14:05:05.283855 134355385849344 run.py:466] Creating samplers for algo quickselect
I0810 14:05:05.283973 134355385849344 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0810 14:05:05.284647 134355385849344 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/quickselect_train/1.0.0
I0810 14:05:05.287918 134355385849344 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/quickselect_train/1.0.0
I0810 14:05:05.291139 134355385849344 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/quickselect_train/1.0.0.
I0810 14:05:05.345985 134355385849344 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split train, from CLRS30/CLRS30_v1.0.0/clrs_dataset/quickselect_train/1.0.0
W0810 14:05:05.367057 134355385849344 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x7a3188892de0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0810 14:05:05.458179 134355385849344 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0810 14:05:05.458801 134355385849344 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/quickselect_val/1.0.0
I0810 14:05:05.461770 134355385849344 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/quickselect_val/1.0.0
I0810 14:05:05.463860 134355385849344 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/quickselect_val/1.0.0.
I0810 14:05:05.500744 134355385849344 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split val, from CLRS30/CLRS30_v1.0.0/clrs_dataset/quickselect_val/1.0.0
I0810 14:05:05.592003 134355385849344 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0810 14:05:05.592573 134355385849344 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/quickselect_test/1.0.0
I0810 14:05:05.595221 134355385849344 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/quickselect_test/1.0.0
I0810 14:05:05.597615 134355385849344 reader.py:262] Creating a tf.data.Dataset reading 16 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/quickselect_test/1.0.0.
I0810 14:05:05.633414 134355385849344 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/quickselect_test/1.0.0
