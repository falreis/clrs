I0810 12:33:58.326698 137284937291264 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0810 12:33:58.327397 137284937291264 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0810 12:33:58.553424 137284937291264 run.py:410] Model: f2 ['graham_scan']
I0810 12:33:58.553532 137284937291264 run.py:412] algorithms ['graham_scan']
I0810 12:33:58.553718 137284937291264 run.py:413] train_lengths [-1]
I0810 12:33:58.553755 137284937291264 run.py:414] train_batch_size 16
I0810 12:33:58.553848 137284937291264 run.py:415] val_batch_size 8
I0810 12:33:58.553883 137284937291264 run.py:416] test_batch_size 8
I0810 12:33:58.553913 137284937291264 run.py:417] chunked_training True
I0810 12:33:58.554032 137284937291264 run.py:418] chunk_length 16
I0810 12:33:58.554063 137284937291264 run.py:419] train_steps 10000
I0810 12:33:58.554107 137284937291264 run.py:420] eval_every 50
I0810 12:33:58.554156 137284937291264 run.py:421] test_every 500
I0810 12:33:58.554189 137284937291264 run.py:422] learning_rate 0.001
I0810 12:33:58.554304 137284937291264 run.py:423] grad_clip_max_norm 1.0
I0810 12:33:58.554337 137284937291264 run.py:424] dropout_prob 0.1
I0810 12:33:58.554367 137284937291264 run.py:425] hint_teacher_forcing 0.0
I0810 12:33:58.554395 137284937291264 run.py:426] hint_mode encoded_decoded
I0810 12:33:58.554498 137284937291264 run.py:427] hint_repred_mode hard_on_eval
I0810 12:33:58.554534 137284937291264 run.py:428] use_ln False
I0810 12:33:58.554563 137284937291264 run.py:429] use_lstm True
I0810 12:33:58.554590 137284937291264 run.py:430] nb_triplet_fts 8
I0810 12:33:58.554618 137284937291264 run.py:431] encoder_init xavier_on_scalars
I0810 12:33:58.554645 137284937291264 run.py:432] processor_type f2
I0810 12:33:58.554675 137284937291264 run.py:433] checkpoint_path CLRS30
I0810 12:33:58.554703 137284937291264 run.py:434] dataset_path CLRS30
I0810 12:33:58.554731 137284937291264 run.py:435] freeze_processor False
I0810 12:33:58.554759 137284937291264 run.py:436] reduction max
I0810 12:33:58.554788 137284937291264 run.py:437] activation elu
I0810 12:33:58.554815 137284937291264 run.py:438] restore_model 
I0810 12:33:58.554843 137284937291264 run.py:439] gated True
I0810 12:33:58.554872 137284937291264 run.py:440] gated_activation sigmoid
I0810 12:33:58.557468 137284937291264 run.py:466] Creating samplers for algo graham_scan
I0810 12:33:58.557599 137284937291264 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0810 12:33:58.558251 137284937291264 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/graham_scan_train/1.0.0
I0810 12:33:58.561974 137284937291264 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/graham_scan_train/1.0.0
I0810 12:33:58.566488 137284937291264 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/graham_scan_train/1.0.0.
I0810 12:33:58.628018 137284937291264 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split train, from CLRS30/CLRS30_v1.0.0/clrs_dataset/graham_scan_train/1.0.0
W0810 12:33:58.649353 137284937291264 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x7cdb9f69ee80> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0810 12:33:58.745797 137284937291264 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0810 12:33:58.746402 137284937291264 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/graham_scan_val/1.0.0
I0810 12:33:58.749226 137284937291264 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/graham_scan_val/1.0.0
I0810 12:33:58.751114 137284937291264 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/graham_scan_val/1.0.0.
I0810 12:33:58.789420 137284937291264 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split val, from CLRS30/CLRS30_v1.0.0/clrs_dataset/graham_scan_val/1.0.0
I0810 12:33:58.885978 137284937291264 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0810 12:33:58.886543 137284937291264 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/graham_scan_test/1.0.0
I0810 12:33:58.889933 137284937291264 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/graham_scan_test/1.0.0
I0810 12:33:58.891970 137284937291264 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/graham_scan_test/1.0.0.
I0810 12:33:58.929863 137284937291264 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/graham_scan_test/1.0.0
