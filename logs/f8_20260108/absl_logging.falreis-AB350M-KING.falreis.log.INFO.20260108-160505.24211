I0108 16:05:07.673812 123859203114496 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0108 16:05:07.674476 123859203114496 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0108 16:05:07.924993 123859203114496 run.py:462] Model: f8 ['activity_selector']
I0108 16:05:07.925096 123859203114496 run.py:464] algorithms ['activity_selector']
I0108 16:05:07.925270 123859203114496 run.py:465] train_lengths ['4', '7', '11', '13', '16']
I0108 16:05:07.925308 123859203114496 run.py:466] train_batch_size 16
I0108 16:05:07.925408 123859203114496 run.py:467] val_batch_size 16
I0108 16:05:07.925440 123859203114496 run.py:468] test_batch_size 16
I0108 16:05:07.925469 123859203114496 run.py:469] chunked_training True
I0108 16:05:07.925587 123859203114496 run.py:470] chunk_length 16
I0108 16:05:07.925619 123859203114496 run.py:471] train_steps 10000
I0108 16:05:07.925649 123859203114496 run.py:472] eval_every 50
I0108 16:05:07.925679 123859203114496 run.py:473] test_every 500
I0108 16:05:07.925709 123859203114496 run.py:474] hidden_size 256
I0108 16:05:07.925740 123859203114496 run.py:475] nb_msg_passing_steps 1
I0108 16:05:07.925769 123859203114496 run.py:476] learning_rate 0.001
I0108 16:05:07.925857 123859203114496 run.py:477] grad_clip_max_norm 1.0
I0108 16:05:07.925887 123859203114496 run.py:478] dropout_prob 0.0
I0108 16:05:07.925919 123859203114496 run.py:479] hint_teacher_forcing 0.0
I0108 16:05:07.925948 123859203114496 run.py:480] hint_mode encoded_decoded
I0108 16:05:07.926045 123859203114496 run.py:481] hint_repred_mode soft
I0108 16:05:07.926074 123859203114496 run.py:482] use_ln True
I0108 16:05:07.926105 123859203114496 run.py:483] use_lstm True
I0108 16:05:07.926134 123859203114496 run.py:484] nb_triplet_fts 16
I0108 16:05:07.926162 123859203114496 run.py:485] encoder_init xavier_on_scalars
I0108 16:05:07.926190 123859203114496 run.py:486] processor_type f8
I0108 16:05:07.926219 123859203114496 run.py:487] checkpoint_path CLRS30
I0108 16:05:07.926251 123859203114496 run.py:488] dataset_path CLRS30
I0108 16:05:07.926280 123859203114496 run.py:489] freeze_processor False
I0108 16:05:07.926309 123859203114496 run.py:490] reduction min
I0108 16:05:07.926337 123859203114496 run.py:491] activation elu
I0108 16:05:07.926364 123859203114496 run.py:492] restore_model 
I0108 16:05:07.926401 123859203114496 run.py:493] gated True
I0108 16:05:07.926430 123859203114496 run.py:494] gated_activation tanh
I0108 16:05:07.926460 123859203114496 run.py:495] memory_type mha
I0108 16:05:07.926489 123859203114496 run.py:496] memory_size 16
I0108 16:05:07.929110 123859203114496 run.py:522] Creating samplers for algo activity_selector
W0108 16:05:07.929284 123859203114496 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0108 16:05:07.929554 123859203114496 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0108 16:05:08.141495 123859203114496 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0108 16:05:08.386530 123859203114496 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0108 16:05:08.687673 123859203114496 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0108 16:05:09.021165 123859203114496 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0108 16:05:09.404893 123859203114496 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0108 16:05:09.405190 123859203114496 samplers.py:124] Creating a dataset with 64 samples.
I0108 16:05:09.431156 123859203114496 run.py:306] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0108 16:05:09.431880 123859203114496 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0108 16:05:09.435425 123859203114496 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0108 16:05:09.438442 123859203114496 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0108 16:05:09.489887 123859203114496 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W0108 16:05:09.510783 123859203114496 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x70a5b33b54e0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0108 16:05:56.097674 123859203114496 run.py:748] Algo activity_selector step 0 current loss 5.450061, current_train_items 32.
I0108 16:06:04.325649 123859203114496 run.py:783] (val) algo activity_selector step 0: {'selected': 0.0, 'score': 0.0, 'examples_seen': 32, 'step': 0, 'algorithm': 'activity_selector'}
I0108 16:06:04.325816 123859203114496 run.py:804] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.000, val scores are: activity_selector: 0.000
I0108 16:07:20.591758 123859203114496 run.py:748] Algo activity_selector step 50 current loss 3.373217, current_train_items 1408.
I0108 16:07:20.775942 123859203114496 run.py:783] (val) algo activity_selector step 50: {'selected': 0.7042801556420234, 'score': 0.7042801556420234, 'examples_seen': 1408, 'step': 50, 'algorithm': 'activity_selector'}
I0108 16:07:20.776139 123859203114496 run.py:804] Checkpointing best model, best avg val score was 0.000, current avg val score is 0.704, val scores are: activity_selector: 0.704
I0108 16:07:22.295429 123859203114496 run.py:748] Algo activity_selector step 100 current loss 3.009344, current_train_items 2800.
I0108 16:07:22.524669 123859203114496 run.py:783] (val) algo activity_selector step 100: {'selected': 0.7128027681660899, 'score': 0.7128027681660899, 'examples_seen': 2800, 'step': 100, 'algorithm': 'activity_selector'}
I0108 16:07:22.524822 123859203114496 run.py:804] Checkpointing best model, best avg val score was 0.704, current avg val score is 0.713, val scores are: activity_selector: 0.713
I0108 16:07:24.081445 123859203114496 run.py:748] Algo activity_selector step 150 current loss 2.558305, current_train_items 4176.
I0108 16:07:24.286451 123859203114496 run.py:783] (val) algo activity_selector step 150: {'selected': 0.7652173913043478, 'score': 0.7652173913043478, 'examples_seen': 4176, 'step': 150, 'algorithm': 'activity_selector'}
I0108 16:07:24.286678 123859203114496 run.py:804] Checkpointing best model, best avg val score was 0.713, current avg val score is 0.765, val scores are: activity_selector: 0.765
I0108 16:07:25.832108 123859203114496 run.py:748] Algo activity_selector step 200 current loss 2.757295, current_train_items 5536.
I0108 16:07:26.032181 123859203114496 run.py:783] (val) algo activity_selector step 200: {'selected': 0.7863247863247862, 'score': 0.7863247863247862, 'examples_seen': 5536, 'step': 200, 'algorithm': 'activity_selector'}
I0108 16:07:26.032334 123859203114496 run.py:804] Checkpointing best model, best avg val score was 0.765, current avg val score is 0.786, val scores are: activity_selector: 0.786
I0108 16:07:27.572239 123859203114496 run.py:748] Algo activity_selector step 250 current loss 2.604872, current_train_items 6944.
I0108 16:07:27.780956 123859203114496 run.py:783] (val) algo activity_selector step 250: {'selected': 0.5970873786407768, 'score': 0.5970873786407768, 'examples_seen': 6944, 'step': 250, 'algorithm': 'activity_selector'}
I0108 16:07:27.781213 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.786, current avg val score is 0.597, val scores are: activity_selector: 0.597
I0108 16:07:29.205125 123859203114496 run.py:748] Algo activity_selector step 300 current loss 2.010639, current_train_items 8304.
I0108 16:07:29.383749 123859203114496 run.py:783] (val) algo activity_selector step 300: {'selected': 0.7272727272727273, 'score': 0.7272727272727273, 'examples_seen': 8304, 'step': 300, 'algorithm': 'activity_selector'}
I0108 16:07:29.383903 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.786, current avg val score is 0.727, val scores are: activity_selector: 0.727
I0108 16:07:30.737397 123859203114496 run.py:748] Algo activity_selector step 350 current loss 2.084400, current_train_items 9680.
I0108 16:07:30.964286 123859203114496 run.py:783] (val) algo activity_selector step 350: {'selected': 0.7636363636363636, 'score': 0.7636363636363636, 'examples_seen': 9680, 'step': 350, 'algorithm': 'activity_selector'}
I0108 16:07:30.964531 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.786, current avg val score is 0.764, val scores are: activity_selector: 0.764
I0108 16:07:32.373327 123859203114496 run.py:748] Algo activity_selector step 400 current loss 1.881999, current_train_items 11072.
I0108 16:07:32.556307 123859203114496 run.py:783] (val) algo activity_selector step 400: {'selected': 0.7602591792656588, 'score': 0.7602591792656588, 'examples_seen': 11072, 'step': 400, 'algorithm': 'activity_selector'}
I0108 16:07:32.556552 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.786, current avg val score is 0.760, val scores are: activity_selector: 0.760
I0108 16:07:33.961256 123859203114496 run.py:748] Algo activity_selector step 450 current loss 1.828345, current_train_items 12448.
I0108 16:07:34.163256 123859203114496 run.py:783] (val) algo activity_selector step 450: {'selected': 0.8902195608782435, 'score': 0.8902195608782435, 'examples_seen': 12448, 'step': 450, 'algorithm': 'activity_selector'}
I0108 16:07:34.163491 123859203114496 run.py:804] Checkpointing best model, best avg val score was 0.786, current avg val score is 0.890, val scores are: activity_selector: 0.890
I0108 16:07:35.740037 123859203114496 run.py:748] Algo activity_selector step 500 current loss 1.887625, current_train_items 13824.
I0108 16:07:35.920683 123859203114496 run.py:783] (val) algo activity_selector step 500: {'selected': 0.8647619047619047, 'score': 0.8647619047619047, 'examples_seen': 13824, 'step': 500, 'algorithm': 'activity_selector'}
I0108 16:07:35.920911 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.890, current avg val score is 0.865, val scores are: activity_selector: 0.865
I0108 16:07:37.332266 123859203114496 run.py:748] Algo activity_selector step 550 current loss 1.981013, current_train_items 15200.
I0108 16:07:37.512008 123859203114496 run.py:783] (val) algo activity_selector step 550: {'selected': 0.8165938864628821, 'score': 0.8165938864628821, 'examples_seen': 15200, 'step': 550, 'algorithm': 'activity_selector'}
I0108 16:07:37.512234 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.890, current avg val score is 0.817, val scores are: activity_selector: 0.817
I0108 16:07:38.916368 123859203114496 run.py:748] Algo activity_selector step 600 current loss 2.008790, current_train_items 16576.
I0108 16:07:39.119495 123859203114496 run.py:783] (val) algo activity_selector step 600: {'selected': 0.8285714285714286, 'score': 0.8285714285714286, 'examples_seen': 16576, 'step': 600, 'algorithm': 'activity_selector'}
I0108 16:07:39.119720 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.890, current avg val score is 0.829, val scores are: activity_selector: 0.829
I0108 16:07:40.525232 123859203114496 run.py:748] Algo activity_selector step 650 current loss 1.672943, current_train_items 17952.
I0108 16:07:40.709987 123859203114496 run.py:783] (val) algo activity_selector step 650: {'selected': 0.8952380952380952, 'score': 0.8952380952380952, 'examples_seen': 17952, 'step': 650, 'algorithm': 'activity_selector'}
I0108 16:07:40.710213 123859203114496 run.py:804] Checkpointing best model, best avg val score was 0.890, current avg val score is 0.895, val scores are: activity_selector: 0.895
I0108 16:07:42.281871 123859203114496 run.py:748] Algo activity_selector step 700 current loss 1.564888, current_train_items 19344.
I0108 16:07:42.467503 123859203114496 run.py:783] (val) algo activity_selector step 700: {'selected': 0.8489795918367347, 'score': 0.8489795918367347, 'examples_seen': 19344, 'step': 700, 'algorithm': 'activity_selector'}
I0108 16:07:42.467655 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.895, current avg val score is 0.849, val scores are: activity_selector: 0.849
I0108 16:07:43.856410 123859203114496 run.py:748] Algo activity_selector step 750 current loss 1.698520, current_train_items 20720.
I0108 16:07:44.058644 123859203114496 run.py:783] (val) algo activity_selector step 750: {'selected': 0.8553191489361701, 'score': 0.8553191489361701, 'examples_seen': 20720, 'step': 750, 'algorithm': 'activity_selector'}
I0108 16:07:44.058874 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.895, current avg val score is 0.855, val scores are: activity_selector: 0.855
I0108 16:07:45.448532 123859203114496 run.py:748] Algo activity_selector step 800 current loss 1.472394, current_train_items 22096.
I0108 16:07:45.649448 123859203114496 run.py:783] (val) algo activity_selector step 800: {'selected': 0.917910447761194, 'score': 0.917910447761194, 'examples_seen': 22096, 'step': 800, 'algorithm': 'activity_selector'}
I0108 16:07:45.649674 123859203114496 run.py:804] Checkpointing best model, best avg val score was 0.895, current avg val score is 0.918, val scores are: activity_selector: 0.918
I0108 16:07:47.194032 123859203114496 run.py:748] Algo activity_selector step 850 current loss 1.325047, current_train_items 23472.
I0108 16:07:47.406930 123859203114496 run.py:783] (val) algo activity_selector step 850: {'selected': 0.8792079207920792, 'score': 0.8792079207920792, 'examples_seen': 23472, 'step': 850, 'algorithm': 'activity_selector'}
I0108 16:07:47.407164 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.918, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0108 16:07:48.817397 123859203114496 run.py:748] Algo activity_selector step 900 current loss 1.606707, current_train_items 24848.
I0108 16:07:49.019915 123859203114496 run.py:783] (val) algo activity_selector step 900: {'selected': 0.9075975359342916, 'score': 0.9075975359342916, 'examples_seen': 24848, 'step': 900, 'algorithm': 'activity_selector'}
I0108 16:07:49.020143 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.918, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0108 16:07:50.413951 123859203114496 run.py:748] Algo activity_selector step 950 current loss 1.525602, current_train_items 26224.
I0108 16:07:50.618211 123859203114496 run.py:783] (val) algo activity_selector step 950: {'selected': 0.8434622467771639, 'score': 0.8434622467771639, 'examples_seen': 26224, 'step': 950, 'algorithm': 'activity_selector'}
I0108 16:07:50.618456 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.918, current avg val score is 0.843, val scores are: activity_selector: 0.843
I0108 16:07:52.027171 123859203114496 run.py:748] Algo activity_selector step 1000 current loss 1.625388, current_train_items 27616.
I0108 16:07:52.217329 123859203114496 run.py:783] (val) algo activity_selector step 1000: {'selected': 0.9077490774907749, 'score': 0.9077490774907749, 'examples_seen': 27616, 'step': 1000, 'algorithm': 'activity_selector'}
I0108 16:07:52.217573 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.918, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0108 16:07:53.633931 123859203114496 run.py:748] Algo activity_selector step 1050 current loss 1.545066, current_train_items 28992.
I0108 16:07:53.830109 123859203114496 run.py:783] (val) algo activity_selector step 1050: {'selected': 0.9018181818181819, 'score': 0.9018181818181819, 'examples_seen': 28992, 'step': 1050, 'algorithm': 'activity_selector'}
I0108 16:07:53.830332 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.918, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0108 16:07:55.224533 123859203114496 run.py:748] Algo activity_selector step 1100 current loss 1.588817, current_train_items 30368.
I0108 16:07:55.428754 123859203114496 run.py:783] (val) algo activity_selector step 1100: {'selected': 0.8647619047619047, 'score': 0.8647619047619047, 'examples_seen': 30368, 'step': 1100, 'algorithm': 'activity_selector'}
I0108 16:07:55.428979 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.918, current avg val score is 0.865, val scores are: activity_selector: 0.865
I0108 16:07:56.846407 123859203114496 run.py:748] Algo activity_selector step 1150 current loss 1.387343, current_train_items 31760.
I0108 16:07:57.026975 123859203114496 run.py:783] (val) algo activity_selector step 1150: {'selected': 0.8662674650698602, 'score': 0.8662674650698602, 'examples_seen': 31760, 'step': 1150, 'algorithm': 'activity_selector'}
I0108 16:07:57.027199 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.918, current avg val score is 0.866, val scores are: activity_selector: 0.866
I0108 16:07:58.410836 123859203114496 run.py:748] Algo activity_selector step 1200 current loss 1.177163, current_train_items 33120.
I0108 16:07:58.639599 123859203114496 run.py:783] (val) algo activity_selector step 1200: {'selected': 0.9168207024029574, 'score': 0.9168207024029574, 'examples_seen': 33120, 'step': 1200, 'algorithm': 'activity_selector'}
I0108 16:07:58.639844 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.918, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0108 16:08:00.055728 123859203114496 run.py:748] Algo activity_selector step 1250 current loss 1.349778, current_train_items 34496.
I0108 16:08:00.243664 123859203114496 run.py:783] (val) algo activity_selector step 1250: {'selected': 0.9257142857142858, 'score': 0.9257142857142858, 'examples_seen': 34496, 'step': 1250, 'algorithm': 'activity_selector'}
I0108 16:08:00.243888 123859203114496 run.py:804] Checkpointing best model, best avg val score was 0.918, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0108 16:08:01.800940 123859203114496 run.py:748] Algo activity_selector step 1300 current loss 1.487545, current_train_items 35888.
I0108 16:08:02.006532 123859203114496 run.py:783] (val) algo activity_selector step 1300: {'selected': 0.8527724665391969, 'score': 0.8527724665391969, 'examples_seen': 35888, 'step': 1300, 'algorithm': 'activity_selector'}
I0108 16:08:02.006762 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.926, current avg val score is 0.853, val scores are: activity_selector: 0.853
I0108 16:08:03.411269 123859203114496 run.py:748] Algo activity_selector step 1350 current loss 1.076524, current_train_items 37264.
I0108 16:08:03.612262 123859203114496 run.py:783] (val) algo activity_selector step 1350: {'selected': 0.9225092250922509, 'score': 0.9225092250922509, 'examples_seen': 37264, 'step': 1350, 'algorithm': 'activity_selector'}
I0108 16:08:03.612500 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.926, current avg val score is 0.923, val scores are: activity_selector: 0.923
I0108 16:08:05.011758 123859203114496 run.py:748] Algo activity_selector step 1400 current loss 1.235912, current_train_items 38640.
I0108 16:08:05.213786 123859203114496 run.py:783] (val) algo activity_selector step 1400: {'selected': 0.8986615678776291, 'score': 0.8986615678776291, 'examples_seen': 38640, 'step': 1400, 'algorithm': 'activity_selector'}
I0108 16:08:05.214024 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.926, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0108 16:08:06.607860 123859203114496 run.py:748] Algo activity_selector step 1450 current loss 1.000619, current_train_items 40016.
I0108 16:08:06.812166 123859203114496 run.py:783] (val) algo activity_selector step 1450: {'selected': 0.905587668593449, 'score': 0.905587668593449, 'examples_seen': 40016, 'step': 1450, 'algorithm': 'activity_selector'}
I0108 16:08:06.812404 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.926, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0108 16:08:08.217773 123859203114496 run.py:748] Algo activity_selector step 1500 current loss 1.676359, current_train_items 41408.
I0108 16:08:08.421257 123859203114496 run.py:783] (val) algo activity_selector step 1500: {'selected': 0.8910133843212237, 'score': 0.8910133843212237, 'examples_seen': 41408, 'step': 1500, 'algorithm': 'activity_selector'}
I0108 16:08:08.421524 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.926, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0108 16:08:09.820013 123859203114496 run.py:748] Algo activity_selector step 1550 current loss 1.279031, current_train_items 42768.
I0108 16:08:10.018995 123859203114496 run.py:783] (val) algo activity_selector step 1550: {'selected': 0.9166666666666667, 'score': 0.9166666666666667, 'examples_seen': 42768, 'step': 1550, 'algorithm': 'activity_selector'}
I0108 16:08:10.019222 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.926, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0108 16:08:11.412899 123859203114496 run.py:748] Algo activity_selector step 1600 current loss 1.262848, current_train_items 44160.
I0108 16:08:11.615258 123859203114496 run.py:783] (val) algo activity_selector step 1600: {'selected': 0.853658536585366, 'score': 0.853658536585366, 'examples_seen': 44160, 'step': 1600, 'algorithm': 'activity_selector'}
I0108 16:08:11.615499 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.926, current avg val score is 0.854, val scores are: activity_selector: 0.854
I0108 16:08:13.019587 123859203114496 run.py:748] Algo activity_selector step 1650 current loss 1.103918, current_train_items 45536.
I0108 16:08:13.222769 123859203114496 run.py:783] (val) algo activity_selector step 1650: {'selected': 0.8681541582150102, 'score': 0.8681541582150102, 'examples_seen': 45536, 'step': 1650, 'algorithm': 'activity_selector'}
I0108 16:08:13.222996 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.926, current avg val score is 0.868, val scores are: activity_selector: 0.868
I0108 16:08:14.620299 123859203114496 run.py:748] Algo activity_selector step 1700 current loss 0.968482, current_train_items 46896.
I0108 16:08:14.823617 123859203114496 run.py:783] (val) algo activity_selector step 1700: {'selected': 0.9254901960784314, 'score': 0.9254901960784314, 'examples_seen': 46896, 'step': 1700, 'algorithm': 'activity_selector'}
I0108 16:08:14.823844 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.926, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0108 16:08:16.219244 123859203114496 run.py:748] Algo activity_selector step 1750 current loss 1.276281, current_train_items 48304.
I0108 16:08:16.423436 123859203114496 run.py:783] (val) algo activity_selector step 1750: {'selected': 0.9288537549407114, 'score': 0.9288537549407114, 'examples_seen': 48304, 'step': 1750, 'algorithm': 'activity_selector'}
I0108 16:08:16.423666 123859203114496 run.py:804] Checkpointing best model, best avg val score was 0.926, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0108 16:08:17.989238 123859203114496 run.py:748] Algo activity_selector step 1800 current loss 1.089314, current_train_items 49664.
I0108 16:08:18.196357 123859203114496 run.py:783] (val) algo activity_selector step 1800: {'selected': 0.9037037037037038, 'score': 0.9037037037037038, 'examples_seen': 49664, 'step': 1800, 'algorithm': 'activity_selector'}
I0108 16:08:18.196604 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.929, current avg val score is 0.904, val scores are: activity_selector: 0.904
I0108 16:08:19.592776 123859203114496 run.py:748] Algo activity_selector step 1850 current loss 1.036842, current_train_items 51056.
I0108 16:08:19.796846 123859203114496 run.py:783] (val) algo activity_selector step 1850: {'selected': 0.8612612612612613, 'score': 0.8612612612612613, 'examples_seen': 51056, 'step': 1850, 'algorithm': 'activity_selector'}
I0108 16:08:19.797070 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.929, current avg val score is 0.861, val scores are: activity_selector: 0.861
I0108 16:08:21.191711 123859203114496 run.py:748] Algo activity_selector step 1900 current loss 0.940891, current_train_items 52432.
I0108 16:08:21.392493 123859203114496 run.py:783] (val) algo activity_selector step 1900: {'selected': 0.8779599271402548, 'score': 0.8779599271402548, 'examples_seen': 52432, 'step': 1900, 'algorithm': 'activity_selector'}
I0108 16:08:21.392687 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.929, current avg val score is 0.878, val scores are: activity_selector: 0.878
I0108 16:08:22.813694 123859203114496 run.py:748] Algo activity_selector step 1950 current loss 1.455122, current_train_items 53808.
I0108 16:08:22.995155 123859203114496 run.py:783] (val) algo activity_selector step 1950: {'selected': 0.8974358974358975, 'score': 0.8974358974358975, 'examples_seen': 53808, 'step': 1950, 'algorithm': 'activity_selector'}
I0108 16:08:22.995401 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.929, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0108 16:08:24.396839 123859203114496 run.py:748] Algo activity_selector step 2000 current loss 0.924522, current_train_items 55184.
I0108 16:08:24.595739 123859203114496 run.py:783] (val) algo activity_selector step 2000: {'selected': 0.9310344827586208, 'score': 0.9310344827586208, 'examples_seen': 55184, 'step': 2000, 'algorithm': 'activity_selector'}
I0108 16:08:24.595977 123859203114496 run.py:804] Checkpointing best model, best avg val score was 0.929, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0108 16:08:26.146819 123859203114496 run.py:748] Algo activity_selector step 2050 current loss 0.922476, current_train_items 56560.
I0108 16:08:26.359539 123859203114496 run.py:783] (val) algo activity_selector step 2050: {'selected': 0.8940269749518305, 'score': 0.8940269749518305, 'examples_seen': 56560, 'step': 2050, 'algorithm': 'activity_selector'}
I0108 16:08:26.359763 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.931, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0108 16:08:27.765555 123859203114496 run.py:748] Algo activity_selector step 2100 current loss 1.246249, current_train_items 57952.
I0108 16:08:27.973884 123859203114496 run.py:783] (val) algo activity_selector step 2100: {'selected': 0.7933884297520661, 'score': 0.7933884297520661, 'examples_seen': 57952, 'step': 2100, 'algorithm': 'activity_selector'}
I0108 16:08:27.974114 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.931, current avg val score is 0.793, val scores are: activity_selector: 0.793
I0108 16:08:29.372864 123859203114496 run.py:748] Algo activity_selector step 2150 current loss 1.224892, current_train_items 59312.
I0108 16:08:29.577564 123859203114496 run.py:783] (val) algo activity_selector step 2150: {'selected': 0.9416342412451362, 'score': 0.9416342412451362, 'examples_seen': 59312, 'step': 2150, 'algorithm': 'activity_selector'}
I0108 16:08:29.577791 123859203114496 run.py:804] Checkpointing best model, best avg val score was 0.931, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0108 16:08:31.149442 123859203114496 run.py:748] Algo activity_selector step 2200 current loss 1.007842, current_train_items 60720.
I0108 16:08:31.362325 123859203114496 run.py:783] (val) algo activity_selector step 2200: {'selected': 0.9414141414141415, 'score': 0.9414141414141415, 'examples_seen': 60720, 'step': 2200, 'algorithm': 'activity_selector'}
I0108 16:08:31.362563 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.942, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0108 16:08:32.747135 123859203114496 run.py:748] Algo activity_selector step 2250 current loss 1.053426, current_train_items 62080.
I0108 16:08:32.976853 123859203114496 run.py:783] (val) algo activity_selector step 2250: {'selected': 0.8735177865612648, 'score': 0.8735177865612648, 'examples_seen': 62080, 'step': 2250, 'algorithm': 'activity_selector'}
I0108 16:08:32.977077 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.942, current avg val score is 0.874, val scores are: activity_selector: 0.874
I0108 16:08:34.367876 123859203114496 run.py:748] Algo activity_selector step 2300 current loss 0.970881, current_train_items 63440.
I0108 16:08:34.580249 123859203114496 run.py:783] (val) algo activity_selector step 2300: {'selected': 0.9083969465648855, 'score': 0.9083969465648855, 'examples_seen': 63440, 'step': 2300, 'algorithm': 'activity_selector'}
I0108 16:08:34.580489 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.942, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0108 16:08:35.983967 123859203114496 run.py:748] Algo activity_selector step 2350 current loss 0.793612, current_train_items 64848.
I0108 16:08:36.189839 123859203114496 run.py:783] (val) algo activity_selector step 2350: {'selected': 0.9247706422018349, 'score': 0.9247706422018349, 'examples_seen': 64848, 'step': 2350, 'algorithm': 'activity_selector'}
I0108 16:08:36.190064 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.942, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0108 16:08:37.623258 123859203114496 run.py:748] Algo activity_selector step 2400 current loss 1.300013, current_train_items 66208.
I0108 16:08:37.806278 123859203114496 run.py:783] (val) algo activity_selector step 2400: {'selected': 0.8815533980582524, 'score': 0.8815533980582524, 'examples_seen': 66208, 'step': 2400, 'algorithm': 'activity_selector'}
I0108 16:08:37.806538 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.942, current avg val score is 0.882, val scores are: activity_selector: 0.882
I0108 16:08:39.220901 123859203114496 run.py:748] Algo activity_selector step 2450 current loss 1.335987, current_train_items 67600.
I0108 16:08:39.410732 123859203114496 run.py:783] (val) algo activity_selector step 2450: {'selected': 0.9616858237547893, 'score': 0.9616858237547893, 'examples_seen': 67600, 'step': 2450, 'algorithm': 'activity_selector'}
I0108 16:08:39.410956 123859203114496 run.py:804] Checkpointing best model, best avg val score was 0.942, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0108 16:08:40.983701 123859203114496 run.py:748] Algo activity_selector step 2500 current loss 0.938542, current_train_items 68976.
I0108 16:08:41.194229 123859203114496 run.py:783] (val) algo activity_selector step 2500: {'selected': 0.9262759924385634, 'score': 0.9262759924385634, 'examples_seen': 68976, 'step': 2500, 'algorithm': 'activity_selector'}
I0108 16:08:41.194505 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.962, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0108 16:08:42.603784 123859203114496 run.py:748] Algo activity_selector step 2550 current loss 0.791889, current_train_items 70352.
I0108 16:08:42.807713 123859203114496 run.py:783] (val) algo activity_selector step 2550: {'selected': 0.9288389513108615, 'score': 0.9288389513108615, 'examples_seen': 70352, 'step': 2550, 'algorithm': 'activity_selector'}
I0108 16:08:42.807962 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.962, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0108 16:08:44.199500 123859203114496 run.py:748] Algo activity_selector step 2600 current loss 0.802604, current_train_items 71728.
I0108 16:08:44.412492 123859203114496 run.py:783] (val) algo activity_selector step 2600: {'selected': 0.8994307400379506, 'score': 0.8994307400379506, 'examples_seen': 71728, 'step': 2600, 'algorithm': 'activity_selector'}
I0108 16:08:44.412725 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.962, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0108 16:08:45.837268 123859203114496 run.py:748] Algo activity_selector step 2650 current loss 0.755942, current_train_items 73104.
I0108 16:08:46.019175 123859203114496 run.py:783] (val) algo activity_selector step 2650: {'selected': 0.9341085271317829, 'score': 0.9341085271317829, 'examples_seen': 73104, 'step': 2650, 'algorithm': 'activity_selector'}
I0108 16:08:46.019413 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.962, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0108 16:08:47.427800 123859203114496 run.py:748] Algo activity_selector step 2700 current loss 0.962009, current_train_items 74496.
I0108 16:08:47.632017 123859203114496 run.py:783] (val) algo activity_selector step 2700: {'selected': 0.9453860640301319, 'score': 0.9453860640301319, 'examples_seen': 74496, 'step': 2700, 'algorithm': 'activity_selector'}
I0108 16:08:47.632242 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.962, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0108 16:08:49.030470 123859203114496 run.py:748] Algo activity_selector step 2750 current loss 0.967245, current_train_items 75856.
I0108 16:08:49.237893 123859203114496 run.py:783] (val) algo activity_selector step 2750: {'selected': 0.9361702127659574, 'score': 0.9361702127659574, 'examples_seen': 75856, 'step': 2750, 'algorithm': 'activity_selector'}
I0108 16:08:49.238114 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.962, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0108 16:08:50.640393 123859203114496 run.py:748] Algo activity_selector step 2800 current loss 0.998103, current_train_items 77264.
I0108 16:08:50.845047 123859203114496 run.py:783] (val) algo activity_selector step 2800: {'selected': 0.9179104477611939, 'score': 0.9179104477611939, 'examples_seen': 77264, 'step': 2800, 'algorithm': 'activity_selector'}
I0108 16:08:50.845278 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.962, current avg val score is 0.918, val scores are: activity_selector: 0.918
I0108 16:08:52.228995 123859203114496 run.py:748] Algo activity_selector step 2850 current loss 1.021652, current_train_items 78624.
I0108 16:08:52.458148 123859203114496 run.py:783] (val) algo activity_selector step 2850: {'selected': 0.958904109589041, 'score': 0.958904109589041, 'examples_seen': 78624, 'step': 2850, 'algorithm': 'activity_selector'}
I0108 16:08:52.458393 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.962, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0108 16:08:53.857123 123859203114496 run.py:748] Algo activity_selector step 2900 current loss 0.872829, current_train_items 80000.
I0108 16:08:54.062332 123859203114496 run.py:783] (val) algo activity_selector step 2900: {'selected': 0.87569573283859, 'score': 0.87569573283859, 'examples_seen': 80000, 'step': 2900, 'algorithm': 'activity_selector'}
I0108 16:08:54.062580 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.962, current avg val score is 0.876, val scores are: activity_selector: 0.876
I0108 16:08:55.454476 123859203114496 run.py:748] Algo activity_selector step 2950 current loss 0.935210, current_train_items 81392.
I0108 16:08:55.669383 123859203114496 run.py:783] (val) algo activity_selector step 2950: {'selected': 0.936902485659656, 'score': 0.936902485659656, 'examples_seen': 81392, 'step': 2950, 'algorithm': 'activity_selector'}
I0108 16:08:55.669629 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.962, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0108 16:08:57.083936 123859203114496 run.py:748] Algo activity_selector step 3000 current loss 0.955716, current_train_items 82752.
I0108 16:08:57.285497 123859203114496 run.py:783] (val) algo activity_selector step 3000: {'selected': 0.9338235294117647, 'score': 0.9338235294117647, 'examples_seen': 82752, 'step': 3000, 'algorithm': 'activity_selector'}
I0108 16:08:57.285721 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.962, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0108 16:08:58.659674 123859203114496 run.py:748] Algo activity_selector step 3050 current loss 0.977452, current_train_items 84144.
I0108 16:08:58.889113 123859203114496 run.py:783] (val) algo activity_selector step 3050: {'selected': 0.9047619047619048, 'score': 0.9047619047619048, 'examples_seen': 84144, 'step': 3050, 'algorithm': 'activity_selector'}
I0108 16:08:58.889340 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.962, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0108 16:09:00.288922 123859203114496 run.py:748] Algo activity_selector step 3100 current loss 1.057520, current_train_items 85520.
I0108 16:09:00.494829 123859203114496 run.py:783] (val) algo activity_selector step 3100: {'selected': 0.8862275449101795, 'score': 0.8862275449101795, 'examples_seen': 85520, 'step': 3100, 'algorithm': 'activity_selector'}
I0108 16:09:00.495056 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.962, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0108 16:09:01.909394 123859203114496 run.py:748] Algo activity_selector step 3150 current loss 0.624919, current_train_items 86896.
I0108 16:09:02.113107 123859203114496 run.py:783] (val) algo activity_selector step 3150: {'selected': 0.9673704414587333, 'score': 0.9673704414587333, 'examples_seen': 86896, 'step': 3150, 'algorithm': 'activity_selector'}
I0108 16:09:02.113327 123859203114496 run.py:804] Checkpointing best model, best avg val score was 0.962, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0108 16:09:03.681580 123859203114496 run.py:748] Algo activity_selector step 3200 current loss 1.066801, current_train_items 88272.
I0108 16:09:03.888725 123859203114496 run.py:783] (val) algo activity_selector step 3200: {'selected': 0.9120879120879121, 'score': 0.9120879120879121, 'examples_seen': 88272, 'step': 3200, 'algorithm': 'activity_selector'}
I0108 16:09:03.888951 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0108 16:09:05.288478 123859203114496 run.py:748] Algo activity_selector step 3250 current loss 0.996846, current_train_items 89664.
I0108 16:09:05.492591 123859203114496 run.py:783] (val) algo activity_selector step 3250: {'selected': 0.9359223300970874, 'score': 0.9359223300970874, 'examples_seen': 89664, 'step': 3250, 'algorithm': 'activity_selector'}
I0108 16:09:05.492813 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0108 16:09:06.898264 123859203114496 run.py:748] Algo activity_selector step 3300 current loss 0.880541, current_train_items 91040.
I0108 16:09:07.111437 123859203114496 run.py:783] (val) algo activity_selector step 3300: {'selected': 0.9193245778611632, 'score': 0.9193245778611632, 'examples_seen': 91040, 'step': 3300, 'algorithm': 'activity_selector'}
I0108 16:09:07.111658 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0108 16:09:08.510662 123859203114496 run.py:748] Algo activity_selector step 3350 current loss 0.931170, current_train_items 92400.
I0108 16:09:08.714801 123859203114496 run.py:783] (val) algo activity_selector step 3350: {'selected': 0.944337811900192, 'score': 0.944337811900192, 'examples_seen': 92400, 'step': 3350, 'algorithm': 'activity_selector'}
I0108 16:09:08.715027 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0108 16:09:10.137130 123859203114496 run.py:748] Algo activity_selector step 3400 current loss 1.542986, current_train_items 93792.
I0108 16:09:10.314824 123859203114496 run.py:783] (val) algo activity_selector step 3400: {'selected': 0.9644859813084112, 'score': 0.9644859813084112, 'examples_seen': 93792, 'step': 3400, 'algorithm': 'activity_selector'}
I0108 16:09:10.314976 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0108 16:09:11.714187 123859203114496 run.py:748] Algo activity_selector step 3450 current loss 0.815282, current_train_items 95168.
I0108 16:09:11.918040 123859203114496 run.py:783] (val) algo activity_selector step 3450: {'selected': 0.9315589353612168, 'score': 0.9315589353612168, 'examples_seen': 95168, 'step': 3450, 'algorithm': 'activity_selector'}
I0108 16:09:11.918264 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0108 16:09:13.318196 123859203114496 run.py:748] Algo activity_selector step 3500 current loss 0.865209, current_train_items 96544.
I0108 16:09:13.517605 123859203114496 run.py:783] (val) algo activity_selector step 3500: {'selected': 0.9302325581395348, 'score': 0.9302325581395348, 'examples_seen': 96544, 'step': 3500, 'algorithm': 'activity_selector'}
I0108 16:09:13.517860 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0108 16:09:14.909921 123859203114496 run.py:748] Algo activity_selector step 3550 current loss 0.966463, current_train_items 97936.
I0108 16:09:15.122797 123859203114496 run.py:783] (val) algo activity_selector step 3550: {'selected': 0.94921875, 'score': 0.94921875, 'examples_seen': 97936, 'step': 3550, 'algorithm': 'activity_selector'}
I0108 16:09:15.123027 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0108 16:09:16.536340 123859203114496 run.py:748] Algo activity_selector step 3600 current loss 0.835171, current_train_items 99312.
I0108 16:09:16.742950 123859203114496 run.py:783] (val) algo activity_selector step 3600: {'selected': 0.9227871939736346, 'score': 0.9227871939736346, 'examples_seen': 99312, 'step': 3600, 'algorithm': 'activity_selector'}
I0108 16:09:16.743173 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.923, val scores are: activity_selector: 0.923
I0108 16:09:18.166716 123859203114496 run.py:748] Algo activity_selector step 3650 current loss 1.260875, current_train_items 100688.
I0108 16:09:18.347838 123859203114496 run.py:783] (val) algo activity_selector step 3650: {'selected': 0.9343065693430657, 'score': 0.9343065693430657, 'examples_seen': 100688, 'step': 3650, 'algorithm': 'activity_selector'}
I0108 16:09:18.348087 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0108 16:09:19.747412 123859203114496 run.py:748] Algo activity_selector step 3700 current loss 0.690532, current_train_items 102064.
I0108 16:09:19.951213 123859203114496 run.py:783] (val) algo activity_selector step 3700: {'selected': 0.9248554913294796, 'score': 0.9248554913294796, 'examples_seen': 102064, 'step': 3700, 'algorithm': 'activity_selector'}
I0108 16:09:19.951496 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0108 16:09:21.361367 123859203114496 run.py:748] Algo activity_selector step 3750 current loss 0.877981, current_train_items 103440.
I0108 16:09:21.564345 123859203114496 run.py:783] (val) algo activity_selector step 3750: {'selected': 0.9090909090909091, 'score': 0.9090909090909091, 'examples_seen': 103440, 'step': 3750, 'algorithm': 'activity_selector'}
I0108 16:09:21.564586 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0108 16:09:22.966639 123859203114496 run.py:748] Algo activity_selector step 3800 current loss 0.707312, current_train_items 104816.
I0108 16:09:23.171572 123859203114496 run.py:783] (val) algo activity_selector step 3800: {'selected': 0.9477911646586346, 'score': 0.9477911646586346, 'examples_seen': 104816, 'step': 3800, 'algorithm': 'activity_selector'}
I0108 16:09:23.171796 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0108 16:09:24.587939 123859203114496 run.py:748] Algo activity_selector step 3850 current loss 0.815700, current_train_items 106208.
I0108 16:09:24.776458 123859203114496 run.py:783] (val) algo activity_selector step 3850: {'selected': 0.9363295880149812, 'score': 0.9363295880149812, 'examples_seen': 106208, 'step': 3850, 'algorithm': 'activity_selector'}
I0108 16:09:24.776684 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0108 16:09:26.186035 123859203114496 run.py:748] Algo activity_selector step 3900 current loss 0.759277, current_train_items 107584.
I0108 16:09:26.391031 123859203114496 run.py:783] (val) algo activity_selector step 3900: {'selected': 0.933852140077821, 'score': 0.933852140077821, 'examples_seen': 107584, 'step': 3900, 'algorithm': 'activity_selector'}
I0108 16:09:26.391257 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0108 16:09:27.817568 123859203114496 run.py:748] Algo activity_selector step 3950 current loss 0.759810, current_train_items 108960.
I0108 16:09:27.998562 123859203114496 run.py:783] (val) algo activity_selector step 3950: {'selected': 0.9560229445506692, 'score': 0.9560229445506692, 'examples_seen': 108960, 'step': 3950, 'algorithm': 'activity_selector'}
I0108 16:09:27.998787 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0108 16:09:29.398835 123859203114496 run.py:748] Algo activity_selector step 4000 current loss 0.747264, current_train_items 110336.
I0108 16:09:29.602684 123859203114496 run.py:783] (val) algo activity_selector step 4000: {'selected': 0.8977272727272727, 'score': 0.8977272727272727, 'examples_seen': 110336, 'step': 4000, 'algorithm': 'activity_selector'}
I0108 16:09:29.602918 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0108 16:09:31.014890 123859203114496 run.py:748] Algo activity_selector step 4050 current loss 0.774496, current_train_items 111712.
I0108 16:09:31.216284 123859203114496 run.py:783] (val) algo activity_selector step 4050: {'selected': 0.9536679536679536, 'score': 0.9536679536679536, 'examples_seen': 111712, 'step': 4050, 'algorithm': 'activity_selector'}
I0108 16:09:31.216476 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0108 16:09:32.610877 123859203114496 run.py:748] Algo activity_selector step 4100 current loss 0.754599, current_train_items 113088.
I0108 16:09:32.814047 123859203114496 run.py:783] (val) algo activity_selector step 4100: {'selected': 0.9363957597173145, 'score': 0.9363957597173145, 'examples_seen': 113088, 'step': 4100, 'algorithm': 'activity_selector'}
I0108 16:09:32.814274 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0108 16:09:34.214604 123859203114496 run.py:748] Algo activity_selector step 4150 current loss 0.710969, current_train_items 114480.
I0108 16:09:34.416221 123859203114496 run.py:783] (val) algo activity_selector step 4150: {'selected': 0.9227799227799228, 'score': 0.9227799227799228, 'examples_seen': 114480, 'step': 4150, 'algorithm': 'activity_selector'}
I0108 16:09:34.416461 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.923, val scores are: activity_selector: 0.923
I0108 16:09:35.812545 123859203114496 run.py:748] Algo activity_selector step 4200 current loss 1.347759, current_train_items 115856.
I0108 16:09:36.014088 123859203114496 run.py:783] (val) algo activity_selector step 4200: {'selected': 0.9598393574297188, 'score': 0.9598393574297188, 'examples_seen': 115856, 'step': 4200, 'algorithm': 'activity_selector'}
I0108 16:09:36.014248 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0108 16:09:37.405883 123859203114496 run.py:748] Algo activity_selector step 4250 current loss 0.804230, current_train_items 117216.
I0108 16:09:37.613924 123859203114496 run.py:783] (val) algo activity_selector step 4250: {'selected': 0.9398496240601503, 'score': 0.9398496240601503, 'examples_seen': 117216, 'step': 4250, 'algorithm': 'activity_selector'}
I0108 16:09:37.614150 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0108 16:09:39.020534 123859203114496 run.py:748] Algo activity_selector step 4300 current loss 0.834786, current_train_items 118624.
I0108 16:09:39.215274 123859203114496 run.py:783] (val) algo activity_selector step 4300: {'selected': 0.9342806394316163, 'score': 0.9342806394316163, 'examples_seen': 118624, 'step': 4300, 'algorithm': 'activity_selector'}
I0108 16:09:39.215517 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0108 16:09:40.653307 123859203114496 run.py:748] Algo activity_selector step 4350 current loss 0.622931, current_train_items 119984.
I0108 16:09:40.832024 123859203114496 run.py:783] (val) algo activity_selector step 4350: {'selected': 0.9201520912547528, 'score': 0.9201520912547528, 'examples_seen': 119984, 'step': 4350, 'algorithm': 'activity_selector'}
I0108 16:09:40.832253 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0108 16:09:42.251913 123859203114496 run.py:748] Algo activity_selector step 4400 current loss 0.827944, current_train_items 121360.
I0108 16:09:42.439598 123859203114496 run.py:783] (val) algo activity_selector step 4400: {'selected': 0.9543726235741445, 'score': 0.9543726235741445, 'examples_seen': 121360, 'step': 4400, 'algorithm': 'activity_selector'}
I0108 16:09:42.439895 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0108 16:09:43.841090 123859203114496 run.py:748] Algo activity_selector step 4450 current loss 0.828219, current_train_items 122752.
I0108 16:09:44.046215 123859203114496 run.py:783] (val) algo activity_selector step 4450: {'selected': 0.9418604651162791, 'score': 0.9418604651162791, 'examples_seen': 122752, 'step': 4450, 'algorithm': 'activity_selector'}
I0108 16:09:44.046470 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0108 16:09:45.455553 123859203114496 run.py:748] Algo activity_selector step 4500 current loss 0.776396, current_train_items 124128.
I0108 16:09:45.660203 123859203114496 run.py:783] (val) algo activity_selector step 4500: {'selected': 0.9651162790697674, 'score': 0.9651162790697674, 'examples_seen': 124128, 'step': 4500, 'algorithm': 'activity_selector'}
I0108 16:09:45.660443 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0108 16:09:47.058381 123859203114496 run.py:748] Algo activity_selector step 4550 current loss 0.791813, current_train_items 125504.
I0108 16:09:47.261843 123859203114496 run.py:783] (val) algo activity_selector step 4550: {'selected': 0.9215686274509804, 'score': 0.9215686274509804, 'examples_seen': 125504, 'step': 4550, 'algorithm': 'activity_selector'}
I0108 16:09:47.262068 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0108 16:09:48.663858 123859203114496 run.py:748] Algo activity_selector step 4600 current loss 1.196947, current_train_items 126880.
I0108 16:09:48.868094 123859203114496 run.py:783] (val) algo activity_selector step 4600: {'selected': 0.9038112522686026, 'score': 0.9038112522686026, 'examples_seen': 126880, 'step': 4600, 'algorithm': 'activity_selector'}
I0108 16:09:48.868323 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.904, val scores are: activity_selector: 0.904
I0108 16:09:50.278622 123859203114496 run.py:748] Algo activity_selector step 4650 current loss 0.607584, current_train_items 128272.
I0108 16:09:50.481098 123859203114496 run.py:783] (val) algo activity_selector step 4650: {'selected': 0.9712092130518234, 'score': 0.9712092130518234, 'examples_seen': 128272, 'step': 4650, 'algorithm': 'activity_selector'}
I0108 16:09:50.481329 123859203114496 run.py:804] Checkpointing best model, best avg val score was 0.967, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0108 16:09:52.048622 123859203114496 run.py:748] Algo activity_selector step 4700 current loss 0.726562, current_train_items 129632.
I0108 16:09:52.255115 123859203114496 run.py:783] (val) algo activity_selector step 4700: {'selected': 0.9490909090909091, 'score': 0.9490909090909091, 'examples_seen': 129632, 'step': 4700, 'algorithm': 'activity_selector'}
I0108 16:09:52.255337 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0108 16:09:53.651576 123859203114496 run.py:748] Algo activity_selector step 4750 current loss 1.140752, current_train_items 131024.
I0108 16:09:53.863251 123859203114496 run.py:783] (val) algo activity_selector step 4750: {'selected': 0.9440298507462687, 'score': 0.9440298507462687, 'examples_seen': 131024, 'step': 4750, 'algorithm': 'activity_selector'}
I0108 16:09:53.863494 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0108 16:09:55.304650 123859203114496 run.py:748] Algo activity_selector step 4800 current loss 0.737828, current_train_items 132400.
I0108 16:09:55.476709 123859203114496 run.py:783] (val) algo activity_selector step 4800: {'selected': 0.9549902152641878, 'score': 0.9549902152641878, 'examples_seen': 132400, 'step': 4800, 'algorithm': 'activity_selector'}
I0108 16:09:55.476933 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0108 16:09:56.870361 123859203114496 run.py:748] Algo activity_selector step 4850 current loss 0.788666, current_train_items 133760.
I0108 16:09:57.082010 123859203114496 run.py:783] (val) algo activity_selector step 4850: {'selected': 0.9250457038391224, 'score': 0.9250457038391224, 'examples_seen': 133760, 'step': 4850, 'algorithm': 'activity_selector'}
I0108 16:09:57.082235 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0108 16:09:58.486831 123859203114496 run.py:748] Algo activity_selector step 4900 current loss 0.767003, current_train_items 135168.
I0108 16:09:58.689986 123859203114496 run.py:783] (val) algo activity_selector step 4900: {'selected': 0.969258589511754, 'score': 0.969258589511754, 'examples_seen': 135168, 'step': 4900, 'algorithm': 'activity_selector'}
I0108 16:09:58.690212 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0108 16:10:00.100216 123859203114496 run.py:748] Algo activity_selector step 4950 current loss 0.778450, current_train_items 136528.
I0108 16:10:00.304096 123859203114496 run.py:783] (val) algo activity_selector step 4950: {'selected': 0.9338677354709419, 'score': 0.9338677354709419, 'examples_seen': 136528, 'step': 4950, 'algorithm': 'activity_selector'}
I0108 16:10:00.304332 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0108 16:10:01.703956 123859203114496 run.py:748] Algo activity_selector step 5000 current loss 0.698159, current_train_items 137920.
I0108 16:10:01.908584 123859203114496 run.py:783] (val) algo activity_selector step 5000: {'selected': 0.9194139194139194, 'score': 0.9194139194139194, 'examples_seen': 137920, 'step': 5000, 'algorithm': 'activity_selector'}
I0108 16:10:01.908812 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0108 16:10:03.311425 123859203114496 run.py:748] Algo activity_selector step 5050 current loss 0.686447, current_train_items 139296.
I0108 16:10:03.517204 123859203114496 run.py:783] (val) algo activity_selector step 5050: {'selected': 0.9504132231404958, 'score': 0.9504132231404958, 'examples_seen': 139296, 'step': 5050, 'algorithm': 'activity_selector'}
I0108 16:10:03.517452 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0108 16:10:04.926629 123859203114496 run.py:748] Algo activity_selector step 5100 current loss 0.894830, current_train_items 140656.
I0108 16:10:05.131288 123859203114496 run.py:783] (val) algo activity_selector step 5100: {'selected': 0.9386973180076628, 'score': 0.9386973180076628, 'examples_seen': 140656, 'step': 5100, 'algorithm': 'activity_selector'}
I0108 16:10:05.131544 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0108 16:10:06.607970 123859203114496 run.py:748] Algo activity_selector step 5150 current loss 1.279452, current_train_items 142048.
I0108 16:10:06.805300 123859203114496 run.py:783] (val) algo activity_selector step 5150: {'selected': 0.8966942148760331, 'score': 0.8966942148760331, 'examples_seen': 142048, 'step': 5150, 'algorithm': 'activity_selector'}
I0108 16:10:06.805553 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0108 16:10:08.206207 123859203114496 run.py:748] Algo activity_selector step 5200 current loss 0.667260, current_train_items 143424.
I0108 16:10:08.407828 123859203114496 run.py:783] (val) algo activity_selector step 5200: {'selected': 0.9603024574669187, 'score': 0.9603024574669187, 'examples_seen': 143424, 'step': 5200, 'algorithm': 'activity_selector'}
I0108 16:10:08.408055 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0108 16:10:09.835178 123859203114496 run.py:748] Algo activity_selector step 5250 current loss 0.800561, current_train_items 144816.
I0108 16:10:10.038666 123859203114496 run.py:783] (val) algo activity_selector step 5250: {'selected': 0.9360902255639098, 'score': 0.9360902255639098, 'examples_seen': 144816, 'step': 5250, 'algorithm': 'activity_selector'}
I0108 16:10:10.038899 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0108 16:10:11.430248 123859203114496 run.py:748] Algo activity_selector step 5300 current loss 0.813235, current_train_items 146176.
I0108 16:10:11.659271 123859203114496 run.py:783] (val) algo activity_selector step 5300: {'selected': 0.9540229885057471, 'score': 0.9540229885057471, 'examples_seen': 146176, 'step': 5300, 'algorithm': 'activity_selector'}
I0108 16:10:11.659514 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0108 16:10:13.087104 123859203114496 run.py:748] Algo activity_selector step 5350 current loss 0.766961, current_train_items 147584.
I0108 16:10:13.280348 123859203114496 run.py:783] (val) algo activity_selector step 5350: {'selected': 0.9566854990583805, 'score': 0.9566854990583805, 'examples_seen': 147584, 'step': 5350, 'algorithm': 'activity_selector'}
I0108 16:10:13.280617 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0108 16:10:14.718577 123859203114496 run.py:748] Algo activity_selector step 5400 current loss 0.729240, current_train_items 148944.
I0108 16:10:14.909314 123859203114496 run.py:783] (val) algo activity_selector step 5400: {'selected': 0.9651162790697674, 'score': 0.9651162790697674, 'examples_seen': 148944, 'step': 5400, 'algorithm': 'activity_selector'}
I0108 16:10:14.909586 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0108 16:10:16.318945 123859203114496 run.py:748] Algo activity_selector step 5450 current loss 0.696752, current_train_items 150304.
I0108 16:10:16.521548 123859203114496 run.py:783] (val) algo activity_selector step 5450: {'selected': 0.9148148148148147, 'score': 0.9148148148148147, 'examples_seen': 150304, 'step': 5450, 'algorithm': 'activity_selector'}
I0108 16:10:16.521772 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0108 16:10:17.930001 123859203114496 run.py:748] Algo activity_selector step 5500 current loss 0.895332, current_train_items 151712.
I0108 16:10:18.134227 123859203114496 run.py:783] (val) algo activity_selector step 5500: {'selected': 0.9377431906614787, 'score': 0.9377431906614787, 'examples_seen': 151712, 'step': 5500, 'algorithm': 'activity_selector'}
I0108 16:10:18.134472 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0108 16:10:19.553309 123859203114496 run.py:748] Algo activity_selector step 5550 current loss 0.850473, current_train_items 153072.
I0108 16:10:19.757723 123859203114496 run.py:783] (val) algo activity_selector step 5550: {'selected': 0.9590017825311942, 'score': 0.9590017825311942, 'examples_seen': 153072, 'step': 5550, 'algorithm': 'activity_selector'}
I0108 16:10:19.757949 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0108 16:10:21.142733 123859203114496 run.py:748] Algo activity_selector step 5600 current loss 0.547997, current_train_items 154464.
I0108 16:10:21.370708 123859203114496 run.py:783] (val) algo activity_selector step 5600: {'selected': 0.9503239740820735, 'score': 0.9503239740820735, 'examples_seen': 154464, 'step': 5600, 'algorithm': 'activity_selector'}
I0108 16:10:21.370950 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0108 16:10:22.794063 123859203114496 run.py:748] Algo activity_selector step 5650 current loss 0.589841, current_train_items 155840.
I0108 16:10:22.983716 123859203114496 run.py:783] (val) algo activity_selector step 5650: {'selected': 0.9502762430939227, 'score': 0.9502762430939227, 'examples_seen': 155840, 'step': 5650, 'algorithm': 'activity_selector'}
I0108 16:10:22.983967 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0108 16:10:24.402472 123859203114496 run.py:748] Algo activity_selector step 5700 current loss 0.607145, current_train_items 157216.
I0108 16:10:24.606185 123859203114496 run.py:783] (val) algo activity_selector step 5700: {'selected': 0.9188034188034186, 'score': 0.9188034188034186, 'examples_seen': 157216, 'step': 5700, 'algorithm': 'activity_selector'}
I0108 16:10:24.606421 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0108 16:10:26.007851 123859203114496 run.py:748] Algo activity_selector step 5750 current loss 1.120600, current_train_items 158592.
I0108 16:10:26.223348 123859203114496 run.py:783] (val) algo activity_selector step 5750: {'selected': 0.9539748953974895, 'score': 0.9539748953974895, 'examples_seen': 158592, 'step': 5750, 'algorithm': 'activity_selector'}
I0108 16:10:26.223591 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0108 16:10:27.641814 123859203114496 run.py:748] Algo activity_selector step 5800 current loss 0.798208, current_train_items 159968.
I0108 16:10:27.844113 123859203114496 run.py:783] (val) algo activity_selector step 5800: {'selected': 0.9405204460966543, 'score': 0.9405204460966543, 'examples_seen': 159968, 'step': 5800, 'algorithm': 'activity_selector'}
I0108 16:10:27.844336 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0108 16:10:29.269731 123859203114496 run.py:748] Algo activity_selector step 5850 current loss 0.817975, current_train_items 161360.
I0108 16:10:29.473811 123859203114496 run.py:783] (val) algo activity_selector step 5850: {'selected': 0.9409368635437881, 'score': 0.9409368635437881, 'examples_seen': 161360, 'step': 5850, 'algorithm': 'activity_selector'}
I0108 16:10:29.474042 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0108 16:10:30.897134 123859203114496 run.py:748] Algo activity_selector step 5900 current loss 0.778968, current_train_items 162720.
I0108 16:10:31.087438 123859203114496 run.py:783] (val) algo activity_selector step 5900: {'selected': 0.9213483146067417, 'score': 0.9213483146067417, 'examples_seen': 162720, 'step': 5900, 'algorithm': 'activity_selector'}
I0108 16:10:31.087589 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0108 16:10:32.487328 123859203114496 run.py:748] Algo activity_selector step 5950 current loss 0.536824, current_train_items 164112.
I0108 16:10:32.691081 123859203114496 run.py:783] (val) algo activity_selector step 5950: {'selected': 0.9330708661417322, 'score': 0.9330708661417322, 'examples_seen': 164112, 'step': 5950, 'algorithm': 'activity_selector'}
I0108 16:10:32.691314 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0108 16:10:34.110965 123859203114496 run.py:748] Algo activity_selector step 6000 current loss 0.661863, current_train_items 165488.
I0108 16:10:34.314056 123859203114496 run.py:783] (val) algo activity_selector step 6000: {'selected': 0.9608540925266904, 'score': 0.9608540925266904, 'examples_seen': 165488, 'step': 6000, 'algorithm': 'activity_selector'}
I0108 16:10:34.314280 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0108 16:10:35.723653 123859203114496 run.py:748] Algo activity_selector step 6050 current loss 0.658402, current_train_items 166864.
I0108 16:10:35.928005 123859203114496 run.py:783] (val) algo activity_selector step 6050: {'selected': 0.9362549800796813, 'score': 0.9362549800796813, 'examples_seen': 166864, 'step': 6050, 'algorithm': 'activity_selector'}
I0108 16:10:35.928245 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0108 16:10:37.336853 123859203114496 run.py:748] Algo activity_selector step 6100 current loss 1.059417, current_train_items 168256.
I0108 16:10:37.540655 123859203114496 run.py:783] (val) algo activity_selector step 6100: {'selected': 0.9596774193548387, 'score': 0.9596774193548387, 'examples_seen': 168256, 'step': 6100, 'algorithm': 'activity_selector'}
I0108 16:10:37.540884 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0108 16:10:38.960882 123859203114496 run.py:748] Algo activity_selector step 6150 current loss 0.819294, current_train_items 169616.
I0108 16:10:39.165124 123859203114496 run.py:783] (val) algo activity_selector step 6150: {'selected': 0.9355509355509355, 'score': 0.9355509355509355, 'examples_seen': 169616, 'step': 6150, 'algorithm': 'activity_selector'}
I0108 16:10:39.165354 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0108 16:10:40.575879 123859203114496 run.py:748] Algo activity_selector step 6200 current loss 0.691641, current_train_items 171008.
I0108 16:10:40.778089 123859203114496 run.py:783] (val) algo activity_selector step 6200: {'selected': 0.9218106995884775, 'score': 0.9218106995884775, 'examples_seen': 171008, 'step': 6200, 'algorithm': 'activity_selector'}
I0108 16:10:40.778315 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0108 16:10:42.194294 123859203114496 run.py:748] Algo activity_selector step 6250 current loss 0.725023, current_train_items 172384.
I0108 16:10:42.391440 123859203114496 run.py:783] (val) algo activity_selector step 6250: {'selected': 0.9394495412844036, 'score': 0.9394495412844036, 'examples_seen': 172384, 'step': 6250, 'algorithm': 'activity_selector'}
I0108 16:10:42.391665 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0108 16:10:43.811791 123859203114496 run.py:748] Algo activity_selector step 6300 current loss 0.797463, current_train_items 173760.
I0108 16:10:44.015795 123859203114496 run.py:783] (val) algo activity_selector step 6300: {'selected': 0.9067164179104477, 'score': 0.9067164179104477, 'examples_seen': 173760, 'step': 6300, 'algorithm': 'activity_selector'}
I0108 16:10:44.016020 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0108 16:10:45.433582 123859203114496 run.py:748] Algo activity_selector step 6350 current loss 0.640382, current_train_items 175136.
I0108 16:10:45.634723 123859203114496 run.py:783] (val) algo activity_selector step 6350: {'selected': 0.9278350515463918, 'score': 0.9278350515463918, 'examples_seen': 175136, 'step': 6350, 'algorithm': 'activity_selector'}
I0108 16:10:45.634887 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0108 16:10:47.032064 123859203114496 run.py:748] Algo activity_selector step 6400 current loss 0.852292, current_train_items 176528.
I0108 16:10:47.236567 123859203114496 run.py:783] (val) algo activity_selector step 6400: {'selected': 0.8787878787878788, 'score': 0.8787878787878788, 'examples_seen': 176528, 'step': 6400, 'algorithm': 'activity_selector'}
I0108 16:10:47.236790 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0108 16:10:48.661644 123859203114496 run.py:748] Algo activity_selector step 6450 current loss 0.515361, current_train_items 177904.
I0108 16:10:48.866169 123859203114496 run.py:783] (val) algo activity_selector step 6450: {'selected': 0.9455909943714821, 'score': 0.9455909943714821, 'examples_seen': 177904, 'step': 6450, 'algorithm': 'activity_selector'}
I0108 16:10:48.866408 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0108 16:10:50.271034 123859203114496 run.py:748] Algo activity_selector step 6500 current loss 0.459788, current_train_items 179264.
I0108 16:10:50.487026 123859203114496 run.py:783] (val) algo activity_selector step 6500: {'selected': 0.9585585585585585, 'score': 0.9585585585585585, 'examples_seen': 179264, 'step': 6500, 'algorithm': 'activity_selector'}
I0108 16:10:50.487268 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0108 16:10:51.898156 123859203114496 run.py:748] Algo activity_selector step 6550 current loss 0.652787, current_train_items 180656.
I0108 16:10:52.099207 123859203114496 run.py:783] (val) algo activity_selector step 6550: {'selected': 0.9584905660377359, 'score': 0.9584905660377359, 'examples_seen': 180656, 'step': 6550, 'algorithm': 'activity_selector'}
I0108 16:10:52.099448 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0108 16:10:53.536094 123859203114496 run.py:748] Algo activity_selector step 6600 current loss 0.949538, current_train_items 182032.
I0108 16:10:53.725123 123859203114496 run.py:783] (val) algo activity_selector step 6600: {'selected': 0.9661654135338347, 'score': 0.9661654135338347, 'examples_seen': 182032, 'step': 6600, 'algorithm': 'activity_selector'}
I0108 16:10:53.725350 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0108 16:10:55.134229 123859203114496 run.py:748] Algo activity_selector step 6650 current loss 0.843158, current_train_items 183408.
I0108 16:10:55.338592 123859203114496 run.py:783] (val) algo activity_selector step 6650: {'selected': 0.919449901768173, 'score': 0.919449901768173, 'examples_seen': 183408, 'step': 6650, 'algorithm': 'activity_selector'}
I0108 16:10:55.338815 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0108 16:10:56.747796 123859203114496 run.py:748] Algo activity_selector step 6700 current loss 0.547771, current_train_items 184800.
I0108 16:10:56.951596 123859203114496 run.py:783] (val) algo activity_selector step 6700: {'selected': 0.9423076923076923, 'score': 0.9423076923076923, 'examples_seen': 184800, 'step': 6700, 'algorithm': 'activity_selector'}
I0108 16:10:56.951818 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0108 16:10:58.390953 123859203114496 run.py:748] Algo activity_selector step 6750 current loss 0.548147, current_train_items 186176.
I0108 16:10:58.576968 123859203114496 run.py:783] (val) algo activity_selector step 6750: {'selected': 0.935672514619883, 'score': 0.935672514619883, 'examples_seen': 186176, 'step': 6750, 'algorithm': 'activity_selector'}
I0108 16:10:58.577195 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0108 16:10:59.986446 123859203114496 run.py:748] Algo activity_selector step 6800 current loss 0.547280, current_train_items 187536.
I0108 16:11:00.190412 123859203114496 run.py:783] (val) algo activity_selector step 6800: {'selected': 0.9393346379647749, 'score': 0.9393346379647749, 'examples_seen': 187536, 'step': 6800, 'algorithm': 'activity_selector'}
I0108 16:11:00.190638 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0108 16:11:01.610654 123859203114496 run.py:748] Algo activity_selector step 6850 current loss 0.677056, current_train_items 188928.
I0108 16:11:01.799413 123859203114496 run.py:783] (val) algo activity_selector step 6850: {'selected': 0.9516441005802708, 'score': 0.9516441005802708, 'examples_seen': 188928, 'step': 6850, 'algorithm': 'activity_selector'}
I0108 16:11:01.799593 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0108 16:11:03.227626 123859203114496 run.py:748] Algo activity_selector step 6900 current loss 0.801810, current_train_items 190304.
I0108 16:11:03.431474 123859203114496 run.py:783] (val) algo activity_selector step 6900: {'selected': 0.9514563106796117, 'score': 0.9514563106796117, 'examples_seen': 190304, 'step': 6900, 'algorithm': 'activity_selector'}
I0108 16:11:03.431714 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0108 16:11:04.846929 123859203114496 run.py:748] Algo activity_selector step 6950 current loss 0.630548, current_train_items 191680.
I0108 16:11:05.051584 123859203114496 run.py:783] (val) algo activity_selector step 6950: {'selected': 0.9047619047619049, 'score': 0.9047619047619049, 'examples_seen': 191680, 'step': 6950, 'algorithm': 'activity_selector'}
I0108 16:11:05.051826 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0108 16:11:06.471252 123859203114496 run.py:748] Algo activity_selector step 7000 current loss 0.648865, current_train_items 193072.
I0108 16:11:06.674706 123859203114496 run.py:783] (val) algo activity_selector step 7000: {'selected': 0.937875751503006, 'score': 0.937875751503006, 'examples_seen': 193072, 'step': 7000, 'algorithm': 'activity_selector'}
I0108 16:11:06.674959 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0108 16:11:08.089149 123859203114496 run.py:748] Algo activity_selector step 7050 current loss 0.523661, current_train_items 194448.
I0108 16:11:08.296636 123859203114496 run.py:783] (val) algo activity_selector step 7050: {'selected': 0.9427480916030535, 'score': 0.9427480916030535, 'examples_seen': 194448, 'step': 7050, 'algorithm': 'activity_selector'}
I0108 16:11:08.296864 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0108 16:11:09.745394 123859203114496 run.py:748] Algo activity_selector step 7100 current loss 1.105350, current_train_items 195824.
I0108 16:11:09.911067 123859203114496 run.py:783] (val) algo activity_selector step 7100: {'selected': 0.9318181818181819, 'score': 0.9318181818181819, 'examples_seen': 195824, 'step': 7100, 'algorithm': 'activity_selector'}
I0108 16:11:09.911296 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0108 16:11:11.313807 123859203114496 run.py:748] Algo activity_selector step 7150 current loss 0.628543, current_train_items 197200.
I0108 16:11:11.523968 123859203114496 run.py:783] (val) algo activity_selector step 7150: {'selected': 0.9139579349904398, 'score': 0.9139579349904398, 'examples_seen': 197200, 'step': 7150, 'algorithm': 'activity_selector'}
I0108 16:11:11.524194 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0108 16:11:12.944159 123859203114496 run.py:748] Algo activity_selector step 7200 current loss 0.803911, current_train_items 198576.
I0108 16:11:13.148584 123859203114496 run.py:783] (val) algo activity_selector step 7200: {'selected': 0.9551020408163265, 'score': 0.9551020408163265, 'examples_seen': 198576, 'step': 7200, 'algorithm': 'activity_selector'}
I0108 16:11:13.148812 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0108 16:11:14.557460 123859203114496 run.py:748] Algo activity_selector step 7250 current loss 0.548518, current_train_items 199952.
I0108 16:11:14.760808 123859203114496 run.py:783] (val) algo activity_selector step 7250: {'selected': 0.984313725490196, 'score': 0.984313725490196, 'examples_seen': 199952, 'step': 7250, 'algorithm': 'activity_selector'}
I0108 16:11:14.761056 123859203114496 run.py:804] Checkpointing best model, best avg val score was 0.971, current avg val score is 0.984, val scores are: activity_selector: 0.984
I0108 16:11:16.340939 123859203114496 run.py:748] Algo activity_selector step 7300 current loss 0.700899, current_train_items 201344.
I0108 16:11:16.547287 123859203114496 run.py:783] (val) algo activity_selector step 7300: {'selected': 0.9659090909090909, 'score': 0.9659090909090909, 'examples_seen': 201344, 'step': 7300, 'algorithm': 'activity_selector'}
I0108 16:11:16.547533 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.984, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0108 16:11:17.967593 123859203114496 run.py:748] Algo activity_selector step 7350 current loss 0.752838, current_train_items 202720.
I0108 16:11:18.170735 123859203114496 run.py:783] (val) algo activity_selector step 7350: {'selected': 0.9502982107355866, 'score': 0.9502982107355866, 'examples_seen': 202720, 'step': 7350, 'algorithm': 'activity_selector'}
I0108 16:11:18.170960 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.984, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0108 16:11:19.603606 123859203114496 run.py:748] Algo activity_selector step 7400 current loss 0.522426, current_train_items 204080.
I0108 16:11:19.785124 123859203114496 run.py:783] (val) algo activity_selector step 7400: {'selected': 0.9520153550863724, 'score': 0.9520153550863724, 'examples_seen': 204080, 'step': 7400, 'algorithm': 'activity_selector'}
I0108 16:11:19.785384 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.984, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0108 16:11:21.193997 123859203114496 run.py:748] Algo activity_selector step 7450 current loss 0.920518, current_train_items 205488.
I0108 16:11:21.397002 123859203114496 run.py:783] (val) algo activity_selector step 7450: {'selected': 0.947565543071161, 'score': 0.947565543071161, 'examples_seen': 205488, 'step': 7450, 'algorithm': 'activity_selector'}
I0108 16:11:21.397155 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.984, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0108 16:11:22.803130 123859203114496 run.py:748] Algo activity_selector step 7500 current loss 0.412651, current_train_items 206848.
I0108 16:11:23.004116 123859203114496 run.py:783] (val) algo activity_selector step 7500: {'selected': 0.9242718446601942, 'score': 0.9242718446601942, 'examples_seen': 206848, 'step': 7500, 'algorithm': 'activity_selector'}
I0108 16:11:23.004305 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.984, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0108 16:11:24.443733 123859203114496 run.py:748] Algo activity_selector step 7550 current loss 1.053125, current_train_items 208224.
I0108 16:11:24.620322 123859203114496 run.py:783] (val) algo activity_selector step 7550: {'selected': 0.8961303462321792, 'score': 0.8961303462321792, 'examples_seen': 208224, 'step': 7550, 'algorithm': 'activity_selector'}
I0108 16:11:24.620480 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.984, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0108 16:11:26.018097 123859203114496 run.py:748] Algo activity_selector step 7600 current loss 0.592147, current_train_items 209616.
I0108 16:11:26.220780 123859203114496 run.py:783] (val) algo activity_selector step 7600: {'selected': 0.947565543071161, 'score': 0.947565543071161, 'examples_seen': 209616, 'step': 7600, 'algorithm': 'activity_selector'}
I0108 16:11:26.221003 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.984, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0108 16:11:27.645658 123859203114496 run.py:748] Algo activity_selector step 7650 current loss 0.855732, current_train_items 210976.
I0108 16:11:27.850330 123859203114496 run.py:783] (val) algo activity_selector step 7650: {'selected': 0.9016697588126159, 'score': 0.9016697588126159, 'examples_seen': 210976, 'step': 7650, 'algorithm': 'activity_selector'}
I0108 16:11:27.850580 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.984, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0108 16:11:29.264281 123859203114496 run.py:748] Algo activity_selector step 7700 current loss 0.715279, current_train_items 212368.
I0108 16:11:29.468394 123859203114496 run.py:783] (val) algo activity_selector step 7700: {'selected': 0.9579158316633267, 'score': 0.9579158316633267, 'examples_seen': 212368, 'step': 7700, 'algorithm': 'activity_selector'}
I0108 16:11:29.468617 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.984, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0108 16:11:30.892300 123859203114496 run.py:748] Algo activity_selector step 7750 current loss 0.710294, current_train_items 213744.
I0108 16:11:31.082533 123859203114496 run.py:783] (val) algo activity_selector step 7750: {'selected': 0.9692307692307692, 'score': 0.9692307692307692, 'examples_seen': 213744, 'step': 7750, 'algorithm': 'activity_selector'}
I0108 16:11:31.082771 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.984, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0108 16:11:32.477254 123859203114496 run.py:748] Algo activity_selector step 7800 current loss 0.629566, current_train_items 215136.
I0108 16:11:32.706950 123859203114496 run.py:783] (val) algo activity_selector step 7800: {'selected': 0.9449715370018975, 'score': 0.9449715370018975, 'examples_seen': 215136, 'step': 7800, 'algorithm': 'activity_selector'}
I0108 16:11:32.707197 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.984, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0108 16:11:34.092438 123859203114496 run.py:748] Algo activity_selector step 7850 current loss 0.542343, current_train_items 216496.
I0108 16:11:34.319663 123859203114496 run.py:783] (val) algo activity_selector step 7850: {'selected': 0.9521988527724666, 'score': 0.9521988527724666, 'examples_seen': 216496, 'step': 7850, 'algorithm': 'activity_selector'}
I0108 16:11:34.319894 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.984, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0108 16:11:35.728270 123859203114496 run.py:748] Algo activity_selector step 7900 current loss 0.459714, current_train_items 217888.
I0108 16:11:35.933058 123859203114496 run.py:783] (val) algo activity_selector step 7900: {'selected': 0.9659090909090908, 'score': 0.9659090909090908, 'examples_seen': 217888, 'step': 7900, 'algorithm': 'activity_selector'}
I0108 16:11:35.933295 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.984, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0108 16:11:37.352471 123859203114496 run.py:748] Algo activity_selector step 7950 current loss 0.539965, current_train_items 219264.
I0108 16:11:37.558138 123859203114496 run.py:783] (val) algo activity_selector step 7950: {'selected': 0.9335863377609108, 'score': 0.9335863377609108, 'examples_seen': 219264, 'step': 7950, 'algorithm': 'activity_selector'}
I0108 16:11:37.558389 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.984, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0108 16:11:38.966896 123859203114496 run.py:748] Algo activity_selector step 8000 current loss 0.503407, current_train_items 220624.
I0108 16:11:39.170790 123859203114496 run.py:783] (val) algo activity_selector step 8000: {'selected': 0.9509433962264151, 'score': 0.9509433962264151, 'examples_seen': 220624, 'step': 8000, 'algorithm': 'activity_selector'}
I0108 16:11:39.171010 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.984, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0108 16:11:40.611967 123859203114496 run.py:748] Algo activity_selector step 8050 current loss 0.587329, current_train_items 222032.
I0108 16:11:40.815108 123859203114496 run.py:783] (val) algo activity_selector step 8050: {'selected': 0.9666666666666667, 'score': 0.9666666666666667, 'examples_seen': 222032, 'step': 8050, 'algorithm': 'activity_selector'}
I0108 16:11:40.815339 123859203114496 run.py:804] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0108 16:11:42.397097 123859203114496 run.py:748] Algo activity_selector step 8100 current loss 0.644390, current_train_items 223392.
I0108 16:11:42.602485 123859203114496 run.py:783] (val) algo activity_selector step 8100: {'selected': 0.956, 'score': 0.956, 'examples_seen': 223392, 'step': 8100, 'algorithm': 'activity_selector'}
I0108 16:11:42.602718 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0108 16:11:44.009377 123859203114496 run.py:748] Algo activity_selector step 8150 current loss 0.571321, current_train_items 224784.
I0108 16:11:44.211822 123859203114496 run.py:783] (val) algo activity_selector step 8150: {'selected': 0.9536679536679535, 'score': 0.9536679536679535, 'examples_seen': 224784, 'step': 8150, 'algorithm': 'activity_selector'}
I0108 16:11:44.211972 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0108 16:11:45.610620 123859203114496 run.py:748] Algo activity_selector step 8200 current loss 0.433124, current_train_items 226160.
I0108 16:11:45.814817 123859203114496 run.py:783] (val) algo activity_selector step 8200: {'selected': 0.9699248120300753, 'score': 0.9699248120300753, 'examples_seen': 226160, 'step': 8200, 'algorithm': 'activity_selector'}
I0108 16:11:45.815039 123859203114496 run.py:804] Checkpointing best model, best avg val score was 0.967, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0108 16:11:47.398235 123859203114496 run.py:748] Algo activity_selector step 8250 current loss 0.560037, current_train_items 227520.
I0108 16:11:47.606618 123859203114496 run.py:783] (val) algo activity_selector step 8250: {'selected': 0.9598470363288718, 'score': 0.9598470363288718, 'examples_seen': 227520, 'step': 8250, 'algorithm': 'activity_selector'}
I0108 16:11:47.606883 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0108 16:11:49.047351 123859203114496 run.py:748] Algo activity_selector step 8300 current loss 0.603248, current_train_items 228912.
I0108 16:11:49.229254 123859203114496 run.py:783] (val) algo activity_selector step 8300: {'selected': 0.9402697495183044, 'score': 0.9402697495183044, 'examples_seen': 228912, 'step': 8300, 'algorithm': 'activity_selector'}
I0108 16:11:49.229493 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0108 16:11:50.667072 123859203114496 run.py:748] Algo activity_selector step 8350 current loss 0.562675, current_train_items 230288.
I0108 16:11:50.848994 123859203114496 run.py:783] (val) algo activity_selector step 8350: {'selected': 0.9253187613843351, 'score': 0.9253187613843351, 'examples_seen': 230288, 'step': 8350, 'algorithm': 'activity_selector'}
I0108 16:11:50.849220 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0108 16:11:52.288361 123859203114496 run.py:748] Algo activity_selector step 8400 current loss 0.616830, current_train_items 231680.
I0108 16:11:52.475130 123859203114496 run.py:783] (val) algo activity_selector step 8400: {'selected': 0.9384615384615385, 'score': 0.9384615384615385, 'examples_seen': 231680, 'step': 8400, 'algorithm': 'activity_selector'}
I0108 16:11:52.475353 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0108 16:11:53.860662 123859203114496 run.py:748] Algo activity_selector step 8450 current loss 0.556872, current_train_items 233040.
I0108 16:11:54.089101 123859203114496 run.py:783] (val) algo activity_selector step 8450: {'selected': 0.9271028037383179, 'score': 0.9271028037383179, 'examples_seen': 233040, 'step': 8450, 'algorithm': 'activity_selector'}
I0108 16:11:54.089326 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0108 16:11:55.497792 123859203114496 run.py:748] Algo activity_selector step 8500 current loss 0.498487, current_train_items 234432.
I0108 16:11:55.702226 123859203114496 run.py:783] (val) algo activity_selector step 8500: {'selected': 0.9563567362428842, 'score': 0.9563567362428842, 'examples_seen': 234432, 'step': 8500, 'algorithm': 'activity_selector'}
I0108 16:11:55.702491 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0108 16:11:57.121540 123859203114496 run.py:748] Algo activity_selector step 8550 current loss 0.495058, current_train_items 235808.
I0108 16:11:57.325279 123859203114496 run.py:783] (val) algo activity_selector step 8550: {'selected': 0.949343339587242, 'score': 0.949343339587242, 'examples_seen': 235808, 'step': 8550, 'algorithm': 'activity_selector'}
I0108 16:11:57.325544 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0108 16:11:58.735067 123859203114496 run.py:748] Algo activity_selector step 8600 current loss 0.570991, current_train_items 237168.
I0108 16:11:58.938391 123859203114496 run.py:783] (val) algo activity_selector step 8600: {'selected': 0.9336016096579477, 'score': 0.9336016096579477, 'examples_seen': 237168, 'step': 8600, 'algorithm': 'activity_selector'}
I0108 16:11:58.938620 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0108 16:12:00.371846 123859203114496 run.py:748] Algo activity_selector step 8650 current loss 0.507172, current_train_items 238576.
I0108 16:12:00.552591 123859203114496 run.py:783] (val) algo activity_selector step 8650: {'selected': 0.9288537549407115, 'score': 0.9288537549407115, 'examples_seen': 238576, 'step': 8650, 'algorithm': 'activity_selector'}
I0108 16:12:00.552830 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0108 16:12:01.972011 123859203114496 run.py:748] Algo activity_selector step 8700 current loss 0.489356, current_train_items 239936.
I0108 16:12:02.177161 123859203114496 run.py:783] (val) algo activity_selector step 8700: {'selected': 0.9566854990583804, 'score': 0.9566854990583804, 'examples_seen': 239936, 'step': 8700, 'algorithm': 'activity_selector'}
I0108 16:12:02.177450 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0108 16:12:03.585871 123859203114496 run.py:748] Algo activity_selector step 8750 current loss 1.214658, current_train_items 241328.
I0108 16:12:03.789566 123859203114496 run.py:783] (val) algo activity_selector step 8750: {'selected': 0.9348230912476723, 'score': 0.9348230912476723, 'examples_seen': 241328, 'step': 8750, 'algorithm': 'activity_selector'}
I0108 16:12:03.789799 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0108 16:12:05.200598 123859203114496 run.py:748] Algo activity_selector step 8800 current loss 0.506612, current_train_items 242704.
I0108 16:12:05.408079 123859203114496 run.py:783] (val) algo activity_selector step 8800: {'selected': 0.9671179883945842, 'score': 0.9671179883945842, 'examples_seen': 242704, 'step': 8800, 'algorithm': 'activity_selector'}
I0108 16:12:05.408229 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0108 16:12:06.815597 123859203114496 run.py:748] Algo activity_selector step 8850 current loss 0.585238, current_train_items 244080.
I0108 16:12:07.017255 123859203114496 run.py:783] (val) algo activity_selector step 8850: {'selected': 0.9770114942528735, 'score': 0.9770114942528735, 'examples_seen': 244080, 'step': 8850, 'algorithm': 'activity_selector'}
I0108 16:12:07.017446 123859203114496 run.py:804] Checkpointing best model, best avg val score was 0.970, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0108 16:12:08.578981 123859203114496 run.py:748] Algo activity_selector step 8900 current loss 0.732444, current_train_items 245456.
I0108 16:12:08.784784 123859203114496 run.py:783] (val) algo activity_selector step 8900: {'selected': 0.888468809073724, 'score': 0.888468809073724, 'examples_seen': 245456, 'step': 8900, 'algorithm': 'activity_selector'}
I0108 16:12:08.784934 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.888, val scores are: activity_selector: 0.888
I0108 16:12:10.206831 123859203114496 run.py:748] Algo activity_selector step 8950 current loss 0.736821, current_train_items 246832.
I0108 16:12:10.384362 123859203114496 run.py:783] (val) algo activity_selector step 8950: {'selected': 0.9492187500000001, 'score': 0.9492187500000001, 'examples_seen': 246832, 'step': 8950, 'algorithm': 'activity_selector'}
I0108 16:12:10.384612 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0108 16:12:11.824944 123859203114496 run.py:748] Algo activity_selector step 9000 current loss 0.832916, current_train_items 248224.
I0108 16:12:12.005044 123859203114496 run.py:783] (val) algo activity_selector step 9000: {'selected': 0.9616858237547893, 'score': 0.9616858237547893, 'examples_seen': 248224, 'step': 9000, 'algorithm': 'activity_selector'}
I0108 16:12:12.005277 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0108 16:12:13.435313 123859203114496 run.py:748] Algo activity_selector step 9050 current loss 0.640957, current_train_items 249584.
I0108 16:12:13.622618 123859203114496 run.py:783] (val) algo activity_selector step 9050: {'selected': 0.9609374999999999, 'score': 0.9609374999999999, 'examples_seen': 249584, 'step': 9050, 'algorithm': 'activity_selector'}
I0108 16:12:13.622843 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0108 16:12:15.040027 123859203114496 run.py:748] Algo activity_selector step 9100 current loss 0.803850, current_train_items 250976.
I0108 16:12:15.241020 123859203114496 run.py:783] (val) algo activity_selector step 9100: {'selected': 0.9300567107750473, 'score': 0.9300567107750473, 'examples_seen': 250976, 'step': 9100, 'algorithm': 'activity_selector'}
I0108 16:12:15.241252 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0108 16:12:16.678112 123859203114496 run.py:748] Algo activity_selector step 9150 current loss 0.614056, current_train_items 252352.
I0108 16:12:16.866496 123859203114496 run.py:783] (val) algo activity_selector step 9150: {'selected': 0.9147005444646098, 'score': 0.9147005444646098, 'examples_seen': 252352, 'step': 9150, 'algorithm': 'activity_selector'}
I0108 16:12:16.866720 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0108 16:12:18.300155 123859203114496 run.py:748] Algo activity_selector step 9200 current loss 0.608431, current_train_items 253728.
I0108 16:12:18.480757 123859203114496 run.py:783] (val) algo activity_selector step 9200: {'selected': 0.934065934065934, 'score': 0.934065934065934, 'examples_seen': 253728, 'step': 9200, 'algorithm': 'activity_selector'}
I0108 16:12:18.480978 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0108 16:12:19.890036 123859203114496 run.py:748] Algo activity_selector step 9250 current loss 0.593631, current_train_items 255120.
I0108 16:12:20.094151 123859203114496 run.py:783] (val) algo activity_selector step 9250: {'selected': 0.9315589353612168, 'score': 0.9315589353612168, 'examples_seen': 255120, 'step': 9250, 'algorithm': 'activity_selector'}
I0108 16:12:20.094397 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0108 16:12:21.537360 123859203114496 run.py:748] Algo activity_selector step 9300 current loss 0.599885, current_train_items 256480.
I0108 16:12:21.715986 123859203114496 run.py:783] (val) algo activity_selector step 9300: {'selected': 0.9655172413793104, 'score': 0.9655172413793104, 'examples_seen': 256480, 'step': 9300, 'algorithm': 'activity_selector'}
I0108 16:12:21.716213 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0108 16:12:23.124858 123859203114496 run.py:748] Algo activity_selector step 9350 current loss 0.938654, current_train_items 257856.
I0108 16:12:23.326474 123859203114496 run.py:783] (val) algo activity_selector step 9350: {'selected': 0.9644859813084112, 'score': 0.9644859813084112, 'examples_seen': 257856, 'step': 9350, 'algorithm': 'activity_selector'}
I0108 16:12:23.326676 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0108 16:12:24.704312 123859203114496 run.py:748] Algo activity_selector step 9400 current loss 0.488751, current_train_items 259248.
I0108 16:12:24.931848 123859203114496 run.py:783] (val) algo activity_selector step 9400: {'selected': 0.9498069498069499, 'score': 0.9498069498069499, 'examples_seen': 259248, 'step': 9400, 'algorithm': 'activity_selector'}
I0108 16:12:24.932086 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0108 16:12:26.351780 123859203114496 run.py:748] Algo activity_selector step 9450 current loss 0.608776, current_train_items 260624.
I0108 16:12:26.552747 123859203114496 run.py:783] (val) algo activity_selector step 9450: {'selected': 0.9691991786447639, 'score': 0.9691991786447639, 'examples_seen': 260624, 'step': 9450, 'algorithm': 'activity_selector'}
I0108 16:12:26.552967 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0108 16:12:27.962222 123859203114496 run.py:748] Algo activity_selector step 9500 current loss 0.445800, current_train_items 262000.
I0108 16:12:28.167201 123859203114496 run.py:783] (val) algo activity_selector step 9500: {'selected': 0.9341085271317829, 'score': 0.9341085271317829, 'examples_seen': 262000, 'step': 9500, 'algorithm': 'activity_selector'}
I0108 16:12:28.167438 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0108 16:12:29.591042 123859203114496 run.py:748] Algo activity_selector step 9550 current loss 0.449862, current_train_items 263392.
I0108 16:12:29.780439 123859203114496 run.py:783] (val) algo activity_selector step 9550: {'selected': 0.9549180327868853, 'score': 0.9549180327868853, 'examples_seen': 263392, 'step': 9550, 'algorithm': 'activity_selector'}
I0108 16:12:29.780661 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0108 16:12:31.208696 123859203114496 run.py:748] Algo activity_selector step 9600 current loss 0.652233, current_train_items 264768.
I0108 16:12:31.413784 123859203114496 run.py:783] (val) algo activity_selector step 9600: {'selected': 0.9614604462474645, 'score': 0.9614604462474645, 'examples_seen': 264768, 'step': 9600, 'algorithm': 'activity_selector'}
I0108 16:12:31.414014 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0108 16:12:32.828969 123859203114496 run.py:748] Algo activity_selector step 9650 current loss 0.855816, current_train_items 266128.
I0108 16:12:33.035616 123859203114496 run.py:783] (val) algo activity_selector step 9650: {'selected': 0.8987108655616943, 'score': 0.8987108655616943, 'examples_seen': 266128, 'step': 9650, 'algorithm': 'activity_selector'}
I0108 16:12:33.035846 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0108 16:12:34.465982 123859203114496 run.py:748] Algo activity_selector step 9700 current loss 0.603900, current_train_items 267520.
I0108 16:12:34.653580 123859203114496 run.py:783] (val) algo activity_selector step 9700: {'selected': 0.9651162790697674, 'score': 0.9651162790697674, 'examples_seen': 267520, 'step': 9700, 'algorithm': 'activity_selector'}
I0108 16:12:34.653806 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0108 16:12:36.074091 123859203114496 run.py:748] Algo activity_selector step 9750 current loss 0.663534, current_train_items 268896.
I0108 16:12:36.276450 123859203114496 run.py:783] (val) algo activity_selector step 9750: {'selected': 0.9032258064516129, 'score': 0.9032258064516129, 'examples_seen': 268896, 'step': 9750, 'algorithm': 'activity_selector'}
I0108 16:12:36.276677 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.903, val scores are: activity_selector: 0.903
I0108 16:12:37.660530 123859203114496 run.py:748] Algo activity_selector step 9800 current loss 1.108142, current_train_items 270272.
I0108 16:12:37.888670 123859203114496 run.py:783] (val) algo activity_selector step 9800: {'selected': 0.9450980392156864, 'score': 0.9450980392156864, 'examples_seen': 270272, 'step': 9800, 'algorithm': 'activity_selector'}
I0108 16:12:37.888893 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0108 16:12:39.297465 123859203114496 run.py:748] Algo activity_selector step 9850 current loss 0.912321, current_train_items 271664.
I0108 16:12:39.500832 123859203114496 run.py:783] (val) algo activity_selector step 9850: {'selected': 0.9477611940298507, 'score': 0.9477611940298507, 'examples_seen': 271664, 'step': 9850, 'algorithm': 'activity_selector'}
I0108 16:12:39.501058 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0108 16:12:40.912701 123859203114496 run.py:748] Algo activity_selector step 9900 current loss 0.585514, current_train_items 273040.
I0108 16:12:41.125015 123859203114496 run.py:783] (val) algo activity_selector step 9900: {'selected': 0.9502982107355865, 'score': 0.9502982107355865, 'examples_seen': 273040, 'step': 9900, 'algorithm': 'activity_selector'}
I0108 16:12:41.125241 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0108 16:12:42.526376 123859203114496 run.py:748] Algo activity_selector step 9950 current loss 0.519848, current_train_items 274400.
I0108 16:12:42.738013 123859203114496 run.py:783] (val) algo activity_selector step 9950: {'selected': 0.9465648854961832, 'score': 0.9465648854961832, 'examples_seen': 274400, 'step': 9950, 'algorithm': 'activity_selector'}
I0108 16:12:42.738238 123859203114496 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0108 16:12:44.128539 123859203114496 run.py:813] Restoring best model from checkpoint...
I0108 16:12:53.353493 123859203114496 run.py:828] (test) algo activity_selector : {'selected': 0.8641509433962264, 'score': 0.8641509433962264, 'examples_seen': 275760, 'step': 10000, 'algorithm': 'activity_selector'}
I0108 16:12:53.353644 123859203114496 run.py:830] Done!
