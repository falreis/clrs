I0819 22:01:52.752490 135470064580096 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0819 22:01:52.753125 135470064580096 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0819 22:01:52.986385 135470064580096 run.py:411] Model: f3 ['activity_selector']
I0819 22:01:52.986487 135470064580096 run.py:413] algorithms ['activity_selector']
I0819 22:01:52.986658 135470064580096 run.py:414] train_lengths ['4', '7', '11', '13', '16']
I0819 22:01:52.986694 135470064580096 run.py:415] train_batch_size 32
I0819 22:01:52.986784 135470064580096 run.py:416] val_batch_size 32
I0819 22:01:52.986815 135470064580096 run.py:417] test_batch_size 32
I0819 22:01:52.986843 135470064580096 run.py:418] chunked_training True
I0819 22:01:52.986961 135470064580096 run.py:419] chunk_length 8
I0819 22:01:52.986991 135470064580096 run.py:420] train_steps 10000
I0819 22:01:52.987020 135470064580096 run.py:421] eval_every 50
I0819 22:01:52.987049 135470064580096 run.py:422] test_every 500
I0819 22:01:52.987077 135470064580096 run.py:423] hidden_size 64
I0819 22:01:52.987107 135470064580096 run.py:424] nb_msg_passing_steps 1
I0819 22:01:52.987135 135470064580096 run.py:425] learning_rate 0.001
I0819 22:01:52.987220 135470064580096 run.py:426] grad_clip_max_norm 1.0
I0819 22:01:52.987248 135470064580096 run.py:427] dropout_prob 0.1
I0819 22:01:52.987276 135470064580096 run.py:428] hint_teacher_forcing 0.0
I0819 22:01:52.987307 135470064580096 run.py:429] hint_mode encoded_decoded
I0819 22:01:52.987416 135470064580096 run.py:430] hint_repred_mode soft
I0819 22:01:52.987444 135470064580096 run.py:431] use_ln False
I0819 22:01:52.987471 135470064580096 run.py:432] use_lstm True
I0819 22:01:52.987498 135470064580096 run.py:433] nb_triplet_fts 8
I0819 22:01:52.987526 135470064580096 run.py:434] encoder_init xavier_on_scalars
I0819 22:01:52.987553 135470064580096 run.py:435] processor_type f3
I0819 22:01:52.987584 135470064580096 run.py:436] checkpoint_path CLRS30
I0819 22:01:52.987612 135470064580096 run.py:437] dataset_path CLRS30
I0819 22:01:52.987640 135470064580096 run.py:438] freeze_processor False
I0819 22:01:52.987667 135470064580096 run.py:439] reduction min
I0819 22:01:52.987694 135470064580096 run.py:440] activation elu
I0819 22:01:52.987720 135470064580096 run.py:441] restore_model 
I0819 22:01:52.987747 135470064580096 run.py:442] gated True
I0819 22:01:52.987774 135470064580096 run.py:443] gated_activation sigmoid
I0819 22:01:52.990502 135470064580096 run.py:469] Creating samplers for algo activity_selector
W0819 22:01:52.990674 135470064580096 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0819 22:01:52.990926 135470064580096 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0819 22:01:53.194855 135470064580096 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0819 22:01:53.432025 135470064580096 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0819 22:01:53.726121 135470064580096 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0819 22:01:54.052656 135470064580096 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0819 22:01:54.438955 135470064580096 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0819 22:01:54.439253 135470064580096 samplers.py:124] Creating a dataset with 64 samples.
I0819 22:01:54.465179 135470064580096 run.py:255] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0819 22:01:54.465911 135470064580096 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0819 22:01:54.469228 135470064580096 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0819 22:01:54.472756 135470064580096 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0819 22:01:54.524451 135470064580096 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W0819 22:01:54.547531 135470064580096 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x7b351089f4c0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0819 22:02:15.158540 135470064580096 run.py:692] Algo activity_selector step 0 current loss 5.657624, current_train_items 32.
I0819 22:02:16.848767 135470064580096 run.py:727] (val) algo activity_selector step 0: {'selected': 0.23529411764705882, 'score': 0.23529411764705882, 'examples_seen': 32, 'step': 0, 'algorithm': 'activity_selector'}
I0819 22:02:16.848926 135470064580096 run.py:748] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.235, val scores are: activity_selector: 0.235
I0819 22:02:39.861369 135470064580096 run.py:692] Algo activity_selector step 50 current loss 4.615246, current_train_items 1440.
I0819 22:02:39.874389 135470064580096 run.py:727] (val) algo activity_selector step 50: {'selected': 0.7205169628432955, 'score': 0.7205169628432955, 'examples_seen': 1440, 'step': 50, 'algorithm': 'activity_selector'}
I0819 22:02:39.874550 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.235, current avg val score is 0.721, val scores are: activity_selector: 0.721
I0819 22:02:40.879881 135470064580096 run.py:692] Algo activity_selector step 100 current loss 3.752180, current_train_items 2816.
I0819 22:02:40.892399 135470064580096 run.py:727] (val) algo activity_selector step 100: {'selected': 0.611336032388664, 'score': 0.611336032388664, 'examples_seen': 2816, 'step': 100, 'algorithm': 'activity_selector'}
I0819 22:02:40.892550 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.721, current avg val score is 0.611, val scores are: activity_selector: 0.611
I0819 22:02:41.868476 135470064580096 run.py:692] Algo activity_selector step 150 current loss 3.821197, current_train_items 4160.
I0819 22:02:41.880926 135470064580096 run.py:727] (val) algo activity_selector step 150: {'selected': 0.671201814058957, 'score': 0.671201814058957, 'examples_seen': 4160, 'step': 150, 'algorithm': 'activity_selector'}
I0819 22:02:41.881099 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.721, current avg val score is 0.671, val scores are: activity_selector: 0.671
I0819 22:02:42.801345 135470064580096 run.py:692] Algo activity_selector step 200 current loss 3.507349, current_train_items 5568.
I0819 22:02:42.813180 135470064580096 run.py:727] (val) algo activity_selector step 200: {'selected': 0.579064587973274, 'score': 0.579064587973274, 'examples_seen': 5568, 'step': 200, 'algorithm': 'activity_selector'}
I0819 22:02:42.813325 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.721, current avg val score is 0.579, val scores are: activity_selector: 0.579
I0819 22:02:43.702575 135470064580096 run.py:692] Algo activity_selector step 250 current loss 3.418211, current_train_items 6976.
I0819 22:02:43.714978 135470064580096 run.py:727] (val) algo activity_selector step 250: {'selected': 0.7063492063492064, 'score': 0.7063492063492064, 'examples_seen': 6976, 'step': 250, 'algorithm': 'activity_selector'}
I0819 22:02:43.715125 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.721, current avg val score is 0.706, val scores are: activity_selector: 0.706
I0819 22:02:44.628373 135470064580096 run.py:692] Algo activity_selector step 300 current loss 3.113706, current_train_items 8288.
I0819 22:02:44.640065 135470064580096 run.py:727] (val) algo activity_selector step 300: {'selected': 0.6733870967741936, 'score': 0.6733870967741936, 'examples_seen': 8288, 'step': 300, 'algorithm': 'activity_selector'}
I0819 22:02:44.640212 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.721, current avg val score is 0.673, val scores are: activity_selector: 0.673
I0819 22:02:45.558130 135470064580096 run.py:692] Algo activity_selector step 350 current loss 2.897695, current_train_items 9696.
I0819 22:02:45.570027 135470064580096 run.py:727] (val) algo activity_selector step 350: {'selected': 0.7346153846153844, 'score': 0.7346153846153844, 'examples_seen': 9696, 'step': 350, 'algorithm': 'activity_selector'}
I0819 22:02:45.570171 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.721, current avg val score is 0.735, val scores are: activity_selector: 0.735
I0819 22:02:46.481701 135470064580096 run.py:692] Algo activity_selector step 400 current loss 2.763680, current_train_items 11104.
I0819 22:02:46.494946 135470064580096 run.py:727] (val) algo activity_selector step 400: {'selected': 0.6857142857142857, 'score': 0.6857142857142857, 'examples_seen': 11104, 'step': 400, 'algorithm': 'activity_selector'}
I0819 22:02:46.495091 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.735, current avg val score is 0.686, val scores are: activity_selector: 0.686
I0819 22:02:47.391850 135470064580096 run.py:692] Algo activity_selector step 450 current loss 2.711746, current_train_items 12448.
I0819 22:02:47.406095 135470064580096 run.py:727] (val) algo activity_selector step 450: {'selected': 0.7309833024118738, 'score': 0.7309833024118738, 'examples_seen': 12448, 'step': 450, 'algorithm': 'activity_selector'}
I0819 22:02:47.406252 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.735, current avg val score is 0.731, val scores are: activity_selector: 0.731
I0819 22:02:48.350401 135470064580096 run.py:692] Algo activity_selector step 500 current loss 2.651142, current_train_items 13824.
I0819 22:02:48.362268 135470064580096 run.py:727] (val) algo activity_selector step 500: {'selected': 0.7415730337078652, 'score': 0.7415730337078652, 'examples_seen': 13824, 'step': 500, 'algorithm': 'activity_selector'}
I0819 22:02:48.362421 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.735, current avg val score is 0.742, val scores are: activity_selector: 0.742
I0819 22:02:49.288306 135470064580096 run.py:692] Algo activity_selector step 550 current loss 2.527535, current_train_items 15232.
I0819 22:02:49.300022 135470064580096 run.py:727] (val) algo activity_selector step 550: {'selected': 0.7794117647058824, 'score': 0.7794117647058824, 'examples_seen': 15232, 'step': 550, 'algorithm': 'activity_selector'}
I0819 22:02:49.300168 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.742, current avg val score is 0.779, val scores are: activity_selector: 0.779
I0819 22:02:50.194187 135470064580096 run.py:692] Algo activity_selector step 600 current loss 2.489046, current_train_items 16576.
I0819 22:02:50.205884 135470064580096 run.py:727] (val) algo activity_selector step 600: {'selected': 0.7514450867052023, 'score': 0.7514450867052023, 'examples_seen': 16576, 'step': 600, 'algorithm': 'activity_selector'}
I0819 22:02:50.206028 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.779, current avg val score is 0.751, val scores are: activity_selector: 0.751
I0819 22:02:51.110724 135470064580096 run.py:692] Algo activity_selector step 650 current loss 2.498295, current_train_items 17952.
I0819 22:02:51.122539 135470064580096 run.py:727] (val) algo activity_selector step 650: {'selected': 0.7818499127399651, 'score': 0.7818499127399651, 'examples_seen': 17952, 'step': 650, 'algorithm': 'activity_selector'}
I0819 22:02:51.122699 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.779, current avg val score is 0.782, val scores are: activity_selector: 0.782
I0819 22:02:52.025459 135470064580096 run.py:692] Algo activity_selector step 700 current loss 2.486659, current_train_items 19360.
I0819 22:02:52.038751 135470064580096 run.py:727] (val) algo activity_selector step 700: {'selected': 0.7648054145516074, 'score': 0.7648054145516074, 'examples_seen': 19360, 'step': 700, 'algorithm': 'activity_selector'}
I0819 22:02:52.038894 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.782, current avg val score is 0.765, val scores are: activity_selector: 0.765
I0819 22:02:52.948859 135470064580096 run.py:692] Algo activity_selector step 750 current loss 2.520071, current_train_items 20736.
I0819 22:02:52.960858 135470064580096 run.py:727] (val) algo activity_selector step 750: {'selected': 0.7832699619771863, 'score': 0.7832699619771863, 'examples_seen': 20736, 'step': 750, 'algorithm': 'activity_selector'}
I0819 22:02:52.961004 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.782, current avg val score is 0.783, val scores are: activity_selector: 0.783
I0819 22:02:53.848611 135470064580096 run.py:692] Algo activity_selector step 800 current loss 2.541171, current_train_items 22112.
I0819 22:02:53.860658 135470064580096 run.py:727] (val) algo activity_selector step 800: {'selected': 0.7483870967741935, 'score': 0.7483870967741935, 'examples_seen': 22112, 'step': 800, 'algorithm': 'activity_selector'}
I0819 22:02:53.860805 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.783, current avg val score is 0.748, val scores are: activity_selector: 0.748
I0819 22:02:54.752095 135470064580096 run.py:692] Algo activity_selector step 850 current loss 2.391054, current_train_items 23488.
I0819 22:02:54.764308 135470064580096 run.py:727] (val) algo activity_selector step 850: {'selected': 0.8020833333333334, 'score': 0.8020833333333334, 'examples_seen': 23488, 'step': 850, 'algorithm': 'activity_selector'}
I0819 22:02:54.764464 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.783, current avg val score is 0.802, val scores are: activity_selector: 0.802
I0819 22:02:55.687510 135470064580096 run.py:692] Algo activity_selector step 900 current loss 2.716159, current_train_items 24864.
I0819 22:02:55.699404 135470064580096 run.py:727] (val) algo activity_selector step 900: {'selected': 0.7663934426229508, 'score': 0.7663934426229508, 'examples_seen': 24864, 'step': 900, 'algorithm': 'activity_selector'}
I0819 22:02:55.699553 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.802, current avg val score is 0.766, val scores are: activity_selector: 0.766
I0819 22:02:56.589594 135470064580096 run.py:692] Algo activity_selector step 950 current loss 2.192745, current_train_items 26240.
I0819 22:02:56.602101 135470064580096 run.py:727] (val) algo activity_selector step 950: {'selected': 0.7392739273927391, 'score': 0.7392739273927391, 'examples_seen': 26240, 'step': 950, 'algorithm': 'activity_selector'}
I0819 22:02:56.602248 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.802, current avg val score is 0.739, val scores are: activity_selector: 0.739
I0819 22:02:57.485250 135470064580096 run.py:692] Algo activity_selector step 1000 current loss 2.480811, current_train_items 27616.
I0819 22:02:57.496854 135470064580096 run.py:727] (val) algo activity_selector step 1000: {'selected': 0.7459677419354839, 'score': 0.7459677419354839, 'examples_seen': 27616, 'step': 1000, 'algorithm': 'activity_selector'}
I0819 22:02:57.496998 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.802, current avg val score is 0.746, val scores are: activity_selector: 0.746
I0819 22:02:58.404116 135470064580096 run.py:692] Algo activity_selector step 1050 current loss 2.504411, current_train_items 28992.
I0819 22:02:58.415792 135470064580096 run.py:727] (val) algo activity_selector step 1050: {'selected': 0.7629513343799057, 'score': 0.7629513343799057, 'examples_seen': 28992, 'step': 1050, 'algorithm': 'activity_selector'}
I0819 22:02:58.415938 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.802, current avg val score is 0.763, val scores are: activity_selector: 0.763
I0819 22:02:59.309609 135470064580096 run.py:692] Algo activity_selector step 1100 current loss 2.046495, current_train_items 30400.
I0819 22:02:59.321354 135470064580096 run.py:727] (val) algo activity_selector step 1100: {'selected': 0.766025641025641, 'score': 0.766025641025641, 'examples_seen': 30400, 'step': 1100, 'algorithm': 'activity_selector'}
I0819 22:02:59.321507 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.802, current avg val score is 0.766, val scores are: activity_selector: 0.766
I0819 22:03:00.200251 135470064580096 run.py:692] Algo activity_selector step 1150 current loss 2.069790, current_train_items 31776.
I0819 22:03:00.211849 135470064580096 run.py:727] (val) algo activity_selector step 1150: {'selected': 0.7562189054726368, 'score': 0.7562189054726368, 'examples_seen': 31776, 'step': 1150, 'algorithm': 'activity_selector'}
I0819 22:03:00.211996 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.802, current avg val score is 0.756, val scores are: activity_selector: 0.756
I0819 22:03:01.116967 135470064580096 run.py:692] Algo activity_selector step 1200 current loss 1.806831, current_train_items 33120.
I0819 22:03:01.128938 135470064580096 run.py:727] (val) algo activity_selector step 1200: {'selected': 0.7840531561461795, 'score': 0.7840531561461795, 'examples_seen': 33120, 'step': 1200, 'algorithm': 'activity_selector'}
I0819 22:03:01.129084 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.802, current avg val score is 0.784, val scores are: activity_selector: 0.784
I0819 22:03:02.037886 135470064580096 run.py:692] Algo activity_selector step 1250 current loss 1.899475, current_train_items 34528.
I0819 22:03:02.049490 135470064580096 run.py:727] (val) algo activity_selector step 1250: {'selected': 0.7446043165467626, 'score': 0.7446043165467626, 'examples_seen': 34528, 'step': 1250, 'algorithm': 'activity_selector'}
I0819 22:03:02.049633 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.802, current avg val score is 0.745, val scores are: activity_selector: 0.745
I0819 22:03:02.915482 135470064580096 run.py:692] Algo activity_selector step 1300 current loss 2.405741, current_train_items 35904.
I0819 22:03:02.927073 135470064580096 run.py:727] (val) algo activity_selector step 1300: {'selected': 0.7906976744186046, 'score': 0.7906976744186046, 'examples_seen': 35904, 'step': 1300, 'algorithm': 'activity_selector'}
I0819 22:03:02.927218 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.802, current avg val score is 0.791, val scores are: activity_selector: 0.791
I0819 22:03:03.816617 135470064580096 run.py:692] Algo activity_selector step 1350 current loss 2.079747, current_train_items 37248.
I0819 22:03:03.828865 135470064580096 run.py:727] (val) algo activity_selector step 1350: {'selected': 0.8237476808905381, 'score': 0.8237476808905381, 'examples_seen': 37248, 'step': 1350, 'algorithm': 'activity_selector'}
I0819 22:03:03.829011 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.802, current avg val score is 0.824, val scores are: activity_selector: 0.824
I0819 22:03:04.739068 135470064580096 run.py:692] Algo activity_selector step 1400 current loss 1.853678, current_train_items 38656.
I0819 22:03:04.750936 135470064580096 run.py:727] (val) algo activity_selector step 1400: {'selected': 0.8088235294117646, 'score': 0.8088235294117646, 'examples_seen': 38656, 'step': 1400, 'algorithm': 'activity_selector'}
I0819 22:03:04.751090 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.824, current avg val score is 0.809, val scores are: activity_selector: 0.809
I0819 22:03:05.621465 135470064580096 run.py:692] Algo activity_selector step 1450 current loss 1.843725, current_train_items 40032.
I0819 22:03:05.633020 135470064580096 run.py:727] (val) algo activity_selector step 1450: {'selected': 0.7914438502673797, 'score': 0.7914438502673797, 'examples_seen': 40032, 'step': 1450, 'algorithm': 'activity_selector'}
I0819 22:03:05.633165 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.824, current avg val score is 0.791, val scores are: activity_selector: 0.791
I0819 22:03:06.532797 135470064580096 run.py:692] Algo activity_selector step 1500 current loss 1.880213, current_train_items 41408.
I0819 22:03:06.547185 135470064580096 run.py:727] (val) algo activity_selector step 1500: {'selected': 0.8013029315960911, 'score': 0.8013029315960911, 'examples_seen': 41408, 'step': 1500, 'algorithm': 'activity_selector'}
I0819 22:03:06.547329 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.824, current avg val score is 0.801, val scores are: activity_selector: 0.801
I0819 22:03:07.449678 135470064580096 run.py:692] Algo activity_selector step 1550 current loss 1.695354, current_train_items 42784.
I0819 22:03:07.461912 135470064580096 run.py:727] (val) algo activity_selector step 1550: {'selected': 0.7826086956521738, 'score': 0.7826086956521738, 'examples_seen': 42784, 'step': 1550, 'algorithm': 'activity_selector'}
I0819 22:03:07.462065 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.824, current avg val score is 0.783, val scores are: activity_selector: 0.783
I0819 22:03:08.358932 135470064580096 run.py:692] Algo activity_selector step 1600 current loss 1.832627, current_train_items 44192.
I0819 22:03:08.370999 135470064580096 run.py:727] (val) algo activity_selector step 1600: {'selected': 0.8086522462562397, 'score': 0.8086522462562397, 'examples_seen': 44192, 'step': 1600, 'algorithm': 'activity_selector'}
I0819 22:03:08.371142 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.824, current avg val score is 0.809, val scores are: activity_selector: 0.809
I0819 22:03:09.252287 135470064580096 run.py:692] Algo activity_selector step 1650 current loss 1.714425, current_train_items 45536.
I0819 22:03:09.264222 135470064580096 run.py:727] (val) algo activity_selector step 1650: {'selected': 0.8121645796064401, 'score': 0.8121645796064401, 'examples_seen': 45536, 'step': 1650, 'algorithm': 'activity_selector'}
I0819 22:03:09.264397 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.824, current avg val score is 0.812, val scores are: activity_selector: 0.812
I0819 22:03:10.165769 135470064580096 run.py:692] Algo activity_selector step 1700 current loss 1.863333, current_train_items 46912.
I0819 22:03:10.177407 135470064580096 run.py:727] (val) algo activity_selector step 1700: {'selected': 0.8129496402877698, 'score': 0.8129496402877698, 'examples_seen': 46912, 'step': 1700, 'algorithm': 'activity_selector'}
I0819 22:03:10.177554 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.824, current avg val score is 0.813, val scores are: activity_selector: 0.813
I0819 22:03:11.091171 135470064580096 run.py:692] Algo activity_selector step 1750 current loss 2.414842, current_train_items 48320.
I0819 22:03:11.103033 135470064580096 run.py:727] (val) algo activity_selector step 1750: {'selected': 0.7909407665505227, 'score': 0.7909407665505227, 'examples_seen': 48320, 'step': 1750, 'algorithm': 'activity_selector'}
I0819 22:03:11.103180 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.824, current avg val score is 0.791, val scores are: activity_selector: 0.791
I0819 22:03:12.001926 135470064580096 run.py:692] Algo activity_selector step 1800 current loss 1.528723, current_train_items 49664.
I0819 22:03:12.013684 135470064580096 run.py:727] (val) algo activity_selector step 1800: {'selected': 0.8283185840707964, 'score': 0.8283185840707964, 'examples_seen': 49664, 'step': 1800, 'algorithm': 'activity_selector'}
I0819 22:03:12.013844 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.824, current avg val score is 0.828, val scores are: activity_selector: 0.828
I0819 22:03:12.936580 135470064580096 run.py:692] Algo activity_selector step 1850 current loss 1.673569, current_train_items 51072.
I0819 22:03:12.949607 135470064580096 run.py:727] (val) algo activity_selector step 1850: {'selected': 0.7972508591065293, 'score': 0.7972508591065293, 'examples_seen': 51072, 'step': 1850, 'algorithm': 'activity_selector'}
I0819 22:03:12.949763 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.828, current avg val score is 0.797, val scores are: activity_selector: 0.797
I0819 22:03:13.842408 135470064580096 run.py:692] Algo activity_selector step 1900 current loss 1.481798, current_train_items 52448.
I0819 22:03:13.854700 135470064580096 run.py:727] (val) algo activity_selector step 1900: {'selected': 0.8169014084507042, 'score': 0.8169014084507042, 'examples_seen': 52448, 'step': 1900, 'algorithm': 'activity_selector'}
I0819 22:03:13.854883 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.828, current avg val score is 0.817, val scores are: activity_selector: 0.817
I0819 22:03:14.747907 135470064580096 run.py:692] Algo activity_selector step 1950 current loss 1.725277, current_train_items 53824.
I0819 22:03:14.759271 135470064580096 run.py:727] (val) algo activity_selector step 1950: {'selected': 0.8315018315018315, 'score': 0.8315018315018315, 'examples_seen': 53824, 'step': 1950, 'algorithm': 'activity_selector'}
I0819 22:03:14.759425 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.828, current avg val score is 0.832, val scores are: activity_selector: 0.832
I0819 22:03:15.669957 135470064580096 run.py:692] Algo activity_selector step 2000 current loss 1.475126, current_train_items 55200.
I0819 22:03:15.682611 135470064580096 run.py:727] (val) algo activity_selector step 2000: {'selected': 0.7792207792207791, 'score': 0.7792207792207791, 'examples_seen': 55200, 'step': 2000, 'algorithm': 'activity_selector'}
I0819 22:03:15.682757 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.832, current avg val score is 0.779, val scores are: activity_selector: 0.779
I0819 22:03:16.571205 135470064580096 run.py:692] Algo activity_selector step 2050 current loss 1.539896, current_train_items 56576.
I0819 22:03:16.583220 135470064580096 run.py:727] (val) algo activity_selector step 2050: {'selected': 0.7901639344262295, 'score': 0.7901639344262295, 'examples_seen': 56576, 'step': 2050, 'algorithm': 'activity_selector'}
I0819 22:03:16.583367 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.832, current avg val score is 0.790, val scores are: activity_selector: 0.790
I0819 22:03:17.485172 135470064580096 run.py:692] Algo activity_selector step 2100 current loss 1.635604, current_train_items 57952.
I0819 22:03:17.496810 135470064580096 run.py:727] (val) algo activity_selector step 2100: {'selected': 0.8056042031523644, 'score': 0.8056042031523644, 'examples_seen': 57952, 'step': 2100, 'algorithm': 'activity_selector'}
I0819 22:03:17.496955 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.832, current avg val score is 0.806, val scores are: activity_selector: 0.806
I0819 22:03:18.386091 135470064580096 run.py:692] Algo activity_selector step 2150 current loss 1.489140, current_train_items 59328.
I0819 22:03:18.397659 135470064580096 run.py:727] (val) algo activity_selector step 2150: {'selected': 0.8413284132841328, 'score': 0.8413284132841328, 'examples_seen': 59328, 'step': 2150, 'algorithm': 'activity_selector'}
I0819 22:03:18.397807 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.832, current avg val score is 0.841, val scores are: activity_selector: 0.841
I0819 22:03:19.286921 135470064580096 run.py:692] Algo activity_selector step 2200 current loss 2.195380, current_train_items 60736.
I0819 22:03:19.298999 135470064580096 run.py:727] (val) algo activity_selector step 2200: {'selected': 0.7889908256880735, 'score': 0.7889908256880735, 'examples_seen': 60736, 'step': 2200, 'algorithm': 'activity_selector'}
I0819 22:03:19.299156 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.841, current avg val score is 0.789, val scores are: activity_selector: 0.789
I0819 22:03:20.201006 135470064580096 run.py:692] Algo activity_selector step 2250 current loss 1.649158, current_train_items 62080.
I0819 22:03:20.212543 135470064580096 run.py:727] (val) algo activity_selector step 2250: {'selected': 0.8015122873345936, 'score': 0.8015122873345936, 'examples_seen': 62080, 'step': 2250, 'algorithm': 'activity_selector'}
I0819 22:03:20.212690 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.841, current avg val score is 0.802, val scores are: activity_selector: 0.802
I0819 22:03:21.103331 135470064580096 run.py:692] Algo activity_selector step 2300 current loss 1.564057, current_train_items 63456.
I0819 22:03:21.115465 135470064580096 run.py:727] (val) algo activity_selector step 2300: {'selected': 0.8540925266903915, 'score': 0.8540925266903915, 'examples_seen': 63456, 'step': 2300, 'algorithm': 'activity_selector'}
I0819 22:03:21.115612 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.841, current avg val score is 0.854, val scores are: activity_selector: 0.854
I0819 22:03:22.023750 135470064580096 run.py:692] Algo activity_selector step 2350 current loss 1.686952, current_train_items 64864.
I0819 22:03:22.035797 135470064580096 run.py:727] (val) algo activity_selector step 2350: {'selected': 0.83704974271012, 'score': 0.83704974271012, 'examples_seen': 64864, 'step': 2350, 'algorithm': 'activity_selector'}
I0819 22:03:22.035945 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.854, current avg val score is 0.837, val scores are: activity_selector: 0.837
I0819 22:03:22.924535 135470064580096 run.py:692] Algo activity_selector step 2400 current loss 1.696393, current_train_items 66208.
I0819 22:03:22.936233 135470064580096 run.py:727] (val) algo activity_selector step 2400: {'selected': 0.8378870673952642, 'score': 0.8378870673952642, 'examples_seen': 66208, 'step': 2400, 'algorithm': 'activity_selector'}
I0819 22:03:22.936384 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.854, current avg val score is 0.838, val scores are: activity_selector: 0.838
I0819 22:03:23.849338 135470064580096 run.py:692] Algo activity_selector step 2450 current loss 1.502328, current_train_items 67616.
I0819 22:03:23.861046 135470064580096 run.py:727] (val) algo activity_selector step 2450: {'selected': 0.8516579406631762, 'score': 0.8516579406631762, 'examples_seen': 67616, 'step': 2450, 'algorithm': 'activity_selector'}
I0819 22:03:23.861193 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.854, current avg val score is 0.852, val scores are: activity_selector: 0.852
I0819 22:03:24.734976 135470064580096 run.py:692] Algo activity_selector step 2500 current loss 1.181307, current_train_items 68992.
I0819 22:03:24.746381 135470064580096 run.py:727] (val) algo activity_selector step 2500: {'selected': 0.8413001912045889, 'score': 0.8413001912045889, 'examples_seen': 68992, 'step': 2500, 'algorithm': 'activity_selector'}
I0819 22:03:24.746529 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.854, current avg val score is 0.841, val scores are: activity_selector: 0.841
I0819 22:03:25.631555 135470064580096 run.py:692] Algo activity_selector step 2550 current loss 1.167412, current_train_items 70368.
I0819 22:03:25.643939 135470064580096 run.py:727] (val) algo activity_selector step 2550: {'selected': 0.8235294117647058, 'score': 0.8235294117647058, 'examples_seen': 70368, 'step': 2550, 'algorithm': 'activity_selector'}
I0819 22:03:25.644099 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.854, current avg val score is 0.824, val scores are: activity_selector: 0.824
I0819 22:03:26.551723 135470064580096 run.py:692] Algo activity_selector step 2600 current loss 1.236992, current_train_items 71744.
I0819 22:03:26.563968 135470064580096 run.py:727] (val) algo activity_selector step 2600: {'selected': 0.8152380952380952, 'score': 0.8152380952380952, 'examples_seen': 71744, 'step': 2600, 'algorithm': 'activity_selector'}
I0819 22:03:26.564110 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.854, current avg val score is 0.815, val scores are: activity_selector: 0.815
I0819 22:03:27.436513 135470064580096 run.py:692] Algo activity_selector step 2650 current loss 1.096885, current_train_items 73120.
I0819 22:03:27.448144 135470064580096 run.py:727] (val) algo activity_selector step 2650: {'selected': 0.8491228070175437, 'score': 0.8491228070175437, 'examples_seen': 73120, 'step': 2650, 'algorithm': 'activity_selector'}
I0819 22:03:27.448290 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.854, current avg val score is 0.849, val scores are: activity_selector: 0.849
I0819 22:03:28.351783 135470064580096 run.py:692] Algo activity_selector step 2700 current loss 1.232050, current_train_items 74496.
I0819 22:03:28.363690 135470064580096 run.py:727] (val) algo activity_selector step 2700: {'selected': 0.8602150537634408, 'score': 0.8602150537634408, 'examples_seen': 74496, 'step': 2700, 'algorithm': 'activity_selector'}
I0819 22:03:28.363835 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.854, current avg val score is 0.860, val scores are: activity_selector: 0.860
I0819 22:03:29.276090 135470064580096 run.py:692] Algo activity_selector step 2750 current loss 1.340080, current_train_items 75872.
I0819 22:03:29.287844 135470064580096 run.py:727] (val) algo activity_selector step 2750: {'selected': 0.8190476190476189, 'score': 0.8190476190476189, 'examples_seen': 75872, 'step': 2750, 'algorithm': 'activity_selector'}
I0819 22:03:29.287991 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.860, current avg val score is 0.819, val scores are: activity_selector: 0.819
I0819 22:03:30.161728 135470064580096 run.py:692] Algo activity_selector step 2800 current loss 1.311577, current_train_items 77280.
I0819 22:03:30.173594 135470064580096 run.py:727] (val) algo activity_selector step 2800: {'selected': 0.8249027237354086, 'score': 0.8249027237354086, 'examples_seen': 77280, 'step': 2800, 'algorithm': 'activity_selector'}
I0819 22:03:30.173740 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.860, current avg val score is 0.825, val scores are: activity_selector: 0.825
I0819 22:03:31.080796 135470064580096 run.py:692] Algo activity_selector step 2850 current loss 1.460604, current_train_items 78624.
I0819 22:03:31.093076 135470064580096 run.py:727] (val) algo activity_selector step 2850: {'selected': 0.8576923076923078, 'score': 0.8576923076923078, 'examples_seen': 78624, 'step': 2850, 'algorithm': 'activity_selector'}
I0819 22:03:31.093233 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.860, current avg val score is 0.858, val scores are: activity_selector: 0.858
I0819 22:03:31.986917 135470064580096 run.py:692] Algo activity_selector step 2900 current loss 1.484478, current_train_items 80032.
I0819 22:03:31.999321 135470064580096 run.py:727] (val) algo activity_selector step 2900: {'selected': 0.8130671506352087, 'score': 0.8130671506352087, 'examples_seen': 80032, 'step': 2900, 'algorithm': 'activity_selector'}
I0819 22:03:31.999476 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.860, current avg val score is 0.813, val scores are: activity_selector: 0.813
I0819 22:03:32.894880 135470064580096 run.py:692] Algo activity_selector step 2950 current loss 1.452298, current_train_items 81408.
I0819 22:03:32.906381 135470064580096 run.py:727] (val) algo activity_selector step 2950: {'selected': 0.862348178137652, 'score': 0.862348178137652, 'examples_seen': 81408, 'step': 2950, 'algorithm': 'activity_selector'}
I0819 22:03:32.906539 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.860, current avg val score is 0.862, val scores are: activity_selector: 0.862
I0819 22:03:33.802086 135470064580096 run.py:692] Algo activity_selector step 3000 current loss 1.663172, current_train_items 82752.
I0819 22:03:33.813791 135470064580096 run.py:727] (val) algo activity_selector step 3000: {'selected': 0.8642447418738051, 'score': 0.8642447418738051, 'examples_seen': 82752, 'step': 3000, 'algorithm': 'activity_selector'}
I0819 22:03:33.813936 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.862, current avg val score is 0.864, val scores are: activity_selector: 0.864
I0819 22:03:34.729562 135470064580096 run.py:692] Algo activity_selector step 3050 current loss 0.984590, current_train_items 84160.
I0819 22:03:34.741464 135470064580096 run.py:727] (val) algo activity_selector step 3050: {'selected': 0.87890625, 'score': 0.87890625, 'examples_seen': 84160, 'step': 3050, 'algorithm': 'activity_selector'}
I0819 22:03:34.741613 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.864, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0819 22:03:35.629919 135470064580096 run.py:692] Algo activity_selector step 3100 current loss 1.198282, current_train_items 85536.
I0819 22:03:35.641557 135470064580096 run.py:727] (val) algo activity_selector step 3100: {'selected': 0.8342440801457194, 'score': 0.8342440801457194, 'examples_seen': 85536, 'step': 3100, 'algorithm': 'activity_selector'}
I0819 22:03:35.641706 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.879, current avg val score is 0.834, val scores are: activity_selector: 0.834
I0819 22:03:36.525908 135470064580096 run.py:692] Algo activity_selector step 3150 current loss 1.220924, current_train_items 86880.
I0819 22:03:36.537642 135470064580096 run.py:727] (val) algo activity_selector step 3150: {'selected': 0.8390410958904109, 'score': 0.8390410958904109, 'examples_seen': 86880, 'step': 3150, 'algorithm': 'activity_selector'}
I0819 22:03:36.537801 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.879, current avg val score is 0.839, val scores are: activity_selector: 0.839
I0819 22:03:37.451995 135470064580096 run.py:692] Algo activity_selector step 3200 current loss 1.225607, current_train_items 88288.
I0819 22:03:37.463568 135470064580096 run.py:727] (val) algo activity_selector step 3200: {'selected': 0.8179959100204499, 'score': 0.8179959100204499, 'examples_seen': 88288, 'step': 3200, 'algorithm': 'activity_selector'}
I0819 22:03:37.463717 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.879, current avg val score is 0.818, val scores are: activity_selector: 0.818
I0819 22:03:38.343229 135470064580096 run.py:692] Algo activity_selector step 3250 current loss 1.264118, current_train_items 89696.
I0819 22:03:38.354820 135470064580096 run.py:727] (val) algo activity_selector step 3250: {'selected': 0.8482490272373542, 'score': 0.8482490272373542, 'examples_seen': 89696, 'step': 3250, 'algorithm': 'activity_selector'}
I0819 22:03:38.354967 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.879, current avg val score is 0.848, val scores are: activity_selector: 0.848
I0819 22:03:39.260106 135470064580096 run.py:692] Algo activity_selector step 3300 current loss 1.082473, current_train_items 91040.
I0819 22:03:39.272369 135470064580096 run.py:727] (val) algo activity_selector step 3300: {'selected': 0.8560311284046693, 'score': 0.8560311284046693, 'examples_seen': 91040, 'step': 3300, 'algorithm': 'activity_selector'}
I0819 22:03:39.272522 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.879, current avg val score is 0.856, val scores are: activity_selector: 0.856
I0819 22:03:40.168824 135470064580096 run.py:692] Algo activity_selector step 3350 current loss 1.435273, current_train_items 92416.
I0819 22:03:40.180642 135470064580096 run.py:727] (val) algo activity_selector step 3350: {'selected': 0.8086785009861933, 'score': 0.8086785009861933, 'examples_seen': 92416, 'step': 3350, 'algorithm': 'activity_selector'}
I0819 22:03:40.180788 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.879, current avg val score is 0.809, val scores are: activity_selector: 0.809
I0819 22:03:41.068502 135470064580096 run.py:692] Algo activity_selector step 3400 current loss 1.312178, current_train_items 93824.
I0819 22:03:41.080414 135470064580096 run.py:727] (val) algo activity_selector step 3400: {'selected': 0.8505338078291815, 'score': 0.8505338078291815, 'examples_seen': 93824, 'step': 3400, 'algorithm': 'activity_selector'}
I0819 22:03:41.080574 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.879, current avg val score is 0.851, val scores are: activity_selector: 0.851
I0819 22:03:41.981894 135470064580096 run.py:692] Algo activity_selector step 3450 current loss 1.090037, current_train_items 95168.
I0819 22:03:41.993428 135470064580096 run.py:727] (val) algo activity_selector step 3450: {'selected': 0.8514056224899598, 'score': 0.8514056224899598, 'examples_seen': 95168, 'step': 3450, 'algorithm': 'activity_selector'}
I0819 22:03:41.993585 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.879, current avg val score is 0.851, val scores are: activity_selector: 0.851
I0819 22:03:42.877158 135470064580096 run.py:692] Algo activity_selector step 3500 current loss 1.088090, current_train_items 96544.
I0819 22:03:42.888974 135470064580096 run.py:727] (val) algo activity_selector step 3500: {'selected': 0.8669201520912547, 'score': 0.8669201520912547, 'examples_seen': 96544, 'step': 3500, 'algorithm': 'activity_selector'}
I0819 22:03:42.889136 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.879, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0819 22:03:43.787683 135470064580096 run.py:692] Algo activity_selector step 3550 current loss 0.912646, current_train_items 97952.
I0819 22:03:43.799552 135470064580096 run.py:727] (val) algo activity_selector step 3550: {'selected': 0.8509803921568627, 'score': 0.8509803921568627, 'examples_seen': 97952, 'step': 3550, 'algorithm': 'activity_selector'}
I0819 22:03:43.799709 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.879, current avg val score is 0.851, val scores are: activity_selector: 0.851
I0819 22:03:44.711585 135470064580096 run.py:692] Algo activity_selector step 3600 current loss 1.083455, current_train_items 99328.
I0819 22:03:44.723341 135470064580096 run.py:727] (val) algo activity_selector step 3600: {'selected': 0.853228962818004, 'score': 0.853228962818004, 'examples_seen': 99328, 'step': 3600, 'algorithm': 'activity_selector'}
I0819 22:03:44.723497 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.879, current avg val score is 0.853, val scores are: activity_selector: 0.853
I0819 22:03:45.615949 135470064580096 run.py:692] Algo activity_selector step 3650 current loss 1.174608, current_train_items 100704.
I0819 22:03:45.627347 135470064580096 run.py:727] (val) algo activity_selector step 3650: {'selected': 0.8660550458715597, 'score': 0.8660550458715597, 'examples_seen': 100704, 'step': 3650, 'algorithm': 'activity_selector'}
I0819 22:03:45.627498 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.879, current avg val score is 0.866, val scores are: activity_selector: 0.866
I0819 22:03:46.523820 135470064580096 run.py:692] Algo activity_selector step 3700 current loss 1.123733, current_train_items 102080.
I0819 22:03:46.536036 135470064580096 run.py:727] (val) algo activity_selector step 3700: {'selected': 0.8599605522682445, 'score': 0.8599605522682445, 'examples_seen': 102080, 'step': 3700, 'algorithm': 'activity_selector'}
I0819 22:03:46.536216 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.879, current avg val score is 0.860, val scores are: activity_selector: 0.860
I0819 22:03:47.438842 135470064580096 run.py:692] Algo activity_selector step 3750 current loss 1.370440, current_train_items 103456.
I0819 22:03:47.450804 135470064580096 run.py:727] (val) algo activity_selector step 3750: {'selected': 0.8581687612208259, 'score': 0.8581687612208259, 'examples_seen': 103456, 'step': 3750, 'algorithm': 'activity_selector'}
I0819 22:03:47.450950 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.879, current avg val score is 0.858, val scores are: activity_selector: 0.858
I0819 22:03:48.352203 135470064580096 run.py:692] Algo activity_selector step 3800 current loss 1.195077, current_train_items 104832.
I0819 22:03:48.363834 135470064580096 run.py:727] (val) algo activity_selector step 3800: {'selected': 0.8951310861423221, 'score': 0.8951310861423221, 'examples_seen': 104832, 'step': 3800, 'algorithm': 'activity_selector'}
I0819 22:03:48.363980 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.879, current avg val score is 0.895, val scores are: activity_selector: 0.895
I0819 22:03:49.257971 135470064580096 run.py:692] Algo activity_selector step 3850 current loss 1.586249, current_train_items 106208.
I0819 22:03:49.271039 135470064580096 run.py:727] (val) algo activity_selector step 3850: {'selected': 0.8107142857142857, 'score': 0.8107142857142857, 'examples_seen': 106208, 'step': 3850, 'algorithm': 'activity_selector'}
I0819 22:03:49.271195 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.895, current avg val score is 0.811, val scores are: activity_selector: 0.811
I0819 22:03:50.202124 135470064580096 run.py:692] Algo activity_selector step 3900 current loss 1.270381, current_train_items 107584.
I0819 22:03:50.213936 135470064580096 run.py:727] (val) algo activity_selector step 3900: {'selected': 0.8819444444444444, 'score': 0.8819444444444444, 'examples_seen': 107584, 'step': 3900, 'algorithm': 'activity_selector'}
I0819 22:03:50.214081 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.895, current avg val score is 0.882, val scores are: activity_selector: 0.882
I0819 22:03:51.095524 135470064580096 run.py:692] Algo activity_selector step 3950 current loss 0.918990, current_train_items 108992.
I0819 22:03:51.107384 135470064580096 run.py:727] (val) algo activity_selector step 3950: {'selected': 0.8714011516314779, 'score': 0.8714011516314779, 'examples_seen': 108992, 'step': 3950, 'algorithm': 'activity_selector'}
I0819 22:03:51.107531 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.895, current avg val score is 0.871, val scores are: activity_selector: 0.871
I0819 22:03:51.968173 135470064580096 run.py:692] Algo activity_selector step 4000 current loss 1.143426, current_train_items 110336.
I0819 22:03:51.979667 135470064580096 run.py:727] (val) algo activity_selector step 4000: {'selected': 0.8270377733598409, 'score': 0.8270377733598409, 'examples_seen': 110336, 'step': 4000, 'algorithm': 'activity_selector'}
I0819 22:03:51.979809 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.895, current avg val score is 0.827, val scores are: activity_selector: 0.827
I0819 22:03:52.876292 135470064580096 run.py:692] Algo activity_selector step 4050 current loss 1.192590, current_train_items 111712.
I0819 22:03:52.889439 135470064580096 run.py:727] (val) algo activity_selector step 4050: {'selected': 0.8749999999999999, 'score': 0.8749999999999999, 'examples_seen': 111712, 'step': 4050, 'algorithm': 'activity_selector'}
I0819 22:03:52.889585 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.895, current avg val score is 0.875, val scores are: activity_selector: 0.875
I0819 22:03:53.787281 135470064580096 run.py:692] Algo activity_selector step 4100 current loss 0.937526, current_train_items 113120.
I0819 22:03:53.799468 135470064580096 run.py:727] (val) algo activity_selector step 4100: {'selected': 0.8556521739130435, 'score': 0.8556521739130435, 'examples_seen': 113120, 'step': 4100, 'algorithm': 'activity_selector'}
I0819 22:03:53.799612 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.895, current avg val score is 0.856, val scores are: activity_selector: 0.856
I0819 22:03:54.673327 135470064580096 run.py:692] Algo activity_selector step 4150 current loss 1.258244, current_train_items 114496.
I0819 22:03:54.685334 135470064580096 run.py:727] (val) algo activity_selector step 4150: {'selected': 0.8670309653916211, 'score': 0.8670309653916211, 'examples_seen': 114496, 'step': 4150, 'algorithm': 'activity_selector'}
I0819 22:03:54.685486 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.895, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0819 22:03:55.557775 135470064580096 run.py:692] Algo activity_selector step 4200 current loss 1.475225, current_train_items 115840.
I0819 22:03:55.569681 135470064580096 run.py:727] (val) algo activity_selector step 4200: {'selected': 0.855513307984791, 'score': 0.855513307984791, 'examples_seen': 115840, 'step': 4200, 'algorithm': 'activity_selector'}
I0819 22:03:55.569827 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.895, current avg val score is 0.856, val scores are: activity_selector: 0.856
I0819 22:03:56.474822 135470064580096 run.py:692] Algo activity_selector step 4250 current loss 1.067616, current_train_items 117248.
I0819 22:03:56.487072 135470064580096 run.py:727] (val) algo activity_selector step 4250: {'selected': 0.8672897196261682, 'score': 0.8672897196261682, 'examples_seen': 117248, 'step': 4250, 'algorithm': 'activity_selector'}
I0819 22:03:56.487221 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.895, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0819 22:03:57.380990 135470064580096 run.py:692] Algo activity_selector step 4300 current loss 1.066944, current_train_items 118656.
I0819 22:03:57.392563 135470064580096 run.py:727] (val) algo activity_selector step 4300: {'selected': 0.9065255731922399, 'score': 0.9065255731922399, 'examples_seen': 118656, 'step': 4300, 'algorithm': 'activity_selector'}
I0819 22:03:57.392706 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.895, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0819 22:03:58.284578 135470064580096 run.py:692] Algo activity_selector step 4350 current loss 0.730790, current_train_items 119968.
I0819 22:03:58.295865 135470064580096 run.py:727] (val) algo activity_selector step 4350: {'selected': 0.8698884758364311, 'score': 0.8698884758364311, 'examples_seen': 119968, 'step': 4350, 'algorithm': 'activity_selector'}
I0819 22:03:58.296009 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.907, current avg val score is 0.870, val scores are: activity_selector: 0.870
I0819 22:03:59.198949 135470064580096 run.py:692] Algo activity_selector step 4400 current loss 1.133987, current_train_items 121376.
I0819 22:03:59.210779 135470064580096 run.py:727] (val) algo activity_selector step 4400: {'selected': 0.8888888888888888, 'score': 0.8888888888888888, 'examples_seen': 121376, 'step': 4400, 'algorithm': 'activity_selector'}
I0819 22:03:59.210926 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.907, current avg val score is 0.889, val scores are: activity_selector: 0.889
I0819 22:04:00.096959 135470064580096 run.py:692] Algo activity_selector step 4450 current loss 1.417757, current_train_items 122784.
I0819 22:04:00.108483 135470064580096 run.py:727] (val) algo activity_selector step 4450: {'selected': 0.8715083798882682, 'score': 0.8715083798882682, 'examples_seen': 122784, 'step': 4450, 'algorithm': 'activity_selector'}
I0819 22:04:00.108626 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.907, current avg val score is 0.872, val scores are: activity_selector: 0.872
I0819 22:04:00.977034 135470064580096 run.py:692] Algo activity_selector step 4500 current loss 1.167279, current_train_items 124128.
I0819 22:04:00.989017 135470064580096 run.py:727] (val) algo activity_selector step 4500: {'selected': 0.8827838827838828, 'score': 0.8827838827838828, 'examples_seen': 124128, 'step': 4500, 'algorithm': 'activity_selector'}
I0819 22:04:00.989168 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.907, current avg val score is 0.883, val scores are: activity_selector: 0.883
I0819 22:04:01.909285 135470064580096 run.py:692] Algo activity_selector step 4550 current loss 0.883361, current_train_items 125504.
I0819 22:04:01.921271 135470064580096 run.py:727] (val) algo activity_selector step 4550: {'selected': 0.8571428571428571, 'score': 0.8571428571428571, 'examples_seen': 125504, 'step': 4550, 'algorithm': 'activity_selector'}
I0819 22:04:01.921458 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.907, current avg val score is 0.857, val scores are: activity_selector: 0.857
I0819 22:04:02.825910 135470064580096 run.py:692] Algo activity_selector step 4600 current loss 0.937780, current_train_items 126912.
I0819 22:04:02.837618 135470064580096 run.py:727] (val) algo activity_selector step 4600: {'selected': 0.8712121212121212, 'score': 0.8712121212121212, 'examples_seen': 126912, 'step': 4600, 'algorithm': 'activity_selector'}
I0819 22:04:02.837773 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.907, current avg val score is 0.871, val scores are: activity_selector: 0.871
I0819 22:04:03.737647 135470064580096 run.py:692] Algo activity_selector step 4650 current loss 0.790128, current_train_items 128288.
I0819 22:04:03.748934 135470064580096 run.py:727] (val) algo activity_selector step 4650: {'selected': 0.9171075837742505, 'score': 0.9171075837742505, 'examples_seen': 128288, 'step': 4650, 'algorithm': 'activity_selector'}
I0819 22:04:03.749083 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.907, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0819 22:04:04.641758 135470064580096 run.py:692] Algo activity_selector step 4700 current loss 1.173691, current_train_items 129632.
I0819 22:04:04.653131 135470064580096 run.py:727] (val) algo activity_selector step 4700: {'selected': 0.8476357267950965, 'score': 0.8476357267950965, 'examples_seen': 129632, 'step': 4700, 'algorithm': 'activity_selector'}
I0819 22:04:04.653275 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.917, current avg val score is 0.848, val scores are: activity_selector: 0.848
I0819 22:04:05.555527 135470064580096 run.py:692] Algo activity_selector step 4750 current loss 1.125189, current_train_items 131040.
I0819 22:04:05.568469 135470064580096 run.py:727] (val) algo activity_selector step 4750: {'selected': 0.8763636363636363, 'score': 0.8763636363636363, 'examples_seen': 131040, 'step': 4750, 'algorithm': 'activity_selector'}
I0819 22:04:05.568619 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.917, current avg val score is 0.876, val scores are: activity_selector: 0.876
I0819 22:04:06.476640 135470064580096 run.py:692] Algo activity_selector step 4800 current loss 1.029076, current_train_items 132416.
I0819 22:04:06.488120 135470064580096 run.py:727] (val) algo activity_selector step 4800: {'selected': 0.8992805755395683, 'score': 0.8992805755395683, 'examples_seen': 132416, 'step': 4800, 'algorithm': 'activity_selector'}
I0819 22:04:06.488263 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.917, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0819 22:04:07.363789 135470064580096 run.py:692] Algo activity_selector step 4850 current loss 1.091736, current_train_items 133760.
I0819 22:04:07.375665 135470064580096 run.py:727] (val) algo activity_selector step 4850: {'selected': 0.8694214876033057, 'score': 0.8694214876033057, 'examples_seen': 133760, 'step': 4850, 'algorithm': 'activity_selector'}
I0819 22:04:07.375820 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.917, current avg val score is 0.869, val scores are: activity_selector: 0.869
I0819 22:04:08.273736 135470064580096 run.py:692] Algo activity_selector step 4900 current loss 0.787511, current_train_items 135168.
I0819 22:04:08.287987 135470064580096 run.py:727] (val) algo activity_selector step 4900: {'selected': 0.8677966101694916, 'score': 0.8677966101694916, 'examples_seen': 135168, 'step': 4900, 'algorithm': 'activity_selector'}
I0819 22:04:08.288132 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.917, current avg val score is 0.868, val scores are: activity_selector: 0.868
I0819 22:04:09.189773 135470064580096 run.py:692] Algo activity_selector step 4950 current loss 0.823210, current_train_items 136544.
I0819 22:04:09.201611 135470064580096 run.py:727] (val) algo activity_selector step 4950: {'selected': 0.8725099601593626, 'score': 0.8725099601593626, 'examples_seen': 136544, 'step': 4950, 'algorithm': 'activity_selector'}
I0819 22:04:09.201751 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.917, current avg val score is 0.873, val scores are: activity_selector: 0.873
I0819 22:04:10.097760 135470064580096 run.py:692] Algo activity_selector step 5000 current loss 1.040358, current_train_items 137952.
I0819 22:04:10.109776 135470064580096 run.py:727] (val) algo activity_selector step 5000: {'selected': 0.8701754385964914, 'score': 0.8701754385964914, 'examples_seen': 137952, 'step': 5000, 'algorithm': 'activity_selector'}
I0819 22:04:10.109920 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.917, current avg val score is 0.870, val scores are: activity_selector: 0.870
I0819 22:04:10.977146 135470064580096 run.py:692] Algo activity_selector step 5050 current loss 0.906211, current_train_items 139296.
I0819 22:04:10.989158 135470064580096 run.py:727] (val) algo activity_selector step 5050: {'selected': 0.8333333333333334, 'score': 0.8333333333333334, 'examples_seen': 139296, 'step': 5050, 'algorithm': 'activity_selector'}
I0819 22:04:10.989314 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.917, current avg val score is 0.833, val scores are: activity_selector: 0.833
I0819 22:04:11.904906 135470064580096 run.py:692] Algo activity_selector step 5100 current loss 1.077058, current_train_items 140672.
I0819 22:04:11.917248 135470064580096 run.py:727] (val) algo activity_selector step 5100: {'selected': 0.9197080291970803, 'score': 0.9197080291970803, 'examples_seen': 140672, 'step': 5100, 'algorithm': 'activity_selector'}
I0819 22:04:11.917400 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.917, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0819 22:04:12.836802 135470064580096 run.py:692] Algo activity_selector step 5150 current loss 1.055723, current_train_items 142080.
I0819 22:04:12.848481 135470064580096 run.py:727] (val) algo activity_selector step 5150: {'selected': 0.8555555555555556, 'score': 0.8555555555555556, 'examples_seen': 142080, 'step': 5150, 'algorithm': 'activity_selector'}
I0819 22:04:12.848639 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.856, val scores are: activity_selector: 0.856
I0819 22:04:13.710202 135470064580096 run.py:692] Algo activity_selector step 5200 current loss 1.059777, current_train_items 143424.
I0819 22:04:13.721782 135470064580096 run.py:727] (val) algo activity_selector step 5200: {'selected': 0.8549618320610687, 'score': 0.8549618320610687, 'examples_seen': 143424, 'step': 5200, 'algorithm': 'activity_selector'}
I0819 22:04:13.721926 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.855, val scores are: activity_selector: 0.855
I0819 22:04:14.622752 135470064580096 run.py:692] Algo activity_selector step 5250 current loss 0.887569, current_train_items 144800.
I0819 22:04:14.634451 135470064580096 run.py:727] (val) algo activity_selector step 5250: {'selected': 0.8920863309352518, 'score': 0.8920863309352518, 'examples_seen': 144800, 'step': 5250, 'algorithm': 'activity_selector'}
I0819 22:04:14.634597 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.892, val scores are: activity_selector: 0.892
I0819 22:04:15.539175 135470064580096 run.py:692] Algo activity_selector step 5300 current loss 0.983503, current_train_items 146208.
I0819 22:04:15.551199 135470064580096 run.py:727] (val) algo activity_selector step 5300: {'selected': 0.888888888888889, 'score': 0.888888888888889, 'examples_seen': 146208, 'step': 5300, 'algorithm': 'activity_selector'}
I0819 22:04:15.551345 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.889, val scores are: activity_selector: 0.889
I0819 22:04:16.417103 135470064580096 run.py:692] Algo activity_selector step 5350 current loss 1.110983, current_train_items 147616.
I0819 22:04:16.428694 135470064580096 run.py:727] (val) algo activity_selector step 5350: {'selected': 0.8779661016949153, 'score': 0.8779661016949153, 'examples_seen': 147616, 'step': 5350, 'algorithm': 'activity_selector'}
I0819 22:04:16.428838 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.878, val scores are: activity_selector: 0.878
I0819 22:04:17.344502 135470064580096 run.py:692] Algo activity_selector step 5400 current loss 1.142736, current_train_items 148928.
I0819 22:04:17.356540 135470064580096 run.py:727] (val) algo activity_selector step 5400: {'selected': 0.9007633587786259, 'score': 0.9007633587786259, 'examples_seen': 148928, 'step': 5400, 'algorithm': 'activity_selector'}
I0819 22:04:17.356688 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.901, val scores are: activity_selector: 0.901
I0819 22:04:18.278585 135470064580096 run.py:692] Algo activity_selector step 5450 current loss 1.211801, current_train_items 150336.
I0819 22:04:18.291501 135470064580096 run.py:727] (val) algo activity_selector step 5450: {'selected': 0.8864468864468864, 'score': 0.8864468864468864, 'examples_seen': 150336, 'step': 5450, 'algorithm': 'activity_selector'}
I0819 22:04:18.291705 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0819 22:04:19.189583 135470064580096 run.py:692] Algo activity_selector step 5500 current loss 0.951117, current_train_items 151744.
I0819 22:04:19.201038 135470064580096 run.py:727] (val) algo activity_selector step 5500: {'selected': 0.8840864440078586, 'score': 0.8840864440078586, 'examples_seen': 151744, 'step': 5500, 'algorithm': 'activity_selector'}
I0819 22:04:19.201201 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0819 22:04:20.080977 135470064580096 run.py:692] Algo activity_selector step 5550 current loss 1.073858, current_train_items 153056.
I0819 22:04:20.093263 135470064580096 run.py:727] (val) algo activity_selector step 5550: {'selected': 0.909433962264151, 'score': 0.909433962264151, 'examples_seen': 153056, 'step': 5550, 'algorithm': 'activity_selector'}
I0819 22:04:20.093435 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0819 22:04:21.015848 135470064580096 run.py:692] Algo activity_selector step 5600 current loss 0.634200, current_train_items 154464.
I0819 22:04:21.027871 135470064580096 run.py:727] (val) algo activity_selector step 5600: {'selected': 0.8795411089866157, 'score': 0.8795411089866157, 'examples_seen': 154464, 'step': 5600, 'algorithm': 'activity_selector'}
I0819 22:04:21.028043 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0819 22:04:21.927105 135470064580096 run.py:692] Algo activity_selector step 5650 current loss 0.741479, current_train_items 155872.
I0819 22:04:21.938834 135470064580096 run.py:727] (val) algo activity_selector step 5650: {'selected': 0.8454706927175843, 'score': 0.8454706927175843, 'examples_seen': 155872, 'step': 5650, 'algorithm': 'activity_selector'}
I0819 22:04:21.938992 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.845, val scores are: activity_selector: 0.845
I0819 22:04:22.814900 135470064580096 run.py:692] Algo activity_selector step 5700 current loss 1.028217, current_train_items 157216.
I0819 22:04:22.828481 135470064580096 run.py:727] (val) algo activity_selector step 5700: {'selected': 0.9054325955734406, 'score': 0.9054325955734406, 'examples_seen': 157216, 'step': 5700, 'algorithm': 'activity_selector'}
I0819 22:04:22.828628 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0819 22:04:23.740168 135470064580096 run.py:692] Algo activity_selector step 5750 current loss 0.944350, current_train_items 158592.
I0819 22:04:23.751878 135470064580096 run.py:727] (val) algo activity_selector step 5750: {'selected': 0.9063097514340345, 'score': 0.9063097514340345, 'examples_seen': 158592, 'step': 5750, 'algorithm': 'activity_selector'}
I0819 22:04:23.752026 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0819 22:04:24.648820 135470064580096 run.py:692] Algo activity_selector step 5800 current loss 0.808210, current_train_items 160000.
I0819 22:04:24.660304 135470064580096 run.py:727] (val) algo activity_selector step 5800: {'selected': 0.8677839851024208, 'score': 0.8677839851024208, 'examples_seen': 160000, 'step': 5800, 'algorithm': 'activity_selector'}
I0819 22:04:24.660461 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.868, val scores are: activity_selector: 0.868
I0819 22:04:25.593489 135470064580096 run.py:692] Algo activity_selector step 5850 current loss 1.046912, current_train_items 161376.
I0819 22:04:25.605689 135470064580096 run.py:727] (val) algo activity_selector step 5850: {'selected': 0.8957952468007313, 'score': 0.8957952468007313, 'examples_seen': 161376, 'step': 5850, 'algorithm': 'activity_selector'}
I0819 22:04:25.605834 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0819 22:04:26.489736 135470064580096 run.py:692] Algo activity_selector step 5900 current loss 0.730204, current_train_items 162720.
I0819 22:04:26.502169 135470064580096 run.py:727] (val) algo activity_selector step 5900: {'selected': 0.8901734104046243, 'score': 0.8901734104046243, 'examples_seen': 162720, 'step': 5900, 'algorithm': 'activity_selector'}
I0819 22:04:26.502328 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.890, val scores are: activity_selector: 0.890
I0819 22:04:27.407666 135470064580096 run.py:692] Algo activity_selector step 5950 current loss 0.717734, current_train_items 164128.
I0819 22:04:27.420111 135470064580096 run.py:727] (val) algo activity_selector step 5950: {'selected': 0.8893058161350844, 'score': 0.8893058161350844, 'examples_seen': 164128, 'step': 5950, 'algorithm': 'activity_selector'}
I0819 22:04:27.420259 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.889, val scores are: activity_selector: 0.889
I0819 22:04:28.332464 135470064580096 run.py:692] Algo activity_selector step 6000 current loss 0.865564, current_train_items 165504.
I0819 22:04:28.344367 135470064580096 run.py:727] (val) algo activity_selector step 6000: {'selected': 0.8897058823529411, 'score': 0.8897058823529411, 'examples_seen': 165504, 'step': 6000, 'algorithm': 'activity_selector'}
I0819 22:04:28.344523 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.890, val scores are: activity_selector: 0.890
I0819 22:04:29.218430 135470064580096 run.py:692] Algo activity_selector step 6050 current loss 1.087156, current_train_items 166880.
I0819 22:04:29.230592 135470064580096 run.py:727] (val) algo activity_selector step 6050: {'selected': 0.8897637795275589, 'score': 0.8897637795275589, 'examples_seen': 166880, 'step': 6050, 'algorithm': 'activity_selector'}
I0819 22:04:29.230737 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.890, val scores are: activity_selector: 0.890
I0819 22:04:30.125170 135470064580096 run.py:692] Algo activity_selector step 6100 current loss 1.029519, current_train_items 168256.
I0819 22:04:30.137271 135470064580096 run.py:727] (val) algo activity_selector step 6100: {'selected': 0.8846880907372402, 'score': 0.8846880907372402, 'examples_seen': 168256, 'step': 6100, 'algorithm': 'activity_selector'}
I0819 22:04:30.137424 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0819 22:04:31.041270 135470064580096 run.py:692] Algo activity_selector step 6150 current loss 1.146511, current_train_items 169632.
I0819 22:04:31.053149 135470064580096 run.py:727] (val) algo activity_selector step 6150: {'selected': 0.8446215139442231, 'score': 0.8446215139442231, 'examples_seen': 169632, 'step': 6150, 'algorithm': 'activity_selector'}
I0819 22:04:31.053295 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.845, val scores are: activity_selector: 0.845
I0819 22:04:31.940789 135470064580096 run.py:692] Algo activity_selector step 6200 current loss 1.530622, current_train_items 171040.
I0819 22:04:31.952780 135470064580096 run.py:727] (val) algo activity_selector step 6200: {'selected': 0.829981718464351, 'score': 0.829981718464351, 'examples_seen': 171040, 'step': 6200, 'algorithm': 'activity_selector'}
I0819 22:04:31.952923 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.830, val scores are: activity_selector: 0.830
I0819 22:04:32.826967 135470064580096 run.py:692] Algo activity_selector step 6250 current loss 1.043197, current_train_items 172384.
I0819 22:04:32.838919 135470064580096 run.py:727] (val) algo activity_selector step 6250: {'selected': 0.9189189189189189, 'score': 0.9189189189189189, 'examples_seen': 172384, 'step': 6250, 'algorithm': 'activity_selector'}
I0819 22:04:32.839065 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0819 22:04:33.735841 135470064580096 run.py:692] Algo activity_selector step 6300 current loss 0.815038, current_train_items 173760.
I0819 22:04:33.747709 135470064580096 run.py:727] (val) algo activity_selector step 6300: {'selected': 0.883720930232558, 'score': 0.883720930232558, 'examples_seen': 173760, 'step': 6300, 'algorithm': 'activity_selector'}
I0819 22:04:33.747855 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0819 22:04:34.659707 135470064580096 run.py:692] Algo activity_selector step 6350 current loss 0.742289, current_train_items 175168.
I0819 22:04:34.671989 135470064580096 run.py:727] (val) algo activity_selector step 6350: {'selected': 0.908745247148289, 'score': 0.908745247148289, 'examples_seen': 175168, 'step': 6350, 'algorithm': 'activity_selector'}
I0819 22:04:34.672135 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0819 22:04:35.528488 135470064580096 run.py:692] Algo activity_selector step 6400 current loss 0.896533, current_train_items 176544.
I0819 22:04:35.540256 135470064580096 run.py:727] (val) algo activity_selector step 6400: {'selected': 0.8913443830570903, 'score': 0.8913443830570903, 'examples_seen': 176544, 'step': 6400, 'algorithm': 'activity_selector'}
I0819 22:04:35.540425 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0819 22:04:36.446153 135470064580096 run.py:692] Algo activity_selector step 6450 current loss 0.720220, current_train_items 177888.
I0819 22:04:36.458393 135470064580096 run.py:727] (val) algo activity_selector step 6450: {'selected': 0.8754578754578756, 'score': 0.8754578754578756, 'examples_seen': 177888, 'step': 6450, 'algorithm': 'activity_selector'}
I0819 22:04:36.458539 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.875, val scores are: activity_selector: 0.875
I0819 22:04:37.372492 135470064580096 run.py:692] Algo activity_selector step 6500 current loss 0.622483, current_train_items 179296.
I0819 22:04:37.384087 135470064580096 run.py:727] (val) algo activity_selector step 6500: {'selected': 0.8673469387755103, 'score': 0.8673469387755103, 'examples_seen': 179296, 'step': 6500, 'algorithm': 'activity_selector'}
I0819 22:04:37.384231 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0819 22:04:38.255910 135470064580096 run.py:692] Algo activity_selector step 6550 current loss 0.930837, current_train_items 180672.
I0819 22:04:38.267408 135470064580096 run.py:727] (val) algo activity_selector step 6550: {'selected': 0.8511383537653241, 'score': 0.8511383537653241, 'examples_seen': 180672, 'step': 6550, 'algorithm': 'activity_selector'}
I0819 22:04:38.267551 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.851, val scores are: activity_selector: 0.851
I0819 22:04:39.160612 135470064580096 run.py:692] Algo activity_selector step 6600 current loss 0.979642, current_train_items 182016.
I0819 22:04:39.172141 135470064580096 run.py:727] (val) algo activity_selector step 6600: {'selected': 0.8651488616462346, 'score': 0.8651488616462346, 'examples_seen': 182016, 'step': 6600, 'algorithm': 'activity_selector'}
I0819 22:04:39.172287 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.865, val scores are: activity_selector: 0.865
I0819 22:04:40.090434 135470064580096 run.py:692] Algo activity_selector step 6650 current loss 1.092432, current_train_items 183424.
I0819 22:04:40.102290 135470064580096 run.py:727] (val) algo activity_selector step 6650: {'selected': 0.862453531598513, 'score': 0.862453531598513, 'examples_seen': 183424, 'step': 6650, 'algorithm': 'activity_selector'}
I0819 22:04:40.102446 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.862, val scores are: activity_selector: 0.862
I0819 22:04:41.002134 135470064580096 run.py:692] Algo activity_selector step 6700 current loss 0.698776, current_train_items 184832.
I0819 22:04:41.013744 135470064580096 run.py:727] (val) algo activity_selector step 6700: {'selected': 0.916504854368932, 'score': 0.916504854368932, 'examples_seen': 184832, 'step': 6700, 'algorithm': 'activity_selector'}
I0819 22:04:41.013889 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0819 22:04:41.891338 135470064580096 run.py:692] Algo activity_selector step 6750 current loss 0.723432, current_train_items 186176.
I0819 22:04:41.903285 135470064580096 run.py:727] (val) algo activity_selector step 6750: {'selected': 0.888468809073724, 'score': 0.888468809073724, 'examples_seen': 186176, 'step': 6750, 'algorithm': 'activity_selector'}
I0819 22:04:41.903459 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.888, val scores are: activity_selector: 0.888
I0819 22:04:42.831678 135470064580096 run.py:692] Algo activity_selector step 6800 current loss 0.906788, current_train_items 187552.
I0819 22:04:42.843823 135470064580096 run.py:727] (val) algo activity_selector step 6800: {'selected': 0.8535714285714285, 'score': 0.8535714285714285, 'examples_seen': 187552, 'step': 6800, 'algorithm': 'activity_selector'}
I0819 22:04:42.843970 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.854, val scores are: activity_selector: 0.854
I0819 22:04:43.747028 135470064580096 run.py:692] Algo activity_selector step 6850 current loss 0.941868, current_train_items 188960.
I0819 22:04:43.758816 135470064580096 run.py:727] (val) algo activity_selector step 6850: {'selected': 0.9107806691449813, 'score': 0.9107806691449813, 'examples_seen': 188960, 'step': 6850, 'algorithm': 'activity_selector'}
I0819 22:04:43.758966 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0819 22:04:44.649169 135470064580096 run.py:692] Algo activity_selector step 6900 current loss 0.799699, current_train_items 190304.
I0819 22:04:44.661199 135470064580096 run.py:727] (val) algo activity_selector step 6900: {'selected': 0.9165048543689319, 'score': 0.9165048543689319, 'examples_seen': 190304, 'step': 6900, 'algorithm': 'activity_selector'}
I0819 22:04:44.661345 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0819 22:04:45.558571 135470064580096 run.py:692] Algo activity_selector step 6950 current loss 0.548303, current_train_items 191680.
I0819 22:04:45.569988 135470064580096 run.py:727] (val) algo activity_selector step 6950: {'selected': 0.9087378640776699, 'score': 0.9087378640776699, 'examples_seen': 191680, 'step': 6950, 'algorithm': 'activity_selector'}
I0819 22:04:45.570136 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0819 22:04:46.467717 135470064580096 run.py:692] Algo activity_selector step 7000 current loss 0.861674, current_train_items 193088.
I0819 22:04:46.479636 135470064580096 run.py:727] (val) algo activity_selector step 7000: {'selected': 0.871401151631478, 'score': 0.871401151631478, 'examples_seen': 193088, 'step': 7000, 'algorithm': 'activity_selector'}
I0819 22:04:46.479780 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.871, val scores are: activity_selector: 0.871
I0819 22:04:47.375729 135470064580096 run.py:692] Algo activity_selector step 7050 current loss 0.763454, current_train_items 194464.
I0819 22:04:47.387480 135470064580096 run.py:727] (val) algo activity_selector step 7050: {'selected': 0.8936170212765957, 'score': 0.8936170212765957, 'examples_seen': 194464, 'step': 7050, 'algorithm': 'activity_selector'}
I0819 22:04:47.387628 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0819 22:04:48.285104 135470064580096 run.py:692] Algo activity_selector step 7100 current loss 0.633701, current_train_items 195840.
I0819 22:04:48.297298 135470064580096 run.py:727] (val) algo activity_selector step 7100: {'selected': 0.9100529100529101, 'score': 0.9100529100529101, 'examples_seen': 195840, 'step': 7100, 'algorithm': 'activity_selector'}
I0819 22:04:48.297482 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0819 22:04:49.182312 135470064580096 run.py:692] Algo activity_selector step 7150 current loss 0.929137, current_train_items 197216.
I0819 22:04:49.194051 135470064580096 run.py:727] (val) algo activity_selector step 7150: {'selected': 0.895910780669145, 'score': 0.895910780669145, 'examples_seen': 197216, 'step': 7150, 'algorithm': 'activity_selector'}
I0819 22:04:49.194200 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.920, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0819 22:04:50.103855 135470064580096 run.py:692] Algo activity_selector step 7200 current loss 0.775258, current_train_items 198592.
I0819 22:04:50.116496 135470064580096 run.py:727] (val) algo activity_selector step 7200: {'selected': 0.9348659003831418, 'score': 0.9348659003831418, 'examples_seen': 198592, 'step': 7200, 'algorithm': 'activity_selector'}
I0819 22:04:50.116642 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.920, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0819 22:04:51.013104 135470064580096 run.py:692] Algo activity_selector step 7250 current loss 1.008549, current_train_items 199968.
I0819 22:04:51.024818 135470064580096 run.py:727] (val) algo activity_selector step 7250: {'selected': 0.8971631205673759, 'score': 0.8971631205673759, 'examples_seen': 199968, 'step': 7250, 'algorithm': 'activity_selector'}
I0819 22:04:51.024968 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.935, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0819 22:04:51.913156 135470064580096 run.py:692] Algo activity_selector step 7300 current loss 1.243852, current_train_items 201344.
I0819 22:04:51.924767 135470064580096 run.py:727] (val) algo activity_selector step 7300: {'selected': 0.8704453441295547, 'score': 0.8704453441295547, 'examples_seen': 201344, 'step': 7300, 'algorithm': 'activity_selector'}
I0819 22:04:51.924913 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.935, current avg val score is 0.870, val scores are: activity_selector: 0.870
I0819 22:04:52.849843 135470064580096 run.py:692] Algo activity_selector step 7350 current loss 0.903095, current_train_items 202720.
I0819 22:04:52.861629 135470064580096 run.py:727] (val) algo activity_selector step 7350: {'selected': 0.9023437500000001, 'score': 0.9023437500000001, 'examples_seen': 202720, 'step': 7350, 'algorithm': 'activity_selector'}
I0819 22:04:52.861775 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.935, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0819 22:04:53.752695 135470064580096 run.py:692] Algo activity_selector step 7400 current loss 0.814341, current_train_items 204096.
I0819 22:04:53.764980 135470064580096 run.py:727] (val) algo activity_selector step 7400: {'selected': 0.8893058161350845, 'score': 0.8893058161350845, 'examples_seen': 204096, 'step': 7400, 'algorithm': 'activity_selector'}
I0819 22:04:53.765125 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.935, current avg val score is 0.889, val scores are: activity_selector: 0.889
I0819 22:04:54.646124 135470064580096 run.py:692] Algo activity_selector step 7450 current loss 0.924682, current_train_items 205504.
I0819 22:04:54.658002 135470064580096 run.py:727] (val) algo activity_selector step 7450: {'selected': 0.895575221238938, 'score': 0.895575221238938, 'examples_seen': 205504, 'step': 7450, 'algorithm': 'activity_selector'}
I0819 22:04:54.658149 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.935, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0819 22:04:55.554193 135470064580096 run.py:692] Algo activity_selector step 7500 current loss 0.530609, current_train_items 206848.
I0819 22:04:55.566263 135470064580096 run.py:727] (val) algo activity_selector step 7500: {'selected': 0.8774703557312253, 'score': 0.8774703557312253, 'examples_seen': 206848, 'step': 7500, 'algorithm': 'activity_selector'}
I0819 22:04:55.566428 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.935, current avg val score is 0.877, val scores are: activity_selector: 0.877
I0819 22:04:56.473362 135470064580096 run.py:692] Algo activity_selector step 7550 current loss 0.646464, current_train_items 208256.
I0819 22:04:56.486837 135470064580096 run.py:727] (val) algo activity_selector step 7550: {'selected': 0.8661417322834646, 'score': 0.8661417322834646, 'examples_seen': 208256, 'step': 7550, 'algorithm': 'activity_selector'}
I0819 22:04:56.486985 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.935, current avg val score is 0.866, val scores are: activity_selector: 0.866
I0819 22:04:57.366396 135470064580096 run.py:692] Algo activity_selector step 7600 current loss 0.720669, current_train_items 209632.
I0819 22:04:57.377808 135470064580096 run.py:727] (val) algo activity_selector step 7600: {'selected': 0.9274336283185841, 'score': 0.9274336283185841, 'examples_seen': 209632, 'step': 7600, 'algorithm': 'activity_selector'}
I0819 22:04:57.377956 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.935, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0819 22:04:58.258958 135470064580096 run.py:692] Algo activity_selector step 7650 current loss 0.998366, current_train_items 210976.
I0819 22:04:58.271365 135470064580096 run.py:727] (val) algo activity_selector step 7650: {'selected': 0.8816793893129772, 'score': 0.8816793893129772, 'examples_seen': 210976, 'step': 7650, 'algorithm': 'activity_selector'}
I0819 22:04:58.271519 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.935, current avg val score is 0.882, val scores are: activity_selector: 0.882
I0819 22:04:59.184848 135470064580096 run.py:692] Algo activity_selector step 7700 current loss 0.810693, current_train_items 212384.
I0819 22:04:59.199023 135470064580096 run.py:727] (val) algo activity_selector step 7700: {'selected': 0.9067641681901281, 'score': 0.9067641681901281, 'examples_seen': 212384, 'step': 7700, 'algorithm': 'activity_selector'}
I0819 22:04:59.199173 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.935, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0819 22:05:00.136537 135470064580096 run.py:692] Algo activity_selector step 7750 current loss 1.098890, current_train_items 213760.
I0819 22:05:00.148863 135470064580096 run.py:727] (val) algo activity_selector step 7750: {'selected': 0.890595009596929, 'score': 0.890595009596929, 'examples_seen': 213760, 'step': 7750, 'algorithm': 'activity_selector'}
I0819 22:05:00.149011 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.935, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0819 22:05:01.068710 135470064580096 run.py:692] Algo activity_selector step 7800 current loss 0.869250, current_train_items 215136.
I0819 22:05:01.080119 135470064580096 run.py:727] (val) algo activity_selector step 7800: {'selected': 0.893854748603352, 'score': 0.893854748603352, 'examples_seen': 215136, 'step': 7800, 'algorithm': 'activity_selector'}
I0819 22:05:01.080265 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.935, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0819 22:05:01.984807 135470064580096 run.py:692] Algo activity_selector step 7850 current loss 0.858513, current_train_items 216512.
I0819 22:05:01.996669 135470064580096 run.py:727] (val) algo activity_selector step 7850: {'selected': 0.9050279329608939, 'score': 0.9050279329608939, 'examples_seen': 216512, 'step': 7850, 'algorithm': 'activity_selector'}
I0819 22:05:01.996816 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.935, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0819 22:05:02.882854 135470064580096 run.py:692] Algo activity_selector step 7900 current loss 0.631721, current_train_items 217920.
I0819 22:05:02.894809 135470064580096 run.py:727] (val) algo activity_selector step 7900: {'selected': 0.9084507042253521, 'score': 0.9084507042253521, 'examples_seen': 217920, 'step': 7900, 'algorithm': 'activity_selector'}
I0819 22:05:02.894997 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.935, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0819 22:05:03.794670 135470064580096 run.py:692] Algo activity_selector step 7950 current loss 0.697539, current_train_items 219264.
I0819 22:05:03.806368 135470064580096 run.py:727] (val) algo activity_selector step 7950: {'selected': 0.922242314647378, 'score': 0.922242314647378, 'examples_seen': 219264, 'step': 7950, 'algorithm': 'activity_selector'}
I0819 22:05:03.806519 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.935, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0819 22:05:04.697836 135470064580096 run.py:692] Algo activity_selector step 8000 current loss 0.720023, current_train_items 220640.
I0819 22:05:04.709460 135470064580096 run.py:727] (val) algo activity_selector step 8000: {'selected': 0.8789571694599627, 'score': 0.8789571694599627, 'examples_seen': 220640, 'step': 8000, 'algorithm': 'activity_selector'}
I0819 22:05:04.709607 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.935, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0819 22:05:05.626073 135470064580096 run.py:692] Algo activity_selector step 8050 current loss 0.782384, current_train_items 222048.
I0819 22:05:05.638123 135470064580096 run.py:727] (val) algo activity_selector step 8050: {'selected': 0.8850174216027874, 'score': 0.8850174216027874, 'examples_seen': 222048, 'step': 8050, 'algorithm': 'activity_selector'}
I0819 22:05:05.638288 135470064580096 run.py:748] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0819 22:05:06.543022 135470064580096 run.py:692] Algo activity_selector step 8100 current loss 1.131604, current_train_items 223392.
I0819 22:05:06.555241 135470064580096 run.py:727] (val) algo activity_selector step 8100: {'selected': 0.9048543689320389, 'score': 0.9048543689320389, 'examples_seen': 223392, 'step': 8100, 'algorithm': 'activity_selector'}
I0819 22:05:06.555393 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.885, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0819 22:05:07.469087 135470064580096 run.py:692] Algo activity_selector step 8150 current loss 0.638656, current_train_items 224800.
I0819 22:05:07.481790 135470064580096 run.py:727] (val) algo activity_selector step 8150: {'selected': 0.8969258589511755, 'score': 0.8969258589511755, 'examples_seen': 224800, 'step': 8150, 'algorithm': 'activity_selector'}
I0819 22:05:07.482002 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.905, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0819 22:05:08.380372 135470064580096 run.py:692] Algo activity_selector step 8200 current loss 0.782269, current_train_items 226176.
I0819 22:05:08.392228 135470064580096 run.py:727] (val) algo activity_selector step 8200: {'selected': 0.8955223880597015, 'score': 0.8955223880597015, 'examples_seen': 226176, 'step': 8200, 'algorithm': 'activity_selector'}
I0819 22:05:08.392373 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.905, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0819 22:05:09.285887 135470064580096 run.py:692] Algo activity_selector step 8250 current loss 0.639215, current_train_items 227520.
I0819 22:05:09.298543 135470064580096 run.py:727] (val) algo activity_selector step 8250: {'selected': 0.9485294117647058, 'score': 0.9485294117647058, 'examples_seen': 227520, 'step': 8250, 'algorithm': 'activity_selector'}
I0819 22:05:09.298690 135470064580096 run.py:748] Checkpointing best model, best avg val score was 0.905, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0819 22:05:10.219456 135470064580096 run.py:692] Algo activity_selector step 8300 current loss 0.691753, current_train_items 228928.
I0819 22:05:10.230911 135470064580096 run.py:727] (val) algo activity_selector step 8300: {'selected': 0.8846153846153846, 'score': 0.8846153846153846, 'examples_seen': 228928, 'step': 8300, 'algorithm': 'activity_selector'}
I0819 22:05:10.231058 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0819 22:05:11.118180 135470064580096 run.py:692] Algo activity_selector step 8350 current loss 0.949072, current_train_items 230304.
I0819 22:05:11.130087 135470064580096 run.py:727] (val) algo activity_selector step 8350: {'selected': 0.9107468123861566, 'score': 0.9107468123861566, 'examples_seen': 230304, 'step': 8350, 'algorithm': 'activity_selector'}
I0819 22:05:11.130230 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0819 22:05:12.040961 135470064580096 run.py:692] Algo activity_selector step 8400 current loss 0.693985, current_train_items 231680.
I0819 22:05:12.052705 135470064580096 run.py:727] (val) algo activity_selector step 8400: {'selected': 0.8852459016393444, 'score': 0.8852459016393444, 'examples_seen': 231680, 'step': 8400, 'algorithm': 'activity_selector'}
I0819 22:05:12.052849 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0819 22:05:12.950208 135470064580096 run.py:692] Algo activity_selector step 8450 current loss 1.015624, current_train_items 233056.
I0819 22:05:12.961880 135470064580096 run.py:727] (val) algo activity_selector step 8450: {'selected': 0.8333333333333333, 'score': 0.8333333333333333, 'examples_seen': 233056, 'step': 8450, 'algorithm': 'activity_selector'}
I0819 22:05:12.962045 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.833, val scores are: activity_selector: 0.833
I0819 22:05:13.842731 135470064580096 run.py:692] Algo activity_selector step 8500 current loss 1.013128, current_train_items 234464.
I0819 22:05:13.854153 135470064580096 run.py:727] (val) algo activity_selector step 8500: {'selected': 0.8484848484848485, 'score': 0.8484848484848485, 'examples_seen': 234464, 'step': 8500, 'algorithm': 'activity_selector'}
I0819 22:05:13.854299 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.848, val scores are: activity_selector: 0.848
I0819 22:05:14.763455 135470064580096 run.py:692] Algo activity_selector step 8550 current loss 0.633542, current_train_items 235808.
I0819 22:05:14.775241 135470064580096 run.py:727] (val) algo activity_selector step 8550: {'selected': 0.9377431906614786, 'score': 0.9377431906614786, 'examples_seen': 235808, 'step': 8550, 'algorithm': 'activity_selector'}
I0819 22:05:14.775393 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0819 22:05:15.655137 135470064580096 run.py:692] Algo activity_selector step 8600 current loss 0.699172, current_train_items 237184.
I0819 22:05:15.666397 135470064580096 run.py:727] (val) algo activity_selector step 8600: {'selected': 0.8867562380038387, 'score': 0.8867562380038387, 'examples_seen': 237184, 'step': 8600, 'algorithm': 'activity_selector'}
I0819 22:05:15.666541 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.887, val scores are: activity_selector: 0.887
I0819 22:05:16.560711 135470064580096 run.py:692] Algo activity_selector step 8650 current loss 1.087934, current_train_items 238592.
I0819 22:05:16.574699 135470064580096 run.py:727] (val) algo activity_selector step 8650: {'selected': 0.8752399232245681, 'score': 0.8752399232245681, 'examples_seen': 238592, 'step': 8650, 'algorithm': 'activity_selector'}
I0819 22:05:16.574856 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.875, val scores are: activity_selector: 0.875
I0819 22:05:17.454658 135470064580096 run.py:692] Algo activity_selector step 8700 current loss 0.743216, current_train_items 239936.
I0819 22:05:17.466052 135470064580096 run.py:727] (val) algo activity_selector step 8700: {'selected': 0.8710280373831776, 'score': 0.8710280373831776, 'examples_seen': 239936, 'step': 8700, 'algorithm': 'activity_selector'}
I0819 22:05:17.466204 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.871, val scores are: activity_selector: 0.871
I0819 22:05:18.356393 135470064580096 run.py:692] Algo activity_selector step 8750 current loss 0.607601, current_train_items 241344.
I0819 22:05:18.368304 135470064580096 run.py:727] (val) algo activity_selector step 8750: {'selected': 0.8981818181818182, 'score': 0.8981818181818182, 'examples_seen': 241344, 'step': 8750, 'algorithm': 'activity_selector'}
I0819 22:05:18.368456 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0819 22:05:19.271060 135470064580096 run.py:692] Algo activity_selector step 8800 current loss 0.693829, current_train_items 242720.
I0819 22:05:19.282944 135470064580096 run.py:727] (val) algo activity_selector step 8800: {'selected': 0.8802946593001841, 'score': 0.8802946593001841, 'examples_seen': 242720, 'step': 8800, 'algorithm': 'activity_selector'}
I0819 22:05:19.283088 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0819 22:05:20.166423 135470064580096 run.py:692] Algo activity_selector step 8850 current loss 0.785565, current_train_items 244096.
I0819 22:05:20.177553 135470064580096 run.py:727] (val) algo activity_selector step 8850: {'selected': 0.9158878504672898, 'score': 0.9158878504672898, 'examples_seen': 244096, 'step': 8850, 'algorithm': 'activity_selector'}
I0819 22:05:20.177694 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.916, val scores are: activity_selector: 0.916
I0819 22:05:21.084094 135470064580096 run.py:692] Algo activity_selector step 8900 current loss 0.674379, current_train_items 245472.
I0819 22:05:21.095589 135470064580096 run.py:727] (val) algo activity_selector step 8900: {'selected': 0.9023941068139963, 'score': 0.9023941068139963, 'examples_seen': 245472, 'step': 8900, 'algorithm': 'activity_selector'}
I0819 22:05:21.095732 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0819 22:05:21.971035 135470064580096 run.py:692] Algo activity_selector step 8950 current loss 0.614516, current_train_items 246848.
I0819 22:05:21.985086 135470064580096 run.py:727] (val) algo activity_selector step 8950: {'selected': 0.9144981412639405, 'score': 0.9144981412639405, 'examples_seen': 246848, 'step': 8950, 'algorithm': 'activity_selector'}
I0819 22:05:21.985232 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0819 22:05:22.890449 135470064580096 run.py:692] Algo activity_selector step 9000 current loss 0.978134, current_train_items 248224.
I0819 22:05:22.901621 135470064580096 run.py:727] (val) algo activity_selector step 9000: {'selected': 0.9101338432122371, 'score': 0.9101338432122371, 'examples_seen': 248224, 'step': 9000, 'algorithm': 'activity_selector'}
I0819 22:05:22.901767 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0819 22:05:23.792900 135470064580096 run.py:692] Algo activity_selector step 9050 current loss 0.821489, current_train_items 249600.
I0819 22:05:23.804969 135470064580096 run.py:727] (val) algo activity_selector step 9050: {'selected': 0.9031007751937984, 'score': 0.9031007751937984, 'examples_seen': 249600, 'step': 9050, 'algorithm': 'activity_selector'}
I0819 22:05:23.805113 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.903, val scores are: activity_selector: 0.903
I0819 22:05:24.673988 135470064580096 run.py:692] Algo activity_selector step 9100 current loss 0.635688, current_train_items 250976.
I0819 22:05:24.685461 135470064580096 run.py:727] (val) algo activity_selector step 9100: {'selected': 0.895910780669145, 'score': 0.895910780669145, 'examples_seen': 250976, 'step': 9100, 'algorithm': 'activity_selector'}
I0819 22:05:24.685604 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0819 22:05:25.589756 135470064580096 run.py:692] Algo activity_selector step 9150 current loss 0.633213, current_train_items 252352.
I0819 22:05:25.600866 135470064580096 run.py:727] (val) algo activity_selector step 9150: {'selected': 0.9242424242424241, 'score': 0.9242424242424241, 'examples_seen': 252352, 'step': 9150, 'algorithm': 'activity_selector'}
I0819 22:05:25.601012 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0819 22:05:26.486688 135470064580096 run.py:692] Algo activity_selector step 9200 current loss 0.719509, current_train_items 253760.
I0819 22:05:26.499029 135470064580096 run.py:727] (val) algo activity_selector step 9200: {'selected': 0.8913043478260869, 'score': 0.8913043478260869, 'examples_seen': 253760, 'step': 9200, 'algorithm': 'activity_selector'}
I0819 22:05:26.499179 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0819 22:05:27.397475 135470064580096 run.py:692] Algo activity_selector step 9250 current loss 0.724966, current_train_items 255136.
I0819 22:05:27.409858 135470064580096 run.py:727] (val) algo activity_selector step 9250: {'selected': 0.8900709219858156, 'score': 0.8900709219858156, 'examples_seen': 255136, 'step': 9250, 'algorithm': 'activity_selector'}
I0819 22:05:27.410005 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.890, val scores are: activity_selector: 0.890
I0819 22:05:28.294006 135470064580096 run.py:692] Algo activity_selector step 9300 current loss 0.479339, current_train_items 256480.
I0819 22:05:28.306434 135470064580096 run.py:727] (val) algo activity_selector step 9300: {'selected': 0.8645640074211502, 'score': 0.8645640074211502, 'examples_seen': 256480, 'step': 9300, 'algorithm': 'activity_selector'}
I0819 22:05:28.306580 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.865, val scores are: activity_selector: 0.865
I0819 22:05:29.213575 135470064580096 run.py:692] Algo activity_selector step 9350 current loss 1.198426, current_train_items 257888.
I0819 22:05:29.225113 135470064580096 run.py:727] (val) algo activity_selector step 9350: {'selected': 0.8623548922056384, 'score': 0.8623548922056384, 'examples_seen': 257888, 'step': 9350, 'algorithm': 'activity_selector'}
I0819 22:05:29.225269 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.862, val scores are: activity_selector: 0.862
I0819 22:05:30.122743 135470064580096 run.py:692] Algo activity_selector step 9400 current loss 0.601482, current_train_items 259264.
I0819 22:05:30.134764 135470064580096 run.py:727] (val) algo activity_selector step 9400: {'selected': 0.8735632183908046, 'score': 0.8735632183908046, 'examples_seen': 259264, 'step': 9400, 'algorithm': 'activity_selector'}
I0819 22:05:30.134922 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.874, val scores are: activity_selector: 0.874
I0819 22:05:31.016880 135470064580096 run.py:692] Algo activity_selector step 9450 current loss 0.689861, current_train_items 260608.
I0819 22:05:31.028604 135470064580096 run.py:727] (val) algo activity_selector step 9450: {'selected': 0.9246031746031746, 'score': 0.9246031746031746, 'examples_seen': 260608, 'step': 9450, 'algorithm': 'activity_selector'}
I0819 22:05:31.028747 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0819 22:05:31.962820 135470064580096 run.py:692] Algo activity_selector step 9500 current loss 0.657042, current_train_items 262016.
I0819 22:05:31.974339 135470064580096 run.py:727] (val) algo activity_selector step 9500: {'selected': 0.8860759493670887, 'score': 0.8860759493670887, 'examples_seen': 262016, 'step': 9500, 'algorithm': 'activity_selector'}
I0819 22:05:31.974494 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0819 22:05:32.847780 135470064580096 run.py:692] Algo activity_selector step 9550 current loss 0.650546, current_train_items 263424.
I0819 22:05:32.859518 135470064580096 run.py:727] (val) algo activity_selector step 9550: {'selected': 0.8649706457925637, 'score': 0.8649706457925637, 'examples_seen': 263424, 'step': 9550, 'algorithm': 'activity_selector'}
I0819 22:05:32.859663 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.865, val scores are: activity_selector: 0.865
I0819 22:05:33.747010 135470064580096 run.py:692] Algo activity_selector step 9600 current loss 0.813486, current_train_items 264768.
I0819 22:05:33.758745 135470064580096 run.py:727] (val) algo activity_selector step 9600: {'selected': 0.9187145557655955, 'score': 0.9187145557655955, 'examples_seen': 264768, 'step': 9600, 'algorithm': 'activity_selector'}
I0819 22:05:33.758891 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0819 22:05:34.674272 135470064580096 run.py:692] Algo activity_selector step 9650 current loss 0.649750, current_train_items 266144.
I0819 22:05:34.685658 135470064580096 run.py:727] (val) algo activity_selector step 9650: {'selected': 0.9227871939736347, 'score': 0.9227871939736347, 'examples_seen': 266144, 'step': 9650, 'algorithm': 'activity_selector'}
I0819 22:05:34.685803 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.923, val scores are: activity_selector: 0.923
I0819 22:05:35.583282 135470064580096 run.py:692] Algo activity_selector step 9700 current loss 0.737979, current_train_items 267552.
I0819 22:05:35.594710 135470064580096 run.py:727] (val) algo activity_selector step 9700: {'selected': 0.9222222222222222, 'score': 0.9222222222222222, 'examples_seen': 267552, 'step': 9700, 'algorithm': 'activity_selector'}
I0819 22:05:35.594858 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0819 22:05:36.492236 135470064580096 run.py:692] Algo activity_selector step 9750 current loss 0.695573, current_train_items 268896.
I0819 22:05:36.504033 135470064580096 run.py:727] (val) algo activity_selector step 9750: {'selected': 0.9359223300970874, 'score': 0.9359223300970874, 'examples_seen': 268896, 'step': 9750, 'algorithm': 'activity_selector'}
I0819 22:05:36.504179 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0819 22:05:37.391630 135470064580096 run.py:692] Algo activity_selector step 9800 current loss 0.777615, current_train_items 270272.
I0819 22:05:37.404069 135470064580096 run.py:727] (val) algo activity_selector step 9800: {'selected': 0.9176470588235294, 'score': 0.9176470588235294, 'examples_seen': 270272, 'step': 9800, 'algorithm': 'activity_selector'}
I0819 22:05:37.404213 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.918, val scores are: activity_selector: 0.918
I0819 22:05:38.303180 135470064580096 run.py:692] Algo activity_selector step 9850 current loss 0.782096, current_train_items 271680.
I0819 22:05:38.314644 135470064580096 run.py:727] (val) algo activity_selector step 9850: {'selected': 0.9134948096885813, 'score': 0.9134948096885813, 'examples_seen': 271680, 'step': 9850, 'algorithm': 'activity_selector'}
I0819 22:05:38.314788 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0819 22:05:39.210837 135470064580096 run.py:692] Algo activity_selector step 9900 current loss 0.665068, current_train_items 273056.
I0819 22:05:39.222541 135470064580096 run.py:727] (val) algo activity_selector step 9900: {'selected': 0.9259962049335863, 'score': 0.9259962049335863, 'examples_seen': 273056, 'step': 9900, 'algorithm': 'activity_selector'}
I0819 22:05:39.222687 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0819 22:05:40.115662 135470064580096 run.py:692] Algo activity_selector step 9950 current loss 0.999159, current_train_items 274400.
I0819 22:05:40.127585 135470064580096 run.py:727] (val) algo activity_selector step 9950: {'selected': 0.8910505836575875, 'score': 0.8910505836575875, 'examples_seen': 274400, 'step': 9950, 'algorithm': 'activity_selector'}
I0819 22:05:40.127729 135470064580096 run.py:751] Not saving new best model, best avg val score was 0.949, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0819 22:05:41.026282 135470064580096 run.py:757] Restoring best model from checkpoint...
I0819 22:05:43.020794 135470064580096 run.py:772] (test) algo activity_selector : {'selected': 0.7174603174603175, 'score': 0.7174603174603175, 'examples_seen': 275776, 'step': 10000, 'algorithm': 'activity_selector'}
I0819 22:05:43.020911 135470064580096 run.py:774] Done!
