I0207 18:33:48.736445 134948952962560 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0207 18:33:48.740643 134948952962560 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0207 18:33:49.995322 134948952962560 run.py:462] Model: f9 ['activity_selector']
I0207 18:33:49.995464 134948952962560 run.py:464] algorithms ['activity_selector']
I0207 18:33:49.995696 134948952962560 run.py:465] train_lengths ['4', '7', '11', '13', '16']
I0207 18:33:49.995750 134948952962560 run.py:466] train_batch_size 16
I0207 18:33:49.995928 134948952962560 run.py:467] val_batch_size 16
I0207 18:33:49.995975 134948952962560 run.py:468] test_batch_size 16
I0207 18:33:49.996043 134948952962560 run.py:469] chunked_training True
I0207 18:33:49.996299 134948952962560 run.py:470] chunk_length 16
I0207 18:33:49.996364 134948952962560 run.py:471] train_steps 10000
I0207 18:33:49.996422 134948952962560 run.py:472] eval_every 50
I0207 18:33:49.996477 134948952962560 run.py:473] test_every 500
I0207 18:33:49.996535 134948952962560 run.py:474] hidden_size 256
I0207 18:33:49.996589 134948952962560 run.py:475] nb_msg_passing_steps 1
I0207 18:33:49.996642 134948952962560 run.py:476] learning_rate 0.001
I0207 18:33:49.996812 134948952962560 run.py:477] grad_clip_max_norm 1.0
I0207 18:33:49.996869 134948952962560 run.py:478] dropout_prob 0.0
I0207 18:33:49.996924 134948952962560 run.py:479] hint_teacher_forcing 0.0
I0207 18:33:49.996981 134948952962560 run.py:480] hint_mode encoded_decoded
I0207 18:33:49.997307 134948952962560 run.py:481] hint_repred_mode soft
I0207 18:33:49.997402 134948952962560 run.py:482] use_ln True
I0207 18:33:49.997468 134948952962560 run.py:483] use_lstm True
I0207 18:33:49.997549 134948952962560 run.py:484] nb_triplet_fts 16
I0207 18:33:49.997613 134948952962560 run.py:485] encoder_init xavier_on_scalars
I0207 18:33:49.997699 134948952962560 run.py:486] processor_type f9
I0207 18:33:49.997795 134948952962560 run.py:487] checkpoint_path CLRS30
I0207 18:33:49.997874 134948952962560 run.py:488] dataset_path CLRS30
I0207 18:33:49.997936 134948952962560 run.py:489] freeze_processor False
I0207 18:33:49.997993 134948952962560 run.py:490] reduction min
I0207 18:33:49.998054 134948952962560 run.py:491] activation elu
I0207 18:33:49.998111 134948952962560 run.py:492] restore_model 
I0207 18:33:49.998166 134948952962560 run.py:493] gated True
I0207 18:33:49.998223 134948952962560 run.py:494] gated_activation sigmoid
I0207 18:33:49.998303 134948952962560 run.py:495] memory_type mha
I0207 18:33:49.998358 134948952962560 run.py:496] memory_size 16
I0207 18:33:50.003048 134948952962560 run.py:522] Creating samplers for algo activity_selector
W0207 18:33:50.003370 134948952962560 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0207 18:33:50.003843 134948952962560 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0207 18:33:50.257270 134948952962560 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0207 18:33:50.524366 134948952962560 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0207 18:33:50.861661 134948952962560 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0207 18:33:51.261754 134948952962560 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0207 18:33:51.708006 134948952962560 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0207 18:33:51.708362 134948952962560 samplers.py:124] Creating a dataset with 64 samples.
I0207 18:33:51.737465 134948952962560 run.py:306] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0207 18:33:51.738392 134948952962560 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0207 18:33:51.742066 134948952962560 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0207 18:33:51.746637 134948952962560 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0207 18:33:51.813959 134948952962560 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W0207 18:33:51.836747 134948952962560 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x7abbbbdc99e0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0207 18:34:39.198031 134948952962560 run.py:748] Algo activity_selector step 0 current loss 5.354810, current_train_items 32.
I0207 18:34:48.077090 134948952962560 run.py:783] (val) algo activity_selector step 0: {'selected': 0.1941747572815534, 'score': 0.1941747572815534, 'examples_seen': 32, 'step': 0, 'algorithm': 'activity_selector'}
I0207 18:34:48.077262 134948952962560 run.py:804] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.194, val scores are: activity_selector: 0.194
I0207 18:35:58.957992 134948952962560 run.py:748] Algo activity_selector step 50 current loss 3.518177, current_train_items 1408.
I0207 18:35:59.120272 134948952962560 run.py:783] (val) algo activity_selector step 50: {'selected': 0.685344827586207, 'score': 0.685344827586207, 'examples_seen': 1408, 'step': 50, 'algorithm': 'activity_selector'}
I0207 18:35:59.120512 134948952962560 run.py:804] Checkpointing best model, best avg val score was 0.194, current avg val score is 0.685, val scores are: activity_selector: 0.685
I0207 18:36:00.552582 134948952962560 run.py:748] Algo activity_selector step 100 current loss 3.589149, current_train_items 2800.
I0207 18:36:00.760691 134948952962560 run.py:783] (val) algo activity_selector step 100: {'selected': 0.7442748091603053, 'score': 0.7442748091603053, 'examples_seen': 2800, 'step': 100, 'algorithm': 'activity_selector'}
I0207 18:36:00.760931 134948952962560 run.py:804] Checkpointing best model, best avg val score was 0.685, current avg val score is 0.744, val scores are: activity_selector: 0.744
I0207 18:36:02.215276 134948952962560 run.py:748] Algo activity_selector step 150 current loss 3.549662, current_train_items 4176.
I0207 18:36:02.379691 134948952962560 run.py:783] (val) algo activity_selector step 150: {'selected': 0.7657142857142857, 'score': 0.7657142857142857, 'examples_seen': 4176, 'step': 150, 'algorithm': 'activity_selector'}
I0207 18:36:02.379922 134948952962560 run.py:804] Checkpointing best model, best avg val score was 0.744, current avg val score is 0.766, val scores are: activity_selector: 0.766
I0207 18:36:03.810389 134948952962560 run.py:748] Algo activity_selector step 200 current loss 2.797335, current_train_items 5536.
I0207 18:36:03.993695 134948952962560 run.py:783] (val) algo activity_selector step 200: {'selected': 0.7738095238095238, 'score': 0.7738095238095238, 'examples_seen': 5536, 'step': 200, 'algorithm': 'activity_selector'}
I0207 18:36:03.993923 134948952962560 run.py:804] Checkpointing best model, best avg val score was 0.766, current avg val score is 0.774, val scores are: activity_selector: 0.774
I0207 18:36:05.438368 134948952962560 run.py:748] Algo activity_selector step 250 current loss 3.154086, current_train_items 6944.
I0207 18:36:05.626499 134948952962560 run.py:783] (val) algo activity_selector step 250: {'selected': 0.68762278978389, 'score': 0.68762278978389, 'examples_seen': 6944, 'step': 250, 'algorithm': 'activity_selector'}
I0207 18:36:05.626742 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.774, current avg val score is 0.688, val scores are: activity_selector: 0.688
I0207 18:36:06.942677 134948952962560 run.py:748] Algo activity_selector step 300 current loss 2.377553, current_train_items 8304.
I0207 18:36:07.120791 134948952962560 run.py:783] (val) algo activity_selector step 300: {'selected': 0.7352941176470589, 'score': 0.7352941176470589, 'examples_seen': 8304, 'step': 300, 'algorithm': 'activity_selector'}
I0207 18:36:07.121022 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.774, current avg val score is 0.735, val scores are: activity_selector: 0.735
I0207 18:36:08.388844 134948952962560 run.py:748] Algo activity_selector step 350 current loss 2.178603, current_train_items 9680.
I0207 18:36:08.564936 134948952962560 run.py:783] (val) algo activity_selector step 350: {'selected': 0.8067796610169492, 'score': 0.8067796610169492, 'examples_seen': 9680, 'step': 350, 'algorithm': 'activity_selector'}
I0207 18:36:08.565085 134948952962560 run.py:804] Checkpointing best model, best avg val score was 0.774, current avg val score is 0.807, val scores are: activity_selector: 0.807
I0207 18:36:10.000808 134948952962560 run.py:748] Algo activity_selector step 400 current loss 1.931601, current_train_items 11072.
I0207 18:36:10.178673 134948952962560 run.py:783] (val) algo activity_selector step 400: {'selected': 0.8222222222222223, 'score': 0.8222222222222223, 'examples_seen': 11072, 'step': 400, 'algorithm': 'activity_selector'}
I0207 18:36:10.178896 134948952962560 run.py:804] Checkpointing best model, best avg val score was 0.807, current avg val score is 0.822, val scores are: activity_selector: 0.822
I0207 18:36:11.657041 134948952962560 run.py:748] Algo activity_selector step 450 current loss 1.900297, current_train_items 12448.
I0207 18:36:11.835463 134948952962560 run.py:783] (val) algo activity_selector step 450: {'selected': 0.7843803056027163, 'score': 0.7843803056027163, 'examples_seen': 12448, 'step': 450, 'algorithm': 'activity_selector'}
I0207 18:36:11.835687 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.822, current avg val score is 0.784, val scores are: activity_selector: 0.784
I0207 18:36:13.128429 134948952962560 run.py:748] Algo activity_selector step 500 current loss 2.053682, current_train_items 13824.
I0207 18:36:13.292828 134948952962560 run.py:783] (val) algo activity_selector step 500: {'selected': 0.817857142857143, 'score': 0.817857142857143, 'examples_seen': 13824, 'step': 500, 'algorithm': 'activity_selector'}
I0207 18:36:13.293051 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.822, current avg val score is 0.818, val scores are: activity_selector: 0.818
I0207 18:36:14.570503 134948952962560 run.py:748] Algo activity_selector step 550 current loss 1.865629, current_train_items 15200.
I0207 18:36:14.747870 134948952962560 run.py:783] (val) algo activity_selector step 550: {'selected': 0.8680688336520077, 'score': 0.8680688336520077, 'examples_seen': 15200, 'step': 550, 'algorithm': 'activity_selector'}
I0207 18:36:14.748020 134948952962560 run.py:804] Checkpointing best model, best avg val score was 0.822, current avg val score is 0.868, val scores are: activity_selector: 0.868
I0207 18:36:16.206167 134948952962560 run.py:748] Algo activity_selector step 600 current loss 1.434168, current_train_items 16576.
I0207 18:36:16.401362 134948952962560 run.py:783] (val) algo activity_selector step 600: {'selected': 0.8944337811900193, 'score': 0.8944337811900193, 'examples_seen': 16576, 'step': 600, 'algorithm': 'activity_selector'}
I0207 18:36:16.401512 134948952962560 run.py:804] Checkpointing best model, best avg val score was 0.868, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0207 18:36:17.833534 134948952962560 run.py:748] Algo activity_selector step 650 current loss 1.641141, current_train_items 17952.
I0207 18:36:18.016489 134948952962560 run.py:783] (val) algo activity_selector step 650: {'selected': 0.9262759924385633, 'score': 0.9262759924385633, 'examples_seen': 17952, 'step': 650, 'algorithm': 'activity_selector'}
I0207 18:36:18.016725 134948952962560 run.py:804] Checkpointing best model, best avg val score was 0.894, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0207 18:36:19.466302 134948952962560 run.py:748] Algo activity_selector step 700 current loss 1.539826, current_train_items 19344.
I0207 18:36:19.644958 134948952962560 run.py:783] (val) algo activity_selector step 700: {'selected': 0.8494623655913978, 'score': 0.8494623655913978, 'examples_seen': 19344, 'step': 700, 'algorithm': 'activity_selector'}
I0207 18:36:19.645181 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.926, current avg val score is 0.849, val scores are: activity_selector: 0.849
I0207 18:36:20.921666 134948952962560 run.py:748] Algo activity_selector step 750 current loss 1.647027, current_train_items 20720.
I0207 18:36:21.112145 134948952962560 run.py:783] (val) algo activity_selector step 750: {'selected': 0.874074074074074, 'score': 0.874074074074074, 'examples_seen': 20720, 'step': 750, 'algorithm': 'activity_selector'}
I0207 18:36:21.112380 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.926, current avg val score is 0.874, val scores are: activity_selector: 0.874
I0207 18:36:22.423675 134948952962560 run.py:748] Algo activity_selector step 800 current loss 1.594851, current_train_items 22096.
I0207 18:36:22.604951 134948952962560 run.py:783] (val) algo activity_selector step 800: {'selected': 0.9323308270676691, 'score': 0.9323308270676691, 'examples_seen': 22096, 'step': 800, 'algorithm': 'activity_selector'}
I0207 18:36:22.605174 134948952962560 run.py:804] Checkpointing best model, best avg val score was 0.926, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0207 18:36:24.049270 134948952962560 run.py:748] Algo activity_selector step 850 current loss 1.883361, current_train_items 23472.
I0207 18:36:24.230568 134948952962560 run.py:783] (val) algo activity_selector step 850: {'selected': 0.8214285714285715, 'score': 0.8214285714285715, 'examples_seen': 23472, 'step': 850, 'algorithm': 'activity_selector'}
I0207 18:36:24.230797 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.932, current avg val score is 0.821, val scores are: activity_selector: 0.821
I0207 18:36:25.519280 134948952962560 run.py:748] Algo activity_selector step 900 current loss 1.718623, current_train_items 24848.
I0207 18:36:25.699082 134948952962560 run.py:783] (val) algo activity_selector step 900: {'selected': 0.8983739837398375, 'score': 0.8983739837398375, 'examples_seen': 24848, 'step': 900, 'algorithm': 'activity_selector'}
I0207 18:36:25.699322 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.932, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0207 18:36:26.998682 134948952962560 run.py:748] Algo activity_selector step 950 current loss 1.319731, current_train_items 26224.
I0207 18:36:27.192202 134948952962560 run.py:783] (val) algo activity_selector step 950: {'selected': 0.8950276243093923, 'score': 0.8950276243093923, 'examples_seen': 26224, 'step': 950, 'algorithm': 'activity_selector'}
I0207 18:36:27.192470 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.932, current avg val score is 0.895, val scores are: activity_selector: 0.895
I0207 18:36:28.471162 134948952962560 run.py:748] Algo activity_selector step 1000 current loss 1.783282, current_train_items 27616.
I0207 18:36:28.650283 134948952962560 run.py:783] (val) algo activity_selector step 1000: {'selected': 0.9001814882032668, 'score': 0.9001814882032668, 'examples_seen': 27616, 'step': 1000, 'algorithm': 'activity_selector'}
I0207 18:36:28.650509 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.932, current avg val score is 0.900, val scores are: activity_selector: 0.900
I0207 18:36:29.955921 134948952962560 run.py:748] Algo activity_selector step 1050 current loss 1.527694, current_train_items 28992.
I0207 18:36:30.120024 134948952962560 run.py:783] (val) algo activity_selector step 1050: {'selected': 0.9236947791164658, 'score': 0.9236947791164658, 'examples_seen': 28992, 'step': 1050, 'algorithm': 'activity_selector'}
I0207 18:36:30.120265 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.932, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0207 18:36:31.399399 134948952962560 run.py:748] Algo activity_selector step 1100 current loss 1.417296, current_train_items 30368.
I0207 18:36:31.583877 134948952962560 run.py:783] (val) algo activity_selector step 1100: {'selected': 0.8810408921933085, 'score': 0.8810408921933085, 'examples_seen': 30368, 'step': 1100, 'algorithm': 'activity_selector'}
I0207 18:36:31.584150 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.932, current avg val score is 0.881, val scores are: activity_selector: 0.881
I0207 18:36:32.889787 134948952962560 run.py:748] Algo activity_selector step 1150 current loss 1.313488, current_train_items 31760.
I0207 18:36:33.070223 134948952962560 run.py:783] (val) algo activity_selector step 1150: {'selected': 0.8745098039215685, 'score': 0.8745098039215685, 'examples_seen': 31760, 'step': 1150, 'algorithm': 'activity_selector'}
I0207 18:36:33.070467 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.932, current avg val score is 0.875, val scores are: activity_selector: 0.875
I0207 18:36:34.359384 134948952962560 run.py:748] Algo activity_selector step 1200 current loss 1.038759, current_train_items 33120.
I0207 18:36:34.539241 134948952962560 run.py:783] (val) algo activity_selector step 1200: {'selected': 0.8990825688073395, 'score': 0.8990825688073395, 'examples_seen': 33120, 'step': 1200, 'algorithm': 'activity_selector'}
I0207 18:36:34.539493 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.932, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0207 18:36:35.791534 134948952962560 run.py:748] Algo activity_selector step 1250 current loss 1.447879, current_train_items 34496.
I0207 18:36:35.995552 134948952962560 run.py:783] (val) algo activity_selector step 1250: {'selected': 0.8692579505300354, 'score': 0.8692579505300354, 'examples_seen': 34496, 'step': 1250, 'algorithm': 'activity_selector'}
I0207 18:36:35.995775 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.932, current avg val score is 0.869, val scores are: activity_selector: 0.869
I0207 18:36:37.281191 134948952962560 run.py:748] Algo activity_selector step 1300 current loss 1.369881, current_train_items 35888.
I0207 18:36:37.483979 134948952962560 run.py:783] (val) algo activity_selector step 1300: {'selected': 0.8934579439252337, 'score': 0.8934579439252337, 'examples_seen': 35888, 'step': 1300, 'algorithm': 'activity_selector'}
I0207 18:36:37.484145 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.932, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0207 18:36:38.771573 134948952962560 run.py:748] Algo activity_selector step 1350 current loss 1.398728, current_train_items 37264.
I0207 18:36:38.956250 134948952962560 run.py:783] (val) algo activity_selector step 1350: {'selected': 0.9369024856596557, 'score': 0.9369024856596557, 'examples_seen': 37264, 'step': 1350, 'algorithm': 'activity_selector'}
I0207 18:36:38.956476 134948952962560 run.py:804] Checkpointing best model, best avg val score was 0.932, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0207 18:36:40.408830 134948952962560 run.py:748] Algo activity_selector step 1400 current loss 1.376138, current_train_items 38640.
I0207 18:36:40.587503 134948952962560 run.py:783] (val) algo activity_selector step 1400: {'selected': 0.9046728971962618, 'score': 0.9046728971962618, 'examples_seen': 38640, 'step': 1400, 'algorithm': 'activity_selector'}
I0207 18:36:40.587744 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.937, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0207 18:36:41.867855 134948952962560 run.py:748] Algo activity_selector step 1450 current loss 0.879284, current_train_items 40016.
I0207 18:36:42.055928 134948952962560 run.py:783] (val) algo activity_selector step 1450: {'selected': 0.930841121495327, 'score': 0.930841121495327, 'examples_seen': 40016, 'step': 1450, 'algorithm': 'activity_selector'}
I0207 18:36:42.056155 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.937, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0207 18:36:43.339041 134948952962560 run.py:748] Algo activity_selector step 1500 current loss 1.430013, current_train_items 41408.
I0207 18:36:43.541319 134948952962560 run.py:783] (val) algo activity_selector step 1500: {'selected': 0.9382239382239382, 'score': 0.9382239382239382, 'examples_seen': 41408, 'step': 1500, 'algorithm': 'activity_selector'}
I0207 18:36:43.541546 134948952962560 run.py:804] Checkpointing best model, best avg val score was 0.937, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0207 18:36:45.005356 134948952962560 run.py:748] Algo activity_selector step 1550 current loss 1.367761, current_train_items 42768.
I0207 18:36:45.169400 134948952962560 run.py:783] (val) algo activity_selector step 1550: {'selected': 0.9037037037037037, 'score': 0.9037037037037037, 'examples_seen': 42768, 'step': 1550, 'algorithm': 'activity_selector'}
I0207 18:36:45.169637 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.904, val scores are: activity_selector: 0.904
I0207 18:36:46.451866 134948952962560 run.py:748] Algo activity_selector step 1600 current loss 1.092956, current_train_items 44160.
I0207 18:36:46.630991 134948952962560 run.py:783] (val) algo activity_selector step 1600: {'selected': 0.8825757575757575, 'score': 0.8825757575757575, 'examples_seen': 44160, 'step': 1600, 'algorithm': 'activity_selector'}
I0207 18:36:46.631213 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.883, val scores are: activity_selector: 0.883
I0207 18:36:47.943631 134948952962560 run.py:748] Algo activity_selector step 1650 current loss 1.165555, current_train_items 45536.
I0207 18:36:48.137586 134948952962560 run.py:783] (val) algo activity_selector step 1650: {'selected': 0.8975409836065574, 'score': 0.8975409836065574, 'examples_seen': 45536, 'step': 1650, 'algorithm': 'activity_selector'}
I0207 18:36:48.137822 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0207 18:36:49.416862 134948952962560 run.py:748] Algo activity_selector step 1700 current loss 0.931548, current_train_items 46896.
I0207 18:36:49.595969 134948952962560 run.py:783] (val) algo activity_selector step 1700: {'selected': 0.9294117647058824, 'score': 0.9294117647058824, 'examples_seen': 46896, 'step': 1700, 'algorithm': 'activity_selector'}
I0207 18:36:49.596191 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0207 18:36:50.873914 134948952962560 run.py:748] Algo activity_selector step 1750 current loss 1.213379, current_train_items 48304.
I0207 18:36:51.051458 134948952962560 run.py:783] (val) algo activity_selector step 1750: {'selected': 0.9025844930417495, 'score': 0.9025844930417495, 'examples_seen': 48304, 'step': 1750, 'algorithm': 'activity_selector'}
I0207 18:36:51.051682 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.903, val scores are: activity_selector: 0.903
I0207 18:36:52.361587 134948952962560 run.py:748] Algo activity_selector step 1800 current loss 1.156434, current_train_items 49664.
I0207 18:36:52.537399 134948952962560 run.py:783] (val) algo activity_selector step 1800: {'selected': 0.9198473282442747, 'score': 0.9198473282442747, 'examples_seen': 49664, 'step': 1800, 'algorithm': 'activity_selector'}
I0207 18:36:52.537635 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0207 18:36:53.829969 134948952962560 run.py:748] Algo activity_selector step 1850 current loss 0.850768, current_train_items 51056.
I0207 18:36:54.009953 134948952962560 run.py:783] (val) algo activity_selector step 1850: {'selected': 0.8856088560885609, 'score': 0.8856088560885609, 'examples_seen': 51056, 'step': 1850, 'algorithm': 'activity_selector'}
I0207 18:36:54.010191 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0207 18:36:55.286943 134948952962560 run.py:748] Algo activity_selector step 1900 current loss 0.945455, current_train_items 52432.
I0207 18:36:55.468190 134948952962560 run.py:783] (val) algo activity_selector step 1900: {'selected': 0.8921389396709324, 'score': 0.8921389396709324, 'examples_seen': 52432, 'step': 1900, 'algorithm': 'activity_selector'}
I0207 18:36:55.468427 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.892, val scores are: activity_selector: 0.892
I0207 18:36:56.743747 134948952962560 run.py:748] Algo activity_selector step 1950 current loss 1.115321, current_train_items 53808.
I0207 18:36:56.936163 134948952962560 run.py:783] (val) algo activity_selector step 1950: {'selected': 0.9340866290018832, 'score': 0.9340866290018832, 'examples_seen': 53808, 'step': 1950, 'algorithm': 'activity_selector'}
I0207 18:36:56.936402 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0207 18:36:58.245245 134948952962560 run.py:748] Algo activity_selector step 2000 current loss 0.905347, current_train_items 55184.
I0207 18:36:58.426781 134948952962560 run.py:783] (val) algo activity_selector step 2000: {'selected': 0.9148148148148149, 'score': 0.9148148148148149, 'examples_seen': 55184, 'step': 2000, 'algorithm': 'activity_selector'}
I0207 18:36:58.427009 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0207 18:36:59.704191 134948952962560 run.py:748] Algo activity_selector step 2050 current loss 0.898416, current_train_items 56560.
I0207 18:36:59.884495 134948952962560 run.py:783] (val) algo activity_selector step 2050: {'selected': 0.8990825688073395, 'score': 0.8990825688073395, 'examples_seen': 56560, 'step': 2050, 'algorithm': 'activity_selector'}
I0207 18:36:59.884721 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0207 18:37:01.171429 134948952962560 run.py:748] Algo activity_selector step 2100 current loss 1.255847, current_train_items 57952.
I0207 18:37:01.352545 134948952962560 run.py:783] (val) algo activity_selector step 2100: {'selected': 0.8096192384769539, 'score': 0.8096192384769539, 'examples_seen': 57952, 'step': 2100, 'algorithm': 'activity_selector'}
I0207 18:37:01.352768 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.810, val scores are: activity_selector: 0.810
I0207 18:37:02.633883 134948952962560 run.py:748] Algo activity_selector step 2150 current loss 1.194233, current_train_items 59312.
I0207 18:37:02.823294 134948952962560 run.py:783] (val) algo activity_selector step 2150: {'selected': 0.9285714285714287, 'score': 0.9285714285714287, 'examples_seen': 59312, 'step': 2150, 'algorithm': 'activity_selector'}
I0207 18:37:02.823523 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0207 18:37:04.133714 134948952962560 run.py:748] Algo activity_selector step 2200 current loss 1.255974, current_train_items 60720.
I0207 18:37:04.299802 134948952962560 run.py:783] (val) algo activity_selector step 2200: {'selected': 0.8583162217659138, 'score': 0.8583162217659138, 'examples_seen': 60720, 'step': 2200, 'algorithm': 'activity_selector'}
I0207 18:37:04.300033 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.858, val scores are: activity_selector: 0.858
I0207 18:37:05.588025 134948952962560 run.py:748] Algo activity_selector step 2250 current loss 0.904697, current_train_items 62080.
I0207 18:37:05.765745 134948952962560 run.py:783] (val) algo activity_selector step 2250: {'selected': 0.9186046511627908, 'score': 0.9186046511627908, 'examples_seen': 62080, 'step': 2250, 'algorithm': 'activity_selector'}
I0207 18:37:05.765969 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0207 18:37:07.036873 134948952962560 run.py:748] Algo activity_selector step 2300 current loss 0.923961, current_train_items 63440.
I0207 18:37:07.211703 134948952962560 run.py:783] (val) algo activity_selector step 2300: {'selected': 0.878727634194831, 'score': 0.878727634194831, 'examples_seen': 63440, 'step': 2300, 'algorithm': 'activity_selector'}
I0207 18:37:07.211853 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0207 18:37:08.512799 134948952962560 run.py:748] Algo activity_selector step 2350 current loss 0.849280, current_train_items 64848.
I0207 18:37:08.691737 134948952962560 run.py:783] (val) algo activity_selector step 2350: {'selected': 0.9757009345794393, 'score': 0.9757009345794393, 'examples_seen': 64848, 'step': 2350, 'algorithm': 'activity_selector'}
I0207 18:37:08.691967 134948952962560 run.py:804] Checkpointing best model, best avg val score was 0.938, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0207 18:37:10.138740 134948952962560 run.py:748] Algo activity_selector step 2400 current loss 0.958116, current_train_items 66208.
I0207 18:37:10.321580 134948952962560 run.py:783] (val) algo activity_selector step 2400: {'selected': 0.9380863039399625, 'score': 0.9380863039399625, 'examples_seen': 66208, 'step': 2400, 'algorithm': 'activity_selector'}
I0207 18:37:10.321809 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0207 18:37:11.585353 134948952962560 run.py:748] Algo activity_selector step 2450 current loss 1.383474, current_train_items 67600.
I0207 18:37:11.780002 134948952962560 run.py:783] (val) algo activity_selector step 2450: {'selected': 0.920517560073937, 'score': 0.920517560073937, 'examples_seen': 67600, 'step': 2450, 'algorithm': 'activity_selector'}
I0207 18:37:11.780247 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0207 18:37:13.066867 134948952962560 run.py:748] Algo activity_selector step 2500 current loss 1.271145, current_train_items 68976.
I0207 18:37:13.254824 134948952962560 run.py:783] (val) algo activity_selector step 2500: {'selected': 0.8777555110220441, 'score': 0.8777555110220441, 'examples_seen': 68976, 'step': 2500, 'algorithm': 'activity_selector'}
I0207 18:37:13.254977 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.878, val scores are: activity_selector: 0.878
I0207 18:37:14.528377 134948952962560 run.py:748] Algo activity_selector step 2550 current loss 0.917044, current_train_items 70352.
I0207 18:37:14.720757 134948952962560 run.py:783] (val) algo activity_selector step 2550: {'selected': 0.9283018867924528, 'score': 0.9283018867924528, 'examples_seen': 70352, 'step': 2550, 'algorithm': 'activity_selector'}
I0207 18:37:14.721002 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0207 18:37:15.998773 134948952962560 run.py:748] Algo activity_selector step 2600 current loss 0.804775, current_train_items 71728.
I0207 18:37:16.178422 134948952962560 run.py:783] (val) algo activity_selector step 2600: {'selected': 0.906930693069307, 'score': 0.906930693069307, 'examples_seen': 71728, 'step': 2600, 'algorithm': 'activity_selector'}
I0207 18:37:16.178648 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0207 18:37:17.444569 134948952962560 run.py:748] Algo activity_selector step 2650 current loss 0.793073, current_train_items 73104.
I0207 18:37:17.633180 134948952962560 run.py:783] (val) algo activity_selector step 2650: {'selected': 0.8861209964412811, 'score': 0.8861209964412811, 'examples_seen': 73104, 'step': 2650, 'algorithm': 'activity_selector'}
I0207 18:37:17.633365 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0207 18:37:18.938524 134948952962560 run.py:748] Algo activity_selector step 2700 current loss 1.113707, current_train_items 74496.
I0207 18:37:19.119386 134948952962560 run.py:783] (val) algo activity_selector step 2700: {'selected': 0.9402985074626865, 'score': 0.9402985074626865, 'examples_seen': 74496, 'step': 2700, 'algorithm': 'activity_selector'}
I0207 18:37:19.119628 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0207 18:37:20.385835 134948952962560 run.py:748] Algo activity_selector step 2750 current loss 1.007878, current_train_items 75856.
I0207 18:37:20.575557 134948952962560 run.py:783] (val) algo activity_selector step 2750: {'selected': 0.959409594095941, 'score': 0.959409594095941, 'examples_seen': 75856, 'step': 2750, 'algorithm': 'activity_selector'}
I0207 18:37:20.575785 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0207 18:37:21.853820 134948952962560 run.py:748] Algo activity_selector step 2800 current loss 0.830880, current_train_items 77264.
I0207 18:37:22.034815 134948952962560 run.py:783] (val) algo activity_selector step 2800: {'selected': 0.8455598455598456, 'score': 0.8455598455598456, 'examples_seen': 77264, 'step': 2800, 'algorithm': 'activity_selector'}
I0207 18:37:22.035059 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.846, val scores are: activity_selector: 0.846
I0207 18:37:23.322189 134948952962560 run.py:748] Algo activity_selector step 2850 current loss 1.007503, current_train_items 78624.
I0207 18:37:23.517215 134948952962560 run.py:783] (val) algo activity_selector step 2850: {'selected': 0.931297709923664, 'score': 0.931297709923664, 'examples_seen': 78624, 'step': 2850, 'algorithm': 'activity_selector'}
I0207 18:37:23.517452 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0207 18:37:24.813006 134948952962560 run.py:748] Algo activity_selector step 2900 current loss 0.932682, current_train_items 80000.
I0207 18:37:24.993564 134948952962560 run.py:783] (val) algo activity_selector step 2900: {'selected': 0.9224489795918367, 'score': 0.9224489795918367, 'examples_seen': 80000, 'step': 2900, 'algorithm': 'activity_selector'}
I0207 18:37:24.993788 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0207 18:37:26.271695 134948952962560 run.py:748] Algo activity_selector step 2950 current loss 0.951253, current_train_items 81392.
I0207 18:37:26.453609 134948952962560 run.py:783] (val) algo activity_selector step 2950: {'selected': 0.8892988929889298, 'score': 0.8892988929889298, 'examples_seen': 81392, 'step': 2950, 'algorithm': 'activity_selector'}
I0207 18:37:26.453830 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.889, val scores are: activity_selector: 0.889
I0207 18:37:27.727963 134948952962560 run.py:748] Algo activity_selector step 3000 current loss 0.852681, current_train_items 82752.
I0207 18:37:27.922729 134948952962560 run.py:783] (val) algo activity_selector step 3000: {'selected': 0.8951048951048951, 'score': 0.8951048951048951, 'examples_seen': 82752, 'step': 3000, 'algorithm': 'activity_selector'}
I0207 18:37:27.922969 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.895, val scores are: activity_selector: 0.895
I0207 18:37:29.209429 134948952962560 run.py:748] Algo activity_selector step 3050 current loss 0.946174, current_train_items 84144.
I0207 18:37:29.415107 134948952962560 run.py:783] (val) algo activity_selector step 3050: {'selected': 0.9188034188034188, 'score': 0.9188034188034188, 'examples_seen': 84144, 'step': 3050, 'algorithm': 'activity_selector'}
I0207 18:37:29.415344 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0207 18:37:30.691253 134948952962560 run.py:748] Algo activity_selector step 3100 current loss 0.937341, current_train_items 85520.
I0207 18:37:30.873128 134948952962560 run.py:783] (val) algo activity_selector step 3100: {'selected': 0.9407265774378585, 'score': 0.9407265774378585, 'examples_seen': 85520, 'step': 3100, 'algorithm': 'activity_selector'}
I0207 18:37:30.873366 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0207 18:37:32.159504 134948952962560 run.py:748] Algo activity_selector step 3150 current loss 0.801286, current_train_items 86896.
I0207 18:37:32.340707 134948952962560 run.py:783] (val) algo activity_selector step 3150: {'selected': 0.9141716566866267, 'score': 0.9141716566866267, 'examples_seen': 86896, 'step': 3150, 'algorithm': 'activity_selector'}
I0207 18:37:32.340927 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0207 18:37:33.617551 134948952962560 run.py:748] Algo activity_selector step 3200 current loss 0.821685, current_train_items 88272.
I0207 18:37:33.804318 134948952962560 run.py:783] (val) algo activity_selector step 3200: {'selected': 0.9340866290018832, 'score': 0.9340866290018832, 'examples_seen': 88272, 'step': 3200, 'algorithm': 'activity_selector'}
I0207 18:37:33.804507 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0207 18:37:35.110367 134948952962560 run.py:748] Algo activity_selector step 3250 current loss 0.980990, current_train_items 89664.
I0207 18:37:35.291906 134948952962560 run.py:783] (val) algo activity_selector step 3250: {'selected': 0.9553398058252428, 'score': 0.9553398058252428, 'examples_seen': 89664, 'step': 3250, 'algorithm': 'activity_selector'}
I0207 18:37:35.292127 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0207 18:37:36.595747 134948952962560 run.py:748] Algo activity_selector step 3300 current loss 0.995884, current_train_items 91040.
I0207 18:37:36.762937 134948952962560 run.py:783] (val) algo activity_selector step 3300: {'selected': 0.9465346534653465, 'score': 0.9465346534653465, 'examples_seen': 91040, 'step': 3300, 'algorithm': 'activity_selector'}
I0207 18:37:36.763175 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0207 18:37:38.051553 134948952962560 run.py:748] Algo activity_selector step 3350 current loss 0.981038, current_train_items 92400.
I0207 18:37:38.219175 134948952962560 run.py:783] (val) algo activity_selector step 3350: {'selected': 0.9258517034068136, 'score': 0.9258517034068136, 'examples_seen': 92400, 'step': 3350, 'algorithm': 'activity_selector'}
I0207 18:37:38.219416 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0207 18:37:39.529844 134948952962560 run.py:748] Algo activity_selector step 3400 current loss 0.908419, current_train_items 93792.
I0207 18:37:39.709579 134948952962560 run.py:783] (val) algo activity_selector step 3400: {'selected': 0.9581749049429658, 'score': 0.9581749049429658, 'examples_seen': 93792, 'step': 3400, 'algorithm': 'activity_selector'}
I0207 18:37:39.709801 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0207 18:37:40.997464 134948952962560 run.py:748] Algo activity_selector step 3450 current loss 0.944249, current_train_items 95168.
I0207 18:37:41.177317 134948952962560 run.py:783] (val) algo activity_selector step 3450: {'selected': 0.9272030651340996, 'score': 0.9272030651340996, 'examples_seen': 95168, 'step': 3450, 'algorithm': 'activity_selector'}
I0207 18:37:41.177539 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0207 18:37:42.455806 134948952962560 run.py:748] Algo activity_selector step 3500 current loss 1.043958, current_train_items 96544.
I0207 18:37:42.634737 134948952962560 run.py:783] (val) algo activity_selector step 3500: {'selected': 0.9349112426035503, 'score': 0.9349112426035503, 'examples_seen': 96544, 'step': 3500, 'algorithm': 'activity_selector'}
I0207 18:37:42.634965 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0207 18:37:43.912729 134948952962560 run.py:748] Algo activity_selector step 3550 current loss 0.724966, current_train_items 97936.
I0207 18:37:44.098639 134948952962560 run.py:783] (val) algo activity_selector step 3550: {'selected': 0.93359375, 'score': 0.93359375, 'examples_seen': 97936, 'step': 3550, 'algorithm': 'activity_selector'}
I0207 18:37:44.098894 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0207 18:37:45.403624 134948952962560 run.py:748] Algo activity_selector step 3600 current loss 0.952714, current_train_items 99312.
I0207 18:37:45.583784 134948952962560 run.py:783] (val) algo activity_selector step 3600: {'selected': 0.9647058823529412, 'score': 0.9647058823529412, 'examples_seen': 99312, 'step': 3600, 'algorithm': 'activity_selector'}
I0207 18:37:45.584009 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0207 18:37:46.862054 134948952962560 run.py:748] Algo activity_selector step 3650 current loss 0.908696, current_train_items 100688.
I0207 18:37:47.041305 134948952962560 run.py:783] (val) algo activity_selector step 3650: {'selected': 0.9379562043795621, 'score': 0.9379562043795621, 'examples_seen': 100688, 'step': 3650, 'algorithm': 'activity_selector'}
I0207 18:37:47.041529 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0207 18:37:48.322382 134948952962560 run.py:748] Algo activity_selector step 3700 current loss 0.655010, current_train_items 102064.
I0207 18:37:48.496367 134948952962560 run.py:783] (val) algo activity_selector step 3700: {'selected': 0.9402697495183043, 'score': 0.9402697495183043, 'examples_seen': 102064, 'step': 3700, 'algorithm': 'activity_selector'}
I0207 18:37:48.496613 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0207 18:37:49.779450 134948952962560 run.py:748] Algo activity_selector step 3750 current loss 0.894623, current_train_items 103440.
I0207 18:37:49.983674 134948952962560 run.py:783] (val) algo activity_selector step 3750: {'selected': 0.9305019305019304, 'score': 0.9305019305019304, 'examples_seen': 103440, 'step': 3750, 'algorithm': 'activity_selector'}
I0207 18:37:49.983825 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0207 18:37:51.251097 134948952962560 run.py:748] Algo activity_selector step 3800 current loss 0.715900, current_train_items 104816.
I0207 18:37:51.429887 134948952962560 run.py:783] (val) algo activity_selector step 3800: {'selected': 0.9450980392156861, 'score': 0.9450980392156861, 'examples_seen': 104816, 'step': 3800, 'algorithm': 'activity_selector'}
I0207 18:37:51.430115 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0207 18:37:52.680851 134948952962560 run.py:748] Algo activity_selector step 3850 current loss 1.426369, current_train_items 106208.
I0207 18:37:52.886022 134948952962560 run.py:783] (val) algo activity_selector step 3850: {'selected': 0.8720720720720722, 'score': 0.8720720720720722, 'examples_seen': 106208, 'step': 3850, 'algorithm': 'activity_selector'}
I0207 18:37:52.886260 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.872, val scores are: activity_selector: 0.872
I0207 18:37:54.188786 134948952962560 run.py:748] Algo activity_selector step 3900 current loss 0.926997, current_train_items 107584.
I0207 18:37:54.355888 134948952962560 run.py:783] (val) algo activity_selector step 3900: {'selected': 0.9612403100775194, 'score': 0.9612403100775194, 'examples_seen': 107584, 'step': 3900, 'algorithm': 'activity_selector'}
I0207 18:37:54.356120 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0207 18:37:55.654044 134948952962560 run.py:748] Algo activity_selector step 3950 current loss 0.836953, current_train_items 108960.
I0207 18:37:55.844461 134948952962560 run.py:783] (val) algo activity_selector step 3950: {'selected': 0.9426987060998151, 'score': 0.9426987060998151, 'examples_seen': 108960, 'step': 3950, 'algorithm': 'activity_selector'}
I0207 18:37:55.844607 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0207 18:37:57.111742 134948952962560 run.py:748] Algo activity_selector step 4000 current loss 0.764103, current_train_items 110336.
I0207 18:37:57.289716 134948952962560 run.py:783] (val) algo activity_selector step 4000: {'selected': 0.9251439539347409, 'score': 0.9251439539347409, 'examples_seen': 110336, 'step': 4000, 'algorithm': 'activity_selector'}
I0207 18:37:57.289862 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0207 18:37:58.561795 134948952962560 run.py:748] Algo activity_selector step 4050 current loss 0.642315, current_train_items 111712.
I0207 18:37:58.742567 134948952962560 run.py:783] (val) algo activity_selector step 4050: {'selected': 0.9510763209393347, 'score': 0.9510763209393347, 'examples_seen': 111712, 'step': 4050, 'algorithm': 'activity_selector'}
I0207 18:37:58.742809 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0207 18:38:00.047055 134948952962560 run.py:748] Algo activity_selector step 4100 current loss 0.746145, current_train_items 113088.
I0207 18:38:00.235464 134948952962560 run.py:783] (val) algo activity_selector step 4100: {'selected': 0.960747663551402, 'score': 0.960747663551402, 'examples_seen': 113088, 'step': 4100, 'algorithm': 'activity_selector'}
I0207 18:38:00.235684 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0207 18:38:01.521873 134948952962560 run.py:748] Algo activity_selector step 4150 current loss 0.820152, current_train_items 114480.
I0207 18:38:01.699800 134948952962560 run.py:783] (val) algo activity_selector step 4150: {'selected': 0.9357798165137615, 'score': 0.9357798165137615, 'examples_seen': 114480, 'step': 4150, 'algorithm': 'activity_selector'}
I0207 18:38:01.700040 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0207 18:38:02.988501 134948952962560 run.py:748] Algo activity_selector step 4200 current loss 1.090279, current_train_items 115856.
I0207 18:38:03.169024 134948952962560 run.py:783] (val) algo activity_selector step 4200: {'selected': 0.8780487804878049, 'score': 0.8780487804878049, 'examples_seen': 115856, 'step': 4200, 'algorithm': 'activity_selector'}
I0207 18:38:03.169267 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.878, val scores are: activity_selector: 0.878
I0207 18:38:04.434872 134948952962560 run.py:748] Algo activity_selector step 4250 current loss 0.710987, current_train_items 117216.
I0207 18:38:04.626947 134948952962560 run.py:783] (val) algo activity_selector step 4250: {'selected': 0.90234375, 'score': 0.90234375, 'examples_seen': 117216, 'step': 4250, 'algorithm': 'activity_selector'}
I0207 18:38:04.627170 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0207 18:38:05.938420 134948952962560 run.py:748] Algo activity_selector step 4300 current loss 1.016436, current_train_items 118624.
I0207 18:38:06.117190 134948952962560 run.py:783] (val) algo activity_selector step 4300: {'selected': 0.914396887159533, 'score': 0.914396887159533, 'examples_seen': 118624, 'step': 4300, 'algorithm': 'activity_selector'}
I0207 18:38:06.117445 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0207 18:38:07.406085 134948952962560 run.py:748] Algo activity_selector step 4350 current loss 0.670435, current_train_items 119984.
I0207 18:38:07.585305 134948952962560 run.py:783] (val) algo activity_selector step 4350: {'selected': 0.9612403100775193, 'score': 0.9612403100775193, 'examples_seen': 119984, 'step': 4350, 'algorithm': 'activity_selector'}
I0207 18:38:07.585532 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0207 18:38:08.863108 134948952962560 run.py:748] Algo activity_selector step 4400 current loss 0.812572, current_train_items 121360.
I0207 18:38:09.041747 134948952962560 run.py:783] (val) algo activity_selector step 4400: {'selected': 0.9346153846153846, 'score': 0.9346153846153846, 'examples_seen': 121360, 'step': 4400, 'algorithm': 'activity_selector'}
I0207 18:38:09.041984 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0207 18:38:10.330938 134948952962560 run.py:748] Algo activity_selector step 4450 current loss 1.341927, current_train_items 122752.
I0207 18:38:10.532777 134948952962560 run.py:783] (val) algo activity_selector step 4450: {'selected': 0.932, 'score': 0.932, 'examples_seen': 122752, 'step': 4450, 'algorithm': 'activity_selector'}
I0207 18:38:10.533032 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0207 18:38:11.808638 134948952962560 run.py:748] Algo activity_selector step 4500 current loss 0.605998, current_train_items 124128.
I0207 18:38:11.999661 134948952962560 run.py:783] (val) algo activity_selector step 4500: {'selected': 0.9644268774703556, 'score': 0.9644268774703556, 'examples_seen': 124128, 'step': 4500, 'algorithm': 'activity_selector'}
I0207 18:38:11.999882 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0207 18:38:13.276791 134948952962560 run.py:748] Algo activity_selector step 4550 current loss 0.790119, current_train_items 125504.
I0207 18:38:13.456680 134948952962560 run.py:783] (val) algo activity_selector step 4550: {'selected': 0.9105367793240557, 'score': 0.9105367793240557, 'examples_seen': 125504, 'step': 4550, 'algorithm': 'activity_selector'}
I0207 18:38:13.456903 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0207 18:38:14.733952 134948952962560 run.py:748] Algo activity_selector step 4600 current loss 0.683074, current_train_items 126880.
I0207 18:38:14.915516 134948952962560 run.py:783] (val) algo activity_selector step 4600: {'selected': 0.9657794676806083, 'score': 0.9657794676806083, 'examples_seen': 126880, 'step': 4600, 'algorithm': 'activity_selector'}
I0207 18:38:14.915784 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0207 18:38:16.234126 134948952962560 run.py:748] Algo activity_selector step 4650 current loss 0.717433, current_train_items 128272.
I0207 18:38:16.416133 134948952962560 run.py:783] (val) algo activity_selector step 4650: {'selected': 0.9589552238805971, 'score': 0.9589552238805971, 'examples_seen': 128272, 'step': 4650, 'algorithm': 'activity_selector'}
I0207 18:38:16.416387 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0207 18:38:17.693834 134948952962560 run.py:748] Algo activity_selector step 4700 current loss 0.735717, current_train_items 129632.
I0207 18:38:17.873257 134948952962560 run.py:783] (val) algo activity_selector step 4700: {'selected': 0.9534450651769087, 'score': 0.9534450651769087, 'examples_seen': 129632, 'step': 4700, 'algorithm': 'activity_selector'}
I0207 18:38:17.873481 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0207 18:38:19.165783 134948952962560 run.py:748] Algo activity_selector step 4750 current loss 1.118639, current_train_items 131024.
I0207 18:38:19.334142 134948952962560 run.py:783] (val) algo activity_selector step 4750: {'selected': 0.9553398058252427, 'score': 0.9553398058252427, 'examples_seen': 131024, 'step': 4750, 'algorithm': 'activity_selector'}
I0207 18:38:19.334380 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0207 18:38:20.613811 134948952962560 run.py:748] Algo activity_selector step 4800 current loss 0.719527, current_train_items 132400.
I0207 18:38:20.830804 134948952962560 run.py:783] (val) algo activity_selector step 4800: {'selected': 0.9448818897637796, 'score': 0.9448818897637796, 'examples_seen': 132400, 'step': 4800, 'algorithm': 'activity_selector'}
I0207 18:38:20.831022 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0207 18:38:22.085502 134948952962560 run.py:748] Algo activity_selector step 4850 current loss 0.820115, current_train_items 133760.
I0207 18:38:22.290589 134948952962560 run.py:783] (val) algo activity_selector step 4850: {'selected': 0.9120879120879121, 'score': 0.9120879120879121, 'examples_seen': 133760, 'step': 4850, 'algorithm': 'activity_selector'}
I0207 18:38:22.290813 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0207 18:38:23.542740 134948952962560 run.py:748] Algo activity_selector step 4900 current loss 0.615795, current_train_items 135168.
I0207 18:38:23.747750 134948952962560 run.py:783] (val) algo activity_selector step 4900: {'selected': 0.9608938547486034, 'score': 0.9608938547486034, 'examples_seen': 135168, 'step': 4900, 'algorithm': 'activity_selector'}
I0207 18:38:23.747977 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0207 18:38:25.008536 134948952962560 run.py:748] Algo activity_selector step 4950 current loss 0.615310, current_train_items 136528.
I0207 18:38:25.213021 134948952962560 run.py:783] (val) algo activity_selector step 4950: {'selected': 0.9254302103250478, 'score': 0.9254302103250478, 'examples_seen': 136528, 'step': 4950, 'algorithm': 'activity_selector'}
I0207 18:38:25.213259 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0207 18:38:26.523809 134948952962560 run.py:748] Algo activity_selector step 5000 current loss 0.610262, current_train_items 137920.
I0207 18:38:26.699832 134948952962560 run.py:783] (val) algo activity_selector step 5000: {'selected': 0.924187725631769, 'score': 0.924187725631769, 'examples_seen': 137920, 'step': 5000, 'algorithm': 'activity_selector'}
I0207 18:38:26.699980 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0207 18:38:27.964402 134948952962560 run.py:748] Algo activity_selector step 5050 current loss 0.711574, current_train_items 139296.
I0207 18:38:28.155307 134948952962560 run.py:783] (val) algo activity_selector step 5050: {'selected': 0.96, 'score': 0.96, 'examples_seen': 139296, 'step': 5050, 'algorithm': 'activity_selector'}
I0207 18:38:28.155531 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0207 18:38:29.444345 134948952962560 run.py:748] Algo activity_selector step 5100 current loss 0.821012, current_train_items 140656.
I0207 18:38:29.623924 134948952962560 run.py:783] (val) algo activity_selector step 5100: {'selected': 0.9628252788104089, 'score': 0.9628252788104089, 'examples_seen': 140656, 'step': 5100, 'algorithm': 'activity_selector'}
I0207 18:38:29.624151 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0207 18:38:30.903280 134948952962560 run.py:748] Algo activity_selector step 5150 current loss 0.952604, current_train_items 142048.
I0207 18:38:31.109212 134948952962560 run.py:783] (val) algo activity_selector step 5150: {'selected': 0.9506903353057199, 'score': 0.9506903353057199, 'examples_seen': 142048, 'step': 5150, 'algorithm': 'activity_selector'}
I0207 18:38:31.109453 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0207 18:38:32.369639 134948952962560 run.py:748] Algo activity_selector step 5200 current loss 0.634977, current_train_items 143424.
I0207 18:38:32.575157 134948952962560 run.py:783] (val) algo activity_selector step 5200: {'selected': 0.9351669941060903, 'score': 0.9351669941060903, 'examples_seen': 143424, 'step': 5200, 'algorithm': 'activity_selector'}
I0207 18:38:32.575395 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0207 18:38:33.864333 134948952962560 run.py:748] Algo activity_selector step 5250 current loss 0.842812, current_train_items 144816.
I0207 18:38:34.041940 134948952962560 run.py:783] (val) algo activity_selector step 5250: {'selected': 0.9487666034155599, 'score': 0.9487666034155599, 'examples_seen': 144816, 'step': 5250, 'algorithm': 'activity_selector'}
I0207 18:38:34.042092 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0207 18:38:35.308932 134948952962560 run.py:748] Algo activity_selector step 5300 current loss 0.911199, current_train_items 146176.
I0207 18:38:35.486714 134948952962560 run.py:783] (val) algo activity_selector step 5300: {'selected': 0.9400386847195357, 'score': 0.9400386847195357, 'examples_seen': 146176, 'step': 5300, 'algorithm': 'activity_selector'}
I0207 18:38:35.486939 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0207 18:38:36.816861 134948952962560 run.py:748] Algo activity_selector step 5350 current loss 0.563883, current_train_items 147584.
I0207 18:38:36.981949 134948952962560 run.py:783] (val) algo activity_selector step 5350: {'selected': 0.9297297297297297, 'score': 0.9297297297297297, 'examples_seen': 147584, 'step': 5350, 'algorithm': 'activity_selector'}
I0207 18:38:36.982172 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0207 18:38:38.269169 134948952962560 run.py:748] Algo activity_selector step 5400 current loss 0.837840, current_train_items 148944.
I0207 18:38:38.447692 134948952962560 run.py:783] (val) algo activity_selector step 5400: {'selected': 0.95, 'score': 0.95, 'examples_seen': 148944, 'step': 5400, 'algorithm': 'activity_selector'}
I0207 18:38:38.447864 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0207 18:38:39.714807 134948952962560 run.py:748] Algo activity_selector step 5450 current loss 0.675561, current_train_items 150304.
I0207 18:38:39.896986 134948952962560 run.py:783] (val) algo activity_selector step 5450: {'selected': 0.927643784786642, 'score': 0.927643784786642, 'examples_seen': 150304, 'step': 5450, 'algorithm': 'activity_selector'}
I0207 18:38:39.897210 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0207 18:38:41.194729 134948952962560 run.py:748] Algo activity_selector step 5500 current loss 0.846749, current_train_items 151712.
I0207 18:38:41.373780 134948952962560 run.py:783] (val) algo activity_selector step 5500: {'selected': 0.8950495049504951, 'score': 0.8950495049504951, 'examples_seen': 151712, 'step': 5500, 'algorithm': 'activity_selector'}
I0207 18:38:41.374007 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.895, val scores are: activity_selector: 0.895
I0207 18:38:42.672704 134948952962560 run.py:748] Algo activity_selector step 5550 current loss 0.821245, current_train_items 153072.
I0207 18:38:42.853613 134948952962560 run.py:783] (val) algo activity_selector step 5550: {'selected': 0.9518716577540106, 'score': 0.9518716577540106, 'examples_seen': 153072, 'step': 5550, 'algorithm': 'activity_selector'}
I0207 18:38:42.853837 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0207 18:38:44.128813 134948952962560 run.py:748] Algo activity_selector step 5600 current loss 0.647279, current_train_items 154464.
I0207 18:38:44.324533 134948952962560 run.py:783] (val) algo activity_selector step 5600: {'selected': 0.9662447257383967, 'score': 0.9662447257383967, 'examples_seen': 154464, 'step': 5600, 'algorithm': 'activity_selector'}
I0207 18:38:44.324779 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0207 18:38:45.579940 134948952962560 run.py:748] Algo activity_selector step 5650 current loss 0.571877, current_train_items 155840.
I0207 18:38:45.770810 134948952962560 run.py:783] (val) algo activity_selector step 5650: {'selected': 0.9379562043795621, 'score': 0.9379562043795621, 'examples_seen': 155840, 'step': 5650, 'algorithm': 'activity_selector'}
I0207 18:38:45.770960 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0207 18:38:47.075680 134948952962560 run.py:748] Algo activity_selector step 5700 current loss 0.659555, current_train_items 157216.
I0207 18:38:47.257509 134948952962560 run.py:783] (val) algo activity_selector step 5700: {'selected': 0.9039301310043668, 'score': 0.9039301310043668, 'examples_seen': 157216, 'step': 5700, 'algorithm': 'activity_selector'}
I0207 18:38:47.257735 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.904, val scores are: activity_selector: 0.904
I0207 18:38:48.535331 134948952962560 run.py:748] Algo activity_selector step 5750 current loss 0.770093, current_train_items 158592.
I0207 18:38:48.712823 134948952962560 run.py:783] (val) algo activity_selector step 5750: {'selected': 0.9498997995991985, 'score': 0.9498997995991985, 'examples_seen': 158592, 'step': 5750, 'algorithm': 'activity_selector'}
I0207 18:38:48.713063 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0207 18:38:49.978762 134948952962560 run.py:748] Algo activity_selector step 5800 current loss 0.663559, current_train_items 159968.
I0207 18:38:50.170568 134948952962560 run.py:783] (val) algo activity_selector step 5800: {'selected': 0.9420560747663551, 'score': 0.9420560747663551, 'examples_seen': 159968, 'step': 5800, 'algorithm': 'activity_selector'}
I0207 18:38:50.170792 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0207 18:38:51.461583 134948952962560 run.py:748] Algo activity_selector step 5850 current loss 0.842185, current_train_items 161360.
I0207 18:38:51.653923 134948952962560 run.py:783] (val) algo activity_selector step 5850: {'selected': 0.9421157684630739, 'score': 0.9421157684630739, 'examples_seen': 161360, 'step': 5850, 'algorithm': 'activity_selector'}
I0207 18:38:51.654147 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0207 18:38:52.947697 134948952962560 run.py:748] Algo activity_selector step 5900 current loss 0.823420, current_train_items 162720.
I0207 18:38:53.124143 134948952962560 run.py:783] (val) algo activity_selector step 5900: {'selected': 0.9394495412844037, 'score': 0.9394495412844037, 'examples_seen': 162720, 'step': 5900, 'algorithm': 'activity_selector'}
I0207 18:38:53.124302 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0207 18:38:54.392929 134948952962560 run.py:748] Algo activity_selector step 5950 current loss 0.531344, current_train_items 164112.
I0207 18:38:54.572943 134948952962560 run.py:783] (val) algo activity_selector step 5950: {'selected': 0.9261477045908184, 'score': 0.9261477045908184, 'examples_seen': 164112, 'step': 5950, 'algorithm': 'activity_selector'}
I0207 18:38:54.573165 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0207 18:38:55.861664 134948952962560 run.py:748] Algo activity_selector step 6000 current loss 0.626358, current_train_items 165488.
I0207 18:38:56.040688 134948952962560 run.py:783] (val) algo activity_selector step 6000: {'selected': 0.9321428571428572, 'score': 0.9321428571428572, 'examples_seen': 165488, 'step': 6000, 'algorithm': 'activity_selector'}
I0207 18:38:56.040913 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0207 18:38:57.354041 134948952962560 run.py:748] Algo activity_selector step 6050 current loss 0.596245, current_train_items 166864.
I0207 18:38:57.534117 134948952962560 run.py:783] (val) algo activity_selector step 6050: {'selected': 0.9301397205588822, 'score': 0.9301397205588822, 'examples_seen': 166864, 'step': 6050, 'algorithm': 'activity_selector'}
I0207 18:38:57.534343 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0207 18:38:58.807559 134948952962560 run.py:748] Algo activity_selector step 6100 current loss 0.726765, current_train_items 168256.
I0207 18:38:58.991216 134948952962560 run.py:783] (val) algo activity_selector step 6100: {'selected': 0.9102296450939458, 'score': 0.9102296450939458, 'examples_seen': 168256, 'step': 6100, 'algorithm': 'activity_selector'}
I0207 18:38:58.991456 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0207 18:39:00.295768 134948952962560 run.py:748] Algo activity_selector step 6150 current loss 0.855988, current_train_items 169616.
I0207 18:39:00.461381 134948952962560 run.py:783] (val) algo activity_selector step 6150: {'selected': 0.9576271186440677, 'score': 0.9576271186440677, 'examples_seen': 169616, 'step': 6150, 'algorithm': 'activity_selector'}
I0207 18:39:00.461616 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0207 18:39:01.725208 134948952962560 run.py:748] Algo activity_selector step 6200 current loss 0.523685, current_train_items 171008.
I0207 18:39:01.926544 134948952962560 run.py:783] (val) algo activity_selector step 6200: {'selected': 0.9322381930184805, 'score': 0.9322381930184805, 'examples_seen': 171008, 'step': 6200, 'algorithm': 'activity_selector'}
I0207 18:39:01.926774 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0207 18:39:03.226856 134948952962560 run.py:748] Algo activity_selector step 6250 current loss 0.627619, current_train_items 172384.
I0207 18:39:03.408847 134948952962560 run.py:783] (val) algo activity_selector step 6250: {'selected': 0.9693486590038315, 'score': 0.9693486590038315, 'examples_seen': 172384, 'step': 6250, 'algorithm': 'activity_selector'}
I0207 18:39:03.409072 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0207 18:39:04.726705 134948952962560 run.py:748] Algo activity_selector step 6300 current loss 0.444014, current_train_items 173760.
I0207 18:39:04.920299 134948952962560 run.py:783] (val) algo activity_selector step 6300: {'selected': 0.967741935483871, 'score': 0.967741935483871, 'examples_seen': 173760, 'step': 6300, 'algorithm': 'activity_selector'}
I0207 18:39:04.920526 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0207 18:39:06.237198 134948952962560 run.py:748] Algo activity_selector step 6350 current loss 0.525571, current_train_items 175136.
I0207 18:39:06.436090 134948952962560 run.py:783] (val) algo activity_selector step 6350: {'selected': 0.9282868525896414, 'score': 0.9282868525896414, 'examples_seen': 175136, 'step': 6350, 'algorithm': 'activity_selector'}
I0207 18:39:06.436280 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0207 18:39:07.720834 134948952962560 run.py:748] Algo activity_selector step 6400 current loss 0.729865, current_train_items 176528.
I0207 18:39:07.899933 134948952962560 run.py:783] (val) algo activity_selector step 6400: {'selected': 0.9317269076305221, 'score': 0.9317269076305221, 'examples_seen': 176528, 'step': 6400, 'algorithm': 'activity_selector'}
I0207 18:39:07.900085 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0207 18:39:09.234167 134948952962560 run.py:748] Algo activity_selector step 6450 current loss 0.422595, current_train_items 177904.
I0207 18:39:09.417807 134948952962560 run.py:783] (val) algo activity_selector step 6450: {'selected': 0.948905109489051, 'score': 0.948905109489051, 'examples_seen': 177904, 'step': 6450, 'algorithm': 'activity_selector'}
I0207 18:39:09.418033 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0207 18:39:10.689352 134948952962560 run.py:748] Algo activity_selector step 6500 current loss 0.590038, current_train_items 179264.
I0207 18:39:10.895461 134948952962560 run.py:783] (val) algo activity_selector step 6500: {'selected': 0.953405017921147, 'score': 0.953405017921147, 'examples_seen': 179264, 'step': 6500, 'algorithm': 'activity_selector'}
I0207 18:39:10.895622 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0207 18:39:12.243584 134948952962560 run.py:748] Algo activity_selector step 6550 current loss 0.634311, current_train_items 180656.
I0207 18:39:12.448504 134948952962560 run.py:783] (val) algo activity_selector step 6550: {'selected': 0.9550561797752809, 'score': 0.9550561797752809, 'examples_seen': 180656, 'step': 6550, 'algorithm': 'activity_selector'}
I0207 18:39:12.448750 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0207 18:39:13.832587 134948952962560 run.py:748] Algo activity_selector step 6600 current loss 0.884473, current_train_items 182032.
I0207 18:39:14.020000 134948952962560 run.py:783] (val) algo activity_selector step 6600: {'selected': 0.9104204753199269, 'score': 0.9104204753199269, 'examples_seen': 182032, 'step': 6600, 'algorithm': 'activity_selector'}
I0207 18:39:14.020257 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0207 18:39:15.362222 134948952962560 run.py:748] Algo activity_selector step 6650 current loss 1.218369, current_train_items 183408.
I0207 18:39:15.553618 134948952962560 run.py:783] (val) algo activity_selector step 6650: {'selected': 0.8261682242990653, 'score': 0.8261682242990653, 'examples_seen': 183408, 'step': 6650, 'algorithm': 'activity_selector'}
I0207 18:39:15.553866 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.826, val scores are: activity_selector: 0.826
I0207 18:39:16.889795 134948952962560 run.py:748] Algo activity_selector step 6700 current loss 0.399815, current_train_items 184800.
I0207 18:39:17.092842 134948952962560 run.py:783] (val) algo activity_selector step 6700: {'selected': 0.9496981891348089, 'score': 0.9496981891348089, 'examples_seen': 184800, 'step': 6700, 'algorithm': 'activity_selector'}
I0207 18:39:17.093103 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0207 18:39:18.451903 134948952962560 run.py:748] Algo activity_selector step 6750 current loss 0.683910, current_train_items 186176.
I0207 18:39:18.638840 134948952962560 run.py:783] (val) algo activity_selector step 6750: {'selected': 0.9502982107355864, 'score': 0.9502982107355864, 'examples_seen': 186176, 'step': 6750, 'algorithm': 'activity_selector'}
I0207 18:39:18.639117 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0207 18:39:20.012855 134948952962560 run.py:748] Algo activity_selector step 6800 current loss 0.570234, current_train_items 187536.
I0207 18:39:20.186876 134948952962560 run.py:783] (val) algo activity_selector step 6800: {'selected': 0.9498069498069499, 'score': 0.9498069498069499, 'examples_seen': 187536, 'step': 6800, 'algorithm': 'activity_selector'}
I0207 18:39:20.187118 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0207 18:39:21.585139 134948952962560 run.py:748] Algo activity_selector step 6850 current loss 0.866622, current_train_items 188928.
I0207 18:39:21.775644 134948952962560 run.py:783] (val) algo activity_selector step 6850: {'selected': 0.9394495412844036, 'score': 0.9394495412844036, 'examples_seen': 188928, 'step': 6850, 'algorithm': 'activity_selector'}
I0207 18:39:21.775804 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0207 18:39:23.150052 134948952962560 run.py:748] Algo activity_selector step 6900 current loss 0.665489, current_train_items 190304.
I0207 18:39:23.334411 134948952962560 run.py:783] (val) algo activity_selector step 6900: {'selected': 0.9688715953307394, 'score': 0.9688715953307394, 'examples_seen': 190304, 'step': 6900, 'algorithm': 'activity_selector'}
I0207 18:39:23.334640 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0207 18:39:24.680872 134948952962560 run.py:748] Algo activity_selector step 6950 current loss 0.716565, current_train_items 191680.
I0207 18:39:24.858647 134948952962560 run.py:783] (val) algo activity_selector step 6950: {'selected': 0.9559748427672956, 'score': 0.9559748427672956, 'examples_seen': 191680, 'step': 6950, 'algorithm': 'activity_selector'}
I0207 18:39:24.858874 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0207 18:39:26.170300 134948952962560 run.py:748] Algo activity_selector step 7000 current loss 0.735647, current_train_items 193072.
I0207 18:39:26.370111 134948952962560 run.py:783] (val) algo activity_selector step 7000: {'selected': 0.9623762376237623, 'score': 0.9623762376237623, 'examples_seen': 193072, 'step': 7000, 'algorithm': 'activity_selector'}
I0207 18:39:26.370379 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0207 18:39:27.690085 134948952962560 run.py:748] Algo activity_selector step 7050 current loss 0.642658, current_train_items 194448.
I0207 18:39:27.899273 134948952962560 run.py:783] (val) algo activity_selector step 7050: {'selected': 0.9052631578947369, 'score': 0.9052631578947369, 'examples_seen': 194448, 'step': 7050, 'algorithm': 'activity_selector'}
I0207 18:39:27.899451 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0207 18:39:29.240454 134948952962560 run.py:748] Algo activity_selector step 7100 current loss 0.567435, current_train_items 195824.
I0207 18:39:29.462190 134948952962560 run.py:783] (val) algo activity_selector step 7100: {'selected': 0.9568480300187618, 'score': 0.9568480300187618, 'examples_seen': 195824, 'step': 7100, 'algorithm': 'activity_selector'}
I0207 18:39:29.462492 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0207 18:39:30.818559 134948952962560 run.py:748] Algo activity_selector step 7150 current loss 0.770648, current_train_items 197200.
I0207 18:39:31.015621 134948952962560 run.py:783] (val) algo activity_selector step 7150: {'selected': 0.9446494464944649, 'score': 0.9446494464944649, 'examples_seen': 197200, 'step': 7150, 'algorithm': 'activity_selector'}
I0207 18:39:31.015878 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0207 18:39:32.393702 134948952962560 run.py:748] Algo activity_selector step 7200 current loss 0.913427, current_train_items 198576.
I0207 18:39:32.585394 134948952962560 run.py:783] (val) algo activity_selector step 7200: {'selected': 0.9407114624505929, 'score': 0.9407114624505929, 'examples_seen': 198576, 'step': 7200, 'algorithm': 'activity_selector'}
I0207 18:39:32.585633 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0207 18:39:33.949543 134948952962560 run.py:748] Algo activity_selector step 7250 current loss 0.621439, current_train_items 199952.
I0207 18:39:34.137977 134948952962560 run.py:783] (val) algo activity_selector step 7250: {'selected': 0.9722222222222223, 'score': 0.9722222222222223, 'examples_seen': 199952, 'step': 7250, 'algorithm': 'activity_selector'}
I0207 18:39:34.138207 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0207 18:39:35.464264 134948952962560 run.py:748] Algo activity_selector step 7300 current loss 0.549374, current_train_items 201344.
I0207 18:39:35.684427 134948952962560 run.py:783] (val) algo activity_selector step 7300: {'selected': 0.9547169811320756, 'score': 0.9547169811320756, 'examples_seen': 201344, 'step': 7300, 'algorithm': 'activity_selector'}
I0207 18:39:35.684599 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0207 18:39:37.000211 134948952962560 run.py:748] Algo activity_selector step 7350 current loss 0.764402, current_train_items 202720.
I0207 18:39:37.202600 134948952962560 run.py:783] (val) algo activity_selector step 7350: {'selected': 0.9444444444444444, 'score': 0.9444444444444444, 'examples_seen': 202720, 'step': 7350, 'algorithm': 'activity_selector'}
I0207 18:39:37.202829 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0207 18:39:38.554222 134948952962560 run.py:748] Algo activity_selector step 7400 current loss 0.786354, current_train_items 204080.
I0207 18:39:38.735980 134948952962560 run.py:783] (val) algo activity_selector step 7400: {'selected': 0.9576923076923076, 'score': 0.9576923076923076, 'examples_seen': 204080, 'step': 7400, 'algorithm': 'activity_selector'}
I0207 18:39:38.736206 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0207 18:39:40.065940 134948952962560 run.py:748] Algo activity_selector step 7450 current loss 0.685927, current_train_items 205488.
I0207 18:39:40.246666 134948952962560 run.py:783] (val) algo activity_selector step 7450: {'selected': 0.9343065693430657, 'score': 0.9343065693430657, 'examples_seen': 205488, 'step': 7450, 'algorithm': 'activity_selector'}
I0207 18:39:40.246898 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0207 18:39:41.607020 134948952962560 run.py:748] Algo activity_selector step 7500 current loss 0.670786, current_train_items 206848.
I0207 18:39:41.795027 134948952962560 run.py:783] (val) algo activity_selector step 7500: {'selected': 0.9659090909090908, 'score': 0.9659090909090908, 'examples_seen': 206848, 'step': 7500, 'algorithm': 'activity_selector'}
I0207 18:39:41.795316 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0207 18:39:43.142410 134948952962560 run.py:748] Algo activity_selector step 7550 current loss 0.548359, current_train_items 208224.
I0207 18:39:43.328118 134948952962560 run.py:783] (val) algo activity_selector step 7550: {'selected': 0.9284332688588008, 'score': 0.9284332688588008, 'examples_seen': 208224, 'step': 7550, 'algorithm': 'activity_selector'}
I0207 18:39:43.328386 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0207 18:39:44.664361 134948952962560 run.py:748] Algo activity_selector step 7600 current loss 0.758087, current_train_items 209616.
I0207 18:39:44.843109 134948952962560 run.py:783] (val) algo activity_selector step 7600: {'selected': 0.9709864603481624, 'score': 0.9709864603481624, 'examples_seen': 209616, 'step': 7600, 'algorithm': 'activity_selector'}
I0207 18:39:44.843362 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0207 18:39:46.166238 134948952962560 run.py:748] Algo activity_selector step 7650 current loss 0.788372, current_train_items 210976.
I0207 18:39:46.360883 134948952962560 run.py:783] (val) algo activity_selector step 7650: {'selected': 0.9418386491557224, 'score': 0.9418386491557224, 'examples_seen': 210976, 'step': 7650, 'algorithm': 'activity_selector'}
I0207 18:39:46.361126 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0207 18:39:47.699361 134948952962560 run.py:748] Algo activity_selector step 7700 current loss 0.776576, current_train_items 212368.
I0207 18:39:47.884463 134948952962560 run.py:783] (val) algo activity_selector step 7700: {'selected': 0.9558232931726907, 'score': 0.9558232931726907, 'examples_seen': 212368, 'step': 7700, 'algorithm': 'activity_selector'}
I0207 18:39:47.884724 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0207 18:39:49.197247 134948952962560 run.py:748] Algo activity_selector step 7750 current loss 0.604447, current_train_items 213744.
I0207 18:39:49.401355 134948952962560 run.py:783] (val) algo activity_selector step 7750: {'selected': 0.9694656488549618, 'score': 0.9694656488549618, 'examples_seen': 213744, 'step': 7750, 'algorithm': 'activity_selector'}
I0207 18:39:49.401640 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0207 18:39:50.742507 134948952962560 run.py:748] Algo activity_selector step 7800 current loss 0.736183, current_train_items 215136.
I0207 18:39:50.923556 134948952962560 run.py:783] (val) algo activity_selector step 7800: {'selected': 0.9416195856873822, 'score': 0.9416195856873822, 'examples_seen': 215136, 'step': 7800, 'algorithm': 'activity_selector'}
I0207 18:39:50.923780 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0207 18:39:52.283239 134948952962560 run.py:748] Algo activity_selector step 7850 current loss 0.568795, current_train_items 216496.
I0207 18:39:52.469505 134948952962560 run.py:783] (val) algo activity_selector step 7850: {'selected': 0.9612403100775193, 'score': 0.9612403100775193, 'examples_seen': 216496, 'step': 7850, 'algorithm': 'activity_selector'}
I0207 18:39:52.469773 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0207 18:39:53.774411 134948952962560 run.py:748] Algo activity_selector step 7900 current loss 0.459894, current_train_items 217888.
I0207 18:39:53.985926 134948952962560 run.py:783] (val) algo activity_selector step 7900: {'selected': 0.9681050656660414, 'score': 0.9681050656660414, 'examples_seen': 217888, 'step': 7900, 'algorithm': 'activity_selector'}
I0207 18:39:53.986158 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0207 18:39:55.324987 134948952962560 run.py:748] Algo activity_selector step 7950 current loss 0.522718, current_train_items 219264.
I0207 18:39:55.538137 134948952962560 run.py:783] (val) algo activity_selector step 7950: {'selected': 0.9684601113172542, 'score': 0.9684601113172542, 'examples_seen': 219264, 'step': 7950, 'algorithm': 'activity_selector'}
I0207 18:39:55.538374 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0207 18:39:56.845655 134948952962560 run.py:748] Algo activity_selector step 8000 current loss 0.641158, current_train_items 220624.
I0207 18:39:57.043315 134948952962560 run.py:783] (val) algo activity_selector step 8000: {'selected': 0.9208103130755063, 'score': 0.9208103130755063, 'examples_seen': 220624, 'step': 8000, 'algorithm': 'activity_selector'}
I0207 18:39:57.043540 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0207 18:39:58.422042 134948952962560 run.py:748] Algo activity_selector step 8050 current loss 0.553464, current_train_items 222032.
I0207 18:39:58.604111 134948952962560 run.py:783] (val) algo activity_selector step 8050: {'selected': 0.9565217391304347, 'score': 0.9565217391304347, 'examples_seen': 222032, 'step': 8050, 'algorithm': 'activity_selector'}
I0207 18:39:58.604346 134948952962560 run.py:804] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0207 18:40:00.081236 134948952962560 run.py:748] Algo activity_selector step 8100 current loss 0.591310, current_train_items 223392.
I0207 18:40:00.310710 134948952962560 run.py:783] (val) algo activity_selector step 8100: {'selected': 0.9421157684630739, 'score': 0.9421157684630739, 'examples_seen': 223392, 'step': 8100, 'algorithm': 'activity_selector'}
I0207 18:40:00.310979 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.957, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0207 18:40:01.674807 134948952962560 run.py:748] Algo activity_selector step 8150 current loss 0.618549, current_train_items 224784.
I0207 18:40:01.871304 134948952962560 run.py:783] (val) algo activity_selector step 8150: {'selected': 0.9578544061302682, 'score': 0.9578544061302682, 'examples_seen': 224784, 'step': 8150, 'algorithm': 'activity_selector'}
I0207 18:40:01.871534 134948952962560 run.py:804] Checkpointing best model, best avg val score was 0.957, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0207 18:40:03.391316 134948952962560 run.py:748] Algo activity_selector step 8200 current loss 0.604421, current_train_items 226160.
I0207 18:40:03.587267 134948952962560 run.py:783] (val) algo activity_selector step 8200: {'selected': 0.9367088607594937, 'score': 0.9367088607594937, 'examples_seen': 226160, 'step': 8200, 'algorithm': 'activity_selector'}
I0207 18:40:03.587495 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.958, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0207 18:40:04.878123 134948952962560 run.py:748] Algo activity_selector step 8250 current loss 0.549827, current_train_items 227520.
I0207 18:40:05.092292 134948952962560 run.py:783] (val) algo activity_selector step 8250: {'selected': 0.9659090909090908, 'score': 0.9659090909090908, 'examples_seen': 227520, 'step': 8250, 'algorithm': 'activity_selector'}
I0207 18:40:05.092547 134948952962560 run.py:804] Checkpointing best model, best avg val score was 0.958, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0207 18:40:06.613604 134948952962560 run.py:748] Algo activity_selector step 8300 current loss 0.534671, current_train_items 228912.
I0207 18:40:06.804580 134948952962560 run.py:783] (val) algo activity_selector step 8300: {'selected': 0.9592233009708738, 'score': 0.9592233009708738, 'examples_seen': 228912, 'step': 8300, 'algorithm': 'activity_selector'}
I0207 18:40:06.804766 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0207 18:40:08.171696 134948952962560 run.py:748] Algo activity_selector step 8350 current loss 0.437650, current_train_items 230288.
I0207 18:40:08.365944 134948952962560 run.py:783] (val) algo activity_selector step 8350: {'selected': 0.9463955637707948, 'score': 0.9463955637707948, 'examples_seen': 230288, 'step': 8350, 'algorithm': 'activity_selector'}
I0207 18:40:08.366122 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0207 18:40:09.750464 134948952962560 run.py:748] Algo activity_selector step 8400 current loss 0.497741, current_train_items 231680.
I0207 18:40:09.946656 134948952962560 run.py:783] (val) algo activity_selector step 8400: {'selected': 0.9514563106796116, 'score': 0.9514563106796116, 'examples_seen': 231680, 'step': 8400, 'algorithm': 'activity_selector'}
I0207 18:40:09.946857 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0207 18:40:11.319923 134948952962560 run.py:748] Algo activity_selector step 8450 current loss 0.593251, current_train_items 233040.
I0207 18:40:11.514024 134948952962560 run.py:783] (val) algo activity_selector step 8450: {'selected': 0.9177330895795247, 'score': 0.9177330895795247, 'examples_seen': 233040, 'step': 8450, 'algorithm': 'activity_selector'}
I0207 18:40:11.514237 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.918, val scores are: activity_selector: 0.918
I0207 18:40:12.861609 134948952962560 run.py:748] Algo activity_selector step 8500 current loss 0.709123, current_train_items 234432.
I0207 18:40:13.051890 134948952962560 run.py:783] (val) algo activity_selector step 8500: {'selected': 0.9595375722543352, 'score': 0.9595375722543352, 'examples_seen': 234432, 'step': 8500, 'algorithm': 'activity_selector'}
I0207 18:40:13.052137 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0207 18:40:14.425270 134948952962560 run.py:748] Algo activity_selector step 8550 current loss 0.512132, current_train_items 235808.
I0207 18:40:14.614541 134948952962560 run.py:783] (val) algo activity_selector step 8550: {'selected': 0.9219330855018588, 'score': 0.9219330855018588, 'examples_seen': 235808, 'step': 8550, 'algorithm': 'activity_selector'}
I0207 18:40:14.614749 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0207 18:40:15.963549 134948952962560 run.py:748] Algo activity_selector step 8600 current loss 0.556333, current_train_items 237168.
I0207 18:40:16.175284 134948952962560 run.py:783] (val) algo activity_selector step 8600: {'selected': 0.927710843373494, 'score': 0.927710843373494, 'examples_seen': 237168, 'step': 8600, 'algorithm': 'activity_selector'}
I0207 18:40:16.175553 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0207 18:40:17.499070 134948952962560 run.py:748] Algo activity_selector step 8650 current loss 0.674080, current_train_items 238576.
I0207 18:40:17.678313 134948952962560 run.py:783] (val) algo activity_selector step 8650: {'selected': 0.9171483622350675, 'score': 0.9171483622350675, 'examples_seen': 238576, 'step': 8650, 'algorithm': 'activity_selector'}
I0207 18:40:17.678576 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0207 18:40:19.050656 134948952962560 run.py:748] Algo activity_selector step 8700 current loss 0.600979, current_train_items 239936.
I0207 18:40:19.255440 134948952962560 run.py:783] (val) algo activity_selector step 8700: {'selected': 0.9326047358834245, 'score': 0.9326047358834245, 'examples_seen': 239936, 'step': 8700, 'algorithm': 'activity_selector'}
I0207 18:40:19.255695 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0207 18:40:20.617164 134948952962560 run.py:748] Algo activity_selector step 8750 current loss 0.658664, current_train_items 241328.
I0207 18:40:20.824700 134948952962560 run.py:783] (val) algo activity_selector step 8750: {'selected': 0.945179584120983, 'score': 0.945179584120983, 'examples_seen': 241328, 'step': 8750, 'algorithm': 'activity_selector'}
I0207 18:40:20.824958 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0207 18:40:22.205114 134948952962560 run.py:748] Algo activity_selector step 8800 current loss 0.446785, current_train_items 242704.
I0207 18:40:22.400732 134948952962560 run.py:783] (val) algo activity_selector step 8800: {'selected': 0.962962962962963, 'score': 0.962962962962963, 'examples_seen': 242704, 'step': 8800, 'algorithm': 'activity_selector'}
I0207 18:40:22.400978 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0207 18:40:23.790017 134948952962560 run.py:748] Algo activity_selector step 8850 current loss 0.618949, current_train_items 244080.
I0207 18:40:23.985906 134948952962560 run.py:783] (val) algo activity_selector step 8850: {'selected': 0.9592233009708738, 'score': 0.9592233009708738, 'examples_seen': 244080, 'step': 8850, 'algorithm': 'activity_selector'}
I0207 18:40:23.986179 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0207 18:40:25.379506 134948952962560 run.py:748] Algo activity_selector step 8900 current loss 0.650538, current_train_items 245456.
I0207 18:40:25.553579 134948952962560 run.py:783] (val) algo activity_selector step 8900: {'selected': 0.9203883495145632, 'score': 0.9203883495145632, 'examples_seen': 245456, 'step': 8900, 'algorithm': 'activity_selector'}
I0207 18:40:25.553775 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0207 18:40:26.915170 134948952962560 run.py:748] Algo activity_selector step 8950 current loss 0.900264, current_train_items 246832.
I0207 18:40:27.111726 134948952962560 run.py:783] (val) algo activity_selector step 8950: {'selected': 0.9142857142857143, 'score': 0.9142857142857143, 'examples_seen': 246832, 'step': 8950, 'algorithm': 'activity_selector'}
I0207 18:40:27.111941 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0207 18:40:28.477212 134948952962560 run.py:748] Algo activity_selector step 9000 current loss 0.617878, current_train_items 248224.
I0207 18:40:28.665983 134948952962560 run.py:783] (val) algo activity_selector step 9000: {'selected': 0.9018181818181817, 'score': 0.9018181818181817, 'examples_seen': 248224, 'step': 9000, 'algorithm': 'activity_selector'}
I0207 18:40:28.666244 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0207 18:40:29.995998 134948952962560 run.py:748] Algo activity_selector step 9050 current loss 0.702274, current_train_items 249584.
I0207 18:40:30.196277 134948952962560 run.py:783] (val) algo activity_selector step 9050: {'selected': 0.9581749049429659, 'score': 0.9581749049429659, 'examples_seen': 249584, 'step': 9050, 'algorithm': 'activity_selector'}
I0207 18:40:30.196513 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0207 18:40:31.563961 134948952962560 run.py:748] Algo activity_selector step 9100 current loss 0.761447, current_train_items 250976.
I0207 18:40:31.759450 134948952962560 run.py:783] (val) algo activity_selector step 9100: {'selected': 0.9631067961165048, 'score': 0.9631067961165048, 'examples_seen': 250976, 'step': 9100, 'algorithm': 'activity_selector'}
I0207 18:40:31.759700 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0207 18:40:33.133994 134948952962560 run.py:748] Algo activity_selector step 9150 current loss 0.560239, current_train_items 252352.
I0207 18:40:33.339957 134948952962560 run.py:783] (val) algo activity_selector step 9150: {'selected': 0.9521988527724665, 'score': 0.9521988527724665, 'examples_seen': 252352, 'step': 9150, 'algorithm': 'activity_selector'}
I0207 18:40:33.340247 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0207 18:40:34.698580 134948952962560 run.py:748] Algo activity_selector step 9200 current loss 0.561711, current_train_items 253728.
I0207 18:40:34.897546 134948952962560 run.py:783] (val) algo activity_selector step 9200: {'selected': 0.9291044776119403, 'score': 0.9291044776119403, 'examples_seen': 253728, 'step': 9200, 'algorithm': 'activity_selector'}
I0207 18:40:34.897783 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0207 18:40:36.294798 134948952962560 run.py:748] Algo activity_selector step 9250 current loss 0.596210, current_train_items 255120.
I0207 18:40:36.486961 134948952962560 run.py:783] (val) algo activity_selector step 9250: {'selected': 0.9323308270676692, 'score': 0.9323308270676692, 'examples_seen': 255120, 'step': 9250, 'algorithm': 'activity_selector'}
I0207 18:40:36.487119 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0207 18:40:37.918022 134948952962560 run.py:748] Algo activity_selector step 9300 current loss 0.597645, current_train_items 256480.
I0207 18:40:38.087042 134948952962560 run.py:783] (val) algo activity_selector step 9300: {'selected': 0.9446494464944649, 'score': 0.9446494464944649, 'examples_seen': 256480, 'step': 9300, 'algorithm': 'activity_selector'}
I0207 18:40:38.087289 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0207 18:40:39.490347 134948952962560 run.py:748] Algo activity_selector step 9350 current loss 0.872892, current_train_items 257856.
I0207 18:40:39.689324 134948952962560 run.py:783] (val) algo activity_selector step 9350: {'selected': 0.9539594843462246, 'score': 0.9539594843462246, 'examples_seen': 257856, 'step': 9350, 'algorithm': 'activity_selector'}
I0207 18:40:39.689571 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0207 18:40:41.091087 134948952962560 run.py:748] Algo activity_selector step 9400 current loss 0.602787, current_train_items 259248.
I0207 18:40:41.289695 134948952962560 run.py:783] (val) algo activity_selector step 9400: {'selected': 0.9222222222222222, 'score': 0.9222222222222222, 'examples_seen': 259248, 'step': 9400, 'algorithm': 'activity_selector'}
I0207 18:40:41.290067 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0207 18:40:42.709060 134948952962560 run.py:748] Algo activity_selector step 9450 current loss 0.672562, current_train_items 260624.
I0207 18:40:42.904163 134948952962560 run.py:783] (val) algo activity_selector step 9450: {'selected': 0.9179687499999999, 'score': 0.9179687499999999, 'examples_seen': 260624, 'step': 9450, 'algorithm': 'activity_selector'}
I0207 18:40:42.904515 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.918, val scores are: activity_selector: 0.918
I0207 18:40:44.312298 134948952962560 run.py:748] Algo activity_selector step 9500 current loss 0.554294, current_train_items 262000.
I0207 18:40:44.504111 134948952962560 run.py:783] (val) algo activity_selector step 9500: {'selected': 0.9598470363288719, 'score': 0.9598470363288719, 'examples_seen': 262000, 'step': 9500, 'algorithm': 'activity_selector'}
I0207 18:40:44.504356 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0207 18:40:45.826435 134948952962560 run.py:748] Algo activity_selector step 9550 current loss 0.499734, current_train_items 263392.
I0207 18:40:46.018198 134948952962560 run.py:783] (val) algo activity_selector step 9550: {'selected': 0.9049586776859505, 'score': 0.9049586776859505, 'examples_seen': 263392, 'step': 9550, 'algorithm': 'activity_selector'}
I0207 18:40:46.018447 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0207 18:40:47.407704 134948952962560 run.py:748] Algo activity_selector step 9600 current loss 0.671755, current_train_items 264768.
I0207 18:40:47.600402 134948952962560 run.py:783] (val) algo activity_selector step 9600: {'selected': 0.9533468559837728, 'score': 0.9533468559837728, 'examples_seen': 264768, 'step': 9600, 'algorithm': 'activity_selector'}
I0207 18:40:47.600584 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0207 18:40:48.979584 134948952962560 run.py:748] Algo activity_selector step 9650 current loss 0.580544, current_train_items 266128.
I0207 18:40:49.161478 134948952962560 run.py:783] (val) algo activity_selector step 9650: {'selected': 0.9553398058252428, 'score': 0.9553398058252428, 'examples_seen': 266128, 'step': 9650, 'algorithm': 'activity_selector'}
I0207 18:40:49.161662 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.966, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0207 18:40:50.511836 134948952962560 run.py:748] Algo activity_selector step 9700 current loss 0.471588, current_train_items 267520.
I0207 18:40:50.720760 134948952962560 run.py:783] (val) algo activity_selector step 9700: {'selected': 0.9774436090225564, 'score': 0.9774436090225564, 'examples_seen': 267520, 'step': 9700, 'algorithm': 'activity_selector'}
I0207 18:40:50.721004 134948952962560 run.py:804] Checkpointing best model, best avg val score was 0.966, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0207 18:40:52.250150 134948952962560 run.py:748] Algo activity_selector step 9750 current loss 0.670514, current_train_items 268896.
I0207 18:40:52.442077 134948952962560 run.py:783] (val) algo activity_selector step 9750: {'selected': 0.9677419354838709, 'score': 0.9677419354838709, 'examples_seen': 268896, 'step': 9750, 'algorithm': 'activity_selector'}
I0207 18:40:52.442338 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0207 18:40:53.813689 134948952962560 run.py:748] Algo activity_selector step 9800 current loss 0.602426, current_train_items 270272.
I0207 18:40:54.008132 134948952962560 run.py:783] (val) algo activity_selector step 9800: {'selected': 0.9484126984126985, 'score': 0.9484126984126985, 'examples_seen': 270272, 'step': 9800, 'algorithm': 'activity_selector'}
I0207 18:40:54.008387 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0207 18:40:55.303358 134948952962560 run.py:748] Algo activity_selector step 9850 current loss 0.647833, current_train_items 271664.
I0207 18:40:55.508199 134948952962560 run.py:783] (val) algo activity_selector step 9850: {'selected': 0.9219858156028368, 'score': 0.9219858156028368, 'examples_seen': 271664, 'step': 9850, 'algorithm': 'activity_selector'}
I0207 18:40:55.508479 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0207 18:40:56.887284 134948952962560 run.py:748] Algo activity_selector step 9900 current loss 0.546096, current_train_items 273040.
I0207 18:40:57.078782 134948952962560 run.py:783] (val) algo activity_selector step 9900: {'selected': 0.9516441005802708, 'score': 0.9516441005802708, 'examples_seen': 273040, 'step': 9900, 'algorithm': 'activity_selector'}
I0207 18:40:57.079010 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0207 18:40:58.452526 134948952962560 run.py:748] Algo activity_selector step 9950 current loss 0.569151, current_train_items 274400.
I0207 18:40:58.645285 134948952962560 run.py:783] (val) algo activity_selector step 9950: {'selected': 0.9669902912621359, 'score': 0.9669902912621359, 'examples_seen': 274400, 'step': 9950, 'algorithm': 'activity_selector'}
I0207 18:40:58.645450 134948952962560 run.py:807] Not saving new best model, best avg val score was 0.977, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0207 18:40:59.973250 134948952962560 run.py:813] Restoring best model from checkpoint...
I0207 18:41:11.796106 134948952962560 run.py:828] (test) algo activity_selector : {'selected': 0.8904593639575972, 'score': 0.8904593639575972, 'examples_seen': 275760, 'step': 10000, 'algorithm': 'activity_selector'}
I0207 18:41:11.796320 134948952962560 run.py:830] Done!
