I0829 18:40:11.579855 129274868512256 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0829 18:40:11.582318 129274868512256 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0829 18:40:11.906221 129274868512256 run.py:412] Model: f4 ['activity_selector']
I0829 18:40:11.906318 129274868512256 run.py:414] algorithms ['activity_selector']
I0829 18:40:11.906485 129274868512256 run.py:415] train_lengths ['4', '7', '11', '13', '16']
I0829 18:40:11.906521 129274868512256 run.py:416] train_batch_size 16
I0829 18:40:11.906618 129274868512256 run.py:417] val_batch_size 16
I0829 18:40:11.906650 129274868512256 run.py:418] test_batch_size 16
I0829 18:40:11.906679 129274868512256 run.py:419] chunked_training True
I0829 18:40:11.906797 129274868512256 run.py:420] chunk_length 8
I0829 18:40:11.906827 129274868512256 run.py:421] train_steps 10000
I0829 18:40:11.906855 129274868512256 run.py:422] eval_every 50
I0829 18:40:11.906883 129274868512256 run.py:423] test_every 500
I0829 18:40:11.906910 129274868512256 run.py:424] hidden_size 128
I0829 18:40:11.906940 129274868512256 run.py:425] nb_msg_passing_steps 1
I0829 18:40:11.906967 129274868512256 run.py:426] learning_rate 0.001
I0829 18:40:11.907053 129274868512256 run.py:427] grad_clip_max_norm 1.0
I0829 18:40:11.907087 129274868512256 run.py:428] dropout_prob 0.0
I0829 18:40:11.907119 129274868512256 run.py:429] hint_teacher_forcing 0.0
I0829 18:40:11.907148 129274868512256 run.py:430] hint_mode encoded_decoded
I0829 18:40:11.907248 129274868512256 run.py:431] hint_repred_mode soft
I0829 18:40:11.907275 129274868512256 run.py:432] use_ln False
I0829 18:40:11.907305 129274868512256 run.py:433] use_lstm True
I0829 18:40:11.907332 129274868512256 run.py:434] nb_triplet_fts 8
I0829 18:40:11.907359 129274868512256 run.py:435] encoder_init xavier_on_scalars
I0829 18:40:11.907385 129274868512256 run.py:436] processor_type f4
I0829 18:40:11.907421 129274868512256 run.py:437] checkpoint_path CLRS30
I0829 18:40:11.907477 129274868512256 run.py:438] dataset_path CLRS30
I0829 18:40:11.907520 129274868512256 run.py:439] freeze_processor False
I0829 18:40:11.907560 129274868512256 run.py:440] reduction min
I0829 18:40:11.907604 129274868512256 run.py:441] activation elu
I0829 18:40:11.907645 129274868512256 run.py:442] restore_model 
I0829 18:40:11.907689 129274868512256 run.py:443] gated False
I0829 18:40:11.907719 129274868512256 run.py:444] gated_activation sigmoid
I0829 18:40:11.910746 129274868512256 run.py:470] Creating samplers for algo activity_selector
W0829 18:40:11.910964 129274868512256 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0829 18:40:11.911253 129274868512256 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0829 18:40:12.115444 129274868512256 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0829 18:40:12.357065 129274868512256 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0829 18:40:12.652643 129274868512256 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0829 18:40:12.978800 129274868512256 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0829 18:40:13.353255 129274868512256 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0829 18:40:13.353537 129274868512256 samplers.py:124] Creating a dataset with 64 samples.
I0829 18:40:13.379165 129274868512256 run.py:256] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0829 18:40:13.379910 129274868512256 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0829 18:40:13.383227 129274868512256 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0829 18:40:13.386577 129274868512256 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0829 18:40:13.442146 129274868512256 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W0829 18:40:13.463642 129274868512256 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x7592a20a7a60> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0829 18:40:39.168295 129274868512256 run.py:693] Algo activity_selector step 0 current loss 5.270394, current_train_items 16.
I0829 18:40:41.647629 129274868512256 run.py:728] (val) algo activity_selector step 0: {'selected': 0.0, 'score': 0.0, 'examples_seen': 16, 'step': 0, 'algorithm': 'activity_selector'}
I0829 18:40:41.647795 129274868512256 run.py:749] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.000, val scores are: activity_selector: 0.000
I0829 18:41:15.257671 129274868512256 run.py:693] Algo activity_selector step 50 current loss 3.838629, current_train_items 720.
I0829 18:41:15.273546 129274868512256 run.py:728] (val) algo activity_selector step 50: {'selected': 0.6426592797783933, 'score': 0.6426592797783933, 'examples_seen': 720, 'step': 50, 'algorithm': 'activity_selector'}
I0829 18:41:15.273701 129274868512256 run.py:749] Checkpointing best model, best avg val score was 0.000, current avg val score is 0.643, val scores are: activity_selector: 0.643
I0829 18:41:15.799320 129274868512256 run.py:693] Algo activity_selector step 100 current loss 3.811038, current_train_items 1408.
I0829 18:41:15.814977 129274868512256 run.py:728] (val) algo activity_selector step 100: {'selected': 0.6889952153110048, 'score': 0.6889952153110048, 'examples_seen': 1408, 'step': 100, 'algorithm': 'activity_selector'}
I0829 18:41:15.815136 129274868512256 run.py:749] Checkpointing best model, best avg val score was 0.643, current avg val score is 0.689, val scores are: activity_selector: 0.689
I0829 18:41:16.353303 129274868512256 run.py:693] Algo activity_selector step 150 current loss 3.543846, current_train_items 2080.
I0829 18:41:16.368547 129274868512256 run.py:728] (val) algo activity_selector step 150: {'selected': 0.6123348017621145, 'score': 0.6123348017621145, 'examples_seen': 2080, 'step': 150, 'algorithm': 'activity_selector'}
I0829 18:41:16.368695 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.689, current avg val score is 0.612, val scores are: activity_selector: 0.612
I0829 18:41:16.897249 129274868512256 run.py:693] Algo activity_selector step 200 current loss 3.303480, current_train_items 2784.
I0829 18:41:16.912355 129274868512256 run.py:728] (val) algo activity_selector step 200: {'selected': 0.702054794520548, 'score': 0.702054794520548, 'examples_seen': 2784, 'step': 200, 'algorithm': 'activity_selector'}
I0829 18:41:16.912501 129274868512256 run.py:749] Checkpointing best model, best avg val score was 0.689, current avg val score is 0.702, val scores are: activity_selector: 0.702
I0829 18:41:17.442126 129274868512256 run.py:693] Algo activity_selector step 250 current loss 3.076468, current_train_items 3488.
I0829 18:41:17.458302 129274868512256 run.py:728] (val) algo activity_selector step 250: {'selected': 0.7210626185958254, 'score': 0.7210626185958254, 'examples_seen': 3488, 'step': 250, 'algorithm': 'activity_selector'}
I0829 18:41:17.458471 129274868512256 run.py:749] Checkpointing best model, best avg val score was 0.702, current avg val score is 0.721, val scores are: activity_selector: 0.721
I0829 18:41:18.002786 129274868512256 run.py:693] Algo activity_selector step 300 current loss 3.020607, current_train_items 4144.
I0829 18:41:18.019479 129274868512256 run.py:728] (val) algo activity_selector step 300: {'selected': 0.7129455909943715, 'score': 0.7129455909943715, 'examples_seen': 4144, 'step': 300, 'algorithm': 'activity_selector'}
I0829 18:41:18.019625 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.721, current avg val score is 0.713, val scores are: activity_selector: 0.713
I0829 18:41:18.549942 129274868512256 run.py:693] Algo activity_selector step 350 current loss 2.541367, current_train_items 4848.
I0829 18:41:18.565515 129274868512256 run.py:728] (val) algo activity_selector step 350: {'selected': 0.7004048582995952, 'score': 0.7004048582995952, 'examples_seen': 4848, 'step': 350, 'algorithm': 'activity_selector'}
I0829 18:41:18.565677 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.721, current avg val score is 0.700, val scores are: activity_selector: 0.700
I0829 18:41:19.112739 129274868512256 run.py:693] Algo activity_selector step 400 current loss 2.802182, current_train_items 5552.
I0829 18:41:19.127666 129274868512256 run.py:728] (val) algo activity_selector step 400: {'selected': 0.7231040564373897, 'score': 0.7231040564373897, 'examples_seen': 5552, 'step': 400, 'algorithm': 'activity_selector'}
I0829 18:41:19.127824 129274868512256 run.py:749] Checkpointing best model, best avg val score was 0.721, current avg val score is 0.723, val scores are: activity_selector: 0.723
I0829 18:41:19.662642 129274868512256 run.py:693] Algo activity_selector step 450 current loss 2.094812, current_train_items 6224.
I0829 18:41:19.678906 129274868512256 run.py:728] (val) algo activity_selector step 450: {'selected': 0.75, 'score': 0.75, 'examples_seen': 6224, 'step': 450, 'algorithm': 'activity_selector'}
I0829 18:41:19.679069 129274868512256 run.py:749] Checkpointing best model, best avg val score was 0.723, current avg val score is 0.750, val scores are: activity_selector: 0.750
I0829 18:41:20.238447 129274868512256 run.py:693] Algo activity_selector step 500 current loss 2.099913, current_train_items 6912.
I0829 18:41:20.257657 129274868512256 run.py:728] (val) algo activity_selector step 500: {'selected': 0.7628458498023716, 'score': 0.7628458498023716, 'examples_seen': 6912, 'step': 500, 'algorithm': 'activity_selector'}
I0829 18:41:20.257826 129274868512256 run.py:749] Checkpointing best model, best avg val score was 0.750, current avg val score is 0.763, val scores are: activity_selector: 0.763
I0829 18:41:20.804282 129274868512256 run.py:693] Algo activity_selector step 550 current loss 1.846383, current_train_items 7616.
I0829 18:41:20.819446 129274868512256 run.py:728] (val) algo activity_selector step 550: {'selected': 0.6829268292682927, 'score': 0.6829268292682927, 'examples_seen': 7616, 'step': 550, 'algorithm': 'activity_selector'}
I0829 18:41:20.819592 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.763, current avg val score is 0.683, val scores are: activity_selector: 0.683
I0829 18:41:21.346009 129274868512256 run.py:693] Algo activity_selector step 600 current loss 2.480693, current_train_items 8288.
I0829 18:41:21.360850 129274868512256 run.py:728] (val) algo activity_selector step 600: {'selected': 0.7482014388489208, 'score': 0.7482014388489208, 'examples_seen': 8288, 'step': 600, 'algorithm': 'activity_selector'}
I0829 18:41:21.360993 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.763, current avg val score is 0.748, val scores are: activity_selector: 0.748
I0829 18:41:21.886065 129274868512256 run.py:693] Algo activity_selector step 650 current loss 2.418416, current_train_items 8976.
I0829 18:41:21.901401 129274868512256 run.py:728] (val) algo activity_selector step 650: {'selected': 0.7198581560283687, 'score': 0.7198581560283687, 'examples_seen': 8976, 'step': 650, 'algorithm': 'activity_selector'}
I0829 18:41:21.901559 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.763, current avg val score is 0.720, val scores are: activity_selector: 0.720
I0829 18:41:22.419622 129274868512256 run.py:693] Algo activity_selector step 700 current loss 1.708479, current_train_items 9680.
I0829 18:41:22.435289 129274868512256 run.py:728] (val) algo activity_selector step 700: {'selected': 0.7235494880546074, 'score': 0.7235494880546074, 'examples_seen': 9680, 'step': 700, 'algorithm': 'activity_selector'}
I0829 18:41:22.435439 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.763, current avg val score is 0.724, val scores are: activity_selector: 0.724
I0829 18:41:22.962558 129274868512256 run.py:693] Algo activity_selector step 750 current loss 1.715355, current_train_items 10368.
I0829 18:41:22.977375 129274868512256 run.py:728] (val) algo activity_selector step 750: {'selected': 0.736462093862816, 'score': 0.736462093862816, 'examples_seen': 10368, 'step': 750, 'algorithm': 'activity_selector'}
I0829 18:41:22.977524 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.763, current avg val score is 0.736, val scores are: activity_selector: 0.736
I0829 18:41:23.482528 129274868512256 run.py:693] Algo activity_selector step 800 current loss 2.486035, current_train_items 11056.
I0829 18:41:23.497390 129274868512256 run.py:728] (val) algo activity_selector step 800: {'selected': 0.7324955116696589, 'score': 0.7324955116696589, 'examples_seen': 11056, 'step': 800, 'algorithm': 'activity_selector'}
I0829 18:41:23.497534 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.763, current avg val score is 0.732, val scores are: activity_selector: 0.732
I0829 18:41:24.008818 129274868512256 run.py:693] Algo activity_selector step 850 current loss 1.821369, current_train_items 11744.
I0829 18:41:24.023712 129274868512256 run.py:728] (val) algo activity_selector step 850: {'selected': 0.7311072056239016, 'score': 0.7311072056239016, 'examples_seen': 11744, 'step': 850, 'algorithm': 'activity_selector'}
I0829 18:41:24.023907 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.763, current avg val score is 0.731, val scores are: activity_selector: 0.731
I0829 18:41:24.558107 129274868512256 run.py:693] Algo activity_selector step 900 current loss 1.892839, current_train_items 12432.
I0829 18:41:24.572718 129274868512256 run.py:728] (val) algo activity_selector step 900: {'selected': 0.701062215477997, 'score': 0.701062215477997, 'examples_seen': 12432, 'step': 900, 'algorithm': 'activity_selector'}
I0829 18:41:24.572864 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.763, current avg val score is 0.701, val scores are: activity_selector: 0.701
I0829 18:41:25.105934 129274868512256 run.py:693] Algo activity_selector step 950 current loss 1.755482, current_train_items 13120.
I0829 18:41:25.124161 129274868512256 run.py:728] (val) algo activity_selector step 950: {'selected': 0.8051948051948051, 'score': 0.8051948051948051, 'examples_seen': 13120, 'step': 950, 'algorithm': 'activity_selector'}
I0829 18:41:25.124362 129274868512256 run.py:749] Checkpointing best model, best avg val score was 0.763, current avg val score is 0.805, val scores are: activity_selector: 0.805
I0829 18:41:25.736852 129274868512256 run.py:693] Algo activity_selector step 1000 current loss 1.622632, current_train_items 13808.
I0829 18:41:25.755383 129274868512256 run.py:728] (val) algo activity_selector step 1000: {'selected': 0.744721689059501, 'score': 0.744721689059501, 'examples_seen': 13808, 'step': 1000, 'algorithm': 'activity_selector'}
I0829 18:41:25.755563 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.805, current avg val score is 0.745, val scores are: activity_selector: 0.745
I0829 18:41:26.381273 129274868512256 run.py:693] Algo activity_selector step 1050 current loss 1.702416, current_train_items 14496.
I0829 18:41:26.399911 129274868512256 run.py:728] (val) algo activity_selector step 1050: {'selected': 0.8161888701517706, 'score': 0.8161888701517706, 'examples_seen': 14496, 'step': 1050, 'algorithm': 'activity_selector'}
I0829 18:41:26.400074 129274868512256 run.py:749] Checkpointing best model, best avg val score was 0.805, current avg val score is 0.816, val scores are: activity_selector: 0.816
I0829 18:41:27.064767 129274868512256 run.py:693] Algo activity_selector step 1100 current loss 1.447844, current_train_items 15200.
I0829 18:41:27.082038 129274868512256 run.py:728] (val) algo activity_selector step 1100: {'selected': 0.7715930902111324, 'score': 0.7715930902111324, 'examples_seen': 15200, 'step': 1100, 'algorithm': 'activity_selector'}
I0829 18:41:27.082234 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.816, current avg val score is 0.772, val scores are: activity_selector: 0.772
I0829 18:41:27.628731 129274868512256 run.py:693] Algo activity_selector step 1150 current loss 1.694098, current_train_items 15888.
I0829 18:41:27.643512 129274868512256 run.py:728] (val) algo activity_selector step 1150: {'selected': 0.7801980198019801, 'score': 0.7801980198019801, 'examples_seen': 15888, 'step': 1150, 'algorithm': 'activity_selector'}
I0829 18:41:27.643664 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.816, current avg val score is 0.780, val scores are: activity_selector: 0.780
I0829 18:41:28.216808 129274868512256 run.py:693] Algo activity_selector step 1200 current loss 1.775292, current_train_items 16560.
I0829 18:41:28.232921 129274868512256 run.py:728] (val) algo activity_selector step 1200: {'selected': 0.7637795275590551, 'score': 0.7637795275590551, 'examples_seen': 16560, 'step': 1200, 'algorithm': 'activity_selector'}
I0829 18:41:28.233088 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.816, current avg val score is 0.764, val scores are: activity_selector: 0.764
I0829 18:41:28.805875 129274868512256 run.py:693] Algo activity_selector step 1250 current loss 1.563564, current_train_items 17264.
I0829 18:41:28.822440 129274868512256 run.py:728] (val) algo activity_selector step 1250: {'selected': 0.7575757575757577, 'score': 0.7575757575757577, 'examples_seen': 17264, 'step': 1250, 'algorithm': 'activity_selector'}
I0829 18:41:28.822595 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.816, current avg val score is 0.758, val scores are: activity_selector: 0.758
I0829 18:41:29.392417 129274868512256 run.py:693] Algo activity_selector step 1300 current loss 1.341059, current_train_items 17952.
I0829 18:41:29.408855 129274868512256 run.py:728] (val) algo activity_selector step 1300: {'selected': 0.7440944881889764, 'score': 0.7440944881889764, 'examples_seen': 17952, 'step': 1300, 'algorithm': 'activity_selector'}
I0829 18:41:29.409015 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.816, current avg val score is 0.744, val scores are: activity_selector: 0.744
I0829 18:41:30.009404 129274868512256 run.py:693] Algo activity_selector step 1350 current loss 1.590817, current_train_items 18624.
I0829 18:41:30.025589 129274868512256 run.py:728] (val) algo activity_selector step 1350: {'selected': 0.7553366174055829, 'score': 0.7553366174055829, 'examples_seen': 18624, 'step': 1350, 'algorithm': 'activity_selector'}
I0829 18:41:30.025751 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.816, current avg val score is 0.755, val scores are: activity_selector: 0.755
I0829 18:41:30.660267 129274868512256 run.py:693] Algo activity_selector step 1400 current loss 0.967409, current_train_items 19328.
I0829 18:41:30.678164 129274868512256 run.py:728] (val) algo activity_selector step 1400: {'selected': 0.7971014492753623, 'score': 0.7971014492753623, 'examples_seen': 19328, 'step': 1400, 'algorithm': 'activity_selector'}
I0829 18:41:30.678422 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.816, current avg val score is 0.797, val scores are: activity_selector: 0.797
I0829 18:41:31.423903 129274868512256 run.py:693] Algo activity_selector step 1450 current loss 1.091572, current_train_items 20016.
I0829 18:41:31.442230 129274868512256 run.py:728] (val) algo activity_selector step 1450: {'selected': 0.7588532883642496, 'score': 0.7588532883642496, 'examples_seen': 20016, 'step': 1450, 'algorithm': 'activity_selector'}
I0829 18:41:31.442489 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.816, current avg val score is 0.759, val scores are: activity_selector: 0.759
I0829 18:41:32.205865 129274868512256 run.py:693] Algo activity_selector step 1500 current loss 0.928454, current_train_items 20704.
I0829 18:41:32.232504 129274868512256 run.py:728] (val) algo activity_selector step 1500: {'selected': 0.802158273381295, 'score': 0.802158273381295, 'examples_seen': 20704, 'step': 1500, 'algorithm': 'activity_selector'}
I0829 18:41:32.232727 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.816, current avg val score is 0.802, val scores are: activity_selector: 0.802
I0829 18:41:32.925245 129274868512256 run.py:693] Algo activity_selector step 1550 current loss 1.953041, current_train_items 21392.
I0829 18:41:32.940709 129274868512256 run.py:728] (val) algo activity_selector step 1550: {'selected': 0.7804878048780488, 'score': 0.7804878048780488, 'examples_seen': 21392, 'step': 1550, 'algorithm': 'activity_selector'}
I0829 18:41:32.940871 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.816, current avg val score is 0.780, val scores are: activity_selector: 0.780
I0829 18:41:33.759501 129274868512256 run.py:693] Algo activity_selector step 1600 current loss 1.212250, current_train_items 22096.
I0829 18:41:33.784444 129274868512256 run.py:728] (val) algo activity_selector step 1600: {'selected': 0.7384615384615384, 'score': 0.7384615384615384, 'examples_seen': 22096, 'step': 1600, 'algorithm': 'activity_selector'}
I0829 18:41:33.784650 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.816, current avg val score is 0.738, val scores are: activity_selector: 0.738
I0829 18:41:34.429440 129274868512256 run.py:693] Algo activity_selector step 1650 current loss 1.344730, current_train_items 22768.
I0829 18:41:34.446460 129274868512256 run.py:728] (val) algo activity_selector step 1650: {'selected': 0.8171641791044776, 'score': 0.8171641791044776, 'examples_seen': 22768, 'step': 1650, 'algorithm': 'activity_selector'}
I0829 18:41:34.446642 129274868512256 run.py:749] Checkpointing best model, best avg val score was 0.816, current avg val score is 0.817, val scores are: activity_selector: 0.817
I0829 18:41:35.141714 129274868512256 run.py:693] Algo activity_selector step 1700 current loss 0.958389, current_train_items 23456.
I0829 18:41:35.167533 129274868512256 run.py:728] (val) algo activity_selector step 1700: {'selected': 0.7959527824620574, 'score': 0.7959527824620574, 'examples_seen': 23456, 'step': 1700, 'algorithm': 'activity_selector'}
I0829 18:41:35.167812 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.817, current avg val score is 0.796, val scores are: activity_selector: 0.796
I0829 18:41:35.885629 129274868512256 run.py:693] Algo activity_selector step 1750 current loss 0.983161, current_train_items 24160.
I0829 18:41:35.906216 129274868512256 run.py:728] (val) algo activity_selector step 1750: {'selected': 0.8075471698113208, 'score': 0.8075471698113208, 'examples_seen': 24160, 'step': 1750, 'algorithm': 'activity_selector'}
I0829 18:41:35.906477 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.817, current avg val score is 0.808, val scores are: activity_selector: 0.808
I0829 18:41:36.568313 129274868512256 run.py:693] Algo activity_selector step 1800 current loss 1.180231, current_train_items 24832.
I0829 18:41:36.590687 129274868512256 run.py:728] (val) algo activity_selector step 1800: {'selected': 0.7791741472172352, 'score': 0.7791741472172352, 'examples_seen': 24832, 'step': 1800, 'algorithm': 'activity_selector'}
I0829 18:41:36.590908 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.817, current avg val score is 0.779, val scores are: activity_selector: 0.779
I0829 18:41:37.342360 129274868512256 run.py:693] Algo activity_selector step 1850 current loss 1.322582, current_train_items 25536.
I0829 18:41:37.359276 129274868512256 run.py:728] (val) algo activity_selector step 1850: {'selected': 0.759581881533101, 'score': 0.759581881533101, 'examples_seen': 25536, 'step': 1850, 'algorithm': 'activity_selector'}
I0829 18:41:37.359466 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.817, current avg val score is 0.760, val scores are: activity_selector: 0.760
I0829 18:41:37.966654 129274868512256 run.py:693] Algo activity_selector step 1900 current loss 1.682547, current_train_items 26224.
I0829 18:41:37.985197 129274868512256 run.py:728] (val) algo activity_selector step 1900: {'selected': 0.7538461538461538, 'score': 0.7538461538461538, 'examples_seen': 26224, 'step': 1900, 'algorithm': 'activity_selector'}
I0829 18:41:37.985394 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.817, current avg val score is 0.754, val scores are: activity_selector: 0.754
I0829 18:41:38.563796 129274868512256 run.py:693] Algo activity_selector step 1950 current loss 0.961938, current_train_items 26912.
I0829 18:41:38.579903 129274868512256 run.py:728] (val) algo activity_selector step 1950: {'selected': 0.7806563039723663, 'score': 0.7806563039723663, 'examples_seen': 26912, 'step': 1950, 'algorithm': 'activity_selector'}
I0829 18:41:38.580071 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.817, current avg val score is 0.781, val scores are: activity_selector: 0.781
I0829 18:41:39.182623 129274868512256 run.py:693] Algo activity_selector step 2000 current loss 1.080756, current_train_items 27600.
I0829 18:41:39.199032 129274868512256 run.py:728] (val) algo activity_selector step 2000: {'selected': 0.8013816925734024, 'score': 0.8013816925734024, 'examples_seen': 27600, 'step': 2000, 'algorithm': 'activity_selector'}
I0829 18:41:39.199201 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.817, current avg val score is 0.801, val scores are: activity_selector: 0.801
I0829 18:41:39.778519 129274868512256 run.py:693] Algo activity_selector step 2050 current loss 1.010747, current_train_items 28288.
I0829 18:41:39.795967 129274868512256 run.py:728] (val) algo activity_selector step 2050: {'selected': 0.7809847198641765, 'score': 0.7809847198641765, 'examples_seen': 28288, 'step': 2050, 'algorithm': 'activity_selector'}
I0829 18:41:39.796140 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.817, current avg val score is 0.781, val scores are: activity_selector: 0.781
I0829 18:41:40.408047 129274868512256 run.py:693] Algo activity_selector step 2100 current loss 1.423387, current_train_items 28976.
I0829 18:41:40.424091 129274868512256 run.py:728] (val) algo activity_selector step 2100: {'selected': 0.778523489932886, 'score': 0.778523489932886, 'examples_seen': 28976, 'step': 2100, 'algorithm': 'activity_selector'}
I0829 18:41:40.424250 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.817, current avg val score is 0.779, val scores are: activity_selector: 0.779
I0829 18:41:41.098174 129274868512256 run.py:693] Algo activity_selector step 2150 current loss 1.037862, current_train_items 29664.
I0829 18:41:41.116055 129274868512256 run.py:728] (val) algo activity_selector step 2150: {'selected': 0.7726432532347504, 'score': 0.7726432532347504, 'examples_seen': 29664, 'step': 2150, 'algorithm': 'activity_selector'}
I0829 18:41:41.116232 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.817, current avg val score is 0.773, val scores are: activity_selector: 0.773
I0829 18:41:41.665467 129274868512256 run.py:693] Algo activity_selector step 2200 current loss 1.176274, current_train_items 30368.
I0829 18:41:41.682476 129274868512256 run.py:728] (val) algo activity_selector step 2200: {'selected': 0.8507462686567165, 'score': 0.8507462686567165, 'examples_seen': 30368, 'step': 2200, 'algorithm': 'activity_selector'}
I0829 18:41:41.682657 129274868512256 run.py:749] Checkpointing best model, best avg val score was 0.817, current avg val score is 0.851, val scores are: activity_selector: 0.851
I0829 18:41:42.351467 129274868512256 run.py:693] Algo activity_selector step 2250 current loss 1.041909, current_train_items 31040.
I0829 18:41:42.369143 129274868512256 run.py:728] (val) algo activity_selector step 2250: {'selected': 0.7904411764705883, 'score': 0.7904411764705883, 'examples_seen': 31040, 'step': 2250, 'algorithm': 'activity_selector'}
I0829 18:41:42.369307 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.851, current avg val score is 0.790, val scores are: activity_selector: 0.790
I0829 18:41:42.980658 129274868512256 run.py:693] Algo activity_selector step 2300 current loss 1.236584, current_train_items 31728.
I0829 18:41:43.000186 129274868512256 run.py:728] (val) algo activity_selector step 2300: {'selected': 0.7869415807560137, 'score': 0.7869415807560137, 'examples_seen': 31728, 'step': 2300, 'algorithm': 'activity_selector'}
I0829 18:41:43.000342 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.851, current avg val score is 0.787, val scores are: activity_selector: 0.787
I0829 18:41:43.614237 129274868512256 run.py:693] Algo activity_selector step 2350 current loss 1.129034, current_train_items 32432.
I0829 18:41:43.632024 129274868512256 run.py:728] (val) algo activity_selector step 2350: {'selected': 0.7692307692307694, 'score': 0.7692307692307694, 'examples_seen': 32432, 'step': 2350, 'algorithm': 'activity_selector'}
I0829 18:41:43.632232 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.851, current avg val score is 0.769, val scores are: activity_selector: 0.769
I0829 18:41:44.257202 129274868512256 run.py:693] Algo activity_selector step 2400 current loss 1.256010, current_train_items 33104.
I0829 18:41:44.276046 129274868512256 run.py:728] (val) algo activity_selector step 2400: {'selected': 0.8049792531120332, 'score': 0.8049792531120332, 'examples_seen': 33104, 'step': 2400, 'algorithm': 'activity_selector'}
I0829 18:41:44.276241 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.851, current avg val score is 0.805, val scores are: activity_selector: 0.805
I0829 18:41:44.969449 129274868512256 run.py:693] Algo activity_selector step 2450 current loss 1.078932, current_train_items 33808.
I0829 18:41:44.986404 129274868512256 run.py:728] (val) algo activity_selector step 2450: {'selected': 0.8488372093023256, 'score': 0.8488372093023256, 'examples_seen': 33808, 'step': 2450, 'algorithm': 'activity_selector'}
I0829 18:41:44.986572 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.851, current avg val score is 0.849, val scores are: activity_selector: 0.849
I0829 18:41:45.625746 129274868512256 run.py:693] Algo activity_selector step 2500 current loss 1.202844, current_train_items 34496.
I0829 18:41:45.643113 129274868512256 run.py:728] (val) algo activity_selector step 2500: {'selected': 0.7836734693877551, 'score': 0.7836734693877551, 'examples_seen': 34496, 'step': 2500, 'algorithm': 'activity_selector'}
I0829 18:41:45.643374 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.851, current avg val score is 0.784, val scores are: activity_selector: 0.784
I0829 18:41:46.243501 129274868512256 run.py:693] Algo activity_selector step 2550 current loss 0.926457, current_train_items 35184.
I0829 18:41:46.260748 129274868512256 run.py:728] (val) algo activity_selector step 2550: {'selected': 0.841726618705036, 'score': 0.841726618705036, 'examples_seen': 35184, 'step': 2550, 'algorithm': 'activity_selector'}
I0829 18:41:46.260917 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.851, current avg val score is 0.842, val scores are: activity_selector: 0.842
I0829 18:41:46.832104 129274868512256 run.py:693] Algo activity_selector step 2600 current loss 1.648174, current_train_items 35872.
I0829 18:41:46.849473 129274868512256 run.py:728] (val) algo activity_selector step 2600: {'selected': 0.8169014084507041, 'score': 0.8169014084507041, 'examples_seen': 35872, 'step': 2600, 'algorithm': 'activity_selector'}
I0829 18:41:46.849620 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.851, current avg val score is 0.817, val scores are: activity_selector: 0.817
I0829 18:41:47.432985 129274868512256 run.py:693] Algo activity_selector step 2650 current loss 1.032157, current_train_items 36560.
I0829 18:41:47.453539 129274868512256 run.py:728] (val) algo activity_selector step 2650: {'selected': 0.8357664233576642, 'score': 0.8357664233576642, 'examples_seen': 36560, 'step': 2650, 'algorithm': 'activity_selector'}
I0829 18:41:47.453710 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.851, current avg val score is 0.836, val scores are: activity_selector: 0.836
I0829 18:41:48.060928 129274868512256 run.py:693] Algo activity_selector step 2700 current loss 0.998615, current_train_items 37248.
I0829 18:41:48.076196 129274868512256 run.py:728] (val) algo activity_selector step 2700: {'selected': 0.8629032258064515, 'score': 0.8629032258064515, 'examples_seen': 37248, 'step': 2700, 'algorithm': 'activity_selector'}
I0829 18:41:48.076390 129274868512256 run.py:749] Checkpointing best model, best avg val score was 0.851, current avg val score is 0.863, val scores are: activity_selector: 0.863
I0829 18:41:48.666170 129274868512256 run.py:693] Algo activity_selector step 2750 current loss 1.132977, current_train_items 37936.
I0829 18:41:48.682810 129274868512256 run.py:728] (val) algo activity_selector step 2750: {'selected': 0.8318890814558058, 'score': 0.8318890814558058, 'examples_seen': 37936, 'step': 2750, 'algorithm': 'activity_selector'}
I0829 18:41:48.682970 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.863, current avg val score is 0.832, val scores are: activity_selector: 0.832
I0829 18:41:49.283098 129274868512256 run.py:693] Algo activity_selector step 2800 current loss 0.827471, current_train_items 38640.
I0829 18:41:49.300107 129274868512256 run.py:728] (val) algo activity_selector step 2800: {'selected': 0.8254545454545456, 'score': 0.8254545454545456, 'examples_seen': 38640, 'step': 2800, 'algorithm': 'activity_selector'}
I0829 18:41:49.300265 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.863, current avg val score is 0.825, val scores are: activity_selector: 0.825
I0829 18:41:49.921185 129274868512256 run.py:693] Algo activity_selector step 2850 current loss 0.911291, current_train_items 39312.
I0829 18:41:49.936710 129274868512256 run.py:728] (val) algo activity_selector step 2850: {'selected': 0.859344894026975, 'score': 0.859344894026975, 'examples_seen': 39312, 'step': 2850, 'algorithm': 'activity_selector'}
I0829 18:41:49.936873 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.863, current avg val score is 0.859, val scores are: activity_selector: 0.859
I0829 18:41:50.512747 129274868512256 run.py:693] Algo activity_selector step 2900 current loss 1.088546, current_train_items 40016.
I0829 18:41:50.530149 129274868512256 run.py:728] (val) algo activity_selector step 2900: {'selected': 0.8312611012433392, 'score': 0.8312611012433392, 'examples_seen': 40016, 'step': 2900, 'algorithm': 'activity_selector'}
I0829 18:41:50.530312 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.863, current avg val score is 0.831, val scores are: activity_selector: 0.831
I0829 18:41:51.094561 129274868512256 run.py:693] Algo activity_selector step 2950 current loss 1.077044, current_train_items 40704.
I0829 18:41:51.111514 129274868512256 run.py:728] (val) algo activity_selector step 2950: {'selected': 0.7925925925925926, 'score': 0.7925925925925926, 'examples_seen': 40704, 'step': 2950, 'algorithm': 'activity_selector'}
I0829 18:41:51.111734 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.863, current avg val score is 0.793, val scores are: activity_selector: 0.793
I0829 18:41:51.676521 129274868512256 run.py:693] Algo activity_selector step 3000 current loss 1.056349, current_train_items 41376.
I0829 18:41:51.692747 129274868512256 run.py:728] (val) algo activity_selector step 3000: {'selected': 0.8561278863232683, 'score': 0.8561278863232683, 'examples_seen': 41376, 'step': 3000, 'algorithm': 'activity_selector'}
I0829 18:41:51.692972 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.863, current avg val score is 0.856, val scores are: activity_selector: 0.856
I0829 18:41:52.270361 129274868512256 run.py:693] Algo activity_selector step 3050 current loss 1.154556, current_train_items 42080.
I0829 18:41:52.296923 129274868512256 run.py:728] (val) algo activity_selector step 3050: {'selected': 0.8207024029574861, 'score': 0.8207024029574861, 'examples_seen': 42080, 'step': 3050, 'algorithm': 'activity_selector'}
I0829 18:41:52.297142 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.863, current avg val score is 0.821, val scores are: activity_selector: 0.821
I0829 18:41:52.839128 129274868512256 run.py:693] Algo activity_selector step 3100 current loss 1.145520, current_train_items 42768.
I0829 18:41:52.858530 129274868512256 run.py:728] (val) algo activity_selector step 3100: {'selected': 0.8555347091932459, 'score': 0.8555347091932459, 'examples_seen': 42768, 'step': 3100, 'algorithm': 'activity_selector'}
I0829 18:41:52.858790 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.863, current avg val score is 0.856, val scores are: activity_selector: 0.856
I0829 18:41:53.396602 129274868512256 run.py:693] Algo activity_selector step 3150 current loss 1.342147, current_train_items 43440.
I0829 18:41:53.413755 129274868512256 run.py:728] (val) algo activity_selector step 3150: {'selected': 0.8256880733944953, 'score': 0.8256880733944953, 'examples_seen': 43440, 'step': 3150, 'algorithm': 'activity_selector'}
I0829 18:41:53.413902 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.863, current avg val score is 0.826, val scores are: activity_selector: 0.826
I0829 18:41:53.973053 129274868512256 run.py:693] Algo activity_selector step 3200 current loss 0.601246, current_train_items 44144.
I0829 18:41:53.988353 129274868512256 run.py:728] (val) algo activity_selector step 3200: {'selected': 0.8370370370370371, 'score': 0.8370370370370371, 'examples_seen': 44144, 'step': 3200, 'algorithm': 'activity_selector'}
I0829 18:41:53.988532 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.863, current avg val score is 0.837, val scores are: activity_selector: 0.837
I0829 18:41:54.512511 129274868512256 run.py:693] Algo activity_selector step 3250 current loss 0.661768, current_train_items 44848.
I0829 18:41:54.527662 129274868512256 run.py:728] (val) algo activity_selector step 3250: {'selected': 0.8738574040219378, 'score': 0.8738574040219378, 'examples_seen': 44848, 'step': 3250, 'algorithm': 'activity_selector'}
I0829 18:41:54.527816 129274868512256 run.py:749] Checkpointing best model, best avg val score was 0.863, current avg val score is 0.874, val scores are: activity_selector: 0.874
I0829 18:41:55.075333 129274868512256 run.py:693] Algo activity_selector step 3300 current loss 0.869310, current_train_items 45520.
I0829 18:41:55.090653 129274868512256 run.py:728] (val) algo activity_selector step 3300: {'selected': 0.85451197053407, 'score': 0.85451197053407, 'examples_seen': 45520, 'step': 3300, 'algorithm': 'activity_selector'}
I0829 18:41:55.090805 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.874, current avg val score is 0.855, val scores are: activity_selector: 0.855
I0829 18:41:55.645381 129274868512256 run.py:693] Algo activity_selector step 3350 current loss 0.713117, current_train_items 46208.
I0829 18:41:55.661112 129274868512256 run.py:728] (val) algo activity_selector step 3350: {'selected': 0.846815834767642, 'score': 0.846815834767642, 'examples_seen': 46208, 'step': 3350, 'algorithm': 'activity_selector'}
I0829 18:41:55.661269 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.874, current avg val score is 0.847, val scores are: activity_selector: 0.847
I0829 18:41:56.210634 129274868512256 run.py:693] Algo activity_selector step 3400 current loss 0.715444, current_train_items 46912.
I0829 18:41:56.227597 129274868512256 run.py:728] (val) algo activity_selector step 3400: {'selected': 0.8447937131630648, 'score': 0.8447937131630648, 'examples_seen': 46912, 'step': 3400, 'algorithm': 'activity_selector'}
I0829 18:41:56.227761 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.874, current avg val score is 0.845, val scores are: activity_selector: 0.845
I0829 18:41:56.831910 129274868512256 run.py:693] Algo activity_selector step 3450 current loss 1.043291, current_train_items 47584.
I0829 18:41:56.848569 129274868512256 run.py:728] (val) algo activity_selector step 3450: {'selected': 0.8613138686131386, 'score': 0.8613138686131386, 'examples_seen': 47584, 'step': 3450, 'algorithm': 'activity_selector'}
I0829 18:41:56.848714 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.874, current avg val score is 0.861, val scores are: activity_selector: 0.861
I0829 18:41:57.399473 129274868512256 run.py:693] Algo activity_selector step 3500 current loss 0.570886, current_train_items 48272.
I0829 18:41:57.416218 129274868512256 run.py:728] (val) algo activity_selector step 3500: {'selected': 0.8721541155866901, 'score': 0.8721541155866901, 'examples_seen': 48272, 'step': 3500, 'algorithm': 'activity_selector'}
I0829 18:41:57.416451 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.874, current avg val score is 0.872, val scores are: activity_selector: 0.872
I0829 18:41:57.973102 129274868512256 run.py:693] Algo activity_selector step 3550 current loss 0.858751, current_train_items 48976.
I0829 18:41:57.988297 129274868512256 run.py:728] (val) algo activity_selector step 3550: {'selected': 0.8705882352941176, 'score': 0.8705882352941176, 'examples_seen': 48976, 'step': 3550, 'algorithm': 'activity_selector'}
I0829 18:41:57.988467 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.874, current avg val score is 0.871, val scores are: activity_selector: 0.871
I0829 18:41:58.563720 129274868512256 run.py:693] Algo activity_selector step 3600 current loss 0.808056, current_train_items 49664.
I0829 18:41:58.580554 129274868512256 run.py:728] (val) algo activity_selector step 3600: {'selected': 0.8247787610619468, 'score': 0.8247787610619468, 'examples_seen': 49664, 'step': 3600, 'algorithm': 'activity_selector'}
I0829 18:41:58.580710 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.874, current avg val score is 0.825, val scores are: activity_selector: 0.825
I0829 18:41:59.154577 129274868512256 run.py:693] Algo activity_selector step 3650 current loss 0.996898, current_train_items 50352.
I0829 18:41:59.169575 129274868512256 run.py:728] (val) algo activity_selector step 3650: {'selected': 0.8306595365418895, 'score': 0.8306595365418895, 'examples_seen': 50352, 'step': 3650, 'algorithm': 'activity_selector'}
I0829 18:41:59.169724 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.874, current avg val score is 0.831, val scores are: activity_selector: 0.831
I0829 18:41:59.746483 129274868512256 run.py:693] Algo activity_selector step 3700 current loss 0.633162, current_train_items 51040.
I0829 18:41:59.763975 129274868512256 run.py:728] (val) algo activity_selector step 3700: {'selected': 0.8419117647058824, 'score': 0.8419117647058824, 'examples_seen': 51040, 'step': 3700, 'algorithm': 'activity_selector'}
I0829 18:41:59.764142 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.874, current avg val score is 0.842, val scores are: activity_selector: 0.842
I0829 18:42:00.346100 129274868512256 run.py:693] Algo activity_selector step 3750 current loss 0.613997, current_train_items 51728.
I0829 18:42:00.362540 129274868512256 run.py:728] (val) algo activity_selector step 3750: {'selected': 0.8586762075134169, 'score': 0.8586762075134169, 'examples_seen': 51728, 'step': 3750, 'algorithm': 'activity_selector'}
I0829 18:42:00.362696 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.874, current avg val score is 0.859, val scores are: activity_selector: 0.859
I0829 18:42:00.935790 129274868512256 run.py:693] Algo activity_selector step 3800 current loss 0.604475, current_train_items 52416.
I0829 18:42:00.954261 129274868512256 run.py:728] (val) algo activity_selector step 3800: {'selected': 0.8645833333333334, 'score': 0.8645833333333334, 'examples_seen': 52416, 'step': 3800, 'algorithm': 'activity_selector'}
I0829 18:42:00.954431 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.874, current avg val score is 0.865, val scores are: activity_selector: 0.865
I0829 18:42:01.502289 129274868512256 run.py:693] Algo activity_selector step 3850 current loss 0.834646, current_train_items 53104.
I0829 18:42:01.518278 129274868512256 run.py:728] (val) algo activity_selector step 3850: {'selected': 0.8604651162790697, 'score': 0.8604651162790697, 'examples_seen': 53104, 'step': 3850, 'algorithm': 'activity_selector'}
I0829 18:42:01.518425 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.874, current avg val score is 0.860, val scores are: activity_selector: 0.860
I0829 18:42:02.096725 129274868512256 run.py:693] Algo activity_selector step 3900 current loss 1.117812, current_train_items 53792.
I0829 18:42:02.113189 129274868512256 run.py:728] (val) algo activity_selector step 3900: {'selected': 0.8635578583765112, 'score': 0.8635578583765112, 'examples_seen': 53792, 'step': 3900, 'algorithm': 'activity_selector'}
I0829 18:42:02.113337 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.874, current avg val score is 0.864, val scores are: activity_selector: 0.864
I0829 18:42:02.687488 129274868512256 run.py:693] Algo activity_selector step 3950 current loss 0.617407, current_train_items 54496.
I0829 18:42:02.703349 129274868512256 run.py:728] (val) algo activity_selector step 3950: {'selected': 0.8917910447761193, 'score': 0.8917910447761193, 'examples_seen': 54496, 'step': 3950, 'algorithm': 'activity_selector'}
I0829 18:42:02.703525 129274868512256 run.py:749] Checkpointing best model, best avg val score was 0.874, current avg val score is 0.892, val scores are: activity_selector: 0.892
I0829 18:42:03.280041 129274868512256 run.py:693] Algo activity_selector step 4000 current loss 1.138515, current_train_items 55168.
I0829 18:42:03.297482 129274868512256 run.py:728] (val) algo activity_selector step 4000: {'selected': 0.893939393939394, 'score': 0.893939393939394, 'examples_seen': 55168, 'step': 4000, 'algorithm': 'activity_selector'}
I0829 18:42:03.297636 129274868512256 run.py:749] Checkpointing best model, best avg val score was 0.892, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0829 18:42:03.927095 129274868512256 run.py:693] Algo activity_selector step 4050 current loss 0.953347, current_train_items 55856.
I0829 18:42:03.946844 129274868512256 run.py:728] (val) algo activity_selector step 4050: {'selected': 0.8432432432432432, 'score': 0.8432432432432432, 'examples_seen': 55856, 'step': 4050, 'algorithm': 'activity_selector'}
I0829 18:42:03.947108 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.843, val scores are: activity_selector: 0.843
I0829 18:42:04.569786 129274868512256 run.py:693] Algo activity_selector step 4100 current loss 1.399506, current_train_items 56560.
I0829 18:42:04.587198 129274868512256 run.py:728] (val) algo activity_selector step 4100: {'selected': 0.8524590163934426, 'score': 0.8524590163934426, 'examples_seen': 56560, 'step': 4100, 'algorithm': 'activity_selector'}
I0829 18:42:04.587394 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.852, val scores are: activity_selector: 0.852
I0829 18:42:05.201468 129274868512256 run.py:693] Algo activity_selector step 4150 current loss 1.091270, current_train_items 57248.
I0829 18:42:05.218230 129274868512256 run.py:728] (val) algo activity_selector step 4150: {'selected': 0.8485915492957746, 'score': 0.8485915492957746, 'examples_seen': 57248, 'step': 4150, 'algorithm': 'activity_selector'}
I0829 18:42:05.218378 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.849, val scores are: activity_selector: 0.849
I0829 18:42:05.781822 129274868512256 run.py:693] Algo activity_selector step 4200 current loss 0.777310, current_train_items 57920.
I0829 18:42:05.798704 129274868512256 run.py:728] (val) algo activity_selector step 4200: {'selected': 0.8603351955307262, 'score': 0.8603351955307262, 'examples_seen': 57920, 'step': 4200, 'algorithm': 'activity_selector'}
I0829 18:42:05.798860 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.860, val scores are: activity_selector: 0.860
I0829 18:42:06.367385 129274868512256 run.py:693] Algo activity_selector step 4250 current loss 0.745830, current_train_items 58624.
I0829 18:42:06.383069 129274868512256 run.py:728] (val) algo activity_selector step 4250: {'selected': 0.8359375000000001, 'score': 0.8359375000000001, 'examples_seen': 58624, 'step': 4250, 'algorithm': 'activity_selector'}
I0829 18:42:06.383232 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.836, val scores are: activity_selector: 0.836
I0829 18:42:06.937401 129274868512256 run.py:693] Algo activity_selector step 4300 current loss 1.207580, current_train_items 59328.
I0829 18:42:06.952589 129274868512256 run.py:728] (val) algo activity_selector step 4300: {'selected': 0.8914728682170542, 'score': 0.8914728682170542, 'examples_seen': 59328, 'step': 4300, 'algorithm': 'activity_selector'}
I0829 18:42:06.952913 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0829 18:42:07.517044 129274868512256 run.py:693] Algo activity_selector step 4350 current loss 0.662271, current_train_items 59984.
I0829 18:42:07.533024 129274868512256 run.py:728] (val) algo activity_selector step 4350: {'selected': 0.8571428571428572, 'score': 0.8571428571428572, 'examples_seen': 59984, 'step': 4350, 'algorithm': 'activity_selector'}
I0829 18:42:07.533188 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.857, val scores are: activity_selector: 0.857
I0829 18:42:08.099096 129274868512256 run.py:693] Algo activity_selector step 4400 current loss 0.585318, current_train_items 60688.
I0829 18:42:08.115216 129274868512256 run.py:728] (val) algo activity_selector step 4400: {'selected': 0.8521400778210118, 'score': 0.8521400778210118, 'examples_seen': 60688, 'step': 4400, 'algorithm': 'activity_selector'}
I0829 18:42:08.115365 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.852, val scores are: activity_selector: 0.852
I0829 18:42:08.666778 129274868512256 run.py:693] Algo activity_selector step 4450 current loss 0.713376, current_train_items 61392.
I0829 18:42:08.683068 129274868512256 run.py:728] (val) algo activity_selector step 4450: {'selected': 0.8888888888888888, 'score': 0.8888888888888888, 'examples_seen': 61392, 'step': 4450, 'algorithm': 'activity_selector'}
I0829 18:42:08.683224 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.889, val scores are: activity_selector: 0.889
I0829 18:42:09.247406 129274868512256 run.py:693] Algo activity_selector step 4500 current loss 0.991528, current_train_items 62064.
I0829 18:42:09.263739 129274868512256 run.py:728] (val) algo activity_selector step 4500: {'selected': 0.8178694158075601, 'score': 0.8178694158075601, 'examples_seen': 62064, 'step': 4500, 'algorithm': 'activity_selector'}
I0829 18:42:09.263890 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.818, val scores are: activity_selector: 0.818
I0829 18:42:09.873663 129274868512256 run.py:693] Algo activity_selector step 4550 current loss 0.879937, current_train_items 62752.
I0829 18:42:09.889024 129274868512256 run.py:728] (val) algo activity_selector step 4550: {'selected': 0.874766355140187, 'score': 0.874766355140187, 'examples_seen': 62752, 'step': 4550, 'algorithm': 'activity_selector'}
I0829 18:42:09.889247 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.875, val scores are: activity_selector: 0.875
I0829 18:42:10.451749 129274868512256 run.py:693] Algo activity_selector step 4600 current loss 0.872688, current_train_items 63456.
I0829 18:42:10.467952 129274868512256 run.py:728] (val) algo activity_selector step 4600: {'selected': 0.8648648648648648, 'score': 0.8648648648648648, 'examples_seen': 63456, 'step': 4600, 'algorithm': 'activity_selector'}
I0829 18:42:10.468108 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.865, val scores are: activity_selector: 0.865
I0829 18:42:11.064110 129274868512256 run.py:693] Algo activity_selector step 4650 current loss 0.608705, current_train_items 64144.
I0829 18:42:11.084446 129274868512256 run.py:728] (val) algo activity_selector step 4650: {'selected': 0.8735632183908046, 'score': 0.8735632183908046, 'examples_seen': 64144, 'step': 4650, 'algorithm': 'activity_selector'}
I0829 18:42:11.084593 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.874, val scores are: activity_selector: 0.874
I0829 18:42:11.663645 129274868512256 run.py:693] Algo activity_selector step 4700 current loss 1.062458, current_train_items 64816.
I0829 18:42:11.679840 129274868512256 run.py:728] (val) algo activity_selector step 4700: {'selected': 0.8771266540642721, 'score': 0.8771266540642721, 'examples_seen': 64816, 'step': 4700, 'algorithm': 'activity_selector'}
I0829 18:42:11.679985 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.877, val scores are: activity_selector: 0.877
I0829 18:42:12.280159 129274868512256 run.py:693] Algo activity_selector step 4750 current loss 0.515487, current_train_items 65520.
I0829 18:42:12.297178 129274868512256 run.py:728] (val) algo activity_selector step 4750: {'selected': 0.8791593695271454, 'score': 0.8791593695271454, 'examples_seen': 65520, 'step': 4750, 'algorithm': 'activity_selector'}
I0829 18:42:12.297337 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0829 18:42:12.986348 129274868512256 run.py:693] Algo activity_selector step 4800 current loss 0.921514, current_train_items 66208.
I0829 18:42:13.003221 129274868512256 run.py:728] (val) algo activity_selector step 4800: {'selected': 0.8864864864864865, 'score': 0.8864864864864865, 'examples_seen': 66208, 'step': 4800, 'algorithm': 'activity_selector'}
I0829 18:42:13.003394 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0829 18:42:13.572487 129274868512256 run.py:693] Algo activity_selector step 4850 current loss 1.248801, current_train_items 66880.
I0829 18:42:13.591544 129274868512256 run.py:728] (val) algo activity_selector step 4850: {'selected': 0.8343079922027291, 'score': 0.8343079922027291, 'examples_seen': 66880, 'step': 4850, 'algorithm': 'activity_selector'}
I0829 18:42:13.591794 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.834, val scores are: activity_selector: 0.834
I0829 18:42:14.157655 129274868512256 run.py:693] Algo activity_selector step 4900 current loss 0.695980, current_train_items 67584.
I0829 18:42:14.173603 129274868512256 run.py:728] (val) algo activity_selector step 4900: {'selected': 0.8610634648370498, 'score': 0.8610634648370498, 'examples_seen': 67584, 'step': 4900, 'algorithm': 'activity_selector'}
I0829 18:42:14.173800 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.861, val scores are: activity_selector: 0.861
I0829 18:42:14.780881 129274868512256 run.py:693] Algo activity_selector step 4950 current loss 0.564248, current_train_items 68272.
I0829 18:42:14.799173 129274868512256 run.py:728] (val) algo activity_selector step 4950: {'selected': 0.8507157464212678, 'score': 0.8507157464212678, 'examples_seen': 68272, 'step': 4950, 'algorithm': 'activity_selector'}
I0829 18:42:14.799327 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.851, val scores are: activity_selector: 0.851
I0829 18:42:15.353317 129274868512256 run.py:693] Algo activity_selector step 5000 current loss 0.583494, current_train_items 68976.
I0829 18:42:15.368519 129274868512256 run.py:728] (val) algo activity_selector step 5000: {'selected': 0.8716094032549728, 'score': 0.8716094032549728, 'examples_seen': 68976, 'step': 5000, 'algorithm': 'activity_selector'}
I0829 18:42:15.368674 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.872, val scores are: activity_selector: 0.872
I0829 18:42:15.911361 129274868512256 run.py:693] Algo activity_selector step 5050 current loss 0.611157, current_train_items 69648.
I0829 18:42:15.929024 129274868512256 run.py:728] (val) algo activity_selector step 5050: {'selected': 0.8742964352720451, 'score': 0.8742964352720451, 'examples_seen': 69648, 'step': 5050, 'algorithm': 'activity_selector'}
I0829 18:42:15.929185 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.874, val scores are: activity_selector: 0.874
I0829 18:42:16.489036 129274868512256 run.py:693] Algo activity_selector step 5100 current loss 0.777154, current_train_items 70336.
I0829 18:42:16.505352 129274868512256 run.py:728] (val) algo activity_selector step 5100: {'selected': 0.8673835125448028, 'score': 0.8673835125448028, 'examples_seen': 70336, 'step': 5100, 'algorithm': 'activity_selector'}
I0829 18:42:16.505511 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0829 18:42:17.065540 129274868512256 run.py:693] Algo activity_selector step 5150 current loss 0.372797, current_train_items 71040.
I0829 18:42:17.082661 129274868512256 run.py:728] (val) algo activity_selector step 5150: {'selected': 0.8571428571428571, 'score': 0.8571428571428571, 'examples_seen': 71040, 'step': 5150, 'algorithm': 'activity_selector'}
I0829 18:42:17.082822 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.857, val scores are: activity_selector: 0.857
I0829 18:42:17.619232 129274868512256 run.py:693] Algo activity_selector step 5200 current loss 1.515836, current_train_items 71712.
I0829 18:42:17.635221 129274868512256 run.py:728] (val) algo activity_selector step 5200: {'selected': 0.8453237410071943, 'score': 0.8453237410071943, 'examples_seen': 71712, 'step': 5200, 'algorithm': 'activity_selector'}
I0829 18:42:17.635378 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.845, val scores are: activity_selector: 0.845
I0829 18:42:18.204029 129274868512256 run.py:693] Algo activity_selector step 5250 current loss 1.024680, current_train_items 72400.
I0829 18:42:18.219947 129274868512256 run.py:728] (val) algo activity_selector step 5250: {'selected': 0.8671586715867159, 'score': 0.8671586715867159, 'examples_seen': 72400, 'step': 5250, 'algorithm': 'activity_selector'}
I0829 18:42:18.220118 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0829 18:42:18.791446 129274868512256 run.py:693] Algo activity_selector step 5300 current loss 0.671746, current_train_items 73104.
I0829 18:42:18.806421 129274868512256 run.py:728] (val) algo activity_selector step 5300: {'selected': 0.8471001757469244, 'score': 0.8471001757469244, 'examples_seen': 73104, 'step': 5300, 'algorithm': 'activity_selector'}
I0829 18:42:18.806616 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.847, val scores are: activity_selector: 0.847
I0829 18:42:19.371664 129274868512256 run.py:693] Algo activity_selector step 5350 current loss 1.145811, current_train_items 73808.
I0829 18:42:19.387722 129274868512256 run.py:728] (val) algo activity_selector step 5350: {'selected': 0.8613678373382624, 'score': 0.8613678373382624, 'examples_seen': 73808, 'step': 5350, 'algorithm': 'activity_selector'}
I0829 18:42:19.387872 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.861, val scores are: activity_selector: 0.861
I0829 18:42:19.976148 129274868512256 run.py:693] Algo activity_selector step 5400 current loss 0.688784, current_train_items 74464.
I0829 18:42:19.992499 129274868512256 run.py:728] (val) algo activity_selector step 5400: {'selected': 0.8831168831168831, 'score': 0.8831168831168831, 'examples_seen': 74464, 'step': 5400, 'algorithm': 'activity_selector'}
I0829 18:42:19.992695 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.883, val scores are: activity_selector: 0.883
I0829 18:42:20.594780 129274868512256 run.py:693] Algo activity_selector step 5450 current loss 0.795352, current_train_items 75168.
I0829 18:42:20.612060 129274868512256 run.py:728] (val) algo activity_selector step 5450: {'selected': 0.8506616257088846, 'score': 0.8506616257088846, 'examples_seen': 75168, 'step': 5450, 'algorithm': 'activity_selector'}
I0829 18:42:20.612251 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.851, val scores are: activity_selector: 0.851
I0829 18:42:21.187150 129274868512256 run.py:693] Algo activity_selector step 5500 current loss 0.624419, current_train_items 75872.
I0829 18:42:21.203891 129274868512256 run.py:728] (val) algo activity_selector step 5500: {'selected': 0.8792792792792792, 'score': 0.8792792792792792, 'examples_seen': 75872, 'step': 5500, 'algorithm': 'activity_selector'}
I0829 18:42:21.204050 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0829 18:42:21.770324 129274868512256 run.py:693] Algo activity_selector step 5550 current loss 0.700699, current_train_items 76528.
I0829 18:42:21.786256 129274868512256 run.py:728] (val) algo activity_selector step 5550: {'selected': 0.8371278458844132, 'score': 0.8371278458844132, 'examples_seen': 76528, 'step': 5550, 'algorithm': 'activity_selector'}
I0829 18:42:21.786407 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.837, val scores are: activity_selector: 0.837
I0829 18:42:22.351401 129274868512256 run.py:693] Algo activity_selector step 5600 current loss 1.090306, current_train_items 77232.
I0829 18:42:22.367281 129274868512256 run.py:728] (val) algo activity_selector step 5600: {'selected': 0.8512110726643598, 'score': 0.8512110726643598, 'examples_seen': 77232, 'step': 5600, 'algorithm': 'activity_selector'}
I0829 18:42:22.367441 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.851, val scores are: activity_selector: 0.851
I0829 18:42:22.916290 129274868512256 run.py:693] Algo activity_selector step 5650 current loss 0.911430, current_train_items 77936.
I0829 18:42:22.931995 129274868512256 run.py:728] (val) algo activity_selector step 5650: {'selected': 0.8197879858657243, 'score': 0.8197879858657243, 'examples_seen': 77936, 'step': 5650, 'algorithm': 'activity_selector'}
I0829 18:42:22.932162 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.820, val scores are: activity_selector: 0.820
I0829 18:42:23.445384 129274868512256 run.py:693] Algo activity_selector step 5700 current loss 0.998317, current_train_items 78608.
I0829 18:42:23.461395 129274868512256 run.py:728] (val) algo activity_selector step 5700: {'selected': 0.8740458015267175, 'score': 0.8740458015267175, 'examples_seen': 78608, 'step': 5700, 'algorithm': 'activity_selector'}
I0829 18:42:23.461539 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.874, val scores are: activity_selector: 0.874
I0829 18:42:24.019012 129274868512256 run.py:693] Algo activity_selector step 5750 current loss 1.333985, current_train_items 79296.
I0829 18:42:24.035588 129274868512256 run.py:728] (val) algo activity_selector step 5750: {'selected': 0.8394276629570747, 'score': 0.8394276629570747, 'examples_seen': 79296, 'step': 5750, 'algorithm': 'activity_selector'}
I0829 18:42:24.035753 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.839, val scores are: activity_selector: 0.839
I0829 18:42:24.586118 129274868512256 run.py:693] Algo activity_selector step 5800 current loss 1.115211, current_train_items 80000.
I0829 18:42:24.602596 129274868512256 run.py:728] (val) algo activity_selector step 5800: {'selected': 0.8798449612403102, 'score': 0.8798449612403102, 'examples_seen': 80000, 'step': 5800, 'algorithm': 'activity_selector'}
I0829 18:42:24.602789 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0829 18:42:25.156966 129274868512256 run.py:693] Algo activity_selector step 5850 current loss 0.386767, current_train_items 80688.
I0829 18:42:25.174567 129274868512256 run.py:728] (val) algo activity_selector step 5850: {'selected': 0.8278388278388278, 'score': 0.8278388278388278, 'examples_seen': 80688, 'step': 5850, 'algorithm': 'activity_selector'}
I0829 18:42:25.174728 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.894, current avg val score is 0.828, val scores are: activity_selector: 0.828
I0829 18:42:25.702222 129274868512256 run.py:693] Algo activity_selector step 5900 current loss 0.320537, current_train_items 81360.
I0829 18:42:25.724771 129274868512256 run.py:728] (val) algo activity_selector step 5900: {'selected': 0.9166666666666667, 'score': 0.9166666666666667, 'examples_seen': 81360, 'step': 5900, 'algorithm': 'activity_selector'}
I0829 18:42:25.725005 129274868512256 run.py:749] Checkpointing best model, best avg val score was 0.894, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0829 18:42:26.268429 129274868512256 run.py:693] Algo activity_selector step 5950 current loss 0.914150, current_train_items 82064.
I0829 18:42:26.284653 129274868512256 run.py:728] (val) algo activity_selector step 5950: {'selected': 0.8844765342960289, 'score': 0.8844765342960289, 'examples_seen': 82064, 'step': 5950, 'algorithm': 'activity_selector'}
I0829 18:42:26.284799 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0829 18:42:26.823469 129274868512256 run.py:693] Algo activity_selector step 6000 current loss 0.735725, current_train_items 82752.
I0829 18:42:26.838949 129274868512256 run.py:728] (val) algo activity_selector step 6000: {'selected': 0.8695652173913043, 'score': 0.8695652173913043, 'examples_seen': 82752, 'step': 6000, 'algorithm': 'activity_selector'}
I0829 18:42:26.839141 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.870, val scores are: activity_selector: 0.870
I0829 18:42:27.377691 129274868512256 run.py:693] Algo activity_selector step 6050 current loss 0.566666, current_train_items 83440.
I0829 18:42:27.395440 129274868512256 run.py:728] (val) algo activity_selector step 6050: {'selected': 0.8235294117647057, 'score': 0.8235294117647057, 'examples_seen': 83440, 'step': 6050, 'algorithm': 'activity_selector'}
I0829 18:42:27.395664 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.824, val scores are: activity_selector: 0.824
I0829 18:42:28.030945 129274868512256 run.py:693] Algo activity_selector step 6100 current loss 0.751220, current_train_items 84128.
I0829 18:42:28.049434 129274868512256 run.py:728] (val) algo activity_selector step 6100: {'selected': 0.8291032148900168, 'score': 0.8291032148900168, 'examples_seen': 84128, 'step': 6100, 'algorithm': 'activity_selector'}
I0829 18:42:28.049597 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.829, val scores are: activity_selector: 0.829
I0829 18:42:28.669640 129274868512256 run.py:693] Algo activity_selector step 6150 current loss 0.685029, current_train_items 84816.
I0829 18:42:28.689824 129274868512256 run.py:728] (val) algo activity_selector step 6150: {'selected': 0.8413284132841329, 'score': 0.8413284132841329, 'examples_seen': 84816, 'step': 6150, 'algorithm': 'activity_selector'}
I0829 18:42:28.690114 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.841, val scores are: activity_selector: 0.841
I0829 18:42:29.291835 129274868512256 run.py:693] Algo activity_selector step 6200 current loss 0.942716, current_train_items 85520.
I0829 18:42:29.307548 129274868512256 run.py:728] (val) algo activity_selector step 6200: {'selected': 0.8475177304964538, 'score': 0.8475177304964538, 'examples_seen': 85520, 'step': 6200, 'algorithm': 'activity_selector'}
I0829 18:42:29.307722 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.848, val scores are: activity_selector: 0.848
I0829 18:42:29.906063 129274868512256 run.py:693] Algo activity_selector step 6250 current loss 0.845233, current_train_items 86192.
I0829 18:42:29.921442 129274868512256 run.py:728] (val) algo activity_selector step 6250: {'selected': 0.8377896613190732, 'score': 0.8377896613190732, 'examples_seen': 86192, 'step': 6250, 'algorithm': 'activity_selector'}
I0829 18:42:29.921613 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.838, val scores are: activity_selector: 0.838
I0829 18:42:30.471591 129274868512256 run.py:693] Algo activity_selector step 6300 current loss 0.965187, current_train_items 86880.
I0829 18:42:30.487596 129274868512256 run.py:728] (val) algo activity_selector step 6300: {'selected': 0.8875968992248061, 'score': 0.8875968992248061, 'examples_seen': 86880, 'step': 6300, 'algorithm': 'activity_selector'}
I0829 18:42:30.487772 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.888, val scores are: activity_selector: 0.888
I0829 18:42:31.140352 129274868512256 run.py:693] Algo activity_selector step 6350 current loss 0.588921, current_train_items 87584.
I0829 18:42:31.156548 129274868512256 run.py:728] (val) algo activity_selector step 6350: {'selected': 0.840064620355412, 'score': 0.840064620355412, 'examples_seen': 87584, 'step': 6350, 'algorithm': 'activity_selector'}
I0829 18:42:31.156720 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.840, val scores are: activity_selector: 0.840
I0829 18:42:31.693573 129274868512256 run.py:693] Algo activity_selector step 6400 current loss 0.688587, current_train_items 88272.
I0829 18:42:31.710165 129274868512256 run.py:728] (val) algo activity_selector step 6400: {'selected': 0.8704061895551257, 'score': 0.8704061895551257, 'examples_seen': 88272, 'step': 6400, 'algorithm': 'activity_selector'}
I0829 18:42:31.710319 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.870, val scores are: activity_selector: 0.870
I0829 18:42:32.267050 129274868512256 run.py:693] Algo activity_selector step 6450 current loss 0.724071, current_train_items 88944.
I0829 18:42:32.287268 129274868512256 run.py:728] (val) algo activity_selector step 6450: {'selected': 0.8626692456479689, 'score': 0.8626692456479689, 'examples_seen': 88944, 'step': 6450, 'algorithm': 'activity_selector'}
I0829 18:42:32.287528 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.863, val scores are: activity_selector: 0.863
I0829 18:42:32.866412 129274868512256 run.py:693] Algo activity_selector step 6500 current loss 0.421377, current_train_items 89648.
I0829 18:42:32.883039 129274868512256 run.py:728] (val) algo activity_selector step 6500: {'selected': 0.8766114180478821, 'score': 0.8766114180478821, 'examples_seen': 89648, 'step': 6500, 'algorithm': 'activity_selector'}
I0829 18:42:32.883198 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.877, val scores are: activity_selector: 0.877
I0829 18:42:33.439156 129274868512256 run.py:693] Algo activity_selector step 6550 current loss 0.729918, current_train_items 90336.
I0829 18:42:33.456411 129274868512256 run.py:728] (val) algo activity_selector step 6550: {'selected': 0.852686308492201, 'score': 0.852686308492201, 'examples_seen': 90336, 'step': 6550, 'algorithm': 'activity_selector'}
I0829 18:42:33.456579 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.853, val scores are: activity_selector: 0.853
I0829 18:42:34.044050 129274868512256 run.py:693] Algo activity_selector step 6600 current loss 0.951473, current_train_items 91008.
I0829 18:42:34.061245 129274868512256 run.py:728] (val) algo activity_selector step 6600: {'selected': 0.8681898066783831, 'score': 0.8681898066783831, 'examples_seen': 91008, 'step': 6600, 'algorithm': 'activity_selector'}
I0829 18:42:34.061390 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.868, val scores are: activity_selector: 0.868
I0829 18:42:34.723269 129274868512256 run.py:693] Algo activity_selector step 6650 current loss 0.490327, current_train_items 91712.
I0829 18:42:34.741799 129274868512256 run.py:728] (val) algo activity_selector step 6650: {'selected': 0.8767123287671232, 'score': 0.8767123287671232, 'examples_seen': 91712, 'step': 6650, 'algorithm': 'activity_selector'}
I0829 18:42:34.741974 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.877, val scores are: activity_selector: 0.877
I0829 18:42:35.436512 129274868512256 run.py:693] Algo activity_selector step 6700 current loss 0.376493, current_train_items 92416.
I0829 18:42:35.453447 129274868512256 run.py:728] (val) algo activity_selector step 6700: {'selected': 0.8613678373382625, 'score': 0.8613678373382625, 'examples_seen': 92416, 'step': 6700, 'algorithm': 'activity_selector'}
I0829 18:42:35.453599 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.861, val scores are: activity_selector: 0.861
I0829 18:42:36.078245 129274868512256 run.py:693] Algo activity_selector step 6750 current loss 0.587116, current_train_items 93088.
I0829 18:42:36.095393 129274868512256 run.py:728] (val) algo activity_selector step 6750: {'selected': 0.8462929475587704, 'score': 0.8462929475587704, 'examples_seen': 93088, 'step': 6750, 'algorithm': 'activity_selector'}
I0829 18:42:36.095553 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.846, val scores are: activity_selector: 0.846
I0829 18:42:36.780928 129274868512256 run.py:693] Algo activity_selector step 6800 current loss 1.293457, current_train_items 93776.
I0829 18:42:36.799714 129274868512256 run.py:728] (val) algo activity_selector step 6800: {'selected': 0.8821292775665398, 'score': 0.8821292775665398, 'examples_seen': 93776, 'step': 6800, 'algorithm': 'activity_selector'}
I0829 18:42:36.799898 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.882, val scores are: activity_selector: 0.882
I0829 18:42:37.466509 129274868512256 run.py:693] Algo activity_selector step 6850 current loss 0.682713, current_train_items 94480.
I0829 18:42:37.482493 129274868512256 run.py:728] (val) algo activity_selector step 6850: {'selected': 0.9100917431192661, 'score': 0.9100917431192661, 'examples_seen': 94480, 'step': 6850, 'algorithm': 'activity_selector'}
I0829 18:42:37.482649 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0829 18:42:38.047213 129274868512256 run.py:693] Algo activity_selector step 6900 current loss 0.350155, current_train_items 95152.
I0829 18:42:38.063385 129274868512256 run.py:728] (val) algo activity_selector step 6900: {'selected': 0.8439108061749572, 'score': 0.8439108061749572, 'examples_seen': 95152, 'step': 6900, 'algorithm': 'activity_selector'}
I0829 18:42:38.063541 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.844, val scores are: activity_selector: 0.844
I0829 18:42:38.643812 129274868512256 run.py:693] Algo activity_selector step 6950 current loss 0.728969, current_train_items 95840.
I0829 18:42:38.660070 129274868512256 run.py:728] (val) algo activity_selector step 6950: {'selected': 0.888454011741683, 'score': 0.888454011741683, 'examples_seen': 95840, 'step': 6950, 'algorithm': 'activity_selector'}
I0829 18:42:38.660228 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.888, val scores are: activity_selector: 0.888
I0829 18:42:39.208616 129274868512256 run.py:693] Algo activity_selector step 7000 current loss 0.447536, current_train_items 96544.
I0829 18:42:39.224491 129274868512256 run.py:728] (val) algo activity_selector step 7000: {'selected': 0.8957528957528957, 'score': 0.8957528957528957, 'examples_seen': 96544, 'step': 7000, 'algorithm': 'activity_selector'}
I0829 18:42:39.224658 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0829 18:42:39.779284 129274868512256 run.py:693] Algo activity_selector step 7050 current loss 0.921056, current_train_items 97232.
I0829 18:42:39.795985 129274868512256 run.py:728] (val) algo activity_selector step 7050: {'selected': 0.8781431334622823, 'score': 0.8781431334622823, 'examples_seen': 97232, 'step': 7050, 'algorithm': 'activity_selector'}
I0829 18:42:39.796139 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.878, val scores are: activity_selector: 0.878
I0829 18:42:40.346173 129274868512256 run.py:693] Algo activity_selector step 7100 current loss 1.097423, current_train_items 97920.
I0829 18:42:40.362742 129274868512256 run.py:728] (val) algo activity_selector step 7100: {'selected': 0.8355387523629489, 'score': 0.8355387523629489, 'examples_seen': 97920, 'step': 7100, 'algorithm': 'activity_selector'}
I0829 18:42:40.362893 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.836, val scores are: activity_selector: 0.836
I0829 18:42:40.911279 129274868512256 run.py:693] Algo activity_selector step 7150 current loss 0.653245, current_train_items 98608.
I0829 18:42:40.927702 129274868512256 run.py:728] (val) algo activity_selector step 7150: {'selected': 0.894927536231884, 'score': 0.894927536231884, 'examples_seen': 98608, 'step': 7150, 'algorithm': 'activity_selector'}
I0829 18:42:40.927866 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.895, val scores are: activity_selector: 0.895
I0829 18:42:41.478886 129274868512256 run.py:693] Algo activity_selector step 7200 current loss 0.627657, current_train_items 99296.
I0829 18:42:41.494654 129274868512256 run.py:728] (val) algo activity_selector step 7200: {'selected': 0.8549019607843137, 'score': 0.8549019607843137, 'examples_seen': 99296, 'step': 7200, 'algorithm': 'activity_selector'}
I0829 18:42:41.494802 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.855, val scores are: activity_selector: 0.855
I0829 18:42:42.064021 129274868512256 run.py:693] Algo activity_selector step 7250 current loss 0.939821, current_train_items 99984.
I0829 18:42:42.080457 129274868512256 run.py:728] (val) algo activity_selector step 7250: {'selected': 0.8571428571428572, 'score': 0.8571428571428572, 'examples_seen': 99984, 'step': 7250, 'algorithm': 'activity_selector'}
I0829 18:42:42.080609 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.857, val scores are: activity_selector: 0.857
I0829 18:42:42.646708 129274868512256 run.py:693] Algo activity_selector step 7300 current loss 0.558789, current_train_items 100672.
I0829 18:42:42.664746 129274868512256 run.py:728] (val) algo activity_selector step 7300: {'selected': 0.8873483535528597, 'score': 0.8873483535528597, 'examples_seen': 100672, 'step': 7300, 'algorithm': 'activity_selector'}
I0829 18:42:42.664962 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.887, val scores are: activity_selector: 0.887
I0829 18:42:43.243244 129274868512256 run.py:693] Algo activity_selector step 7350 current loss 0.668089, current_train_items 101360.
I0829 18:42:43.259546 129274868512256 run.py:728] (val) algo activity_selector step 7350: {'selected': 0.8956356736242884, 'score': 0.8956356736242884, 'examples_seen': 101360, 'step': 7350, 'algorithm': 'activity_selector'}
I0829 18:42:43.259688 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0829 18:42:43.807961 129274868512256 run.py:693] Algo activity_selector step 7400 current loss 0.722524, current_train_items 102048.
I0829 18:42:43.824097 129274868512256 run.py:728] (val) algo activity_selector step 7400: {'selected': 0.8892794376098417, 'score': 0.8892794376098417, 'examples_seen': 102048, 'step': 7400, 'algorithm': 'activity_selector'}
I0829 18:42:43.824247 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.889, val scores are: activity_selector: 0.889
I0829 18:42:44.366755 129274868512256 run.py:693] Algo activity_selector step 7450 current loss 0.710174, current_train_items 102752.
I0829 18:42:44.383232 129274868512256 run.py:728] (val) algo activity_selector step 7450: {'selected': 0.8052805280528054, 'score': 0.8052805280528054, 'examples_seen': 102752, 'step': 7450, 'algorithm': 'activity_selector'}
I0829 18:42:44.383384 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.805, val scores are: activity_selector: 0.805
I0829 18:42:44.986561 129274868512256 run.py:693] Algo activity_selector step 7500 current loss 0.544540, current_train_items 103424.
I0829 18:42:45.005381 129274868512256 run.py:728] (val) algo activity_selector step 7500: {'selected': 0.8493647912885662, 'score': 0.8493647912885662, 'examples_seen': 103424, 'step': 7500, 'algorithm': 'activity_selector'}
I0829 18:42:45.005569 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.849, val scores are: activity_selector: 0.849
I0829 18:42:45.615955 129274868512256 run.py:693] Algo activity_selector step 7550 current loss 0.864807, current_train_items 104128.
I0829 18:42:45.635598 129274868512256 run.py:728] (val) algo activity_selector step 7550: {'selected': 0.866412213740458, 'score': 0.866412213740458, 'examples_seen': 104128, 'step': 7550, 'algorithm': 'activity_selector'}
I0829 18:42:45.635843 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.866, val scores are: activity_selector: 0.866
I0829 18:42:46.182505 129274868512256 run.py:693] Algo activity_selector step 7600 current loss 0.393402, current_train_items 104816.
I0829 18:42:46.198363 129274868512256 run.py:728] (val) algo activity_selector step 7600: {'selected': 0.8006872852233677, 'score': 0.8006872852233677, 'examples_seen': 104816, 'step': 7600, 'algorithm': 'activity_selector'}
I0829 18:42:46.198510 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.801, val scores are: activity_selector: 0.801
I0829 18:42:46.735513 129274868512256 run.py:693] Algo activity_selector step 7650 current loss 1.002252, current_train_items 105488.
I0829 18:42:46.750575 129274868512256 run.py:728] (val) algo activity_selector step 7650: {'selected': 0.8813559322033898, 'score': 0.8813559322033898, 'examples_seen': 105488, 'step': 7650, 'algorithm': 'activity_selector'}
I0829 18:42:46.750721 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.881, val scores are: activity_selector: 0.881
I0829 18:42:47.306615 129274868512256 run.py:693] Algo activity_selector step 7700 current loss 0.450383, current_train_items 106192.
I0829 18:42:47.322429 129274868512256 run.py:728] (val) algo activity_selector step 7700: {'selected': 0.8825622775800711, 'score': 0.8825622775800711, 'examples_seen': 106192, 'step': 7700, 'algorithm': 'activity_selector'}
I0829 18:42:47.322587 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.883, val scores are: activity_selector: 0.883
I0829 18:42:47.860424 129274868512256 run.py:693] Algo activity_selector step 7750 current loss 0.414360, current_train_items 106880.
I0829 18:42:47.876338 129274868512256 run.py:728] (val) algo activity_selector step 7750: {'selected': 0.8609022556390977, 'score': 0.8609022556390977, 'examples_seen': 106880, 'step': 7750, 'algorithm': 'activity_selector'}
I0829 18:42:47.876487 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.861, val scores are: activity_selector: 0.861
I0829 18:42:48.440732 129274868512256 run.py:693] Algo activity_selector step 7800 current loss 0.536412, current_train_items 107568.
I0829 18:42:48.455585 129274868512256 run.py:728] (val) algo activity_selector step 7800: {'selected': 0.8648648648648648, 'score': 0.8648648648648648, 'examples_seen': 107568, 'step': 7800, 'algorithm': 'activity_selector'}
I0829 18:42:48.455740 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.865, val scores are: activity_selector: 0.865
I0829 18:42:49.008291 129274868512256 run.py:693] Algo activity_selector step 7850 current loss 0.794250, current_train_items 108256.
I0829 18:42:49.024987 129274868512256 run.py:728] (val) algo activity_selector step 7850: {'selected': 0.8906560636182903, 'score': 0.8906560636182903, 'examples_seen': 108256, 'step': 7850, 'algorithm': 'activity_selector'}
I0829 18:42:49.025155 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0829 18:42:49.568577 129274868512256 run.py:693] Algo activity_selector step 7900 current loss 0.399780, current_train_items 108960.
I0829 18:42:49.584913 129274868512256 run.py:728] (val) algo activity_selector step 7900: {'selected': 0.8743362831858408, 'score': 0.8743362831858408, 'examples_seen': 108960, 'step': 7900, 'algorithm': 'activity_selector'}
I0829 18:42:49.585185 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.874, val scores are: activity_selector: 0.874
I0829 18:42:50.138589 129274868512256 run.py:693] Algo activity_selector step 7950 current loss 0.808339, current_train_items 109632.
I0829 18:42:50.154177 129274868512256 run.py:728] (val) algo activity_selector step 7950: {'selected': 0.8645833333333333, 'score': 0.8645833333333333, 'examples_seen': 109632, 'step': 7950, 'algorithm': 'activity_selector'}
I0829 18:42:50.154338 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.865, val scores are: activity_selector: 0.865
I0829 18:42:50.682145 129274868512256 run.py:693] Algo activity_selector step 8000 current loss 0.583916, current_train_items 110320.
I0829 18:42:50.698216 129274868512256 run.py:728] (val) algo activity_selector step 8000: {'selected': 0.8884688090737239, 'score': 0.8884688090737239, 'examples_seen': 110320, 'step': 8000, 'algorithm': 'activity_selector'}
I0829 18:42:50.698364 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.917, current avg val score is 0.888, val scores are: activity_selector: 0.888
I0829 18:42:51.244651 129274868512256 run.py:693] Algo activity_selector step 8050 current loss 0.878978, current_train_items 111024.
I0829 18:42:51.260847 129274868512256 run.py:728] (val) algo activity_selector step 8050: {'selected': 0.8076923076923076, 'score': 0.8076923076923076, 'examples_seen': 111024, 'step': 8050, 'algorithm': 'activity_selector'}
I0829 18:42:51.260993 129274868512256 run.py:749] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.808, val scores are: activity_selector: 0.808
I0829 18:42:51.827406 129274868512256 run.py:693] Algo activity_selector step 8100 current loss 0.556948, current_train_items 111696.
I0829 18:42:51.842854 129274868512256 run.py:728] (val) algo activity_selector step 8100: {'selected': 0.8810916179337231, 'score': 0.8810916179337231, 'examples_seen': 111696, 'step': 8100, 'algorithm': 'activity_selector'}
I0829 18:42:51.843024 129274868512256 run.py:749] Checkpointing best model, best avg val score was 0.808, current avg val score is 0.881, val scores are: activity_selector: 0.881
I0829 18:42:52.408063 129274868512256 run.py:693] Algo activity_selector step 8150 current loss 0.728382, current_train_items 112400.
I0829 18:42:52.423621 129274868512256 run.py:728] (val) algo activity_selector step 8150: {'selected': 0.8103727714748784, 'score': 0.8103727714748784, 'examples_seen': 112400, 'step': 8150, 'algorithm': 'activity_selector'}
I0829 18:42:52.423794 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.881, current avg val score is 0.810, val scores are: activity_selector: 0.810
I0829 18:42:52.980615 129274868512256 run.py:693] Algo activity_selector step 8200 current loss 0.578448, current_train_items 113088.
I0829 18:42:52.996926 129274868512256 run.py:728] (val) algo activity_selector step 8200: {'selected': 0.9132947976878613, 'score': 0.9132947976878613, 'examples_seen': 113088, 'step': 8200, 'algorithm': 'activity_selector'}
I0829 18:42:52.997091 129274868512256 run.py:749] Checkpointing best model, best avg val score was 0.881, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0829 18:42:53.538776 129274868512256 run.py:693] Algo activity_selector step 8250 current loss 0.728521, current_train_items 113760.
I0829 18:42:53.553222 129274868512256 run.py:728] (val) algo activity_selector step 8250: {'selected': 0.9027777777777777, 'score': 0.9027777777777777, 'examples_seen': 113760, 'step': 8250, 'algorithm': 'activity_selector'}
I0829 18:42:53.553443 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.903, val scores are: activity_selector: 0.903
I0829 18:42:54.108746 129274868512256 run.py:693] Algo activity_selector step 8300 current loss 0.946962, current_train_items 114464.
I0829 18:42:54.125221 129274868512256 run.py:728] (val) algo activity_selector step 8300: {'selected': 0.8556521739130435, 'score': 0.8556521739130435, 'examples_seen': 114464, 'step': 8300, 'algorithm': 'activity_selector'}
I0829 18:42:54.125372 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.856, val scores are: activity_selector: 0.856
I0829 18:42:54.664487 129274868512256 run.py:693] Algo activity_selector step 8350 current loss 0.769319, current_train_items 115152.
I0829 18:42:54.680438 129274868512256 run.py:728] (val) algo activity_selector step 8350: {'selected': 0.8638838475499091, 'score': 0.8638838475499091, 'examples_seen': 115152, 'step': 8350, 'algorithm': 'activity_selector'}
I0829 18:42:54.680581 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.864, val scores are: activity_selector: 0.864
I0829 18:42:55.226348 129274868512256 run.py:693] Algo activity_selector step 8400 current loss 0.430527, current_train_items 115840.
I0829 18:42:55.242087 129274868512256 run.py:728] (val) algo activity_selector step 8400: {'selected': 0.8689138576779026, 'score': 0.8689138576779026, 'examples_seen': 115840, 'step': 8400, 'algorithm': 'activity_selector'}
I0829 18:42:55.242246 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.869, val scores are: activity_selector: 0.869
I0829 18:42:55.786281 129274868512256 run.py:693] Algo activity_selector step 8450 current loss 0.714484, current_train_items 116528.
I0829 18:42:55.802065 129274868512256 run.py:728] (val) algo activity_selector step 8450: {'selected': 0.8446969696969697, 'score': 0.8446969696969697, 'examples_seen': 116528, 'step': 8450, 'algorithm': 'activity_selector'}
I0829 18:42:55.802321 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.845, val scores are: activity_selector: 0.845
I0829 18:42:56.340049 129274868512256 run.py:693] Algo activity_selector step 8500 current loss 0.654725, current_train_items 117232.
I0829 18:42:56.356030 129274868512256 run.py:728] (val) algo activity_selector step 8500: {'selected': 0.846307385229541, 'score': 0.846307385229541, 'examples_seen': 117232, 'step': 8500, 'algorithm': 'activity_selector'}
I0829 18:42:56.356195 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.846, val scores are: activity_selector: 0.846
I0829 18:42:56.908250 129274868512256 run.py:693] Algo activity_selector step 8550 current loss 0.725633, current_train_items 117904.
I0829 18:42:56.924007 129274868512256 run.py:728] (val) algo activity_selector step 8550: {'selected': 0.8709055876685935, 'score': 0.8709055876685935, 'examples_seen': 117904, 'step': 8550, 'algorithm': 'activity_selector'}
I0829 18:42:56.924160 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.871, val scores are: activity_selector: 0.871
I0829 18:42:57.476357 129274868512256 run.py:693] Algo activity_selector step 8600 current loss 0.741664, current_train_items 118592.
I0829 18:42:57.492334 129274868512256 run.py:728] (val) algo activity_selector step 8600: {'selected': 0.8825757575757576, 'score': 0.8825757575757576, 'examples_seen': 118592, 'step': 8600, 'algorithm': 'activity_selector'}
I0829 18:42:57.492488 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.883, val scores are: activity_selector: 0.883
I0829 18:42:58.030055 129274868512256 run.py:693] Algo activity_selector step 8650 current loss 1.014863, current_train_items 119296.
I0829 18:42:58.045938 129274868512256 run.py:728] (val) algo activity_selector step 8650: {'selected': 0.846743295019157, 'score': 0.846743295019157, 'examples_seen': 119296, 'step': 8650, 'algorithm': 'activity_selector'}
I0829 18:42:58.046098 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.847, val scores are: activity_selector: 0.847
I0829 18:42:58.607706 129274868512256 run.py:693] Algo activity_selector step 8700 current loss 0.394663, current_train_items 119968.
I0829 18:42:58.624240 129274868512256 run.py:728] (val) algo activity_selector step 8700: {'selected': 0.8720720720720719, 'score': 0.8720720720720719, 'examples_seen': 119968, 'step': 8700, 'algorithm': 'activity_selector'}
I0829 18:42:58.624427 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.872, val scores are: activity_selector: 0.872
I0829 18:42:59.188096 129274868512256 run.py:693] Algo activity_selector step 8750 current loss 0.489030, current_train_items 120672.
I0829 18:42:59.204093 129274868512256 run.py:728] (val) algo activity_selector step 8750: {'selected': 0.8857644991212654, 'score': 0.8857644991212654, 'examples_seen': 120672, 'step': 8750, 'algorithm': 'activity_selector'}
I0829 18:42:59.204280 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0829 18:42:59.770031 129274868512256 run.py:693] Algo activity_selector step 8800 current loss 0.871224, current_train_items 121360.
I0829 18:42:59.786503 129274868512256 run.py:728] (val) algo activity_selector step 8800: {'selected': 0.8602540834845734, 'score': 0.8602540834845734, 'examples_seen': 121360, 'step': 8800, 'algorithm': 'activity_selector'}
I0829 18:42:59.786665 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.860, val scores are: activity_selector: 0.860
I0829 18:43:00.356590 129274868512256 run.py:693] Algo activity_selector step 8850 current loss 0.335084, current_train_items 122048.
I0829 18:43:00.372307 129274868512256 run.py:728] (val) algo activity_selector step 8850: {'selected': 0.8541666666666667, 'score': 0.8541666666666667, 'examples_seen': 122048, 'step': 8850, 'algorithm': 'activity_selector'}
I0829 18:43:00.372490 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.854, val scores are: activity_selector: 0.854
I0829 18:43:00.953320 129274868512256 run.py:693] Algo activity_selector step 8900 current loss 0.684385, current_train_items 122736.
I0829 18:43:00.968762 129274868512256 run.py:728] (val) algo activity_selector step 8900: {'selected': 0.8186915887850468, 'score': 0.8186915887850468, 'examples_seen': 122736, 'step': 8900, 'algorithm': 'activity_selector'}
I0829 18:43:00.968944 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.819, val scores are: activity_selector: 0.819
I0829 18:43:01.566229 129274868512256 run.py:693] Algo activity_selector step 8950 current loss 0.638858, current_train_items 123424.
I0829 18:43:01.581703 129274868512256 run.py:728] (val) algo activity_selector step 8950: {'selected': 0.8792792792792792, 'score': 0.8792792792792792, 'examples_seen': 123424, 'step': 8950, 'algorithm': 'activity_selector'}
I0829 18:43:01.581847 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0829 18:43:02.162930 129274868512256 run.py:693] Algo activity_selector step 9000 current loss 0.664846, current_train_items 124112.
I0829 18:43:02.182274 129274868512256 run.py:728] (val) algo activity_selector step 9000: {'selected': 0.8235294117647058, 'score': 0.8235294117647058, 'examples_seen': 124112, 'step': 9000, 'algorithm': 'activity_selector'}
I0829 18:43:02.182440 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.824, val scores are: activity_selector: 0.824
I0829 18:43:02.731844 129274868512256 run.py:693] Algo activity_selector step 9050 current loss 1.179899, current_train_items 124800.
I0829 18:43:02.748149 129274868512256 run.py:728] (val) algo activity_selector step 9050: {'selected': 0.8666666666666667, 'score': 0.8666666666666667, 'examples_seen': 124800, 'step': 9050, 'algorithm': 'activity_selector'}
I0829 18:43:02.748391 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0829 18:43:03.279777 129274868512256 run.py:693] Algo activity_selector step 9100 current loss 0.585147, current_train_items 125488.
I0829 18:43:03.294848 129274868512256 run.py:728] (val) algo activity_selector step 9100: {'selected': 0.8684684684684685, 'score': 0.8684684684684685, 'examples_seen': 125488, 'step': 9100, 'algorithm': 'activity_selector'}
I0829 18:43:03.295006 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.868, val scores are: activity_selector: 0.868
I0829 18:43:03.833935 129274868512256 run.py:693] Algo activity_selector step 9150 current loss 0.427276, current_train_items 126176.
I0829 18:43:03.849009 129274868512256 run.py:728] (val) algo activity_selector step 9150: {'selected': 0.8604206500956022, 'score': 0.8604206500956022, 'examples_seen': 126176, 'step': 9150, 'algorithm': 'activity_selector'}
I0829 18:43:03.849162 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.860, val scores are: activity_selector: 0.860
I0829 18:43:04.377681 129274868512256 run.py:693] Algo activity_selector step 9200 current loss 0.622601, current_train_items 126880.
I0829 18:43:04.392856 129274868512256 run.py:728] (val) algo activity_selector step 9200: {'selected': 0.8561020036429872, 'score': 0.8561020036429872, 'examples_seen': 126880, 'step': 9200, 'algorithm': 'activity_selector'}
I0829 18:43:04.393013 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.856, val scores are: activity_selector: 0.856
I0829 18:43:04.925113 129274868512256 run.py:693] Algo activity_selector step 9250 current loss 0.778463, current_train_items 127568.
I0829 18:43:04.941188 129274868512256 run.py:728] (val) algo activity_selector step 9250: {'selected': 0.8803088803088802, 'score': 0.8803088803088802, 'examples_seen': 127568, 'step': 9250, 'algorithm': 'activity_selector'}
I0829 18:43:04.941343 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0829 18:43:05.466669 129274868512256 run.py:693] Algo activity_selector step 9300 current loss 0.429636, current_train_items 128240.
I0829 18:43:05.481522 129274868512256 run.py:728] (val) algo activity_selector step 9300: {'selected': 0.8666666666666668, 'score': 0.8666666666666668, 'examples_seen': 128240, 'step': 9300, 'algorithm': 'activity_selector'}
I0829 18:43:05.481668 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0829 18:43:06.015233 129274868512256 run.py:693] Algo activity_selector step 9350 current loss 0.537521, current_train_items 128944.
I0829 18:43:06.030926 129274868512256 run.py:728] (val) algo activity_selector step 9350: {'selected': 0.8785714285714286, 'score': 0.8785714285714286, 'examples_seen': 128944, 'step': 9350, 'algorithm': 'activity_selector'}
I0829 18:43:06.031091 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0829 18:43:06.560270 129274868512256 run.py:693] Algo activity_selector step 9400 current loss 0.823362, current_train_items 129632.
I0829 18:43:06.576617 129274868512256 run.py:728] (val) algo activity_selector step 9400: {'selected': 0.863716814159292, 'score': 0.863716814159292, 'examples_seen': 129632, 'step': 9400, 'algorithm': 'activity_selector'}
I0829 18:43:06.576768 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.864, val scores are: activity_selector: 0.864
I0829 18:43:07.105445 129274868512256 run.py:693] Algo activity_selector step 9450 current loss 0.952501, current_train_items 130304.
I0829 18:43:07.120981 129274868512256 run.py:728] (val) algo activity_selector step 9450: {'selected': 0.8634064080944351, 'score': 0.8634064080944351, 'examples_seen': 130304, 'step': 9450, 'algorithm': 'activity_selector'}
I0829 18:43:07.121140 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.863, val scores are: activity_selector: 0.863
I0829 18:43:07.692189 129274868512256 run.py:693] Algo activity_selector step 9500 current loss 0.736619, current_train_items 131008.
I0829 18:43:07.708287 129274868512256 run.py:728] (val) algo activity_selector step 9500: {'selected': 0.8654545454545454, 'score': 0.8654545454545454, 'examples_seen': 131008, 'step': 9500, 'algorithm': 'activity_selector'}
I0829 18:43:07.708441 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.865, val scores are: activity_selector: 0.865
I0829 18:43:08.255137 129274868512256 run.py:693] Algo activity_selector step 9550 current loss 0.744304, current_train_items 131712.
I0829 18:43:08.271022 129274868512256 run.py:728] (val) algo activity_selector step 9550: {'selected': 0.8436911487758945, 'score': 0.8436911487758945, 'examples_seen': 131712, 'step': 9550, 'algorithm': 'activity_selector'}
I0829 18:43:08.271191 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.844, val scores are: activity_selector: 0.844
I0829 18:43:08.835811 129274868512256 run.py:693] Algo activity_selector step 9600 current loss 0.628223, current_train_items 132384.
I0829 18:43:08.852555 129274868512256 run.py:728] (val) algo activity_selector step 9600: {'selected': 0.8345070422535212, 'score': 0.8345070422535212, 'examples_seen': 132384, 'step': 9600, 'algorithm': 'activity_selector'}
I0829 18:43:08.852726 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.835, val scores are: activity_selector: 0.835
I0829 18:43:09.443990 129274868512256 run.py:693] Algo activity_selector step 9650 current loss 0.779691, current_train_items 133072.
I0829 18:43:09.459785 129274868512256 run.py:728] (val) algo activity_selector step 9650: {'selected': 0.8508064516129032, 'score': 0.8508064516129032, 'examples_seen': 133072, 'step': 9650, 'algorithm': 'activity_selector'}
I0829 18:43:09.459940 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.851, val scores are: activity_selector: 0.851
I0829 18:43:10.072071 129274868512256 run.py:693] Algo activity_selector step 9700 current loss 0.551345, current_train_items 133776.
I0829 18:43:10.089456 129274868512256 run.py:728] (val) algo activity_selector step 9700: {'selected': 0.889261744966443, 'score': 0.889261744966443, 'examples_seen': 133776, 'step': 9700, 'algorithm': 'activity_selector'}
I0829 18:43:10.089636 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.889, val scores are: activity_selector: 0.889
I0829 18:43:10.661275 129274868512256 run.py:693] Algo activity_selector step 9750 current loss 0.828707, current_train_items 134448.
I0829 18:43:10.677415 129274868512256 run.py:728] (val) algo activity_selector step 9750: {'selected': 0.8942486085343228, 'score': 0.8942486085343228, 'examples_seen': 134448, 'step': 9750, 'algorithm': 'activity_selector'}
I0829 18:43:10.677563 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0829 18:43:11.262693 129274868512256 run.py:693] Algo activity_selector step 9800 current loss 0.608772, current_train_items 135136.
I0829 18:43:11.278098 129274868512256 run.py:728] (val) algo activity_selector step 9800: {'selected': 0.888888888888889, 'score': 0.888888888888889, 'examples_seen': 135136, 'step': 9800, 'algorithm': 'activity_selector'}
I0829 18:43:11.278261 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.889, val scores are: activity_selector: 0.889
I0829 18:43:11.839020 129274868512256 run.py:693] Algo activity_selector step 9850 current loss 0.507710, current_train_items 135840.
I0829 18:43:11.854711 129274868512256 run.py:728] (val) algo activity_selector step 9850: {'selected': 0.8852459016393444, 'score': 0.8852459016393444, 'examples_seen': 135840, 'step': 9850, 'algorithm': 'activity_selector'}
I0829 18:43:11.854878 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0829 18:43:12.449273 129274868512256 run.py:693] Algo activity_selector step 9900 current loss 1.027830, current_train_items 136528.
I0829 18:43:12.464925 129274868512256 run.py:728] (val) algo activity_selector step 9900: {'selected': 0.876984126984127, 'score': 0.876984126984127, 'examples_seen': 136528, 'step': 9900, 'algorithm': 'activity_selector'}
I0829 18:43:12.465098 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.877, val scores are: activity_selector: 0.877
I0829 18:43:13.033479 129274868512256 run.py:693] Algo activity_selector step 9950 current loss 0.589910, current_train_items 137200.
I0829 18:43:13.049989 129274868512256 run.py:728] (val) algo activity_selector step 9950: {'selected': 0.8496503496503497, 'score': 0.8496503496503497, 'examples_seen': 137200, 'step': 9950, 'algorithm': 'activity_selector'}
I0829 18:43:13.050171 129274868512256 run.py:752] Not saving new best model, best avg val score was 0.913, current avg val score is 0.850, val scores are: activity_selector: 0.850
I0829 18:43:13.611821 129274868512256 run.py:758] Restoring best model from checkpoint...
I0829 18:43:16.761379 129274868512256 run.py:773] (test) algo activity_selector : {'selected': 0.6917808219178082, 'score': 0.6917808219178082, 'examples_seen': 137888, 'step': 10000, 'algorithm': 'activity_selector'}
I0829 18:43:16.761552 129274868512256 run.py:775] Done!
