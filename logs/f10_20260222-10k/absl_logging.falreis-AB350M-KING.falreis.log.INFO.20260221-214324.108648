I0221 21:43:27.179921 136516138993152 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0221 21:43:27.180567 136516138993152 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0221 21:43:27.441558 136516138993152 run.py:443] Model: f10 ['activity_selector']
I0221 21:43:27.441682 136516138993152 run.py:445] algorithms ['activity_selector']
I0221 21:43:27.441914 136516138993152 run.py:446] train_lengths ['4', '7', '11', '13', '16']
I0221 21:43:27.441966 136516138993152 run.py:447] train_batch_size 16
I0221 21:43:27.442105 136516138993152 run.py:448] val_batch_size 16
I0221 21:43:27.442153 136516138993152 run.py:449] test_batch_size 16
I0221 21:43:27.442193 136516138993152 run.py:450] chunked_training True
I0221 21:43:27.442365 136516138993152 run.py:451] chunk_length 16
I0221 21:43:27.442410 136516138993152 run.py:452] train_steps 10001
I0221 21:43:27.442452 136516138993152 run.py:453] eval_every 50
I0221 21:43:27.442492 136516138993152 run.py:454] test_every 500
I0221 21:43:27.442531 136516138993152 run.py:455] hidden_size 256
I0221 21:43:27.442574 136516138993152 run.py:456] nb_msg_passing_steps 1
I0221 21:43:27.442614 136516138993152 run.py:457] learning_rate 0.001
I0221 21:43:27.442748 136516138993152 run.py:458] grad_clip_max_norm 1.0
I0221 21:43:27.442788 136516138993152 run.py:459] dropout_prob 0.0
I0221 21:43:27.442827 136516138993152 run.py:460] hint_teacher_forcing 0.0
I0221 21:43:27.442871 136516138993152 run.py:461] hint_mode encoded_decoded
I0221 21:43:27.443020 136516138993152 run.py:462] hint_repred_mode soft
I0221 21:43:27.443071 136516138993152 run.py:463] use_ln True
I0221 21:43:27.443111 136516138993152 run.py:464] use_lstm True
I0221 21:43:27.443149 136516138993152 run.py:465] nb_triplet_fts 16
I0221 21:43:27.443192 136516138993152 run.py:466] encoder_init xavier_on_scalars
I0221 21:43:27.443231 136516138993152 run.py:467] processor_type f10
I0221 21:43:27.443270 136516138993152 run.py:468] checkpoint_path CLRS30
I0221 21:43:27.443308 136516138993152 run.py:469] dataset_path CLRS30
I0221 21:43:27.443351 136516138993152 run.py:470] freeze_processor False
I0221 21:43:27.443389 136516138993152 run.py:471] reduction min
I0221 21:43:27.443427 136516138993152 run.py:472] activation elu
I0221 21:43:27.443465 136516138993152 run.py:473] restore_model 
I0221 21:43:27.443507 136516138993152 run.py:474] gated True
I0221 21:43:27.443546 136516138993152 run.py:475] gated_activation sigmoid
I0221 21:43:27.443583 136516138993152 run.py:476] memory_type mha
I0221 21:43:27.443624 136516138993152 run.py:477] memory_size 16
I0221 21:43:27.446578 136516138993152 run.py:503] Creating samplers for algo activity_selector
W0221 21:43:27.446863 136516138993152 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0221 21:43:27.447218 136516138993152 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0221 21:43:27.660604 136516138993152 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0221 21:43:27.905488 136516138993152 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0221 21:43:28.209318 136516138993152 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0221 21:43:28.576370 136516138993152 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0221 21:43:28.985344 136516138993152 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0221 21:43:28.985706 136516138993152 samplers.py:124] Creating a dataset with 64 samples.
I0221 21:43:29.011744 136516138993152 run.py:287] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0221 21:43:29.012504 136516138993152 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0221 21:43:29.015824 136516138993152 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0221 21:43:29.018855 136516138993152 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0221 21:43:29.075081 136516138993152 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W0221 21:43:29.102252 136516138993152 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x7c289f6d2200> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0221 21:44:09.155410 136516138993152 run.py:729] Algo activity_selector step 0 current loss 5.169609, current_train_items 32.
I0221 21:44:20.762959 136516138993152 run.py:764] (val) algo activity_selector step 0: {'selected': 0.6187245590230666, 'score': 0.6187245590230666, 'examples_seen': 32, 'step': 0, 'algorithm': 'activity_selector'}
I0221 21:44:20.763153 136516138993152 run.py:785] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.619, val scores are: activity_selector: 0.619
I0221 21:45:20.203681 136516138993152 run.py:729] Algo activity_selector step 50 current loss 3.597789, current_train_items 1408.
I0221 21:45:20.354309 136516138993152 run.py:764] (val) algo activity_selector step 50: {'selected': 0.7218934911242604, 'score': 0.7218934911242604, 'examples_seen': 1408, 'step': 50, 'algorithm': 'activity_selector'}
I0221 21:45:20.354552 136516138993152 run.py:785] Checkpointing best model, best avg val score was 0.619, current avg val score is 0.722, val scores are: activity_selector: 0.722
I0221 21:45:21.618762 136516138993152 run.py:729] Algo activity_selector step 100 current loss 3.321518, current_train_items 2800.
I0221 21:45:21.771852 136516138993152 run.py:764] (val) algo activity_selector step 100: {'selected': 0.7434343434343433, 'score': 0.7434343434343433, 'examples_seen': 2800, 'step': 100, 'algorithm': 'activity_selector'}
I0221 21:45:21.772119 136516138993152 run.py:785] Checkpointing best model, best avg val score was 0.722, current avg val score is 0.743, val scores are: activity_selector: 0.743
I0221 21:45:23.030037 136516138993152 run.py:729] Algo activity_selector step 150 current loss 2.354233, current_train_items 4176.
I0221 21:45:23.186430 136516138993152 run.py:764] (val) algo activity_selector step 150: {'selected': 0.7858407079646017, 'score': 0.7858407079646017, 'examples_seen': 4176, 'step': 150, 'algorithm': 'activity_selector'}
I0221 21:45:23.186669 136516138993152 run.py:785] Checkpointing best model, best avg val score was 0.743, current avg val score is 0.786, val scores are: activity_selector: 0.786
I0221 21:45:24.416978 136516138993152 run.py:729] Algo activity_selector step 200 current loss 2.276159, current_train_items 5536.
I0221 21:45:24.560225 136516138993152 run.py:764] (val) algo activity_selector step 200: {'selected': 0.8256513026052105, 'score': 0.8256513026052105, 'examples_seen': 5536, 'step': 200, 'algorithm': 'activity_selector'}
I0221 21:45:24.560528 136516138993152 run.py:785] Checkpointing best model, best avg val score was 0.786, current avg val score is 0.826, val scores are: activity_selector: 0.826
I0221 21:45:25.806572 136516138993152 run.py:729] Algo activity_selector step 250 current loss 3.271693, current_train_items 6944.
I0221 21:45:25.947074 136516138993152 run.py:764] (val) algo activity_selector step 250: {'selected': 0.5268542199488491, 'score': 0.5268542199488491, 'examples_seen': 6944, 'step': 250, 'algorithm': 'activity_selector'}
I0221 21:45:25.947331 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.826, current avg val score is 0.527, val scores are: activity_selector: 0.527
I0221 21:45:27.029992 136516138993152 run.py:729] Algo activity_selector step 300 current loss 2.246514, current_train_items 8304.
I0221 21:45:27.169610 136516138993152 run.py:764] (val) algo activity_selector step 300: {'selected': 0.8101761252446185, 'score': 0.8101761252446185, 'examples_seen': 8304, 'step': 300, 'algorithm': 'activity_selector'}
I0221 21:45:27.169843 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.826, current avg val score is 0.810, val scores are: activity_selector: 0.810
I0221 21:45:28.239807 136516138993152 run.py:729] Algo activity_selector step 350 current loss 1.945721, current_train_items 9680.
I0221 21:45:28.380453 136516138993152 run.py:764] (val) algo activity_selector step 350: {'selected': 0.8293650793650792, 'score': 0.8293650793650792, 'examples_seen': 9680, 'step': 350, 'algorithm': 'activity_selector'}
I0221 21:45:28.380681 136516138993152 run.py:785] Checkpointing best model, best avg val score was 0.826, current avg val score is 0.829, val scores are: activity_selector: 0.829
I0221 21:45:29.600312 136516138993152 run.py:729] Algo activity_selector step 400 current loss 1.873365, current_train_items 11072.
I0221 21:45:29.739926 136516138993152 run.py:764] (val) algo activity_selector step 400: {'selected': 0.8128342245989305, 'score': 0.8128342245989305, 'examples_seen': 11072, 'step': 400, 'algorithm': 'activity_selector'}
I0221 21:45:29.740166 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.829, current avg val score is 0.813, val scores are: activity_selector: 0.813
I0221 21:45:30.814913 136516138993152 run.py:729] Algo activity_selector step 450 current loss 1.810270, current_train_items 12448.
I0221 21:45:30.956206 136516138993152 run.py:764] (val) algo activity_selector step 450: {'selected': 0.8822355289421159, 'score': 0.8822355289421159, 'examples_seen': 12448, 'step': 450, 'algorithm': 'activity_selector'}
I0221 21:45:30.956451 136516138993152 run.py:785] Checkpointing best model, best avg val score was 0.829, current avg val score is 0.882, val scores are: activity_selector: 0.882
I0221 21:45:32.236020 136516138993152 run.py:729] Algo activity_selector step 500 current loss 2.193563, current_train_items 13824.
I0221 21:45:32.402123 136516138993152 run.py:764] (val) algo activity_selector step 500: {'selected': 0.8339622641509433, 'score': 0.8339622641509433, 'examples_seen': 13824, 'step': 500, 'algorithm': 'activity_selector'}
I0221 21:45:32.402379 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.882, current avg val score is 0.834, val scores are: activity_selector: 0.834
I0221 21:45:33.497142 136516138993152 run.py:729] Algo activity_selector step 550 current loss 1.855399, current_train_items 15200.
I0221 21:45:33.647059 136516138993152 run.py:764] (val) algo activity_selector step 550: {'selected': 0.8598848368522073, 'score': 0.8598848368522073, 'examples_seen': 15200, 'step': 550, 'algorithm': 'activity_selector'}
I0221 21:45:33.647294 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.882, current avg val score is 0.860, val scores are: activity_selector: 0.860
I0221 21:45:34.782955 136516138993152 run.py:729] Algo activity_selector step 600 current loss 1.691695, current_train_items 16576.
I0221 21:45:34.933658 136516138993152 run.py:764] (val) algo activity_selector step 600: {'selected': 0.9028571428571429, 'score': 0.9028571428571429, 'examples_seen': 16576, 'step': 600, 'algorithm': 'activity_selector'}
I0221 21:45:34.933914 136516138993152 run.py:785] Checkpointing best model, best avg val score was 0.882, current avg val score is 0.903, val scores are: activity_selector: 0.903
I0221 21:45:36.192889 136516138993152 run.py:729] Algo activity_selector step 650 current loss 1.889037, current_train_items 17952.
I0221 21:45:36.341561 136516138993152 run.py:764] (val) algo activity_selector step 650: {'selected': 0.8795620437956204, 'score': 0.8795620437956204, 'examples_seen': 17952, 'step': 650, 'algorithm': 'activity_selector'}
I0221 21:45:36.341818 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.903, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0221 21:45:37.469857 136516138993152 run.py:729] Algo activity_selector step 700 current loss 1.431165, current_train_items 19344.
I0221 21:45:37.621261 136516138993152 run.py:764] (val) algo activity_selector step 700: {'selected': 0.843065693430657, 'score': 0.843065693430657, 'examples_seen': 19344, 'step': 700, 'algorithm': 'activity_selector'}
I0221 21:45:37.621488 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.903, current avg val score is 0.843, val scores are: activity_selector: 0.843
I0221 21:45:38.744452 136516138993152 run.py:729] Algo activity_selector step 750 current loss 1.616002, current_train_items 20720.
I0221 21:45:38.898589 136516138993152 run.py:764] (val) algo activity_selector step 750: {'selected': 0.8946322067594434, 'score': 0.8946322067594434, 'examples_seen': 20720, 'step': 750, 'algorithm': 'activity_selector'}
I0221 21:45:38.898812 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.903, current avg val score is 0.895, val scores are: activity_selector: 0.895
I0221 21:45:39.969683 136516138993152 run.py:729] Algo activity_selector step 800 current loss 1.527281, current_train_items 22096.
I0221 21:45:40.110271 136516138993152 run.py:764] (val) algo activity_selector step 800: {'selected': 0.9175627240143369, 'score': 0.9175627240143369, 'examples_seen': 22096, 'step': 800, 'algorithm': 'activity_selector'}
I0221 21:45:40.110494 136516138993152 run.py:785] Checkpointing best model, best avg val score was 0.903, current avg val score is 0.918, val scores are: activity_selector: 0.918
I0221 21:45:41.340035 136516138993152 run.py:729] Algo activity_selector step 850 current loss 1.743749, current_train_items 23472.
I0221 21:45:41.480218 136516138993152 run.py:764] (val) algo activity_selector step 850: {'selected': 0.8763636363636363, 'score': 0.8763636363636363, 'examples_seen': 23472, 'step': 850, 'algorithm': 'activity_selector'}
I0221 21:45:41.480457 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.918, current avg val score is 0.876, val scores are: activity_selector: 0.876
I0221 21:45:42.554653 136516138993152 run.py:729] Algo activity_selector step 900 current loss 1.677377, current_train_items 24848.
I0221 21:45:42.694875 136516138993152 run.py:764] (val) algo activity_selector step 900: {'selected': 0.8740458015267176, 'score': 0.8740458015267176, 'examples_seen': 24848, 'step': 900, 'algorithm': 'activity_selector'}
I0221 21:45:42.695122 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.918, current avg val score is 0.874, val scores are: activity_selector: 0.874
I0221 21:45:43.760545 136516138993152 run.py:729] Algo activity_selector step 950 current loss 1.489192, current_train_items 26224.
I0221 21:45:43.899275 136516138993152 run.py:764] (val) algo activity_selector step 950: {'selected': 0.8591304347826088, 'score': 0.8591304347826088, 'examples_seen': 26224, 'step': 950, 'algorithm': 'activity_selector'}
I0221 21:45:43.899495 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.918, current avg val score is 0.859, val scores are: activity_selector: 0.859
I0221 21:45:44.967493 136516138993152 run.py:729] Algo activity_selector step 1000 current loss 1.630527, current_train_items 27616.
I0221 21:45:45.108658 136516138993152 run.py:764] (val) algo activity_selector step 1000: {'selected': 0.9080675422138837, 'score': 0.9080675422138837, 'examples_seen': 27616, 'step': 1000, 'algorithm': 'activity_selector'}
I0221 21:45:45.108898 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.918, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0221 21:45:46.189695 136516138993152 run.py:729] Algo activity_selector step 1050 current loss 1.603272, current_train_items 28992.
I0221 21:45:46.344553 136516138993152 run.py:764] (val) algo activity_selector step 1050: {'selected': 0.9221556886227545, 'score': 0.9221556886227545, 'examples_seen': 28992, 'step': 1050, 'algorithm': 'activity_selector'}
I0221 21:45:46.344778 136516138993152 run.py:785] Checkpointing best model, best avg val score was 0.918, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0221 21:45:47.587807 136516138993152 run.py:729] Algo activity_selector step 1100 current loss 1.285136, current_train_items 30368.
I0221 21:45:47.724863 136516138993152 run.py:764] (val) algo activity_selector step 1100: {'selected': 0.8991935483870968, 'score': 0.8991935483870968, 'examples_seen': 30368, 'step': 1100, 'algorithm': 'activity_selector'}
I0221 21:45:47.725133 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.922, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0221 21:45:48.799217 136516138993152 run.py:729] Algo activity_selector step 1150 current loss 1.398143, current_train_items 31760.
I0221 21:45:48.942201 136516138993152 run.py:764] (val) algo activity_selector step 1150: {'selected': 0.9182156133828996, 'score': 0.9182156133828996, 'examples_seen': 31760, 'step': 1150, 'algorithm': 'activity_selector'}
I0221 21:45:48.942462 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.922, current avg val score is 0.918, val scores are: activity_selector: 0.918
I0221 21:45:50.024270 136516138993152 run.py:729] Algo activity_selector step 1200 current loss 1.198201, current_train_items 33120.
I0221 21:45:50.179625 136516138993152 run.py:764] (val) algo activity_selector step 1200: {'selected': 0.9523809523809523, 'score': 0.9523809523809523, 'examples_seen': 33120, 'step': 1200, 'algorithm': 'activity_selector'}
I0221 21:45:50.179847 136516138993152 run.py:785] Checkpointing best model, best avg val score was 0.922, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0221 21:45:51.430616 136516138993152 run.py:729] Algo activity_selector step 1250 current loss 1.419092, current_train_items 34496.
I0221 21:45:51.588979 136516138993152 run.py:764] (val) algo activity_selector step 1250: {'selected': 0.8896925858951175, 'score': 0.8896925858951175, 'examples_seen': 34496, 'step': 1250, 'algorithm': 'activity_selector'}
I0221 21:45:51.589164 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.890, val scores are: activity_selector: 0.890
I0221 21:45:52.695443 136516138993152 run.py:729] Algo activity_selector step 1300 current loss 1.280598, current_train_items 35888.
I0221 21:45:52.842400 136516138993152 run.py:764] (val) algo activity_selector step 1300: {'selected': 0.920388349514563, 'score': 0.920388349514563, 'examples_seen': 35888, 'step': 1300, 'algorithm': 'activity_selector'}
I0221 21:45:52.842633 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0221 21:45:53.927135 136516138993152 run.py:729] Algo activity_selector step 1350 current loss 1.154076, current_train_items 37264.
I0221 21:45:54.074073 136516138993152 run.py:764] (val) algo activity_selector step 1350: {'selected': 0.9077212806026366, 'score': 0.9077212806026366, 'examples_seen': 37264, 'step': 1350, 'algorithm': 'activity_selector'}
I0221 21:45:54.074309 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0221 21:45:55.210063 136516138993152 run.py:729] Algo activity_selector step 1400 current loss 1.400051, current_train_items 38640.
I0221 21:45:55.363777 136516138993152 run.py:764] (val) algo activity_selector step 1400: {'selected': 0.9132075471698113, 'score': 0.9132075471698113, 'examples_seen': 38640, 'step': 1400, 'algorithm': 'activity_selector'}
I0221 21:45:55.364025 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0221 21:45:56.456606 136516138993152 run.py:729] Algo activity_selector step 1450 current loss 1.113216, current_train_items 40016.
I0221 21:45:56.595357 136516138993152 run.py:764] (val) algo activity_selector step 1450: {'selected': 0.8820116054158608, 'score': 0.8820116054158608, 'examples_seen': 40016, 'step': 1450, 'algorithm': 'activity_selector'}
I0221 21:45:56.595581 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.882, val scores are: activity_selector: 0.882
I0221 21:45:57.692130 136516138993152 run.py:729] Algo activity_selector step 1500 current loss 1.300109, current_train_items 41408.
I0221 21:45:57.841612 136516138993152 run.py:764] (val) algo activity_selector step 1500: {'selected': 0.8513238289205703, 'score': 0.8513238289205703, 'examples_seen': 41408, 'step': 1500, 'algorithm': 'activity_selector'}
I0221 21:45:57.841994 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.851, val scores are: activity_selector: 0.851
I0221 21:45:58.980569 136516138993152 run.py:729] Algo activity_selector step 1550 current loss 1.487367, current_train_items 42768.
I0221 21:45:59.143808 136516138993152 run.py:764] (val) algo activity_selector step 1550: {'selected': 0.8108108108108109, 'score': 0.8108108108108109, 'examples_seen': 42768, 'step': 1550, 'algorithm': 'activity_selector'}
I0221 21:45:59.144032 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.811, val scores are: activity_selector: 0.811
I0221 21:46:00.270760 136516138993152 run.py:729] Algo activity_selector step 1600 current loss 1.286939, current_train_items 44160.
I0221 21:46:00.408313 136516138993152 run.py:764] (val) algo activity_selector step 1600: {'selected': 0.8798449612403102, 'score': 0.8798449612403102, 'examples_seen': 44160, 'step': 1600, 'algorithm': 'activity_selector'}
I0221 21:46:00.408563 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0221 21:46:01.540860 136516138993152 run.py:729] Algo activity_selector step 1650 current loss 1.115273, current_train_items 45536.
I0221 21:46:01.687535 136516138993152 run.py:764] (val) algo activity_selector step 1650: {'selected': 0.8607068607068609, 'score': 0.8607068607068609, 'examples_seen': 45536, 'step': 1650, 'algorithm': 'activity_selector'}
I0221 21:46:01.687704 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.861, val scores are: activity_selector: 0.861
I0221 21:46:02.775108 136516138993152 run.py:729] Algo activity_selector step 1700 current loss 1.253882, current_train_items 46896.
I0221 21:46:02.913241 136516138993152 run.py:764] (val) algo activity_selector step 1700: {'selected': 0.8674242424242423, 'score': 0.8674242424242423, 'examples_seen': 46896, 'step': 1700, 'algorithm': 'activity_selector'}
I0221 21:46:02.913476 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0221 21:46:03.993751 136516138993152 run.py:729] Algo activity_selector step 1750 current loss 1.431872, current_train_items 48304.
I0221 21:46:04.135027 136516138993152 run.py:764] (val) algo activity_selector step 1750: {'selected': 0.9215686274509803, 'score': 0.9215686274509803, 'examples_seen': 48304, 'step': 1750, 'algorithm': 'activity_selector'}
I0221 21:46:04.135279 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0221 21:46:05.281225 136516138993152 run.py:729] Algo activity_selector step 1800 current loss 1.023105, current_train_items 49664.
I0221 21:46:05.433620 136516138993152 run.py:764] (val) algo activity_selector step 1800: {'selected': 0.9087523277467411, 'score': 0.9087523277467411, 'examples_seen': 49664, 'step': 1800, 'algorithm': 'activity_selector'}
I0221 21:46:05.433882 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0221 21:46:06.518184 136516138993152 run.py:729] Algo activity_selector step 1850 current loss 0.897927, current_train_items 51056.
I0221 21:46:06.671605 136516138993152 run.py:764] (val) algo activity_selector step 1850: {'selected': 0.8799999999999999, 'score': 0.8799999999999999, 'examples_seen': 51056, 'step': 1850, 'algorithm': 'activity_selector'}
I0221 21:46:06.671836 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0221 21:46:07.754109 136516138993152 run.py:729] Algo activity_selector step 1900 current loss 1.198215, current_train_items 52432.
I0221 21:46:07.899499 136516138993152 run.py:764] (val) algo activity_selector step 1900: {'selected': 0.8892857142857143, 'score': 0.8892857142857143, 'examples_seen': 52432, 'step': 1900, 'algorithm': 'activity_selector'}
I0221 21:46:07.899724 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.889, val scores are: activity_selector: 0.889
I0221 21:46:08.989849 136516138993152 run.py:729] Algo activity_selector step 1950 current loss 1.200525, current_train_items 53808.
I0221 21:46:09.134773 136516138993152 run.py:764] (val) algo activity_selector step 1950: {'selected': 0.9154411764705882, 'score': 0.9154411764705882, 'examples_seen': 53808, 'step': 1950, 'algorithm': 'activity_selector'}
I0221 21:46:09.134998 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0221 21:46:10.230911 136516138993152 run.py:729] Algo activity_selector step 2000 current loss 1.138742, current_train_items 55184.
I0221 21:46:10.370995 136516138993152 run.py:764] (val) algo activity_selector step 2000: {'selected': 0.9151873767258383, 'score': 0.9151873767258383, 'examples_seen': 55184, 'step': 2000, 'algorithm': 'activity_selector'}
I0221 21:46:10.371249 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0221 21:46:11.443697 136516138993152 run.py:729] Algo activity_selector step 2050 current loss 1.029683, current_train_items 56560.
I0221 21:46:11.582951 136516138993152 run.py:764] (val) algo activity_selector step 2050: {'selected': 0.8666666666666667, 'score': 0.8666666666666667, 'examples_seen': 56560, 'step': 2050, 'algorithm': 'activity_selector'}
I0221 21:46:11.583197 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0221 21:46:12.704655 136516138993152 run.py:729] Algo activity_selector step 2100 current loss 1.382326, current_train_items 57952.
I0221 21:46:12.860269 136516138993152 run.py:764] (val) algo activity_selector step 2100: {'selected': 0.8835341365461847, 'score': 0.8835341365461847, 'examples_seen': 57952, 'step': 2100, 'algorithm': 'activity_selector'}
I0221 21:46:12.860506 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0221 21:46:13.984740 136516138993152 run.py:729] Algo activity_selector step 2150 current loss 1.176647, current_train_items 59312.
I0221 21:46:14.138181 136516138993152 run.py:764] (val) algo activity_selector step 2150: {'selected': 0.8432835820895522, 'score': 0.8432835820895522, 'examples_seen': 59312, 'step': 2150, 'algorithm': 'activity_selector'}
I0221 21:46:14.138416 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.843, val scores are: activity_selector: 0.843
I0221 21:46:15.267834 136516138993152 run.py:729] Algo activity_selector step 2200 current loss 1.142510, current_train_items 60720.
I0221 21:46:15.419446 136516138993152 run.py:764] (val) algo activity_selector step 2200: {'selected': 0.8955223880597015, 'score': 0.8955223880597015, 'examples_seen': 60720, 'step': 2200, 'algorithm': 'activity_selector'}
I0221 21:46:15.419701 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0221 21:46:16.554708 136516138993152 run.py:729] Algo activity_selector step 2250 current loss 0.980020, current_train_items 62080.
I0221 21:46:16.705480 136516138993152 run.py:764] (val) algo activity_selector step 2250: {'selected': 0.9208103130755063, 'score': 0.9208103130755063, 'examples_seen': 62080, 'step': 2250, 'algorithm': 'activity_selector'}
I0221 21:46:16.705730 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0221 21:46:17.819656 136516138993152 run.py:729] Algo activity_selector step 2300 current loss 1.228564, current_train_items 63440.
I0221 21:46:17.972412 136516138993152 run.py:764] (val) algo activity_selector step 2300: {'selected': 0.8791593695271455, 'score': 0.8791593695271455, 'examples_seen': 63440, 'step': 2300, 'algorithm': 'activity_selector'}
I0221 21:46:17.972641 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0221 21:46:19.102891 136516138993152 run.py:729] Algo activity_selector step 2350 current loss 0.945177, current_train_items 64848.
I0221 21:46:19.253201 136516138993152 run.py:764] (val) algo activity_selector step 2350: {'selected': 0.9438202247191011, 'score': 0.9438202247191011, 'examples_seen': 64848, 'step': 2350, 'algorithm': 'activity_selector'}
I0221 21:46:19.253430 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0221 21:46:20.374099 136516138993152 run.py:729] Algo activity_selector step 2400 current loss 0.915343, current_train_items 66208.
I0221 21:46:20.526709 136516138993152 run.py:764] (val) algo activity_selector step 2400: {'selected': 0.9351145038167938, 'score': 0.9351145038167938, 'examples_seen': 66208, 'step': 2400, 'algorithm': 'activity_selector'}
I0221 21:46:20.526935 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0221 21:46:21.710180 136516138993152 run.py:729] Algo activity_selector step 2450 current loss 1.225201, current_train_items 67600.
I0221 21:46:21.813779 136516138993152 run.py:764] (val) algo activity_selector step 2450: {'selected': 0.9302325581395349, 'score': 0.9302325581395349, 'examples_seen': 67600, 'step': 2450, 'algorithm': 'activity_selector'}
I0221 21:46:21.814016 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0221 21:46:23.026738 136516138993152 run.py:729] Algo activity_selector step 2500 current loss 0.918668, current_train_items 68976.
I0221 21:46:23.143368 136516138993152 run.py:764] (val) algo activity_selector step 2500: {'selected': 0.9090909090909092, 'score': 0.9090909090909092, 'examples_seen': 68976, 'step': 2500, 'algorithm': 'activity_selector'}
I0221 21:46:23.143610 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.952, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0221 21:46:24.442829 136516138993152 run.py:729] Algo activity_selector step 2550 current loss 0.944487, current_train_items 70352.
I0221 21:46:24.530339 136516138993152 run.py:764] (val) algo activity_selector step 2550: {'selected': 0.9613899613899614, 'score': 0.9613899613899614, 'examples_seen': 70352, 'step': 2550, 'algorithm': 'activity_selector'}
I0221 21:46:24.530637 136516138993152 run.py:785] Checkpointing best model, best avg val score was 0.952, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0221 21:46:26.154383 136516138993152 run.py:729] Algo activity_selector step 2600 current loss 0.906330, current_train_items 71728.
I0221 21:46:26.249825 136516138993152 run.py:764] (val) algo activity_selector step 2600: {'selected': 0.9118198874296436, 'score': 0.9118198874296436, 'examples_seen': 71728, 'step': 2600, 'algorithm': 'activity_selector'}
I0221 21:46:26.250008 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0221 21:46:27.414886 136516138993152 run.py:729] Algo activity_selector step 2650 current loss 0.885314, current_train_items 73104.
I0221 21:46:27.558955 136516138993152 run.py:764] (val) algo activity_selector step 2650: {'selected': 0.9083503054989817, 'score': 0.9083503054989817, 'examples_seen': 73104, 'step': 2650, 'algorithm': 'activity_selector'}
I0221 21:46:27.559180 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.961, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0221 21:46:28.695841 136516138993152 run.py:729] Algo activity_selector step 2700 current loss 0.887231, current_train_items 74496.
I0221 21:46:28.860858 136516138993152 run.py:764] (val) algo activity_selector step 2700: {'selected': 0.9642184557438794, 'score': 0.9642184557438794, 'examples_seen': 74496, 'step': 2700, 'algorithm': 'activity_selector'}
I0221 21:46:28.861108 136516138993152 run.py:785] Checkpointing best model, best avg val score was 0.961, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0221 21:46:30.124727 136516138993152 run.py:729] Algo activity_selector step 2750 current loss 0.783772, current_train_items 75856.
I0221 21:46:30.275528 136516138993152 run.py:764] (val) algo activity_selector step 2750: {'selected': 0.9265536723163842, 'score': 0.9265536723163842, 'examples_seen': 75856, 'step': 2750, 'algorithm': 'activity_selector'}
I0221 21:46:30.275764 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.964, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0221 21:46:31.385583 136516138993152 run.py:729] Algo activity_selector step 2800 current loss 0.992485, current_train_items 77264.
I0221 21:46:31.536536 136516138993152 run.py:764] (val) algo activity_selector step 2800: {'selected': 0.8592321755027423, 'score': 0.8592321755027423, 'examples_seen': 77264, 'step': 2800, 'algorithm': 'activity_selector'}
I0221 21:46:31.536851 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.964, current avg val score is 0.859, val scores are: activity_selector: 0.859
I0221 21:46:32.663287 136516138993152 run.py:729] Algo activity_selector step 2850 current loss 1.073008, current_train_items 78624.
I0221 21:46:32.813807 136516138993152 run.py:764] (val) algo activity_selector step 2850: {'selected': 0.962671905697446, 'score': 0.962671905697446, 'examples_seen': 78624, 'step': 2850, 'algorithm': 'activity_selector'}
I0221 21:46:32.814082 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.964, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0221 21:46:33.912111 136516138993152 run.py:729] Algo activity_selector step 2900 current loss 1.052512, current_train_items 80000.
I0221 21:46:34.078377 136516138993152 run.py:764] (val) algo activity_selector step 2900: {'selected': 0.9037328094302554, 'score': 0.9037328094302554, 'examples_seen': 80000, 'step': 2900, 'algorithm': 'activity_selector'}
I0221 21:46:34.078626 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.964, current avg val score is 0.904, val scores are: activity_selector: 0.904
I0221 21:46:35.206919 136516138993152 run.py:729] Algo activity_selector step 2950 current loss 0.761559, current_train_items 81392.
I0221 21:46:35.341597 136516138993152 run.py:764] (val) algo activity_selector step 2950: {'selected': 0.9032258064516129, 'score': 0.9032258064516129, 'examples_seen': 81392, 'step': 2950, 'algorithm': 'activity_selector'}
I0221 21:46:35.341822 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.964, current avg val score is 0.903, val scores are: activity_selector: 0.903
I0221 21:46:36.470214 136516138993152 run.py:729] Algo activity_selector step 3000 current loss 1.221453, current_train_items 82752.
I0221 21:46:36.622709 136516138993152 run.py:764] (val) algo activity_selector step 3000: {'selected': 0.9528985507246377, 'score': 0.9528985507246377, 'examples_seen': 82752, 'step': 3000, 'algorithm': 'activity_selector'}
I0221 21:46:36.622953 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.964, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0221 21:46:37.724307 136516138993152 run.py:729] Algo activity_selector step 3050 current loss 0.754756, current_train_items 84144.
I0221 21:46:37.887242 136516138993152 run.py:764] (val) algo activity_selector step 3050: {'selected': 0.9705882352941178, 'score': 0.9705882352941178, 'examples_seen': 84144, 'step': 3050, 'algorithm': 'activity_selector'}
I0221 21:46:37.887502 136516138993152 run.py:785] Checkpointing best model, best avg val score was 0.964, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0221 21:46:39.168258 136516138993152 run.py:729] Algo activity_selector step 3100 current loss 0.877008, current_train_items 85520.
I0221 21:46:39.316544 136516138993152 run.py:764] (val) algo activity_selector step 3100: {'selected': 0.9346534653465347, 'score': 0.9346534653465347, 'examples_seen': 85520, 'step': 3100, 'algorithm': 'activity_selector'}
I0221 21:46:39.316792 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0221 21:46:40.439637 136516138993152 run.py:729] Algo activity_selector step 3150 current loss 0.660607, current_train_items 86896.
I0221 21:46:40.591618 136516138993152 run.py:764] (val) algo activity_selector step 3150: {'selected': 0.8722986247544205, 'score': 0.8722986247544205, 'examples_seen': 86896, 'step': 3150, 'algorithm': 'activity_selector'}
I0221 21:46:40.591871 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.872, val scores are: activity_selector: 0.872
I0221 21:46:41.708317 136516138993152 run.py:729] Algo activity_selector step 3200 current loss 0.906246, current_train_items 88272.
I0221 21:46:41.861980 136516138993152 run.py:764] (val) algo activity_selector step 3200: {'selected': 0.9320388349514563, 'score': 0.9320388349514563, 'examples_seen': 88272, 'step': 3200, 'algorithm': 'activity_selector'}
I0221 21:46:41.862226 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0221 21:46:42.973065 136516138993152 run.py:729] Algo activity_selector step 3250 current loss 1.028426, current_train_items 89664.
I0221 21:46:43.122563 136516138993152 run.py:764] (val) algo activity_selector step 3250: {'selected': 0.9296875, 'score': 0.9296875, 'examples_seen': 89664, 'step': 3250, 'algorithm': 'activity_selector'}
I0221 21:46:43.122792 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0221 21:46:44.245414 136516138993152 run.py:729] Algo activity_selector step 3300 current loss 0.907414, current_train_items 91040.
I0221 21:46:44.396973 136516138993152 run.py:764] (val) algo activity_selector step 3300: {'selected': 0.9451795841209829, 'score': 0.9451795841209829, 'examples_seen': 91040, 'step': 3300, 'algorithm': 'activity_selector'}
I0221 21:46:44.397250 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0221 21:46:45.535380 136516138993152 run.py:729] Algo activity_selector step 3350 current loss 1.049588, current_train_items 92400.
I0221 21:46:45.684635 136516138993152 run.py:764] (val) algo activity_selector step 3350: {'selected': 0.9279112754158964, 'score': 0.9279112754158964, 'examples_seen': 92400, 'step': 3350, 'algorithm': 'activity_selector'}
I0221 21:46:45.684875 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0221 21:46:46.774543 136516138993152 run.py:729] Algo activity_selector step 3400 current loss 1.040613, current_train_items 93792.
I0221 21:46:46.902499 136516138993152 run.py:764] (val) algo activity_selector step 3400: {'selected': 0.9551656920077972, 'score': 0.9551656920077972, 'examples_seen': 93792, 'step': 3400, 'algorithm': 'activity_selector'}
I0221 21:46:46.902728 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0221 21:46:48.019376 136516138993152 run.py:729] Algo activity_selector step 3450 current loss 0.869003, current_train_items 95168.
I0221 21:46:48.170937 136516138993152 run.py:764] (val) algo activity_selector step 3450: {'selected': 0.9366602687140114, 'score': 0.9366602687140114, 'examples_seen': 95168, 'step': 3450, 'algorithm': 'activity_selector'}
I0221 21:46:48.171185 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0221 21:46:49.258939 136516138993152 run.py:729] Algo activity_selector step 3500 current loss 0.914220, current_train_items 96544.
I0221 21:46:49.427700 136516138993152 run.py:764] (val) algo activity_selector step 3500: {'selected': 0.924643584521385, 'score': 0.924643584521385, 'examples_seen': 96544, 'step': 3500, 'algorithm': 'activity_selector'}
I0221 21:46:49.427934 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0221 21:46:50.524448 136516138993152 run.py:729] Algo activity_selector step 3550 current loss 0.805050, current_train_items 97936.
I0221 21:46:50.664768 136516138993152 run.py:764] (val) algo activity_selector step 3550: {'selected': 0.9523809523809523, 'score': 0.9523809523809523, 'examples_seen': 97936, 'step': 3550, 'algorithm': 'activity_selector'}
I0221 21:46:50.664995 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0221 21:46:51.735222 136516138993152 run.py:729] Algo activity_selector step 3600 current loss 1.205710, current_train_items 99312.
I0221 21:46:51.887931 136516138993152 run.py:764] (val) algo activity_selector step 3600: {'selected': 0.9551020408163265, 'score': 0.9551020408163265, 'examples_seen': 99312, 'step': 3600, 'algorithm': 'activity_selector'}
I0221 21:46:51.888172 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0221 21:46:52.951678 136516138993152 run.py:729] Algo activity_selector step 3650 current loss 1.089916, current_train_items 100688.
I0221 21:46:53.105198 136516138993152 run.py:764] (val) algo activity_selector step 3650: {'selected': 0.9487179487179487, 'score': 0.9487179487179487, 'examples_seen': 100688, 'step': 3650, 'algorithm': 'activity_selector'}
I0221 21:46:53.105470 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0221 21:46:54.191524 136516138993152 run.py:729] Algo activity_selector step 3700 current loss 0.714560, current_train_items 102064.
I0221 21:46:54.346791 136516138993152 run.py:764] (val) algo activity_selector step 3700: {'selected': 0.8979591836734694, 'score': 0.8979591836734694, 'examples_seen': 102064, 'step': 3700, 'algorithm': 'activity_selector'}
I0221 21:46:54.347057 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0221 21:46:55.435969 136516138993152 run.py:729] Algo activity_selector step 3750 current loss 1.130477, current_train_items 103440.
I0221 21:46:55.568344 136516138993152 run.py:764] (val) algo activity_selector step 3750: {'selected': 0.8893280632411067, 'score': 0.8893280632411067, 'examples_seen': 103440, 'step': 3750, 'algorithm': 'activity_selector'}
I0221 21:46:55.568566 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.889, val scores are: activity_selector: 0.889
I0221 21:46:56.655788 136516138993152 run.py:729] Algo activity_selector step 3800 current loss 0.879804, current_train_items 104816.
I0221 21:46:56.795843 136516138993152 run.py:764] (val) algo activity_selector step 3800: {'selected': 0.920892494929006, 'score': 0.920892494929006, 'examples_seen': 104816, 'step': 3800, 'algorithm': 'activity_selector'}
I0221 21:46:56.796107 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0221 21:46:57.884702 136516138993152 run.py:729] Algo activity_selector step 3850 current loss 1.144451, current_train_items 106208.
I0221 21:46:58.028083 136516138993152 run.py:764] (val) algo activity_selector step 3850: {'selected': 0.9388560157790927, 'score': 0.9388560157790927, 'examples_seen': 106208, 'step': 3850, 'algorithm': 'activity_selector'}
I0221 21:46:58.028313 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0221 21:46:59.146522 136516138993152 run.py:729] Algo activity_selector step 3900 current loss 1.005380, current_train_items 107584.
I0221 21:46:59.298746 136516138993152 run.py:764] (val) algo activity_selector step 3900: {'selected': 0.8836363636363637, 'score': 0.8836363636363637, 'examples_seen': 107584, 'step': 3900, 'algorithm': 'activity_selector'}
I0221 21:46:59.299018 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0221 21:47:00.422432 136516138993152 run.py:729] Algo activity_selector step 3950 current loss 0.850163, current_train_items 108960.
I0221 21:47:00.564279 136516138993152 run.py:764] (val) algo activity_selector step 3950: {'selected': 0.969811320754717, 'score': 0.969811320754717, 'examples_seen': 108960, 'step': 3950, 'algorithm': 'activity_selector'}
I0221 21:47:00.564504 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0221 21:47:01.690603 136516138993152 run.py:729] Algo activity_selector step 4000 current loss 0.929643, current_train_items 110336.
I0221 21:47:01.842959 136516138993152 run.py:764] (val) algo activity_selector step 4000: {'selected': 0.8733459357277883, 'score': 0.8733459357277883, 'examples_seen': 110336, 'step': 4000, 'algorithm': 'activity_selector'}
I0221 21:47:01.843207 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.873, val scores are: activity_selector: 0.873
I0221 21:47:02.951469 136516138993152 run.py:729] Algo activity_selector step 4050 current loss 0.718056, current_train_items 111712.
I0221 21:47:03.093125 136516138993152 run.py:764] (val) algo activity_selector step 4050: {'selected': 0.9266409266409267, 'score': 0.9266409266409267, 'examples_seen': 111712, 'step': 4050, 'algorithm': 'activity_selector'}
I0221 21:47:03.093356 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0221 21:47:04.156503 136516138993152 run.py:729] Algo activity_selector step 4100 current loss 0.799884, current_train_items 113088.
I0221 21:47:04.312109 136516138993152 run.py:764] (val) algo activity_selector step 4100: {'selected': 0.9094412331406552, 'score': 0.9094412331406552, 'examples_seen': 113088, 'step': 4100, 'algorithm': 'activity_selector'}
I0221 21:47:04.312359 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0221 21:47:05.406494 136516138993152 run.py:729] Algo activity_selector step 4150 current loss 0.919209, current_train_items 114480.
I0221 21:47:05.572115 136516138993152 run.py:764] (val) algo activity_selector step 4150: {'selected': 0.946360153256705, 'score': 0.946360153256705, 'examples_seen': 114480, 'step': 4150, 'algorithm': 'activity_selector'}
I0221 21:47:05.572436 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0221 21:47:06.657397 136516138993152 run.py:729] Algo activity_selector step 4200 current loss 0.991568, current_train_items 115856.
I0221 21:47:06.800159 136516138993152 run.py:764] (val) algo activity_selector step 4200: {'selected': 0.9498997995991983, 'score': 0.9498997995991983, 'examples_seen': 115856, 'step': 4200, 'algorithm': 'activity_selector'}
I0221 21:47:06.800409 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0221 21:47:07.868205 136516138993152 run.py:729] Algo activity_selector step 4250 current loss 1.119007, current_train_items 117216.
I0221 21:47:08.007455 136516138993152 run.py:764] (val) algo activity_selector step 4250: {'selected': 0.9475655430711611, 'score': 0.9475655430711611, 'examples_seen': 117216, 'step': 4250, 'algorithm': 'activity_selector'}
I0221 21:47:08.007677 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0221 21:47:09.120090 136516138993152 run.py:729] Algo activity_selector step 4300 current loss 0.698499, current_train_items 118624.
I0221 21:47:09.259908 136516138993152 run.py:764] (val) algo activity_selector step 4300: {'selected': 0.9523809523809523, 'score': 0.9523809523809523, 'examples_seen': 118624, 'step': 4300, 'algorithm': 'activity_selector'}
I0221 21:47:09.260155 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0221 21:47:10.325596 136516138993152 run.py:729] Algo activity_selector step 4350 current loss 0.616301, current_train_items 119984.
I0221 21:47:10.480069 136516138993152 run.py:764] (val) algo activity_selector step 4350: {'selected': 0.9477911646586347, 'score': 0.9477911646586347, 'examples_seen': 119984, 'step': 4350, 'algorithm': 'activity_selector'}
I0221 21:47:10.480299 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0221 21:47:11.568353 136516138993152 run.py:729] Algo activity_selector step 4400 current loss 0.605530, current_train_items 121360.
I0221 21:47:11.706129 136516138993152 run.py:764] (val) algo activity_selector step 4400: {'selected': 0.9292543021032506, 'score': 0.9292543021032506, 'examples_seen': 121360, 'step': 4400, 'algorithm': 'activity_selector'}
I0221 21:47:11.706332 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0221 21:47:12.768947 136516138993152 run.py:729] Algo activity_selector step 4450 current loss 0.987069, current_train_items 122752.
I0221 21:47:12.906520 136516138993152 run.py:764] (val) algo activity_selector step 4450: {'selected': 0.937625754527163, 'score': 0.937625754527163, 'examples_seen': 122752, 'step': 4450, 'algorithm': 'activity_selector'}
I0221 21:47:12.906743 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.971, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0221 21:47:13.972031 136516138993152 run.py:729] Algo activity_selector step 4500 current loss 0.770685, current_train_items 124128.
I0221 21:47:14.109659 136516138993152 run.py:764] (val) algo activity_selector step 4500: {'selected': 0.9724409448818897, 'score': 0.9724409448818897, 'examples_seen': 124128, 'step': 4500, 'algorithm': 'activity_selector'}
I0221 21:47:14.109843 136516138993152 run.py:785] Checkpointing best model, best avg val score was 0.971, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0221 21:47:15.333270 136516138993152 run.py:729] Algo activity_selector step 4550 current loss 0.729115, current_train_items 125504.
I0221 21:47:15.476004 136516138993152 run.py:764] (val) algo activity_selector step 4550: {'selected': 0.9243027888446215, 'score': 0.9243027888446215, 'examples_seen': 125504, 'step': 4550, 'algorithm': 'activity_selector'}
I0221 21:47:15.476244 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0221 21:47:16.548654 136516138993152 run.py:729] Algo activity_selector step 4600 current loss 1.025959, current_train_items 126880.
I0221 21:47:16.688902 136516138993152 run.py:764] (val) algo activity_selector step 4600: {'selected': 0.9380863039399624, 'score': 0.9380863039399624, 'examples_seen': 126880, 'step': 4600, 'algorithm': 'activity_selector'}
I0221 21:47:16.689146 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0221 21:47:17.751137 136516138993152 run.py:729] Algo activity_selector step 4650 current loss 0.760968, current_train_items 128272.
I0221 21:47:17.905702 136516138993152 run.py:764] (val) algo activity_selector step 4650: {'selected': 0.9273743016759777, 'score': 0.9273743016759777, 'examples_seen': 128272, 'step': 4650, 'algorithm': 'activity_selector'}
I0221 21:47:17.905930 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0221 21:47:18.974823 136516138993152 run.py:729] Algo activity_selector step 4700 current loss 1.020764, current_train_items 129632.
I0221 21:47:19.127575 136516138993152 run.py:764] (val) algo activity_selector step 4700: {'selected': 0.9366602687140115, 'score': 0.9366602687140115, 'examples_seen': 129632, 'step': 4700, 'algorithm': 'activity_selector'}
I0221 21:47:19.127808 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0221 21:47:20.199937 136516138993152 run.py:729] Algo activity_selector step 4750 current loss 0.975108, current_train_items 131024.
I0221 21:47:20.342310 136516138993152 run.py:764] (val) algo activity_selector step 4750: {'selected': 0.9090909090909091, 'score': 0.9090909090909091, 'examples_seen': 131024, 'step': 4750, 'algorithm': 'activity_selector'}
I0221 21:47:20.342541 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0221 21:47:21.423588 136516138993152 run.py:729] Algo activity_selector step 4800 current loss 0.769739, current_train_items 132400.
I0221 21:47:21.574970 136516138993152 run.py:764] (val) algo activity_selector step 4800: {'selected': 0.9473684210526315, 'score': 0.9473684210526315, 'examples_seen': 132400, 'step': 4800, 'algorithm': 'activity_selector'}
I0221 21:47:21.575215 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0221 21:47:22.639835 136516138993152 run.py:729] Algo activity_selector step 4850 current loss 0.644889, current_train_items 133760.
I0221 21:47:22.778669 136516138993152 run.py:764] (val) algo activity_selector step 4850: {'selected': 0.9547920433996384, 'score': 0.9547920433996384, 'examples_seen': 133760, 'step': 4850, 'algorithm': 'activity_selector'}
I0221 21:47:22.778900 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0221 21:47:23.843492 136516138993152 run.py:729] Algo activity_selector step 4900 current loss 0.828245, current_train_items 135168.
I0221 21:47:23.983929 136516138993152 run.py:764] (val) algo activity_selector step 4900: {'selected': 0.9484902309058615, 'score': 0.9484902309058615, 'examples_seen': 135168, 'step': 4900, 'algorithm': 'activity_selector'}
I0221 21:47:23.984184 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0221 21:47:25.058191 136516138993152 run.py:729] Algo activity_selector step 4950 current loss 0.650089, current_train_items 136528.
I0221 21:47:25.198209 136516138993152 run.py:764] (val) algo activity_selector step 4950: {'selected': 0.9142857142857143, 'score': 0.9142857142857143, 'examples_seen': 136528, 'step': 4950, 'algorithm': 'activity_selector'}
I0221 21:47:25.198448 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0221 21:47:26.260902 136516138993152 run.py:729] Algo activity_selector step 5000 current loss 0.500119, current_train_items 137920.
I0221 21:47:26.402908 136516138993152 run.py:764] (val) algo activity_selector step 5000: {'selected': 0.9655172413793104, 'score': 0.9655172413793104, 'examples_seen': 137920, 'step': 5000, 'algorithm': 'activity_selector'}
I0221 21:47:26.403171 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0221 21:47:27.461145 136516138993152 run.py:729] Algo activity_selector step 5050 current loss 0.892761, current_train_items 139296.
I0221 21:47:27.616231 136516138993152 run.py:764] (val) algo activity_selector step 5050: {'selected': 0.9411764705882354, 'score': 0.9411764705882354, 'examples_seen': 139296, 'step': 5050, 'algorithm': 'activity_selector'}
I0221 21:47:27.616477 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0221 21:47:28.702176 136516138993152 run.py:729] Algo activity_selector step 5100 current loss 0.896917, current_train_items 140656.
I0221 21:47:28.847646 136516138993152 run.py:764] (val) algo activity_selector step 5100: {'selected': 0.9442379182156134, 'score': 0.9442379182156134, 'examples_seen': 140656, 'step': 5100, 'algorithm': 'activity_selector'}
I0221 21:47:28.847920 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0221 21:47:29.921153 136516138993152 run.py:729] Algo activity_selector step 5150 current loss 1.245466, current_train_items 142048.
I0221 21:47:30.076322 136516138993152 run.py:764] (val) algo activity_selector step 5150: {'selected': 0.9518072289156626, 'score': 0.9518072289156626, 'examples_seen': 142048, 'step': 5150, 'algorithm': 'activity_selector'}
I0221 21:47:30.076555 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.972, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0221 21:47:31.149660 136516138993152 run.py:729] Algo activity_selector step 5200 current loss 0.634842, current_train_items 143424.
I0221 21:47:31.288470 136516138993152 run.py:764] (val) algo activity_selector step 5200: {'selected': 0.9751434034416826, 'score': 0.9751434034416826, 'examples_seen': 143424, 'step': 5200, 'algorithm': 'activity_selector'}
I0221 21:47:31.288687 136516138993152 run.py:785] Checkpointing best model, best avg val score was 0.972, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0221 21:47:32.510862 136516138993152 run.py:729] Algo activity_selector step 5250 current loss 0.671222, current_train_items 144816.
I0221 21:47:32.647772 136516138993152 run.py:764] (val) algo activity_selector step 5250: {'selected': 0.9090909090909092, 'score': 0.9090909090909092, 'examples_seen': 144816, 'step': 5250, 'algorithm': 'activity_selector'}
I0221 21:47:32.648000 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.975, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0221 21:47:33.709508 136516138993152 run.py:729] Algo activity_selector step 5300 current loss 0.887609, current_train_items 146176.
I0221 21:47:33.851381 136516138993152 run.py:764] (val) algo activity_selector step 5300: {'selected': 0.9188191881918819, 'score': 0.9188191881918819, 'examples_seen': 146176, 'step': 5300, 'algorithm': 'activity_selector'}
I0221 21:47:33.851635 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.975, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0221 21:47:34.916086 136516138993152 run.py:729] Algo activity_selector step 5350 current loss 0.675812, current_train_items 147584.
I0221 21:47:35.065028 136516138993152 run.py:764] (val) algo activity_selector step 5350: {'selected': 0.955719557195572, 'score': 0.955719557195572, 'examples_seen': 147584, 'step': 5350, 'algorithm': 'activity_selector'}
I0221 21:47:35.065268 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.975, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0221 21:47:36.145069 136516138993152 run.py:729] Algo activity_selector step 5400 current loss 0.779439, current_train_items 148944.
I0221 21:47:36.287760 136516138993152 run.py:764] (val) algo activity_selector step 5400: {'selected': 0.9542743538767396, 'score': 0.9542743538767396, 'examples_seen': 148944, 'step': 5400, 'algorithm': 'activity_selector'}
I0221 21:47:36.287985 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.975, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0221 21:47:37.367112 136516138993152 run.py:729] Algo activity_selector step 5450 current loss 0.751749, current_train_items 150304.
I0221 21:47:37.506104 136516138993152 run.py:764] (val) algo activity_selector step 5450: {'selected': 0.9323308270676691, 'score': 0.9323308270676691, 'examples_seen': 150304, 'step': 5450, 'algorithm': 'activity_selector'}
I0221 21:47:37.506331 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.975, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0221 21:47:38.557065 136516138993152 run.py:729] Algo activity_selector step 5500 current loss 0.677749, current_train_items 151712.
I0221 21:47:38.720780 136516138993152 run.py:764] (val) algo activity_selector step 5500: {'selected': 0.9196787148594379, 'score': 0.9196787148594379, 'examples_seen': 151712, 'step': 5500, 'algorithm': 'activity_selector'}
I0221 21:47:38.721033 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.975, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0221 21:47:39.798907 136516138993152 run.py:729] Algo activity_selector step 5550 current loss 0.676157, current_train_items 153072.
I0221 21:47:39.947913 136516138993152 run.py:764] (val) algo activity_selector step 5550: {'selected': 0.9890109890109892, 'score': 0.9890109890109892, 'examples_seen': 153072, 'step': 5550, 'algorithm': 'activity_selector'}
I0221 21:47:39.948188 136516138993152 run.py:785] Checkpointing best model, best avg val score was 0.975, current avg val score is 0.989, val scores are: activity_selector: 0.989
I0221 21:47:41.198322 136516138993152 run.py:729] Algo activity_selector step 5600 current loss 0.632932, current_train_items 154464.
I0221 21:47:41.342575 136516138993152 run.py:764] (val) algo activity_selector step 5600: {'selected': 0.9170305676855895, 'score': 0.9170305676855895, 'examples_seen': 154464, 'step': 5600, 'algorithm': 'activity_selector'}
I0221 21:47:41.342823 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0221 21:47:42.410510 136516138993152 run.py:729] Algo activity_selector step 5650 current loss 0.737647, current_train_items 155840.
I0221 21:47:42.567441 136516138993152 run.py:764] (val) algo activity_selector step 5650: {'selected': 0.9440298507462687, 'score': 0.9440298507462687, 'examples_seen': 155840, 'step': 5650, 'algorithm': 'activity_selector'}
I0221 21:47:42.567682 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0221 21:47:43.676734 136516138993152 run.py:729] Algo activity_selector step 5700 current loss 0.753526, current_train_items 157216.
I0221 21:47:43.831653 136516138993152 run.py:764] (val) algo activity_selector step 5700: {'selected': 0.9284164859002169, 'score': 0.9284164859002169, 'examples_seen': 157216, 'step': 5700, 'algorithm': 'activity_selector'}
I0221 21:47:43.831881 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0221 21:47:44.903812 136516138993152 run.py:729] Algo activity_selector step 5750 current loss 0.863729, current_train_items 158592.
I0221 21:47:45.044557 136516138993152 run.py:764] (val) algo activity_selector step 5750: {'selected': 0.9374999999999999, 'score': 0.9374999999999999, 'examples_seen': 158592, 'step': 5750, 'algorithm': 'activity_selector'}
I0221 21:47:45.044793 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0221 21:47:46.142197 136516138993152 run.py:729] Algo activity_selector step 5800 current loss 0.645693, current_train_items 159968.
I0221 21:47:46.289973 136516138993152 run.py:764] (val) algo activity_selector step 5800: {'selected': 0.9308411214953272, 'score': 0.9308411214953272, 'examples_seen': 159968, 'step': 5800, 'algorithm': 'activity_selector'}
I0221 21:47:46.290261 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0221 21:47:47.447214 136516138993152 run.py:729] Algo activity_selector step 5850 current loss 0.912326, current_train_items 161360.
I0221 21:47:47.594814 136516138993152 run.py:764] (val) algo activity_selector step 5850: {'selected': 0.9458917835671343, 'score': 0.9458917835671343, 'examples_seen': 161360, 'step': 5850, 'algorithm': 'activity_selector'}
I0221 21:47:47.595061 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0221 21:47:48.709991 136516138993152 run.py:729] Algo activity_selector step 5900 current loss 0.567160, current_train_items 162720.
I0221 21:47:48.863413 136516138993152 run.py:764] (val) algo activity_selector step 5900: {'selected': 0.9316081330868762, 'score': 0.9316081330868762, 'examples_seen': 162720, 'step': 5900, 'algorithm': 'activity_selector'}
I0221 21:47:48.863646 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0221 21:47:49.973906 136516138993152 run.py:729] Algo activity_selector step 5950 current loss 0.688642, current_train_items 164112.
I0221 21:47:50.121960 136516138993152 run.py:764] (val) algo activity_selector step 5950: {'selected': 0.9347826086956521, 'score': 0.9347826086956521, 'examples_seen': 164112, 'step': 5950, 'algorithm': 'activity_selector'}
I0221 21:47:50.122208 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0221 21:47:51.199244 136516138993152 run.py:729] Algo activity_selector step 6000 current loss 0.792854, current_train_items 165488.
I0221 21:47:51.340452 136516138993152 run.py:764] (val) algo activity_selector step 6000: {'selected': 0.9568345323741007, 'score': 0.9568345323741007, 'examples_seen': 165488, 'step': 6000, 'algorithm': 'activity_selector'}
I0221 21:47:51.340686 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0221 21:47:52.432888 136516138993152 run.py:729] Algo activity_selector step 6050 current loss 0.629353, current_train_items 166864.
I0221 21:47:52.582186 136516138993152 run.py:764] (val) algo activity_selector step 6050: {'selected': 0.9625, 'score': 0.9625, 'examples_seen': 166864, 'step': 6050, 'algorithm': 'activity_selector'}
I0221 21:47:52.582428 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0221 21:47:53.657185 136516138993152 run.py:729] Algo activity_selector step 6100 current loss 0.491300, current_train_items 168256.
I0221 21:47:53.799993 136516138993152 run.py:764] (val) algo activity_selector step 6100: {'selected': 0.9598393574297189, 'score': 0.9598393574297189, 'examples_seen': 168256, 'step': 6100, 'algorithm': 'activity_selector'}
I0221 21:47:53.800248 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0221 21:47:54.906780 136516138993152 run.py:729] Algo activity_selector step 6150 current loss 0.857273, current_train_items 169616.
I0221 21:47:55.047842 136516138993152 run.py:764] (val) algo activity_selector step 6150: {'selected': 0.9453781512605043, 'score': 0.9453781512605043, 'examples_seen': 169616, 'step': 6150, 'algorithm': 'activity_selector'}
I0221 21:47:55.048098 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0221 21:47:56.124886 136516138993152 run.py:729] Algo activity_selector step 6200 current loss 0.756794, current_train_items 171008.
I0221 21:47:56.291612 136516138993152 run.py:764] (val) algo activity_selector step 6200: {'selected': 0.919917864476386, 'score': 0.919917864476386, 'examples_seen': 171008, 'step': 6200, 'algorithm': 'activity_selector'}
I0221 21:47:56.291839 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0221 21:47:57.440432 136516138993152 run.py:729] Algo activity_selector step 6250 current loss 0.748110, current_train_items 172384.
I0221 21:47:57.591310 136516138993152 run.py:764] (val) algo activity_selector step 6250: {'selected': 0.9590643274853802, 'score': 0.9590643274853802, 'examples_seen': 172384, 'step': 6250, 'algorithm': 'activity_selector'}
I0221 21:47:57.591541 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0221 21:47:58.689075 136516138993152 run.py:729] Algo activity_selector step 6300 current loss 0.634391, current_train_items 173760.
I0221 21:47:58.829884 136516138993152 run.py:764] (val) algo activity_selector step 6300: {'selected': 0.951830443159923, 'score': 0.951830443159923, 'examples_seen': 173760, 'step': 6300, 'algorithm': 'activity_selector'}
I0221 21:47:58.830137 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0221 21:47:59.897599 136516138993152 run.py:729] Algo activity_selector step 6350 current loss 0.593294, current_train_items 175136.
I0221 21:48:00.057527 136516138993152 run.py:764] (val) algo activity_selector step 6350: {'selected': 0.9421157684630739, 'score': 0.9421157684630739, 'examples_seen': 175136, 'step': 6350, 'algorithm': 'activity_selector'}
I0221 21:48:00.057804 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0221 21:48:01.132378 136516138993152 run.py:729] Algo activity_selector step 6400 current loss 0.711060, current_train_items 176528.
I0221 21:48:01.299436 136516138993152 run.py:764] (val) algo activity_selector step 6400: {'selected': 0.9421487603305784, 'score': 0.9421487603305784, 'examples_seen': 176528, 'step': 6400, 'algorithm': 'activity_selector'}
I0221 21:48:01.299685 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0221 21:48:02.455453 136516138993152 run.py:729] Algo activity_selector step 6450 current loss 0.551244, current_train_items 177904.
I0221 21:48:02.609712 136516138993152 run.py:764] (val) algo activity_selector step 6450: {'selected': 0.8923076923076922, 'score': 0.8923076923076922, 'examples_seen': 177904, 'step': 6450, 'algorithm': 'activity_selector'}
I0221 21:48:02.609956 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.892, val scores are: activity_selector: 0.892
I0221 21:48:03.739842 136516138993152 run.py:729] Algo activity_selector step 6500 current loss 0.504382, current_train_items 179264.
I0221 21:48:03.879259 136516138993152 run.py:764] (val) algo activity_selector step 6500: {'selected': 0.9544626593806922, 'score': 0.9544626593806922, 'examples_seen': 179264, 'step': 6500, 'algorithm': 'activity_selector'}
I0221 21:48:03.879485 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0221 21:48:04.955634 136516138993152 run.py:729] Algo activity_selector step 6550 current loss 0.721071, current_train_items 180656.
I0221 21:48:05.097877 136516138993152 run.py:764] (val) algo activity_selector step 6550: {'selected': 0.9340866290018832, 'score': 0.9340866290018832, 'examples_seen': 180656, 'step': 6550, 'algorithm': 'activity_selector'}
I0221 21:48:05.098130 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0221 21:48:06.223400 136516138993152 run.py:729] Algo activity_selector step 6600 current loss 0.782744, current_train_items 182032.
I0221 21:48:06.388211 136516138993152 run.py:764] (val) algo activity_selector step 6600: {'selected': 0.931297709923664, 'score': 0.931297709923664, 'examples_seen': 182032, 'step': 6600, 'algorithm': 'activity_selector'}
I0221 21:48:06.388440 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0221 21:48:07.503584 136516138993152 run.py:729] Algo activity_selector step 6650 current loss 0.698285, current_train_items 183408.
I0221 21:48:07.651720 136516138993152 run.py:764] (val) algo activity_selector step 6650: {'selected': 0.9508840864440079, 'score': 0.9508840864440079, 'examples_seen': 183408, 'step': 6650, 'algorithm': 'activity_selector'}
I0221 21:48:07.651951 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0221 21:48:08.800055 136516138993152 run.py:729] Algo activity_selector step 6700 current loss 0.580479, current_train_items 184800.
I0221 21:48:08.961744 136516138993152 run.py:764] (val) algo activity_selector step 6700: {'selected': 0.9129593810444875, 'score': 0.9129593810444875, 'examples_seen': 184800, 'step': 6700, 'algorithm': 'activity_selector'}
I0221 21:48:08.961973 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0221 21:48:10.069309 136516138993152 run.py:729] Algo activity_selector step 6750 current loss 0.633019, current_train_items 186176.
I0221 21:48:10.234632 136516138993152 run.py:764] (val) algo activity_selector step 6750: {'selected': 0.9655172413793104, 'score': 0.9655172413793104, 'examples_seen': 186176, 'step': 6750, 'algorithm': 'activity_selector'}
I0221 21:48:10.234864 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0221 21:48:11.341139 136516138993152 run.py:729] Algo activity_selector step 6800 current loss 0.620683, current_train_items 187536.
I0221 21:48:11.502534 136516138993152 run.py:764] (val) algo activity_selector step 6800: {'selected': 0.9391634980988594, 'score': 0.9391634980988594, 'examples_seen': 187536, 'step': 6800, 'algorithm': 'activity_selector'}
I0221 21:48:11.502789 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0221 21:48:12.610694 136516138993152 run.py:729] Algo activity_selector step 6850 current loss 0.813228, current_train_items 188928.
I0221 21:48:12.762566 136516138993152 run.py:764] (val) algo activity_selector step 6850: {'selected': 0.9378531073446328, 'score': 0.9378531073446328, 'examples_seen': 188928, 'step': 6850, 'algorithm': 'activity_selector'}
I0221 21:48:12.762786 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0221 21:48:13.873525 136516138993152 run.py:729] Algo activity_selector step 6900 current loss 0.589559, current_train_items 190304.
I0221 21:48:14.022839 136516138993152 run.py:764] (val) algo activity_selector step 6900: {'selected': 0.9386138613861386, 'score': 0.9386138613861386, 'examples_seen': 190304, 'step': 6900, 'algorithm': 'activity_selector'}
I0221 21:48:14.023098 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0221 21:48:15.130338 136516138993152 run.py:729] Algo activity_selector step 6950 current loss 0.643488, current_train_items 191680.
I0221 21:48:15.280799 136516138993152 run.py:764] (val) algo activity_selector step 6950: {'selected': 0.930327868852459, 'score': 0.930327868852459, 'examples_seen': 191680, 'step': 6950, 'algorithm': 'activity_selector'}
I0221 21:48:15.280982 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0221 21:48:16.373411 136516138993152 run.py:729] Algo activity_selector step 7000 current loss 0.730438, current_train_items 193072.
I0221 21:48:16.523349 136516138993152 run.py:764] (val) algo activity_selector step 7000: {'selected': 0.9614604462474645, 'score': 0.9614604462474645, 'examples_seen': 193072, 'step': 7000, 'algorithm': 'activity_selector'}
I0221 21:48:16.523499 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0221 21:48:17.611055 136516138993152 run.py:729] Algo activity_selector step 7050 current loss 0.439592, current_train_items 194448.
I0221 21:48:17.774583 136516138993152 run.py:764] (val) algo activity_selector step 7050: {'selected': 0.952029520295203, 'score': 0.952029520295203, 'examples_seen': 194448, 'step': 7050, 'algorithm': 'activity_selector'}
I0221 21:48:17.774731 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0221 21:48:18.866885 136516138993152 run.py:729] Algo activity_selector step 7100 current loss 0.653661, current_train_items 195824.
I0221 21:48:19.013070 136516138993152 run.py:764] (val) algo activity_selector step 7100: {'selected': 0.9702602230483272, 'score': 0.9702602230483272, 'examples_seen': 195824, 'step': 7100, 'algorithm': 'activity_selector'}
I0221 21:48:19.013227 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0221 21:48:20.110747 136516138993152 run.py:729] Algo activity_selector step 7150 current loss 0.572070, current_train_items 197200.
I0221 21:48:20.258996 136516138993152 run.py:764] (val) algo activity_selector step 7150: {'selected': 0.9445506692160611, 'score': 0.9445506692160611, 'examples_seen': 197200, 'step': 7150, 'algorithm': 'activity_selector'}
I0221 21:48:20.259161 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0221 21:48:21.358799 136516138993152 run.py:729] Algo activity_selector step 7200 current loss 0.737948, current_train_items 198576.
I0221 21:48:21.505535 136516138993152 run.py:764] (val) algo activity_selector step 7200: {'selected': 0.9477911646586346, 'score': 0.9477911646586346, 'examples_seen': 198576, 'step': 7200, 'algorithm': 'activity_selector'}
I0221 21:48:21.505764 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0221 21:48:22.632218 136516138993152 run.py:729] Algo activity_selector step 7250 current loss 0.677123, current_train_items 199952.
I0221 21:48:22.766884 136516138993152 run.py:764] (val) algo activity_selector step 7250: {'selected': 0.9640000000000001, 'score': 0.9640000000000001, 'examples_seen': 199952, 'step': 7250, 'algorithm': 'activity_selector'}
I0221 21:48:22.767127 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0221 21:48:23.871921 136516138993152 run.py:729] Algo activity_selector step 7300 current loss 0.679061, current_train_items 201344.
I0221 21:48:24.023645 136516138993152 run.py:764] (val) algo activity_selector step 7300: {'selected': 0.9325396825396824, 'score': 0.9325396825396824, 'examples_seen': 201344, 'step': 7300, 'algorithm': 'activity_selector'}
I0221 21:48:24.023868 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0221 21:48:25.142283 136516138993152 run.py:729] Algo activity_selector step 7350 current loss 0.603394, current_train_items 202720.
I0221 21:48:25.294170 136516138993152 run.py:764] (val) algo activity_selector step 7350: {'selected': 0.9440993788819875, 'score': 0.9440993788819875, 'examples_seen': 202720, 'step': 7350, 'algorithm': 'activity_selector'}
I0221 21:48:25.294392 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0221 21:48:26.393439 136516138993152 run.py:729] Algo activity_selector step 7400 current loss 0.612531, current_train_items 204080.
I0221 21:48:26.542476 136516138993152 run.py:764] (val) algo activity_selector step 7400: {'selected': 0.9576923076923076, 'score': 0.9576923076923076, 'examples_seen': 204080, 'step': 7400, 'algorithm': 'activity_selector'}
I0221 21:48:26.542706 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0221 21:48:27.643560 136516138993152 run.py:729] Algo activity_selector step 7450 current loss 0.658363, current_train_items 205488.
I0221 21:48:27.793352 136516138993152 run.py:764] (val) algo activity_selector step 7450: {'selected': 0.9477611940298508, 'score': 0.9477611940298508, 'examples_seen': 205488, 'step': 7450, 'algorithm': 'activity_selector'}
I0221 21:48:27.793579 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0221 21:48:28.906140 136516138993152 run.py:729] Algo activity_selector step 7500 current loss 0.565984, current_train_items 206848.
I0221 21:48:29.055733 136516138993152 run.py:764] (val) algo activity_selector step 7500: {'selected': 0.9734848484848485, 'score': 0.9734848484848485, 'examples_seen': 206848, 'step': 7500, 'algorithm': 'activity_selector'}
I0221 21:48:29.055982 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0221 21:48:30.147581 136516138993152 run.py:729] Algo activity_selector step 7550 current loss 0.659157, current_train_items 208224.
I0221 21:48:30.314090 136516138993152 run.py:764] (val) algo activity_selector step 7550: {'selected': 0.8659793814432989, 'score': 0.8659793814432989, 'examples_seen': 208224, 'step': 7550, 'algorithm': 'activity_selector'}
I0221 21:48:30.314315 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.866, val scores are: activity_selector: 0.866
I0221 21:48:31.413592 136516138993152 run.py:729] Algo activity_selector step 7600 current loss 0.722112, current_train_items 209616.
I0221 21:48:31.562376 136516138993152 run.py:764] (val) algo activity_selector step 7600: {'selected': 0.9812734082397003, 'score': 0.9812734082397003, 'examples_seen': 209616, 'step': 7600, 'algorithm': 'activity_selector'}
I0221 21:48:31.562602 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0221 21:48:32.673648 136516138993152 run.py:729] Algo activity_selector step 7650 current loss 0.723448, current_train_items 210976.
I0221 21:48:32.822144 136516138993152 run.py:764] (val) algo activity_selector step 7650: {'selected': 0.9132075471698113, 'score': 0.9132075471698113, 'examples_seen': 210976, 'step': 7650, 'algorithm': 'activity_selector'}
I0221 21:48:32.822363 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0221 21:48:33.927568 136516138993152 run.py:729] Algo activity_selector step 7700 current loss 0.661429, current_train_items 212368.
I0221 21:48:34.078458 136516138993152 run.py:764] (val) algo activity_selector step 7700: {'selected': 0.9146341463414633, 'score': 0.9146341463414633, 'examples_seen': 212368, 'step': 7700, 'algorithm': 'activity_selector'}
I0221 21:48:34.078683 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0221 21:48:35.167749 136516138993152 run.py:729] Algo activity_selector step 7750 current loss 0.854503, current_train_items 213744.
I0221 21:48:35.329578 136516138993152 run.py:764] (val) algo activity_selector step 7750: {'selected': 0.9455909943714822, 'score': 0.9455909943714822, 'examples_seen': 213744, 'step': 7750, 'algorithm': 'activity_selector'}
I0221 21:48:35.329805 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0221 21:48:36.430954 136516138993152 run.py:729] Algo activity_selector step 7800 current loss 0.754222, current_train_items 215136.
I0221 21:48:36.595659 136516138993152 run.py:764] (val) algo activity_selector step 7800: {'selected': 0.9262295081967212, 'score': 0.9262295081967212, 'examples_seen': 215136, 'step': 7800, 'algorithm': 'activity_selector'}
I0221 21:48:36.595909 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0221 21:48:37.713460 136516138993152 run.py:729] Algo activity_selector step 7850 current loss 0.440579, current_train_items 216496.
I0221 21:48:37.845890 136516138993152 run.py:764] (val) algo activity_selector step 7850: {'selected': 0.924643584521385, 'score': 0.924643584521385, 'examples_seen': 216496, 'step': 7850, 'algorithm': 'activity_selector'}
I0221 21:48:37.846132 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0221 21:48:38.945906 136516138993152 run.py:729] Algo activity_selector step 7900 current loss 0.566713, current_train_items 217888.
I0221 21:48:39.094069 136516138993152 run.py:764] (val) algo activity_selector step 7900: {'selected': 0.9449715370018975, 'score': 0.9449715370018975, 'examples_seen': 217888, 'step': 7900, 'algorithm': 'activity_selector'}
I0221 21:48:39.094295 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0221 21:48:40.189065 136516138993152 run.py:729] Algo activity_selector step 7950 current loss 0.550128, current_train_items 219264.
I0221 21:48:40.352209 136516138993152 run.py:764] (val) algo activity_selector step 7950: {'selected': 0.9275929549902152, 'score': 0.9275929549902152, 'examples_seen': 219264, 'step': 7950, 'algorithm': 'activity_selector'}
I0221 21:48:40.352439 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0221 21:48:41.456210 136516138993152 run.py:729] Algo activity_selector step 8000 current loss 0.501134, current_train_items 220624.
I0221 21:48:41.605648 136516138993152 run.py:764] (val) algo activity_selector step 8000: {'selected': 0.9595375722543352, 'score': 0.9595375722543352, 'examples_seen': 220624, 'step': 8000, 'algorithm': 'activity_selector'}
I0221 21:48:41.605879 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0221 21:48:42.709798 136516138993152 run.py:729] Algo activity_selector step 8050 current loss 0.543398, current_train_items 222032.
I0221 21:48:42.862622 136516138993152 run.py:764] (val) algo activity_selector step 8050: {'selected': 0.9560229445506692, 'score': 0.9560229445506692, 'examples_seen': 222032, 'step': 8050, 'algorithm': 'activity_selector'}
I0221 21:48:42.862851 136516138993152 run.py:785] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0221 21:48:44.103270 136516138993152 run.py:729] Algo activity_selector step 8100 current loss 0.716275, current_train_items 223392.
I0221 21:48:44.261638 136516138993152 run.py:764] (val) algo activity_selector step 8100: {'selected': 0.9454545454545455, 'score': 0.9454545454545455, 'examples_seen': 223392, 'step': 8100, 'algorithm': 'activity_selector'}
I0221 21:48:44.261877 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.956, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0221 21:48:45.363710 136516138993152 run.py:729] Algo activity_selector step 8150 current loss 0.489084, current_train_items 224784.
I0221 21:48:45.513487 136516138993152 run.py:764] (val) algo activity_selector step 8150: {'selected': 0.937142857142857, 'score': 0.937142857142857, 'examples_seen': 224784, 'step': 8150, 'algorithm': 'activity_selector'}
I0221 21:48:45.513716 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.956, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0221 21:48:46.597754 136516138993152 run.py:729] Algo activity_selector step 8200 current loss 0.498998, current_train_items 226160.
I0221 21:48:46.762300 136516138993152 run.py:764] (val) algo activity_selector step 8200: {'selected': 0.9633911368015414, 'score': 0.9633911368015414, 'examples_seen': 226160, 'step': 8200, 'algorithm': 'activity_selector'}
I0221 21:48:46.762528 136516138993152 run.py:785] Checkpointing best model, best avg val score was 0.956, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0221 21:48:48.017136 136516138993152 run.py:729] Algo activity_selector step 8250 current loss 0.671898, current_train_items 227520.
I0221 21:48:48.176769 136516138993152 run.py:764] (val) algo activity_selector step 8250: {'selected': 0.901010101010101, 'score': 0.901010101010101, 'examples_seen': 227520, 'step': 8250, 'algorithm': 'activity_selector'}
I0221 21:48:48.177011 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.963, current avg val score is 0.901, val scores are: activity_selector: 0.901
I0221 21:48:49.296983 136516138993152 run.py:729] Algo activity_selector step 8300 current loss 0.610795, current_train_items 228912.
I0221 21:48:49.432150 136516138993152 run.py:764] (val) algo activity_selector step 8300: {'selected': 0.9206963249516441, 'score': 0.9206963249516441, 'examples_seen': 228912, 'step': 8300, 'algorithm': 'activity_selector'}
I0221 21:48:49.432381 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.963, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0221 21:48:50.518009 136516138993152 run.py:729] Algo activity_selector step 8350 current loss 0.563608, current_train_items 230288.
I0221 21:48:50.678751 136516138993152 run.py:764] (val) algo activity_selector step 8350: {'selected': 0.9420560747663551, 'score': 0.9420560747663551, 'examples_seen': 230288, 'step': 8350, 'algorithm': 'activity_selector'}
I0221 21:48:50.678903 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.963, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0221 21:48:51.773088 136516138993152 run.py:729] Algo activity_selector step 8400 current loss 0.627434, current_train_items 231680.
I0221 21:48:51.939225 136516138993152 run.py:764] (val) algo activity_selector step 8400: {'selected': 0.9209486166007906, 'score': 0.9209486166007906, 'examples_seen': 231680, 'step': 8400, 'algorithm': 'activity_selector'}
I0221 21:48:51.939458 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.963, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0221 21:48:53.035349 136516138993152 run.py:729] Algo activity_selector step 8450 current loss 0.519574, current_train_items 233040.
I0221 21:48:53.198080 136516138993152 run.py:764] (val) algo activity_selector step 8450: {'selected': 0.9171270718232045, 'score': 0.9171270718232045, 'examples_seen': 233040, 'step': 8450, 'algorithm': 'activity_selector'}
I0221 21:48:53.198233 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.963, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0221 21:48:54.276452 136516138993152 run.py:729] Algo activity_selector step 8500 current loss 0.739208, current_train_items 234432.
I0221 21:48:54.441910 136516138993152 run.py:764] (val) algo activity_selector step 8500: {'selected': 0.9631067961165048, 'score': 0.9631067961165048, 'examples_seen': 234432, 'step': 8500, 'algorithm': 'activity_selector'}
I0221 21:48:54.442167 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.963, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0221 21:48:55.555804 136516138993152 run.py:729] Algo activity_selector step 8550 current loss 0.613601, current_train_items 235808.
I0221 21:48:55.703366 136516138993152 run.py:764] (val) algo activity_selector step 8550: {'selected': 0.9583333333333333, 'score': 0.9583333333333333, 'examples_seen': 235808, 'step': 8550, 'algorithm': 'activity_selector'}
I0221 21:48:55.703593 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.963, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0221 21:48:56.794772 136516138993152 run.py:729] Algo activity_selector step 8600 current loss 0.382614, current_train_items 237168.
I0221 21:48:56.956390 136516138993152 run.py:764] (val) algo activity_selector step 8600: {'selected': 0.9458917835671343, 'score': 0.9458917835671343, 'examples_seen': 237168, 'step': 8600, 'algorithm': 'activity_selector'}
I0221 21:48:56.956539 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.963, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0221 21:48:58.033908 136516138993152 run.py:729] Algo activity_selector step 8650 current loss 0.441830, current_train_items 238576.
I0221 21:48:58.196394 136516138993152 run.py:764] (val) algo activity_selector step 8650: {'selected': 0.9073724007561437, 'score': 0.9073724007561437, 'examples_seen': 238576, 'step': 8650, 'algorithm': 'activity_selector'}
I0221 21:48:58.196625 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.963, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0221 21:48:59.310161 136516138993152 run.py:729] Algo activity_selector step 8700 current loss 0.714613, current_train_items 239936.
I0221 21:48:59.460751 136516138993152 run.py:764] (val) algo activity_selector step 8700: {'selected': 0.9449715370018975, 'score': 0.9449715370018975, 'examples_seen': 239936, 'step': 8700, 'algorithm': 'activity_selector'}
I0221 21:48:59.460972 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.963, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0221 21:49:00.555531 136516138993152 run.py:729] Algo activity_selector step 8750 current loss 0.611965, current_train_items 241328.
I0221 21:49:00.702958 136516138993152 run.py:764] (val) algo activity_selector step 8750: {'selected': 0.9389312977099237, 'score': 0.9389312977099237, 'examples_seen': 241328, 'step': 8750, 'algorithm': 'activity_selector'}
I0221 21:49:00.703201 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.963, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0221 21:49:01.810124 136516138993152 run.py:729] Algo activity_selector step 8800 current loss 0.616298, current_train_items 242704.
I0221 21:49:01.960036 136516138993152 run.py:764] (val) algo activity_selector step 8800: {'selected': 0.9236499068901304, 'score': 0.9236499068901304, 'examples_seen': 242704, 'step': 8800, 'algorithm': 'activity_selector'}
I0221 21:49:01.960278 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.963, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0221 21:49:03.071611 136516138993152 run.py:729] Algo activity_selector step 8850 current loss 0.541584, current_train_items 244080.
I0221 21:49:03.217841 136516138993152 run.py:764] (val) algo activity_selector step 8850: {'selected': 0.95703125, 'score': 0.95703125, 'examples_seen': 244080, 'step': 8850, 'algorithm': 'activity_selector'}
I0221 21:49:03.217993 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.963, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0221 21:49:04.310649 136516138993152 run.py:729] Algo activity_selector step 8900 current loss 0.431169, current_train_items 245456.
I0221 21:49:04.460136 136516138993152 run.py:764] (val) algo activity_selector step 8900: {'selected': 0.934108527131783, 'score': 0.934108527131783, 'examples_seen': 245456, 'step': 8900, 'algorithm': 'activity_selector'}
I0221 21:49:04.460364 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.963, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0221 21:49:05.555490 136516138993152 run.py:729] Algo activity_selector step 8950 current loss 0.812440, current_train_items 246832.
I0221 21:49:05.704740 136516138993152 run.py:764] (val) algo activity_selector step 8950: {'selected': 0.8909426987060998, 'score': 0.8909426987060998, 'examples_seen': 246832, 'step': 8950, 'algorithm': 'activity_selector'}
I0221 21:49:05.704965 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.963, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0221 21:49:06.815846 136516138993152 run.py:729] Algo activity_selector step 9000 current loss 0.722605, current_train_items 248224.
I0221 21:49:06.966519 136516138993152 run.py:764] (val) algo activity_selector step 9000: {'selected': 0.9885931558935361, 'score': 0.9885931558935361, 'examples_seen': 248224, 'step': 9000, 'algorithm': 'activity_selector'}
I0221 21:49:06.966744 136516138993152 run.py:785] Checkpointing best model, best avg val score was 0.963, current avg val score is 0.989, val scores are: activity_selector: 0.989
I0221 21:49:08.221417 136516138993152 run.py:729] Algo activity_selector step 9050 current loss 0.889505, current_train_items 249584.
I0221 21:49:08.368678 136516138993152 run.py:764] (val) algo activity_selector step 9050: {'selected': 0.9586466165413534, 'score': 0.9586466165413534, 'examples_seen': 249584, 'step': 9050, 'algorithm': 'activity_selector'}
I0221 21:49:08.368923 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0221 21:49:09.467484 136516138993152 run.py:729] Algo activity_selector step 9100 current loss 0.598624, current_train_items 250976.
I0221 21:49:09.612746 136516138993152 run.py:764] (val) algo activity_selector step 9100: {'selected': 0.9457943925233645, 'score': 0.9457943925233645, 'examples_seen': 250976, 'step': 9100, 'algorithm': 'activity_selector'}
I0221 21:49:09.612913 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0221 21:49:10.711801 136516138993152 run.py:729] Algo activity_selector step 9150 current loss 0.639919, current_train_items 252352.
I0221 21:49:10.862826 136516138993152 run.py:764] (val) algo activity_selector step 9150: {'selected': 0.9622641509433963, 'score': 0.9622641509433963, 'examples_seen': 252352, 'step': 9150, 'algorithm': 'activity_selector'}
I0221 21:49:10.863074 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0221 21:49:11.963590 136516138993152 run.py:729] Algo activity_selector step 9200 current loss 0.535405, current_train_items 253728.
I0221 21:49:12.112723 136516138993152 run.py:764] (val) algo activity_selector step 9200: {'selected': 0.9613899613899612, 'score': 0.9613899613899612, 'examples_seen': 253728, 'step': 9200, 'algorithm': 'activity_selector'}
I0221 21:49:12.112957 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0221 21:49:13.212618 136516138993152 run.py:729] Algo activity_selector step 9250 current loss 0.764019, current_train_items 255120.
I0221 21:49:13.361223 136516138993152 run.py:764] (val) algo activity_selector step 9250: {'selected': 0.945736434108527, 'score': 0.945736434108527, 'examples_seen': 255120, 'step': 9250, 'algorithm': 'activity_selector'}
I0221 21:49:13.361452 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0221 21:49:14.469657 136516138993152 run.py:729] Algo activity_selector step 9300 current loss 0.607796, current_train_items 256480.
I0221 21:49:14.619397 136516138993152 run.py:764] (val) algo activity_selector step 9300: {'selected': 0.9377289377289377, 'score': 0.9377289377289377, 'examples_seen': 256480, 'step': 9300, 'algorithm': 'activity_selector'}
I0221 21:49:14.619622 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0221 21:49:15.709280 136516138993152 run.py:729] Algo activity_selector step 9350 current loss 0.546058, current_train_items 257856.
I0221 21:49:15.875133 136516138993152 run.py:764] (val) algo activity_selector step 9350: {'selected': 0.945996275605214, 'score': 0.945996275605214, 'examples_seen': 257856, 'step': 9350, 'algorithm': 'activity_selector'}
I0221 21:49:15.875378 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0221 21:49:16.965051 136516138993152 run.py:729] Algo activity_selector step 9400 current loss 0.752160, current_train_items 259248.
I0221 21:49:17.128319 136516138993152 run.py:764] (val) algo activity_selector step 9400: {'selected': 0.9673704414587332, 'score': 0.9673704414587332, 'examples_seen': 259248, 'step': 9400, 'algorithm': 'activity_selector'}
I0221 21:49:17.128599 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0221 21:49:18.246441 136516138993152 run.py:729] Algo activity_selector step 9450 current loss 0.718907, current_train_items 260624.
I0221 21:49:18.395692 136516138993152 run.py:764] (val) algo activity_selector step 9450: {'selected': 0.9496981891348089, 'score': 0.9496981891348089, 'examples_seen': 260624, 'step': 9450, 'algorithm': 'activity_selector'}
I0221 21:49:18.395921 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0221 21:49:19.496582 136516138993152 run.py:729] Algo activity_selector step 9500 current loss 0.496715, current_train_items 262000.
I0221 21:49:19.647447 136516138993152 run.py:764] (val) algo activity_selector step 9500: {'selected': 0.9276437847866418, 'score': 0.9276437847866418, 'examples_seen': 262000, 'step': 9500, 'algorithm': 'activity_selector'}
I0221 21:49:19.647706 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0221 21:49:20.733886 136516138993152 run.py:729] Algo activity_selector step 9550 current loss 0.526783, current_train_items 263392.
I0221 21:49:20.899987 136516138993152 run.py:764] (val) algo activity_selector step 9550: {'selected': 0.9558232931726908, 'score': 0.9558232931726908, 'examples_seen': 263392, 'step': 9550, 'algorithm': 'activity_selector'}
I0221 21:49:20.900245 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0221 21:49:22.013163 136516138993152 run.py:729] Algo activity_selector step 9600 current loss 0.558866, current_train_items 264768.
I0221 21:49:22.164990 136516138993152 run.py:764] (val) algo activity_selector step 9600: {'selected': 0.9567010309278351, 'score': 0.9567010309278351, 'examples_seen': 264768, 'step': 9600, 'algorithm': 'activity_selector'}
I0221 21:49:22.165233 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0221 21:49:23.267720 136516138993152 run.py:729] Algo activity_selector step 9650 current loss 0.431044, current_train_items 266128.
I0221 21:49:23.417804 136516138993152 run.py:764] (val) algo activity_selector step 9650: {'selected': 0.9503816793893128, 'score': 0.9503816793893128, 'examples_seen': 266128, 'step': 9650, 'algorithm': 'activity_selector'}
I0221 21:49:23.418008 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0221 21:49:24.514587 136516138993152 run.py:729] Algo activity_selector step 9700 current loss 0.551148, current_train_items 267520.
I0221 21:49:24.665363 136516138993152 run.py:764] (val) algo activity_selector step 9700: {'selected': 0.9733840304182511, 'score': 0.9733840304182511, 'examples_seen': 267520, 'step': 9700, 'algorithm': 'activity_selector'}
I0221 21:49:24.665617 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0221 21:49:25.798349 136516138993152 run.py:729] Algo activity_selector step 9750 current loss 0.582785, current_train_items 268896.
I0221 21:49:25.965738 136516138993152 run.py:764] (val) algo activity_selector step 9750: {'selected': 0.9539078156312626, 'score': 0.9539078156312626, 'examples_seen': 268896, 'step': 9750, 'algorithm': 'activity_selector'}
I0221 21:49:25.965989 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0221 21:49:27.074569 136516138993152 run.py:729] Algo activity_selector step 9800 current loss 0.540741, current_train_items 270272.
I0221 21:49:27.218980 136516138993152 run.py:764] (val) algo activity_selector step 9800: {'selected': 0.9763779527559054, 'score': 0.9763779527559054, 'examples_seen': 270272, 'step': 9800, 'algorithm': 'activity_selector'}
I0221 21:49:27.219149 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0221 21:49:28.312995 136516138993152 run.py:729] Algo activity_selector step 9850 current loss 0.479625, current_train_items 271664.
I0221 21:49:28.460851 136516138993152 run.py:764] (val) algo activity_selector step 9850: {'selected': 0.96045197740113, 'score': 0.96045197740113, 'examples_seen': 271664, 'step': 9850, 'algorithm': 'activity_selector'}
I0221 21:49:28.461097 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0221 21:49:29.571926 136516138993152 run.py:729] Algo activity_selector step 9900 current loss 1.059360, current_train_items 273040.
I0221 21:49:29.724146 136516138993152 run.py:764] (val) algo activity_selector step 9900: {'selected': 0.953125, 'score': 0.953125, 'examples_seen': 273040, 'step': 9900, 'algorithm': 'activity_selector'}
I0221 21:49:29.724378 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0221 21:49:30.825435 136516138993152 run.py:729] Algo activity_selector step 9950 current loss 0.611041, current_train_items 274400.
I0221 21:49:30.973141 136516138993152 run.py:764] (val) algo activity_selector step 9950: {'selected': 0.919626168224299, 'score': 0.919626168224299, 'examples_seen': 274400, 'step': 9950, 'algorithm': 'activity_selector'}
I0221 21:49:30.973366 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0221 21:49:32.070002 136516138993152 run.py:729] Algo activity_selector step 10000 current loss 0.560862, current_train_items 275792.
I0221 21:49:32.217514 136516138993152 run.py:764] (val) algo activity_selector step 10000: {'selected': 0.95703125, 'score': 0.95703125, 'examples_seen': 275792, 'step': 10000, 'algorithm': 'activity_selector'}
I0221 21:49:32.217757 136516138993152 run.py:788] Not saving new best model, best avg val score was 0.989, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0221 21:49:32.217853 136516138993152 run.py:794] Restoring best model from checkpoint...
I0221 21:49:44.711850 136516138993152 run.py:809] (test) algo activity_selector : {'selected': 0.880281690140845, 'score': 0.880281690140845, 'examples_seen': 275792, 'step': 10001, 'algorithm': 'activity_selector'}
I0221 21:49:44.712001 136516138993152 run.py:811] Done!
