I0830 18:03:55.680565 133100262716928 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0830 18:03:55.682912 133100262716928 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0830 18:03:56.002795 133100262716928 run.py:426] Model: f4 ['activity_selector', 'task_scheduling']
I0830 18:03:56.002905 133100262716928 run.py:428] algorithms ['activity_selector', 'task_scheduling']
I0830 18:03:56.003100 133100262716928 run.py:429] train_lengths ['4', '7', '11', '13', '16']
I0830 18:03:56.003143 133100262716928 run.py:430] train_batch_size 16
I0830 18:03:56.003271 133100262716928 run.py:431] val_batch_size 16
I0830 18:03:56.003304 133100262716928 run.py:432] test_batch_size 16
I0830 18:03:56.003335 133100262716928 run.py:433] chunked_training True
I0830 18:03:56.003470 133100262716928 run.py:434] chunk_length 8
I0830 18:03:56.003502 133100262716928 run.py:435] train_steps 10000
I0830 18:03:56.003536 133100262716928 run.py:436] eval_every 50
I0830 18:03:56.003567 133100262716928 run.py:437] test_every 500
I0830 18:03:56.003597 133100262716928 run.py:438] hidden_size 128
I0830 18:03:56.003625 133100262716928 run.py:439] nb_msg_passing_steps 1
I0830 18:03:56.003655 133100262716928 run.py:440] learning_rate 0.001
I0830 18:03:56.003759 133100262716928 run.py:441] grad_clip_max_norm 1.0
I0830 18:03:56.003791 133100262716928 run.py:442] dropout_prob 0.0
I0830 18:03:56.003821 133100262716928 run.py:443] hint_teacher_forcing 0.0
I0830 18:03:56.003850 133100262716928 run.py:444] hint_mode encoded_decoded
I0830 18:03:56.003966 133100262716928 run.py:445] hint_repred_mode soft
I0830 18:03:56.003997 133100262716928 run.py:446] use_ln False
I0830 18:03:56.004029 133100262716928 run.py:447] use_lstm True
I0830 18:03:56.004059 133100262716928 run.py:448] nb_triplet_fts 8
I0830 18:03:56.004087 133100262716928 run.py:449] encoder_init xavier_on_scalars
I0830 18:03:56.004116 133100262716928 run.py:450] processor_type f4
I0830 18:03:56.004146 133100262716928 run.py:451] checkpoint_path CLRS30
I0830 18:03:56.004190 133100262716928 run.py:452] dataset_path CLRS30
I0830 18:03:56.004224 133100262716928 run.py:453] freeze_processor False
I0830 18:03:56.004253 133100262716928 run.py:454] reduction min
I0830 18:03:56.004282 133100262716928 run.py:455] activation elu
I0830 18:03:56.004311 133100262716928 run.py:456] restore_model 
I0830 18:03:56.004340 133100262716928 run.py:457] gated False
I0830 18:03:56.004371 133100262716928 run.py:458] gated_activation sigmoid
I0830 18:03:56.007334 133100262716928 run.py:484] Creating samplers for algo activity_selector
W0830 18:03:56.007552 133100262716928 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0830 18:03:56.007846 133100262716928 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0830 18:03:56.214605 133100262716928 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0830 18:03:56.454382 133100262716928 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0830 18:03:56.753161 133100262716928 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0830 18:03:57.083111 133100262716928 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0830 18:03:57.463001 133100262716928 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0830 18:03:57.463305 133100262716928 samplers.py:124] Creating a dataset with 64 samples.
I0830 18:03:57.488976 133100262716928 run.py:270] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0830 18:03:57.489683 133100262716928 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0830 18:03:57.493267 133100262716928 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0830 18:03:57.496428 133100262716928 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0830 18:03:57.550087 133100262716928 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W0830 18:03:57.570565 133100262716928 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x790d4d5739c0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0830 18:03:57.657089 133100262716928 run.py:484] Creating samplers for algo task_scheduling
W0830 18:03:57.657330 133100262716928 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.TaskSampler'>
W0830 18:03:57.853523 133100262716928 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.TaskSampler'>
W0830 18:03:58.077579 133100262716928 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.TaskSampler'>
W0830 18:03:58.358619 133100262716928 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.TaskSampler'>
W0830 18:03:58.668811 133100262716928 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.TaskSampler'>
W0830 18:03:59.027738 133100262716928 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.TaskSampler'>
I0830 18:03:59.028028 133100262716928 samplers.py:124] Creating a dataset with 64 samples.
I0830 18:03:59.052608 133100262716928 run.py:270] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0830 18:03:59.053185 133100262716928 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/task_scheduling_test/1.0.0
I0830 18:03:59.055973 133100262716928 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/task_scheduling_test/1.0.0
I0830 18:03:59.057970 133100262716928 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/task_scheduling_test/1.0.0.
I0830 18:03:59.091210 133100262716928 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/task_scheduling_test/1.0.0
I0830 18:04:24.304665 133100262716928 run.py:707] Algo activity_selector step 0 current loss 6.127175, current_train_items 16.
I0830 18:04:29.536761 133100262716928 run.py:707] Algo task_scheduling step 0 current loss 6.653638, current_train_items 16.
I0830 18:04:31.854538 133100262716928 run.py:742] (val) algo activity_selector step 0: {'selected': 0.4271047227926078, 'score': 0.4271047227926078, 'examples_seen': 16, 'step': 0, 'algorithm': 'activity_selector'}
I0830 18:04:33.369049 133100262716928 run.py:742] (val) algo task_scheduling step 0: {'selected': 0.0, 'score': 0.0, 'examples_seen': 16, 'step': 0, 'algorithm': 'task_scheduling'}
I0830 18:04:33.369216 133100262716928 run.py:763] Checkpointing best model, best avg val score was -0.500, current avg val score is 0.214, val scores are: activity_selector: 0.427, task_scheduling: 0.000
I0830 18:05:26.312798 133100262716928 run.py:707] Algo activity_selector step 50 current loss 4.238782, current_train_items 720.
I0830 18:05:26.317352 133100262716928 run.py:707] Algo task_scheduling step 50 current loss 3.585004, current_train_items 720.
I0830 18:05:26.334411 133100262716928 run.py:742] (val) algo activity_selector step 50: {'selected': 0.7189292543021032, 'score': 0.7189292543021032, 'examples_seen': 720, 'step': 50, 'algorithm': 'activity_selector'}
I0830 18:05:26.342178 133100262716928 run.py:742] (val) algo task_scheduling step 50: {'selected': 0.8260061919504643, 'score': 0.8260061919504643, 'examples_seen': 720, 'step': 50, 'algorithm': 'task_scheduling'}
I0830 18:05:26.342327 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.214, current avg val score is 0.772, val scores are: activity_selector: 0.719, task_scheduling: 0.826
I0830 18:05:27.376600 133100262716928 run.py:707] Algo activity_selector step 100 current loss 3.337230, current_train_items 1408.
I0830 18:05:27.381015 133100262716928 run.py:707] Algo task_scheduling step 100 current loss 3.382649, current_train_items 1408.
I0830 18:05:27.397132 133100262716928 run.py:742] (val) algo activity_selector step 100: {'selected': 0.7692307692307693, 'score': 0.7692307692307693, 'examples_seen': 1408, 'step': 100, 'algorithm': 'activity_selector'}
I0830 18:05:27.404672 133100262716928 run.py:742] (val) algo task_scheduling step 100: {'selected': 0.8576923076923078, 'score': 0.8576923076923078, 'examples_seen': 1408, 'step': 100, 'algorithm': 'task_scheduling'}
I0830 18:05:27.404812 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.772, current avg val score is 0.813, val scores are: activity_selector: 0.769, task_scheduling: 0.858
I0830 18:05:28.487367 133100262716928 run.py:707] Algo activity_selector step 150 current loss 3.124678, current_train_items 2080.
I0830 18:05:28.491845 133100262716928 run.py:707] Algo task_scheduling step 150 current loss 5.289871, current_train_items 2080.
I0830 18:05:28.509149 133100262716928 run.py:742] (val) algo activity_selector step 150: {'selected': 0.7781954887218044, 'score': 0.7781954887218044, 'examples_seen': 2080, 'step': 150, 'algorithm': 'activity_selector'}
I0830 18:05:28.516697 133100262716928 run.py:742] (val) algo task_scheduling step 150: {'selected': 0.8067025733093957, 'score': 0.8067025733093957, 'examples_seen': 2080, 'step': 150, 'algorithm': 'task_scheduling'}
I0830 18:05:28.516841 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.813, current avg val score is 0.792, val scores are: activity_selector: 0.778, task_scheduling: 0.807
I0830 18:05:29.601136 133100262716928 run.py:707] Algo activity_selector step 200 current loss 2.670532, current_train_items 2784.
I0830 18:05:29.605398 133100262716928 run.py:707] Algo task_scheduling step 200 current loss 3.418084, current_train_items 2784.
I0830 18:05:29.622144 133100262716928 run.py:742] (val) algo activity_selector step 200: {'selected': 0.7228070175438597, 'score': 0.7228070175438597, 'examples_seen': 2784, 'step': 200, 'algorithm': 'activity_selector'}
I0830 18:05:29.629727 133100262716928 run.py:742] (val) algo task_scheduling step 200: {'selected': 0.8247678018575851, 'score': 0.8247678018575851, 'examples_seen': 2784, 'step': 200, 'algorithm': 'task_scheduling'}
I0830 18:05:29.629868 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.813, current avg val score is 0.774, val scores are: activity_selector: 0.723, task_scheduling: 0.825
I0830 18:05:30.670240 133100262716928 run.py:707] Algo activity_selector step 250 current loss 2.872621, current_train_items 3488.
I0830 18:05:30.674710 133100262716928 run.py:707] Algo task_scheduling step 250 current loss 3.162051, current_train_items 3488.
I0830 18:05:30.691539 133100262716928 run.py:742] (val) algo activity_selector step 250: {'selected': 0.7206611570247933, 'score': 0.7206611570247933, 'examples_seen': 3488, 'step': 250, 'algorithm': 'activity_selector'}
I0830 18:05:30.699103 133100262716928 run.py:742] (val) algo task_scheduling step 250: {'selected': 0.8810996563573882, 'score': 0.8810996563573882, 'examples_seen': 3488, 'step': 250, 'algorithm': 'task_scheduling'}
I0830 18:05:30.699248 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.813, current avg val score is 0.801, val scores are: activity_selector: 0.721, task_scheduling: 0.881
I0830 18:05:31.757602 133100262716928 run.py:707] Algo activity_selector step 300 current loss 2.804883, current_train_items 4144.
I0830 18:05:31.762033 133100262716928 run.py:707] Algo task_scheduling step 300 current loss 3.072490, current_train_items 4144.
I0830 18:05:31.779354 133100262716928 run.py:742] (val) algo activity_selector step 300: {'selected': 0.7900355871886121, 'score': 0.7900355871886121, 'examples_seen': 4144, 'step': 300, 'algorithm': 'activity_selector'}
I0830 18:05:31.786879 133100262716928 run.py:742] (val) algo task_scheduling step 300: {'selected': 0.8659397049390635, 'score': 0.8659397049390635, 'examples_seen': 4144, 'step': 300, 'algorithm': 'task_scheduling'}
I0830 18:05:31.787019 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.813, current avg val score is 0.828, val scores are: activity_selector: 0.790, task_scheduling: 0.866
I0830 18:05:32.876384 133100262716928 run.py:707] Algo activity_selector step 350 current loss 3.143645, current_train_items 4848.
I0830 18:05:32.880951 133100262716928 run.py:707] Algo task_scheduling step 350 current loss 3.259284, current_train_items 4848.
I0830 18:05:32.897418 133100262716928 run.py:742] (val) algo activity_selector step 350: {'selected': 0.698901098901099, 'score': 0.698901098901099, 'examples_seen': 4848, 'step': 350, 'algorithm': 'activity_selector'}
I0830 18:05:32.904956 133100262716928 run.py:742] (val) algo task_scheduling step 350: {'selected': 0.884896872920825, 'score': 0.884896872920825, 'examples_seen': 4848, 'step': 350, 'algorithm': 'task_scheduling'}
I0830 18:05:32.905096 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.828, current avg val score is 0.792, val scores are: activity_selector: 0.699, task_scheduling: 0.885
I0830 18:05:33.973860 133100262716928 run.py:707] Algo activity_selector step 400 current loss 1.998825, current_train_items 5552.
I0830 18:05:33.978327 133100262716928 run.py:707] Algo task_scheduling step 400 current loss 2.957990, current_train_items 5552.
I0830 18:05:33.994772 133100262716928 run.py:742] (val) algo activity_selector step 400: {'selected': 0.7716814159292035, 'score': 0.7716814159292035, 'examples_seen': 5552, 'step': 400, 'algorithm': 'activity_selector'}
I0830 18:05:34.002422 133100262716928 run.py:742] (val) algo task_scheduling step 400: {'selected': 0.8891873740765615, 'score': 0.8891873740765615, 'examples_seen': 5552, 'step': 400, 'algorithm': 'task_scheduling'}
I0830 18:05:34.002568 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.828, current avg val score is 0.830, val scores are: activity_selector: 0.772, task_scheduling: 0.889
I0830 18:05:35.066782 133100262716928 run.py:707] Algo activity_selector step 450 current loss 2.353375, current_train_items 6224.
I0830 18:05:35.071257 133100262716928 run.py:707] Algo task_scheduling step 450 current loss 2.879908, current_train_items 6224.
I0830 18:05:35.088903 133100262716928 run.py:742] (val) algo activity_selector step 450: {'selected': 0.8030888030888031, 'score': 0.8030888030888031, 'examples_seen': 6224, 'step': 450, 'algorithm': 'activity_selector'}
I0830 18:05:35.096561 133100262716928 run.py:742] (val) algo task_scheduling step 450: {'selected': 0.8674217188540974, 'score': 0.8674217188540974, 'examples_seen': 6224, 'step': 450, 'algorithm': 'task_scheduling'}
I0830 18:05:35.096709 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.830, current avg val score is 0.835, val scores are: activity_selector: 0.803, task_scheduling: 0.867
I0830 18:05:36.187026 133100262716928 run.py:707] Algo activity_selector step 500 current loss 2.105190, current_train_items 6912.
I0830 18:05:36.191480 133100262716928 run.py:707] Algo task_scheduling step 500 current loss 2.613209, current_train_items 6912.
I0830 18:05:36.208352 133100262716928 run.py:742] (val) algo activity_selector step 500: {'selected': 0.7524752475247525, 'score': 0.7524752475247525, 'examples_seen': 6912, 'step': 500, 'algorithm': 'activity_selector'}
I0830 18:05:36.215954 133100262716928 run.py:742] (val) algo task_scheduling step 500: {'selected': 0.9019876627827279, 'score': 0.9019876627827279, 'examples_seen': 6912, 'step': 500, 'algorithm': 'task_scheduling'}
I0830 18:05:36.216096 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.835, current avg val score is 0.827, val scores are: activity_selector: 0.752, task_scheduling: 0.902
I0830 18:05:37.280290 133100262716928 run.py:707] Algo activity_selector step 550 current loss 1.790152, current_train_items 7616.
I0830 18:05:37.284820 133100262716928 run.py:707] Algo task_scheduling step 550 current loss 2.648963, current_train_items 7616.
I0830 18:05:37.302255 133100262716928 run.py:742] (val) algo activity_selector step 550: {'selected': 0.8089887640449439, 'score': 0.8089887640449439, 'examples_seen': 7616, 'step': 550, 'algorithm': 'activity_selector'}
I0830 18:05:37.309927 133100262716928 run.py:742] (val) algo task_scheduling step 550: {'selected': 0.9121107266435986, 'score': 0.9121107266435986, 'examples_seen': 7616, 'step': 550, 'algorithm': 'task_scheduling'}
I0830 18:05:37.310071 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.835, current avg val score is 0.861, val scores are: activity_selector: 0.809, task_scheduling: 0.912
I0830 18:05:38.370257 133100262716928 run.py:707] Algo activity_selector step 600 current loss 2.343226, current_train_items 8288.
I0830 18:05:38.374758 133100262716928 run.py:707] Algo task_scheduling step 600 current loss 2.615482, current_train_items 8288.
I0830 18:05:38.391253 133100262716928 run.py:742] (val) algo activity_selector step 600: {'selected': 0.78397212543554, 'score': 0.78397212543554, 'examples_seen': 8288, 'step': 600, 'algorithm': 'activity_selector'}
I0830 18:05:38.398772 133100262716928 run.py:742] (val) algo task_scheduling step 600: {'selected': 0.9088378566457899, 'score': 0.9088378566457899, 'examples_seen': 8288, 'step': 600, 'algorithm': 'task_scheduling'}
I0830 18:05:38.398912 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.861, current avg val score is 0.846, val scores are: activity_selector: 0.784, task_scheduling: 0.909
I0830 18:05:39.503031 133100262716928 run.py:707] Algo activity_selector step 650 current loss 1.780965, current_train_items 8976.
I0830 18:05:39.507501 133100262716928 run.py:707] Algo task_scheduling step 650 current loss 2.701370, current_train_items 8976.
I0830 18:05:39.526982 133100262716928 run.py:742] (val) algo activity_selector step 650: {'selected': 0.8150807899461401, 'score': 0.8150807899461401, 'examples_seen': 8976, 'step': 650, 'algorithm': 'activity_selector'}
I0830 18:05:39.534711 133100262716928 run.py:742] (val) algo task_scheduling step 650: {'selected': 0.8778833107191315, 'score': 0.8778833107191315, 'examples_seen': 8976, 'step': 650, 'algorithm': 'task_scheduling'}
I0830 18:05:39.534852 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.861, current avg val score is 0.846, val scores are: activity_selector: 0.815, task_scheduling: 0.878
I0830 18:05:40.592366 133100262716928 run.py:707] Algo activity_selector step 700 current loss 1.442270, current_train_items 9680.
I0830 18:05:40.596916 133100262716928 run.py:707] Algo task_scheduling step 700 current loss 2.744888, current_train_items 9680.
I0830 18:05:40.613812 133100262716928 run.py:742] (val) algo activity_selector step 700: {'selected': 0.7766179540709812, 'score': 0.7766179540709812, 'examples_seen': 9680, 'step': 700, 'algorithm': 'activity_selector'}
I0830 18:05:40.621340 133100262716928 run.py:742] (val) algo task_scheduling step 700: {'selected': 0.8908716540837338, 'score': 0.8908716540837338, 'examples_seen': 9680, 'step': 700, 'algorithm': 'task_scheduling'}
I0830 18:05:40.621483 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.861, current avg val score is 0.834, val scores are: activity_selector: 0.777, task_scheduling: 0.891
I0830 18:05:41.698160 133100262716928 run.py:707] Algo activity_selector step 750 current loss 1.761533, current_train_items 10368.
I0830 18:05:41.702663 133100262716928 run.py:707] Algo task_scheduling step 750 current loss 2.280651, current_train_items 10368.
I0830 18:05:41.719006 133100262716928 run.py:742] (val) algo activity_selector step 750: {'selected': 0.7692307692307693, 'score': 0.7692307692307693, 'examples_seen': 10368, 'step': 750, 'algorithm': 'activity_selector'}
I0830 18:05:41.726550 133100262716928 run.py:742] (val) algo task_scheduling step 750: {'selected': 0.9140518417462482, 'score': 0.9140518417462482, 'examples_seen': 10368, 'step': 750, 'algorithm': 'task_scheduling'}
I0830 18:05:41.726691 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.861, current avg val score is 0.842, val scores are: activity_selector: 0.769, task_scheduling: 0.914
I0830 18:05:42.768317 133100262716928 run.py:707] Algo activity_selector step 800 current loss 1.550118, current_train_items 11056.
I0830 18:05:42.772829 133100262716928 run.py:707] Algo task_scheduling step 800 current loss 2.651664, current_train_items 11056.
I0830 18:05:42.790127 133100262716928 run.py:742] (val) algo activity_selector step 800: {'selected': 0.8265306122448979, 'score': 0.8265306122448979, 'examples_seen': 11056, 'step': 800, 'algorithm': 'activity_selector'}
I0830 18:05:42.797730 133100262716928 run.py:742] (val) algo task_scheduling step 800: {'selected': 0.9016501650165017, 'score': 0.9016501650165017, 'examples_seen': 11056, 'step': 800, 'algorithm': 'task_scheduling'}
I0830 18:05:42.797871 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.861, current avg val score is 0.864, val scores are: activity_selector: 0.827, task_scheduling: 0.902
I0830 18:05:43.872260 133100262716928 run.py:707] Algo activity_selector step 850 current loss 1.898701, current_train_items 11744.
I0830 18:05:43.876732 133100262716928 run.py:707] Algo task_scheduling step 850 current loss 3.078116, current_train_items 11744.
I0830 18:05:43.893989 133100262716928 run.py:742] (val) algo activity_selector step 850: {'selected': 0.7000000000000001, 'score': 0.7000000000000001, 'examples_seen': 11744, 'step': 850, 'algorithm': 'activity_selector'}
I0830 18:05:43.901488 133100262716928 run.py:742] (val) algo task_scheduling step 850: {'selected': 0.9080079417604235, 'score': 0.9080079417604235, 'examples_seen': 11744, 'step': 850, 'algorithm': 'task_scheduling'}
I0830 18:05:43.901631 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.864, current avg val score is 0.804, val scores are: activity_selector: 0.700, task_scheduling: 0.908
I0830 18:05:44.995365 133100262716928 run.py:707] Algo activity_selector step 900 current loss 1.456338, current_train_items 12432.
I0830 18:05:44.999858 133100262716928 run.py:707] Algo task_scheduling step 900 current loss 3.200948, current_train_items 12432.
I0830 18:05:45.017235 133100262716928 run.py:742] (val) algo activity_selector step 900: {'selected': 0.7739307535641547, 'score': 0.7739307535641547, 'examples_seen': 12432, 'step': 900, 'algorithm': 'activity_selector'}
I0830 18:05:45.024822 133100262716928 run.py:742] (val) algo task_scheduling step 900: {'selected': 0.8851612903225807, 'score': 0.8851612903225807, 'examples_seen': 12432, 'step': 900, 'algorithm': 'task_scheduling'}
I0830 18:05:45.024963 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.864, current avg val score is 0.830, val scores are: activity_selector: 0.774, task_scheduling: 0.885
I0830 18:05:46.081345 133100262716928 run.py:707] Algo activity_selector step 950 current loss 1.476995, current_train_items 13120.
I0830 18:05:46.085896 133100262716928 run.py:707] Algo task_scheduling step 950 current loss 2.276619, current_train_items 13120.
I0830 18:05:46.103382 133100262716928 run.py:742] (val) algo activity_selector step 950: {'selected': 0.7632027257240204, 'score': 0.7632027257240204, 'examples_seen': 13120, 'step': 950, 'algorithm': 'activity_selector'}
I0830 18:05:46.110936 133100262716928 run.py:742] (val) algo task_scheduling step 950: {'selected': 0.9187279151943464, 'score': 0.9187279151943464, 'examples_seen': 13120, 'step': 950, 'algorithm': 'task_scheduling'}
I0830 18:05:46.111079 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.864, current avg val score is 0.841, val scores are: activity_selector: 0.763, task_scheduling: 0.919
I0830 18:05:47.159754 133100262716928 run.py:707] Algo activity_selector step 1000 current loss 1.806917, current_train_items 13808.
I0830 18:05:47.164423 133100262716928 run.py:707] Algo task_scheduling step 1000 current loss 2.449996, current_train_items 13808.
I0830 18:05:47.181506 133100262716928 run.py:742] (val) algo activity_selector step 1000: {'selected': 0.7495961227786753, 'score': 0.7495961227786753, 'examples_seen': 13808, 'step': 1000, 'algorithm': 'activity_selector'}
I0830 18:05:47.189054 133100262716928 run.py:742] (val) algo task_scheduling step 1000: {'selected': 0.9073170731707316, 'score': 0.9073170731707316, 'examples_seen': 13808, 'step': 1000, 'algorithm': 'task_scheduling'}
I0830 18:05:47.189205 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.864, current avg val score is 0.828, val scores are: activity_selector: 0.750, task_scheduling: 0.907
I0830 18:05:48.268412 133100262716928 run.py:707] Algo activity_selector step 1050 current loss 1.570876, current_train_items 14496.
I0830 18:05:48.272992 133100262716928 run.py:707] Algo task_scheduling step 1050 current loss 2.840469, current_train_items 14496.
I0830 18:05:48.290682 133100262716928 run.py:742] (val) algo activity_selector step 1050: {'selected': 0.8028169014084509, 'score': 0.8028169014084509, 'examples_seen': 14496, 'step': 1050, 'algorithm': 'activity_selector'}
I0830 18:05:48.298404 133100262716928 run.py:742] (val) algo task_scheduling step 1050: {'selected': 0.8927848954821308, 'score': 0.8927848954821308, 'examples_seen': 14496, 'step': 1050, 'algorithm': 'task_scheduling'}
I0830 18:05:48.298550 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.864, current avg val score is 0.848, val scores are: activity_selector: 0.803, task_scheduling: 0.893
I0830 18:05:49.362756 133100262716928 run.py:707] Algo activity_selector step 1100 current loss 1.233109, current_train_items 15200.
I0830 18:05:49.367283 133100262716928 run.py:707] Algo task_scheduling step 1100 current loss 2.906575, current_train_items 15200.
I0830 18:05:49.386628 133100262716928 run.py:742] (val) algo activity_selector step 1100: {'selected': 0.8089887640449438, 'score': 0.8089887640449438, 'examples_seen': 15200, 'step': 1100, 'algorithm': 'activity_selector'}
I0830 18:05:49.394805 133100262716928 run.py:742] (val) algo task_scheduling step 1100: {'selected': 0.9171122994652408, 'score': 0.9171122994652408, 'examples_seen': 15200, 'step': 1100, 'algorithm': 'task_scheduling'}
I0830 18:05:49.394953 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.864, current avg val score is 0.863, val scores are: activity_selector: 0.809, task_scheduling: 0.917
I0830 18:05:50.454512 133100262716928 run.py:707] Algo activity_selector step 1150 current loss 1.518835, current_train_items 15888.
I0830 18:05:50.459066 133100262716928 run.py:707] Algo task_scheduling step 1150 current loss 2.539831, current_train_items 15888.
I0830 18:05:50.477992 133100262716928 run.py:742] (val) algo activity_selector step 1150: {'selected': 0.7657512116316639, 'score': 0.7657512116316639, 'examples_seen': 15888, 'step': 1150, 'algorithm': 'activity_selector'}
I0830 18:05:50.485631 133100262716928 run.py:742] (val) algo task_scheduling step 1150: {'selected': 0.8977900552486188, 'score': 0.8977900552486188, 'examples_seen': 15888, 'step': 1150, 'algorithm': 'task_scheduling'}
I0830 18:05:50.485780 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.864, current avg val score is 0.832, val scores are: activity_selector: 0.766, task_scheduling: 0.898
I0830 18:05:51.555818 133100262716928 run.py:707] Algo activity_selector step 1200 current loss 1.337183, current_train_items 16560.
I0830 18:05:51.560930 133100262716928 run.py:707] Algo task_scheduling step 1200 current loss 2.306632, current_train_items 16560.
I0830 18:05:51.577214 133100262716928 run.py:742] (val) algo activity_selector step 1200: {'selected': 0.8372943327239488, 'score': 0.8372943327239488, 'examples_seen': 16560, 'step': 1200, 'algorithm': 'activity_selector'}
I0830 18:05:51.584830 133100262716928 run.py:742] (val) algo task_scheduling step 1200: {'selected': 0.9101123595505618, 'score': 0.9101123595505618, 'examples_seen': 16560, 'step': 1200, 'algorithm': 'task_scheduling'}
I0830 18:05:51.584968 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.864, current avg val score is 0.874, val scores are: activity_selector: 0.837, task_scheduling: 0.910
I0830 18:05:52.708017 133100262716928 run.py:707] Algo activity_selector step 1250 current loss 1.137392, current_train_items 17264.
I0830 18:05:52.712722 133100262716928 run.py:707] Algo task_scheduling step 1250 current loss 2.036109, current_train_items 17264.
I0830 18:05:52.731234 133100262716928 run.py:742] (val) algo activity_selector step 1250: {'selected': 0.8274647887323944, 'score': 0.8274647887323944, 'examples_seen': 17264, 'step': 1250, 'algorithm': 'activity_selector'}
I0830 18:05:52.739209 133100262716928 run.py:742] (val) algo task_scheduling step 1250: {'selected': 0.9297994269340973, 'score': 0.9297994269340973, 'examples_seen': 17264, 'step': 1250, 'algorithm': 'task_scheduling'}
I0830 18:05:52.739370 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.874, current avg val score is 0.879, val scores are: activity_selector: 0.827, task_scheduling: 0.930
I0830 18:05:53.836880 133100262716928 run.py:707] Algo activity_selector step 1300 current loss 1.539060, current_train_items 17952.
I0830 18:05:53.842262 133100262716928 run.py:707] Algo task_scheduling step 1300 current loss 2.738224, current_train_items 17952.
I0830 18:05:53.862325 133100262716928 run.py:742] (val) algo activity_selector step 1300: {'selected': 0.7805825242718447, 'score': 0.7805825242718447, 'examples_seen': 17952, 'step': 1300, 'algorithm': 'activity_selector'}
I0830 18:05:53.871582 133100262716928 run.py:742] (val) algo task_scheduling step 1300: {'selected': 0.9097127222982216, 'score': 0.9097127222982216, 'examples_seen': 17952, 'step': 1300, 'algorithm': 'task_scheduling'}
I0830 18:05:53.871760 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.879, current avg val score is 0.845, val scores are: activity_selector: 0.781, task_scheduling: 0.910
I0830 18:05:55.035027 133100262716928 run.py:707] Algo activity_selector step 1350 current loss 1.454454, current_train_items 18624.
I0830 18:05:55.039800 133100262716928 run.py:707] Algo task_scheduling step 1350 current loss 1.819995, current_train_items 18624.
I0830 18:05:55.058731 133100262716928 run.py:742] (val) algo activity_selector step 1350: {'selected': 0.7912457912457913, 'score': 0.7912457912457913, 'examples_seen': 18624, 'step': 1350, 'algorithm': 'activity_selector'}
I0830 18:05:55.066531 133100262716928 run.py:742] (val) algo task_scheduling step 1350: {'selected': 0.9253731343283582, 'score': 0.9253731343283582, 'examples_seen': 18624, 'step': 1350, 'algorithm': 'task_scheduling'}
I0830 18:05:55.066674 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.879, current avg val score is 0.858, val scores are: activity_selector: 0.791, task_scheduling: 0.925
I0830 18:05:56.192622 133100262716928 run.py:707] Algo activity_selector step 1400 current loss 0.964036, current_train_items 19328.
I0830 18:05:56.197670 133100262716928 run.py:707] Algo task_scheduling step 1400 current loss 2.609432, current_train_items 19328.
I0830 18:05:56.214046 133100262716928 run.py:742] (val) algo activity_selector step 1400: {'selected': 0.8530465949820788, 'score': 0.8530465949820788, 'examples_seen': 19328, 'step': 1400, 'algorithm': 'activity_selector'}
I0830 18:05:56.221652 133100262716928 run.py:742] (val) algo task_scheduling step 1400: {'selected': 0.9281314168377824, 'score': 0.9281314168377824, 'examples_seen': 19328, 'step': 1400, 'algorithm': 'task_scheduling'}
I0830 18:05:56.221794 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.879, current avg val score is 0.891, val scores are: activity_selector: 0.853, task_scheduling: 0.928
I0830 18:05:57.507385 133100262716928 run.py:707] Algo activity_selector step 1450 current loss 1.325490, current_train_items 20016.
I0830 18:05:57.512011 133100262716928 run.py:707] Algo task_scheduling step 1450 current loss 2.238187, current_train_items 20016.
I0830 18:05:57.530209 133100262716928 run.py:742] (val) algo activity_selector step 1450: {'selected': 0.8122605363984674, 'score': 0.8122605363984674, 'examples_seen': 20016, 'step': 1450, 'algorithm': 'activity_selector'}
I0830 18:05:57.537801 133100262716928 run.py:742] (val) algo task_scheduling step 1450: {'selected': 0.9364968597348221, 'score': 0.9364968597348221, 'examples_seen': 20016, 'step': 1450, 'algorithm': 'task_scheduling'}
I0830 18:05:57.537948 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.891, current avg val score is 0.874, val scores are: activity_selector: 0.812, task_scheduling: 0.936
I0830 18:05:58.729765 133100262716928 run.py:707] Algo activity_selector step 1500 current loss 1.036821, current_train_items 20704.
I0830 18:05:58.734565 133100262716928 run.py:707] Algo task_scheduling step 1500 current loss 1.991503, current_train_items 20704.
I0830 18:05:58.754689 133100262716928 run.py:742] (val) algo activity_selector step 1500: {'selected': 0.8424908424908424, 'score': 0.8424908424908424, 'examples_seen': 20704, 'step': 1500, 'algorithm': 'activity_selector'}
I0830 18:05:58.762593 133100262716928 run.py:742] (val) algo task_scheduling step 1500: {'selected': 0.9215686274509803, 'score': 0.9215686274509803, 'examples_seen': 20704, 'step': 1500, 'algorithm': 'task_scheduling'}
I0830 18:05:58.762752 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.891, current avg val score is 0.882, val scores are: activity_selector: 0.842, task_scheduling: 0.922
I0830 18:05:59.900786 133100262716928 run.py:707] Algo activity_selector step 1550 current loss 1.279392, current_train_items 21392.
I0830 18:05:59.906473 133100262716928 run.py:707] Algo task_scheduling step 1550 current loss 1.874502, current_train_items 21392.
I0830 18:05:59.924421 133100262716928 run.py:742] (val) algo activity_selector step 1550: {'selected': 0.8687615526802218, 'score': 0.8687615526802218, 'examples_seen': 21392, 'step': 1550, 'algorithm': 'activity_selector'}
I0830 18:05:59.932085 133100262716928 run.py:742] (val) algo task_scheduling step 1550: {'selected': 0.918918918918919, 'score': 0.918918918918919, 'examples_seen': 21392, 'step': 1550, 'algorithm': 'task_scheduling'}
I0830 18:05:59.932240 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.891, current avg val score is 0.894, val scores are: activity_selector: 0.869, task_scheduling: 0.919
I0830 18:06:01.191322 133100262716928 run.py:707] Algo activity_selector step 1600 current loss 1.124328, current_train_items 22096.
I0830 18:06:01.196344 133100262716928 run.py:707] Algo task_scheduling step 1600 current loss 2.827395, current_train_items 22096.
I0830 18:06:01.219264 133100262716928 run.py:742] (val) algo activity_selector step 1600: {'selected': 0.8284023668639053, 'score': 0.8284023668639053, 'examples_seen': 22096, 'step': 1600, 'algorithm': 'activity_selector'}
I0830 18:06:01.227744 133100262716928 run.py:742] (val) algo task_scheduling step 1600: {'selected': 0.9148455162019593, 'score': 0.9148455162019593, 'examples_seen': 22096, 'step': 1600, 'algorithm': 'task_scheduling'}
I0830 18:06:01.227894 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.894, current avg val score is 0.872, val scores are: activity_selector: 0.828, task_scheduling: 0.915
I0830 18:06:02.651416 133100262716928 run.py:707] Algo activity_selector step 1650 current loss 0.986530, current_train_items 22768.
I0830 18:06:02.659265 133100262716928 run.py:707] Algo task_scheduling step 1650 current loss 2.290756, current_train_items 22768.
I0830 18:06:02.681662 133100262716928 run.py:742] (val) algo activity_selector step 1650: {'selected': 0.8336594911937377, 'score': 0.8336594911937377, 'examples_seen': 22768, 'step': 1650, 'algorithm': 'activity_selector'}
I0830 18:06:02.691797 133100262716928 run.py:742] (val) algo task_scheduling step 1650: {'selected': 0.9146341463414634, 'score': 0.9146341463414634, 'examples_seen': 22768, 'step': 1650, 'algorithm': 'task_scheduling'}
I0830 18:06:02.691969 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.894, current avg val score is 0.874, val scores are: activity_selector: 0.834, task_scheduling: 0.915
I0830 18:06:04.008097 133100262716928 run.py:707] Algo activity_selector step 1700 current loss 0.748338, current_train_items 23456.
I0830 18:06:04.013038 133100262716928 run.py:707] Algo task_scheduling step 1700 current loss 1.628722, current_train_items 23456.
I0830 18:06:04.033586 133100262716928 run.py:742] (val) algo activity_selector step 1700: {'selected': 0.8588709677419355, 'score': 0.8588709677419355, 'examples_seen': 23456, 'step': 1700, 'algorithm': 'activity_selector'}
I0830 18:06:04.042861 133100262716928 run.py:742] (val) algo task_scheduling step 1700: {'selected': 0.9208333333333334, 'score': 0.9208333333333334, 'examples_seen': 23456, 'step': 1700, 'algorithm': 'task_scheduling'}
I0830 18:06:04.043077 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.894, current avg val score is 0.890, val scores are: activity_selector: 0.859, task_scheduling: 0.921
I0830 18:06:05.376742 133100262716928 run.py:707] Algo activity_selector step 1750 current loss 1.172479, current_train_items 24160.
I0830 18:06:05.381508 133100262716928 run.py:707] Algo task_scheduling step 1750 current loss 2.348816, current_train_items 24160.
I0830 18:06:05.399374 133100262716928 run.py:742] (val) algo activity_selector step 1750: {'selected': 0.8646616541353384, 'score': 0.8646616541353384, 'examples_seen': 24160, 'step': 1750, 'algorithm': 'activity_selector'}
I0830 18:06:05.408599 133100262716928 run.py:742] (val) algo task_scheduling step 1750: {'selected': 0.940416367552046, 'score': 0.940416367552046, 'examples_seen': 24160, 'step': 1750, 'algorithm': 'task_scheduling'}
I0830 18:06:05.408771 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.894, current avg val score is 0.903, val scores are: activity_selector: 0.865, task_scheduling: 0.940
I0830 18:06:06.523690 133100262716928 run.py:707] Algo activity_selector step 1800 current loss 1.368196, current_train_items 24832.
I0830 18:06:06.528858 133100262716928 run.py:707] Algo task_scheduling step 1800 current loss 2.072460, current_train_items 24832.
I0830 18:06:06.546915 133100262716928 run.py:742] (val) algo activity_selector step 1800: {'selected': 0.8402366863905326, 'score': 0.8402366863905326, 'examples_seen': 24832, 'step': 1800, 'algorithm': 'activity_selector'}
I0830 18:06:06.555830 133100262716928 run.py:742] (val) algo task_scheduling step 1800: {'selected': 0.9245541838134431, 'score': 0.9245541838134431, 'examples_seen': 24832, 'step': 1800, 'algorithm': 'task_scheduling'}
I0830 18:06:06.556045 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.903, current avg val score is 0.882, val scores are: activity_selector: 0.840, task_scheduling: 0.925
I0830 18:06:07.684834 133100262716928 run.py:707] Algo activity_selector step 1850 current loss 0.985750, current_train_items 25536.
I0830 18:06:07.689516 133100262716928 run.py:707] Algo task_scheduling step 1850 current loss 1.898141, current_train_items 25536.
I0830 18:06:07.707872 133100262716928 run.py:742] (val) algo activity_selector step 1850: {'selected': 0.7820773930753565, 'score': 0.7820773930753565, 'examples_seen': 25536, 'step': 1850, 'algorithm': 'activity_selector'}
I0830 18:06:07.715711 133100262716928 run.py:742] (val) algo task_scheduling step 1850: {'selected': 0.9525222551928783, 'score': 0.9525222551928783, 'examples_seen': 25536, 'step': 1850, 'algorithm': 'task_scheduling'}
I0830 18:06:07.715874 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.903, current avg val score is 0.867, val scores are: activity_selector: 0.782, task_scheduling: 0.953
I0830 18:06:08.847379 133100262716928 run.py:707] Algo activity_selector step 1900 current loss 1.506058, current_train_items 26224.
I0830 18:06:08.852607 133100262716928 run.py:707] Algo task_scheduling step 1900 current loss 2.018999, current_train_items 26224.
I0830 18:06:08.870039 133100262716928 run.py:742] (val) algo activity_selector step 1900: {'selected': 0.8245315161839863, 'score': 0.8245315161839863, 'examples_seen': 26224, 'step': 1900, 'algorithm': 'activity_selector'}
I0830 18:06:08.878026 133100262716928 run.py:742] (val) algo task_scheduling step 1900: {'selected': 0.9358327325162221, 'score': 0.9358327325162221, 'examples_seen': 26224, 'step': 1900, 'algorithm': 'task_scheduling'}
I0830 18:06:08.878202 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.903, current avg val score is 0.880, val scores are: activity_selector: 0.825, task_scheduling: 0.936
I0830 18:06:09.940717 133100262716928 run.py:707] Algo activity_selector step 1950 current loss 0.672342, current_train_items 26912.
I0830 18:06:09.945202 133100262716928 run.py:707] Algo task_scheduling step 1950 current loss 2.558253, current_train_items 26912.
I0830 18:06:09.966043 133100262716928 run.py:742] (val) algo activity_selector step 1950: {'selected': 0.8801571709233792, 'score': 0.8801571709233792, 'examples_seen': 26912, 'step': 1950, 'algorithm': 'activity_selector'}
I0830 18:06:09.973570 133100262716928 run.py:742] (val) algo task_scheduling step 1950: {'selected': 0.9094678645473394, 'score': 0.9094678645473394, 'examples_seen': 26912, 'step': 1950, 'algorithm': 'task_scheduling'}
I0830 18:06:09.973709 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.903, current avg val score is 0.895, val scores are: activity_selector: 0.880, task_scheduling: 0.909
I0830 18:06:11.096860 133100262716928 run.py:707] Algo activity_selector step 2000 current loss 1.187127, current_train_items 27600.
I0830 18:06:11.101688 133100262716928 run.py:707] Algo task_scheduling step 2000 current loss 2.111336, current_train_items 27600.
I0830 18:06:11.119282 133100262716928 run.py:742] (val) algo activity_selector step 2000: {'selected': 0.8740458015267175, 'score': 0.8740458015267175, 'examples_seen': 27600, 'step': 2000, 'algorithm': 'activity_selector'}
I0830 18:06:11.128406 133100262716928 run.py:742] (val) algo task_scheduling step 2000: {'selected': 0.9403973509933774, 'score': 0.9403973509933774, 'examples_seen': 27600, 'step': 2000, 'algorithm': 'task_scheduling'}
I0830 18:06:11.128549 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.903, current avg val score is 0.907, val scores are: activity_selector: 0.874, task_scheduling: 0.940
I0830 18:06:12.212988 133100262716928 run.py:707] Algo activity_selector step 2050 current loss 0.870682, current_train_items 28288.
I0830 18:06:12.217905 133100262716928 run.py:707] Algo task_scheduling step 2050 current loss 2.000335, current_train_items 28288.
I0830 18:06:12.235070 133100262716928 run.py:742] (val) algo activity_selector step 2050: {'selected': 0.8161764705882353, 'score': 0.8161764705882353, 'examples_seen': 28288, 'step': 2050, 'algorithm': 'activity_selector'}
I0830 18:06:12.243151 133100262716928 run.py:742] (val) algo task_scheduling step 2050: {'selected': 0.8987854251012146, 'score': 0.8987854251012146, 'examples_seen': 28288, 'step': 2050, 'algorithm': 'task_scheduling'}
I0830 18:06:12.243296 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.907, current avg val score is 0.857, val scores are: activity_selector: 0.816, task_scheduling: 0.899
I0830 18:06:13.321033 133100262716928 run.py:707] Algo activity_selector step 2100 current loss 1.261947, current_train_items 28976.
I0830 18:06:13.325552 133100262716928 run.py:707] Algo task_scheduling step 2100 current loss 2.548267, current_train_items 28976.
I0830 18:06:13.342787 133100262716928 run.py:742] (val) algo activity_selector step 2100: {'selected': 0.860759493670886, 'score': 0.860759493670886, 'examples_seen': 28976, 'step': 2100, 'algorithm': 'activity_selector'}
I0830 18:06:13.350353 133100262716928 run.py:742] (val) algo task_scheduling step 2100: {'selected': 0.9363831308077197, 'score': 0.9363831308077197, 'examples_seen': 28976, 'step': 2100, 'algorithm': 'task_scheduling'}
I0830 18:06:13.350493 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.907, current avg val score is 0.899, val scores are: activity_selector: 0.861, task_scheduling: 0.936
I0830 18:06:14.401543 133100262716928 run.py:707] Algo activity_selector step 2150 current loss 1.004026, current_train_items 29664.
I0830 18:06:14.406453 133100262716928 run.py:707] Algo task_scheduling step 2150 current loss 1.903412, current_train_items 29664.
I0830 18:06:14.422875 133100262716928 run.py:742] (val) algo activity_selector step 2150: {'selected': 0.8333333333333334, 'score': 0.8333333333333334, 'examples_seen': 29664, 'step': 2150, 'algorithm': 'activity_selector'}
I0830 18:06:14.430410 133100262716928 run.py:742] (val) algo task_scheduling step 2150: {'selected': 0.9221394719025051, 'score': 0.9221394719025051, 'examples_seen': 29664, 'step': 2150, 'algorithm': 'task_scheduling'}
I0830 18:06:14.430552 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.907, current avg val score is 0.878, val scores are: activity_selector: 0.833, task_scheduling: 0.922
I0830 18:06:15.480727 133100262716928 run.py:707] Algo activity_selector step 2200 current loss 1.276607, current_train_items 30368.
I0830 18:06:15.485422 133100262716928 run.py:707] Algo task_scheduling step 2200 current loss 1.688324, current_train_items 30368.
I0830 18:06:15.502574 133100262716928 run.py:742] (val) algo activity_selector step 2200: {'selected': 0.8571428571428571, 'score': 0.8571428571428571, 'examples_seen': 30368, 'step': 2200, 'algorithm': 'activity_selector'}
I0830 18:06:15.511141 133100262716928 run.py:742] (val) algo task_scheduling step 2200: {'selected': 0.9332365747460087, 'score': 0.9332365747460087, 'examples_seen': 30368, 'step': 2200, 'algorithm': 'task_scheduling'}
I0830 18:06:15.511290 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.907, current avg val score is 0.895, val scores are: activity_selector: 0.857, task_scheduling: 0.933
I0830 18:06:16.614609 133100262716928 run.py:707] Algo activity_selector step 2250 current loss 0.650932, current_train_items 31040.
I0830 18:06:16.619192 133100262716928 run.py:707] Algo task_scheduling step 2250 current loss 2.976044, current_train_items 31040.
I0830 18:06:16.636657 133100262716928 run.py:742] (val) algo activity_selector step 2250: {'selected': 0.816793893129771, 'score': 0.816793893129771, 'examples_seen': 31040, 'step': 2250, 'algorithm': 'activity_selector'}
I0830 18:06:16.645140 133100262716928 run.py:742] (val) algo task_scheduling step 2250: {'selected': 0.9125000000000001, 'score': 0.9125000000000001, 'examples_seen': 31040, 'step': 2250, 'algorithm': 'task_scheduling'}
I0830 18:06:16.645286 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.907, current avg val score is 0.865, val scores are: activity_selector: 0.817, task_scheduling: 0.913
I0830 18:06:17.776829 133100262716928 run.py:707] Algo activity_selector step 2300 current loss 0.700373, current_train_items 31728.
I0830 18:06:17.781788 133100262716928 run.py:707] Algo task_scheduling step 2300 current loss 1.799479, current_train_items 31728.
I0830 18:06:17.802495 133100262716928 run.py:742] (val) algo activity_selector step 2300: {'selected': 0.8754578754578753, 'score': 0.8754578754578753, 'examples_seen': 31728, 'step': 2300, 'algorithm': 'activity_selector'}
I0830 18:06:17.810381 133100262716928 run.py:742] (val) algo task_scheduling step 2300: {'selected': 0.9322879543834639, 'score': 0.9322879543834639, 'examples_seen': 31728, 'step': 2300, 'algorithm': 'task_scheduling'}
I0830 18:06:17.810531 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.907, current avg val score is 0.904, val scores are: activity_selector: 0.875, task_scheduling: 0.932
I0830 18:06:18.910600 133100262716928 run.py:707] Algo activity_selector step 2350 current loss 0.760265, current_train_items 32432.
I0830 18:06:18.915252 133100262716928 run.py:707] Algo task_scheduling step 2350 current loss 1.771162, current_train_items 32432.
I0830 18:06:18.933063 133100262716928 run.py:742] (val) algo activity_selector step 2350: {'selected': 0.896797153024911, 'score': 0.896797153024911, 'examples_seen': 32432, 'step': 2350, 'algorithm': 'activity_selector'}
I0830 18:06:18.940809 133100262716928 run.py:742] (val) algo task_scheduling step 2350: {'selected': 0.9397058823529412, 'score': 0.9397058823529412, 'examples_seen': 32432, 'step': 2350, 'algorithm': 'task_scheduling'}
I0830 18:06:18.940958 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.907, current avg val score is 0.918, val scores are: activity_selector: 0.897, task_scheduling: 0.940
I0830 18:06:20.029767 133100262716928 run.py:707] Algo activity_selector step 2400 current loss 1.296868, current_train_items 33104.
I0830 18:06:20.034238 133100262716928 run.py:707] Algo task_scheduling step 2400 current loss 1.803691, current_train_items 33104.
I0830 18:06:20.051290 133100262716928 run.py:742] (val) algo activity_selector step 2400: {'selected': 0.8533834586466166, 'score': 0.8533834586466166, 'examples_seen': 33104, 'step': 2400, 'algorithm': 'activity_selector'}
I0830 18:06:20.059040 133100262716928 run.py:742] (val) algo task_scheduling step 2400: {'selected': 0.9301038062283736, 'score': 0.9301038062283736, 'examples_seen': 33104, 'step': 2400, 'algorithm': 'task_scheduling'}
I0830 18:06:20.059201 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.918, current avg val score is 0.892, val scores are: activity_selector: 0.853, task_scheduling: 0.930
I0830 18:06:21.169462 133100262716928 run.py:707] Algo activity_selector step 2450 current loss 1.037791, current_train_items 33808.
I0830 18:06:21.173899 133100262716928 run.py:707] Algo task_scheduling step 2450 current loss 1.597950, current_train_items 33808.
I0830 18:06:21.191820 133100262716928 run.py:742] (val) algo activity_selector step 2450: {'selected': 0.8592057761732852, 'score': 0.8592057761732852, 'examples_seen': 33808, 'step': 2450, 'algorithm': 'activity_selector'}
I0830 18:06:21.199709 133100262716928 run.py:742] (val) algo task_scheduling step 2450: {'selected': 0.9288702928870293, 'score': 0.9288702928870293, 'examples_seen': 33808, 'step': 2450, 'algorithm': 'task_scheduling'}
I0830 18:06:21.199854 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.918, current avg val score is 0.894, val scores are: activity_selector: 0.859, task_scheduling: 0.929
I0830 18:06:22.266851 133100262716928 run.py:707] Algo activity_selector step 2500 current loss 0.740108, current_train_items 34496.
I0830 18:06:22.272042 133100262716928 run.py:707] Algo task_scheduling step 2500 current loss 2.193009, current_train_items 34496.
I0830 18:06:22.291862 133100262716928 run.py:742] (val) algo activity_selector step 2500: {'selected': 0.8656126482213439, 'score': 0.8656126482213439, 'examples_seen': 34496, 'step': 2500, 'algorithm': 'activity_selector'}
I0830 18:06:22.299818 133100262716928 run.py:742] (val) algo task_scheduling step 2500: {'selected': 0.9339887640449438, 'score': 0.9339887640449438, 'examples_seen': 34496, 'step': 2500, 'algorithm': 'task_scheduling'}
I0830 18:06:22.299996 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.918, current avg val score is 0.900, val scores are: activity_selector: 0.866, task_scheduling: 0.934
I0830 18:06:23.443498 133100262716928 run.py:707] Algo activity_selector step 2550 current loss 0.982017, current_train_items 35184.
I0830 18:06:23.448109 133100262716928 run.py:707] Algo task_scheduling step 2550 current loss 1.720274, current_train_items 35184.
I0830 18:06:23.465401 133100262716928 run.py:742] (val) algo activity_selector step 2550: {'selected': 0.8610567514677104, 'score': 0.8610567514677104, 'examples_seen': 35184, 'step': 2550, 'algorithm': 'activity_selector'}
I0830 18:06:23.473525 133100262716928 run.py:742] (val) algo task_scheduling step 2550: {'selected': 0.9345279117849759, 'score': 0.9345279117849759, 'examples_seen': 35184, 'step': 2550, 'algorithm': 'task_scheduling'}
I0830 18:06:23.473669 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.918, current avg val score is 0.898, val scores are: activity_selector: 0.861, task_scheduling: 0.935
I0830 18:06:24.604758 133100262716928 run.py:707] Algo activity_selector step 2600 current loss 0.788367, current_train_items 35872.
I0830 18:06:24.609568 133100262716928 run.py:707] Algo task_scheduling step 2600 current loss 1.810876, current_train_items 35872.
I0830 18:06:24.627637 133100262716928 run.py:742] (val) algo activity_selector step 2600: {'selected': 0.8301886792452831, 'score': 0.8301886792452831, 'examples_seen': 35872, 'step': 2600, 'algorithm': 'activity_selector'}
I0830 18:06:24.635204 133100262716928 run.py:742] (val) algo task_scheduling step 2600: {'selected': 0.9102564102564102, 'score': 0.9102564102564102, 'examples_seen': 35872, 'step': 2600, 'algorithm': 'task_scheduling'}
I0830 18:06:24.635344 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.918, current avg val score is 0.870, val scores are: activity_selector: 0.830, task_scheduling: 0.910
I0830 18:06:25.682249 133100262716928 run.py:707] Algo activity_selector step 2650 current loss 0.950282, current_train_items 36560.
I0830 18:06:25.686733 133100262716928 run.py:707] Algo task_scheduling step 2650 current loss 2.211297, current_train_items 36560.
I0830 18:06:25.705403 133100262716928 run.py:742] (val) algo activity_selector step 2650: {'selected': 0.8500881834215168, 'score': 0.8500881834215168, 'examples_seen': 36560, 'step': 2650, 'algorithm': 'activity_selector'}
I0830 18:06:25.713662 133100262716928 run.py:742] (val) algo task_scheduling step 2650: {'selected': 0.9433691756272401, 'score': 0.9433691756272401, 'examples_seen': 36560, 'step': 2650, 'algorithm': 'task_scheduling'}
I0830 18:06:25.713818 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.918, current avg val score is 0.897, val scores are: activity_selector: 0.850, task_scheduling: 0.943
I0830 18:06:27.085021 133100262716928 run.py:707] Algo activity_selector step 2700 current loss 0.667863, current_train_items 37248.
I0830 18:06:27.089628 133100262716928 run.py:707] Algo task_scheduling step 2700 current loss 1.654925, current_train_items 37248.
I0830 18:06:27.108837 133100262716928 run.py:742] (val) algo activity_selector step 2700: {'selected': 0.8787878787878788, 'score': 0.8787878787878788, 'examples_seen': 37248, 'step': 2700, 'algorithm': 'activity_selector'}
I0830 18:06:27.116740 133100262716928 run.py:742] (val) algo task_scheduling step 2700: {'selected': 0.9164265129682997, 'score': 0.9164265129682997, 'examples_seen': 37248, 'step': 2700, 'algorithm': 'task_scheduling'}
I0830 18:06:27.116891 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.918, current avg val score is 0.898, val scores are: activity_selector: 0.879, task_scheduling: 0.916
I0830 18:06:28.220568 133100262716928 run.py:707] Algo activity_selector step 2750 current loss 1.073545, current_train_items 37936.
I0830 18:06:28.225353 133100262716928 run.py:707] Algo task_scheduling step 2750 current loss 2.122930, current_train_items 37936.
I0830 18:06:28.242659 133100262716928 run.py:742] (val) algo activity_selector step 2750: {'selected': 0.8702010968921389, 'score': 0.8702010968921389, 'examples_seen': 37936, 'step': 2750, 'algorithm': 'activity_selector'}
I0830 18:06:28.250240 133100262716928 run.py:742] (val) algo task_scheduling step 2750: {'selected': 0.9335324869305451, 'score': 0.9335324869305451, 'examples_seen': 37936, 'step': 2750, 'algorithm': 'task_scheduling'}
I0830 18:06:28.250382 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.918, current avg val score is 0.902, val scores are: activity_selector: 0.870, task_scheduling: 0.934
I0830 18:06:29.313353 133100262716928 run.py:707] Algo activity_selector step 2800 current loss 0.696813, current_train_items 38640.
I0830 18:06:29.317920 133100262716928 run.py:707] Algo task_scheduling step 2800 current loss 3.014156, current_train_items 38640.
I0830 18:06:29.333993 133100262716928 run.py:742] (val) algo activity_selector step 2800: {'selected': 0.84251968503937, 'score': 0.84251968503937, 'examples_seen': 38640, 'step': 2800, 'algorithm': 'activity_selector'}
I0830 18:06:29.341640 133100262716928 run.py:742] (val) algo task_scheduling step 2800: {'selected': 0.889945652173913, 'score': 0.889945652173913, 'examples_seen': 38640, 'step': 2800, 'algorithm': 'task_scheduling'}
I0830 18:06:29.341778 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.918, current avg val score is 0.866, val scores are: activity_selector: 0.843, task_scheduling: 0.890
I0830 18:06:30.421612 133100262716928 run.py:707] Algo activity_selector step 2850 current loss 0.926808, current_train_items 39312.
I0830 18:06:30.426521 133100262716928 run.py:707] Algo task_scheduling step 2850 current loss 1.624197, current_train_items 39312.
I0830 18:06:30.445084 133100262716928 run.py:742] (val) algo activity_selector step 2850: {'selected': 0.8657314629258517, 'score': 0.8657314629258517, 'examples_seen': 39312, 'step': 2850, 'algorithm': 'activity_selector'}
I0830 18:06:30.452605 133100262716928 run.py:742] (val) algo task_scheduling step 2850: {'selected': 0.9133425034387895, 'score': 0.9133425034387895, 'examples_seen': 39312, 'step': 2850, 'algorithm': 'task_scheduling'}
I0830 18:06:30.452751 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.918, current avg val score is 0.890, val scores are: activity_selector: 0.866, task_scheduling: 0.913
I0830 18:06:31.565626 133100262716928 run.py:707] Algo activity_selector step 2900 current loss 0.685727, current_train_items 40016.
I0830 18:06:31.570121 133100262716928 run.py:707] Algo task_scheduling step 2900 current loss 2.659869, current_train_items 40016.
I0830 18:06:31.586686 133100262716928 run.py:742] (val) algo activity_selector step 2900: {'selected': 0.8221343873517787, 'score': 0.8221343873517787, 'examples_seen': 40016, 'step': 2900, 'algorithm': 'activity_selector'}
I0830 18:06:31.594262 133100262716928 run.py:742] (val) algo task_scheduling step 2900: {'selected': 0.9101123595505618, 'score': 0.9101123595505618, 'examples_seen': 40016, 'step': 2900, 'algorithm': 'task_scheduling'}
I0830 18:06:31.594412 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.918, current avg val score is 0.866, val scores are: activity_selector: 0.822, task_scheduling: 0.910
I0830 18:06:32.678139 133100262716928 run.py:707] Algo activity_selector step 2950 current loss 0.735133, current_train_items 40704.
I0830 18:06:32.682637 133100262716928 run.py:707] Algo task_scheduling step 2950 current loss 1.595753, current_train_items 40704.
I0830 18:06:32.699073 133100262716928 run.py:742] (val) algo activity_selector step 2950: {'selected': 0.8745247148288975, 'score': 0.8745247148288975, 'examples_seen': 40704, 'step': 2950, 'algorithm': 'activity_selector'}
I0830 18:06:32.706729 133100262716928 run.py:742] (val) algo task_scheduling step 2950: {'selected': 0.9446870451237264, 'score': 0.9446870451237264, 'examples_seen': 40704, 'step': 2950, 'algorithm': 'task_scheduling'}
I0830 18:06:32.706871 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.918, current avg val score is 0.910, val scores are: activity_selector: 0.875, task_scheduling: 0.945
I0830 18:06:33.790537 133100262716928 run.py:707] Algo activity_selector step 3000 current loss 0.741046, current_train_items 41376.
I0830 18:06:33.795069 133100262716928 run.py:707] Algo task_scheduling step 3000 current loss 1.430212, current_train_items 41376.
I0830 18:06:33.812355 133100262716928 run.py:742] (val) algo activity_selector step 3000: {'selected': 0.8540925266903915, 'score': 0.8540925266903915, 'examples_seen': 41376, 'step': 3000, 'algorithm': 'activity_selector'}
I0830 18:06:33.819906 133100262716928 run.py:742] (val) algo task_scheduling step 3000: {'selected': 0.9364081062194269, 'score': 0.9364081062194269, 'examples_seen': 41376, 'step': 3000, 'algorithm': 'task_scheduling'}
I0830 18:06:33.820045 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.918, current avg val score is 0.895, val scores are: activity_selector: 0.854, task_scheduling: 0.936
I0830 18:06:34.895603 133100262716928 run.py:707] Algo activity_selector step 3050 current loss 0.898446, current_train_items 42080.
I0830 18:06:34.900136 133100262716928 run.py:707] Algo task_scheduling step 3050 current loss 1.732260, current_train_items 42080.
I0830 18:06:34.917173 133100262716928 run.py:742] (val) algo activity_selector step 3050: {'selected': 0.8605108055009822, 'score': 0.8605108055009822, 'examples_seen': 42080, 'step': 3050, 'algorithm': 'activity_selector'}
I0830 18:06:34.924628 133100262716928 run.py:742] (val) algo task_scheduling step 3050: {'selected': 0.9333333333333332, 'score': 0.9333333333333332, 'examples_seen': 42080, 'step': 3050, 'algorithm': 'task_scheduling'}
I0830 18:06:34.924767 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.918, current avg val score is 0.897, val scores are: activity_selector: 0.861, task_scheduling: 0.933
I0830 18:06:35.984875 133100262716928 run.py:707] Algo activity_selector step 3100 current loss 0.708341, current_train_items 42768.
I0830 18:06:35.989502 133100262716928 run.py:707] Algo task_scheduling step 3100 current loss 1.377085, current_train_items 42768.
I0830 18:06:36.006647 133100262716928 run.py:742] (val) algo activity_selector step 3100: {'selected': 0.866785079928952, 'score': 0.866785079928952, 'examples_seen': 42768, 'step': 3100, 'algorithm': 'activity_selector'}
I0830 18:06:36.014145 133100262716928 run.py:742] (val) algo task_scheduling step 3100: {'selected': 0.9336188436830836, 'score': 0.9336188436830836, 'examples_seen': 42768, 'step': 3100, 'algorithm': 'task_scheduling'}
I0830 18:06:36.014295 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.918, current avg val score is 0.900, val scores are: activity_selector: 0.867, task_scheduling: 0.934
I0830 18:06:37.058454 133100262716928 run.py:707] Algo activity_selector step 3150 current loss 0.595860, current_train_items 43440.
I0830 18:06:37.062911 133100262716928 run.py:707] Algo task_scheduling step 3150 current loss 1.721873, current_train_items 43440.
I0830 18:06:37.079848 133100262716928 run.py:742] (val) algo activity_selector step 3150: {'selected': 0.8612099644128113, 'score': 0.8612099644128113, 'examples_seen': 43440, 'step': 3150, 'algorithm': 'activity_selector'}
I0830 18:06:37.087345 133100262716928 run.py:742] (val) algo task_scheduling step 3150: {'selected': 0.9094678645473393, 'score': 0.9094678645473393, 'examples_seen': 43440, 'step': 3150, 'algorithm': 'task_scheduling'}
I0830 18:06:37.087484 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.918, current avg val score is 0.885, val scores are: activity_selector: 0.861, task_scheduling: 0.909
I0830 18:06:38.160599 133100262716928 run.py:707] Algo activity_selector step 3200 current loss 0.736799, current_train_items 44144.
I0830 18:06:38.165459 133100262716928 run.py:707] Algo task_scheduling step 3200 current loss 1.745384, current_train_items 44144.
I0830 18:06:38.181926 133100262716928 run.py:742] (val) algo activity_selector step 3200: {'selected': 0.8740458015267176, 'score': 0.8740458015267176, 'examples_seen': 44144, 'step': 3200, 'algorithm': 'activity_selector'}
I0830 18:06:38.189539 133100262716928 run.py:742] (val) algo task_scheduling step 3200: {'selected': 0.9121171770972036, 'score': 0.9121171770972036, 'examples_seen': 44144, 'step': 3200, 'algorithm': 'task_scheduling'}
I0830 18:06:38.189682 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.918, current avg val score is 0.893, val scores are: activity_selector: 0.874, task_scheduling: 0.912
I0830 18:06:39.251598 133100262716928 run.py:707] Algo activity_selector step 3250 current loss 1.001106, current_train_items 44848.
I0830 18:06:39.256237 133100262716928 run.py:707] Algo task_scheduling step 3250 current loss 1.512305, current_train_items 44848.
I0830 18:06:39.273718 133100262716928 run.py:742] (val) algo activity_selector step 3250: {'selected': 0.9073724007561437, 'score': 0.9073724007561437, 'examples_seen': 44848, 'step': 3250, 'algorithm': 'activity_selector'}
I0830 18:06:39.281329 133100262716928 run.py:742] (val) algo task_scheduling step 3250: {'selected': 0.9393290506780871, 'score': 0.9393290506780871, 'examples_seen': 44848, 'step': 3250, 'algorithm': 'task_scheduling'}
I0830 18:06:39.281476 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.918, current avg val score is 0.923, val scores are: activity_selector: 0.907, task_scheduling: 0.939
I0830 18:06:40.379342 133100262716928 run.py:707] Algo activity_selector step 3300 current loss 0.964859, current_train_items 45520.
I0830 18:06:40.384011 133100262716928 run.py:707] Algo task_scheduling step 3300 current loss 1.376340, current_train_items 45520.
I0830 18:06:40.401408 133100262716928 run.py:742] (val) algo activity_selector step 3300: {'selected': 0.8704453441295548, 'score': 0.8704453441295548, 'examples_seen': 45520, 'step': 3300, 'algorithm': 'activity_selector'}
I0830 18:06:40.410489 133100262716928 run.py:742] (val) algo task_scheduling step 3300: {'selected': 0.9245411284840246, 'score': 0.9245411284840246, 'examples_seen': 45520, 'step': 3300, 'algorithm': 'task_scheduling'}
I0830 18:06:40.410633 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.897, val scores are: activity_selector: 0.870, task_scheduling: 0.925
I0830 18:06:41.507040 133100262716928 run.py:707] Algo activity_selector step 3350 current loss 0.902493, current_train_items 46208.
I0830 18:06:41.511730 133100262716928 run.py:707] Algo task_scheduling step 3350 current loss 1.499454, current_train_items 46208.
I0830 18:06:41.529034 133100262716928 run.py:742] (val) algo activity_selector step 3350: {'selected': 0.8449197860962567, 'score': 0.8449197860962567, 'examples_seen': 46208, 'step': 3350, 'algorithm': 'activity_selector'}
I0830 18:06:41.536750 133100262716928 run.py:742] (val) algo task_scheduling step 3350: {'selected': 0.9369241672572645, 'score': 0.9369241672572645, 'examples_seen': 46208, 'step': 3350, 'algorithm': 'task_scheduling'}
I0830 18:06:41.536902 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.891, val scores are: activity_selector: 0.845, task_scheduling: 0.937
I0830 18:06:42.637825 133100262716928 run.py:707] Algo activity_selector step 3400 current loss 0.674566, current_train_items 46912.
I0830 18:06:42.642721 133100262716928 run.py:707] Algo task_scheduling step 3400 current loss 2.495195, current_train_items 46912.
I0830 18:06:42.659717 133100262716928 run.py:742] (val) algo activity_selector step 3400: {'selected': 0.9120879120879121, 'score': 0.9120879120879121, 'examples_seen': 46912, 'step': 3400, 'algorithm': 'activity_selector'}
I0830 18:06:42.667441 133100262716928 run.py:742] (val) algo task_scheduling step 3400: {'selected': 0.9375886524822694, 'score': 0.9375886524822694, 'examples_seen': 46912, 'step': 3400, 'algorithm': 'task_scheduling'}
I0830 18:06:42.667590 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.923, current avg val score is 0.925, val scores are: activity_selector: 0.912, task_scheduling: 0.938
I0830 18:06:43.785151 133100262716928 run.py:707] Algo activity_selector step 3450 current loss 0.550557, current_train_items 47584.
I0830 18:06:43.789652 133100262716928 run.py:707] Algo task_scheduling step 3450 current loss 1.522194, current_train_items 47584.
I0830 18:06:43.806873 133100262716928 run.py:742] (val) algo activity_selector step 3450: {'selected': 0.8373015873015872, 'score': 0.8373015873015872, 'examples_seen': 47584, 'step': 3450, 'algorithm': 'activity_selector'}
I0830 18:06:43.814391 133100262716928 run.py:742] (val) algo task_scheduling step 3450: {'selected': 0.9318497913769124, 'score': 0.9318497913769124, 'examples_seen': 47584, 'step': 3450, 'algorithm': 'task_scheduling'}
I0830 18:06:43.814533 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.885, val scores are: activity_selector: 0.837, task_scheduling: 0.932
I0830 18:06:44.886910 133100262716928 run.py:707] Algo activity_selector step 3500 current loss 0.807008, current_train_items 48272.
I0830 18:06:44.891551 133100262716928 run.py:707] Algo task_scheduling step 3500 current loss 1.629972, current_train_items 48272.
I0830 18:06:44.909932 133100262716928 run.py:742] (val) algo activity_selector step 3500: {'selected': 0.8755020080321286, 'score': 0.8755020080321286, 'examples_seen': 48272, 'step': 3500, 'algorithm': 'activity_selector'}
I0830 18:06:44.918255 133100262716928 run.py:742] (val) algo task_scheduling step 3500: {'selected': 0.9306518723994452, 'score': 0.9306518723994452, 'examples_seen': 48272, 'step': 3500, 'algorithm': 'task_scheduling'}
I0830 18:06:44.918401 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.903, val scores are: activity_selector: 0.876, task_scheduling: 0.931
I0830 18:06:46.011194 133100262716928 run.py:707] Algo activity_selector step 3550 current loss 0.770638, current_train_items 48976.
I0830 18:06:46.015780 133100262716928 run.py:707] Algo task_scheduling step 3550 current loss 2.077871, current_train_items 48976.
I0830 18:06:46.033723 133100262716928 run.py:742] (val) algo activity_selector step 3550: {'selected': 0.8577319587628865, 'score': 0.8577319587628865, 'examples_seen': 48976, 'step': 3550, 'algorithm': 'activity_selector'}
I0830 18:06:46.041443 133100262716928 run.py:742] (val) algo task_scheduling step 3550: {'selected': 0.9030544488711819, 'score': 0.9030544488711819, 'examples_seen': 48976, 'step': 3550, 'algorithm': 'task_scheduling'}
I0830 18:06:46.041583 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.880, val scores are: activity_selector: 0.858, task_scheduling: 0.903
I0830 18:06:47.119200 133100262716928 run.py:707] Algo activity_selector step 3600 current loss 0.847260, current_train_items 49664.
I0830 18:06:47.123634 133100262716928 run.py:707] Algo task_scheduling step 3600 current loss 1.796477, current_train_items 49664.
I0830 18:06:47.140427 133100262716928 run.py:742] (val) algo activity_selector step 3600: {'selected': 0.9200779727095516, 'score': 0.9200779727095516, 'examples_seen': 49664, 'step': 3600, 'algorithm': 'activity_selector'}
I0830 18:06:47.148020 133100262716928 run.py:742] (val) algo task_scheduling step 3600: {'selected': 0.929144385026738, 'score': 0.929144385026738, 'examples_seen': 49664, 'step': 3600, 'algorithm': 'task_scheduling'}
I0830 18:06:47.148169 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.925, val scores are: activity_selector: 0.920, task_scheduling: 0.929
I0830 18:06:48.225191 133100262716928 run.py:707] Algo activity_selector step 3650 current loss 0.639348, current_train_items 50352.
I0830 18:06:48.229679 133100262716928 run.py:707] Algo task_scheduling step 3650 current loss 1.618425, current_train_items 50352.
I0830 18:06:48.247100 133100262716928 run.py:742] (val) algo activity_selector step 3650: {'selected': 0.8979591836734694, 'score': 0.8979591836734694, 'examples_seen': 50352, 'step': 3650, 'algorithm': 'activity_selector'}
I0830 18:06:48.254763 133100262716928 run.py:742] (val) algo task_scheduling step 3650: {'selected': 0.9302325581395349, 'score': 0.9302325581395349, 'examples_seen': 50352, 'step': 3650, 'algorithm': 'task_scheduling'}
I0830 18:06:48.254904 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.914, val scores are: activity_selector: 0.898, task_scheduling: 0.930
I0830 18:06:49.325784 133100262716928 run.py:707] Algo activity_selector step 3700 current loss 1.202932, current_train_items 51040.
I0830 18:06:49.330542 133100262716928 run.py:707] Algo task_scheduling step 3700 current loss 1.371886, current_train_items 51040.
I0830 18:06:49.348296 133100262716928 run.py:742] (val) algo activity_selector step 3700: {'selected': 0.8501026694045175, 'score': 0.8501026694045175, 'examples_seen': 51040, 'step': 3700, 'algorithm': 'activity_selector'}
I0830 18:06:49.355844 133100262716928 run.py:742] (val) algo task_scheduling step 3700: {'selected': 0.9340735600277585, 'score': 0.9340735600277585, 'examples_seen': 51040, 'step': 3700, 'algorithm': 'task_scheduling'}
I0830 18:06:49.355995 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.892, val scores are: activity_selector: 0.850, task_scheduling: 0.934
I0830 18:06:50.452694 133100262716928 run.py:707] Algo activity_selector step 3750 current loss 1.080940, current_train_items 51728.
I0830 18:06:50.457145 133100262716928 run.py:707] Algo task_scheduling step 3750 current loss 2.302537, current_train_items 51728.
I0830 18:06:50.474361 133100262716928 run.py:742] (val) algo activity_selector step 3750: {'selected': 0.8599221789883268, 'score': 0.8599221789883268, 'examples_seen': 51728, 'step': 3750, 'algorithm': 'activity_selector'}
I0830 18:06:50.481952 133100262716928 run.py:742] (val) algo task_scheduling step 3750: {'selected': 0.9258997882851093, 'score': 0.9258997882851093, 'examples_seen': 51728, 'step': 3750, 'algorithm': 'task_scheduling'}
I0830 18:06:50.482093 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.893, val scores are: activity_selector: 0.860, task_scheduling: 0.926
I0830 18:06:51.558572 133100262716928 run.py:707] Algo activity_selector step 3800 current loss 0.694126, current_train_items 52416.
I0830 18:06:51.563026 133100262716928 run.py:707] Algo task_scheduling step 3800 current loss 1.770777, current_train_items 52416.
I0830 18:06:51.580020 133100262716928 run.py:742] (val) algo activity_selector step 3800: {'selected': 0.89811320754717, 'score': 0.89811320754717, 'examples_seen': 52416, 'step': 3800, 'algorithm': 'activity_selector'}
I0830 18:06:51.587532 133100262716928 run.py:742] (val) algo task_scheduling step 3800: {'selected': 0.913223140495868, 'score': 0.913223140495868, 'examples_seen': 52416, 'step': 3800, 'algorithm': 'task_scheduling'}
I0830 18:06:51.587675 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.906, val scores are: activity_selector: 0.898, task_scheduling: 0.913
I0830 18:06:52.654431 133100262716928 run.py:707] Algo activity_selector step 3850 current loss 1.262233, current_train_items 53104.
I0830 18:06:52.659136 133100262716928 run.py:707] Algo task_scheduling step 3850 current loss 1.495350, current_train_items 53104.
I0830 18:06:52.676573 133100262716928 run.py:742] (val) algo activity_selector step 3850: {'selected': 0.7970749542961609, 'score': 0.7970749542961609, 'examples_seen': 53104, 'step': 3850, 'algorithm': 'activity_selector'}
I0830 18:06:52.684148 133100262716928 run.py:742] (val) algo task_scheduling step 3850: {'selected': 0.9418439716312056, 'score': 0.9418439716312056, 'examples_seen': 53104, 'step': 3850, 'algorithm': 'task_scheduling'}
I0830 18:06:52.684299 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.869, val scores are: activity_selector: 0.797, task_scheduling: 0.942
I0830 18:06:53.785227 133100262716928 run.py:707] Algo activity_selector step 3900 current loss 0.507412, current_train_items 53792.
I0830 18:06:53.790254 133100262716928 run.py:707] Algo task_scheduling step 3900 current loss 1.496209, current_train_items 53792.
I0830 18:06:53.807870 133100262716928 run.py:742] (val) algo activity_selector step 3900: {'selected': 0.8892988929889298, 'score': 0.8892988929889298, 'examples_seen': 53792, 'step': 3900, 'algorithm': 'activity_selector'}
I0830 18:06:53.815556 133100262716928 run.py:742] (val) algo task_scheduling step 3900: {'selected': 0.9305555555555556, 'score': 0.9305555555555556, 'examples_seen': 53792, 'step': 3900, 'algorithm': 'task_scheduling'}
I0830 18:06:53.815711 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.910, val scores are: activity_selector: 0.889, task_scheduling: 0.931
I0830 18:06:54.901297 133100262716928 run.py:707] Algo activity_selector step 3950 current loss 0.965219, current_train_items 54496.
I0830 18:06:54.905724 133100262716928 run.py:707] Algo task_scheduling step 3950 current loss 2.530499, current_train_items 54496.
I0830 18:06:54.922780 133100262716928 run.py:742] (val) algo activity_selector step 3950: {'selected': 0.8931297709923665, 'score': 0.8931297709923665, 'examples_seen': 54496, 'step': 3950, 'algorithm': 'activity_selector'}
I0830 18:06:54.930410 133100262716928 run.py:742] (val) algo task_scheduling step 3950: {'selected': 0.9429978888106968, 'score': 0.9429978888106968, 'examples_seen': 54496, 'step': 3950, 'algorithm': 'task_scheduling'}
I0830 18:06:54.930563 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.918, val scores are: activity_selector: 0.893, task_scheduling: 0.943
I0830 18:06:55.973506 133100262716928 run.py:707] Algo activity_selector step 4000 current loss 1.112607, current_train_items 55168.
I0830 18:06:55.978100 133100262716928 run.py:707] Algo task_scheduling step 4000 current loss 1.312035, current_train_items 55168.
I0830 18:06:55.994609 133100262716928 run.py:742] (val) algo activity_selector step 4000: {'selected': 0.8336842105263158, 'score': 0.8336842105263158, 'examples_seen': 55168, 'step': 4000, 'algorithm': 'activity_selector'}
I0830 18:06:56.002243 133100262716928 run.py:742] (val) algo task_scheduling step 4000: {'selected': 0.9304286718200984, 'score': 0.9304286718200984, 'examples_seen': 55168, 'step': 4000, 'algorithm': 'task_scheduling'}
I0830 18:06:56.002398 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.882, val scores are: activity_selector: 0.834, task_scheduling: 0.930
I0830 18:06:57.090991 133100262716928 run.py:707] Algo activity_selector step 4050 current loss 0.895018, current_train_items 55856.
I0830 18:06:57.095580 133100262716928 run.py:707] Algo task_scheduling step 4050 current loss 2.293968, current_train_items 55856.
I0830 18:06:57.112079 133100262716928 run.py:742] (val) algo activity_selector step 4050: {'selected': 0.8593749999999999, 'score': 0.8593749999999999, 'examples_seen': 55856, 'step': 4050, 'algorithm': 'activity_selector'}
I0830 18:06:57.119824 133100262716928 run.py:742] (val) algo task_scheduling step 4050: {'selected': 0.8790915163660654, 'score': 0.8790915163660654, 'examples_seen': 55856, 'step': 4050, 'algorithm': 'task_scheduling'}
I0830 18:06:57.119966 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.869, val scores are: activity_selector: 0.859, task_scheduling: 0.879
I0830 18:06:58.207764 133100262716928 run.py:707] Algo activity_selector step 4100 current loss 0.547135, current_train_items 56560.
I0830 18:06:58.212190 133100262716928 run.py:707] Algo task_scheduling step 4100 current loss 1.293688, current_train_items 56560.
I0830 18:06:58.229150 133100262716928 run.py:742] (val) algo activity_selector step 4100: {'selected': 0.8840864440078585, 'score': 0.8840864440078585, 'examples_seen': 56560, 'step': 4100, 'algorithm': 'activity_selector'}
I0830 18:06:58.236768 133100262716928 run.py:742] (val) algo task_scheduling step 4100: {'selected': 0.9421602787456447, 'score': 0.9421602787456447, 'examples_seen': 56560, 'step': 4100, 'algorithm': 'task_scheduling'}
I0830 18:06:58.236909 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.913, val scores are: activity_selector: 0.884, task_scheduling: 0.942
I0830 18:06:59.292558 133100262716928 run.py:707] Algo activity_selector step 4150 current loss 1.072551, current_train_items 57248.
I0830 18:06:59.297183 133100262716928 run.py:707] Algo task_scheduling step 4150 current loss 1.211784, current_train_items 57248.
I0830 18:06:59.313942 133100262716928 run.py:742] (val) algo activity_selector step 4150: {'selected': 0.8638838475499092, 'score': 0.8638838475499092, 'examples_seen': 57248, 'step': 4150, 'algorithm': 'activity_selector'}
I0830 18:06:59.321592 133100262716928 run.py:742] (val) algo task_scheduling step 4150: {'selected': 0.9232934553131598, 'score': 0.9232934553131598, 'examples_seen': 57248, 'step': 4150, 'algorithm': 'task_scheduling'}
I0830 18:06:59.321737 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.894, val scores are: activity_selector: 0.864, task_scheduling: 0.923
I0830 18:07:00.394242 133100262716928 run.py:707] Algo activity_selector step 4200 current loss 0.913320, current_train_items 57920.
I0830 18:07:00.399392 133100262716928 run.py:707] Algo task_scheduling step 4200 current loss 1.871008, current_train_items 57920.
I0830 18:07:00.417043 133100262716928 run.py:742] (val) algo activity_selector step 4200: {'selected': 0.8522072936660269, 'score': 0.8522072936660269, 'examples_seen': 57920, 'step': 4200, 'algorithm': 'activity_selector'}
I0830 18:07:00.424547 133100262716928 run.py:742] (val) algo task_scheduling step 4200: {'selected': 0.8875739644970414, 'score': 0.8875739644970414, 'examples_seen': 57920, 'step': 4200, 'algorithm': 'task_scheduling'}
I0830 18:07:00.424687 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.870, val scores are: activity_selector: 0.852, task_scheduling: 0.888
I0830 18:07:01.522419 133100262716928 run.py:707] Algo activity_selector step 4250 current loss 0.858780, current_train_items 58624.
I0830 18:07:01.526882 133100262716928 run.py:707] Algo task_scheduling step 4250 current loss 1.406103, current_train_items 58624.
I0830 18:07:01.543768 133100262716928 run.py:742] (val) algo activity_selector step 4250: {'selected': 0.8450704225352113, 'score': 0.8450704225352113, 'examples_seen': 58624, 'step': 4250, 'algorithm': 'activity_selector'}
I0830 18:07:01.551256 133100262716928 run.py:742] (val) algo task_scheduling step 4250: {'selected': 0.9469026548672566, 'score': 0.9469026548672566, 'examples_seen': 58624, 'step': 4250, 'algorithm': 'task_scheduling'}
I0830 18:07:01.551402 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.896, val scores are: activity_selector: 0.845, task_scheduling: 0.947
I0830 18:07:02.619200 133100262716928 run.py:707] Algo activity_selector step 4300 current loss 0.988795, current_train_items 59328.
I0830 18:07:02.623919 133100262716928 run.py:707] Algo task_scheduling step 4300 current loss 1.492520, current_train_items 59328.
I0830 18:07:02.641478 133100262716928 run.py:742] (val) algo activity_selector step 4300: {'selected': 0.8846880907372401, 'score': 0.8846880907372401, 'examples_seen': 59328, 'step': 4300, 'algorithm': 'activity_selector'}
I0830 18:07:02.649094 133100262716928 run.py:742] (val) algo task_scheduling step 4300: {'selected': 0.9249291784702549, 'score': 0.9249291784702549, 'examples_seen': 59328, 'step': 4300, 'algorithm': 'task_scheduling'}
I0830 18:07:02.649242 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.905, val scores are: activity_selector: 0.885, task_scheduling: 0.925
I0830 18:07:03.733762 133100262716928 run.py:707] Algo activity_selector step 4350 current loss 0.953571, current_train_items 59984.
I0830 18:07:03.738226 133100262716928 run.py:707] Algo task_scheduling step 4350 current loss 1.933700, current_train_items 59984.
I0830 18:07:03.755513 133100262716928 run.py:742] (val) algo activity_selector step 4350: {'selected': 0.8942115768463075, 'score': 0.8942115768463075, 'examples_seen': 59984, 'step': 4350, 'algorithm': 'activity_selector'}
I0830 18:07:03.763095 133100262716928 run.py:742] (val) algo task_scheduling step 4350: {'selected': 0.9467625899280576, 'score': 0.9467625899280576, 'examples_seen': 59984, 'step': 4350, 'algorithm': 'task_scheduling'}
I0830 18:07:03.763256 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.920, val scores are: activity_selector: 0.894, task_scheduling: 0.947
I0830 18:07:04.878572 133100262716928 run.py:707] Algo activity_selector step 4400 current loss 0.974196, current_train_items 60688.
I0830 18:07:04.883114 133100262716928 run.py:707] Algo task_scheduling step 4400 current loss 1.493459, current_train_items 60688.
I0830 18:07:04.899771 133100262716928 run.py:742] (val) algo activity_selector step 4400: {'selected': 0.8912655971479502, 'score': 0.8912655971479502, 'examples_seen': 60688, 'step': 4400, 'algorithm': 'activity_selector'}
I0830 18:07:04.907340 133100262716928 run.py:742] (val) algo task_scheduling step 4400: {'selected': 0.9275362318840579, 'score': 0.9275362318840579, 'examples_seen': 60688, 'step': 4400, 'algorithm': 'task_scheduling'}
I0830 18:07:04.907490 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.909, val scores are: activity_selector: 0.891, task_scheduling: 0.928
I0830 18:07:05.993171 133100262716928 run.py:707] Algo activity_selector step 4450 current loss 0.792539, current_train_items 61392.
I0830 18:07:05.997671 133100262716928 run.py:707] Algo task_scheduling step 4450 current loss 1.290449, current_train_items 61392.
I0830 18:07:06.014481 133100262716928 run.py:742] (val) algo activity_selector step 4450: {'selected': 0.890595009596929, 'score': 0.890595009596929, 'examples_seen': 61392, 'step': 4450, 'algorithm': 'activity_selector'}
I0830 18:07:06.022064 133100262716928 run.py:742] (val) algo task_scheduling step 4450: {'selected': 0.936257710760795, 'score': 0.936257710760795, 'examples_seen': 61392, 'step': 4450, 'algorithm': 'task_scheduling'}
I0830 18:07:06.022220 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.913, val scores are: activity_selector: 0.891, task_scheduling: 0.936
I0830 18:07:07.075337 133100262716928 run.py:707] Algo activity_selector step 4500 current loss 0.661683, current_train_items 62064.
I0830 18:07:07.079735 133100262716928 run.py:707] Algo task_scheduling step 4500 current loss 1.412649, current_train_items 62064.
I0830 18:07:07.096887 133100262716928 run.py:742] (val) algo activity_selector step 4500: {'selected': 0.9023941068139963, 'score': 0.9023941068139963, 'examples_seen': 62064, 'step': 4500, 'algorithm': 'activity_selector'}
I0830 18:07:07.104516 133100262716928 run.py:742] (val) algo task_scheduling step 4500: {'selected': 0.9463487332339792, 'score': 0.9463487332339792, 'examples_seen': 62064, 'step': 4500, 'algorithm': 'task_scheduling'}
I0830 18:07:07.104663 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.924, val scores are: activity_selector: 0.902, task_scheduling: 0.946
I0830 18:07:08.187226 133100262716928 run.py:707] Algo activity_selector step 4550 current loss 0.640359, current_train_items 62752.
I0830 18:07:08.191669 133100262716928 run.py:707] Algo task_scheduling step 4550 current loss 1.166920, current_train_items 62752.
I0830 18:07:08.209414 133100262716928 run.py:742] (val) algo activity_selector step 4550: {'selected': 0.8677685950413223, 'score': 0.8677685950413223, 'examples_seen': 62752, 'step': 4550, 'algorithm': 'activity_selector'}
I0830 18:07:08.217341 133100262716928 run.py:742] (val) algo task_scheduling step 4550: {'selected': 0.9221476510067115, 'score': 0.9221476510067115, 'examples_seen': 62752, 'step': 4550, 'algorithm': 'task_scheduling'}
I0830 18:07:08.217488 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.895, val scores are: activity_selector: 0.868, task_scheduling: 0.922
I0830 18:07:09.300103 133100262716928 run.py:707] Algo activity_selector step 4600 current loss 0.772179, current_train_items 63456.
I0830 18:07:09.304668 133100262716928 run.py:707] Algo task_scheduling step 4600 current loss 1.200703, current_train_items 63456.
I0830 18:07:09.321578 133100262716928 run.py:742] (val) algo activity_selector step 4600: {'selected': 0.8728652751423149, 'score': 0.8728652751423149, 'examples_seen': 63456, 'step': 4600, 'algorithm': 'activity_selector'}
I0830 18:07:09.329088 133100262716928 run.py:742] (val) algo task_scheduling step 4600: {'selected': 0.9401829697396199, 'score': 0.9401829697396199, 'examples_seen': 63456, 'step': 4600, 'algorithm': 'task_scheduling'}
I0830 18:07:09.329239 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.907, val scores are: activity_selector: 0.873, task_scheduling: 0.940
I0830 18:07:10.405799 133100262716928 run.py:707] Algo activity_selector step 4650 current loss 0.522785, current_train_items 64144.
I0830 18:07:10.410143 133100262716928 run.py:707] Algo task_scheduling step 4650 current loss 1.546644, current_train_items 64144.
I0830 18:07:10.431199 133100262716928 run.py:742] (val) algo activity_selector step 4650: {'selected': 0.8662674650698603, 'score': 0.8662674650698603, 'examples_seen': 64144, 'step': 4650, 'algorithm': 'activity_selector'}
I0830 18:07:10.438885 133100262716928 run.py:742] (val) algo task_scheduling step 4650: {'selected': 0.9159779614325069, 'score': 0.9159779614325069, 'examples_seen': 64144, 'step': 4650, 'algorithm': 'task_scheduling'}
I0830 18:07:10.439032 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.891, val scores are: activity_selector: 0.866, task_scheduling: 0.916
I0830 18:07:11.500206 133100262716928 run.py:707] Algo activity_selector step 4700 current loss 0.688206, current_train_items 64816.
I0830 18:07:11.504624 133100262716928 run.py:707] Algo task_scheduling step 4700 current loss 1.685950, current_train_items 64816.
I0830 18:07:11.522125 133100262716928 run.py:742] (val) algo activity_selector step 4700: {'selected': 0.8981818181818181, 'score': 0.8981818181818181, 'examples_seen': 64816, 'step': 4700, 'algorithm': 'activity_selector'}
I0830 18:07:11.529707 133100262716928 run.py:742] (val) algo task_scheduling step 4700: {'selected': 0.9423210562890896, 'score': 0.9423210562890896, 'examples_seen': 64816, 'step': 4700, 'algorithm': 'task_scheduling'}
I0830 18:07:11.529846 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.920, val scores are: activity_selector: 0.898, task_scheduling: 0.942
I0830 18:07:12.610357 133100262716928 run.py:707] Algo activity_selector step 4750 current loss 1.496962, current_train_items 65520.
I0830 18:07:12.614820 133100262716928 run.py:707] Algo task_scheduling step 4750 current loss 1.967370, current_train_items 65520.
I0830 18:07:12.631804 133100262716928 run.py:742] (val) algo activity_selector step 4750: {'selected': 0.853228962818004, 'score': 0.853228962818004, 'examples_seen': 65520, 'step': 4750, 'algorithm': 'activity_selector'}
I0830 18:07:12.639340 133100262716928 run.py:742] (val) algo task_scheduling step 4750: {'selected': 0.9360824742268041, 'score': 0.9360824742268041, 'examples_seen': 65520, 'step': 4750, 'algorithm': 'task_scheduling'}
I0830 18:07:12.639481 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.895, val scores are: activity_selector: 0.853, task_scheduling: 0.936
I0830 18:07:13.709109 133100262716928 run.py:707] Algo activity_selector step 4800 current loss 0.551268, current_train_items 66208.
I0830 18:07:13.713605 133100262716928 run.py:707] Algo task_scheduling step 4800 current loss 1.119672, current_train_items 66208.
I0830 18:07:13.730455 133100262716928 run.py:742] (val) algo activity_selector step 4800: {'selected': 0.8770642201834863, 'score': 0.8770642201834863, 'examples_seen': 66208, 'step': 4800, 'algorithm': 'activity_selector'}
I0830 18:07:13.737992 133100262716928 run.py:742] (val) algo task_scheduling step 4800: {'selected': 0.9292221443587947, 'score': 0.9292221443587947, 'examples_seen': 66208, 'step': 4800, 'algorithm': 'task_scheduling'}
I0830 18:07:13.738135 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.903, val scores are: activity_selector: 0.877, task_scheduling: 0.929
I0830 18:07:14.780271 133100262716928 run.py:707] Algo activity_selector step 4850 current loss 0.931800, current_train_items 66880.
I0830 18:07:14.784679 133100262716928 run.py:707] Algo task_scheduling step 4850 current loss 1.131685, current_train_items 66880.
I0830 18:07:14.801480 133100262716928 run.py:742] (val) algo activity_selector step 4850: {'selected': 0.8741721854304635, 'score': 0.8741721854304635, 'examples_seen': 66880, 'step': 4850, 'algorithm': 'activity_selector'}
I0830 18:07:14.809591 133100262716928 run.py:742] (val) algo task_scheduling step 4850: {'selected': 0.9145931405514458, 'score': 0.9145931405514458, 'examples_seen': 66880, 'step': 4850, 'algorithm': 'task_scheduling'}
I0830 18:07:14.809736 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.894, val scores are: activity_selector: 0.874, task_scheduling: 0.915
I0830 18:07:15.887506 133100262716928 run.py:707] Algo activity_selector step 4900 current loss 0.619340, current_train_items 67584.
I0830 18:07:15.892295 133100262716928 run.py:707] Algo task_scheduling step 4900 current loss 1.263107, current_train_items 67584.
I0830 18:07:15.908824 133100262716928 run.py:742] (val) algo activity_selector step 4900: {'selected': 0.9177330895795246, 'score': 0.9177330895795246, 'examples_seen': 67584, 'step': 4900, 'algorithm': 'activity_selector'}
I0830 18:07:15.916421 133100262716928 run.py:742] (val) algo task_scheduling step 4900: {'selected': 0.9495380241648897, 'score': 0.9495380241648897, 'examples_seen': 67584, 'step': 4900, 'algorithm': 'task_scheduling'}
I0830 18:07:15.916564 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.925, current avg val score is 0.934, val scores are: activity_selector: 0.918, task_scheduling: 0.950
I0830 18:07:17.053517 133100262716928 run.py:707] Algo activity_selector step 4950 current loss 0.508882, current_train_items 68272.
I0830 18:07:17.058132 133100262716928 run.py:707] Algo task_scheduling step 4950 current loss 1.233800, current_train_items 68272.
I0830 18:07:17.075620 133100262716928 run.py:742] (val) algo activity_selector step 4950: {'selected': 0.8404669260700389, 'score': 0.8404669260700389, 'examples_seen': 68272, 'step': 4950, 'algorithm': 'activity_selector'}
I0830 18:07:17.083215 133100262716928 run.py:742] (val) algo task_scheduling step 4950: {'selected': 0.9328719723183391, 'score': 0.9328719723183391, 'examples_seen': 68272, 'step': 4950, 'algorithm': 'task_scheduling'}
I0830 18:07:17.083359 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.887, val scores are: activity_selector: 0.840, task_scheduling: 0.933
I0830 18:07:18.189559 133100262716928 run.py:707] Algo activity_selector step 5000 current loss 0.892346, current_train_items 68976.
I0830 18:07:18.194457 133100262716928 run.py:707] Algo task_scheduling step 5000 current loss 1.028243, current_train_items 68976.
I0830 18:07:18.211563 133100262716928 run.py:742] (val) algo activity_selector step 5000: {'selected': 0.8801498127340823, 'score': 0.8801498127340823, 'examples_seen': 68976, 'step': 5000, 'algorithm': 'activity_selector'}
I0830 18:07:18.219270 133100262716928 run.py:742] (val) algo task_scheduling step 5000: {'selected': 0.9023066485753054, 'score': 0.9023066485753054, 'examples_seen': 68976, 'step': 5000, 'algorithm': 'task_scheduling'}
I0830 18:07:18.219414 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.891, val scores are: activity_selector: 0.880, task_scheduling: 0.902
I0830 18:07:19.294809 133100262716928 run.py:707] Algo activity_selector step 5050 current loss 0.994949, current_train_items 69648.
I0830 18:07:19.299069 133100262716928 run.py:707] Algo task_scheduling step 5050 current loss 2.064898, current_train_items 69648.
I0830 18:07:19.315609 133100262716928 run.py:742] (val) algo activity_selector step 5050: {'selected': 0.8983739837398375, 'score': 0.8983739837398375, 'examples_seen': 69648, 'step': 5050, 'algorithm': 'activity_selector'}
I0830 18:07:19.323203 133100262716928 run.py:742] (val) algo task_scheduling step 5050: {'selected': 0.9053778080326754, 'score': 0.9053778080326754, 'examples_seen': 69648, 'step': 5050, 'algorithm': 'task_scheduling'}
I0830 18:07:19.323346 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.902, val scores are: activity_selector: 0.898, task_scheduling: 0.905
I0830 18:07:20.411694 133100262716928 run.py:707] Algo activity_selector step 5100 current loss 0.696095, current_train_items 70336.
I0830 18:07:20.416441 133100262716928 run.py:707] Algo task_scheduling step 5100 current loss 1.717331, current_train_items 70336.
I0830 18:07:20.434308 133100262716928 run.py:742] (val) algo activity_selector step 5100: {'selected': 0.8798586572438162, 'score': 0.8798586572438162, 'examples_seen': 70336, 'step': 5100, 'algorithm': 'activity_selector'}
I0830 18:07:20.441881 133100262716928 run.py:742] (val) algo task_scheduling step 5100: {'selected': 0.9391304347826088, 'score': 0.9391304347826088, 'examples_seen': 70336, 'step': 5100, 'algorithm': 'task_scheduling'}
I0830 18:07:20.442022 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.909, val scores are: activity_selector: 0.880, task_scheduling: 0.939
I0830 18:07:21.535168 133100262716928 run.py:707] Algo activity_selector step 5150 current loss 0.664189, current_train_items 71040.
I0830 18:07:21.539875 133100262716928 run.py:707] Algo task_scheduling step 5150 current loss 1.217194, current_train_items 71040.
I0830 18:07:21.557358 133100262716928 run.py:742] (val) algo activity_selector step 5150: {'selected': 0.8786764705882353, 'score': 0.8786764705882353, 'examples_seen': 71040, 'step': 5150, 'algorithm': 'activity_selector'}
I0830 18:07:21.564893 133100262716928 run.py:742] (val) algo task_scheduling step 5150: {'selected': 0.9313304721030042, 'score': 0.9313304721030042, 'examples_seen': 71040, 'step': 5150, 'algorithm': 'task_scheduling'}
I0830 18:07:21.565042 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.905, val scores are: activity_selector: 0.879, task_scheduling: 0.931
I0830 18:07:22.615862 133100262716928 run.py:707] Algo activity_selector step 5200 current loss 1.114824, current_train_items 71712.
I0830 18:07:22.620361 133100262716928 run.py:707] Algo task_scheduling step 5200 current loss 1.242944, current_train_items 71712.
I0830 18:07:22.637687 133100262716928 run.py:742] (val) algo activity_selector step 5200: {'selected': 0.8884462151394422, 'score': 0.8884462151394422, 'examples_seen': 71712, 'step': 5200, 'algorithm': 'activity_selector'}
I0830 18:07:22.645307 133100262716928 run.py:742] (val) algo task_scheduling step 5200: {'selected': 0.9502262443438914, 'score': 0.9502262443438914, 'examples_seen': 71712, 'step': 5200, 'algorithm': 'task_scheduling'}
I0830 18:07:22.645448 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.919, val scores are: activity_selector: 0.888, task_scheduling: 0.950
I0830 18:07:23.740624 133100262716928 run.py:707] Algo activity_selector step 5250 current loss 0.550909, current_train_items 72400.
I0830 18:07:23.745204 133100262716928 run.py:707] Algo task_scheduling step 5250 current loss 1.799710, current_train_items 72400.
I0830 18:07:23.762350 133100262716928 run.py:742] (val) algo activity_selector step 5250: {'selected': 0.8934579439252337, 'score': 0.8934579439252337, 'examples_seen': 72400, 'step': 5250, 'algorithm': 'activity_selector'}
I0830 18:07:23.770049 133100262716928 run.py:742] (val) algo task_scheduling step 5250: {'selected': 0.9263456090651557, 'score': 0.9263456090651557, 'examples_seen': 72400, 'step': 5250, 'algorithm': 'task_scheduling'}
I0830 18:07:23.770210 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.910, val scores are: activity_selector: 0.893, task_scheduling: 0.926
I0830 18:07:24.878625 133100262716928 run.py:707] Algo activity_selector step 5300 current loss 0.854563, current_train_items 73104.
I0830 18:07:24.883306 133100262716928 run.py:707] Algo task_scheduling step 5300 current loss 1.590346, current_train_items 73104.
I0830 18:07:24.900883 133100262716928 run.py:742] (val) algo activity_selector step 5300: {'selected': 0.8935361216730039, 'score': 0.8935361216730039, 'examples_seen': 73104, 'step': 5300, 'algorithm': 'activity_selector'}
I0830 18:07:24.908738 133100262716928 run.py:742] (val) algo task_scheduling step 5300: {'selected': 0.9274755927475593, 'score': 0.9274755927475593, 'examples_seen': 73104, 'step': 5300, 'algorithm': 'task_scheduling'}
I0830 18:07:24.908897 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.911, val scores are: activity_selector: 0.894, task_scheduling: 0.927
I0830 18:07:25.964459 133100262716928 run.py:707] Algo activity_selector step 5350 current loss 0.964614, current_train_items 73808.
I0830 18:07:25.969013 133100262716928 run.py:707] Algo task_scheduling step 5350 current loss 1.459610, current_train_items 73808.
I0830 18:07:25.986226 133100262716928 run.py:742] (val) algo activity_selector step 5350: {'selected': 0.8999999999999999, 'score': 0.8999999999999999, 'examples_seen': 73808, 'step': 5350, 'algorithm': 'activity_selector'}
I0830 18:07:25.993962 133100262716928 run.py:742] (val) algo task_scheduling step 5350: {'selected': 0.8924302788844622, 'score': 0.8924302788844622, 'examples_seen': 73808, 'step': 5350, 'algorithm': 'task_scheduling'}
I0830 18:07:25.994102 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.896, val scores are: activity_selector: 0.900, task_scheduling: 0.892
I0830 18:07:27.080160 133100262716928 run.py:707] Algo activity_selector step 5400 current loss 1.009890, current_train_items 74464.
I0830 18:07:27.084596 133100262716928 run.py:707] Algo task_scheduling step 5400 current loss 1.097739, current_train_items 74464.
I0830 18:07:27.101556 133100262716928 run.py:742] (val) algo activity_selector step 5400: {'selected': 0.8910133843212237, 'score': 0.8910133843212237, 'examples_seen': 74464, 'step': 5400, 'algorithm': 'activity_selector'}
I0830 18:07:27.109164 133100262716928 run.py:742] (val) algo task_scheduling step 5400: {'selected': 0.9209770114942528, 'score': 0.9209770114942528, 'examples_seen': 74464, 'step': 5400, 'algorithm': 'task_scheduling'}
I0830 18:07:27.109309 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.906, val scores are: activity_selector: 0.891, task_scheduling: 0.921
I0830 18:07:28.194271 133100262716928 run.py:707] Algo activity_selector step 5450 current loss 0.584453, current_train_items 75168.
I0830 18:07:28.198843 133100262716928 run.py:707] Algo task_scheduling step 5450 current loss 1.125127, current_train_items 75168.
I0830 18:07:28.219261 133100262716928 run.py:742] (val) algo activity_selector step 5450: {'selected': 0.8651911468812877, 'score': 0.8651911468812877, 'examples_seen': 75168, 'step': 5450, 'algorithm': 'activity_selector'}
I0830 18:07:28.226799 133100262716928 run.py:742] (val) algo task_scheduling step 5450: {'selected': 0.9315642458100558, 'score': 0.9315642458100558, 'examples_seen': 75168, 'step': 5450, 'algorithm': 'task_scheduling'}
I0830 18:07:28.226943 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.898, val scores are: activity_selector: 0.865, task_scheduling: 0.932
I0830 18:07:29.294218 133100262716928 run.py:707] Algo activity_selector step 5500 current loss 0.967287, current_train_items 75872.
I0830 18:07:29.299173 133100262716928 run.py:707] Algo task_scheduling step 5500 current loss 1.469916, current_train_items 75872.
I0830 18:07:29.315984 133100262716928 run.py:742] (val) algo activity_selector step 5500: {'selected': 0.8835341365461848, 'score': 0.8835341365461848, 'examples_seen': 75872, 'step': 5500, 'algorithm': 'activity_selector'}
I0830 18:07:29.323556 133100262716928 run.py:742] (val) algo task_scheduling step 5500: {'selected': 0.9161469161469162, 'score': 0.9161469161469162, 'examples_seen': 75872, 'step': 5500, 'algorithm': 'task_scheduling'}
I0830 18:07:29.323695 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.900, val scores are: activity_selector: 0.884, task_scheduling: 0.916
I0830 18:07:30.370318 133100262716928 run.py:707] Algo activity_selector step 5550 current loss 0.676858, current_train_items 76528.
I0830 18:07:30.375554 133100262716928 run.py:707] Algo task_scheduling step 5550 current loss 1.293748, current_train_items 76528.
I0830 18:07:30.393799 133100262716928 run.py:742] (val) algo activity_selector step 5550: {'selected': 0.9116117850953207, 'score': 0.9116117850953207, 'examples_seen': 76528, 'step': 5550, 'algorithm': 'activity_selector'}
I0830 18:07:30.401458 133100262716928 run.py:742] (val) algo task_scheduling step 5550: {'selected': 0.9152768512341561, 'score': 0.9152768512341561, 'examples_seen': 76528, 'step': 5550, 'algorithm': 'task_scheduling'}
I0830 18:07:30.401597 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.913, val scores are: activity_selector: 0.912, task_scheduling: 0.915
I0830 18:07:31.495900 133100262716928 run.py:707] Algo activity_selector step 5600 current loss 1.257142, current_train_items 77232.
I0830 18:07:31.500428 133100262716928 run.py:707] Algo task_scheduling step 5600 current loss 1.234674, current_train_items 77232.
I0830 18:07:31.519330 133100262716928 run.py:742] (val) algo activity_selector step 5600: {'selected': 0.8818565400843882, 'score': 0.8818565400843882, 'examples_seen': 77232, 'step': 5600, 'algorithm': 'activity_selector'}
I0830 18:07:31.526978 133100262716928 run.py:742] (val) algo task_scheduling step 5600: {'selected': 0.9095928226363009, 'score': 0.9095928226363009, 'examples_seen': 77232, 'step': 5600, 'algorithm': 'task_scheduling'}
I0830 18:07:31.527121 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.896, val scores are: activity_selector: 0.882, task_scheduling: 0.910
I0830 18:07:32.597291 133100262716928 run.py:707] Algo activity_selector step 5650 current loss 0.755652, current_train_items 77936.
I0830 18:07:32.601725 133100262716928 run.py:707] Algo task_scheduling step 5650 current loss 1.787470, current_train_items 77936.
I0830 18:07:32.618751 133100262716928 run.py:742] (val) algo activity_selector step 5650: {'selected': 0.9009009009009008, 'score': 0.9009009009009008, 'examples_seen': 77936, 'step': 5650, 'algorithm': 'activity_selector'}
I0830 18:07:32.626230 133100262716928 run.py:742] (val) algo task_scheduling step 5650: {'selected': 0.9416785206258891, 'score': 0.9416785206258891, 'examples_seen': 77936, 'step': 5650, 'algorithm': 'task_scheduling'}
I0830 18:07:32.626373 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.921, val scores are: activity_selector: 0.901, task_scheduling: 0.942
I0830 18:07:33.663891 133100262716928 run.py:707] Algo activity_selector step 5700 current loss 1.065732, current_train_items 78608.
I0830 18:07:33.668624 133100262716928 run.py:707] Algo task_scheduling step 5700 current loss 1.431816, current_train_items 78608.
I0830 18:07:33.685266 133100262716928 run.py:742] (val) algo activity_selector step 5700: {'selected': 0.8816326530612244, 'score': 0.8816326530612244, 'examples_seen': 78608, 'step': 5700, 'algorithm': 'activity_selector'}
I0830 18:07:33.692823 133100262716928 run.py:742] (val) algo task_scheduling step 5700: {'selected': 0.9657683903860159, 'score': 0.9657683903860159, 'examples_seen': 78608, 'step': 5700, 'algorithm': 'task_scheduling'}
I0830 18:07:33.692969 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.924, val scores are: activity_selector: 0.882, task_scheduling: 0.966
I0830 18:07:34.778630 133100262716928 run.py:707] Algo activity_selector step 5750 current loss 0.676283, current_train_items 79296.
I0830 18:07:34.783131 133100262716928 run.py:707] Algo task_scheduling step 5750 current loss 1.203564, current_train_items 79296.
I0830 18:07:34.799539 133100262716928 run.py:742] (val) algo activity_selector step 5750: {'selected': 0.8987341772151898, 'score': 0.8987341772151898, 'examples_seen': 79296, 'step': 5750, 'algorithm': 'activity_selector'}
I0830 18:07:34.807102 133100262716928 run.py:742] (val) algo task_scheduling step 5750: {'selected': 0.9322289156626505, 'score': 0.9322289156626505, 'examples_seen': 79296, 'step': 5750, 'algorithm': 'task_scheduling'}
I0830 18:07:34.807271 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.915, val scores are: activity_selector: 0.899, task_scheduling: 0.932
I0830 18:07:35.901847 133100262716928 run.py:707] Algo activity_selector step 5800 current loss 1.029209, current_train_items 80000.
I0830 18:07:35.906505 133100262716928 run.py:707] Algo task_scheduling step 5800 current loss 1.514737, current_train_items 80000.
I0830 18:07:35.924018 133100262716928 run.py:742] (val) algo activity_selector step 5800: {'selected': 0.873517786561265, 'score': 0.873517786561265, 'examples_seen': 80000, 'step': 5800, 'algorithm': 'activity_selector'}
I0830 18:07:35.931546 133100262716928 run.py:742] (val) algo task_scheduling step 5800: {'selected': 0.9388679245283019, 'score': 0.9388679245283019, 'examples_seen': 80000, 'step': 5800, 'algorithm': 'task_scheduling'}
I0830 18:07:35.931689 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.906, val scores are: activity_selector: 0.874, task_scheduling: 0.939
I0830 18:07:37.015612 133100262716928 run.py:707] Algo activity_selector step 5850 current loss 0.752281, current_train_items 80688.
I0830 18:07:37.020128 133100262716928 run.py:707] Algo task_scheduling step 5850 current loss 1.099759, current_train_items 80688.
I0830 18:07:37.036983 133100262716928 run.py:742] (val) algo activity_selector step 5850: {'selected': 0.8508946322067595, 'score': 0.8508946322067595, 'examples_seen': 80688, 'step': 5850, 'algorithm': 'activity_selector'}
I0830 18:07:37.044540 133100262716928 run.py:742] (val) algo task_scheduling step 5850: {'selected': 0.944206008583691, 'score': 0.944206008583691, 'examples_seen': 80688, 'step': 5850, 'algorithm': 'task_scheduling'}
I0830 18:07:37.044683 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.898, val scores are: activity_selector: 0.851, task_scheduling: 0.944
I0830 18:07:38.096359 133100262716928 run.py:707] Algo activity_selector step 5900 current loss 0.557044, current_train_items 81360.
I0830 18:07:38.100835 133100262716928 run.py:707] Algo task_scheduling step 5900 current loss 1.490841, current_train_items 81360.
I0830 18:07:38.118976 133100262716928 run.py:742] (val) algo activity_selector step 5900: {'selected': 0.8825622775800712, 'score': 0.8825622775800712, 'examples_seen': 81360, 'step': 5900, 'algorithm': 'activity_selector'}
I0830 18:07:38.127542 133100262716928 run.py:742] (val) algo task_scheduling step 5900: {'selected': 0.9383070301291249, 'score': 0.9383070301291249, 'examples_seen': 81360, 'step': 5900, 'algorithm': 'task_scheduling'}
I0830 18:07:38.127701 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.910, val scores are: activity_selector: 0.883, task_scheduling: 0.938
I0830 18:07:39.183805 133100262716928 run.py:707] Algo activity_selector step 5950 current loss 0.519935, current_train_items 82064.
I0830 18:07:39.188231 133100262716928 run.py:707] Algo task_scheduling step 5950 current loss 0.994720, current_train_items 82064.
I0830 18:07:39.205529 133100262716928 run.py:742] (val) algo activity_selector step 5950: {'selected': 0.8527131782945736, 'score': 0.8527131782945736, 'examples_seen': 82064, 'step': 5950, 'algorithm': 'activity_selector'}
I0830 18:07:39.213086 133100262716928 run.py:742] (val) algo task_scheduling step 5950: {'selected': 0.9355322338830585, 'score': 0.9355322338830585, 'examples_seen': 82064, 'step': 5950, 'algorithm': 'task_scheduling'}
I0830 18:07:39.213243 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.894, val scores are: activity_selector: 0.853, task_scheduling: 0.936
I0830 18:07:40.285003 133100262716928 run.py:707] Algo activity_selector step 6000 current loss 0.789497, current_train_items 82752.
I0830 18:07:40.289632 133100262716928 run.py:707] Algo task_scheduling step 6000 current loss 1.294875, current_train_items 82752.
I0830 18:07:40.306235 133100262716928 run.py:742] (val) algo activity_selector step 6000: {'selected': 0.910958904109589, 'score': 0.910958904109589, 'examples_seen': 82752, 'step': 6000, 'algorithm': 'activity_selector'}
I0830 18:07:40.313754 133100262716928 run.py:742] (val) algo task_scheduling step 6000: {'selected': 0.9458272327964861, 'score': 0.9458272327964861, 'examples_seen': 82752, 'step': 6000, 'algorithm': 'task_scheduling'}
I0830 18:07:40.313897 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.928, val scores are: activity_selector: 0.911, task_scheduling: 0.946
I0830 18:07:41.385508 133100262716928 run.py:707] Algo activity_selector step 6050 current loss 0.623190, current_train_items 83440.
I0830 18:07:41.389811 133100262716928 run.py:707] Algo task_scheduling step 6050 current loss 2.187363, current_train_items 83440.
I0830 18:07:41.407149 133100262716928 run.py:742] (val) algo activity_selector step 6050: {'selected': 0.859538784067086, 'score': 0.859538784067086, 'examples_seen': 83440, 'step': 6050, 'algorithm': 'activity_selector'}
I0830 18:07:41.414713 133100262716928 run.py:742] (val) algo task_scheduling step 6050: {'selected': 0.9158620689655173, 'score': 0.9158620689655173, 'examples_seen': 83440, 'step': 6050, 'algorithm': 'task_scheduling'}
I0830 18:07:41.414854 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.888, val scores are: activity_selector: 0.860, task_scheduling: 0.916
I0830 18:07:42.502972 133100262716928 run.py:707] Algo activity_selector step 6100 current loss 1.047410, current_train_items 84128.
I0830 18:07:42.507649 133100262716928 run.py:707] Algo task_scheduling step 6100 current loss 1.319389, current_train_items 84128.
I0830 18:07:42.524881 133100262716928 run.py:742] (val) algo activity_selector step 6100: {'selected': 0.8983739837398373, 'score': 0.8983739837398373, 'examples_seen': 84128, 'step': 6100, 'algorithm': 'activity_selector'}
I0830 18:07:42.532445 133100262716928 run.py:742] (val) algo task_scheduling step 6100: {'selected': 0.946685878962536, 'score': 0.946685878962536, 'examples_seen': 84128, 'step': 6100, 'algorithm': 'task_scheduling'}
I0830 18:07:42.532586 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.923, val scores are: activity_selector: 0.898, task_scheduling: 0.947
I0830 18:07:43.614997 133100262716928 run.py:707] Algo activity_selector step 6150 current loss 0.805101, current_train_items 84816.
I0830 18:07:43.619905 133100262716928 run.py:707] Algo task_scheduling step 6150 current loss 1.139189, current_train_items 84816.
I0830 18:07:43.637208 133100262716928 run.py:742] (val) algo activity_selector step 6150: {'selected': 0.8831683168316832, 'score': 0.8831683168316832, 'examples_seen': 84816, 'step': 6150, 'algorithm': 'activity_selector'}
I0830 18:07:43.644784 133100262716928 run.py:742] (val) algo task_scheduling step 6150: {'selected': 0.953125, 'score': 0.953125, 'examples_seen': 84816, 'step': 6150, 'algorithm': 'task_scheduling'}
I0830 18:07:43.644925 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.918, val scores are: activity_selector: 0.883, task_scheduling: 0.953
I0830 18:07:44.715162 133100262716928 run.py:707] Algo activity_selector step 6200 current loss 0.595088, current_train_items 85520.
I0830 18:07:44.720042 133100262716928 run.py:707] Algo task_scheduling step 6200 current loss 1.041823, current_train_items 85520.
I0830 18:07:44.736912 133100262716928 run.py:742] (val) algo activity_selector step 6200: {'selected': 0.8507157464212679, 'score': 0.8507157464212679, 'examples_seen': 85520, 'step': 6200, 'algorithm': 'activity_selector'}
I0830 18:07:44.744495 133100262716928 run.py:742] (val) algo task_scheduling step 6200: {'selected': 0.9089655172413794, 'score': 0.9089655172413794, 'examples_seen': 85520, 'step': 6200, 'algorithm': 'task_scheduling'}
I0830 18:07:44.744635 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.880, val scores are: activity_selector: 0.851, task_scheduling: 0.909
I0830 18:07:45.813942 133100262716928 run.py:707] Algo activity_selector step 6250 current loss 0.664274, current_train_items 86192.
I0830 18:07:45.818463 133100262716928 run.py:707] Algo task_scheduling step 6250 current loss 0.995674, current_train_items 86192.
I0830 18:07:45.835918 133100262716928 run.py:742] (val) algo activity_selector step 6250: {'selected': 0.9138576779026217, 'score': 0.9138576779026217, 'examples_seen': 86192, 'step': 6250, 'algorithm': 'activity_selector'}
I0830 18:07:45.843439 133100262716928 run.py:742] (val) algo task_scheduling step 6250: {'selected': 0.9371841155234658, 'score': 0.9371841155234658, 'examples_seen': 86192, 'step': 6250, 'algorithm': 'task_scheduling'}
I0830 18:07:45.843581 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.926, val scores are: activity_selector: 0.914, task_scheduling: 0.937
I0830 18:07:46.929654 133100262716928 run.py:707] Algo activity_selector step 6300 current loss 1.056650, current_train_items 86880.
I0830 18:07:46.934110 133100262716928 run.py:707] Algo task_scheduling step 6300 current loss 1.082218, current_train_items 86880.
I0830 18:07:46.951474 133100262716928 run.py:742] (val) algo activity_selector step 6300: {'selected': 0.8918406072106262, 'score': 0.8918406072106262, 'examples_seen': 86880, 'step': 6300, 'algorithm': 'activity_selector'}
I0830 18:07:46.959006 133100262716928 run.py:742] (val) algo task_scheduling step 6300: {'selected': 0.9277777777777778, 'score': 0.9277777777777778, 'examples_seen': 86880, 'step': 6300, 'algorithm': 'task_scheduling'}
I0830 18:07:46.959144 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.910, val scores are: activity_selector: 0.892, task_scheduling: 0.928
I0830 18:07:48.080629 133100262716928 run.py:707] Algo activity_selector step 6350 current loss 0.292274, current_train_items 87584.
I0830 18:07:48.085235 133100262716928 run.py:707] Algo task_scheduling step 6350 current loss 1.544022, current_train_items 87584.
I0830 18:07:48.102550 133100262716928 run.py:742] (val) algo activity_selector step 6350: {'selected': 0.8515625, 'score': 0.8515625, 'examples_seen': 87584, 'step': 6350, 'algorithm': 'activity_selector'}
I0830 18:07:48.110136 133100262716928 run.py:742] (val) algo task_scheduling step 6350: {'selected': 0.9207195203197868, 'score': 0.9207195203197868, 'examples_seen': 87584, 'step': 6350, 'algorithm': 'task_scheduling'}
I0830 18:07:48.110282 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.886, val scores are: activity_selector: 0.852, task_scheduling: 0.921
I0830 18:07:49.151509 133100262716928 run.py:707] Algo activity_selector step 6400 current loss 0.646571, current_train_items 88272.
I0830 18:07:49.155939 133100262716928 run.py:707] Algo task_scheduling step 6400 current loss 1.256258, current_train_items 88272.
I0830 18:07:49.173175 133100262716928 run.py:742] (val) algo activity_selector step 6400: {'selected': 0.8861283643892339, 'score': 0.8861283643892339, 'examples_seen': 88272, 'step': 6400, 'algorithm': 'activity_selector'}
I0830 18:07:49.180752 133100262716928 run.py:742] (val) algo task_scheduling step 6400: {'selected': 0.9288702928870293, 'score': 0.9288702928870293, 'examples_seen': 88272, 'step': 6400, 'algorithm': 'task_scheduling'}
I0830 18:07:49.180893 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.907, val scores are: activity_selector: 0.886, task_scheduling: 0.929
I0830 18:07:50.266283 133100262716928 run.py:707] Algo activity_selector step 6450 current loss 0.715686, current_train_items 88944.
I0830 18:07:50.270867 133100262716928 run.py:707] Algo task_scheduling step 6450 current loss 1.743933, current_train_items 88944.
I0830 18:07:50.288151 133100262716928 run.py:742] (val) algo activity_selector step 6450: {'selected': 0.8571428571428571, 'score': 0.8571428571428571, 'examples_seen': 88944, 'step': 6450, 'algorithm': 'activity_selector'}
I0830 18:07:50.295800 133100262716928 run.py:742] (val) algo task_scheduling step 6450: {'selected': 0.9463487332339791, 'score': 0.9463487332339791, 'examples_seen': 88944, 'step': 6450, 'algorithm': 'task_scheduling'}
I0830 18:07:50.295940 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.902, val scores are: activity_selector: 0.857, task_scheduling: 0.946
I0830 18:07:51.388590 133100262716928 run.py:707] Algo activity_selector step 6500 current loss 0.875216, current_train_items 89648.
I0830 18:07:51.393831 133100262716928 run.py:707] Algo task_scheduling step 6500 current loss 2.184559, current_train_items 89648.
I0830 18:07:51.410192 133100262716928 run.py:742] (val) algo activity_selector step 6500: {'selected': 0.8700173310225304, 'score': 0.8700173310225304, 'examples_seen': 89648, 'step': 6500, 'algorithm': 'activity_selector'}
I0830 18:07:51.417743 133100262716928 run.py:742] (val) algo task_scheduling step 6500: {'selected': 0.9112343966712899, 'score': 0.9112343966712899, 'examples_seen': 89648, 'step': 6500, 'algorithm': 'task_scheduling'}
I0830 18:07:51.417883 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.891, val scores are: activity_selector: 0.870, task_scheduling: 0.911
I0830 18:07:52.488479 133100262716928 run.py:707] Algo activity_selector step 6550 current loss 0.872072, current_train_items 90336.
I0830 18:07:52.493556 133100262716928 run.py:707] Algo task_scheduling step 6550 current loss 1.395781, current_train_items 90336.
I0830 18:07:52.511019 133100262716928 run.py:742] (val) algo activity_selector step 6550: {'selected': 0.8467432950191571, 'score': 0.8467432950191571, 'examples_seen': 90336, 'step': 6550, 'algorithm': 'activity_selector'}
I0830 18:07:52.518727 133100262716928 run.py:742] (val) algo task_scheduling step 6550: {'selected': 0.9490084985835694, 'score': 0.9490084985835694, 'examples_seen': 90336, 'step': 6550, 'algorithm': 'task_scheduling'}
I0830 18:07:52.518867 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.898, val scores are: activity_selector: 0.847, task_scheduling: 0.949
I0830 18:07:53.619862 133100262716928 run.py:707] Algo activity_selector step 6600 current loss 0.353351, current_train_items 91008.
I0830 18:07:53.624506 133100262716928 run.py:707] Algo task_scheduling step 6600 current loss 2.105753, current_train_items 91008.
I0830 18:07:53.642415 133100262716928 run.py:742] (val) algo activity_selector step 6600: {'selected': 0.9026217228464419, 'score': 0.9026217228464419, 'examples_seen': 91008, 'step': 6600, 'algorithm': 'activity_selector'}
I0830 18:07:53.650008 133100262716928 run.py:742] (val) algo task_scheduling step 6600: {'selected': 0.8970588235294118, 'score': 0.8970588235294118, 'examples_seen': 91008, 'step': 6600, 'algorithm': 'task_scheduling'}
I0830 18:07:53.650172 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.900, val scores are: activity_selector: 0.903, task_scheduling: 0.897
I0830 18:07:54.797906 133100262716928 run.py:707] Algo activity_selector step 6650 current loss 0.649739, current_train_items 91712.
I0830 18:07:54.802225 133100262716928 run.py:707] Algo task_scheduling step 6650 current loss 1.044091, current_train_items 91712.
I0830 18:07:54.818193 133100262716928 run.py:742] (val) algo activity_selector step 6650: {'selected': 0.8538011695906433, 'score': 0.8538011695906433, 'examples_seen': 91712, 'step': 6650, 'algorithm': 'activity_selector'}
I0830 18:07:54.826720 133100262716928 run.py:742] (val) algo task_scheduling step 6650: {'selected': 0.9383954154727794, 'score': 0.9383954154727794, 'examples_seen': 91712, 'step': 6650, 'algorithm': 'task_scheduling'}
I0830 18:07:54.826865 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.896, val scores are: activity_selector: 0.854, task_scheduling: 0.938
I0830 18:07:55.914622 133100262716928 run.py:707] Algo activity_selector step 6700 current loss 0.759951, current_train_items 92416.
I0830 18:07:55.919055 133100262716928 run.py:707] Algo task_scheduling step 6700 current loss 1.209480, current_train_items 92416.
I0830 18:07:55.938386 133100262716928 run.py:742] (val) algo activity_selector step 6700: {'selected': 0.8901960784313725, 'score': 0.8901960784313725, 'examples_seen': 92416, 'step': 6700, 'algorithm': 'activity_selector'}
I0830 18:07:55.947857 133100262716928 run.py:742] (val) algo task_scheduling step 6700: {'selected': 0.9094514210178454, 'score': 0.9094514210178454, 'examples_seen': 92416, 'step': 6700, 'algorithm': 'task_scheduling'}
I0830 18:07:55.948025 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.900, val scores are: activity_selector: 0.890, task_scheduling: 0.909
I0830 18:07:57.030417 133100262716928 run.py:707] Algo activity_selector step 6750 current loss 0.672787, current_train_items 93088.
I0830 18:07:57.035117 133100262716928 run.py:707] Algo task_scheduling step 6750 current loss 1.089719, current_train_items 93088.
I0830 18:07:57.055568 133100262716928 run.py:742] (val) algo activity_selector step 6750: {'selected': 0.8772635814889335, 'score': 0.8772635814889335, 'examples_seen': 93088, 'step': 6750, 'algorithm': 'activity_selector'}
I0830 18:07:57.063322 133100262716928 run.py:742] (val) algo task_scheduling step 6750: {'selected': 0.917987594762233, 'score': 0.917987594762233, 'examples_seen': 93088, 'step': 6750, 'algorithm': 'task_scheduling'}
I0830 18:07:57.063464 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.898, val scores are: activity_selector: 0.877, task_scheduling: 0.918
I0830 18:07:58.189730 133100262716928 run.py:707] Algo activity_selector step 6800 current loss 0.385941, current_train_items 93776.
I0830 18:07:58.196959 133100262716928 run.py:707] Algo task_scheduling step 6800 current loss 1.409460, current_train_items 93776.
I0830 18:07:58.214846 133100262716928 run.py:742] (val) algo activity_selector step 6800: {'selected': 0.8509803921568627, 'score': 0.8509803921568627, 'examples_seen': 93776, 'step': 6800, 'algorithm': 'activity_selector'}
I0830 18:07:58.222496 133100262716928 run.py:742] (val) algo task_scheduling step 6800: {'selected': 0.9424157303370786, 'score': 0.9424157303370786, 'examples_seen': 93776, 'step': 6800, 'algorithm': 'task_scheduling'}
I0830 18:07:58.222641 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.897, val scores are: activity_selector: 0.851, task_scheduling: 0.942
I0830 18:07:59.311607 133100262716928 run.py:707] Algo activity_selector step 6850 current loss 0.430018, current_train_items 94480.
I0830 18:07:59.315736 133100262716928 run.py:707] Algo task_scheduling step 6850 current loss 0.967333, current_train_items 94480.
I0830 18:07:59.333871 133100262716928 run.py:742] (val) algo activity_selector step 6850: {'selected': 0.8848920863309353, 'score': 0.8848920863309353, 'examples_seen': 94480, 'step': 6850, 'algorithm': 'activity_selector'}
I0830 18:07:59.343011 133100262716928 run.py:742] (val) algo task_scheduling step 6850: {'selected': 0.9307207837648706, 'score': 0.9307207837648706, 'examples_seen': 94480, 'step': 6850, 'algorithm': 'task_scheduling'}
I0830 18:07:59.343172 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.908, val scores are: activity_selector: 0.885, task_scheduling: 0.931
I0830 18:08:00.435546 133100262716928 run.py:707] Algo activity_selector step 6900 current loss 0.738708, current_train_items 95152.
I0830 18:08:00.439814 133100262716928 run.py:707] Algo task_scheduling step 6900 current loss 0.888982, current_train_items 95152.
I0830 18:08:00.456928 133100262716928 run.py:742] (val) algo activity_selector step 6900: {'selected': 0.87374749498998, 'score': 0.87374749498998, 'examples_seen': 95152, 'step': 6900, 'algorithm': 'activity_selector'}
I0830 18:08:00.464505 133100262716928 run.py:742] (val) algo task_scheduling step 6900: {'selected': 0.919889502762431, 'score': 0.919889502762431, 'examples_seen': 95152, 'step': 6900, 'algorithm': 'task_scheduling'}
I0830 18:08:00.464655 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.897, val scores are: activity_selector: 0.874, task_scheduling: 0.920
I0830 18:08:01.645621 133100262716928 run.py:707] Algo activity_selector step 6950 current loss 0.622966, current_train_items 95840.
I0830 18:08:01.651747 133100262716928 run.py:707] Algo task_scheduling step 6950 current loss 1.142262, current_train_items 95840.
I0830 18:08:01.670321 133100262716928 run.py:742] (val) algo activity_selector step 6950: {'selected': 0.8724279835390946, 'score': 0.8724279835390946, 'examples_seen': 95840, 'step': 6950, 'algorithm': 'activity_selector'}
I0830 18:08:01.678484 133100262716928 run.py:742] (val) algo task_scheduling step 6950: {'selected': 0.9465201465201465, 'score': 0.9465201465201465, 'examples_seen': 95840, 'step': 6950, 'algorithm': 'task_scheduling'}
I0830 18:08:01.678651 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.909, val scores are: activity_selector: 0.872, task_scheduling: 0.947
I0830 18:08:02.852251 133100262716928 run.py:707] Algo activity_selector step 7000 current loss 0.521455, current_train_items 96544.
I0830 18:08:02.856804 133100262716928 run.py:707] Algo task_scheduling step 7000 current loss 1.358179, current_train_items 96544.
I0830 18:08:02.873714 133100262716928 run.py:742] (val) algo activity_selector step 7000: {'selected': 0.8711656441717791, 'score': 0.8711656441717791, 'examples_seen': 96544, 'step': 7000, 'algorithm': 'activity_selector'}
I0830 18:08:02.881285 133100262716928 run.py:742] (val) algo task_scheduling step 7000: {'selected': 0.9352112676056338, 'score': 0.9352112676056338, 'examples_seen': 96544, 'step': 7000, 'algorithm': 'task_scheduling'}
I0830 18:08:02.881428 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.903, val scores are: activity_selector: 0.871, task_scheduling: 0.935
I0830 18:08:03.965284 133100262716928 run.py:707] Algo activity_selector step 7050 current loss 0.947135, current_train_items 97232.
I0830 18:08:03.969936 133100262716928 run.py:707] Algo task_scheduling step 7050 current loss 1.714809, current_train_items 97232.
I0830 18:08:03.986348 133100262716928 run.py:742] (val) algo activity_selector step 7050: {'selected': 0.8770642201834862, 'score': 0.8770642201834862, 'examples_seen': 97232, 'step': 7050, 'algorithm': 'activity_selector'}
I0830 18:08:03.993892 133100262716928 run.py:742] (val) algo task_scheduling step 7050: {'selected': 0.927927927927928, 'score': 0.927927927927928, 'examples_seen': 97232, 'step': 7050, 'algorithm': 'task_scheduling'}
I0830 18:08:03.994033 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.902, val scores are: activity_selector: 0.877, task_scheduling: 0.928
I0830 18:08:05.076296 133100262716928 run.py:707] Algo activity_selector step 7100 current loss 0.549367, current_train_items 97920.
I0830 18:08:05.082347 133100262716928 run.py:707] Algo task_scheduling step 7100 current loss 0.822820, current_train_items 97920.
I0830 18:08:05.101677 133100262716928 run.py:742] (val) algo activity_selector step 7100: {'selected': 0.8828828828828829, 'score': 0.8828828828828829, 'examples_seen': 97920, 'step': 7100, 'algorithm': 'activity_selector'}
I0830 18:08:05.113354 133100262716928 run.py:742] (val) algo task_scheduling step 7100: {'selected': 0.9403701165181632, 'score': 0.9403701165181632, 'examples_seen': 97920, 'step': 7100, 'algorithm': 'task_scheduling'}
I0830 18:08:05.113652 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.912, val scores are: activity_selector: 0.883, task_scheduling: 0.940
I0830 18:08:06.178043 133100262716928 run.py:707] Algo activity_selector step 7150 current loss 0.705361, current_train_items 98608.
I0830 18:08:06.182673 133100262716928 run.py:707] Algo task_scheduling step 7150 current loss 0.888952, current_train_items 98608.
I0830 18:08:06.199599 133100262716928 run.py:742] (val) algo activity_selector step 7150: {'selected': 0.8803245436105476, 'score': 0.8803245436105476, 'examples_seen': 98608, 'step': 7150, 'algorithm': 'activity_selector'}
I0830 18:08:06.207139 133100262716928 run.py:742] (val) algo task_scheduling step 7150: {'selected': 0.933609958506224, 'score': 0.933609958506224, 'examples_seen': 98608, 'step': 7150, 'algorithm': 'task_scheduling'}
I0830 18:08:06.207289 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.907, val scores are: activity_selector: 0.880, task_scheduling: 0.934
I0830 18:08:07.317891 133100262716928 run.py:707] Algo activity_selector step 7200 current loss 0.900494, current_train_items 99296.
I0830 18:08:07.322613 133100262716928 run.py:707] Algo task_scheduling step 7200 current loss 0.947344, current_train_items 99296.
I0830 18:08:07.340204 133100262716928 run.py:742] (val) algo activity_selector step 7200: {'selected': 0.888015717092338, 'score': 0.888015717092338, 'examples_seen': 99296, 'step': 7200, 'algorithm': 'activity_selector'}
I0830 18:08:07.347781 133100262716928 run.py:742] (val) algo task_scheduling step 7200: {'selected': 0.944644140905823, 'score': 0.944644140905823, 'examples_seen': 99296, 'step': 7200, 'algorithm': 'task_scheduling'}
I0830 18:08:07.347923 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.916, val scores are: activity_selector: 0.888, task_scheduling: 0.945
I0830 18:08:08.430298 133100262716928 run.py:707] Algo activity_selector step 7250 current loss 0.571933, current_train_items 99984.
I0830 18:08:08.435073 133100262716928 run.py:707] Algo task_scheduling step 7250 current loss 0.849908, current_train_items 99984.
I0830 18:08:08.453238 133100262716928 run.py:742] (val) algo activity_selector step 7250: {'selected': 0.9128787878787878, 'score': 0.9128787878787878, 'examples_seen': 99984, 'step': 7250, 'algorithm': 'activity_selector'}
I0830 18:08:08.461210 133100262716928 run.py:742] (val) algo task_scheduling step 7250: {'selected': 0.9307479224376731, 'score': 0.9307479224376731, 'examples_seen': 99984, 'step': 7250, 'algorithm': 'task_scheduling'}
I0830 18:08:08.461360 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.922, val scores are: activity_selector: 0.913, task_scheduling: 0.931
I0830 18:08:09.521135 133100262716928 run.py:707] Algo activity_selector step 7300 current loss 0.491168, current_train_items 100672.
I0830 18:08:09.527493 133100262716928 run.py:707] Algo task_scheduling step 7300 current loss 0.804013, current_train_items 100672.
I0830 18:08:09.551119 133100262716928 run.py:742] (val) algo activity_selector step 7300: {'selected': 0.874274661508704, 'score': 0.874274661508704, 'examples_seen': 100672, 'step': 7300, 'algorithm': 'activity_selector'}
I0830 18:08:09.559062 133100262716928 run.py:742] (val) algo task_scheduling step 7300: {'selected': 0.906166219839142, 'score': 0.906166219839142, 'examples_seen': 100672, 'step': 7300, 'algorithm': 'task_scheduling'}
I0830 18:08:09.559228 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.890, val scores are: activity_selector: 0.874, task_scheduling: 0.906
I0830 18:08:10.655198 133100262716928 run.py:707] Algo activity_selector step 7350 current loss 0.906365, current_train_items 101360.
I0830 18:08:10.660288 133100262716928 run.py:707] Algo task_scheduling step 7350 current loss 1.230856, current_train_items 101360.
I0830 18:08:10.677769 133100262716928 run.py:742] (val) algo activity_selector step 7350: {'selected': 0.8901734104046243, 'score': 0.8901734104046243, 'examples_seen': 101360, 'step': 7350, 'algorithm': 'activity_selector'}
I0830 18:08:10.686142 133100262716928 run.py:742] (val) algo task_scheduling step 7350: {'selected': 0.8925081433224755, 'score': 0.8925081433224755, 'examples_seen': 101360, 'step': 7350, 'algorithm': 'task_scheduling'}
I0830 18:08:10.686297 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.891, val scores are: activity_selector: 0.890, task_scheduling: 0.893
I0830 18:08:11.782033 133100262716928 run.py:707] Algo activity_selector step 7400 current loss 0.833532, current_train_items 102048.
I0830 18:08:11.786788 133100262716928 run.py:707] Algo task_scheduling step 7400 current loss 1.055067, current_train_items 102048.
I0830 18:08:11.803230 133100262716928 run.py:742] (val) algo activity_selector step 7400: {'selected': 0.8677248677248678, 'score': 0.8677248677248678, 'examples_seen': 102048, 'step': 7400, 'algorithm': 'activity_selector'}
I0830 18:08:11.810792 133100262716928 run.py:742] (val) algo task_scheduling step 7400: {'selected': 0.9158751696065129, 'score': 0.9158751696065129, 'examples_seen': 102048, 'step': 7400, 'algorithm': 'task_scheduling'}
I0830 18:08:11.810930 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.892, val scores are: activity_selector: 0.868, task_scheduling: 0.916
I0830 18:08:12.871759 133100262716928 run.py:707] Algo activity_selector step 7450 current loss 0.964341, current_train_items 102752.
I0830 18:08:12.876623 133100262716928 run.py:707] Algo task_scheduling step 7450 current loss 1.168797, current_train_items 102752.
I0830 18:08:12.893548 133100262716928 run.py:742] (val) algo activity_selector step 7450: {'selected': 0.8710280373831776, 'score': 0.8710280373831776, 'examples_seen': 102752, 'step': 7450, 'algorithm': 'activity_selector'}
I0830 18:08:12.901093 133100262716928 run.py:742] (val) algo task_scheduling step 7450: {'selected': 0.9398601398601399, 'score': 0.9398601398601399, 'examples_seen': 102752, 'step': 7450, 'algorithm': 'task_scheduling'}
I0830 18:08:12.901249 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.905, val scores are: activity_selector: 0.871, task_scheduling: 0.940
I0830 18:08:13.981183 133100262716928 run.py:707] Algo activity_selector step 7500 current loss 0.593654, current_train_items 103424.
I0830 18:08:13.985797 133100262716928 run.py:707] Algo task_scheduling step 7500 current loss 1.017808, current_train_items 103424.
I0830 18:08:14.002753 133100262716928 run.py:742] (val) algo activity_selector step 7500: {'selected': 0.9128014842300556, 'score': 0.9128014842300556, 'examples_seen': 103424, 'step': 7500, 'algorithm': 'activity_selector'}
I0830 18:08:14.010431 133100262716928 run.py:742] (val) algo task_scheduling step 7500: {'selected': 0.9254955570745045, 'score': 0.9254955570745045, 'examples_seen': 103424, 'step': 7500, 'algorithm': 'task_scheduling'}
I0830 18:08:14.010578 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.919, val scores are: activity_selector: 0.913, task_scheduling: 0.925
I0830 18:08:15.119501 133100262716928 run.py:707] Algo activity_selector step 7550 current loss 0.669448, current_train_items 104128.
I0830 18:08:15.125278 133100262716928 run.py:707] Algo task_scheduling step 7550 current loss 1.134269, current_train_items 104128.
I0830 18:08:15.142071 133100262716928 run.py:742] (val) algo activity_selector step 7550: {'selected': 0.8482632541133457, 'score': 0.8482632541133457, 'examples_seen': 104128, 'step': 7550, 'algorithm': 'activity_selector'}
I0830 18:08:15.149713 133100262716928 run.py:742] (val) algo task_scheduling step 7550: {'selected': 0.9054054054054055, 'score': 0.9054054054054055, 'examples_seen': 104128, 'step': 7550, 'algorithm': 'task_scheduling'}
I0830 18:08:15.149858 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.877, val scores are: activity_selector: 0.848, task_scheduling: 0.905
I0830 18:08:16.232053 133100262716928 run.py:707] Algo activity_selector step 7600 current loss 0.672791, current_train_items 104816.
I0830 18:08:16.236605 133100262716928 run.py:707] Algo task_scheduling step 7600 current loss 1.058962, current_train_items 104816.
I0830 18:08:16.253571 133100262716928 run.py:742] (val) algo activity_selector step 7600: {'selected': 0.9097605893186005, 'score': 0.9097605893186005, 'examples_seen': 104816, 'step': 7600, 'algorithm': 'activity_selector'}
I0830 18:08:16.261107 133100262716928 run.py:742] (val) algo task_scheduling step 7600: {'selected': 0.9311064718162839, 'score': 0.9311064718162839, 'examples_seen': 104816, 'step': 7600, 'algorithm': 'task_scheduling'}
I0830 18:08:16.261261 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.920, val scores are: activity_selector: 0.910, task_scheduling: 0.931
I0830 18:08:17.341119 133100262716928 run.py:707] Algo activity_selector step 7650 current loss 0.450929, current_train_items 105488.
I0830 18:08:17.345638 133100262716928 run.py:707] Algo task_scheduling step 7650 current loss 0.944640, current_train_items 105488.
I0830 18:08:17.363123 133100262716928 run.py:742] (val) algo activity_selector step 7650: {'selected': 0.8984374999999999, 'score': 0.8984374999999999, 'examples_seen': 105488, 'step': 7650, 'algorithm': 'activity_selector'}
I0830 18:08:17.371271 133100262716928 run.py:742] (val) algo task_scheduling step 7650: {'selected': 0.9388335704125178, 'score': 0.9388335704125178, 'examples_seen': 105488, 'step': 7650, 'algorithm': 'task_scheduling'}
I0830 18:08:17.371419 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.919, val scores are: activity_selector: 0.898, task_scheduling: 0.939
I0830 18:08:18.476391 133100262716928 run.py:707] Algo activity_selector step 7700 current loss 0.753462, current_train_items 106192.
I0830 18:08:18.481616 133100262716928 run.py:707] Algo task_scheduling step 7700 current loss 0.745901, current_train_items 106192.
I0830 18:08:18.499518 133100262716928 run.py:742] (val) algo activity_selector step 7700: {'selected': 0.9155722326454034, 'score': 0.9155722326454034, 'examples_seen': 106192, 'step': 7700, 'algorithm': 'activity_selector'}
I0830 18:08:18.507655 133100262716928 run.py:742] (val) algo task_scheduling step 7700: {'selected': 0.9160409556313993, 'score': 0.9160409556313993, 'examples_seen': 106192, 'step': 7700, 'algorithm': 'task_scheduling'}
I0830 18:08:18.507818 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.916, val scores are: activity_selector: 0.916, task_scheduling: 0.916
I0830 18:08:19.574436 133100262716928 run.py:707] Algo activity_selector step 7750 current loss 0.841018, current_train_items 106880.
I0830 18:08:19.579335 133100262716928 run.py:707] Algo task_scheduling step 7750 current loss 1.207097, current_train_items 106880.
I0830 18:08:19.596468 133100262716928 run.py:742] (val) algo activity_selector step 7750: {'selected': 0.9076923076923077, 'score': 0.9076923076923077, 'examples_seen': 106880, 'step': 7750, 'algorithm': 'activity_selector'}
I0830 18:08:19.604460 133100262716928 run.py:742] (val) algo task_scheduling step 7750: {'selected': 0.898936170212766, 'score': 0.898936170212766, 'examples_seen': 106880, 'step': 7750, 'algorithm': 'task_scheduling'}
I0830 18:08:19.604623 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.903, val scores are: activity_selector: 0.908, task_scheduling: 0.899
I0830 18:08:20.681834 133100262716928 run.py:707] Algo activity_selector step 7800 current loss 0.541146, current_train_items 107568.
I0830 18:08:20.686522 133100262716928 run.py:707] Algo task_scheduling step 7800 current loss 0.943935, current_train_items 107568.
I0830 18:08:20.703591 133100262716928 run.py:742] (val) algo activity_selector step 7800: {'selected': 0.874766355140187, 'score': 0.874766355140187, 'examples_seen': 107568, 'step': 7800, 'algorithm': 'activity_selector'}
I0830 18:08:20.711223 133100262716928 run.py:742] (val) algo task_scheduling step 7800: {'selected': 0.9272976680384087, 'score': 0.9272976680384087, 'examples_seen': 107568, 'step': 7800, 'algorithm': 'task_scheduling'}
I0830 18:08:20.711380 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.901, val scores are: activity_selector: 0.875, task_scheduling: 0.927
I0830 18:08:21.791690 133100262716928 run.py:707] Algo activity_selector step 7850 current loss 0.664560, current_train_items 108256.
I0830 18:08:21.796212 133100262716928 run.py:707] Algo task_scheduling step 7850 current loss 0.856749, current_train_items 108256.
I0830 18:08:21.812969 133100262716928 run.py:742] (val) algo activity_selector step 7850: {'selected': 0.8731884057971016, 'score': 0.8731884057971016, 'examples_seen': 108256, 'step': 7850, 'algorithm': 'activity_selector'}
I0830 18:08:21.820543 133100262716928 run.py:742] (val) algo task_scheduling step 7850: {'selected': 0.9226666666666665, 'score': 0.9226666666666665, 'examples_seen': 108256, 'step': 7850, 'algorithm': 'task_scheduling'}
I0830 18:08:21.820698 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.898, val scores are: activity_selector: 0.873, task_scheduling: 0.923
I0830 18:08:22.871578 133100262716928 run.py:707] Algo activity_selector step 7900 current loss 0.876261, current_train_items 108960.
I0830 18:08:22.879969 133100262716928 run.py:707] Algo task_scheduling step 7900 current loss 0.795432, current_train_items 108960.
I0830 18:08:22.899672 133100262716928 run.py:742] (val) algo activity_selector step 7900: {'selected': 0.9001751313485116, 'score': 0.9001751313485116, 'examples_seen': 108960, 'step': 7900, 'algorithm': 'activity_selector'}
I0830 18:08:22.910075 133100262716928 run.py:742] (val) algo task_scheduling step 7900: {'selected': 0.9270021261516656, 'score': 0.9270021261516656, 'examples_seen': 108960, 'step': 7900, 'algorithm': 'task_scheduling'}
I0830 18:08:22.910273 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.914, val scores are: activity_selector: 0.900, task_scheduling: 0.927
I0830 18:08:24.023004 133100262716928 run.py:707] Algo activity_selector step 7950 current loss 0.583998, current_train_items 109632.
I0830 18:08:24.027551 133100262716928 run.py:707] Algo task_scheduling step 7950 current loss 1.185959, current_train_items 109632.
I0830 18:08:24.044987 133100262716928 run.py:742] (val) algo activity_selector step 7950: {'selected': 0.8974358974358975, 'score': 0.8974358974358975, 'examples_seen': 109632, 'step': 7950, 'algorithm': 'activity_selector'}
I0830 18:08:24.052633 133100262716928 run.py:742] (val) algo task_scheduling step 7950: {'selected': 0.9335180055401662, 'score': 0.9335180055401662, 'examples_seen': 109632, 'step': 7950, 'algorithm': 'task_scheduling'}
I0830 18:08:24.052774 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.915, val scores are: activity_selector: 0.897, task_scheduling: 0.934
I0830 18:08:25.118767 133100262716928 run.py:707] Algo activity_selector step 8000 current loss 0.826868, current_train_items 110320.
I0830 18:08:25.123181 133100262716928 run.py:707] Algo task_scheduling step 8000 current loss 0.929454, current_train_items 110320.
I0830 18:08:25.142399 133100262716928 run.py:742] (val) algo activity_selector step 8000: {'selected': 0.8974358974358974, 'score': 0.8974358974358974, 'examples_seen': 110320, 'step': 8000, 'algorithm': 'activity_selector'}
I0830 18:08:25.150380 133100262716928 run.py:742] (val) algo task_scheduling step 8000: {'selected': 0.9031821259309412, 'score': 0.9031821259309412, 'examples_seen': 110320, 'step': 8000, 'algorithm': 'task_scheduling'}
I0830 18:08:25.150533 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.900, val scores are: activity_selector: 0.897, task_scheduling: 0.903
I0830 18:08:26.226753 133100262716928 run.py:707] Algo activity_selector step 8050 current loss 0.487138, current_train_items 111024.
I0830 18:08:26.231760 133100262716928 run.py:707] Algo task_scheduling step 8050 current loss 0.905668, current_train_items 111024.
I0830 18:08:26.248840 133100262716928 run.py:742] (val) algo activity_selector step 8050: {'selected': 0.9158878504672897, 'score': 0.9158878504672897, 'examples_seen': 111024, 'step': 8050, 'algorithm': 'activity_selector'}
I0830 18:08:26.256701 133100262716928 run.py:742] (val) algo task_scheduling step 8050: {'selected': 0.9331395348837209, 'score': 0.9331395348837209, 'examples_seen': 111024, 'step': 8050, 'algorithm': 'task_scheduling'}
I0830 18:08:26.256842 133100262716928 run.py:763] Checkpointing best model, best avg val score was -0.500, current avg val score is 0.925, val scores are: activity_selector: 0.916, task_scheduling: 0.933
I0830 18:08:27.344741 133100262716928 run.py:707] Algo activity_selector step 8100 current loss 0.623662, current_train_items 111696.
I0830 18:08:27.349348 133100262716928 run.py:707] Algo task_scheduling step 8100 current loss 0.944878, current_train_items 111696.
I0830 18:08:27.366554 133100262716928 run.py:742] (val) algo activity_selector step 8100: {'selected': 0.8802946593001842, 'score': 0.8802946593001842, 'examples_seen': 111696, 'step': 8100, 'algorithm': 'activity_selector'}
I0830 18:08:27.374167 133100262716928 run.py:742] (val) algo task_scheduling step 8100: {'selected': 0.9335180055401662, 'score': 0.9335180055401662, 'examples_seen': 111696, 'step': 8100, 'algorithm': 'task_scheduling'}
I0830 18:08:27.374341 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.907, val scores are: activity_selector: 0.880, task_scheduling: 0.934
I0830 18:08:28.456229 133100262716928 run.py:707] Algo activity_selector step 8150 current loss 0.943108, current_train_items 112400.
I0830 18:08:28.460753 133100262716928 run.py:707] Algo task_scheduling step 8150 current loss 1.157027, current_train_items 112400.
I0830 18:08:28.478324 133100262716928 run.py:742] (val) algo activity_selector step 8150: {'selected': 0.8741007194244604, 'score': 0.8741007194244604, 'examples_seen': 112400, 'step': 8150, 'algorithm': 'activity_selector'}
I0830 18:08:28.485885 133100262716928 run.py:742] (val) algo task_scheduling step 8150: {'selected': 0.9203539823008849, 'score': 0.9203539823008849, 'examples_seen': 112400, 'step': 8150, 'algorithm': 'task_scheduling'}
I0830 18:08:28.486029 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.897, val scores are: activity_selector: 0.874, task_scheduling: 0.920
I0830 18:08:29.570194 133100262716928 run.py:707] Algo activity_selector step 8200 current loss 0.598195, current_train_items 113088.
I0830 18:08:29.574764 133100262716928 run.py:707] Algo task_scheduling step 8200 current loss 1.112576, current_train_items 113088.
I0830 18:08:29.592346 133100262716928 run.py:742] (val) algo activity_selector step 8200: {'selected': 0.905027932960894, 'score': 0.905027932960894, 'examples_seen': 113088, 'step': 8200, 'algorithm': 'activity_selector'}
I0830 18:08:29.599916 133100262716928 run.py:742] (val) algo task_scheduling step 8200: {'selected': 0.8974854932301741, 'score': 0.8974854932301741, 'examples_seen': 113088, 'step': 8200, 'algorithm': 'task_scheduling'}
I0830 18:08:29.600068 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.901, val scores are: activity_selector: 0.905, task_scheduling: 0.897
I0830 18:08:30.688794 133100262716928 run.py:707] Algo activity_selector step 8250 current loss 0.849066, current_train_items 113760.
I0830 18:08:30.693234 133100262716928 run.py:707] Algo task_scheduling step 8250 current loss 1.010282, current_train_items 113760.
I0830 18:08:30.710338 133100262716928 run.py:742] (val) algo activity_selector step 8250: {'selected': 0.8940269749518305, 'score': 0.8940269749518305, 'examples_seen': 113760, 'step': 8250, 'algorithm': 'activity_selector'}
I0830 18:08:30.717827 133100262716928 run.py:742] (val) algo task_scheduling step 8250: {'selected': 0.9184782608695653, 'score': 0.9184782608695653, 'examples_seen': 113760, 'step': 8250, 'algorithm': 'task_scheduling'}
I0830 18:08:30.717968 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.906, val scores are: activity_selector: 0.894, task_scheduling: 0.918
I0830 18:08:31.821749 133100262716928 run.py:707] Algo activity_selector step 8300 current loss 0.842970, current_train_items 114464.
I0830 18:08:31.826720 133100262716928 run.py:707] Algo task_scheduling step 8300 current loss 0.978902, current_train_items 114464.
I0830 18:08:31.843878 133100262716928 run.py:742] (val) algo activity_selector step 8300: {'selected': 0.8628158844765343, 'score': 0.8628158844765343, 'examples_seen': 114464, 'step': 8300, 'algorithm': 'activity_selector'}
I0830 18:08:31.851608 133100262716928 run.py:742] (val) algo task_scheduling step 8300: {'selected': 0.9157458563535912, 'score': 0.9157458563535912, 'examples_seen': 114464, 'step': 8300, 'algorithm': 'task_scheduling'}
I0830 18:08:31.851753 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.889, val scores are: activity_selector: 0.863, task_scheduling: 0.916
I0830 18:08:32.911621 133100262716928 run.py:707] Algo activity_selector step 8350 current loss 0.755871, current_train_items 115152.
I0830 18:08:32.916121 133100262716928 run.py:707] Algo task_scheduling step 8350 current loss 0.973266, current_train_items 115152.
I0830 18:08:32.933761 133100262716928 run.py:742] (val) algo activity_selector step 8350: {'selected': 0.863406408094435, 'score': 0.863406408094435, 'examples_seen': 115152, 'step': 8350, 'algorithm': 'activity_selector'}
I0830 18:08:32.941368 133100262716928 run.py:742] (val) algo task_scheduling step 8350: {'selected': 0.9193989071038251, 'score': 0.9193989071038251, 'examples_seen': 115152, 'step': 8350, 'algorithm': 'task_scheduling'}
I0830 18:08:32.941520 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.891, val scores are: activity_selector: 0.863, task_scheduling: 0.919
I0830 18:08:34.032335 133100262716928 run.py:707] Algo activity_selector step 8400 current loss 0.339807, current_train_items 115840.
I0830 18:08:34.036769 133100262716928 run.py:707] Algo task_scheduling step 8400 current loss 0.799072, current_train_items 115840.
I0830 18:08:34.054061 133100262716928 run.py:742] (val) algo activity_selector step 8400: {'selected': 0.8660550458715596, 'score': 0.8660550458715596, 'examples_seen': 115840, 'step': 8400, 'algorithm': 'activity_selector'}
I0830 18:08:34.061743 133100262716928 run.py:742] (val) algo task_scheduling step 8400: {'selected': 0.9244383934649422, 'score': 0.9244383934649422, 'examples_seen': 115840, 'step': 8400, 'algorithm': 'task_scheduling'}
I0830 18:08:34.061887 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.895, val scores are: activity_selector: 0.866, task_scheduling: 0.924
I0830 18:08:35.142265 133100262716928 run.py:707] Algo activity_selector step 8450 current loss 0.611091, current_train_items 116528.
I0830 18:08:35.146738 133100262716928 run.py:707] Algo task_scheduling step 8450 current loss 1.334411, current_train_items 116528.
I0830 18:08:35.164311 133100262716928 run.py:742] (val) algo activity_selector step 8450: {'selected': 0.8411867364746946, 'score': 0.8411867364746946, 'examples_seen': 116528, 'step': 8450, 'algorithm': 'activity_selector'}
I0830 18:08:35.171862 133100262716928 run.py:742] (val) algo task_scheduling step 8450: {'selected': 0.9195710455764076, 'score': 0.9195710455764076, 'examples_seen': 116528, 'step': 8450, 'algorithm': 'task_scheduling'}
I0830 18:08:35.172005 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.880, val scores are: activity_selector: 0.841, task_scheduling: 0.920
I0830 18:08:36.227406 133100262716928 run.py:707] Algo activity_selector step 8500 current loss 0.775600, current_train_items 117232.
I0830 18:08:36.232056 133100262716928 run.py:707] Algo task_scheduling step 8500 current loss 1.106179, current_train_items 117232.
I0830 18:08:36.249328 133100262716928 run.py:742] (val) algo activity_selector step 8500: {'selected': 0.876865671641791, 'score': 0.876865671641791, 'examples_seen': 117232, 'step': 8500, 'algorithm': 'activity_selector'}
I0830 18:08:36.256902 133100262716928 run.py:742] (val) algo task_scheduling step 8500: {'selected': 0.9109589041095891, 'score': 0.9109589041095891, 'examples_seen': 117232, 'step': 8500, 'algorithm': 'task_scheduling'}
I0830 18:08:36.257043 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.925, current avg val score is 0.894, val scores are: activity_selector: 0.877, task_scheduling: 0.911
I0830 18:08:37.353079 133100262716928 run.py:707] Algo activity_selector step 8550 current loss 0.661942, current_train_items 117904.
I0830 18:08:37.357761 133100262716928 run.py:707] Algo task_scheduling step 8550 current loss 0.776379, current_train_items 117904.
I0830 18:08:37.375191 133100262716928 run.py:742] (val) algo activity_selector step 8550: {'selected': 0.924812030075188, 'score': 0.924812030075188, 'examples_seen': 117904, 'step': 8550, 'algorithm': 'activity_selector'}
I0830 18:08:37.382915 133100262716928 run.py:742] (val) algo task_scheduling step 8550: {'selected': 0.9321074964639321, 'score': 0.9321074964639321, 'examples_seen': 117904, 'step': 8550, 'algorithm': 'task_scheduling'}
I0830 18:08:37.383067 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.925, current avg val score is 0.928, val scores are: activity_selector: 0.925, task_scheduling: 0.932
I0830 18:08:38.510473 133100262716928 run.py:707] Algo activity_selector step 8600 current loss 0.694308, current_train_items 118592.
I0830 18:08:38.515201 133100262716928 run.py:707] Algo task_scheduling step 8600 current loss 0.671064, current_train_items 118592.
I0830 18:08:38.532248 133100262716928 run.py:742] (val) algo activity_selector step 8600: {'selected': 0.8992248062015504, 'score': 0.8992248062015504, 'examples_seen': 118592, 'step': 8600, 'algorithm': 'activity_selector'}
I0830 18:08:38.539863 133100262716928 run.py:742] (val) algo task_scheduling step 8600: {'selected': 0.9303621169916435, 'score': 0.9303621169916435, 'examples_seen': 118592, 'step': 8600, 'algorithm': 'task_scheduling'}
I0830 18:08:38.540019 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.915, val scores are: activity_selector: 0.899, task_scheduling: 0.930
I0830 18:08:39.623085 133100262716928 run.py:707] Algo activity_selector step 8650 current loss 0.575685, current_train_items 119296.
I0830 18:08:39.627534 133100262716928 run.py:707] Algo task_scheduling step 8650 current loss 0.637186, current_train_items 119296.
I0830 18:08:39.644607 133100262716928 run.py:742] (val) algo activity_selector step 8650: {'selected': 0.8597122302158273, 'score': 0.8597122302158273, 'examples_seen': 119296, 'step': 8650, 'algorithm': 'activity_selector'}
I0830 18:08:39.652182 133100262716928 run.py:742] (val) algo task_scheduling step 8650: {'selected': 0.9255617977528089, 'score': 0.9255617977528089, 'examples_seen': 119296, 'step': 8650, 'algorithm': 'task_scheduling'}
I0830 18:08:39.652322 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.893, val scores are: activity_selector: 0.860, task_scheduling: 0.926
I0830 18:08:40.712574 133100262716928 run.py:707] Algo activity_selector step 8700 current loss 0.863374, current_train_items 119968.
I0830 18:08:40.717130 133100262716928 run.py:707] Algo task_scheduling step 8700 current loss 0.726226, current_train_items 119968.
I0830 18:08:40.952469 133100262716928 run.py:742] (val) algo activity_selector step 8700: {'selected': 0.8747731397459165, 'score': 0.8747731397459165, 'examples_seen': 119968, 'step': 8700, 'algorithm': 'activity_selector'}
I0830 18:08:40.960208 133100262716928 run.py:742] (val) algo task_scheduling step 8700: {'selected': 0.9568294409058741, 'score': 0.9568294409058741, 'examples_seen': 119968, 'step': 8700, 'algorithm': 'task_scheduling'}
I0830 18:08:40.960351 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.916, val scores are: activity_selector: 0.875, task_scheduling: 0.957
I0830 18:08:42.027484 133100262716928 run.py:707] Algo activity_selector step 8750 current loss 0.807065, current_train_items 120672.
I0830 18:08:42.032217 133100262716928 run.py:707] Algo task_scheduling step 8750 current loss 0.645165, current_train_items 120672.
I0830 18:08:42.049210 133100262716928 run.py:742] (val) algo activity_selector step 8750: {'selected': 0.8920353982300885, 'score': 0.8920353982300885, 'examples_seen': 120672, 'step': 8750, 'algorithm': 'activity_selector'}
I0830 18:08:42.056706 133100262716928 run.py:742] (val) algo task_scheduling step 8750: {'selected': 0.9253112033195021, 'score': 0.9253112033195021, 'examples_seen': 120672, 'step': 8750, 'algorithm': 'task_scheduling'}
I0830 18:08:42.056847 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.909, val scores are: activity_selector: 0.892, task_scheduling: 0.925
I0830 18:08:43.119098 133100262716928 run.py:707] Algo activity_selector step 8800 current loss 1.304335, current_train_items 121360.
I0830 18:08:43.123746 133100262716928 run.py:707] Algo task_scheduling step 8800 current loss 1.247064, current_train_items 121360.
I0830 18:08:43.140901 133100262716928 run.py:742] (val) algo activity_selector step 8800: {'selected': 0.9044117647058824, 'score': 0.9044117647058824, 'examples_seen': 121360, 'step': 8800, 'algorithm': 'activity_selector'}
I0830 18:08:43.148426 133100262716928 run.py:742] (val) algo task_scheduling step 8800: {'selected': 0.942240779401531, 'score': 0.942240779401531, 'examples_seen': 121360, 'step': 8800, 'algorithm': 'task_scheduling'}
I0830 18:08:43.148581 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.923, val scores are: activity_selector: 0.904, task_scheduling: 0.942
I0830 18:08:44.210486 133100262716928 run.py:707] Algo activity_selector step 8850 current loss 0.799191, current_train_items 122048.
I0830 18:08:44.214903 133100262716928 run.py:707] Algo task_scheduling step 8850 current loss 1.506951, current_train_items 122048.
I0830 18:08:44.231753 133100262716928 run.py:742] (val) algo activity_selector step 8850: {'selected': 0.8596491228070176, 'score': 0.8596491228070176, 'examples_seen': 122048, 'step': 8850, 'algorithm': 'activity_selector'}
I0830 18:08:44.239478 133100262716928 run.py:742] (val) algo task_scheduling step 8850: {'selected': 0.9197860962566845, 'score': 0.9197860962566845, 'examples_seen': 122048, 'step': 8850, 'algorithm': 'task_scheduling'}
I0830 18:08:44.239622 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.890, val scores are: activity_selector: 0.860, task_scheduling: 0.920
I0830 18:08:45.395093 133100262716928 run.py:707] Algo activity_selector step 8900 current loss 0.877851, current_train_items 122736.
I0830 18:08:45.399636 133100262716928 run.py:707] Algo task_scheduling step 8900 current loss 1.137084, current_train_items 122736.
I0830 18:08:45.416320 133100262716928 run.py:742] (val) algo activity_selector step 8900: {'selected': 0.8692307692307694, 'score': 0.8692307692307694, 'examples_seen': 122736, 'step': 8900, 'algorithm': 'activity_selector'}
I0830 18:08:45.424288 133100262716928 run.py:742] (val) algo task_scheduling step 8900: {'selected': 0.9393728222996516, 'score': 0.9393728222996516, 'examples_seen': 122736, 'step': 8900, 'algorithm': 'task_scheduling'}
I0830 18:08:45.424429 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.904, val scores are: activity_selector: 0.869, task_scheduling: 0.939
I0830 18:08:46.489602 133100262716928 run.py:707] Algo activity_selector step 8950 current loss 0.856098, current_train_items 123424.
I0830 18:08:46.494643 133100262716928 run.py:707] Algo task_scheduling step 8950 current loss 0.617628, current_train_items 123424.
I0830 18:08:46.512462 133100262716928 run.py:742] (val) algo activity_selector step 8950: {'selected': 0.9087301587301587, 'score': 0.9087301587301587, 'examples_seen': 123424, 'step': 8950, 'algorithm': 'activity_selector'}
I0830 18:08:46.519920 133100262716928 run.py:742] (val) algo task_scheduling step 8950: {'selected': 0.9442857142857142, 'score': 0.9442857142857142, 'examples_seen': 123424, 'step': 8950, 'algorithm': 'task_scheduling'}
I0830 18:08:46.520064 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.927, val scores are: activity_selector: 0.909, task_scheduling: 0.944
I0830 18:08:47.619556 133100262716928 run.py:707] Algo activity_selector step 9000 current loss 0.336023, current_train_items 124112.
I0830 18:08:47.624424 133100262716928 run.py:707] Algo task_scheduling step 9000 current loss 0.984051, current_train_items 124112.
I0830 18:08:47.641851 133100262716928 run.py:742] (val) algo activity_selector step 9000: {'selected': 0.8851851851851852, 'score': 0.8851851851851852, 'examples_seen': 124112, 'step': 9000, 'algorithm': 'activity_selector'}
I0830 18:08:47.649483 133100262716928 run.py:742] (val) algo task_scheduling step 9000: {'selected': 0.9444844989185293, 'score': 0.9444844989185293, 'examples_seen': 124112, 'step': 9000, 'algorithm': 'task_scheduling'}
I0830 18:08:47.649627 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.915, val scores are: activity_selector: 0.885, task_scheduling: 0.944
I0830 18:08:48.727659 133100262716928 run.py:707] Algo activity_selector step 9050 current loss 0.514521, current_train_items 124800.
I0830 18:08:48.732097 133100262716928 run.py:707] Algo task_scheduling step 9050 current loss 1.229652, current_train_items 124800.
I0830 18:08:48.750086 133100262716928 run.py:742] (val) algo activity_selector step 9050: {'selected': 0.883720930232558, 'score': 0.883720930232558, 'examples_seen': 124800, 'step': 9050, 'algorithm': 'activity_selector'}
I0830 18:08:48.758147 133100262716928 run.py:742] (val) algo task_scheduling step 9050: {'selected': 0.9475982532751092, 'score': 0.9475982532751092, 'examples_seen': 124800, 'step': 9050, 'algorithm': 'task_scheduling'}
I0830 18:08:48.758308 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.916, val scores are: activity_selector: 0.884, task_scheduling: 0.948
I0830 18:08:49.837085 133100262716928 run.py:707] Algo activity_selector step 9100 current loss 0.481064, current_train_items 125488.
I0830 18:08:49.841873 133100262716928 run.py:707] Algo task_scheduling step 9100 current loss 0.921771, current_train_items 125488.
I0830 18:08:49.860071 133100262716928 run.py:742] (val) algo activity_selector step 9100: {'selected': 0.8952380952380953, 'score': 0.8952380952380953, 'examples_seen': 125488, 'step': 9100, 'algorithm': 'activity_selector'}
I0830 18:08:49.867928 133100262716928 run.py:742] (val) algo task_scheduling step 9100: {'selected': 0.9211618257261411, 'score': 0.9211618257261411, 'examples_seen': 125488, 'step': 9100, 'algorithm': 'task_scheduling'}
I0830 18:08:49.868068 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.908, val scores are: activity_selector: 0.895, task_scheduling: 0.921
I0830 18:08:50.983717 133100262716928 run.py:707] Algo activity_selector step 9150 current loss 0.741807, current_train_items 126176.
I0830 18:08:50.987998 133100262716928 run.py:707] Algo task_scheduling step 9150 current loss 1.016937, current_train_items 126176.
I0830 18:08:51.005411 133100262716928 run.py:742] (val) algo activity_selector step 9150: {'selected': 0.8544061302681992, 'score': 0.8544061302681992, 'examples_seen': 126176, 'step': 9150, 'algorithm': 'activity_selector'}
I0830 18:08:51.013098 133100262716928 run.py:742] (val) algo task_scheduling step 9150: {'selected': 0.9544807965860597, 'score': 0.9544807965860597, 'examples_seen': 126176, 'step': 9150, 'algorithm': 'task_scheduling'}
I0830 18:08:51.013249 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.904, val scores are: activity_selector: 0.854, task_scheduling: 0.954
I0830 18:08:52.135485 133100262716928 run.py:707] Algo activity_selector step 9200 current loss 1.389033, current_train_items 126880.
I0830 18:08:52.140386 133100262716928 run.py:707] Algo task_scheduling step 9200 current loss 1.052591, current_train_items 126880.
I0830 18:08:52.158442 133100262716928 run.py:742] (val) algo activity_selector step 9200: {'selected': 0.8818011257035647, 'score': 0.8818011257035647, 'examples_seen': 126880, 'step': 9200, 'algorithm': 'activity_selector'}
I0830 18:08:52.167421 133100262716928 run.py:742] (val) algo task_scheduling step 9200: {'selected': 0.9354614850798058, 'score': 0.9354614850798058, 'examples_seen': 126880, 'step': 9200, 'algorithm': 'task_scheduling'}
I0830 18:08:52.167572 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.909, val scores are: activity_selector: 0.882, task_scheduling: 0.935
I0830 18:08:53.305669 133100262716928 run.py:707] Algo activity_selector step 9250 current loss 0.598616, current_train_items 127568.
I0830 18:08:53.310247 133100262716928 run.py:707] Algo task_scheduling step 9250 current loss 1.065493, current_train_items 127568.
I0830 18:08:53.327594 133100262716928 run.py:742] (val) algo activity_selector step 9250: {'selected': 0.9080234833659491, 'score': 0.9080234833659491, 'examples_seen': 127568, 'step': 9250, 'algorithm': 'activity_selector'}
I0830 18:08:53.335212 133100262716928 run.py:742] (val) algo task_scheduling step 9250: {'selected': 0.9044414535666218, 'score': 0.9044414535666218, 'examples_seen': 127568, 'step': 9250, 'algorithm': 'task_scheduling'}
I0830 18:08:53.335368 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.906, val scores are: activity_selector: 0.908, task_scheduling: 0.904
I0830 18:08:54.402982 133100262716928 run.py:707] Algo activity_selector step 9300 current loss 1.014054, current_train_items 128240.
I0830 18:08:54.407547 133100262716928 run.py:707] Algo task_scheduling step 9300 current loss 0.827223, current_train_items 128240.
I0830 18:08:54.424603 133100262716928 run.py:742] (val) algo activity_selector step 9300: {'selected': 0.9104204753199269, 'score': 0.9104204753199269, 'examples_seen': 128240, 'step': 9300, 'algorithm': 'activity_selector'}
I0830 18:08:54.432180 133100262716928 run.py:742] (val) algo task_scheduling step 9300: {'selected': 0.9428571428571427, 'score': 0.9428571428571427, 'examples_seen': 128240, 'step': 9300, 'algorithm': 'task_scheduling'}
I0830 18:08:54.432322 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.927, val scores are: activity_selector: 0.910, task_scheduling: 0.943
I0830 18:08:55.536844 133100262716928 run.py:707] Algo activity_selector step 9350 current loss 0.557717, current_train_items 128944.
I0830 18:08:55.541735 133100262716928 run.py:707] Algo task_scheduling step 9350 current loss 0.575398, current_train_items 128944.
I0830 18:08:55.558880 133100262716928 run.py:742] (val) algo activity_selector step 9350: {'selected': 0.8864059590316573, 'score': 0.8864059590316573, 'examples_seen': 128944, 'step': 9350, 'algorithm': 'activity_selector'}
I0830 18:08:55.566536 133100262716928 run.py:742] (val) algo task_scheduling step 9350: {'selected': 0.9183673469387754, 'score': 0.9183673469387754, 'examples_seen': 128944, 'step': 9350, 'algorithm': 'task_scheduling'}
I0830 18:08:55.566674 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.902, val scores are: activity_selector: 0.886, task_scheduling: 0.918
I0830 18:08:56.631582 133100262716928 run.py:707] Algo activity_selector step 9400 current loss 0.629678, current_train_items 129632.
I0830 18:08:56.636198 133100262716928 run.py:707] Algo task_scheduling step 9400 current loss 0.809723, current_train_items 129632.
I0830 18:08:56.653904 133100262716928 run.py:742] (val) algo activity_selector step 9400: {'selected': 0.8768656716417911, 'score': 0.8768656716417911, 'examples_seen': 129632, 'step': 9400, 'algorithm': 'activity_selector'}
I0830 18:08:56.661550 133100262716928 run.py:742] (val) algo task_scheduling step 9400: {'selected': 0.932157394843962, 'score': 0.932157394843962, 'examples_seen': 129632, 'step': 9400, 'algorithm': 'task_scheduling'}
I0830 18:08:56.661701 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.905, val scores are: activity_selector: 0.877, task_scheduling: 0.932
I0830 18:08:57.735676 133100262716928 run.py:707] Algo activity_selector step 9450 current loss 0.902057, current_train_items 130304.
I0830 18:08:57.740264 133100262716928 run.py:707] Algo task_scheduling step 9450 current loss 1.015113, current_train_items 130304.
I0830 18:08:57.757479 133100262716928 run.py:742] (val) algo activity_selector step 9450: {'selected': 0.8472505091649694, 'score': 0.8472505091649694, 'examples_seen': 130304, 'step': 9450, 'algorithm': 'activity_selector'}
I0830 18:08:57.765094 133100262716928 run.py:742] (val) algo task_scheduling step 9450: {'selected': 0.8869565217391304, 'score': 0.8869565217391304, 'examples_seen': 130304, 'step': 9450, 'algorithm': 'task_scheduling'}
I0830 18:08:57.765244 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.867, val scores are: activity_selector: 0.847, task_scheduling: 0.887
I0830 18:08:58.923852 133100262716928 run.py:707] Algo activity_selector step 9500 current loss 0.994027, current_train_items 131008.
I0830 18:08:58.929227 133100262716928 run.py:707] Algo task_scheduling step 9500 current loss 0.866968, current_train_items 131008.
I0830 18:08:58.945680 133100262716928 run.py:742] (val) algo activity_selector step 9500: {'selected': 0.8648648648648649, 'score': 0.8648648648648649, 'examples_seen': 131008, 'step': 9500, 'algorithm': 'activity_selector'}
I0830 18:08:58.953372 133100262716928 run.py:742] (val) algo task_scheduling step 9500: {'selected': 0.939032936229853, 'score': 0.939032936229853, 'examples_seen': 131008, 'step': 9500, 'algorithm': 'task_scheduling'}
I0830 18:08:58.953514 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.902, val scores are: activity_selector: 0.865, task_scheduling: 0.939
I0830 18:09:00.047831 133100262716928 run.py:707] Algo activity_selector step 9550 current loss 0.468615, current_train_items 131712.
I0830 18:09:00.052041 133100262716928 run.py:707] Algo task_scheduling step 9550 current loss 1.162319, current_train_items 131712.
I0830 18:09:00.068427 133100262716928 run.py:742] (val) algo activity_selector step 9550: {'selected': 0.890595009596929, 'score': 0.890595009596929, 'examples_seen': 131712, 'step': 9550, 'algorithm': 'activity_selector'}
I0830 18:09:00.076168 133100262716928 run.py:742] (val) algo task_scheduling step 9550: {'selected': 0.9284750337381916, 'score': 0.9284750337381916, 'examples_seen': 131712, 'step': 9550, 'algorithm': 'task_scheduling'}
I0830 18:09:00.076328 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.910, val scores are: activity_selector: 0.891, task_scheduling: 0.928
I0830 18:09:01.141567 133100262716928 run.py:707] Algo activity_selector step 9600 current loss 0.561577, current_train_items 132384.
I0830 18:09:01.146416 133100262716928 run.py:707] Algo task_scheduling step 9600 current loss 1.022950, current_train_items 132384.
I0830 18:09:01.163423 133100262716928 run.py:742] (val) algo activity_selector step 9600: {'selected': 0.906187624750499, 'score': 0.906187624750499, 'examples_seen': 132384, 'step': 9600, 'algorithm': 'activity_selector'}
I0830 18:09:01.171043 133100262716928 run.py:742] (val) algo task_scheduling step 9600: {'selected': 0.9296928327645051, 'score': 0.9296928327645051, 'examples_seen': 132384, 'step': 9600, 'algorithm': 'task_scheduling'}
I0830 18:09:01.171189 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.918, val scores are: activity_selector: 0.906, task_scheduling: 0.930
I0830 18:09:02.264165 133100262716928 run.py:707] Algo activity_selector step 9650 current loss 0.578866, current_train_items 133072.
I0830 18:09:02.268986 133100262716928 run.py:707] Algo task_scheduling step 9650 current loss 1.661963, current_train_items 133072.
I0830 18:09:02.287735 133100262716928 run.py:742] (val) algo activity_selector step 9650: {'selected': 0.9108159392789373, 'score': 0.9108159392789373, 'examples_seen': 133072, 'step': 9650, 'algorithm': 'activity_selector'}
I0830 18:09:02.295459 133100262716928 run.py:742] (val) algo task_scheduling step 9650: {'selected': 0.9536516853932584, 'score': 0.9536516853932584, 'examples_seen': 133072, 'step': 9650, 'algorithm': 'task_scheduling'}
I0830 18:09:02.295604 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.928, current avg val score is 0.932, val scores are: activity_selector: 0.911, task_scheduling: 0.954
I0830 18:09:03.388122 133100262716928 run.py:707] Algo activity_selector step 9700 current loss 0.936774, current_train_items 133776.
I0830 18:09:03.392682 133100262716928 run.py:707] Algo task_scheduling step 9700 current loss 0.886749, current_train_items 133776.
I0830 18:09:03.409859 133100262716928 run.py:742] (val) algo activity_selector step 9700: {'selected': 0.9429657794676807, 'score': 0.9429657794676807, 'examples_seen': 133776, 'step': 9700, 'algorithm': 'activity_selector'}
I0830 18:09:03.417466 133100262716928 run.py:742] (val) algo task_scheduling step 9700: {'selected': 0.9242320819112627, 'score': 0.9242320819112627, 'examples_seen': 133776, 'step': 9700, 'algorithm': 'task_scheduling'}
I0830 18:09:03.417606 133100262716928 run.py:763] Checkpointing best model, best avg val score was 0.932, current avg val score is 0.934, val scores are: activity_selector: 0.943, task_scheduling: 0.924
I0830 18:09:04.508597 133100262716928 run.py:707] Algo activity_selector step 9750 current loss 0.861533, current_train_items 134448.
I0830 18:09:04.513108 133100262716928 run.py:707] Algo task_scheduling step 9750 current loss 0.858348, current_train_items 134448.
I0830 18:09:04.530652 133100262716928 run.py:742] (val) algo activity_selector step 9750: {'selected': 0.8780487804878049, 'score': 0.8780487804878049, 'examples_seen': 134448, 'step': 9750, 'algorithm': 'activity_selector'}
I0830 18:09:04.538636 133100262716928 run.py:742] (val) algo task_scheduling step 9750: {'selected': 0.9260539046302695, 'score': 0.9260539046302695, 'examples_seen': 134448, 'step': 9750, 'algorithm': 'task_scheduling'}
I0830 18:09:04.538780 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.902, val scores are: activity_selector: 0.878, task_scheduling: 0.926
I0830 18:09:05.606851 133100262716928 run.py:707] Algo activity_selector step 9800 current loss 0.869146, current_train_items 135136.
I0830 18:09:05.611479 133100262716928 run.py:707] Algo task_scheduling step 9800 current loss 0.910758, current_train_items 135136.
I0830 18:09:05.628206 133100262716928 run.py:742] (val) algo activity_selector step 9800: {'selected': 0.9372549019607842, 'score': 0.9372549019607842, 'examples_seen': 135136, 'step': 9800, 'algorithm': 'activity_selector'}
I0830 18:09:05.635716 133100262716928 run.py:742] (val) algo task_scheduling step 9800: {'selected': 0.9260013577732519, 'score': 0.9260013577732519, 'examples_seen': 135136, 'step': 9800, 'algorithm': 'task_scheduling'}
I0830 18:09:05.635857 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.932, val scores are: activity_selector: 0.937, task_scheduling: 0.926
I0830 18:09:06.711463 133100262716928 run.py:707] Algo activity_selector step 9850 current loss 0.429349, current_train_items 135840.
I0830 18:09:06.716022 133100262716928 run.py:707] Algo task_scheduling step 9850 current loss 1.285308, current_train_items 135840.
I0830 18:09:06.732904 133100262716928 run.py:742] (val) algo activity_selector step 9850: {'selected': 0.896551724137931, 'score': 0.896551724137931, 'examples_seen': 135840, 'step': 9850, 'algorithm': 'activity_selector'}
I0830 18:09:06.740550 133100262716928 run.py:742] (val) algo task_scheduling step 9850: {'selected': 0.93353705118411, 'score': 0.93353705118411, 'examples_seen': 135840, 'step': 9850, 'algorithm': 'task_scheduling'}
I0830 18:09:06.740694 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.915, val scores are: activity_selector: 0.897, task_scheduling: 0.934
I0830 18:09:07.814806 133100262716928 run.py:707] Algo activity_selector step 9900 current loss 0.513636, current_train_items 136528.
I0830 18:09:07.819307 133100262716928 run.py:707] Algo task_scheduling step 9900 current loss 0.643954, current_train_items 136528.
I0830 18:09:07.837703 133100262716928 run.py:742] (val) algo activity_selector step 9900: {'selected': 0.9027237354085602, 'score': 0.9027237354085602, 'examples_seen': 136528, 'step': 9900, 'algorithm': 'activity_selector'}
I0830 18:09:07.845419 133100262716928 run.py:742] (val) algo task_scheduling step 9900: {'selected': 0.9430780042164442, 'score': 0.9430780042164442, 'examples_seen': 136528, 'step': 9900, 'algorithm': 'task_scheduling'}
I0830 18:09:07.845567 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.923, val scores are: activity_selector: 0.903, task_scheduling: 0.943
I0830 18:09:08.912591 133100262716928 run.py:707] Algo activity_selector step 9950 current loss 0.752187, current_train_items 137200.
I0830 18:09:08.917257 133100262716928 run.py:707] Algo task_scheduling step 9950 current loss 0.785616, current_train_items 137200.
I0830 18:09:08.934367 133100262716928 run.py:742] (val) algo activity_selector step 9950: {'selected': 0.9073359073359073, 'score': 0.9073359073359073, 'examples_seen': 137200, 'step': 9950, 'algorithm': 'activity_selector'}
I0830 18:09:08.941935 133100262716928 run.py:742] (val) algo task_scheduling step 9950: {'selected': 0.9198080877313229, 'score': 0.9198080877313229, 'examples_seen': 137200, 'step': 9950, 'algorithm': 'task_scheduling'}
I0830 18:09:08.942076 133100262716928 run.py:766] Not saving new best model, best avg val score was 0.934, current avg val score is 0.914, val scores are: activity_selector: 0.907, task_scheduling: 0.920
I0830 18:09:10.025080 133100262716928 run.py:772] Restoring best model from checkpoint...
I0830 18:09:12.948595 133100262716928 run.py:787] (test) algo activity_selector : {'selected': 0.7790262172284644, 'score': 0.7790262172284644, 'examples_seen': 137888, 'step': 10000, 'algorithm': 'activity_selector'}
I0830 18:09:14.175679 133100262716928 run.py:787] (test) algo task_scheduling : {'selected': 0.8629441624365483, 'score': 0.8629441624365483, 'examples_seen': 137888, 'step': 10000, 'algorithm': 'task_scheduling'}
I0830 18:09:14.175802 133100262716928 run.py:789] Done!
