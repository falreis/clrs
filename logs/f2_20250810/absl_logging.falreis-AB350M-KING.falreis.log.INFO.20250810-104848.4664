I0810 10:48:50.832380 135480425092608 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0810 10:48:50.834765 135480425092608 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0810 10:48:51.151463 135480425092608 run.py:410] Model: f2 ['activity_selector']
I0810 10:48:51.151567 135480425092608 run.py:412] algorithms ['activity_selector']
I0810 10:48:51.151736 135480425092608 run.py:413] train_lengths [-1]
I0810 10:48:51.151772 135480425092608 run.py:414] train_batch_size 16
I0810 10:48:51.151870 135480425092608 run.py:415] val_batch_size 8
I0810 10:48:51.151901 135480425092608 run.py:416] test_batch_size 8
I0810 10:48:51.151930 135480425092608 run.py:417] chunked_training True
I0810 10:48:51.152048 135480425092608 run.py:418] chunk_length 16
I0810 10:48:51.152078 135480425092608 run.py:419] train_steps 10000
I0810 10:48:51.152107 135480425092608 run.py:420] eval_every 50
I0810 10:48:51.152135 135480425092608 run.py:421] test_every 500
I0810 10:48:51.152166 135480425092608 run.py:422] learning_rate 0.001
I0810 10:48:51.152253 135480425092608 run.py:423] grad_clip_max_norm 1.0
I0810 10:48:51.152282 135480425092608 run.py:424] dropout_prob 0.1
I0810 10:48:51.152311 135480425092608 run.py:425] hint_teacher_forcing 0.0
I0810 10:48:51.152339 135480425092608 run.py:426] hint_mode encoded_decoded
I0810 10:48:51.152440 135480425092608 run.py:427] hint_repred_mode hard_on_eval
I0810 10:48:51.152469 135480425092608 run.py:428] use_ln False
I0810 10:48:51.152497 135480425092608 run.py:429] use_lstm True
I0810 10:48:51.152533 135480425092608 run.py:430] nb_triplet_fts 8
I0810 10:48:51.152562 135480425092608 run.py:431] encoder_init xavier_on_scalars
I0810 10:48:51.152590 135480425092608 run.py:432] processor_type f2
I0810 10:48:51.152617 135480425092608 run.py:433] checkpoint_path CLRS30
I0810 10:48:51.152644 135480425092608 run.py:434] dataset_path CLRS30
I0810 10:48:51.152672 135480425092608 run.py:435] freeze_processor False
I0810 10:48:51.152700 135480425092608 run.py:436] reduction max
I0810 10:48:51.152731 135480425092608 run.py:437] activation elu
I0810 10:48:51.152759 135480425092608 run.py:438] restore_model 
I0810 10:48:51.152786 135480425092608 run.py:439] gated True
I0810 10:48:51.152814 135480425092608 run.py:440] gated_activation sigmoid
I0810 10:48:51.155518 135480425092608 run.py:466] Creating samplers for algo activity_selector
I0810 10:48:51.155634 135480425092608 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0810 10:48:51.156286 135480425092608 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_train/1.0.0
I0810 10:48:51.159028 135480425092608 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_train/1.0.0
I0810 10:48:51.162340 135480425092608 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_train/1.0.0.
I0810 10:48:51.215972 135480425092608 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split train, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_train/1.0.0
W0810 10:48:51.236576 135480425092608 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x7b377a0c2de0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0810 10:48:51.317096 135480425092608 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0810 10:48:51.317717 135480425092608 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_val/1.0.0
I0810 10:48:51.320173 135480425092608 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_val/1.0.0
I0810 10:48:51.322077 135480425092608 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_val/1.0.0.
I0810 10:48:51.355363 135480425092608 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split val, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_val/1.0.0
I0810 10:48:51.431755 135480425092608 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0810 10:48:51.432319 135480425092608 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0810 10:48:51.434813 135480425092608 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0810 10:48:51.436718 135480425092608 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0810 10:48:51.469753 135480425092608 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0810 10:49:13.237831 135480425092608 run.py:689] Algo activity_selector step 0 current loss 7.040636, current_train_items 16.
I0810 10:49:18.585282 135480425092608 run.py:724] (val) algo activity_selector step 0: {'selected': 0.28571428571428575, 'score': 0.28571428571428575, 'examples_seen': 16, 'step': 0, 'algorithm': 'activity_selector'}
I0810 10:49:18.585447 135480425092608 run.py:745] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.286, val scores are: activity_selector: 0.286
I0810 10:49:19.308869 135480425092608 run.py:689] Algo activity_selector step 50 current loss 5.674488, current_train_items 768.
I0810 10:49:19.406161 135480425092608 run.py:724] (val) algo activity_selector step 50: {'selected': 0.6161137440758294, 'score': 0.6161137440758294, 'examples_seen': 768, 'step': 50, 'algorithm': 'activity_selector'}
I0810 10:49:19.406397 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.286, current avg val score is 0.616, val scores are: activity_selector: 0.616
I0810 10:49:20.127447 135480425092608 run.py:689] Algo activity_selector step 100 current loss 5.557369, current_train_items 1520.
I0810 10:49:20.227998 135480425092608 run.py:724] (val) algo activity_selector step 100: {'selected': 0.030303030303030307, 'score': 0.030303030303030307, 'examples_seen': 1520, 'step': 100, 'algorithm': 'activity_selector'}
I0810 10:49:20.228235 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.616, current avg val score is 0.030, val scores are: activity_selector: 0.030
I0810 10:49:20.934794 135480425092608 run.py:689] Algo activity_selector step 150 current loss 5.523181, current_train_items 2288.
I0810 10:49:21.030902 135480425092608 run.py:724] (val) algo activity_selector step 150: {'selected': 0.7166666666666666, 'score': 0.7166666666666666, 'examples_seen': 2288, 'step': 150, 'algorithm': 'activity_selector'}
I0810 10:49:21.031119 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.616, current avg val score is 0.717, val scores are: activity_selector: 0.717
I0810 10:49:21.740081 135480425092608 run.py:689] Algo activity_selector step 200 current loss 5.241833, current_train_items 3040.
I0810 10:49:21.851601 135480425092608 run.py:724] (val) algo activity_selector step 200: {'selected': 0.7244094488188977, 'score': 0.7244094488188977, 'examples_seen': 3040, 'step': 200, 'algorithm': 'activity_selector'}
I0810 10:49:21.851820 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.717, current avg val score is 0.724, val scores are: activity_selector: 0.724
I0810 10:49:22.560644 135480425092608 run.py:689] Algo activity_selector step 250 current loss 4.988855, current_train_items 3792.
I0810 10:49:22.669612 135480425092608 run.py:724] (val) algo activity_selector step 250: {'selected': 0.3431952662721894, 'score': 0.3431952662721894, 'examples_seen': 3792, 'step': 250, 'algorithm': 'activity_selector'}
I0810 10:49:22.669845 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.724, current avg val score is 0.343, val scores are: activity_selector: 0.343
I0810 10:49:23.368352 135480425092608 run.py:689] Algo activity_selector step 300 current loss 4.532368, current_train_items 4544.
I0810 10:49:23.473034 135480425092608 run.py:724] (val) algo activity_selector step 300: {'selected': 0.7235772357723578, 'score': 0.7235772357723578, 'examples_seen': 4544, 'step': 300, 'algorithm': 'activity_selector'}
I0810 10:49:23.473257 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.724, current avg val score is 0.724, val scores are: activity_selector: 0.724
I0810 10:49:24.187500 135480425092608 run.py:689] Algo activity_selector step 350 current loss 3.947362, current_train_items 5296.
I0810 10:49:24.275933 135480425092608 run.py:724] (val) algo activity_selector step 350: {'selected': 0.638095238095238, 'score': 0.638095238095238, 'examples_seen': 5296, 'step': 350, 'algorithm': 'activity_selector'}
I0810 10:49:24.276173 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.724, current avg val score is 0.638, val scores are: activity_selector: 0.638
I0810 10:49:24.982330 135480425092608 run.py:689] Algo activity_selector step 400 current loss 3.894732, current_train_items 6048.
I0810 10:49:25.077642 135480425092608 run.py:724] (val) algo activity_selector step 400: {'selected': 0.6146788990825689, 'score': 0.6146788990825689, 'examples_seen': 6048, 'step': 400, 'algorithm': 'activity_selector'}
I0810 10:49:25.077866 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.724, current avg val score is 0.615, val scores are: activity_selector: 0.615
I0810 10:49:25.768575 135480425092608 run.py:689] Algo activity_selector step 450 current loss 4.130407, current_train_items 6800.
I0810 10:49:25.881406 135480425092608 run.py:724] (val) algo activity_selector step 450: {'selected': 0.7083333333333333, 'score': 0.7083333333333333, 'examples_seen': 6800, 'step': 450, 'algorithm': 'activity_selector'}
I0810 10:49:25.881642 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.724, current avg val score is 0.708, val scores are: activity_selector: 0.708
I0810 10:49:26.587873 135480425092608 run.py:689] Algo activity_selector step 500 current loss 3.495683, current_train_items 7552.
I0810 10:49:26.685929 135480425092608 run.py:724] (val) algo activity_selector step 500: {'selected': 0.7447698744769875, 'score': 0.7447698744769875, 'examples_seen': 7552, 'step': 500, 'algorithm': 'activity_selector'}
I0810 10:49:26.686151 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.724, current avg val score is 0.745, val scores are: activity_selector: 0.745
I0810 10:49:27.395073 135480425092608 run.py:689] Algo activity_selector step 550 current loss 3.355896, current_train_items 8304.
I0810 10:49:27.507100 135480425092608 run.py:724] (val) algo activity_selector step 550: {'selected': 0.702928870292887, 'score': 0.702928870292887, 'examples_seen': 8304, 'step': 550, 'algorithm': 'activity_selector'}
I0810 10:49:27.507326 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.745, current avg val score is 0.703, val scores are: activity_selector: 0.703
I0810 10:49:28.213046 135480425092608 run.py:689] Algo activity_selector step 600 current loss 3.514239, current_train_items 9056.
I0810 10:49:28.308348 135480425092608 run.py:724] (val) algo activity_selector step 600: {'selected': 0.6866952789699571, 'score': 0.6866952789699571, 'examples_seen': 9056, 'step': 600, 'algorithm': 'activity_selector'}
I0810 10:49:28.308492 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.745, current avg val score is 0.687, val scores are: activity_selector: 0.687
I0810 10:49:29.014090 135480425092608 run.py:689] Algo activity_selector step 650 current loss 3.415915, current_train_items 9808.
I0810 10:49:29.110142 135480425092608 run.py:724] (val) algo activity_selector step 650: {'selected': 0.8091603053435115, 'score': 0.8091603053435115, 'examples_seen': 9808, 'step': 650, 'algorithm': 'activity_selector'}
I0810 10:49:29.110366 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.745, current avg val score is 0.809, val scores are: activity_selector: 0.809
I0810 10:49:29.836698 135480425092608 run.py:689] Algo activity_selector step 700 current loss 2.785304, current_train_items 10560.
I0810 10:49:29.933039 135480425092608 run.py:724] (val) algo activity_selector step 700: {'selected': 0.7637795275590551, 'score': 0.7637795275590551, 'examples_seen': 10560, 'step': 700, 'algorithm': 'activity_selector'}
I0810 10:49:29.933304 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.809, current avg val score is 0.764, val scores are: activity_selector: 0.764
I0810 10:49:30.639921 135480425092608 run.py:689] Algo activity_selector step 750 current loss 3.122077, current_train_items 11312.
I0810 10:49:30.738796 135480425092608 run.py:724] (val) algo activity_selector step 750: {'selected': 0.7467811158798283, 'score': 0.7467811158798283, 'examples_seen': 11312, 'step': 750, 'algorithm': 'activity_selector'}
I0810 10:49:30.739018 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.809, current avg val score is 0.747, val scores are: activity_selector: 0.747
I0810 10:49:31.446156 135480425092608 run.py:689] Algo activity_selector step 800 current loss 2.635191, current_train_items 12064.
I0810 10:49:31.542982 135480425092608 run.py:724] (val) algo activity_selector step 800: {'selected': 0.8150943396226417, 'score': 0.8150943396226417, 'examples_seen': 12064, 'step': 800, 'algorithm': 'activity_selector'}
I0810 10:49:31.543202 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.809, current avg val score is 0.815, val scores are: activity_selector: 0.815
I0810 10:49:32.253945 135480425092608 run.py:689] Algo activity_selector step 850 current loss 3.022156, current_train_items 12816.
I0810 10:49:32.362654 135480425092608 run.py:724] (val) algo activity_selector step 850: {'selected': 0.748898678414097, 'score': 0.748898678414097, 'examples_seen': 12816, 'step': 850, 'algorithm': 'activity_selector'}
I0810 10:49:32.362879 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.815, current avg val score is 0.749, val scores are: activity_selector: 0.749
I0810 10:49:33.070307 135480425092608 run.py:689] Algo activity_selector step 900 current loss 2.117996, current_train_items 13568.
I0810 10:49:33.169053 135480425092608 run.py:724] (val) algo activity_selector step 900: {'selected': 0.801556420233463, 'score': 0.801556420233463, 'examples_seen': 13568, 'step': 900, 'algorithm': 'activity_selector'}
I0810 10:49:33.169273 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.815, current avg val score is 0.802, val scores are: activity_selector: 0.802
I0810 10:49:33.878100 135480425092608 run.py:689] Algo activity_selector step 950 current loss 1.593291, current_train_items 14320.
I0810 10:49:33.975381 135480425092608 run.py:724] (val) algo activity_selector step 950: {'selected': 0.8273092369477912, 'score': 0.8273092369477912, 'examples_seen': 14320, 'step': 950, 'algorithm': 'activity_selector'}
I0810 10:49:33.975613 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.815, current avg val score is 0.827, val scores are: activity_selector: 0.827
I0810 10:49:34.702794 135480425092608 run.py:689] Algo activity_selector step 1000 current loss 5.136709, current_train_items 15088.
I0810 10:49:34.801715 135480425092608 run.py:724] (val) algo activity_selector step 1000: {'selected': 0.8, 'score': 0.8, 'examples_seen': 15088, 'step': 1000, 'algorithm': 'activity_selector'}
I0810 10:49:34.801937 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.827, current avg val score is 0.800, val scores are: activity_selector: 0.800
I0810 10:49:35.506696 135480425092608 run.py:689] Algo activity_selector step 1050 current loss 4.685065, current_train_items 15840.
I0810 10:49:35.603601 135480425092608 run.py:724] (val) algo activity_selector step 1050: {'selected': 0.8016528925619835, 'score': 0.8016528925619835, 'examples_seen': 15840, 'step': 1050, 'algorithm': 'activity_selector'}
I0810 10:49:35.603828 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.827, current avg val score is 0.802, val scores are: activity_selector: 0.802
I0810 10:49:36.291505 135480425092608 run.py:689] Algo activity_selector step 1100 current loss 3.909916, current_train_items 16592.
I0810 10:49:36.402750 135480425092608 run.py:724] (val) algo activity_selector step 1100: {'selected': 0.8217054263565892, 'score': 0.8217054263565892, 'examples_seen': 16592, 'step': 1100, 'algorithm': 'activity_selector'}
I0810 10:49:36.402973 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.827, current avg val score is 0.822, val scores are: activity_selector: 0.822
I0810 10:49:37.110551 135480425092608 run.py:689] Algo activity_selector step 1150 current loss 3.564691, current_train_items 17344.
I0810 10:49:37.207464 135480425092608 run.py:724] (val) algo activity_selector step 1150: {'selected': 0.856, 'score': 0.856, 'examples_seen': 17344, 'step': 1150, 'algorithm': 'activity_selector'}
I0810 10:49:37.207699 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.827, current avg val score is 0.856, val scores are: activity_selector: 0.856
I0810 10:49:37.935554 135480425092608 run.py:689] Algo activity_selector step 1200 current loss 3.216531, current_train_items 18096.
I0810 10:49:38.032372 135480425092608 run.py:724] (val) algo activity_selector step 1200: {'selected': 0.8799999999999999, 'score': 0.8799999999999999, 'examples_seen': 18096, 'step': 1200, 'algorithm': 'activity_selector'}
I0810 10:49:38.032623 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.856, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0810 10:49:38.743618 135480425092608 run.py:689] Algo activity_selector step 1250 current loss 2.901504, current_train_items 18848.
I0810 10:49:38.855454 135480425092608 run.py:724] (val) algo activity_selector step 1250: {'selected': 0.8880597014925373, 'score': 0.8880597014925373, 'examples_seen': 18848, 'step': 1250, 'algorithm': 'activity_selector'}
I0810 10:49:38.855715 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.880, current avg val score is 0.888, val scores are: activity_selector: 0.888
I0810 10:49:39.570255 135480425092608 run.py:689] Algo activity_selector step 1300 current loss 3.068510, current_train_items 19600.
I0810 10:49:39.680516 135480425092608 run.py:724] (val) algo activity_selector step 1300: {'selected': 0.8413284132841328, 'score': 0.8413284132841328, 'examples_seen': 19600, 'step': 1300, 'algorithm': 'activity_selector'}
I0810 10:49:39.680793 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.888, current avg val score is 0.841, val scores are: activity_selector: 0.841
I0810 10:49:40.388499 135480425092608 run.py:689] Algo activity_selector step 1350 current loss 2.672827, current_train_items 20352.
I0810 10:49:40.485841 135480425092608 run.py:724] (val) algo activity_selector step 1350: {'selected': 0.7686274509803921, 'score': 0.7686274509803921, 'examples_seen': 20352, 'step': 1350, 'algorithm': 'activity_selector'}
I0810 10:49:40.486094 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.888, current avg val score is 0.769, val scores are: activity_selector: 0.769
I0810 10:49:41.178347 135480425092608 run.py:689] Algo activity_selector step 1400 current loss 2.576893, current_train_items 21104.
I0810 10:49:41.291391 135480425092608 run.py:724] (val) algo activity_selector step 1400: {'selected': 0.8796992481203008, 'score': 0.8796992481203008, 'examples_seen': 21104, 'step': 1400, 'algorithm': 'activity_selector'}
I0810 10:49:41.291671 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.888, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0810 10:49:41.999676 135480425092608 run.py:689] Algo activity_selector step 1450 current loss 2.496984, current_train_items 21856.
I0810 10:49:42.095898 135480425092608 run.py:724] (val) algo activity_selector step 1450: {'selected': 0.8296296296296297, 'score': 0.8296296296296297, 'examples_seen': 21856, 'step': 1450, 'algorithm': 'activity_selector'}
I0810 10:49:42.096121 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.888, current avg val score is 0.830, val scores are: activity_selector: 0.830
I0810 10:49:42.788317 135480425092608 run.py:689] Algo activity_selector step 1500 current loss 2.317880, current_train_items 22608.
I0810 10:49:42.900438 135480425092608 run.py:724] (val) algo activity_selector step 1500: {'selected': 0.8897338403041826, 'score': 0.8897338403041826, 'examples_seen': 22608, 'step': 1500, 'algorithm': 'activity_selector'}
I0810 10:49:42.900700 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.888, current avg val score is 0.890, val scores are: activity_selector: 0.890
I0810 10:49:43.644618 135480425092608 run.py:689] Algo activity_selector step 1550 current loss 2.144800, current_train_items 23360.
I0810 10:49:43.726711 135480425092608 run.py:724] (val) algo activity_selector step 1550: {'selected': 0.8616600790513834, 'score': 0.8616600790513834, 'examples_seen': 23360, 'step': 1550, 'algorithm': 'activity_selector'}
I0810 10:49:43.726957 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.890, current avg val score is 0.862, val scores are: activity_selector: 0.862
I0810 10:49:44.435771 135480425092608 run.py:689] Algo activity_selector step 1600 current loss 1.902730, current_train_items 24112.
I0810 10:49:44.533349 135480425092608 run.py:724] (val) algo activity_selector step 1600: {'selected': 0.8988764044943821, 'score': 0.8988764044943821, 'examples_seen': 24112, 'step': 1600, 'algorithm': 'activity_selector'}
I0810 10:49:44.533583 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.890, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0810 10:49:45.260753 135480425092608 run.py:689] Algo activity_selector step 1650 current loss 1.470612, current_train_items 24864.
I0810 10:49:45.358712 135480425092608 run.py:724] (val) algo activity_selector step 1650: {'selected': 0.8625954198473283, 'score': 0.8625954198473283, 'examples_seen': 24864, 'step': 1650, 'algorithm': 'activity_selector'}
I0810 10:49:45.358932 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.899, current avg val score is 0.863, val scores are: activity_selector: 0.863
I0810 10:49:46.067082 135480425092608 run.py:689] Algo activity_selector step 1700 current loss 2.017459, current_train_items 25616.
I0810 10:49:46.164319 135480425092608 run.py:724] (val) algo activity_selector step 1700: {'selected': 0.8932806324110673, 'score': 0.8932806324110673, 'examples_seen': 25616, 'step': 1700, 'algorithm': 'activity_selector'}
I0810 10:49:46.164557 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.899, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0810 10:49:46.872654 135480425092608 run.py:689] Algo activity_selector step 1750 current loss 2.802403, current_train_items 26368.
I0810 10:49:46.969684 135480425092608 run.py:724] (val) algo activity_selector step 1750: {'selected': 0.8515625, 'score': 0.8515625, 'examples_seen': 26368, 'step': 1750, 'algorithm': 'activity_selector'}
I0810 10:49:46.969962 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.899, current avg val score is 0.852, val scores are: activity_selector: 0.852
I0810 10:49:47.678677 135480425092608 run.py:689] Algo activity_selector step 1800 current loss 0.934349, current_train_items 27120.
I0810 10:49:47.775777 135480425092608 run.py:724] (val) algo activity_selector step 1800: {'selected': 0.8828125, 'score': 0.8828125, 'examples_seen': 27120, 'step': 1800, 'algorithm': 'activity_selector'}
I0810 10:49:47.776025 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.899, current avg val score is 0.883, val scores are: activity_selector: 0.883
I0810 10:49:48.484583 135480425092608 run.py:689] Algo activity_selector step 1850 current loss 4.980514, current_train_items 27888.
I0810 10:49:48.581989 135480425092608 run.py:724] (val) algo activity_selector step 1850: {'selected': 0.9166666666666667, 'score': 0.9166666666666667, 'examples_seen': 27888, 'step': 1850, 'algorithm': 'activity_selector'}
I0810 10:49:48.582234 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.899, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0810 10:49:49.307059 135480425092608 run.py:689] Algo activity_selector step 1900 current loss 4.374842, current_train_items 28640.
I0810 10:49:49.403447 135480425092608 run.py:724] (val) algo activity_selector step 1900: {'selected': 0.9019607843137256, 'score': 0.9019607843137256, 'examples_seen': 28640, 'step': 1900, 'algorithm': 'activity_selector'}
I0810 10:49:49.403679 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.917, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0810 10:49:50.091294 135480425092608 run.py:689] Algo activity_selector step 1950 current loss 3.926970, current_train_items 29392.
I0810 10:49:50.330087 135480425092608 run.py:724] (val) algo activity_selector step 1950: {'selected': 0.8433734939759037, 'score': 0.8433734939759037, 'examples_seen': 29392, 'step': 1950, 'algorithm': 'activity_selector'}
I0810 10:49:50.330233 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.917, current avg val score is 0.843, val scores are: activity_selector: 0.843
I0810 10:49:51.031940 135480425092608 run.py:689] Algo activity_selector step 2000 current loss 3.164341, current_train_items 30144.
I0810 10:49:51.130342 135480425092608 run.py:724] (val) algo activity_selector step 2000: {'selected': 0.8735632183908046, 'score': 0.8735632183908046, 'examples_seen': 30144, 'step': 2000, 'algorithm': 'activity_selector'}
I0810 10:49:51.130577 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.917, current avg val score is 0.874, val scores are: activity_selector: 0.874
I0810 10:49:51.838379 135480425092608 run.py:689] Algo activity_selector step 2050 current loss 2.976086, current_train_items 30896.
I0810 10:49:51.935678 135480425092608 run.py:724] (val) algo activity_selector step 2050: {'selected': 0.8571428571428572, 'score': 0.8571428571428572, 'examples_seen': 30896, 'step': 2050, 'algorithm': 'activity_selector'}
I0810 10:49:51.935929 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.917, current avg val score is 0.857, val scores are: activity_selector: 0.857
I0810 10:49:52.628752 135480425092608 run.py:689] Algo activity_selector step 2100 current loss 2.674557, current_train_items 31648.
I0810 10:49:52.740693 135480425092608 run.py:724] (val) algo activity_selector step 2100: {'selected': 0.8731343283582089, 'score': 0.8731343283582089, 'examples_seen': 31648, 'step': 2100, 'algorithm': 'activity_selector'}
I0810 10:49:52.740930 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.917, current avg val score is 0.873, val scores are: activity_selector: 0.873
I0810 10:49:53.448334 135480425092608 run.py:689] Algo activity_selector step 2150 current loss 2.508609, current_train_items 32400.
I0810 10:49:53.543804 135480425092608 run.py:724] (val) algo activity_selector step 2150: {'selected': 0.8880597014925373, 'score': 0.8880597014925373, 'examples_seen': 32400, 'step': 2150, 'algorithm': 'activity_selector'}
I0810 10:49:53.544026 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.917, current avg val score is 0.888, val scores are: activity_selector: 0.888
I0810 10:49:54.236030 135480425092608 run.py:689] Algo activity_selector step 2200 current loss 2.372022, current_train_items 33152.
I0810 10:49:54.349236 135480425092608 run.py:724] (val) algo activity_selector step 2200: {'selected': 0.8571428571428571, 'score': 0.8571428571428571, 'examples_seen': 33152, 'step': 2200, 'algorithm': 'activity_selector'}
I0810 10:49:54.349458 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.917, current avg val score is 0.857, val scores are: activity_selector: 0.857
I0810 10:49:55.041507 135480425092608 run.py:689] Algo activity_selector step 2250 current loss 2.481826, current_train_items 33904.
I0810 10:49:55.154048 135480425092608 run.py:724] (val) algo activity_selector step 2250: {'selected': 0.9049429657794676, 'score': 0.9049429657794676, 'examples_seen': 33904, 'step': 2250, 'algorithm': 'activity_selector'}
I0810 10:49:55.154275 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.917, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0810 10:49:55.862578 135480425092608 run.py:689] Algo activity_selector step 2300 current loss 2.467666, current_train_items 34656.
I0810 10:49:55.956464 135480425092608 run.py:724] (val) algo activity_selector step 2300: {'selected': 0.9302325581395349, 'score': 0.9302325581395349, 'examples_seen': 34656, 'step': 2300, 'algorithm': 'activity_selector'}
I0810 10:49:55.956718 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.917, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0810 10:49:56.674439 135480425092608 run.py:689] Algo activity_selector step 2350 current loss 2.385792, current_train_items 35408.
I0810 10:49:56.771036 135480425092608 run.py:724] (val) algo activity_selector step 2350: {'selected': 0.9285714285714285, 'score': 0.9285714285714285, 'examples_seen': 35408, 'step': 2350, 'algorithm': 'activity_selector'}
I0810 10:49:56.771224 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.930, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0810 10:49:57.473416 135480425092608 run.py:689] Algo activity_selector step 2400 current loss 1.887486, current_train_items 36160.
I0810 10:49:57.570703 135480425092608 run.py:724] (val) algo activity_selector step 2400: {'selected': 0.8863636363636365, 'score': 0.8863636363636365, 'examples_seen': 36160, 'step': 2400, 'algorithm': 'activity_selector'}
I0810 10:49:57.570933 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.930, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0810 10:49:58.262575 135480425092608 run.py:689] Algo activity_selector step 2450 current loss 1.582042, current_train_items 36912.
I0810 10:49:58.372396 135480425092608 run.py:724] (val) algo activity_selector step 2450: {'selected': 0.9118773946360154, 'score': 0.9118773946360154, 'examples_seen': 36912, 'step': 2450, 'algorithm': 'activity_selector'}
I0810 10:49:58.372642 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.930, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0810 10:49:59.073384 135480425092608 run.py:689] Algo activity_selector step 2500 current loss 1.566188, current_train_items 37664.
I0810 10:49:59.167503 135480425092608 run.py:724] (val) algo activity_selector step 2500: {'selected': 0.8949416342412451, 'score': 0.8949416342412451, 'examples_seen': 37664, 'step': 2500, 'algorithm': 'activity_selector'}
I0810 10:49:59.167664 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.930, current avg val score is 0.895, val scores are: activity_selector: 0.895
I0810 10:49:59.866965 135480425092608 run.py:689] Algo activity_selector step 2550 current loss 1.328707, current_train_items 38416.
I0810 10:49:59.965345 135480425092608 run.py:724] (val) algo activity_selector step 2550: {'selected': 0.9260700389105059, 'score': 0.9260700389105059, 'examples_seen': 38416, 'step': 2550, 'algorithm': 'activity_selector'}
I0810 10:49:59.965641 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.930, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0810 10:50:00.671610 135480425092608 run.py:689] Algo activity_selector step 2600 current loss 1.281937, current_train_items 39168.
I0810 10:50:00.769644 135480425092608 run.py:724] (val) algo activity_selector step 2600: {'selected': 0.9160305343511451, 'score': 0.9160305343511451, 'examples_seen': 39168, 'step': 2600, 'algorithm': 'activity_selector'}
I0810 10:50:00.769867 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.930, current avg val score is 0.916, val scores are: activity_selector: 0.916
I0810 10:50:01.459698 135480425092608 run.py:689] Algo activity_selector step 2650 current loss 0.306587, current_train_items 39920.
I0810 10:50:01.570222 135480425092608 run.py:724] (val) algo activity_selector step 2650: {'selected': 0.9494163424124514, 'score': 0.9494163424124514, 'examples_seen': 39920, 'step': 2650, 'algorithm': 'activity_selector'}
I0810 10:50:01.570440 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.930, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0810 10:50:02.296007 135480425092608 run.py:689] Algo activity_selector step 2700 current loss 4.796250, current_train_items 40688.
I0810 10:50:02.394685 135480425092608 run.py:724] (val) algo activity_selector step 2700: {'selected': 0.8778625954198475, 'score': 0.8778625954198475, 'examples_seen': 40688, 'step': 2700, 'algorithm': 'activity_selector'}
I0810 10:50:02.394908 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.949, current avg val score is 0.878, val scores are: activity_selector: 0.878
I0810 10:50:03.066327 135480425092608 run.py:689] Algo activity_selector step 2750 current loss 4.568654, current_train_items 41440.
I0810 10:50:03.191555 135480425092608 run.py:724] (val) algo activity_selector step 2750: {'selected': 0.8897338403041826, 'score': 0.8897338403041826, 'examples_seen': 41440, 'step': 2750, 'algorithm': 'activity_selector'}
I0810 10:50:03.191776 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.949, current avg val score is 0.890, val scores are: activity_selector: 0.890
I0810 10:50:03.890020 135480425092608 run.py:689] Algo activity_selector step 2800 current loss 3.805988, current_train_items 42192.
I0810 10:50:03.987299 135480425092608 run.py:724] (val) algo activity_selector step 2800: {'selected': 0.9063670411985019, 'score': 0.9063670411985019, 'examples_seen': 42192, 'step': 2800, 'algorithm': 'activity_selector'}
I0810 10:50:03.987565 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.949, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0810 10:50:04.692341 135480425092608 run.py:689] Algo activity_selector step 2850 current loss 3.155560, current_train_items 42944.
I0810 10:50:04.788200 135480425092608 run.py:724] (val) algo activity_selector step 2850: {'selected': 0.8984375, 'score': 0.8984375, 'examples_seen': 42944, 'step': 2850, 'algorithm': 'activity_selector'}
I0810 10:50:04.788447 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.949, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0810 10:50:05.508545 135480425092608 run.py:689] Algo activity_selector step 2900 current loss 2.855319, current_train_items 43696.
I0810 10:50:05.591704 135480425092608 run.py:724] (val) algo activity_selector step 2900: {'selected': 0.9090909090909091, 'score': 0.9090909090909091, 'examples_seen': 43696, 'step': 2900, 'algorithm': 'activity_selector'}
I0810 10:50:05.591928 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.949, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0810 10:50:06.281551 135480425092608 run.py:689] Algo activity_selector step 2950 current loss 2.687321, current_train_items 44448.
I0810 10:50:06.393322 135480425092608 run.py:724] (val) algo activity_selector step 2950: {'selected': 0.8847583643122677, 'score': 0.8847583643122677, 'examples_seen': 44448, 'step': 2950, 'algorithm': 'activity_selector'}
I0810 10:50:06.393558 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.949, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0810 10:50:07.090926 135480425092608 run.py:689] Algo activity_selector step 3000 current loss 2.437758, current_train_items 45200.
I0810 10:50:07.194122 135480425092608 run.py:724] (val) algo activity_selector step 3000: {'selected': 0.9398496240601504, 'score': 0.9398496240601504, 'examples_seen': 45200, 'step': 3000, 'algorithm': 'activity_selector'}
I0810 10:50:07.194349 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.949, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0810 10:50:07.898890 135480425092608 run.py:689] Algo activity_selector step 3050 current loss 2.187261, current_train_items 45952.
I0810 10:50:07.994832 135480425092608 run.py:724] (val) algo activity_selector step 3050: {'selected': 0.9022556390977443, 'score': 0.9022556390977443, 'examples_seen': 45952, 'step': 3050, 'algorithm': 'activity_selector'}
I0810 10:50:07.995080 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.949, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0810 10:50:08.699537 135480425092608 run.py:689] Algo activity_selector step 3100 current loss 2.198269, current_train_items 46704.
I0810 10:50:08.797967 135480425092608 run.py:724] (val) algo activity_selector step 3100: {'selected': 0.8897338403041826, 'score': 0.8897338403041826, 'examples_seen': 46704, 'step': 3100, 'algorithm': 'activity_selector'}
I0810 10:50:08.798191 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.949, current avg val score is 0.890, val scores are: activity_selector: 0.890
I0810 10:50:09.503463 135480425092608 run.py:689] Algo activity_selector step 3150 current loss 2.000592, current_train_items 47456.
I0810 10:50:09.600670 135480425092608 run.py:724] (val) algo activity_selector step 3150: {'selected': 0.9266409266409267, 'score': 0.9266409266409267, 'examples_seen': 47456, 'step': 3150, 'algorithm': 'activity_selector'}
I0810 10:50:09.600888 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.949, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0810 10:50:10.306154 135480425092608 run.py:689] Algo activity_selector step 3200 current loss 2.045500, current_train_items 48208.
I0810 10:50:10.401618 135480425092608 run.py:724] (val) algo activity_selector step 3200: {'selected': 0.9545454545454547, 'score': 0.9545454545454547, 'examples_seen': 48208, 'step': 3200, 'algorithm': 'activity_selector'}
I0810 10:50:10.401838 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.949, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0810 10:50:11.127049 135480425092608 run.py:689] Algo activity_selector step 3250 current loss 1.592816, current_train_items 48960.
I0810 10:50:11.225540 135480425092608 run.py:724] (val) algo activity_selector step 3250: {'selected': 0.9277566539923955, 'score': 0.9277566539923955, 'examples_seen': 48960, 'step': 3250, 'algorithm': 'activity_selector'}
I0810 10:50:11.225764 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0810 10:50:11.930876 135480425092608 run.py:689] Algo activity_selector step 3300 current loss 1.543153, current_train_items 49712.
I0810 10:50:12.029028 135480425092608 run.py:724] (val) algo activity_selector step 3300: {'selected': 0.8518518518518519, 'score': 0.8518518518518519, 'examples_seen': 49712, 'step': 3300, 'algorithm': 'activity_selector'}
I0810 10:50:12.029249 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.852, val scores are: activity_selector: 0.852
I0810 10:50:12.734399 135480425092608 run.py:689] Algo activity_selector step 3350 current loss 1.327483, current_train_items 50464.
I0810 10:50:12.830860 135480425092608 run.py:724] (val) algo activity_selector step 3350: {'selected': 0.9494163424124514, 'score': 0.9494163424124514, 'examples_seen': 50464, 'step': 3350, 'algorithm': 'activity_selector'}
I0810 10:50:12.831086 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0810 10:50:13.521118 135480425092608 run.py:689] Algo activity_selector step 3400 current loss 1.648065, current_train_items 51216.
I0810 10:50:13.632793 135480425092608 run.py:724] (val) algo activity_selector step 3400: {'selected': 0.9042145593869731, 'score': 0.9042145593869731, 'examples_seen': 51216, 'step': 3400, 'algorithm': 'activity_selector'}
I0810 10:50:13.633028 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.904, val scores are: activity_selector: 0.904
I0810 10:50:14.322690 135480425092608 run.py:689] Algo activity_selector step 3450 current loss 1.341130, current_train_items 51968.
I0810 10:50:14.435878 135480425092608 run.py:724] (val) algo activity_selector step 3450: {'selected': 0.9318181818181818, 'score': 0.9318181818181818, 'examples_seen': 51968, 'step': 3450, 'algorithm': 'activity_selector'}
I0810 10:50:14.436103 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0810 10:50:15.141389 135480425092608 run.py:689] Algo activity_selector step 3500 current loss 0.444427, current_train_items 52720.
I0810 10:50:15.238520 135480425092608 run.py:724] (val) algo activity_selector step 3500: {'selected': 0.9076923076923076, 'score': 0.9076923076923076, 'examples_seen': 52720, 'step': 3500, 'algorithm': 'activity_selector'}
I0810 10:50:15.238763 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0810 10:50:15.928634 135480425092608 run.py:689] Algo activity_selector step 3550 current loss 4.568191, current_train_items 53488.
I0810 10:50:16.040689 135480425092608 run.py:724] (val) algo activity_selector step 3550: {'selected': 0.9022556390977443, 'score': 0.9022556390977443, 'examples_seen': 53488, 'step': 3550, 'algorithm': 'activity_selector'}
I0810 10:50:16.040912 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0810 10:50:16.742698 135480425092608 run.py:689] Algo activity_selector step 3600 current loss 4.403755, current_train_items 54240.
I0810 10:50:16.837061 135480425092608 run.py:724] (val) algo activity_selector step 3600: {'selected': 0.9166666666666667, 'score': 0.9166666666666667, 'examples_seen': 54240, 'step': 3600, 'algorithm': 'activity_selector'}
I0810 10:50:16.837280 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0810 10:50:17.536111 135480425092608 run.py:689] Algo activity_selector step 3650 current loss 4.020435, current_train_items 54992.
I0810 10:50:17.630829 135480425092608 run.py:724] (val) algo activity_selector step 3650: {'selected': 0.9105058365758755, 'score': 0.9105058365758755, 'examples_seen': 54992, 'step': 3650, 'algorithm': 'activity_selector'}
I0810 10:50:17.631054 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0810 10:50:18.334967 135480425092608 run.py:689] Algo activity_selector step 3700 current loss 3.143450, current_train_items 55744.
I0810 10:50:18.431432 135480425092608 run.py:724] (val) algo activity_selector step 3700: {'selected': 0.8821292775665398, 'score': 0.8821292775665398, 'examples_seen': 55744, 'step': 3700, 'algorithm': 'activity_selector'}
I0810 10:50:18.431685 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.882, val scores are: activity_selector: 0.882
I0810 10:50:19.136051 135480425092608 run.py:689] Algo activity_selector step 3750 current loss 2.718498, current_train_items 56496.
I0810 10:50:19.233063 135480425092608 run.py:724] (val) algo activity_selector step 3750: {'selected': 0.9266409266409267, 'score': 0.9266409266409267, 'examples_seen': 56496, 'step': 3750, 'algorithm': 'activity_selector'}
I0810 10:50:19.233284 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0810 10:50:19.937670 135480425092608 run.py:689] Algo activity_selector step 3800 current loss 2.748919, current_train_items 57248.
I0810 10:50:20.034245 135480425092608 run.py:724] (val) algo activity_selector step 3800: {'selected': 0.9283018867924527, 'score': 0.9283018867924527, 'examples_seen': 57248, 'step': 3800, 'algorithm': 'activity_selector'}
I0810 10:50:20.034466 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0810 10:50:20.738853 135480425092608 run.py:689] Algo activity_selector step 3850 current loss 2.363671, current_train_items 58000.
I0810 10:50:20.830411 135480425092608 run.py:724] (val) algo activity_selector step 3850: {'selected': 0.9230769230769231, 'score': 0.9230769230769231, 'examples_seen': 58000, 'step': 3850, 'algorithm': 'activity_selector'}
I0810 10:50:20.830596 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.923, val scores are: activity_selector: 0.923
I0810 10:50:21.531590 135480425092608 run.py:689] Algo activity_selector step 3900 current loss 2.406266, current_train_items 58752.
I0810 10:50:21.624998 135480425092608 run.py:724] (val) algo activity_selector step 3900: {'selected': 0.8394160583941607, 'score': 0.8394160583941607, 'examples_seen': 58752, 'step': 3900, 'algorithm': 'activity_selector'}
I0810 10:50:21.625174 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.839, val scores are: activity_selector: 0.839
I0810 10:50:22.314384 135480425092608 run.py:689] Algo activity_selector step 3950 current loss 2.054813, current_train_items 59504.
I0810 10:50:22.422225 135480425092608 run.py:724] (val) algo activity_selector step 3950: {'selected': 0.8805970149253731, 'score': 0.8805970149253731, 'examples_seen': 59504, 'step': 3950, 'algorithm': 'activity_selector'}
I0810 10:50:22.422372 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.881, val scores are: activity_selector: 0.881
I0810 10:50:23.120961 135480425092608 run.py:689] Algo activity_selector step 4000 current loss 2.150526, current_train_items 60256.
I0810 10:50:23.218770 135480425092608 run.py:724] (val) algo activity_selector step 4000: {'selected': 0.9015151515151514, 'score': 0.9015151515151514, 'examples_seen': 60256, 'step': 4000, 'algorithm': 'activity_selector'}
I0810 10:50:23.218996 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0810 10:50:23.923817 135480425092608 run.py:689] Algo activity_selector step 4050 current loss 2.135871, current_train_items 61008.
I0810 10:50:24.020506 135480425092608 run.py:724] (val) algo activity_selector step 4050: {'selected': 0.9189189189189189, 'score': 0.9189189189189189, 'examples_seen': 61008, 'step': 4050, 'algorithm': 'activity_selector'}
I0810 10:50:24.020755 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0810 10:50:24.712647 135480425092608 run.py:689] Algo activity_selector step 4100 current loss 2.075238, current_train_items 61760.
I0810 10:50:24.822752 135480425092608 run.py:724] (val) algo activity_selector step 4100: {'selected': 0.9416342412451363, 'score': 0.9416342412451363, 'examples_seen': 61760, 'step': 4100, 'algorithm': 'activity_selector'}
I0810 10:50:24.822973 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0810 10:50:25.512723 135480425092608 run.py:689] Algo activity_selector step 4150 current loss 1.526019, current_train_items 62512.
I0810 10:50:25.623364 135480425092608 run.py:724] (val) algo activity_selector step 4150: {'selected': 0.9104477611940298, 'score': 0.9104477611940298, 'examples_seen': 62512, 'step': 4150, 'algorithm': 'activity_selector'}
I0810 10:50:25.623599 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0810 10:50:26.328808 135480425092608 run.py:689] Algo activity_selector step 4200 current loss 1.368356, current_train_items 63264.
I0810 10:50:26.420033 135480425092608 run.py:724] (val) algo activity_selector step 4200: {'selected': 0.9333333333333333, 'score': 0.9333333333333333, 'examples_seen': 63264, 'step': 4200, 'algorithm': 'activity_selector'}
I0810 10:50:26.420229 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0810 10:50:27.109660 135480425092608 run.py:689] Algo activity_selector step 4250 current loss 1.117495, current_train_items 64016.
I0810 10:50:27.215294 135480425092608 run.py:724] (val) algo activity_selector step 4250: {'selected': 0.9169960474308301, 'score': 0.9169960474308301, 'examples_seen': 64016, 'step': 4250, 'algorithm': 'activity_selector'}
I0810 10:50:27.215520 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0810 10:50:27.916364 135480425092608 run.py:689] Algo activity_selector step 4300 current loss 2.453746, current_train_items 64768.
I0810 10:50:28.013337 135480425092608 run.py:724] (val) algo activity_selector step 4300: {'selected': 0.8897338403041826, 'score': 0.8897338403041826, 'examples_seen': 64768, 'step': 4300, 'algorithm': 'activity_selector'}
I0810 10:50:28.013577 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.890, val scores are: activity_selector: 0.890
I0810 10:50:28.718734 135480425092608 run.py:689] Algo activity_selector step 4350 current loss 1.150305, current_train_items 65520.
I0810 10:50:28.812229 135480425092608 run.py:724] (val) algo activity_selector step 4350: {'selected': 0.9328063241106719, 'score': 0.9328063241106719, 'examples_seen': 65520, 'step': 4350, 'algorithm': 'activity_selector'}
I0810 10:50:28.812457 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0810 10:50:29.517966 135480425092608 run.py:689] Algo activity_selector step 4400 current loss 4.190947, current_train_items 66288.
I0810 10:50:29.616075 135480425092608 run.py:724] (val) algo activity_selector step 4400: {'selected': 0.9236641221374045, 'score': 0.9236641221374045, 'examples_seen': 66288, 'step': 4400, 'algorithm': 'activity_selector'}
I0810 10:50:29.616313 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0810 10:50:30.317721 135480425092608 run.py:689] Algo activity_selector step 4450 current loss 4.103351, current_train_items 67040.
I0810 10:50:30.416703 135480425092608 run.py:724] (val) algo activity_selector step 4450: {'selected': 0.9318181818181818, 'score': 0.9318181818181818, 'examples_seen': 67040, 'step': 4450, 'algorithm': 'activity_selector'}
I0810 10:50:30.416949 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0810 10:50:31.115800 135480425092608 run.py:689] Algo activity_selector step 4500 current loss 3.256526, current_train_items 67792.
I0810 10:50:31.212027 135480425092608 run.py:724] (val) algo activity_selector step 4500: {'selected': 0.9453125000000001, 'score': 0.9453125000000001, 'examples_seen': 67792, 'step': 4500, 'algorithm': 'activity_selector'}
I0810 10:50:31.212247 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0810 10:50:31.901686 135480425092608 run.py:689] Algo activity_selector step 4550 current loss 3.233472, current_train_items 68544.
I0810 10:50:32.009577 135480425092608 run.py:724] (val) algo activity_selector step 4550: {'selected': 0.8905660377358491, 'score': 0.8905660377358491, 'examples_seen': 68544, 'step': 4550, 'algorithm': 'activity_selector'}
I0810 10:50:32.009800 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0810 10:50:32.695714 135480425092608 run.py:689] Algo activity_selector step 4600 current loss 2.747494, current_train_items 69296.
I0810 10:50:32.801427 135480425092608 run.py:724] (val) algo activity_selector step 4600: {'selected': 0.9272030651340997, 'score': 0.9272030651340997, 'examples_seen': 69296, 'step': 4600, 'algorithm': 'activity_selector'}
I0810 10:50:32.801583 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0810 10:50:33.500265 135480425092608 run.py:689] Algo activity_selector step 4650 current loss 2.522106, current_train_items 70048.
I0810 10:50:33.597402 135480425092608 run.py:724] (val) algo activity_selector step 4650: {'selected': 0.920152091254753, 'score': 0.920152091254753, 'examples_seen': 70048, 'step': 4650, 'algorithm': 'activity_selector'}
I0810 10:50:33.597637 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0810 10:50:34.287414 135480425092608 run.py:689] Algo activity_selector step 4700 current loss 2.311316, current_train_items 70800.
I0810 10:50:34.398995 135480425092608 run.py:724] (val) algo activity_selector step 4700: {'selected': 0.9166666666666667, 'score': 0.9166666666666667, 'examples_seen': 70800, 'step': 4700, 'algorithm': 'activity_selector'}
I0810 10:50:34.399217 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0810 10:50:35.097392 135480425092608 run.py:689] Algo activity_selector step 4750 current loss 2.453296, current_train_items 71552.
I0810 10:50:35.200155 135480425092608 run.py:724] (val) algo activity_selector step 4750: {'selected': 0.9453125000000001, 'score': 0.9453125000000001, 'examples_seen': 71552, 'step': 4750, 'algorithm': 'activity_selector'}
I0810 10:50:35.200377 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0810 10:50:35.904861 135480425092608 run.py:689] Algo activity_selector step 4800 current loss 2.069913, current_train_items 72304.
I0810 10:50:36.001277 135480425092608 run.py:724] (val) algo activity_selector step 4800: {'selected': 0.9343629343629343, 'score': 0.9343629343629343, 'examples_seen': 72304, 'step': 4800, 'algorithm': 'activity_selector'}
I0810 10:50:36.001502 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0810 10:50:36.706486 135480425092608 run.py:689] Algo activity_selector step 4850 current loss 2.123484, current_train_items 73056.
I0810 10:50:36.796315 135480425092608 run.py:724] (val) algo activity_selector step 4850: {'selected': 0.8965517241379312, 'score': 0.8965517241379312, 'examples_seen': 73056, 'step': 4850, 'algorithm': 'activity_selector'}
I0810 10:50:36.796475 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0810 10:50:37.495325 135480425092608 run.py:689] Algo activity_selector step 4900 current loss 2.091700, current_train_items 73808.
I0810 10:50:37.591713 135480425092608 run.py:724] (val) algo activity_selector step 4900: {'selected': 0.9125475285171102, 'score': 0.9125475285171102, 'examples_seen': 73808, 'step': 4900, 'algorithm': 'activity_selector'}
I0810 10:50:37.591936 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0810 10:50:38.283786 135480425092608 run.py:689] Algo activity_selector step 4950 current loss 1.696279, current_train_items 74560.
I0810 10:50:38.394155 135480425092608 run.py:724] (val) algo activity_selector step 4950: {'selected': 0.8854961832061069, 'score': 0.8854961832061069, 'examples_seen': 74560, 'step': 4950, 'algorithm': 'activity_selector'}
I0810 10:50:38.394376 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0810 10:50:39.099225 135480425092608 run.py:689] Algo activity_selector step 5000 current loss 1.556830, current_train_items 75312.
I0810 10:50:39.196109 135480425092608 run.py:724] (val) algo activity_selector step 5000: {'selected': 0.8932806324110673, 'score': 0.8932806324110673, 'examples_seen': 75312, 'step': 5000, 'algorithm': 'activity_selector'}
I0810 10:50:39.196337 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0810 10:50:39.888324 135480425092608 run.py:689] Algo activity_selector step 5050 current loss 1.240578, current_train_items 76064.
I0810 10:50:39.997640 135480425092608 run.py:724] (val) algo activity_selector step 5050: {'selected': 0.9189189189189189, 'score': 0.9189189189189189, 'examples_seen': 76064, 'step': 5050, 'algorithm': 'activity_selector'}
I0810 10:50:39.997869 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0810 10:50:40.703221 135480425092608 run.py:689] Algo activity_selector step 5100 current loss 1.024586, current_train_items 76816.
I0810 10:50:40.799939 135480425092608 run.py:724] (val) algo activity_selector step 5100: {'selected': 0.9254901960784314, 'score': 0.9254901960784314, 'examples_seen': 76816, 'step': 5100, 'algorithm': 'activity_selector'}
I0810 10:50:40.800162 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0810 10:50:41.506794 135480425092608 run.py:689] Algo activity_selector step 5150 current loss 1.410418, current_train_items 77568.
I0810 10:50:41.604591 135480425092608 run.py:724] (val) algo activity_selector step 5150: {'selected': 0.9063670411985019, 'score': 0.9063670411985019, 'examples_seen': 77568, 'step': 5150, 'algorithm': 'activity_selector'}
I0810 10:50:41.604815 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0810 10:50:42.318279 135480425092608 run.py:689] Algo activity_selector step 5200 current loss 0.891215, current_train_items 78320.
I0810 10:50:42.410875 135480425092608 run.py:724] (val) algo activity_selector step 5200: {'selected': 0.9490196078431372, 'score': 0.9490196078431372, 'examples_seen': 78320, 'step': 5200, 'algorithm': 'activity_selector'}
I0810 10:50:42.411095 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0810 10:50:43.102145 135480425092608 run.py:689] Algo activity_selector step 5250 current loss 5.412735, current_train_items 79088.
I0810 10:50:43.212722 135480425092608 run.py:724] (val) algo activity_selector step 5250: {'selected': 0.9224806201550388, 'score': 0.9224806201550388, 'examples_seen': 79088, 'step': 5250, 'algorithm': 'activity_selector'}
I0810 10:50:43.212943 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0810 10:50:43.907972 135480425092608 run.py:689] Algo activity_selector step 5300 current loss 3.621088, current_train_items 79840.
I0810 10:50:44.008955 135480425092608 run.py:724] (val) algo activity_selector step 5300: {'selected': 0.9411764705882353, 'score': 0.9411764705882353, 'examples_seen': 79840, 'step': 5300, 'algorithm': 'activity_selector'}
I0810 10:50:44.009209 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.955, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0810 10:50:44.709614 135480425092608 run.py:689] Algo activity_selector step 5350 current loss 3.542591, current_train_items 80592.
I0810 10:50:44.807512 135480425092608 run.py:724] (val) algo activity_selector step 5350: {'selected': 0.9652509652509652, 'score': 0.9652509652509652, 'examples_seen': 80592, 'step': 5350, 'algorithm': 'activity_selector'}
I0810 10:50:44.807757 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.955, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0810 10:50:45.533304 135480425092608 run.py:689] Algo activity_selector step 5400 current loss 2.962180, current_train_items 81344.
I0810 10:50:45.625481 135480425092608 run.py:724] (val) algo activity_selector step 5400: {'selected': 0.9498069498069497, 'score': 0.9498069498069497, 'examples_seen': 81344, 'step': 5400, 'algorithm': 'activity_selector'}
I0810 10:50:45.625720 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0810 10:50:46.331825 135480425092608 run.py:689] Algo activity_selector step 5450 current loss 2.833612, current_train_items 82096.
I0810 10:50:46.422444 135480425092608 run.py:724] (val) algo activity_selector step 5450: {'selected': 0.9494163424124514, 'score': 0.9494163424124514, 'examples_seen': 82096, 'step': 5450, 'algorithm': 'activity_selector'}
I0810 10:50:46.422598 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0810 10:50:47.122550 135480425092608 run.py:689] Algo activity_selector step 5500 current loss 2.347257, current_train_items 82848.
I0810 10:50:47.220931 135480425092608 run.py:724] (val) algo activity_selector step 5500: {'selected': 0.8939393939393939, 'score': 0.8939393939393939, 'examples_seen': 82848, 'step': 5500, 'algorithm': 'activity_selector'}
I0810 10:50:47.221153 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0810 10:50:47.911861 135480425092608 run.py:689] Algo activity_selector step 5550 current loss 2.467842, current_train_items 83600.
I0810 10:50:48.020697 135480425092608 run.py:724] (val) algo activity_selector step 5550: {'selected': 0.920754716981132, 'score': 0.920754716981132, 'examples_seen': 83600, 'step': 5550, 'algorithm': 'activity_selector'}
I0810 10:50:48.020927 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0810 10:50:48.713589 135480425092608 run.py:689] Algo activity_selector step 5600 current loss 2.208133, current_train_items 84352.
I0810 10:50:48.825555 135480425092608 run.py:724] (val) algo activity_selector step 5600: {'selected': 0.9132075471698113, 'score': 0.9132075471698113, 'examples_seen': 84352, 'step': 5600, 'algorithm': 'activity_selector'}
I0810 10:50:48.825796 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0810 10:50:49.531814 135480425092608 run.py:689] Algo activity_selector step 5650 current loss 2.149606, current_train_items 85104.
I0810 10:50:49.628831 135480425092608 run.py:724] (val) algo activity_selector step 5650: {'selected': 0.9266409266409267, 'score': 0.9266409266409267, 'examples_seen': 85104, 'step': 5650, 'algorithm': 'activity_selector'}
I0810 10:50:49.629055 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0810 10:50:50.335695 135480425092608 run.py:689] Algo activity_selector step 5700 current loss 1.894997, current_train_items 85856.
I0810 10:50:50.435398 135480425092608 run.py:724] (val) algo activity_selector step 5700: {'selected': 0.9343629343629343, 'score': 0.9343629343629343, 'examples_seen': 85856, 'step': 5700, 'algorithm': 'activity_selector'}
I0810 10:50:50.435633 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0810 10:50:51.126797 135480425092608 run.py:689] Algo activity_selector step 5750 current loss 1.932773, current_train_items 86608.
I0810 10:50:51.239372 135480425092608 run.py:724] (val) algo activity_selector step 5750: {'selected': 0.9111969111969112, 'score': 0.9111969111969112, 'examples_seen': 86608, 'step': 5750, 'algorithm': 'activity_selector'}
I0810 10:50:51.239603 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0810 10:50:51.945944 135480425092608 run.py:689] Algo activity_selector step 5800 current loss 1.761073, current_train_items 87360.
I0810 10:50:52.037499 135480425092608 run.py:724] (val) algo activity_selector step 5800: {'selected': 0.9302325581395349, 'score': 0.9302325581395349, 'examples_seen': 87360, 'step': 5800, 'algorithm': 'activity_selector'}
I0810 10:50:52.037728 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0810 10:50:52.744728 135480425092608 run.py:689] Algo activity_selector step 5850 current loss 1.532591, current_train_items 88112.
I0810 10:50:52.841736 135480425092608 run.py:724] (val) algo activity_selector step 5850: {'selected': 0.9272030651340997, 'score': 0.9272030651340997, 'examples_seen': 88112, 'step': 5850, 'algorithm': 'activity_selector'}
I0810 10:50:52.841964 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0810 10:50:53.547856 135480425092608 run.py:689] Algo activity_selector step 5900 current loss 1.167060, current_train_items 88864.
I0810 10:50:53.645132 135480425092608 run.py:724] (val) algo activity_selector step 5900: {'selected': 0.9365079365079365, 'score': 0.9365079365079365, 'examples_seen': 88864, 'step': 5900, 'algorithm': 'activity_selector'}
I0810 10:50:53.645374 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0810 10:50:54.337056 135480425092608 run.py:689] Algo activity_selector step 5950 current loss 1.890533, current_train_items 89616.
I0810 10:50:54.451052 135480425092608 run.py:724] (val) algo activity_selector step 5950: {'selected': 0.9523809523809524, 'score': 0.9523809523809524, 'examples_seen': 89616, 'step': 5950, 'algorithm': 'activity_selector'}
I0810 10:50:54.451277 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0810 10:50:55.158620 135480425092608 run.py:689] Algo activity_selector step 6000 current loss 1.057557, current_train_items 90368.
I0810 10:50:55.255709 135480425092608 run.py:724] (val) algo activity_selector step 6000: {'selected': 0.9465648854961831, 'score': 0.9465648854961831, 'examples_seen': 90368, 'step': 6000, 'algorithm': 'activity_selector'}
I0810 10:50:55.255938 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0810 10:50:55.962752 135480425092608 run.py:689] Algo activity_selector step 6050 current loss 0.447930, current_train_items 91120.
I0810 10:50:56.061057 135480425092608 run.py:724] (val) algo activity_selector step 6050: {'selected': 0.9457364341085271, 'score': 0.9457364341085271, 'examples_seen': 91120, 'step': 6050, 'algorithm': 'activity_selector'}
I0810 10:50:56.061288 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0810 10:50:56.768653 135480425092608 run.py:689] Algo activity_selector step 6100 current loss 4.758353, current_train_items 91888.
I0810 10:50:56.866276 135480425092608 run.py:724] (val) algo activity_selector step 6100: {'selected': 0.9612403100775193, 'score': 0.9612403100775193, 'examples_seen': 91888, 'step': 6100, 'algorithm': 'activity_selector'}
I0810 10:50:56.866498 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0810 10:50:57.568794 135480425092608 run.py:689] Algo activity_selector step 6150 current loss 4.167722, current_train_items 92640.
I0810 10:50:57.663126 135480425092608 run.py:724] (val) algo activity_selector step 6150: {'selected': 0.9389312977099236, 'score': 0.9389312977099236, 'examples_seen': 92640, 'step': 6150, 'algorithm': 'activity_selector'}
I0810 10:50:57.663299 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0810 10:50:58.344938 135480425092608 run.py:689] Algo activity_selector step 6200 current loss 3.461401, current_train_items 93392.
I0810 10:50:58.458691 135480425092608 run.py:724] (val) algo activity_selector step 6200: {'selected': 0.9393939393939394, 'score': 0.9393939393939394, 'examples_seen': 93392, 'step': 6200, 'algorithm': 'activity_selector'}
I0810 10:50:58.458932 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0810 10:50:59.164247 135480425092608 run.py:689] Algo activity_selector step 6250 current loss 2.911964, current_train_items 94144.
I0810 10:50:59.263108 135480425092608 run.py:724] (val) algo activity_selector step 6250: {'selected': 0.9389312977099236, 'score': 0.9389312977099236, 'examples_seen': 94144, 'step': 6250, 'algorithm': 'activity_selector'}
I0810 10:50:59.263334 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0810 10:50:59.965295 135480425092608 run.py:689] Algo activity_selector step 6300 current loss 2.612345, current_train_items 94896.
I0810 10:51:00.069364 135480425092608 run.py:724] (val) algo activity_selector step 6300: {'selected': 0.9042145593869731, 'score': 0.9042145593869731, 'examples_seen': 94896, 'step': 6300, 'algorithm': 'activity_selector'}
I0810 10:51:00.069607 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.904, val scores are: activity_selector: 0.904
I0810 10:51:00.775706 135480425092608 run.py:689] Algo activity_selector step 6350 current loss 2.393696, current_train_items 95648.
I0810 10:51:00.871891 135480425092608 run.py:724] (val) algo activity_selector step 6350: {'selected': 0.9296874999999999, 'score': 0.9296874999999999, 'examples_seen': 95648, 'step': 6350, 'algorithm': 'activity_selector'}
I0810 10:51:00.872116 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0810 10:51:01.583268 135480425092608 run.py:689] Algo activity_selector step 6400 current loss 2.336226, current_train_items 96400.
I0810 10:51:01.674106 135480425092608 run.py:724] (val) algo activity_selector step 6400: {'selected': 0.9277566539923955, 'score': 0.9277566539923955, 'examples_seen': 96400, 'step': 6400, 'algorithm': 'activity_selector'}
I0810 10:51:01.674331 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0810 10:51:02.396809 135480425092608 run.py:689] Algo activity_selector step 6450 current loss 2.173963, current_train_items 97152.
I0810 10:51:02.479013 135480425092608 run.py:724] (val) algo activity_selector step 6450: {'selected': 0.9416342412451363, 'score': 0.9416342412451363, 'examples_seen': 97152, 'step': 6450, 'algorithm': 'activity_selector'}
I0810 10:51:02.479166 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0810 10:51:03.179161 135480425092608 run.py:689] Algo activity_selector step 6500 current loss 1.971973, current_train_items 97904.
I0810 10:51:03.274144 135480425092608 run.py:724] (val) algo activity_selector step 6500: {'selected': 0.9049429657794676, 'score': 0.9049429657794676, 'examples_seen': 97904, 'step': 6500, 'algorithm': 'activity_selector'}
I0810 10:51:03.274371 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0810 10:51:03.981071 135480425092608 run.py:689] Algo activity_selector step 6550 current loss 1.984535, current_train_items 98656.
I0810 10:51:04.078826 135480425092608 run.py:724] (val) algo activity_selector step 6550: {'selected': 0.9272030651340997, 'score': 0.9272030651340997, 'examples_seen': 98656, 'step': 6550, 'algorithm': 'activity_selector'}
I0810 10:51:04.079050 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0810 10:51:04.785138 135480425092608 run.py:689] Algo activity_selector step 6600 current loss 1.935998, current_train_items 99408.
I0810 10:51:04.883251 135480425092608 run.py:724] (val) algo activity_selector step 6600: {'selected': 0.9283018867924527, 'score': 0.9283018867924527, 'examples_seen': 99408, 'step': 6600, 'algorithm': 'activity_selector'}
I0810 10:51:04.883476 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0810 10:51:05.575108 135480425092608 run.py:689] Algo activity_selector step 6650 current loss 1.609447, current_train_items 100160.
I0810 10:51:05.688139 135480425092608 run.py:724] (val) algo activity_selector step 6650: {'selected': 0.9242424242424243, 'score': 0.9242424242424243, 'examples_seen': 100160, 'step': 6650, 'algorithm': 'activity_selector'}
I0810 10:51:05.688360 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0810 10:51:06.403156 135480425092608 run.py:689] Algo activity_selector step 6700 current loss 1.414666, current_train_items 100912.
I0810 10:51:06.493503 135480425092608 run.py:724] (val) algo activity_selector step 6700: {'selected': 0.9132075471698113, 'score': 0.9132075471698113, 'examples_seen': 100912, 'step': 6700, 'algorithm': 'activity_selector'}
I0810 10:51:06.493734 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0810 10:51:07.200433 135480425092608 run.py:689] Algo activity_selector step 6750 current loss 1.397100, current_train_items 101664.
I0810 10:51:07.299055 135480425092608 run.py:724] (val) algo activity_selector step 6750: {'selected': 0.9448818897637796, 'score': 0.9448818897637796, 'examples_seen': 101664, 'step': 6750, 'algorithm': 'activity_selector'}
I0810 10:51:07.299296 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0810 10:51:07.990881 135480425092608 run.py:689] Algo activity_selector step 6800 current loss 1.042749, current_train_items 102416.
I0810 10:51:08.098902 135480425092608 run.py:724] (val) algo activity_selector step 6800: {'selected': 0.9448818897637796, 'score': 0.9448818897637796, 'examples_seen': 102416, 'step': 6800, 'algorithm': 'activity_selector'}
I0810 10:51:08.099127 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0810 10:51:08.805968 135480425092608 run.py:689] Algo activity_selector step 6850 current loss 1.082175, current_train_items 103168.
I0810 10:51:08.903266 135480425092608 run.py:724] (val) algo activity_selector step 6850: {'selected': 0.9429657794676807, 'score': 0.9429657794676807, 'examples_seen': 103168, 'step': 6850, 'algorithm': 'activity_selector'}
I0810 10:51:08.903486 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0810 10:51:09.594421 135480425092608 run.py:689] Algo activity_selector step 6900 current loss 0.558545, current_train_items 103920.
I0810 10:51:09.708084 135480425092608 run.py:724] (val) algo activity_selector step 6900: {'selected': 0.9291338582677167, 'score': 0.9291338582677167, 'examples_seen': 103920, 'step': 6900, 'algorithm': 'activity_selector'}
I0810 10:51:09.708316 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0810 10:51:10.414757 135480425092608 run.py:689] Algo activity_selector step 6950 current loss 4.635828, current_train_items 104688.
I0810 10:51:10.508701 135480425092608 run.py:724] (val) algo activity_selector step 6950: {'selected': 0.9609375, 'score': 0.9609375, 'examples_seen': 104688, 'step': 6950, 'algorithm': 'activity_selector'}
I0810 10:51:10.508924 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0810 10:51:11.211459 135480425092608 run.py:689] Algo activity_selector step 7000 current loss 3.806304, current_train_items 105440.
I0810 10:51:11.309008 135480425092608 run.py:724] (val) algo activity_selector step 7000: {'selected': 0.9333333333333333, 'score': 0.9333333333333333, 'examples_seen': 105440, 'step': 7000, 'algorithm': 'activity_selector'}
I0810 10:51:11.309230 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0810 10:51:12.008996 135480425092608 run.py:689] Algo activity_selector step 7050 current loss 3.217705, current_train_items 106192.
I0810 10:51:12.099961 135480425092608 run.py:724] (val) algo activity_selector step 7050: {'selected': 0.9104477611940298, 'score': 0.9104477611940298, 'examples_seen': 106192, 'step': 7050, 'algorithm': 'activity_selector'}
I0810 10:51:12.100185 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0810 10:51:12.786831 135480425092608 run.py:689] Algo activity_selector step 7100 current loss 2.900521, current_train_items 106944.
I0810 10:51:12.900458 135480425092608 run.py:724] (val) algo activity_selector step 7100: {'selected': 0.9312977099236641, 'score': 0.9312977099236641, 'examples_seen': 106944, 'step': 7100, 'algorithm': 'activity_selector'}
I0810 10:51:12.900698 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0810 10:51:13.591740 135480425092608 run.py:689] Algo activity_selector step 7150 current loss 2.633420, current_train_items 107696.
I0810 10:51:13.701272 135480425092608 run.py:724] (val) algo activity_selector step 7150: {'selected': 0.9538461538461539, 'score': 0.9538461538461539, 'examples_seen': 107696, 'step': 7150, 'algorithm': 'activity_selector'}
I0810 10:51:13.701494 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0810 10:51:14.408399 135480425092608 run.py:689] Algo activity_selector step 7200 current loss 2.326441, current_train_items 108448.
I0810 10:51:14.505738 135480425092608 run.py:724] (val) algo activity_selector step 7200: {'selected': 0.9575289575289576, 'score': 0.9575289575289576, 'examples_seen': 108448, 'step': 7200, 'algorithm': 'activity_selector'}
I0810 10:51:14.505959 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0810 10:51:15.215167 135480425092608 run.py:689] Algo activity_selector step 7250 current loss 2.496666, current_train_items 109200.
I0810 10:51:15.309670 135480425092608 run.py:724] (val) algo activity_selector step 7250: {'selected': 0.8796992481203008, 'score': 0.8796992481203008, 'examples_seen': 109200, 'step': 7250, 'algorithm': 'activity_selector'}
I0810 10:51:15.309817 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0810 10:51:15.999997 135480425092608 run.py:689] Algo activity_selector step 7300 current loss 2.199550, current_train_items 109952.
I0810 10:51:16.111120 135480425092608 run.py:724] (val) algo activity_selector step 7300: {'selected': 0.9318181818181818, 'score': 0.9318181818181818, 'examples_seen': 109952, 'step': 7300, 'algorithm': 'activity_selector'}
I0810 10:51:16.111340 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0810 10:51:16.817988 135480425092608 run.py:689] Algo activity_selector step 7350 current loss 2.049016, current_train_items 110704.
I0810 10:51:16.914536 135480425092608 run.py:724] (val) algo activity_selector step 7350: {'selected': 0.9571984435797665, 'score': 0.9571984435797665, 'examples_seen': 110704, 'step': 7350, 'algorithm': 'activity_selector'}
I0810 10:51:16.914761 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0810 10:51:17.620693 135480425092608 run.py:689] Algo activity_selector step 7400 current loss 2.155453, current_train_items 111456.
I0810 10:51:17.717274 135480425092608 run.py:724] (val) algo activity_selector step 7400: {'selected': 0.9429657794676807, 'score': 0.9429657794676807, 'examples_seen': 111456, 'step': 7400, 'algorithm': 'activity_selector'}
I0810 10:51:17.717498 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0810 10:51:18.423955 135480425092608 run.py:689] Algo activity_selector step 7450 current loss 1.870781, current_train_items 112208.
I0810 10:51:18.520583 135480425092608 run.py:724] (val) algo activity_selector step 7450: {'selected': 0.9022556390977443, 'score': 0.9022556390977443, 'examples_seen': 112208, 'step': 7450, 'algorithm': 'activity_selector'}
I0810 10:51:18.520804 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0810 10:51:19.227231 135480425092608 run.py:689] Algo activity_selector step 7500 current loss 1.588936, current_train_items 112960.
I0810 10:51:19.323415 135480425092608 run.py:724] (val) algo activity_selector step 7500: {'selected': 0.9022556390977443, 'score': 0.9022556390977443, 'examples_seen': 112960, 'step': 7500, 'algorithm': 'activity_selector'}
I0810 10:51:19.323667 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0810 10:51:20.033072 135480425092608 run.py:689] Algo activity_selector step 7550 current loss 1.374079, current_train_items 113712.
I0810 10:51:20.125833 135480425092608 run.py:724] (val) algo activity_selector step 7550: {'selected': 0.9132075471698113, 'score': 0.9132075471698113, 'examples_seen': 113712, 'step': 7550, 'algorithm': 'activity_selector'}
I0810 10:51:20.126059 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0810 10:51:20.828570 135480425092608 run.py:689] Algo activity_selector step 7600 current loss 1.157146, current_train_items 114464.
I0810 10:51:20.930300 135480425092608 run.py:724] (val) algo activity_selector step 7600: {'selected': 0.9501915708812262, 'score': 0.9501915708812262, 'examples_seen': 114464, 'step': 7600, 'algorithm': 'activity_selector'}
I0810 10:51:20.930540 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0810 10:51:21.637101 135480425092608 run.py:689] Algo activity_selector step 7650 current loss 1.082748, current_train_items 115216.
I0810 10:51:21.734499 135480425092608 run.py:724] (val) algo activity_selector step 7650: {'selected': 0.920152091254753, 'score': 0.920152091254753, 'examples_seen': 115216, 'step': 7650, 'algorithm': 'activity_selector'}
I0810 10:51:21.734739 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0810 10:51:22.441381 135480425092608 run.py:689] Algo activity_selector step 7700 current loss 1.208547, current_train_items 115968.
I0810 10:51:22.538317 135480425092608 run.py:724] (val) algo activity_selector step 7700: {'selected': 0.9189189189189189, 'score': 0.9189189189189189, 'examples_seen': 115968, 'step': 7700, 'algorithm': 'activity_selector'}
I0810 10:51:22.538553 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0810 10:51:23.237310 135480425092608 run.py:689] Algo activity_selector step 7750 current loss 0.380840, current_train_items 116720.
I0810 10:51:23.341159 135480425092608 run.py:724] (val) algo activity_selector step 7750: {'selected': 0.9461538461538461, 'score': 0.9461538461538461, 'examples_seen': 116720, 'step': 7750, 'algorithm': 'activity_selector'}
I0810 10:51:23.341382 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0810 10:51:24.048269 135480425092608 run.py:689] Algo activity_selector step 7800 current loss 4.651186, current_train_items 117488.
I0810 10:51:24.146790 135480425092608 run.py:724] (val) algo activity_selector step 7800: {'selected': 0.9453125000000001, 'score': 0.9453125000000001, 'examples_seen': 117488, 'step': 7800, 'algorithm': 'activity_selector'}
I0810 10:51:24.147015 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0810 10:51:24.833283 135480425092608 run.py:689] Algo activity_selector step 7850 current loss 4.276305, current_train_items 118240.
I0810 10:51:24.944845 135480425092608 run.py:724] (val) algo activity_selector step 7850: {'selected': 0.9236641221374045, 'score': 0.9236641221374045, 'examples_seen': 118240, 'step': 7850, 'algorithm': 'activity_selector'}
I0810 10:51:24.945094 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0810 10:51:25.644663 135480425092608 run.py:689] Algo activity_selector step 7900 current loss 3.260437, current_train_items 118992.
I0810 10:51:25.742372 135480425092608 run.py:724] (val) algo activity_selector step 7900: {'selected': 0.9098039215686274, 'score': 0.9098039215686274, 'examples_seen': 118992, 'step': 7900, 'algorithm': 'activity_selector'}
I0810 10:51:25.742629 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0810 10:51:26.433091 135480425092608 run.py:689] Algo activity_selector step 7950 current loss 2.805218, current_train_items 119744.
I0810 10:51:26.545946 135480425092608 run.py:724] (val) algo activity_selector step 7950: {'selected': 0.9333333333333333, 'score': 0.9333333333333333, 'examples_seen': 119744, 'step': 7950, 'algorithm': 'activity_selector'}
I0810 10:51:26.546198 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0810 10:51:27.252009 135480425092608 run.py:689] Algo activity_selector step 8000 current loss 2.648378, current_train_items 120496.
I0810 10:51:27.349814 135480425092608 run.py:724] (val) algo activity_selector step 8000: {'selected': 0.9647058823529412, 'score': 0.9647058823529412, 'examples_seen': 120496, 'step': 8000, 'algorithm': 'activity_selector'}
I0810 10:51:27.350043 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0810 10:51:28.058950 135480425092608 run.py:689] Algo activity_selector step 8050 current loss 2.400864, current_train_items 121248.
I0810 10:51:28.157163 135480425092608 run.py:724] (val) algo activity_selector step 8050: {'selected': 0.8981132075471698, 'score': 0.8981132075471698, 'examples_seen': 121248, 'step': 8050, 'algorithm': 'activity_selector'}
I0810 10:51:28.157415 135480425092608 run.py:745] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0810 10:51:28.882551 135480425092608 run.py:689] Algo activity_selector step 8100 current loss 2.262022, current_train_items 122000.
I0810 10:51:28.979904 135480425092608 run.py:724] (val) algo activity_selector step 8100: {'selected': 0.9056603773584906, 'score': 0.9056603773584906, 'examples_seen': 122000, 'step': 8100, 'algorithm': 'activity_selector'}
I0810 10:51:28.980129 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.898, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0810 10:51:29.706913 135480425092608 run.py:689] Algo activity_selector step 8150 current loss 2.242211, current_train_items 122752.
I0810 10:51:29.803635 135480425092608 run.py:724] (val) algo activity_selector step 8150: {'selected': 0.8623188405797102, 'score': 0.8623188405797102, 'examples_seen': 122752, 'step': 8150, 'algorithm': 'activity_selector'}
I0810 10:51:29.803859 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.906, current avg val score is 0.862, val scores are: activity_selector: 0.862
I0810 10:51:30.509615 135480425092608 run.py:689] Algo activity_selector step 8200 current loss 2.016664, current_train_items 123504.
I0810 10:51:30.607824 135480425092608 run.py:724] (val) algo activity_selector step 8200: {'selected': 0.8805970149253731, 'score': 0.8805970149253731, 'examples_seen': 123504, 'step': 8200, 'algorithm': 'activity_selector'}
I0810 10:51:30.608048 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.906, current avg val score is 0.881, val scores are: activity_selector: 0.881
I0810 10:51:31.314325 135480425092608 run.py:689] Algo activity_selector step 8250 current loss 2.166355, current_train_items 124256.
I0810 10:51:31.410845 135480425092608 run.py:724] (val) algo activity_selector step 8250: {'selected': 0.8981132075471698, 'score': 0.8981132075471698, 'examples_seen': 124256, 'step': 8250, 'algorithm': 'activity_selector'}
I0810 10:51:31.411105 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.906, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0810 10:51:32.117351 135480425092608 run.py:689] Algo activity_selector step 8300 current loss 1.831952, current_train_items 125008.
I0810 10:51:32.216281 135480425092608 run.py:724] (val) algo activity_selector step 8300: {'selected': 0.9230769230769231, 'score': 0.9230769230769231, 'examples_seen': 125008, 'step': 8300, 'algorithm': 'activity_selector'}
I0810 10:51:32.216504 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.906, current avg val score is 0.923, val scores are: activity_selector: 0.923
I0810 10:51:32.938783 135480425092608 run.py:689] Algo activity_selector step 8350 current loss 1.624443, current_train_items 125760.
I0810 10:51:33.036478 135480425092608 run.py:724] (val) algo activity_selector step 8350: {'selected': 0.9166666666666667, 'score': 0.9166666666666667, 'examples_seen': 125760, 'step': 8350, 'algorithm': 'activity_selector'}
I0810 10:51:33.036712 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.923, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0810 10:51:33.743642 135480425092608 run.py:689] Algo activity_selector step 8400 current loss 2.036193, current_train_items 126512.
I0810 10:51:33.841689 135480425092608 run.py:724] (val) algo activity_selector step 8400: {'selected': 0.9218749999999999, 'score': 0.9218749999999999, 'examples_seen': 126512, 'step': 8400, 'algorithm': 'activity_selector'}
I0810 10:51:33.841908 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.923, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0810 10:51:34.548508 135480425092608 run.py:689] Algo activity_selector step 8450 current loss 1.225183, current_train_items 127264.
I0810 10:51:34.638977 135480425092608 run.py:724] (val) algo activity_selector step 8450: {'selected': 0.946969696969697, 'score': 0.946969696969697, 'examples_seen': 127264, 'step': 8450, 'algorithm': 'activity_selector'}
I0810 10:51:34.639126 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.923, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0810 10:51:35.356777 135480425092608 run.py:689] Algo activity_selector step 8500 current loss 1.182138, current_train_items 128016.
I0810 10:51:35.462856 135480425092608 run.py:724] (val) algo activity_selector step 8500: {'selected': 0.9375, 'score': 0.9375, 'examples_seen': 128016, 'step': 8500, 'algorithm': 'activity_selector'}
I0810 10:51:35.463081 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.947, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0810 10:51:36.170320 135480425092608 run.py:689] Algo activity_selector step 8550 current loss 1.324849, current_train_items 128768.
I0810 10:51:36.266806 135480425092608 run.py:724] (val) algo activity_selector step 8550: {'selected': 0.9118773946360154, 'score': 0.9118773946360154, 'examples_seen': 128768, 'step': 8550, 'algorithm': 'activity_selector'}
I0810 10:51:36.267026 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.947, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0810 10:51:36.989167 135480425092608 run.py:689] Algo activity_selector step 8600 current loss 0.752154, current_train_items 129520.
I0810 10:51:37.070941 135480425092608 run.py:724] (val) algo activity_selector step 8600: {'selected': 0.9494163424124514, 'score': 0.9494163424124514, 'examples_seen': 129520, 'step': 8600, 'algorithm': 'activity_selector'}
I0810 10:51:37.071087 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.947, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0810 10:51:37.786649 135480425092608 run.py:689] Algo activity_selector step 8650 current loss 4.454169, current_train_items 130288.
I0810 10:51:37.884847 135480425092608 run.py:724] (val) algo activity_selector step 8650: {'selected': 0.9501915708812262, 'score': 0.9501915708812262, 'examples_seen': 130288, 'step': 8650, 'algorithm': 'activity_selector'}
I0810 10:51:37.885086 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.949, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0810 10:51:38.609781 135480425092608 run.py:689] Algo activity_selector step 8700 current loss 4.198201, current_train_items 131040.
I0810 10:51:38.705556 135480425092608 run.py:724] (val) algo activity_selector step 8700: {'selected': 0.9461538461538461, 'score': 0.9461538461538461, 'examples_seen': 131040, 'step': 8700, 'algorithm': 'activity_selector'}
I0810 10:51:38.705781 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.950, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0810 10:51:39.421508 135480425092608 run.py:689] Algo activity_selector step 8750 current loss 3.269426, current_train_items 131792.
I0810 10:51:39.500653 135480425092608 run.py:724] (val) algo activity_selector step 8750: {'selected': 0.9389312977099236, 'score': 0.9389312977099236, 'examples_seen': 131792, 'step': 8750, 'algorithm': 'activity_selector'}
I0810 10:51:39.500875 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.950, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0810 10:51:40.205962 135480425092608 run.py:689] Algo activity_selector step 8800 current loss 2.960476, current_train_items 132544.
I0810 10:51:40.304996 135480425092608 run.py:724] (val) algo activity_selector step 8800: {'selected': 0.9393939393939394, 'score': 0.9393939393939394, 'examples_seen': 132544, 'step': 8800, 'algorithm': 'activity_selector'}
I0810 10:51:40.305219 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.950, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0810 10:51:41.011067 135480425092608 run.py:689] Algo activity_selector step 8850 current loss 2.470995, current_train_items 133296.
I0810 10:51:41.110025 135480425092608 run.py:724] (val) algo activity_selector step 8850: {'selected': 0.9575289575289576, 'score': 0.9575289575289576, 'examples_seen': 133296, 'step': 8850, 'algorithm': 'activity_selector'}
I0810 10:51:41.110245 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.950, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0810 10:51:41.847400 135480425092608 run.py:689] Algo activity_selector step 8900 current loss 2.431059, current_train_items 134048.
I0810 10:51:41.928201 135480425092608 run.py:724] (val) algo activity_selector step 8900: {'selected': 0.9307692307692308, 'score': 0.9307692307692308, 'examples_seen': 134048, 'step': 8900, 'algorithm': 'activity_selector'}
I0810 10:51:41.928348 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0810 10:51:42.616377 135480425092608 run.py:689] Algo activity_selector step 8950 current loss 2.268103, current_train_items 134800.
I0810 10:51:42.725291 135480425092608 run.py:724] (val) algo activity_selector step 8950: {'selected': 0.9348659003831418, 'score': 0.9348659003831418, 'examples_seen': 134800, 'step': 8950, 'algorithm': 'activity_selector'}
I0810 10:51:42.725467 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0810 10:51:43.418353 135480425092608 run.py:689] Algo activity_selector step 9000 current loss 2.191727, current_train_items 135552.
I0810 10:51:43.527181 135480425092608 run.py:724] (val) algo activity_selector step 9000: {'selected': 0.900763358778626, 'score': 0.900763358778626, 'examples_seen': 135552, 'step': 9000, 'algorithm': 'activity_selector'}
I0810 10:51:43.527401 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.901, val scores are: activity_selector: 0.901
I0810 10:51:44.233547 135480425092608 run.py:689] Algo activity_selector step 9050 current loss 1.975081, current_train_items 136304.
I0810 10:51:44.327017 135480425092608 run.py:724] (val) algo activity_selector step 9050: {'selected': 0.9022556390977443, 'score': 0.9022556390977443, 'examples_seen': 136304, 'step': 9050, 'algorithm': 'activity_selector'}
I0810 10:51:44.327188 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0810 10:51:45.033203 135480425092608 run.py:689] Algo activity_selector step 9100 current loss 1.988014, current_train_items 137056.
I0810 10:51:45.131174 135480425092608 run.py:724] (val) algo activity_selector step 9100: {'selected': 0.920754716981132, 'score': 0.920754716981132, 'examples_seen': 137056, 'step': 9100, 'algorithm': 'activity_selector'}
I0810 10:51:45.131401 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0810 10:51:45.835696 135480425092608 run.py:689] Algo activity_selector step 9150 current loss 1.690567, current_train_items 137808.
I0810 10:51:45.933541 135480425092608 run.py:724] (val) algo activity_selector step 9150: {'selected': 0.9160305343511451, 'score': 0.9160305343511451, 'examples_seen': 137808, 'step': 9150, 'algorithm': 'activity_selector'}
I0810 10:51:45.933762 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.916, val scores are: activity_selector: 0.916
I0810 10:51:46.633590 135480425092608 run.py:689] Algo activity_selector step 9200 current loss 1.719904, current_train_items 138560.
I0810 10:51:46.737935 135480425092608 run.py:724] (val) algo activity_selector step 9200: {'selected': 0.909090909090909, 'score': 0.909090909090909, 'examples_seen': 138560, 'step': 9200, 'algorithm': 'activity_selector'}
I0810 10:51:46.738156 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0810 10:51:47.429817 135480425092608 run.py:689] Algo activity_selector step 9250 current loss 1.479138, current_train_items 139312.
I0810 10:51:47.542243 135480425092608 run.py:724] (val) algo activity_selector step 9250: {'selected': 0.9615384615384616, 'score': 0.9615384615384616, 'examples_seen': 139312, 'step': 9250, 'algorithm': 'activity_selector'}
I0810 10:51:47.542477 135480425092608 run.py:745] Checkpointing best model, best avg val score was 0.958, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0810 10:51:48.266081 135480425092608 run.py:689] Algo activity_selector step 9300 current loss 1.163081, current_train_items 140064.
I0810 10:51:48.363686 135480425092608 run.py:724] (val) algo activity_selector step 9300: {'selected': 0.9097744360902256, 'score': 0.9097744360902256, 'examples_seen': 140064, 'step': 9300, 'algorithm': 'activity_selector'}
I0810 10:51:48.363943 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.962, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0810 10:51:49.086281 135480425092608 run.py:689] Algo activity_selector step 9350 current loss 1.048768, current_train_items 140816.
I0810 10:51:49.166865 135480425092608 run.py:724] (val) algo activity_selector step 9350: {'selected': 0.937984496124031, 'score': 0.937984496124031, 'examples_seen': 140816, 'step': 9350, 'algorithm': 'activity_selector'}
I0810 10:51:49.167089 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.962, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0810 10:51:49.873925 135480425092608 run.py:689] Algo activity_selector step 9400 current loss 1.128065, current_train_items 141568.
I0810 10:51:49.969447 135480425092608 run.py:724] (val) algo activity_selector step 9400: {'selected': 0.9465648854961831, 'score': 0.9465648854961831, 'examples_seen': 141568, 'step': 9400, 'algorithm': 'activity_selector'}
I0810 10:51:49.969680 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.962, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0810 10:51:50.669068 135480425092608 run.py:689] Algo activity_selector step 9450 current loss 0.717485, current_train_items 142320.
I0810 10:51:50.774315 135480425092608 run.py:724] (val) algo activity_selector step 9450: {'selected': 0.9118773946360154, 'score': 0.9118773946360154, 'examples_seen': 142320, 'step': 9450, 'algorithm': 'activity_selector'}
I0810 10:51:50.774547 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.962, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0810 10:51:51.481412 135480425092608 run.py:689] Algo activity_selector step 9500 current loss 5.001958, current_train_items 143088.
I0810 10:51:51.578083 135480425092608 run.py:724] (val) algo activity_selector step 9500: {'selected': 0.9328063241106719, 'score': 0.9328063241106719, 'examples_seen': 143088, 'step': 9500, 'algorithm': 'activity_selector'}
I0810 10:51:51.578305 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.962, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0810 10:51:52.281151 135480425092608 run.py:689] Algo activity_selector step 9550 current loss 3.762515, current_train_items 143840.
I0810 10:51:52.378600 135480425092608 run.py:724] (val) algo activity_selector step 9550: {'selected': 0.920754716981132, 'score': 0.920754716981132, 'examples_seen': 143840, 'step': 9550, 'algorithm': 'activity_selector'}
I0810 10:51:52.378823 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.962, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0810 10:51:53.078663 135480425092608 run.py:689] Algo activity_selector step 9600 current loss 3.418615, current_train_items 144592.
I0810 10:51:53.175686 135480425092608 run.py:724] (val) algo activity_selector step 9600: {'selected': 0.9348659003831418, 'score': 0.9348659003831418, 'examples_seen': 144592, 'step': 9600, 'algorithm': 'activity_selector'}
I0810 10:51:53.175920 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.962, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0810 10:51:53.881450 135480425092608 run.py:689] Algo activity_selector step 9650 current loss 2.751782, current_train_items 145344.
I0810 10:51:53.981011 135480425092608 run.py:724] (val) algo activity_selector step 9650: {'selected': 0.9359999999999999, 'score': 0.9359999999999999, 'examples_seen': 145344, 'step': 9650, 'algorithm': 'activity_selector'}
I0810 10:51:53.981236 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.962, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0810 10:51:54.687347 135480425092608 run.py:689] Algo activity_selector step 9700 current loss 2.616645, current_train_items 146096.
I0810 10:51:54.784307 135480425092608 run.py:724] (val) algo activity_selector step 9700: {'selected': 0.9049429657794676, 'score': 0.9049429657794676, 'examples_seen': 146096, 'step': 9700, 'algorithm': 'activity_selector'}
I0810 10:51:54.784543 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.962, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0810 10:51:55.490318 135480425092608 run.py:689] Algo activity_selector step 9750 current loss 2.331551, current_train_items 146848.
I0810 10:51:55.587984 135480425092608 run.py:724] (val) algo activity_selector step 9750: {'selected': 0.9090909090909091, 'score': 0.9090909090909091, 'examples_seen': 146848, 'step': 9750, 'algorithm': 'activity_selector'}
I0810 10:51:55.588205 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.962, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0810 10:51:56.294455 135480425092608 run.py:689] Algo activity_selector step 9800 current loss 2.188290, current_train_items 147600.
I0810 10:51:56.390927 135480425092608 run.py:724] (val) algo activity_selector step 9800: {'selected': 0.9022556390977443, 'score': 0.9022556390977443, 'examples_seen': 147600, 'step': 9800, 'algorithm': 'activity_selector'}
I0810 10:51:56.391163 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.962, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0810 10:51:57.097700 135480425092608 run.py:689] Algo activity_selector step 9850 current loss 2.179559, current_train_items 148352.
I0810 10:51:57.194666 135480425092608 run.py:724] (val) algo activity_selector step 9850: {'selected': 0.8947368421052632, 'score': 0.8947368421052632, 'examples_seen': 148352, 'step': 9850, 'algorithm': 'activity_selector'}
I0810 10:51:57.194887 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.962, current avg val score is 0.895, val scores are: activity_selector: 0.895
I0810 10:51:57.900027 135480425092608 run.py:689] Algo activity_selector step 9900 current loss 2.385715, current_train_items 149104.
I0810 10:51:57.996399 135480425092608 run.py:724] (val) algo activity_selector step 9900: {'selected': 0.8905660377358491, 'score': 0.8905660377358491, 'examples_seen': 149104, 'step': 9900, 'algorithm': 'activity_selector'}
I0810 10:51:57.996633 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.962, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0810 10:51:58.702715 135480425092608 run.py:689] Algo activity_selector step 9950 current loss 1.919714, current_train_items 149856.
I0810 10:51:58.799783 135480425092608 run.py:724] (val) algo activity_selector step 9950: {'selected': 0.8905660377358491, 'score': 0.8905660377358491, 'examples_seen': 149856, 'step': 9950, 'algorithm': 'activity_selector'}
I0810 10:51:58.800007 135480425092608 run.py:748] Not saving new best model, best avg val score was 0.962, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0810 10:51:59.492546 135480425092608 run.py:754] Restoring best model from checkpoint...
I0810 10:52:05.368893 135480425092608 run.py:769] (test) algo activity_selector : {'selected': 0.9236363636363637, 'score': 0.9236363636363637, 'examples_seen': 150592, 'step': 10000, 'algorithm': 'activity_selector'}
I0810 10:52:05.369034 135480425092608 run.py:771] Done!
