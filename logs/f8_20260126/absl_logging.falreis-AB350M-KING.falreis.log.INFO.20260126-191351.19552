I0126 19:13:53.713943 136314624493056 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0126 19:13:53.714632 136314624493056 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0126 19:13:53.952896 136314624493056 run.py:462] Model: f8 ['activity_selector']
I0126 19:13:53.952996 136314624493056 run.py:464] algorithms ['activity_selector']
I0126 19:13:53.953172 136314624493056 run.py:465] train_lengths ['4', '7', '11', '13', '16']
I0126 19:13:53.953208 136314624493056 run.py:466] train_batch_size 16
I0126 19:13:53.953300 136314624493056 run.py:467] val_batch_size 16
I0126 19:13:53.953331 136314624493056 run.py:468] test_batch_size 16
I0126 19:13:53.953361 136314624493056 run.py:469] chunked_training True
I0126 19:13:53.953487 136314624493056 run.py:470] chunk_length 16
I0126 19:13:53.953518 136314624493056 run.py:471] train_steps 10000
I0126 19:13:53.953547 136314624493056 run.py:472] eval_every 50
I0126 19:13:53.953575 136314624493056 run.py:473] test_every 500
I0126 19:13:53.953606 136314624493056 run.py:474] hidden_size 256
I0126 19:13:53.953634 136314624493056 run.py:475] nb_msg_passing_steps 1
I0126 19:13:53.953662 136314624493056 run.py:476] learning_rate 0.001
I0126 19:13:53.953750 136314624493056 run.py:477] grad_clip_max_norm 1.0
I0126 19:13:53.953782 136314624493056 run.py:478] dropout_prob 0.0
I0126 19:13:53.953812 136314624493056 run.py:479] hint_teacher_forcing 0.0
I0126 19:13:53.953841 136314624493056 run.py:480] hint_mode encoded_decoded
I0126 19:13:53.953941 136314624493056 run.py:481] hint_repred_mode soft
I0126 19:13:53.953972 136314624493056 run.py:482] use_ln True
I0126 19:13:53.954001 136314624493056 run.py:483] use_lstm True
I0126 19:13:53.954028 136314624493056 run.py:484] nb_triplet_fts 16
I0126 19:13:53.954056 136314624493056 run.py:485] encoder_init xavier_on_scalars
I0126 19:13:53.954084 136314624493056 run.py:486] processor_type f8
I0126 19:13:53.954112 136314624493056 run.py:487] checkpoint_path CLRS30
I0126 19:13:53.954143 136314624493056 run.py:488] dataset_path CLRS30
I0126 19:13:53.954171 136314624493056 run.py:489] freeze_processor False
I0126 19:13:53.954199 136314624493056 run.py:490] reduction min
I0126 19:13:53.954227 136314624493056 run.py:491] activation elu
I0126 19:13:53.954254 136314624493056 run.py:492] restore_model 
I0126 19:13:53.954281 136314624493056 run.py:493] gated True
I0126 19:13:53.954311 136314624493056 run.py:494] gated_activation elu
I0126 19:13:53.954339 136314624493056 run.py:495] memory_type mha
I0126 19:13:53.954366 136314624493056 run.py:496] memory_size 16
I0126 19:13:53.957082 136314624493056 run.py:522] Creating samplers for algo activity_selector
W0126 19:13:53.957262 136314624493056 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0126 19:13:53.957525 136314624493056 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0126 19:13:54.178256 136314624493056 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0126 19:13:54.420985 136314624493056 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0126 19:13:54.722549 136314624493056 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0126 19:13:55.056642 136314624493056 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0126 19:13:55.442280 136314624493056 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0126 19:13:55.442571 136314624493056 samplers.py:124] Creating a dataset with 64 samples.
I0126 19:13:55.468768 136314624493056 run.py:306] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0126 19:13:55.469495 136314624493056 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0126 19:13:55.473317 136314624493056 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0126 19:13:55.476341 136314624493056 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0126 19:13:55.527701 136314624493056 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W0126 19:13:55.549095 136314624493056 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x7bf9b43b1440> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0126 19:14:38.641469 136314624493056 run.py:748] Algo activity_selector step 0 current loss 5.365568, current_train_items 32.
I0126 19:14:48.122281 136314624493056 run.py:783] (val) algo activity_selector step 0: {'selected': 0.12541254125412543, 'score': 0.12541254125412543, 'examples_seen': 32, 'step': 0, 'algorithm': 'activity_selector'}
I0126 19:14:48.122471 136314624493056 run.py:804] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.125, val scores are: activity_selector: 0.125
I0126 19:16:00.725329 136314624493056 run.py:748] Algo activity_selector step 50 current loss 3.560262, current_train_items 1408.
I0126 19:16:00.906791 136314624493056 run.py:783] (val) algo activity_selector step 50: {'selected': 0.712871287128713, 'score': 0.712871287128713, 'examples_seen': 1408, 'step': 50, 'algorithm': 'activity_selector'}
I0126 19:16:00.907034 136314624493056 run.py:804] Checkpointing best model, best avg val score was 0.125, current avg val score is 0.713, val scores are: activity_selector: 0.713
I0126 19:16:02.343113 136314624493056 run.py:748] Algo activity_selector step 100 current loss 3.706303, current_train_items 2800.
I0126 19:16:02.526129 136314624493056 run.py:783] (val) algo activity_selector step 100: {'selected': 0.6845360824742268, 'score': 0.6845360824742268, 'examples_seen': 2800, 'step': 100, 'algorithm': 'activity_selector'}
I0126 19:16:02.526355 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.713, current avg val score is 0.685, val scores are: activity_selector: 0.685
I0126 19:16:03.817179 136314624493056 run.py:748] Algo activity_selector step 150 current loss 2.569940, current_train_items 4176.
I0126 19:16:03.998753 136314624493056 run.py:783] (val) algo activity_selector step 150: {'selected': 0.7708703374777975, 'score': 0.7708703374777975, 'examples_seen': 4176, 'step': 150, 'algorithm': 'activity_selector'}
I0126 19:16:03.998980 136314624493056 run.py:804] Checkpointing best model, best avg val score was 0.713, current avg val score is 0.771, val scores are: activity_selector: 0.771
I0126 19:16:05.463383 136314624493056 run.py:748] Algo activity_selector step 200 current loss 2.675223, current_train_items 5536.
I0126 19:16:05.648549 136314624493056 run.py:783] (val) algo activity_selector step 200: {'selected': 0.7567567567567567, 'score': 0.7567567567567567, 'examples_seen': 5536, 'step': 200, 'algorithm': 'activity_selector'}
I0126 19:16:05.648782 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.771, current avg val score is 0.757, val scores are: activity_selector: 0.757
I0126 19:16:06.934038 136314624493056 run.py:748] Algo activity_selector step 250 current loss 2.691998, current_train_items 6944.
I0126 19:16:07.114907 136314624493056 run.py:783] (val) algo activity_selector step 250: {'selected': 0.7915869980879541, 'score': 0.7915869980879541, 'examples_seen': 6944, 'step': 250, 'algorithm': 'activity_selector'}
I0126 19:16:07.115173 136314624493056 run.py:804] Checkpointing best model, best avg val score was 0.771, current avg val score is 0.792, val scores are: activity_selector: 0.792
I0126 19:16:08.591520 136314624493056 run.py:748] Algo activity_selector step 300 current loss 1.926342, current_train_items 8304.
I0126 19:16:08.757224 136314624493056 run.py:783] (val) algo activity_selector step 300: {'selected': 0.8360957642725598, 'score': 0.8360957642725598, 'examples_seen': 8304, 'step': 300, 'algorithm': 'activity_selector'}
I0126 19:16:08.757466 136314624493056 run.py:804] Checkpointing best model, best avg val score was 0.792, current avg val score is 0.836, val scores are: activity_selector: 0.836
I0126 19:16:10.200269 136314624493056 run.py:748] Algo activity_selector step 350 current loss 1.791398, current_train_items 9680.
I0126 19:16:10.383659 136314624493056 run.py:783] (val) algo activity_selector step 350: {'selected': 0.8364312267657992, 'score': 0.8364312267657992, 'examples_seen': 9680, 'step': 350, 'algorithm': 'activity_selector'}
I0126 19:16:10.383888 136314624493056 run.py:804] Checkpointing best model, best avg val score was 0.836, current avg val score is 0.836, val scores are: activity_selector: 0.836
I0126 19:16:11.821438 136314624493056 run.py:748] Algo activity_selector step 400 current loss 2.329207, current_train_items 11072.
I0126 19:16:12.002866 136314624493056 run.py:783] (val) algo activity_selector step 400: {'selected': 0.7717171717171717, 'score': 0.7717171717171717, 'examples_seen': 11072, 'step': 400, 'algorithm': 'activity_selector'}
I0126 19:16:12.003095 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.836, current avg val score is 0.772, val scores are: activity_selector: 0.772
I0126 19:16:13.299844 136314624493056 run.py:748] Algo activity_selector step 450 current loss 1.666382, current_train_items 12448.
I0126 19:16:13.481779 136314624493056 run.py:783] (val) algo activity_selector step 450: {'selected': 0.8527131782945736, 'score': 0.8527131782945736, 'examples_seen': 12448, 'step': 450, 'algorithm': 'activity_selector'}
I0126 19:16:13.482038 136314624493056 run.py:804] Checkpointing best model, best avg val score was 0.836, current avg val score is 0.853, val scores are: activity_selector: 0.853
I0126 19:16:14.936129 136314624493056 run.py:748] Algo activity_selector step 500 current loss 2.765793, current_train_items 13824.
I0126 19:16:15.110889 136314624493056 run.py:783] (val) algo activity_selector step 500: {'selected': 0.7948243992606283, 'score': 0.7948243992606283, 'examples_seen': 13824, 'step': 500, 'algorithm': 'activity_selector'}
I0126 19:16:15.111113 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.853, current avg val score is 0.795, val scores are: activity_selector: 0.795
I0126 19:16:16.382985 136314624493056 run.py:748] Algo activity_selector step 550 current loss 2.135223, current_train_items 15200.
I0126 19:16:16.575707 136314624493056 run.py:783] (val) algo activity_selector step 550: {'selected': 0.8571428571428573, 'score': 0.8571428571428573, 'examples_seen': 15200, 'step': 550, 'algorithm': 'activity_selector'}
I0126 19:16:16.575934 136314624493056 run.py:804] Checkpointing best model, best avg val score was 0.853, current avg val score is 0.857, val scores are: activity_selector: 0.857
I0126 19:16:18.034895 136314624493056 run.py:748] Algo activity_selector step 600 current loss 1.793383, current_train_items 16576.
I0126 19:16:18.216453 136314624493056 run.py:783] (val) algo activity_selector step 600: {'selected': 0.8230912476722533, 'score': 0.8230912476722533, 'examples_seen': 16576, 'step': 600, 'algorithm': 'activity_selector'}
I0126 19:16:18.216681 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.857, current avg val score is 0.823, val scores are: activity_selector: 0.823
I0126 19:16:19.503605 136314624493056 run.py:748] Algo activity_selector step 650 current loss 1.833256, current_train_items 17952.
I0126 19:16:19.683766 136314624493056 run.py:783] (val) algo activity_selector step 650: {'selected': 0.8996138996138996, 'score': 0.8996138996138996, 'examples_seen': 17952, 'step': 650, 'algorithm': 'activity_selector'}
I0126 19:16:19.683990 136314624493056 run.py:804] Checkpointing best model, best avg val score was 0.857, current avg val score is 0.900, val scores are: activity_selector: 0.900
I0126 19:16:21.112969 136314624493056 run.py:748] Algo activity_selector step 700 current loss 1.957819, current_train_items 19344.
I0126 19:16:21.320992 136314624493056 run.py:783] (val) algo activity_selector step 700: {'selected': 0.8853754940711462, 'score': 0.8853754940711462, 'examples_seen': 19344, 'step': 700, 'algorithm': 'activity_selector'}
I0126 19:16:21.321218 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.900, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0126 19:16:22.621394 136314624493056 run.py:748] Algo activity_selector step 750 current loss 1.541655, current_train_items 20720.
I0126 19:16:22.801986 136314624493056 run.py:783] (val) algo activity_selector step 750: {'selected': 0.8581818181818183, 'score': 0.8581818181818183, 'examples_seen': 20720, 'step': 750, 'algorithm': 'activity_selector'}
I0126 19:16:22.802212 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.900, current avg val score is 0.858, val scores are: activity_selector: 0.858
I0126 19:16:24.065710 136314624493056 run.py:748] Algo activity_selector step 800 current loss 1.704629, current_train_items 22096.
I0126 19:16:24.270009 136314624493056 run.py:783] (val) algo activity_selector step 800: {'selected': 0.890721649484536, 'score': 0.890721649484536, 'examples_seen': 22096, 'step': 800, 'algorithm': 'activity_selector'}
I0126 19:16:24.270232 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.900, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0126 19:16:25.536636 136314624493056 run.py:748] Algo activity_selector step 850 current loss 2.416922, current_train_items 23472.
I0126 19:16:25.729079 136314624493056 run.py:783] (val) algo activity_selector step 850: {'selected': 0.8680688336520077, 'score': 0.8680688336520077, 'examples_seen': 23472, 'step': 850, 'algorithm': 'activity_selector'}
I0126 19:16:25.729302 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.900, current avg val score is 0.868, val scores are: activity_selector: 0.868
I0126 19:16:27.014986 136314624493056 run.py:748] Algo activity_selector step 900 current loss 2.064329, current_train_items 24848.
I0126 19:16:27.193941 136314624493056 run.py:783] (val) algo activity_selector step 900: {'selected': 0.860377358490566, 'score': 0.860377358490566, 'examples_seen': 24848, 'step': 900, 'algorithm': 'activity_selector'}
I0126 19:16:27.194167 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.900, current avg val score is 0.860, val scores are: activity_selector: 0.860
I0126 19:16:28.472142 136314624493056 run.py:748] Algo activity_selector step 950 current loss 1.343455, current_train_items 26224.
I0126 19:16:28.651039 136314624493056 run.py:783] (val) algo activity_selector step 950: {'selected': 0.8527724665391969, 'score': 0.8527724665391969, 'examples_seen': 26224, 'step': 950, 'algorithm': 'activity_selector'}
I0126 19:16:28.651264 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.900, current avg val score is 0.853, val scores are: activity_selector: 0.853
I0126 19:16:29.927970 136314624493056 run.py:748] Algo activity_selector step 1000 current loss 1.390809, current_train_items 27616.
I0126 19:16:30.108187 136314624493056 run.py:783] (val) algo activity_selector step 1000: {'selected': 0.9236234458259324, 'score': 0.9236234458259324, 'examples_seen': 27616, 'step': 1000, 'algorithm': 'activity_selector'}
I0126 19:16:30.108428 136314624493056 run.py:804] Checkpointing best model, best avg val score was 0.900, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0126 19:16:31.544785 136314624493056 run.py:748] Algo activity_selector step 1050 current loss 1.746072, current_train_items 28992.
I0126 19:16:31.725853 136314624493056 run.py:783] (val) algo activity_selector step 1050: {'selected': 0.9126213592233009, 'score': 0.9126213592233009, 'examples_seen': 28992, 'step': 1050, 'algorithm': 'activity_selector'}
I0126 19:16:31.726076 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.924, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0126 19:16:32.980859 136314624493056 run.py:748] Algo activity_selector step 1100 current loss 1.351322, current_train_items 30368.
I0126 19:16:33.184146 136314624493056 run.py:783] (val) algo activity_selector step 1100: {'selected': 0.8977955911823646, 'score': 0.8977955911823646, 'examples_seen': 30368, 'step': 1100, 'algorithm': 'activity_selector'}
I0126 19:16:33.184369 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.924, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0126 19:16:34.466866 136314624493056 run.py:748] Algo activity_selector step 1150 current loss 1.220716, current_train_items 31760.
I0126 19:16:34.645750 136314624493056 run.py:783] (val) algo activity_selector step 1150: {'selected': 0.8643410852713178, 'score': 0.8643410852713178, 'examples_seen': 31760, 'step': 1150, 'algorithm': 'activity_selector'}
I0126 19:16:34.645973 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.924, current avg val score is 0.864, val scores are: activity_selector: 0.864
I0126 19:16:35.933716 136314624493056 run.py:748] Algo activity_selector step 1200 current loss 1.197674, current_train_items 33120.
I0126 19:16:36.112596 136314624493056 run.py:783] (val) algo activity_selector step 1200: {'selected': 0.8633093525179856, 'score': 0.8633093525179856, 'examples_seen': 33120, 'step': 1200, 'algorithm': 'activity_selector'}
I0126 19:16:36.112825 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.924, current avg val score is 0.863, val scores are: activity_selector: 0.863
I0126 19:16:37.390197 136314624493056 run.py:748] Algo activity_selector step 1250 current loss 1.338618, current_train_items 34496.
I0126 19:16:37.570284 136314624493056 run.py:783] (val) algo activity_selector step 1250: {'selected': 0.9471698113207547, 'score': 0.9471698113207547, 'examples_seen': 34496, 'step': 1250, 'algorithm': 'activity_selector'}
I0126 19:16:37.570527 136314624493056 run.py:804] Checkpointing best model, best avg val score was 0.924, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0126 19:16:39.012875 136314624493056 run.py:748] Algo activity_selector step 1300 current loss 1.296520, current_train_items 35888.
I0126 19:16:39.194789 136314624493056 run.py:783] (val) algo activity_selector step 1300: {'selected': 0.9483747609942639, 'score': 0.9483747609942639, 'examples_seen': 35888, 'step': 1300, 'algorithm': 'activity_selector'}
I0126 19:16:39.195021 136314624493056 run.py:804] Checkpointing best model, best avg val score was 0.947, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0126 19:16:40.632268 136314624493056 run.py:748] Algo activity_selector step 1350 current loss 1.017957, current_train_items 37264.
I0126 19:16:40.814601 136314624493056 run.py:783] (val) algo activity_selector step 1350: {'selected': 0.9263565891472869, 'score': 0.9263565891472869, 'examples_seen': 37264, 'step': 1350, 'algorithm': 'activity_selector'}
I0126 19:16:40.814828 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0126 19:16:42.091553 136314624493056 run.py:748] Algo activity_selector step 1400 current loss 1.259354, current_train_items 38640.
I0126 19:16:42.270994 136314624493056 run.py:783] (val) algo activity_selector step 1400: {'selected': 0.8761220825852781, 'score': 0.8761220825852781, 'examples_seen': 38640, 'step': 1400, 'algorithm': 'activity_selector'}
I0126 19:16:42.271239 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.876, val scores are: activity_selector: 0.876
I0126 19:16:43.548343 136314624493056 run.py:748] Algo activity_selector step 1450 current loss 0.954728, current_train_items 40016.
I0126 19:16:43.728531 136314624493056 run.py:783] (val) algo activity_selector step 1450: {'selected': 0.8847736625514404, 'score': 0.8847736625514404, 'examples_seen': 40016, 'step': 1450, 'algorithm': 'activity_selector'}
I0126 19:16:43.728689 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0126 19:16:45.009138 136314624493056 run.py:748] Algo activity_selector step 1500 current loss 1.271479, current_train_items 41408.
I0126 19:16:45.188670 136314624493056 run.py:783] (val) algo activity_selector step 1500: {'selected': 0.8354430379746836, 'score': 0.8354430379746836, 'examples_seen': 41408, 'step': 1500, 'algorithm': 'activity_selector'}
I0126 19:16:45.188894 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.835, val scores are: activity_selector: 0.835
I0126 19:16:46.485583 136314624493056 run.py:748] Algo activity_selector step 1550 current loss 1.127081, current_train_items 42768.
I0126 19:16:46.646062 136314624493056 run.py:783] (val) algo activity_selector step 1550: {'selected': 0.9073359073359074, 'score': 0.9073359073359074, 'examples_seen': 42768, 'step': 1550, 'algorithm': 'activity_selector'}
I0126 19:16:46.646287 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0126 19:16:47.921940 136314624493056 run.py:748] Algo activity_selector step 1600 current loss 1.158383, current_train_items 44160.
I0126 19:16:48.327565 136314624493056 run.py:783] (val) algo activity_selector step 1600: {'selected': 0.9126984126984127, 'score': 0.9126984126984127, 'examples_seen': 44160, 'step': 1600, 'algorithm': 'activity_selector'}
I0126 19:16:48.327720 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0126 19:16:49.602885 136314624493056 run.py:748] Algo activity_selector step 1650 current loss 1.061294, current_train_items 45536.
I0126 19:16:49.783562 136314624493056 run.py:783] (val) algo activity_selector step 1650: {'selected': 0.8711656441717791, 'score': 0.8711656441717791, 'examples_seen': 45536, 'step': 1650, 'algorithm': 'activity_selector'}
I0126 19:16:49.783810 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.871, val scores are: activity_selector: 0.871
I0126 19:16:51.043344 136314624493056 run.py:748] Algo activity_selector step 1700 current loss 1.118427, current_train_items 46896.
I0126 19:16:51.247847 136314624493056 run.py:783] (val) algo activity_selector step 1700: {'selected': 0.9458917835671342, 'score': 0.9458917835671342, 'examples_seen': 46896, 'step': 1700, 'algorithm': 'activity_selector'}
I0126 19:16:51.248071 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0126 19:16:52.528285 136314624493056 run.py:748] Algo activity_selector step 1750 current loss 1.160581, current_train_items 48304.
I0126 19:16:52.706705 136314624493056 run.py:783] (val) algo activity_selector step 1750: {'selected': 0.9210526315789475, 'score': 0.9210526315789475, 'examples_seen': 48304, 'step': 1750, 'algorithm': 'activity_selector'}
I0126 19:16:52.706933 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0126 19:16:53.995024 136314624493056 run.py:748] Algo activity_selector step 1800 current loss 1.305432, current_train_items 49664.
I0126 19:16:54.172447 136314624493056 run.py:783] (val) algo activity_selector step 1800: {'selected': 0.919449901768173, 'score': 0.919449901768173, 'examples_seen': 49664, 'step': 1800, 'algorithm': 'activity_selector'}
I0126 19:16:54.172677 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0126 19:16:55.455847 136314624493056 run.py:748] Algo activity_selector step 1850 current loss 0.969545, current_train_items 51056.
I0126 19:16:55.636949 136314624493056 run.py:783] (val) algo activity_selector step 1850: {'selected': 0.8754578754578756, 'score': 0.8754578754578756, 'examples_seen': 51056, 'step': 1850, 'algorithm': 'activity_selector'}
I0126 19:16:55.637171 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.875, val scores are: activity_selector: 0.875
I0126 19:16:56.901660 136314624493056 run.py:748] Algo activity_selector step 1900 current loss 0.895987, current_train_items 52432.
I0126 19:16:57.094228 136314624493056 run.py:783] (val) algo activity_selector step 1900: {'selected': 0.9107806691449815, 'score': 0.9107806691449815, 'examples_seen': 52432, 'step': 1900, 'algorithm': 'activity_selector'}
I0126 19:16:57.094468 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0126 19:16:58.383277 136314624493056 run.py:748] Algo activity_selector step 1950 current loss 1.082303, current_train_items 53808.
I0126 19:16:58.563513 136314624493056 run.py:783] (val) algo activity_selector step 1950: {'selected': 0.9222423146473779, 'score': 0.9222423146473779, 'examples_seen': 53808, 'step': 1950, 'algorithm': 'activity_selector'}
I0126 19:16:58.563752 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0126 19:16:59.833499 136314624493056 run.py:748] Algo activity_selector step 2000 current loss 0.986641, current_train_items 55184.
I0126 19:17:00.030332 136314624493056 run.py:783] (val) algo activity_selector step 2000: {'selected': 0.9248554913294799, 'score': 0.9248554913294799, 'examples_seen': 55184, 'step': 2000, 'algorithm': 'activity_selector'}
I0126 19:17:00.030593 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0126 19:17:01.311113 136314624493056 run.py:748] Algo activity_selector step 2050 current loss 0.965176, current_train_items 56560.
I0126 19:17:01.493279 136314624493056 run.py:783] (val) algo activity_selector step 2050: {'selected': 0.9001814882032667, 'score': 0.9001814882032667, 'examples_seen': 56560, 'step': 2050, 'algorithm': 'activity_selector'}
I0126 19:17:01.493547 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.900, val scores are: activity_selector: 0.900
I0126 19:17:02.804093 136314624493056 run.py:748] Algo activity_selector step 2100 current loss 1.353287, current_train_items 57952.
I0126 19:17:02.965662 136314624493056 run.py:783] (val) algo activity_selector step 2100: {'selected': 0.872, 'score': 0.872, 'examples_seen': 57952, 'step': 2100, 'algorithm': 'activity_selector'}
I0126 19:17:02.965902 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.872, val scores are: activity_selector: 0.872
I0126 19:17:04.263103 136314624493056 run.py:748] Algo activity_selector step 2150 current loss 1.172271, current_train_items 59312.
I0126 19:17:04.430791 136314624493056 run.py:783] (val) algo activity_selector step 2150: {'selected': 0.9305019305019305, 'score': 0.9305019305019305, 'examples_seen': 59312, 'step': 2150, 'algorithm': 'activity_selector'}
I0126 19:17:04.431035 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0126 19:17:05.716632 136314624493056 run.py:748] Algo activity_selector step 2200 current loss 1.365903, current_train_items 60720.
I0126 19:17:05.896639 136314624493056 run.py:783] (val) algo activity_selector step 2200: {'selected': 0.9407114624505929, 'score': 0.9407114624505929, 'examples_seen': 60720, 'step': 2200, 'algorithm': 'activity_selector'}
I0126 19:17:05.896864 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0126 19:17:07.189535 136314624493056 run.py:748] Algo activity_selector step 2250 current loss 0.942685, current_train_items 62080.
I0126 19:17:07.367041 136314624493056 run.py:783] (val) algo activity_selector step 2250: {'selected': 0.8679245283018869, 'score': 0.8679245283018869, 'examples_seen': 62080, 'step': 2250, 'algorithm': 'activity_selector'}
I0126 19:17:07.367268 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.868, val scores are: activity_selector: 0.868
I0126 19:17:08.624567 136314624493056 run.py:748] Algo activity_selector step 2300 current loss 0.927276, current_train_items 63440.
I0126 19:17:08.828646 136314624493056 run.py:783] (val) algo activity_selector step 2300: {'selected': 0.9087378640776699, 'score': 0.9087378640776699, 'examples_seen': 63440, 'step': 2300, 'algorithm': 'activity_selector'}
I0126 19:17:08.828871 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0126 19:17:10.113058 136314624493056 run.py:748] Algo activity_selector step 2350 current loss 0.830842, current_train_items 64848.
I0126 19:17:10.295165 136314624493056 run.py:783] (val) algo activity_selector step 2350: {'selected': 0.9514925373134329, 'score': 0.9514925373134329, 'examples_seen': 64848, 'step': 2350, 'algorithm': 'activity_selector'}
I0126 19:17:10.295389 136314624493056 run.py:804] Checkpointing best model, best avg val score was 0.948, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0126 19:17:11.718600 136314624493056 run.py:748] Algo activity_selector step 2400 current loss 1.141295, current_train_items 66208.
I0126 19:17:11.928972 136314624493056 run.py:783] (val) algo activity_selector step 2400: {'selected': 0.911070780399274, 'score': 0.911070780399274, 'examples_seen': 66208, 'step': 2400, 'algorithm': 'activity_selector'}
I0126 19:17:11.929229 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.951, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0126 19:17:13.185039 136314624493056 run.py:748] Algo activity_selector step 2450 current loss 1.050997, current_train_items 67600.
I0126 19:17:13.389457 136314624493056 run.py:783] (val) algo activity_selector step 2450: {'selected': 0.9307692307692308, 'score': 0.9307692307692308, 'examples_seen': 67600, 'step': 2450, 'algorithm': 'activity_selector'}
I0126 19:17:13.389765 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.951, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0126 19:17:14.678208 136314624493056 run.py:748] Algo activity_selector step 2500 current loss 0.833997, current_train_items 68976.
I0126 19:17:14.861615 136314624493056 run.py:783] (val) algo activity_selector step 2500: {'selected': 0.9224652087475149, 'score': 0.9224652087475149, 'examples_seen': 68976, 'step': 2500, 'algorithm': 'activity_selector'}
I0126 19:17:14.861857 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.951, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0126 19:17:16.132934 136314624493056 run.py:748] Algo activity_selector step 2550 current loss 0.879258, current_train_items 70352.
I0126 19:17:16.338756 136314624493056 run.py:783] (val) algo activity_selector step 2550: {'selected': 0.9188118811881187, 'score': 0.9188118811881187, 'examples_seen': 70352, 'step': 2550, 'algorithm': 'activity_selector'}
I0126 19:17:16.339001 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.951, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0126 19:17:17.620910 136314624493056 run.py:748] Algo activity_selector step 2600 current loss 0.769555, current_train_items 71728.
I0126 19:17:17.801116 136314624493056 run.py:783] (val) algo activity_selector step 2600: {'selected': 0.9263565891472868, 'score': 0.9263565891472868, 'examples_seen': 71728, 'step': 2600, 'algorithm': 'activity_selector'}
I0126 19:17:17.801339 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.951, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0126 19:17:19.082948 136314624493056 run.py:748] Algo activity_selector step 2650 current loss 0.832186, current_train_items 73104.
I0126 19:17:19.263239 136314624493056 run.py:783] (val) algo activity_selector step 2650: {'selected': 0.9163498098859316, 'score': 0.9163498098859316, 'examples_seen': 73104, 'step': 2650, 'algorithm': 'activity_selector'}
I0126 19:17:19.263477 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.951, current avg val score is 0.916, val scores are: activity_selector: 0.916
I0126 19:17:20.533961 136314624493056 run.py:748] Algo activity_selector step 2700 current loss 0.887253, current_train_items 74496.
I0126 19:17:20.738609 136314624493056 run.py:783] (val) algo activity_selector step 2700: {'selected': 0.9534450651769087, 'score': 0.9534450651769087, 'examples_seen': 74496, 'step': 2700, 'algorithm': 'activity_selector'}
I0126 19:17:20.738836 136314624493056 run.py:804] Checkpointing best model, best avg val score was 0.951, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0126 19:17:22.194280 136314624493056 run.py:748] Algo activity_selector step 2750 current loss 0.927222, current_train_items 75856.
I0126 19:17:22.374360 136314624493056 run.py:783] (val) algo activity_selector step 2750: {'selected': 0.9260700389105058, 'score': 0.9260700389105058, 'examples_seen': 75856, 'step': 2750, 'algorithm': 'activity_selector'}
I0126 19:17:22.374604 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.953, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0126 19:17:23.643936 136314624493056 run.py:748] Algo activity_selector step 2800 current loss 0.802690, current_train_items 77264.
I0126 19:17:23.834785 136314624493056 run.py:783] (val) algo activity_selector step 2800: {'selected': 0.8925318761384335, 'score': 0.8925318761384335, 'examples_seen': 77264, 'step': 2800, 'algorithm': 'activity_selector'}
I0126 19:17:23.835011 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.953, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0126 19:17:25.143829 136314624493056 run.py:748] Algo activity_selector step 2850 current loss 0.980549, current_train_items 78624.
I0126 19:17:25.308844 136314624493056 run.py:783] (val) algo activity_selector step 2850: {'selected': 0.9573643410852712, 'score': 0.9573643410852712, 'examples_seen': 78624, 'step': 2850, 'algorithm': 'activity_selector'}
I0126 19:17:25.309068 136314624493056 run.py:804] Checkpointing best model, best avg val score was 0.953, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0126 19:17:26.742535 136314624493056 run.py:748] Algo activity_selector step 2900 current loss 0.893881, current_train_items 80000.
I0126 19:17:26.936817 136314624493056 run.py:783] (val) algo activity_selector step 2900: {'selected': 0.909090909090909, 'score': 0.909090909090909, 'examples_seen': 80000, 'step': 2900, 'algorithm': 'activity_selector'}
I0126 19:17:26.937039 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.957, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0126 19:17:28.218266 136314624493056 run.py:748] Algo activity_selector step 2950 current loss 0.895514, current_train_items 81392.
I0126 19:17:28.399025 136314624493056 run.py:783] (val) algo activity_selector step 2950: {'selected': 0.9152542372881357, 'score': 0.9152542372881357, 'examples_seen': 81392, 'step': 2950, 'algorithm': 'activity_selector'}
I0126 19:17:28.399353 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.957, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0126 19:17:29.697806 136314624493056 run.py:748] Algo activity_selector step 3000 current loss 1.057532, current_train_items 82752.
I0126 19:17:29.879275 136314624493056 run.py:783] (val) algo activity_selector step 3000: {'selected': 0.9157509157509158, 'score': 0.9157509157509158, 'examples_seen': 82752, 'step': 3000, 'algorithm': 'activity_selector'}
I0126 19:17:29.879514 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.957, current avg val score is 0.916, val scores are: activity_selector: 0.916
I0126 19:17:31.163799 136314624493056 run.py:748] Algo activity_selector step 3050 current loss 0.729321, current_train_items 84144.
I0126 19:17:31.344246 136314624493056 run.py:783] (val) algo activity_selector step 3050: {'selected': 0.9193548387096775, 'score': 0.9193548387096775, 'examples_seen': 84144, 'step': 3050, 'algorithm': 'activity_selector'}
I0126 19:17:31.344502 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.957, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0126 19:17:32.624782 136314624493056 run.py:748] Algo activity_selector step 3100 current loss 0.926224, current_train_items 85520.
I0126 19:17:32.805741 136314624493056 run.py:783] (val) algo activity_selector step 3100: {'selected': 0.9367588932806324, 'score': 0.9367588932806324, 'examples_seen': 85520, 'step': 3100, 'algorithm': 'activity_selector'}
I0126 19:17:32.805981 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.957, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0126 19:17:34.084452 136314624493056 run.py:748] Algo activity_selector step 3150 current loss 0.660671, current_train_items 86896.
I0126 19:17:34.278652 136314624493056 run.py:783] (val) algo activity_selector step 3150: {'selected': 0.9442379182156133, 'score': 0.9442379182156133, 'examples_seen': 86896, 'step': 3150, 'algorithm': 'activity_selector'}
I0126 19:17:34.278875 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.957, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0126 19:17:35.559559 136314624493056 run.py:748] Algo activity_selector step 3200 current loss 0.758510, current_train_items 88272.
I0126 19:17:35.741023 136314624493056 run.py:783] (val) algo activity_selector step 3200: {'selected': 0.9046728971962616, 'score': 0.9046728971962616, 'examples_seen': 88272, 'step': 3200, 'algorithm': 'activity_selector'}
I0126 19:17:35.741250 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.957, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0126 19:17:37.024193 136314624493056 run.py:748] Algo activity_selector step 3250 current loss 0.989942, current_train_items 89664.
I0126 19:17:37.204747 136314624493056 run.py:783] (val) algo activity_selector step 3250: {'selected': 0.9473684210526315, 'score': 0.9473684210526315, 'examples_seen': 89664, 'step': 3250, 'algorithm': 'activity_selector'}
I0126 19:17:37.204972 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.957, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0126 19:17:38.496347 136314624493056 run.py:748] Algo activity_selector step 3300 current loss 0.972612, current_train_items 91040.
I0126 19:17:38.676985 136314624493056 run.py:783] (val) algo activity_selector step 3300: {'selected': 0.928030303030303, 'score': 0.928030303030303, 'examples_seen': 91040, 'step': 3300, 'algorithm': 'activity_selector'}
I0126 19:17:38.677205 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.957, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0126 19:17:39.946104 136314624493056 run.py:748] Algo activity_selector step 3350 current loss 0.812618, current_train_items 92400.
I0126 19:17:40.138034 136314624493056 run.py:783] (val) algo activity_selector step 3350: {'selected': 0.922201138519924, 'score': 0.922201138519924, 'examples_seen': 92400, 'step': 3350, 'algorithm': 'activity_selector'}
I0126 19:17:40.138261 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.957, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0126 19:17:41.422508 136314624493056 run.py:748] Algo activity_selector step 3400 current loss 1.114158, current_train_items 93792.
I0126 19:17:41.603702 136314624493056 run.py:783] (val) algo activity_selector step 3400: {'selected': 0.888454011741683, 'score': 0.888454011741683, 'examples_seen': 93792, 'step': 3400, 'algorithm': 'activity_selector'}
I0126 19:17:41.603928 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.957, current avg val score is 0.888, val scores are: activity_selector: 0.888
I0126 19:17:42.894757 136314624493056 run.py:748] Algo activity_selector step 3450 current loss 0.891367, current_train_items 95168.
I0126 19:17:43.076221 136314624493056 run.py:783] (val) algo activity_selector step 3450: {'selected': 0.9132947976878613, 'score': 0.9132947976878613, 'examples_seen': 95168, 'step': 3450, 'algorithm': 'activity_selector'}
I0126 19:17:43.076469 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.957, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0126 19:17:44.356242 136314624493056 run.py:748] Algo activity_selector step 3500 current loss 0.893012, current_train_items 96544.
I0126 19:17:44.538018 136314624493056 run.py:783] (val) algo activity_selector step 3500: {'selected': 0.937625754527163, 'score': 0.937625754527163, 'examples_seen': 96544, 'step': 3500, 'algorithm': 'activity_selector'}
I0126 19:17:44.538245 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.957, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0126 19:17:45.818742 136314624493056 run.py:748] Algo activity_selector step 3550 current loss 0.833477, current_train_items 97936.
I0126 19:17:46.000666 136314624493056 run.py:783] (val) algo activity_selector step 3550: {'selected': 0.9257812499999999, 'score': 0.9257812499999999, 'examples_seen': 97936, 'step': 3550, 'algorithm': 'activity_selector'}
I0126 19:17:46.000890 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.957, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0126 19:17:47.309570 136314624493056 run.py:748] Algo activity_selector step 3600 current loss 1.247394, current_train_items 99312.
I0126 19:17:47.475662 136314624493056 run.py:783] (val) algo activity_selector step 3600: {'selected': 0.9632653061224489, 'score': 0.9632653061224489, 'examples_seen': 99312, 'step': 3600, 'algorithm': 'activity_selector'}
I0126 19:17:47.475888 136314624493056 run.py:804] Checkpointing best model, best avg val score was 0.957, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0126 19:17:48.897351 136314624493056 run.py:748] Algo activity_selector step 3650 current loss 1.026034, current_train_items 100688.
I0126 19:17:49.072807 136314624493056 run.py:783] (val) algo activity_selector step 3650: {'selected': 0.9518518518518518, 'score': 0.9518518518518518, 'examples_seen': 100688, 'step': 3650, 'algorithm': 'activity_selector'}
I0126 19:17:49.073037 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.963, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0126 19:17:50.357012 136314624493056 run.py:748] Algo activity_selector step 3700 current loss 0.855445, current_train_items 102064.
I0126 19:17:50.538548 136314624493056 run.py:783] (val) algo activity_selector step 3700: {'selected': 0.948, 'score': 0.948, 'examples_seen': 102064, 'step': 3700, 'algorithm': 'activity_selector'}
I0126 19:17:50.538794 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.963, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0126 19:17:51.832221 136314624493056 run.py:748] Algo activity_selector step 3750 current loss 1.193219, current_train_items 103440.
I0126 19:17:52.014268 136314624493056 run.py:783] (val) algo activity_selector step 3750: {'selected': 0.9184890656063618, 'score': 0.9184890656063618, 'examples_seen': 103440, 'step': 3750, 'algorithm': 'activity_selector'}
I0126 19:17:52.014507 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.963, current avg val score is 0.918, val scores are: activity_selector: 0.918
I0126 19:17:53.294130 136314624493056 run.py:748] Algo activity_selector step 3800 current loss 0.765375, current_train_items 104816.
I0126 19:17:53.475522 136314624493056 run.py:783] (val) algo activity_selector step 3800: {'selected': 0.9050505050505051, 'score': 0.9050505050505051, 'examples_seen': 104816, 'step': 3800, 'algorithm': 'activity_selector'}
I0126 19:17:53.475749 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.963, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0126 19:17:54.754586 136314624493056 run.py:748] Algo activity_selector step 3850 current loss 1.007542, current_train_items 106208.
I0126 19:17:54.936104 136314624493056 run.py:783] (val) algo activity_selector step 3850: {'selected': 0.9315589353612168, 'score': 0.9315589353612168, 'examples_seen': 106208, 'step': 3850, 'algorithm': 'activity_selector'}
I0126 19:17:54.936336 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.963, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0126 19:17:56.227749 136314624493056 run.py:748] Algo activity_selector step 3900 current loss 0.872217, current_train_items 107584.
I0126 19:17:56.407452 136314624493056 run.py:783] (val) algo activity_selector step 3900: {'selected': 0.9477756286266925, 'score': 0.9477756286266925, 'examples_seen': 107584, 'step': 3900, 'algorithm': 'activity_selector'}
I0126 19:17:56.407679 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.963, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0126 19:17:57.690961 136314624493056 run.py:748] Algo activity_selector step 3950 current loss 0.897303, current_train_items 108960.
I0126 19:17:57.872631 136314624493056 run.py:783] (val) algo activity_selector step 3950: {'selected': 0.8881118881118881, 'score': 0.8881118881118881, 'examples_seen': 108960, 'step': 3950, 'algorithm': 'activity_selector'}
I0126 19:17:57.872860 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.963, current avg val score is 0.888, val scores are: activity_selector: 0.888
I0126 19:17:59.154278 136314624493056 run.py:748] Algo activity_selector step 4000 current loss 0.862073, current_train_items 110336.
I0126 19:17:59.334484 136314624493056 run.py:783] (val) algo activity_selector step 4000: {'selected': 0.8970873786407767, 'score': 0.8970873786407767, 'examples_seen': 110336, 'step': 4000, 'algorithm': 'activity_selector'}
I0126 19:17:59.334709 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.963, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0126 19:18:00.628937 136314624493056 run.py:748] Algo activity_selector step 4050 current loss 0.781395, current_train_items 111712.
I0126 19:18:00.807496 136314624493056 run.py:783] (val) algo activity_selector step 4050: {'selected': 0.9141791044776119, 'score': 0.9141791044776119, 'examples_seen': 111712, 'step': 4050, 'algorithm': 'activity_selector'}
I0126 19:18:00.807722 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.963, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0126 19:18:02.068239 136314624493056 run.py:748] Algo activity_selector step 4100 current loss 0.924565, current_train_items 113088.
I0126 19:18:02.273017 136314624493056 run.py:783] (val) algo activity_selector step 4100: {'selected': 0.9537892791127541, 'score': 0.9537892791127541, 'examples_seen': 113088, 'step': 4100, 'algorithm': 'activity_selector'}
I0126 19:18:02.273238 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.963, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0126 19:18:03.546088 136314624493056 run.py:748] Algo activity_selector step 4150 current loss 0.874657, current_train_items 114480.
I0126 19:18:03.738288 136314624493056 run.py:783] (val) algo activity_selector step 4150: {'selected': 0.8793774319066149, 'score': 0.8793774319066149, 'examples_seen': 114480, 'step': 4150, 'algorithm': 'activity_selector'}
I0126 19:18:03.738537 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.963, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0126 19:18:05.005248 136314624493056 run.py:748] Algo activity_selector step 4200 current loss 1.081439, current_train_items 115856.
I0126 19:18:05.209336 136314624493056 run.py:783] (val) algo activity_selector step 4200: {'selected': 0.8695652173913043, 'score': 0.8695652173913043, 'examples_seen': 115856, 'step': 4200, 'algorithm': 'activity_selector'}
I0126 19:18:05.209579 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.963, current avg val score is 0.870, val scores are: activity_selector: 0.870
I0126 19:18:06.490276 136314624493056 run.py:748] Algo activity_selector step 4250 current loss 0.867328, current_train_items 117216.
I0126 19:18:06.672121 136314624493056 run.py:783] (val) algo activity_selector step 4250: {'selected': 0.9100719424460432, 'score': 0.9100719424460432, 'examples_seen': 117216, 'step': 4250, 'algorithm': 'activity_selector'}
I0126 19:18:06.672368 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.963, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0126 19:18:07.936511 136314624493056 run.py:748] Algo activity_selector step 4300 current loss 1.065958, current_train_items 118624.
I0126 19:18:08.138799 136314624493056 run.py:783] (val) algo activity_selector step 4300: {'selected': 0.9299610894941636, 'score': 0.9299610894941636, 'examples_seen': 118624, 'step': 4300, 'algorithm': 'activity_selector'}
I0126 19:18:08.139023 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.963, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0126 19:18:09.430633 136314624493056 run.py:748] Algo activity_selector step 4350 current loss 0.675793, current_train_items 119984.
I0126 19:18:09.610666 136314624493056 run.py:783] (val) algo activity_selector step 4350: {'selected': 0.9647058823529413, 'score': 0.9647058823529413, 'examples_seen': 119984, 'step': 4350, 'algorithm': 'activity_selector'}
I0126 19:18:09.610893 136314624493056 run.py:804] Checkpointing best model, best avg val score was 0.963, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0126 19:18:11.042423 136314624493056 run.py:748] Algo activity_selector step 4400 current loss 0.717593, current_train_items 121360.
I0126 19:18:11.223023 136314624493056 run.py:783] (val) algo activity_selector step 4400: {'selected': 0.9132075471698112, 'score': 0.9132075471698112, 'examples_seen': 121360, 'step': 4400, 'algorithm': 'activity_selector'}
I0126 19:18:11.223248 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.965, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0126 19:18:12.507487 136314624493056 run.py:748] Algo activity_selector step 4450 current loss 1.022758, current_train_items 122752.
I0126 19:18:12.687323 136314624493056 run.py:783] (val) algo activity_selector step 4450: {'selected': 0.9651162790697675, 'score': 0.9651162790697675, 'examples_seen': 122752, 'step': 4450, 'algorithm': 'activity_selector'}
I0126 19:18:12.687576 136314624493056 run.py:804] Checkpointing best model, best avg val score was 0.965, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0126 19:18:14.135699 136314624493056 run.py:748] Algo activity_selector step 4500 current loss 1.150715, current_train_items 124128.
I0126 19:18:14.317309 136314624493056 run.py:783] (val) algo activity_selector step 4500: {'selected': 0.9824561403508771, 'score': 0.9824561403508771, 'examples_seen': 124128, 'step': 4500, 'algorithm': 'activity_selector'}
I0126 19:18:14.317546 136314624493056 run.py:804] Checkpointing best model, best avg val score was 0.965, current avg val score is 0.982, val scores are: activity_selector: 0.982
I0126 19:18:15.754355 136314624493056 run.py:748] Algo activity_selector step 4550 current loss 0.763006, current_train_items 125504.
I0126 19:18:15.939200 136314624493056 run.py:783] (val) algo activity_selector step 4550: {'selected': 0.93812375249501, 'score': 0.93812375249501, 'examples_seen': 125504, 'step': 4550, 'algorithm': 'activity_selector'}
I0126 19:18:15.939445 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0126 19:18:17.238865 136314624493056 run.py:748] Algo activity_selector step 4600 current loss 0.868725, current_train_items 126880.
I0126 19:18:17.402600 136314624493056 run.py:783] (val) algo activity_selector step 4600: {'selected': 0.9390962671905698, 'score': 0.9390962671905698, 'examples_seen': 126880, 'step': 4600, 'algorithm': 'activity_selector'}
I0126 19:18:17.402832 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0126 19:18:18.694864 136314624493056 run.py:748] Algo activity_selector step 4650 current loss 0.972719, current_train_items 128272.
I0126 19:18:18.871345 136314624493056 run.py:783] (val) algo activity_selector step 4650: {'selected': 0.9530956848030019, 'score': 0.9530956848030019, 'examples_seen': 128272, 'step': 4650, 'algorithm': 'activity_selector'}
I0126 19:18:18.871589 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0126 19:18:20.127767 136314624493056 run.py:748] Algo activity_selector step 4700 current loss 0.871846, current_train_items 129632.
I0126 19:18:20.332245 136314624493056 run.py:783] (val) algo activity_selector step 4700: {'selected': 0.9294755877034357, 'score': 0.9294755877034357, 'examples_seen': 129632, 'step': 4700, 'algorithm': 'activity_selector'}
I0126 19:18:20.332492 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0126 19:18:21.613852 136314624493056 run.py:748] Algo activity_selector step 4750 current loss 0.953848, current_train_items 131024.
I0126 19:18:21.791966 136314624493056 run.py:783] (val) algo activity_selector step 4750: {'selected': 0.9520153550863724, 'score': 0.9520153550863724, 'examples_seen': 131024, 'step': 4750, 'algorithm': 'activity_selector'}
I0126 19:18:21.792193 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0126 19:18:23.087215 136314624493056 run.py:748] Algo activity_selector step 4800 current loss 0.643708, current_train_items 132400.
I0126 19:18:23.267473 136314624493056 run.py:783] (val) algo activity_selector step 4800: {'selected': 0.920388349514563, 'score': 0.920388349514563, 'examples_seen': 132400, 'step': 4800, 'algorithm': 'activity_selector'}
I0126 19:18:23.267697 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0126 19:18:24.548571 136314624493056 run.py:748] Algo activity_selector step 4850 current loss 0.868763, current_train_items 133760.
I0126 19:18:24.729352 136314624493056 run.py:783] (val) algo activity_selector step 4850: {'selected': 0.9497400346620452, 'score': 0.9497400346620452, 'examples_seen': 133760, 'step': 4850, 'algorithm': 'activity_selector'}
I0126 19:18:24.729599 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0126 19:18:26.010598 136314624493056 run.py:748] Algo activity_selector step 4900 current loss 0.767035, current_train_items 135168.
I0126 19:18:26.191073 136314624493056 run.py:783] (val) algo activity_selector step 4900: {'selected': 0.9399293286219081, 'score': 0.9399293286219081, 'examples_seen': 135168, 'step': 4900, 'algorithm': 'activity_selector'}
I0126 19:18:26.191296 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0126 19:18:27.482859 136314624493056 run.py:748] Algo activity_selector step 4950 current loss 0.810315, current_train_items 136528.
I0126 19:18:27.665904 136314624493056 run.py:783] (val) algo activity_selector step 4950: {'selected': 0.9239543726235742, 'score': 0.9239543726235742, 'examples_seen': 136528, 'step': 4950, 'algorithm': 'activity_selector'}
I0126 19:18:27.666128 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0126 19:18:28.923337 136314624493056 run.py:748] Algo activity_selector step 5000 current loss 0.736515, current_train_items 137920.
I0126 19:18:29.128697 136314624493056 run.py:783] (val) algo activity_selector step 5000: {'selected': 0.9552238805970149, 'score': 0.9552238805970149, 'examples_seen': 137920, 'step': 5000, 'algorithm': 'activity_selector'}
I0126 19:18:29.128917 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0126 19:18:30.421298 136314624493056 run.py:748] Algo activity_selector step 5050 current loss 0.767136, current_train_items 139296.
I0126 19:18:30.591604 136314624493056 run.py:783] (val) algo activity_selector step 5050: {'selected': 0.9397590361445783, 'score': 0.9397590361445783, 'examples_seen': 139296, 'step': 5050, 'algorithm': 'activity_selector'}
I0126 19:18:30.591830 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0126 19:18:31.894175 136314624493056 run.py:748] Algo activity_selector step 5100 current loss 0.796438, current_train_items 140656.
I0126 19:18:32.063171 136314624493056 run.py:783] (val) algo activity_selector step 5100: {'selected': 0.9523809523809524, 'score': 0.9523809523809524, 'examples_seen': 140656, 'step': 5100, 'algorithm': 'activity_selector'}
I0126 19:18:32.063396 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0126 19:18:33.361648 136314624493056 run.py:748] Algo activity_selector step 5150 current loss 0.955235, current_train_items 142048.
I0126 19:18:33.528130 136314624493056 run.py:783] (val) algo activity_selector step 5150: {'selected': 0.8875, 'score': 0.8875, 'examples_seen': 142048, 'step': 5150, 'algorithm': 'activity_selector'}
I0126 19:18:33.528352 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.887, val scores are: activity_selector: 0.887
I0126 19:18:34.795582 136314624493056 run.py:748] Algo activity_selector step 5200 current loss 0.678682, current_train_items 143424.
I0126 19:18:34.990894 136314624493056 run.py:783] (val) algo activity_selector step 5200: {'selected': 0.9593810444874274, 'score': 0.9593810444874274, 'examples_seen': 143424, 'step': 5200, 'algorithm': 'activity_selector'}
I0126 19:18:34.991119 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0126 19:18:36.281394 136314624493056 run.py:748] Algo activity_selector step 5250 current loss 0.940317, current_train_items 144816.
I0126 19:18:36.463048 136314624493056 run.py:783] (val) algo activity_selector step 5250: {'selected': 0.9669902912621358, 'score': 0.9669902912621358, 'examples_seen': 144816, 'step': 5250, 'algorithm': 'activity_selector'}
I0126 19:18:36.463275 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0126 19:18:37.730890 136314624493056 run.py:748] Algo activity_selector step 5300 current loss 0.713756, current_train_items 146176.
I0126 19:18:37.924435 136314624493056 run.py:783] (val) algo activity_selector step 5300: {'selected': 0.9393939393939394, 'score': 0.9393939393939394, 'examples_seen': 146176, 'step': 5300, 'algorithm': 'activity_selector'}
I0126 19:18:37.924670 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0126 19:18:39.207214 136314624493056 run.py:748] Algo activity_selector step 5350 current loss 0.876925, current_train_items 147584.
I0126 19:18:39.387542 136314624493056 run.py:783] (val) algo activity_selector step 5350: {'selected': 0.9577981651376147, 'score': 0.9577981651376147, 'examples_seen': 147584, 'step': 5350, 'algorithm': 'activity_selector'}
I0126 19:18:39.387767 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0126 19:18:40.680169 136314624493056 run.py:748] Algo activity_selector step 5400 current loss 0.730420, current_train_items 148944.
I0126 19:18:40.861078 136314624493056 run.py:783] (val) algo activity_selector step 5400: {'selected': 0.9640000000000001, 'score': 0.9640000000000001, 'examples_seen': 148944, 'step': 5400, 'algorithm': 'activity_selector'}
I0126 19:18:40.861307 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0126 19:18:42.143445 136314624493056 run.py:748] Algo activity_selector step 5450 current loss 0.919478, current_train_items 150304.
I0126 19:18:42.322655 136314624493056 run.py:783] (val) algo activity_selector step 5450: {'selected': 0.9141716566866267, 'score': 0.9141716566866267, 'examples_seen': 150304, 'step': 5450, 'algorithm': 'activity_selector'}
I0126 19:18:42.322880 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0126 19:18:43.613591 136314624493056 run.py:748] Algo activity_selector step 5500 current loss 0.741317, current_train_items 151712.
I0126 19:18:43.786781 136314624493056 run.py:783] (val) algo activity_selector step 5500: {'selected': 0.932806324110672, 'score': 0.932806324110672, 'examples_seen': 151712, 'step': 5500, 'algorithm': 'activity_selector'}
I0126 19:18:43.787007 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0126 19:18:45.081790 136314624493056 run.py:748] Algo activity_selector step 5550 current loss 0.793562, current_train_items 153072.
I0126 19:18:45.262255 136314624493056 run.py:783] (val) algo activity_selector step 5550: {'selected': 0.925531914893617, 'score': 0.925531914893617, 'examples_seen': 153072, 'step': 5550, 'algorithm': 'activity_selector'}
I0126 19:18:45.262500 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0126 19:18:46.544388 136314624493056 run.py:748] Algo activity_selector step 5600 current loss 0.685714, current_train_items 154464.
I0126 19:18:46.723722 136314624493056 run.py:783] (val) algo activity_selector step 5600: {'selected': 0.9358178053830227, 'score': 0.9358178053830227, 'examples_seen': 154464, 'step': 5600, 'algorithm': 'activity_selector'}
I0126 19:18:46.723967 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0126 19:18:48.011752 136314624493056 run.py:748] Algo activity_selector step 5650 current loss 0.554526, current_train_items 155840.
I0126 19:18:48.183535 136314624493056 run.py:783] (val) algo activity_selector step 5650: {'selected': 0.9614678899082569, 'score': 0.9614678899082569, 'examples_seen': 155840, 'step': 5650, 'algorithm': 'activity_selector'}
I0126 19:18:48.183687 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0126 19:18:49.463332 136314624493056 run.py:748] Algo activity_selector step 5700 current loss 0.764466, current_train_items 157216.
I0126 19:18:49.644207 136314624493056 run.py:783] (val) algo activity_selector step 5700: {'selected': 0.9157667386609072, 'score': 0.9157667386609072, 'examples_seen': 157216, 'step': 5700, 'algorithm': 'activity_selector'}
I0126 19:18:49.644445 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.916, val scores are: activity_selector: 0.916
I0126 19:18:50.940335 136314624493056 run.py:748] Algo activity_selector step 5750 current loss 0.822085, current_train_items 158592.
I0126 19:18:51.118995 136314624493056 run.py:783] (val) algo activity_selector step 5750: {'selected': 0.9056603773584906, 'score': 0.9056603773584906, 'examples_seen': 158592, 'step': 5750, 'algorithm': 'activity_selector'}
I0126 19:18:51.119222 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0126 19:18:52.399085 136314624493056 run.py:748] Algo activity_selector step 5800 current loss 0.919399, current_train_items 159968.
I0126 19:18:52.579682 136314624493056 run.py:783] (val) algo activity_selector step 5800: {'selected': 0.9120879120879121, 'score': 0.9120879120879121, 'examples_seen': 159968, 'step': 5800, 'algorithm': 'activity_selector'}
I0126 19:18:52.579908 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0126 19:18:53.875100 136314624493056 run.py:748] Algo activity_selector step 5850 current loss 0.900314, current_train_items 161360.
I0126 19:18:54.055525 136314624493056 run.py:783] (val) algo activity_selector step 5850: {'selected': 0.9362549800796813, 'score': 0.9362549800796813, 'examples_seen': 161360, 'step': 5850, 'algorithm': 'activity_selector'}
I0126 19:18:54.055749 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0126 19:18:55.334313 136314624493056 run.py:748] Algo activity_selector step 5900 current loss 0.679951, current_train_items 162720.
I0126 19:18:55.515797 136314624493056 run.py:783] (val) algo activity_selector step 5900: {'selected': 0.9400386847195358, 'score': 0.9400386847195358, 'examples_seen': 162720, 'step': 5900, 'algorithm': 'activity_selector'}
I0126 19:18:55.516025 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0126 19:18:56.784117 136314624493056 run.py:748] Algo activity_selector step 5950 current loss 0.726438, current_train_items 164112.
I0126 19:18:56.976183 136314624493056 run.py:783] (val) algo activity_selector step 5950: {'selected': 0.9277108433734939, 'score': 0.9277108433734939, 'examples_seen': 164112, 'step': 5950, 'algorithm': 'activity_selector'}
I0126 19:18:56.976428 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0126 19:18:58.266579 136314624493056 run.py:748] Algo activity_selector step 6000 current loss 0.743974, current_train_items 165488.
I0126 19:18:58.446183 136314624493056 run.py:783] (val) algo activity_selector step 6000: {'selected': 0.9781818181818182, 'score': 0.9781818181818182, 'examples_seen': 165488, 'step': 6000, 'algorithm': 'activity_selector'}
I0126 19:18:58.446441 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.978, val scores are: activity_selector: 0.978
I0126 19:18:59.730008 136314624493056 run.py:748] Algo activity_selector step 6050 current loss 0.756522, current_train_items 166864.
I0126 19:18:59.910695 136314624493056 run.py:783] (val) algo activity_selector step 6050: {'selected': 0.8560460652591171, 'score': 0.8560460652591171, 'examples_seen': 166864, 'step': 6050, 'algorithm': 'activity_selector'}
I0126 19:18:59.910925 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.856, val scores are: activity_selector: 0.856
I0126 19:19:01.179515 136314624493056 run.py:748] Algo activity_selector step 6100 current loss 0.932200, current_train_items 168256.
I0126 19:19:01.370814 136314624493056 run.py:783] (val) algo activity_selector step 6100: {'selected': 0.9577464788732395, 'score': 0.9577464788732395, 'examples_seen': 168256, 'step': 6100, 'algorithm': 'activity_selector'}
I0126 19:19:01.371039 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0126 19:19:02.681355 136314624493056 run.py:748] Algo activity_selector step 6150 current loss 1.065789, current_train_items 169616.
I0126 19:19:02.841737 136314624493056 run.py:783] (val) algo activity_selector step 6150: {'selected': 0.9513742071881607, 'score': 0.9513742071881607, 'examples_seen': 169616, 'step': 6150, 'algorithm': 'activity_selector'}
I0126 19:19:02.841970 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0126 19:19:04.101337 136314624493056 run.py:748] Algo activity_selector step 6200 current loss 0.899979, current_train_items 171008.
I0126 19:19:04.306104 136314624493056 run.py:783] (val) algo activity_selector step 6200: {'selected': 0.9440993788819877, 'score': 0.9440993788819877, 'examples_seen': 171008, 'step': 6200, 'algorithm': 'activity_selector'}
I0126 19:19:04.306332 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0126 19:19:05.588798 136314624493056 run.py:748] Algo activity_selector step 6250 current loss 1.113281, current_train_items 172384.
I0126 19:19:05.768743 136314624493056 run.py:783] (val) algo activity_selector step 6250: {'selected': 0.9728682170542635, 'score': 0.9728682170542635, 'examples_seen': 172384, 'step': 6250, 'algorithm': 'activity_selector'}
I0126 19:19:05.768972 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0126 19:19:07.050466 136314624493056 run.py:748] Algo activity_selector step 6300 current loss 0.497660, current_train_items 173760.
I0126 19:19:07.242986 136314624493056 run.py:783] (val) algo activity_selector step 6300: {'selected': 0.9431818181818182, 'score': 0.9431818181818182, 'examples_seen': 173760, 'step': 6300, 'algorithm': 'activity_selector'}
I0126 19:19:07.243213 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0126 19:19:08.525416 136314624493056 run.py:748] Algo activity_selector step 6350 current loss 0.486319, current_train_items 175136.
I0126 19:19:08.704217 136314624493056 run.py:783] (val) algo activity_selector step 6350: {'selected': 0.9635627530364372, 'score': 0.9635627530364372, 'examples_seen': 175136, 'step': 6350, 'algorithm': 'activity_selector'}
I0126 19:19:08.704479 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0126 19:19:09.990710 136314624493056 run.py:748] Algo activity_selector step 6400 current loss 0.705936, current_train_items 176528.
I0126 19:19:10.167286 136314624493056 run.py:783] (val) algo activity_selector step 6400: {'selected': 0.8761904761904763, 'score': 0.8761904761904763, 'examples_seen': 176528, 'step': 6400, 'algorithm': 'activity_selector'}
I0126 19:19:10.167444 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.876, val scores are: activity_selector: 0.876
I0126 19:19:11.462846 136314624493056 run.py:748] Algo activity_selector step 6450 current loss 0.661174, current_train_items 177904.
I0126 19:19:11.625510 136314624493056 run.py:783] (val) algo activity_selector step 6450: {'selected': 0.933572710951526, 'score': 0.933572710951526, 'examples_seen': 177904, 'step': 6450, 'algorithm': 'activity_selector'}
I0126 19:19:11.625761 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0126 19:19:12.927931 136314624493056 run.py:748] Algo activity_selector step 6500 current loss 0.574237, current_train_items 179264.
I0126 19:19:13.089487 136314624493056 run.py:783] (val) algo activity_selector step 6500: {'selected': 0.9527145359019265, 'score': 0.9527145359019265, 'examples_seen': 179264, 'step': 6500, 'algorithm': 'activity_selector'}
I0126 19:19:13.089746 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0126 19:19:14.374336 136314624493056 run.py:748] Algo activity_selector step 6550 current loss 0.705332, current_train_items 180656.
I0126 19:19:14.556797 136314624493056 run.py:783] (val) algo activity_selector step 6550: {'selected': 0.9400749063670412, 'score': 0.9400749063670412, 'examples_seen': 180656, 'step': 6550, 'algorithm': 'activity_selector'}
I0126 19:19:14.557021 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0126 19:19:15.836622 136314624493056 run.py:748] Algo activity_selector step 6600 current loss 0.753163, current_train_items 182032.
I0126 19:19:16.031430 136314624493056 run.py:783] (val) algo activity_selector step 6600: {'selected': 0.9405204460966542, 'score': 0.9405204460966542, 'examples_seen': 182032, 'step': 6600, 'algorithm': 'activity_selector'}
I0126 19:19:16.031683 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0126 19:19:17.316506 136314624493056 run.py:748] Algo activity_selector step 6650 current loss 1.205374, current_train_items 183408.
I0126 19:19:17.493742 136314624493056 run.py:783] (val) algo activity_selector step 6650: {'selected': 0.8966861598440545, 'score': 0.8966861598440545, 'examples_seen': 183408, 'step': 6650, 'algorithm': 'activity_selector'}
I0126 19:19:17.493973 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0126 19:19:18.774806 136314624493056 run.py:748] Algo activity_selector step 6700 current loss 0.634984, current_train_items 184800.
I0126 19:19:18.956814 136314624493056 run.py:783] (val) algo activity_selector step 6700: {'selected': 0.9397590361445783, 'score': 0.9397590361445783, 'examples_seen': 184800, 'step': 6700, 'algorithm': 'activity_selector'}
I0126 19:19:18.957060 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0126 19:19:20.253772 136314624493056 run.py:748] Algo activity_selector step 6750 current loss 0.657882, current_train_items 186176.
I0126 19:19:20.435622 136314624493056 run.py:783] (val) algo activity_selector step 6750: {'selected': 0.9467213114754098, 'score': 0.9467213114754098, 'examples_seen': 186176, 'step': 6750, 'algorithm': 'activity_selector'}
I0126 19:19:20.435868 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0126 19:19:21.715016 136314624493056 run.py:748] Algo activity_selector step 6800 current loss 0.672027, current_train_items 187536.
I0126 19:19:21.896360 136314624493056 run.py:783] (val) algo activity_selector step 6800: {'selected': 0.9271028037383177, 'score': 0.9271028037383177, 'examples_seen': 187536, 'step': 6800, 'algorithm': 'activity_selector'}
I0126 19:19:21.896620 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0126 19:19:23.181822 136314624493056 run.py:748] Algo activity_selector step 6850 current loss 0.916453, current_train_items 188928.
I0126 19:19:23.361242 136314624493056 run.py:783] (val) algo activity_selector step 6850: {'selected': 0.9107142857142857, 'score': 0.9107142857142857, 'examples_seen': 188928, 'step': 6850, 'algorithm': 'activity_selector'}
I0126 19:19:23.361426 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0126 19:19:24.644108 136314624493056 run.py:748] Algo activity_selector step 6900 current loss 0.673137, current_train_items 190304.
I0126 19:19:24.822680 136314624493056 run.py:783] (val) algo activity_selector step 6900: {'selected': 0.9315589353612167, 'score': 0.9315589353612167, 'examples_seen': 190304, 'step': 6900, 'algorithm': 'activity_selector'}
I0126 19:19:24.822910 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0126 19:19:26.104113 136314624493056 run.py:748] Algo activity_selector step 6950 current loss 0.653386, current_train_items 191680.
I0126 19:19:26.284911 136314624493056 run.py:783] (val) algo activity_selector step 6950: {'selected': 0.929336188436831, 'score': 0.929336188436831, 'examples_seen': 191680, 'step': 6950, 'algorithm': 'activity_selector'}
I0126 19:19:26.285157 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0126 19:19:27.566873 136314624493056 run.py:748] Algo activity_selector step 7000 current loss 0.727999, current_train_items 193072.
I0126 19:19:27.746400 136314624493056 run.py:783] (val) algo activity_selector step 7000: {'selected': 0.9277566539923955, 'score': 0.9277566539923955, 'examples_seen': 193072, 'step': 7000, 'algorithm': 'activity_selector'}
I0126 19:19:27.746647 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0126 19:19:29.038382 136314624493056 run.py:748] Algo activity_selector step 7050 current loss 0.524492, current_train_items 194448.
I0126 19:19:29.217945 136314624493056 run.py:783] (val) algo activity_selector step 7050: {'selected': 0.9424860853432282, 'score': 0.9424860853432282, 'examples_seen': 194448, 'step': 7050, 'algorithm': 'activity_selector'}
I0126 19:19:29.218171 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0126 19:19:30.490437 136314624493056 run.py:748] Algo activity_selector step 7100 current loss 0.652137, current_train_items 195824.
I0126 19:19:30.682904 136314624493056 run.py:783] (val) algo activity_selector step 7100: {'selected': 0.9606003752345215, 'score': 0.9606003752345215, 'examples_seen': 195824, 'step': 7100, 'algorithm': 'activity_selector'}
I0126 19:19:30.683134 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0126 19:19:31.964324 136314624493056 run.py:748] Algo activity_selector step 7150 current loss 0.610556, current_train_items 197200.
I0126 19:19:32.143390 136314624493056 run.py:783] (val) algo activity_selector step 7150: {'selected': 0.9315589353612167, 'score': 0.9315589353612167, 'examples_seen': 197200, 'step': 7150, 'algorithm': 'activity_selector'}
I0126 19:19:32.143638 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0126 19:19:33.423329 136314624493056 run.py:748] Algo activity_selector step 7200 current loss 0.678484, current_train_items 198576.
I0126 19:19:33.615366 136314624493056 run.py:783] (val) algo activity_selector step 7200: {'selected': 0.963855421686747, 'score': 0.963855421686747, 'examples_seen': 198576, 'step': 7200, 'algorithm': 'activity_selector'}
I0126 19:19:33.615615 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0126 19:19:34.897507 136314624493056 run.py:748] Algo activity_selector step 7250 current loss 0.749844, current_train_items 199952.
I0126 19:19:35.080071 136314624493056 run.py:783] (val) algo activity_selector step 7250: {'selected': 0.9514170040485829, 'score': 0.9514170040485829, 'examples_seen': 199952, 'step': 7250, 'algorithm': 'activity_selector'}
I0126 19:19:35.080324 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0126 19:19:36.361953 136314624493056 run.py:748] Algo activity_selector step 7300 current loss 0.810788, current_train_items 201344.
I0126 19:19:36.542060 136314624493056 run.py:783] (val) algo activity_selector step 7300: {'selected': 0.9510763209393347, 'score': 0.9510763209393347, 'examples_seen': 201344, 'step': 7300, 'algorithm': 'activity_selector'}
I0126 19:19:36.542303 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0126 19:19:37.832296 136314624493056 run.py:748] Algo activity_selector step 7350 current loss 1.039413, current_train_items 202720.
I0126 19:19:38.016106 136314624493056 run.py:783] (val) algo activity_selector step 7350: {'selected': 0.9025423728813559, 'score': 0.9025423728813559, 'examples_seen': 202720, 'step': 7350, 'algorithm': 'activity_selector'}
I0126 19:19:38.016346 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.903, val scores are: activity_selector: 0.903
I0126 19:19:39.288739 136314624493056 run.py:748] Algo activity_selector step 7400 current loss 0.662365, current_train_items 204080.
I0126 19:19:39.481068 136314624493056 run.py:783] (val) algo activity_selector step 7400: {'selected': 0.9622266401590457, 'score': 0.9622266401590457, 'examples_seen': 204080, 'step': 7400, 'algorithm': 'activity_selector'}
I0126 19:19:39.481292 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0126 19:19:40.765331 136314624493056 run.py:748] Algo activity_selector step 7450 current loss 0.614238, current_train_items 205488.
I0126 19:19:40.944203 136314624493056 run.py:783] (val) algo activity_selector step 7450: {'selected': 0.9506398537477149, 'score': 0.9506398537477149, 'examples_seen': 205488, 'step': 7450, 'algorithm': 'activity_selector'}
I0126 19:19:40.944377 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0126 19:19:42.219943 136314624493056 run.py:748] Algo activity_selector step 7500 current loss 0.514647, current_train_items 206848.
I0126 19:19:42.401081 136314624493056 run.py:783] (val) algo activity_selector step 7500: {'selected': 0.9568627450980391, 'score': 0.9568627450980391, 'examples_seen': 206848, 'step': 7500, 'algorithm': 'activity_selector'}
I0126 19:19:42.401339 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0126 19:19:43.683210 136314624493056 run.py:748] Algo activity_selector step 7550 current loss 0.590342, current_train_items 208224.
I0126 19:19:43.862365 136314624493056 run.py:783] (val) algo activity_selector step 7550: {'selected': 0.9243353783231082, 'score': 0.9243353783231082, 'examples_seen': 208224, 'step': 7550, 'algorithm': 'activity_selector'}
I0126 19:19:43.862619 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0126 19:19:45.144540 136314624493056 run.py:748] Algo activity_selector step 7600 current loss 0.624532, current_train_items 209616.
I0126 19:19:45.325005 136314624493056 run.py:783] (val) algo activity_selector step 7600: {'selected': 0.9481481481481483, 'score': 0.9481481481481483, 'examples_seen': 209616, 'step': 7600, 'algorithm': 'activity_selector'}
I0126 19:19:45.325230 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0126 19:19:46.621152 136314624493056 run.py:748] Algo activity_selector step 7650 current loss 0.755023, current_train_items 210976.
I0126 19:19:46.800425 136314624493056 run.py:783] (val) algo activity_selector step 7650: {'selected': 0.9074074074074073, 'score': 0.9074074074074073, 'examples_seen': 210976, 'step': 7650, 'algorithm': 'activity_selector'}
I0126 19:19:46.800652 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0126 19:19:48.058074 136314624493056 run.py:748] Algo activity_selector step 7700 current loss 0.759865, current_train_items 212368.
I0126 19:19:48.262641 136314624493056 run.py:783] (val) algo activity_selector step 7700: {'selected': 0.9546351084812624, 'score': 0.9546351084812624, 'examples_seen': 212368, 'step': 7700, 'algorithm': 'activity_selector'}
I0126 19:19:48.262865 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0126 19:19:49.544922 136314624493056 run.py:748] Algo activity_selector step 7750 current loss 0.565030, current_train_items 213744.
I0126 19:19:49.723662 136314624493056 run.py:783] (val) algo activity_selector step 7750: {'selected': 0.9561904761904763, 'score': 0.9561904761904763, 'examples_seen': 213744, 'step': 7750, 'algorithm': 'activity_selector'}
I0126 19:19:49.723890 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0126 19:19:51.024853 136314624493056 run.py:748] Algo activity_selector step 7800 current loss 0.712705, current_train_items 215136.
I0126 19:19:51.204121 136314624493056 run.py:783] (val) algo activity_selector step 7800: {'selected': 0.928709055876686, 'score': 0.928709055876686, 'examples_seen': 215136, 'step': 7800, 'algorithm': 'activity_selector'}
I0126 19:19:51.204346 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0126 19:19:52.485877 136314624493056 run.py:748] Algo activity_selector step 7850 current loss 0.522838, current_train_items 216496.
I0126 19:19:52.665845 136314624493056 run.py:783] (val) algo activity_selector step 7850: {'selected': 0.9763779527559054, 'score': 0.9763779527559054, 'examples_seen': 216496, 'step': 7850, 'algorithm': 'activity_selector'}
I0126 19:19:52.666073 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0126 19:19:53.946131 136314624493056 run.py:748] Algo activity_selector step 7900 current loss 0.442078, current_train_items 217888.
I0126 19:19:54.127157 136314624493056 run.py:783] (val) algo activity_selector step 7900: {'selected': 0.9479553903345724, 'score': 0.9479553903345724, 'examples_seen': 217888, 'step': 7900, 'algorithm': 'activity_selector'}
I0126 19:19:54.127382 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0126 19:19:55.422297 136314624493056 run.py:748] Algo activity_selector step 7950 current loss 0.755970, current_train_items 219264.
I0126 19:19:55.601434 136314624493056 run.py:783] (val) algo activity_selector step 7950: {'selected': 0.946768060836502, 'score': 0.946768060836502, 'examples_seen': 219264, 'step': 7950, 'algorithm': 'activity_selector'}
I0126 19:19:55.601666 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0126 19:19:56.884648 136314624493056 run.py:748] Algo activity_selector step 8000 current loss 0.567207, current_train_items 220624.
I0126 19:19:57.064702 136314624493056 run.py:783] (val) algo activity_selector step 8000: {'selected': 0.9429657794676807, 'score': 0.9429657794676807, 'examples_seen': 220624, 'step': 8000, 'algorithm': 'activity_selector'}
I0126 19:19:57.064945 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.982, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0126 19:19:58.419494 136314624493056 run.py:748] Algo activity_selector step 8050 current loss 0.539964, current_train_items 222032.
I0126 19:19:58.585618 136314624493056 run.py:783] (val) algo activity_selector step 8050: {'selected': 0.9459459459459459, 'score': 0.9459459459459459, 'examples_seen': 222032, 'step': 8050, 'algorithm': 'activity_selector'}
I0126 19:19:58.585843 136314624493056 run.py:804] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0126 19:20:00.034214 136314624493056 run.py:748] Algo activity_selector step 8100 current loss 0.624292, current_train_items 223392.
I0126 19:20:00.216167 136314624493056 run.py:783] (val) algo activity_selector step 8100: {'selected': 0.9724409448818899, 'score': 0.9724409448818899, 'examples_seen': 223392, 'step': 8100, 'algorithm': 'activity_selector'}
I0126 19:20:00.216393 136314624493056 run.py:804] Checkpointing best model, best avg val score was 0.946, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0126 19:20:01.656814 136314624493056 run.py:748] Algo activity_selector step 8150 current loss 0.445833, current_train_items 224784.
I0126 19:20:01.839009 136314624493056 run.py:783] (val) algo activity_selector step 8150: {'selected': 0.9498069498069499, 'score': 0.9498069498069499, 'examples_seen': 224784, 'step': 8150, 'algorithm': 'activity_selector'}
I0126 19:20:01.839234 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0126 19:20:03.121465 136314624493056 run.py:748] Algo activity_selector step 8200 current loss 0.649460, current_train_items 226160.
I0126 19:20:03.302494 136314624493056 run.py:783] (val) algo activity_selector step 8200: {'selected': 0.9107142857142857, 'score': 0.9107142857142857, 'examples_seen': 226160, 'step': 8200, 'algorithm': 'activity_selector'}
I0126 19:20:03.302716 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0126 19:20:04.594841 136314624493056 run.py:748] Algo activity_selector step 8250 current loss 0.585314, current_train_items 227520.
I0126 19:20:04.774397 136314624493056 run.py:783] (val) algo activity_selector step 8250: {'selected': 0.9498069498069497, 'score': 0.9498069498069497, 'examples_seen': 227520, 'step': 8250, 'algorithm': 'activity_selector'}
I0126 19:20:04.774647 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0126 19:20:06.033993 136314624493056 run.py:748] Algo activity_selector step 8300 current loss 0.663536, current_train_items 228912.
I0126 19:20:06.240567 136314624493056 run.py:783] (val) algo activity_selector step 8300: {'selected': 0.9610894941634242, 'score': 0.9610894941634242, 'examples_seen': 228912, 'step': 8300, 'algorithm': 'activity_selector'}
I0126 19:20:06.240795 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0126 19:20:07.523063 136314624493056 run.py:748] Algo activity_selector step 8350 current loss 0.728755, current_train_items 230288.
I0126 19:20:07.703862 136314624493056 run.py:783] (val) algo activity_selector step 8350: {'selected': 0.9506398537477149, 'score': 0.9506398537477149, 'examples_seen': 230288, 'step': 8350, 'algorithm': 'activity_selector'}
I0126 19:20:07.704089 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0126 19:20:08.997014 136314624493056 run.py:748] Algo activity_selector step 8400 current loss 0.539492, current_train_items 231680.
I0126 19:20:09.177983 136314624493056 run.py:783] (val) algo activity_selector step 8400: {'selected': 0.9431818181818182, 'score': 0.9431818181818182, 'examples_seen': 231680, 'step': 8400, 'algorithm': 'activity_selector'}
I0126 19:20:09.178248 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0126 19:20:10.435134 136314624493056 run.py:748] Algo activity_selector step 8450 current loss 0.646138, current_train_items 233040.
I0126 19:20:10.639479 136314624493056 run.py:783] (val) algo activity_selector step 8450: {'selected': 0.9510763209393347, 'score': 0.9510763209393347, 'examples_seen': 233040, 'step': 8450, 'algorithm': 'activity_selector'}
I0126 19:20:10.639704 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0126 19:20:11.923783 136314624493056 run.py:748] Algo activity_selector step 8500 current loss 0.626468, current_train_items 234432.
I0126 19:20:12.104001 136314624493056 run.py:783] (val) algo activity_selector step 8500: {'selected': 0.9536679536679536, 'score': 0.9536679536679536, 'examples_seen': 234432, 'step': 8500, 'algorithm': 'activity_selector'}
I0126 19:20:12.104226 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0126 19:20:13.396417 136314624493056 run.py:748] Algo activity_selector step 8550 current loss 0.629248, current_train_items 235808.
I0126 19:20:13.578488 136314624493056 run.py:783] (val) algo activity_selector step 8550: {'selected': 0.9510763209393346, 'score': 0.9510763209393346, 'examples_seen': 235808, 'step': 8550, 'algorithm': 'activity_selector'}
I0126 19:20:13.578725 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0126 19:20:14.864600 136314624493056 run.py:748] Algo activity_selector step 8600 current loss 0.428541, current_train_items 237168.
I0126 19:20:15.041287 136314624493056 run.py:783] (val) algo activity_selector step 8600: {'selected': 0.9540918163672655, 'score': 0.9540918163672655, 'examples_seen': 237168, 'step': 8600, 'algorithm': 'activity_selector'}
I0126 19:20:15.041545 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0126 19:20:16.312022 136314624493056 run.py:748] Algo activity_selector step 8650 current loss 0.597704, current_train_items 238576.
I0126 19:20:16.506737 136314624493056 run.py:783] (val) algo activity_selector step 8650: {'selected': 0.937142857142857, 'score': 0.937142857142857, 'examples_seen': 238576, 'step': 8650, 'algorithm': 'activity_selector'}
I0126 19:20:16.507010 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0126 19:20:17.799058 136314624493056 run.py:748] Algo activity_selector step 8700 current loss 0.621646, current_train_items 239936.
I0126 19:20:17.980637 136314624493056 run.py:783] (val) algo activity_selector step 8700: {'selected': 0.9269230769230768, 'score': 0.9269230769230768, 'examples_seen': 239936, 'step': 8700, 'algorithm': 'activity_selector'}
I0126 19:20:17.980860 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0126 19:20:19.260662 136314624493056 run.py:748] Algo activity_selector step 8750 current loss 0.546072, current_train_items 241328.
I0126 19:20:19.442284 136314624493056 run.py:783] (val) algo activity_selector step 8750: {'selected': 0.9562043795620438, 'score': 0.9562043795620438, 'examples_seen': 241328, 'step': 8750, 'algorithm': 'activity_selector'}
I0126 19:20:19.442529 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0126 19:20:20.724115 136314624493056 run.py:748] Algo activity_selector step 8800 current loss 0.518240, current_train_items 242704.
I0126 19:20:20.909935 136314624493056 run.py:783] (val) algo activity_selector step 8800: {'selected': 0.9490196078431372, 'score': 0.9490196078431372, 'examples_seen': 242704, 'step': 8800, 'algorithm': 'activity_selector'}
I0126 19:20:20.910200 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0126 19:20:22.204947 136314624493056 run.py:748] Algo activity_selector step 8850 current loss 0.783918, current_train_items 244080.
I0126 19:20:22.385894 136314624493056 run.py:783] (val) algo activity_selector step 8850: {'selected': 0.9375, 'score': 0.9375, 'examples_seen': 244080, 'step': 8850, 'algorithm': 'activity_selector'}
I0126 19:20:22.386119 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0126 19:20:23.682488 136314624493056 run.py:748] Algo activity_selector step 8900 current loss 0.658401, current_train_items 245456.
I0126 19:20:23.850527 136314624493056 run.py:783] (val) algo activity_selector step 8900: {'selected': 0.923076923076923, 'score': 0.923076923076923, 'examples_seen': 245456, 'step': 8900, 'algorithm': 'activity_selector'}
I0126 19:20:23.850751 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.923, val scores are: activity_selector: 0.923
I0126 19:20:25.131380 136314624493056 run.py:748] Algo activity_selector step 8950 current loss 0.589017, current_train_items 246832.
I0126 19:20:25.311860 136314624493056 run.py:783] (val) algo activity_selector step 8950: {'selected': 0.9453125, 'score': 0.9453125, 'examples_seen': 246832, 'step': 8950, 'algorithm': 'activity_selector'}
I0126 19:20:25.312083 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0126 19:20:26.603932 136314624493056 run.py:748] Algo activity_selector step 9000 current loss 0.742960, current_train_items 248224.
I0126 19:20:26.787398 136314624493056 run.py:783] (val) algo activity_selector step 9000: {'selected': 0.9455909943714822, 'score': 0.9455909943714822, 'examples_seen': 248224, 'step': 9000, 'algorithm': 'activity_selector'}
I0126 19:20:26.787642 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0126 19:20:28.070235 136314624493056 run.py:748] Algo activity_selector step 9050 current loss 0.654401, current_train_items 249584.
I0126 19:20:28.250193 136314624493056 run.py:783] (val) algo activity_selector step 9050: {'selected': 0.9676190476190476, 'score': 0.9676190476190476, 'examples_seen': 249584, 'step': 9050, 'algorithm': 'activity_selector'}
I0126 19:20:28.250439 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0126 19:20:29.531314 136314624493056 run.py:748] Algo activity_selector step 9100 current loss 0.818484, current_train_items 250976.
I0126 19:20:29.712465 136314624493056 run.py:783] (val) algo activity_selector step 9100: {'selected': 0.9398496240601504, 'score': 0.9398496240601504, 'examples_seen': 250976, 'step': 9100, 'algorithm': 'activity_selector'}
I0126 19:20:29.712706 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0126 19:20:30.992043 136314624493056 run.py:748] Algo activity_selector step 9150 current loss 0.588401, current_train_items 252352.
I0126 19:20:31.183658 136314624493056 run.py:783] (val) algo activity_selector step 9150: {'selected': 0.9420560747663552, 'score': 0.9420560747663552, 'examples_seen': 252352, 'step': 9150, 'algorithm': 'activity_selector'}
I0126 19:20:31.183884 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0126 19:20:32.466970 136314624493056 run.py:748] Algo activity_selector step 9200 current loss 0.526096, current_train_items 253728.
I0126 19:20:32.648139 136314624493056 run.py:783] (val) algo activity_selector step 9200: {'selected': 0.9355432780847146, 'score': 0.9355432780847146, 'examples_seen': 253728, 'step': 9200, 'algorithm': 'activity_selector'}
I0126 19:20:32.648366 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0126 19:20:33.945057 136314624493056 run.py:748] Algo activity_selector step 9250 current loss 0.592964, current_train_items 255120.
I0126 19:20:34.108929 136314624493056 run.py:783] (val) algo activity_selector step 9250: {'selected': 0.9529190207156308, 'score': 0.9529190207156308, 'examples_seen': 255120, 'step': 9250, 'algorithm': 'activity_selector'}
I0126 19:20:34.109152 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0126 19:20:35.399646 136314624493056 run.py:748] Algo activity_selector step 9300 current loss 0.797661, current_train_items 256480.
I0126 19:20:35.582820 136314624493056 run.py:783] (val) algo activity_selector step 9300: {'selected': 0.9695817490494296, 'score': 0.9695817490494296, 'examples_seen': 256480, 'step': 9300, 'algorithm': 'activity_selector'}
I0126 19:20:35.583050 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0126 19:20:36.843330 136314624493056 run.py:748] Algo activity_selector step 9350 current loss 0.664139, current_train_items 257856.
I0126 19:20:37.046577 136314624493056 run.py:783] (val) algo activity_selector step 9350: {'selected': 0.9651376146788991, 'score': 0.9651376146788991, 'examples_seen': 257856, 'step': 9350, 'algorithm': 'activity_selector'}
I0126 19:20:37.046808 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0126 19:20:38.304433 136314624493056 run.py:748] Algo activity_selector step 9400 current loss 0.581418, current_train_items 259248.
I0126 19:20:38.510599 136314624493056 run.py:783] (val) algo activity_selector step 9400: {'selected': 0.9481481481481481, 'score': 0.9481481481481481, 'examples_seen': 259248, 'step': 9400, 'algorithm': 'activity_selector'}
I0126 19:20:38.510846 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0126 19:20:39.842222 136314624493056 run.py:748] Algo activity_selector step 9450 current loss 0.489106, current_train_items 260624.
I0126 19:20:40.022630 136314624493056 run.py:783] (val) algo activity_selector step 9450: {'selected': 0.9588477366255144, 'score': 0.9588477366255144, 'examples_seen': 260624, 'step': 9450, 'algorithm': 'activity_selector'}
I0126 19:20:40.022856 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0126 19:20:41.300669 136314624493056 run.py:748] Algo activity_selector step 9500 current loss 0.607160, current_train_items 262000.
I0126 19:20:41.480155 136314624493056 run.py:783] (val) algo activity_selector step 9500: {'selected': 0.9128014842300556, 'score': 0.9128014842300556, 'examples_seen': 262000, 'step': 9500, 'algorithm': 'activity_selector'}
I0126 19:20:41.480387 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0126 19:20:42.746453 136314624493056 run.py:748] Algo activity_selector step 9550 current loss 0.409215, current_train_items 263392.
I0126 19:20:42.951096 136314624493056 run.py:783] (val) algo activity_selector step 9550: {'selected': 0.9652351738241308, 'score': 0.9652351738241308, 'examples_seen': 263392, 'step': 9550, 'algorithm': 'activity_selector'}
I0126 19:20:42.951345 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0126 19:20:44.247930 136314624493056 run.py:748] Algo activity_selector step 9600 current loss 0.687797, current_train_items 264768.
I0126 19:20:44.433460 136314624493056 run.py:783] (val) algo activity_selector step 9600: {'selected': 0.9634146341463415, 'score': 0.9634146341463415, 'examples_seen': 264768, 'step': 9600, 'algorithm': 'activity_selector'}
I0126 19:20:44.433687 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0126 19:20:45.700419 136314624493056 run.py:748] Algo activity_selector step 9650 current loss 0.503658, current_train_items 266128.
I0126 19:20:45.910189 136314624493056 run.py:783] (val) algo activity_selector step 9650: {'selected': 0.9433962264150944, 'score': 0.9433962264150944, 'examples_seen': 266128, 'step': 9650, 'algorithm': 'activity_selector'}
I0126 19:20:45.910495 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0126 19:20:47.199423 136314624493056 run.py:748] Algo activity_selector step 9700 current loss 0.460807, current_train_items 267520.
I0126 19:20:47.378929 136314624493056 run.py:783] (val) algo activity_selector step 9700: {'selected': 0.9598470363288719, 'score': 0.9598470363288719, 'examples_seen': 267520, 'step': 9700, 'algorithm': 'activity_selector'}
I0126 19:20:47.379158 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0126 19:20:48.686953 136314624493056 run.py:748] Algo activity_selector step 9750 current loss 0.696151, current_train_items 268896.
I0126 19:20:48.865129 136314624493056 run.py:783] (val) algo activity_selector step 9750: {'selected': 0.9254302103250478, 'score': 0.9254302103250478, 'examples_seen': 268896, 'step': 9750, 'algorithm': 'activity_selector'}
I0126 19:20:48.865359 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0126 19:20:50.142822 136314624493056 run.py:748] Algo activity_selector step 9800 current loss 0.916577, current_train_items 270272.
I0126 19:20:50.333894 136314624493056 run.py:783] (val) algo activity_selector step 9800: {'selected': 0.9486166007905138, 'score': 0.9486166007905138, 'examples_seen': 270272, 'step': 9800, 'algorithm': 'activity_selector'}
I0126 19:20:50.334116 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0126 19:20:51.620479 136314624493056 run.py:748] Algo activity_selector step 9850 current loss 0.444041, current_train_items 271664.
I0126 19:20:51.800044 136314624493056 run.py:783] (val) algo activity_selector step 9850: {'selected': 0.9426987060998151, 'score': 0.9426987060998151, 'examples_seen': 271664, 'step': 9850, 'algorithm': 'activity_selector'}
I0126 19:20:51.800229 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0126 19:20:53.093839 136314624493056 run.py:748] Algo activity_selector step 9900 current loss 0.498364, current_train_items 273040.
I0126 19:20:53.274188 136314624493056 run.py:783] (val) algo activity_selector step 9900: {'selected': 0.9457364341085271, 'score': 0.9457364341085271, 'examples_seen': 273040, 'step': 9900, 'algorithm': 'activity_selector'}
I0126 19:20:53.274427 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0126 19:20:54.561203 136314624493056 run.py:748] Algo activity_selector step 9950 current loss 0.457386, current_train_items 274400.
I0126 19:20:54.739718 136314624493056 run.py:783] (val) algo activity_selector step 9950: {'selected': 0.9621212121212122, 'score': 0.9621212121212122, 'examples_seen': 274400, 'step': 9950, 'algorithm': 'activity_selector'}
I0126 19:20:54.739947 136314624493056 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0126 19:20:55.996362 136314624493056 run.py:813] Restoring best model from checkpoint...
I0126 19:21:06.635548 136314624493056 run.py:828] (test) algo activity_selector : {'selected': 0.856637168141593, 'score': 0.856637168141593, 'examples_seen': 275760, 'step': 10000, 'algorithm': 'activity_selector'}
I0126 19:21:06.635698 136314624493056 run.py:830] Done!
