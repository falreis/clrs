I0714 12:02:27.875879 132935198687872 xla_bridge.py:924] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0714 12:02:27.897640 132935198687872 xla_bridge.py:924] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0714 12:02:28.999839 132935198687872 run.py:415] Model: falreis ['activity_selector']
I0714 12:02:28.999993 132935198687872 run.py:417] algorithms ['activity_selector']
I0714 12:02:29.000312 132935198687872 run.py:418] train_lengths ['2', '3', '5', '7', '11', '13', '16']
I0714 12:02:29.000398 132935198687872 run.py:419] train_batch_size 16
I0714 12:02:29.000629 132935198687872 run.py:420] val_batch_size 8
I0714 12:02:29.000678 132935198687872 run.py:421] test_batch_size 8
I0714 12:02:29.000736 132935198687872 run.py:422] chunked_training True
I0714 12:02:29.001115 132935198687872 run.py:423] chunk_length 16
I0714 12:02:29.001156 132935198687872 run.py:424] train_steps 10000
I0714 12:02:29.001191 132935198687872 run.py:425] eval_every 50
I0714 12:02:29.001224 132935198687872 run.py:426] test_every 500
I0714 12:02:29.001254 132935198687872 run.py:427] learning_rate 0.001
I0714 12:02:29.001445 132935198687872 run.py:428] grad_clip_max_norm 1.0
I0714 12:02:29.001479 132935198687872 run.py:429] dropout_prob 0.1
I0714 12:02:29.001532 132935198687872 run.py:430] hint_teacher_forcing 0.0
I0714 12:02:29.001565 132935198687872 run.py:431] hint_mode encoded_decoded
I0714 12:02:29.001722 132935198687872 run.py:432] hint_repred_mode hard_on_eval
I0714 12:02:29.001765 132935198687872 run.py:433] use_ln False
I0714 12:02:29.001800 132935198687872 run.py:434] use_lstm True
I0714 12:02:29.001832 132935198687872 run.py:435] nb_triplet_fts 8
I0714 12:02:29.001863 132935198687872 run.py:436] encoder_init xavier_on_scalars
I0714 12:02:29.001907 132935198687872 run.py:437] processor_type falreis
I0714 12:02:29.001937 132935198687872 run.py:438] checkpoint_path CLRS30
I0714 12:02:29.001965 132935198687872 run.py:439] dataset_path CLRS30
I0714 12:02:29.001994 132935198687872 run.py:440] freeze_processor False
I0714 12:02:29.002022 132935198687872 run.py:441] reduction min
I0714 12:02:29.002051 132935198687872 run.py:442] activation elu
I0714 12:02:29.002079 132935198687872 run.py:443] algorithm_models ['F1', 'F2']
I0714 12:02:29.002110 132935198687872 run.py:444] restore_model 
I0714 12:02:29.002139 132935198687872 run.py:445] gated True
I0714 12:02:29.002169 132935198687872 run.py:446] gated_activation sigmoid
I0714 12:02:29.004440 132935198687872 run.py:472] Creating samplers for algo activity_selector
W0714 12:02:29.004688 132935198687872 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0714 12:02:29.005050 132935198687872 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0714 12:02:29.208189 132935198687872 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0714 12:02:29.422548 132935198687872 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0714 12:02:29.671879 132935198687872 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0714 12:02:29.986163 132935198687872 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0714 12:02:30.324127 132935198687872 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0714 12:02:30.711480 132935198687872 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0714 12:02:31.198324 132935198687872 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0714 12:02:31.198797 132935198687872 samplers.py:124] Creating a dataset with 64 samples.
I0714 12:02:31.234969 132935198687872 run.py:261] Dataset not found in CLRS30/CLRS30_v1.0.0. Downloading...
I0714 12:02:58.052749 132935198687872 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0714 12:02:58.055722 132935198687872 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0714 12:02:58.066221 132935198687872 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0714 12:02:58.168179 132935198687872 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0714 12:03:40.880820 132935198687872 run.py:687] Algo activity_selector step 0 current loss 3.776386, current_train_items 64.
I0714 12:03:42.212728 132935198687872 run.py:722] (val) algo activity_selector step 0: {'selected': 0.27677725118483415, 'score': 0.27677725118483415, 'examples_seen': 64, 'step': 0, 'algorithm': 'activity_selector'}
I0714 12:03:42.212985 132935198687872 run.py:743] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.277, val scores are: activity_selector: 0.277
I0714 12:04:36.553034 132935198687872 run.py:687] Algo activity_selector step 50 current loss 3.564515, current_train_items 2080.
I0714 12:04:36.597139 132935198687872 run.py:722] (val) algo activity_selector step 50: {'selected': 0.6702127659574468, 'score': 0.6702127659574468, 'examples_seen': 2080, 'step': 50, 'algorithm': 'activity_selector'}
I0714 12:04:36.597412 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.277, current avg val score is 0.670, val scores are: activity_selector: 0.670
I0714 12:04:38.439504 132935198687872 run.py:687] Algo activity_selector step 100 current loss 3.180802, current_train_items 4064.
I0714 12:04:38.533804 132935198687872 run.py:722] (val) algo activity_selector step 100: {'selected': 0.6488011283497884, 'score': 0.6488011283497884, 'examples_seen': 4064, 'step': 100, 'algorithm': 'activity_selector'}
I0714 12:04:38.534055 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.670, current avg val score is 0.649, val scores are: activity_selector: 0.649
I0714 12:04:40.235079 132935198687872 run.py:687] Algo activity_selector step 150 current loss 4.217081, current_train_items 6016.
I0714 12:04:40.284244 132935198687872 run.py:722] (val) algo activity_selector step 150: {'selected': 0.6730245231607629, 'score': 0.6730245231607629, 'examples_seen': 6016, 'step': 150, 'algorithm': 'activity_selector'}
I0714 12:04:40.284492 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.670, current avg val score is 0.673, val scores are: activity_selector: 0.673
I0714 12:04:41.604862 132935198687872 run.py:687] Algo activity_selector step 200 current loss 4.030929, current_train_items 8016.
I0714 12:04:41.657846 132935198687872 run.py:722] (val) algo activity_selector step 200: {'selected': 0.7188755020080321, 'score': 0.7188755020080321, 'examples_seen': 8016, 'step': 200, 'algorithm': 'activity_selector'}
I0714 12:04:41.658053 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.673, current avg val score is 0.719, val scores are: activity_selector: 0.719
I0714 12:04:43.063960 132935198687872 run.py:687] Algo activity_selector step 250 current loss 4.296281, current_train_items 9952.
I0714 12:04:43.121082 132935198687872 run.py:722] (val) algo activity_selector step 250: {'selected': 0.6974169741697417, 'score': 0.6974169741697417, 'examples_seen': 9952, 'step': 250, 'algorithm': 'activity_selector'}
I0714 12:04:43.121282 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.719, current avg val score is 0.697, val scores are: activity_selector: 0.697
I0714 12:04:44.431778 132935198687872 run.py:687] Algo activity_selector step 300 current loss 1.763272, current_train_items 12000.
I0714 12:04:44.477710 132935198687872 run.py:722] (val) algo activity_selector step 300: {'selected': 0.6630434782608696, 'score': 0.6630434782608696, 'examples_seen': 12000, 'step': 300, 'algorithm': 'activity_selector'}
I0714 12:04:44.477949 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.719, current avg val score is 0.663, val scores are: activity_selector: 0.663
I0714 12:04:45.797936 132935198687872 run.py:687] Algo activity_selector step 350 current loss 1.372871, current_train_items 14032.
I0714 12:04:45.841251 132935198687872 run.py:722] (val) algo activity_selector step 350: {'selected': 0.776595744680851, 'score': 0.776595744680851, 'examples_seen': 14032, 'step': 350, 'algorithm': 'activity_selector'}
I0714 12:04:45.841515 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.719, current avg val score is 0.777, val scores are: activity_selector: 0.777
I0714 12:04:47.198447 132935198687872 run.py:687] Algo activity_selector step 400 current loss 2.195399, current_train_items 16000.
I0714 12:04:47.241674 132935198687872 run.py:722] (val) algo activity_selector step 400: {'selected': 0.7664473684210528, 'score': 0.7664473684210528, 'examples_seen': 16000, 'step': 400, 'algorithm': 'activity_selector'}
I0714 12:04:47.241888 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.777, current avg val score is 0.766, val scores are: activity_selector: 0.766
I0714 12:04:48.504884 132935198687872 run.py:687] Algo activity_selector step 450 current loss 1.657233, current_train_items 18000.
I0714 12:04:48.552083 132935198687872 run.py:722] (val) algo activity_selector step 450: {'selected': 0.7754318618042226, 'score': 0.7754318618042226, 'examples_seen': 18000, 'step': 450, 'algorithm': 'activity_selector'}
I0714 12:04:48.552289 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.777, current avg val score is 0.775, val scores are: activity_selector: 0.775
I0714 12:04:50.158569 132935198687872 run.py:687] Algo activity_selector step 500 current loss 1.763084, current_train_items 19952.
I0714 12:04:50.262231 132935198687872 run.py:722] (val) algo activity_selector step 500: {'selected': 0.8202614379084969, 'score': 0.8202614379084969, 'examples_seen': 19952, 'step': 500, 'algorithm': 'activity_selector'}
I0714 12:04:50.262519 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.777, current avg val score is 0.820, val scores are: activity_selector: 0.820
I0714 12:04:52.169435 132935198687872 run.py:687] Algo activity_selector step 550 current loss 3.266844, current_train_items 21920.
I0714 12:04:52.227008 132935198687872 run.py:722] (val) algo activity_selector step 550: {'selected': 0.8327759197324415, 'score': 0.8327759197324415, 'examples_seen': 21920, 'step': 550, 'algorithm': 'activity_selector'}
I0714 12:04:52.227209 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.820, current avg val score is 0.833, val scores are: activity_selector: 0.833
I0714 12:04:53.520387 132935198687872 run.py:687] Algo activity_selector step 600 current loss 3.359655, current_train_items 23904.
I0714 12:04:53.581844 132935198687872 run.py:722] (val) algo activity_selector step 600: {'selected': 0.8571428571428572, 'score': 0.8571428571428572, 'examples_seen': 23904, 'step': 600, 'algorithm': 'activity_selector'}
I0714 12:04:53.582056 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.833, current avg val score is 0.857, val scores are: activity_selector: 0.857
I0714 12:04:54.909122 132935198687872 run.py:687] Algo activity_selector step 650 current loss 0.963891, current_train_items 25920.
I0714 12:04:54.951725 132935198687872 run.py:722] (val) algo activity_selector step 650: {'selected': 0.8424778761061946, 'score': 0.8424778761061946, 'examples_seen': 25920, 'step': 650, 'algorithm': 'activity_selector'}
I0714 12:04:54.951914 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.857, current avg val score is 0.842, val scores are: activity_selector: 0.842
I0714 12:04:56.257439 132935198687872 run.py:687] Algo activity_selector step 700 current loss 0.675808, current_train_items 27952.
I0714 12:04:56.301960 132935198687872 run.py:722] (val) algo activity_selector step 700: {'selected': 0.8475836431226766, 'score': 0.8475836431226766, 'examples_seen': 27952, 'step': 700, 'algorithm': 'activity_selector'}
I0714 12:04:56.302172 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.857, current avg val score is 0.848, val scores are: activity_selector: 0.848
I0714 12:04:57.583981 132935198687872 run.py:687] Algo activity_selector step 750 current loss 0.950376, current_train_items 29936.
I0714 12:04:57.649194 132935198687872 run.py:722] (val) algo activity_selector step 750: {'selected': 0.8500881834215167, 'score': 0.8500881834215167, 'examples_seen': 29936, 'step': 750, 'algorithm': 'activity_selector'}
I0714 12:04:57.649523 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.857, current avg val score is 0.850, val scores are: activity_selector: 0.850
I0714 12:04:59.032542 132935198687872 run.py:687] Algo activity_selector step 800 current loss 0.784030, current_train_items 31920.
I0714 12:04:59.082530 132935198687872 run.py:722] (val) algo activity_selector step 800: {'selected': 0.7993079584775087, 'score': 0.7993079584775087, 'examples_seen': 31920, 'step': 800, 'algorithm': 'activity_selector'}
I0714 12:04:59.082730 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.857, current avg val score is 0.799, val scores are: activity_selector: 0.799
I0714 12:05:00.396292 132935198687872 run.py:687] Algo activity_selector step 850 current loss 2.330511, current_train_items 33904.
I0714 12:05:00.445543 132935198687872 run.py:722] (val) algo activity_selector step 850: {'selected': 0.8640973630831643, 'score': 0.8640973630831643, 'examples_seen': 33904, 'step': 850, 'algorithm': 'activity_selector'}
I0714 12:05:00.445740 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.857, current avg val score is 0.864, val scores are: activity_selector: 0.864
I0714 12:05:01.891786 132935198687872 run.py:687] Algo activity_selector step 900 current loss 2.591058, current_train_items 35856.
I0714 12:05:02.001818 132935198687872 run.py:722] (val) algo activity_selector step 900: {'selected': 0.887719298245614, 'score': 0.887719298245614, 'examples_seen': 35856, 'step': 900, 'algorithm': 'activity_selector'}
I0714 12:05:02.002074 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.864, current avg val score is 0.888, val scores are: activity_selector: 0.888
I0714 12:05:04.119719 132935198687872 run.py:687] Algo activity_selector step 950 current loss 1.571556, current_train_items 37808.
I0714 12:05:04.182588 132935198687872 run.py:722] (val) algo activity_selector step 950: {'selected': 0.8759124087591241, 'score': 0.8759124087591241, 'examples_seen': 37808, 'step': 950, 'algorithm': 'activity_selector'}
I0714 12:05:04.182780 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.888, current avg val score is 0.876, val scores are: activity_selector: 0.876
I0714 12:05:05.496099 132935198687872 run.py:687] Algo activity_selector step 1000 current loss 0.267266, current_train_items 39872.
I0714 12:05:05.536275 132935198687872 run.py:722] (val) algo activity_selector step 1000: {'selected': 0.852575488454707, 'score': 0.852575488454707, 'examples_seen': 39872, 'step': 1000, 'algorithm': 'activity_selector'}
I0714 12:05:05.536516 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.888, current avg val score is 0.853, val scores are: activity_selector: 0.853
I0714 12:05:06.851912 132935198687872 run.py:687] Algo activity_selector step 1050 current loss 0.484147, current_train_items 41872.
I0714 12:05:06.894982 132935198687872 run.py:722] (val) algo activity_selector step 1050: {'selected': 0.8933092224231465, 'score': 0.8933092224231465, 'examples_seen': 41872, 'step': 1050, 'algorithm': 'activity_selector'}
I0714 12:05:06.895241 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.888, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0714 12:05:08.237280 132935198687872 run.py:687] Algo activity_selector step 1100 current loss 1.512084, current_train_items 43872.
I0714 12:05:08.282801 132935198687872 run.py:722] (val) algo activity_selector step 1100: {'selected': 0.9058823529411764, 'score': 0.9058823529411764, 'examples_seen': 43872, 'step': 1100, 'algorithm': 'activity_selector'}
I0714 12:05:08.283009 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.893, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0714 12:05:09.635776 132935198687872 run.py:687] Algo activity_selector step 1150 current loss 1.457164, current_train_items 45856.
I0714 12:05:09.679511 132935198687872 run.py:722] (val) algo activity_selector step 1150: {'selected': 0.8712522045855379, 'score': 0.8712522045855379, 'examples_seen': 45856, 'step': 1150, 'algorithm': 'activity_selector'}
I0714 12:05:09.679725 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.906, current avg val score is 0.871, val scores are: activity_selector: 0.871
I0714 12:05:10.976176 132935198687872 run.py:687] Algo activity_selector step 1200 current loss 2.281466, current_train_items 47808.
I0714 12:05:11.026797 132935198687872 run.py:722] (val) algo activity_selector step 1200: {'selected': 0.9056603773584906, 'score': 0.9056603773584906, 'examples_seen': 47808, 'step': 1200, 'algorithm': 'activity_selector'}
I0714 12:05:11.027024 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.906, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0714 12:05:12.348874 132935198687872 run.py:687] Algo activity_selector step 1250 current loss 2.013568, current_train_items 49808.
I0714 12:05:12.405551 132935198687872 run.py:722] (val) algo activity_selector step 1250: {'selected': 0.9320388349514563, 'score': 0.9320388349514563, 'examples_seen': 49808, 'step': 1250, 'algorithm': 'activity_selector'}
I0714 12:05:12.405758 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.906, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0714 12:05:13.759628 132935198687872 run.py:687] Algo activity_selector step 1300 current loss 5.394526, current_train_items 51760.
I0714 12:05:13.832567 132935198687872 run.py:722] (val) algo activity_selector step 1300: {'selected': 0.8976660682226212, 'score': 0.8976660682226212, 'examples_seen': 51760, 'step': 1300, 'algorithm': 'activity_selector'}
I0714 12:05:13.832773 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.932, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0714 12:05:15.983416 132935198687872 run.py:687] Algo activity_selector step 1350 current loss 0.564482, current_train_items 53792.
I0714 12:05:16.076864 132935198687872 run.py:722] (val) algo activity_selector step 1350: {'selected': 0.8928571428571428, 'score': 0.8928571428571428, 'examples_seen': 53792, 'step': 1350, 'algorithm': 'activity_selector'}
I0714 12:05:16.077101 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.932, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0714 12:05:17.484240 132935198687872 run.py:687] Algo activity_selector step 1400 current loss 0.342133, current_train_items 55824.
I0714 12:05:17.526412 132935198687872 run.py:722] (val) algo activity_selector step 1400: {'selected': 0.9328358208955223, 'score': 0.9328358208955223, 'examples_seen': 55824, 'step': 1400, 'algorithm': 'activity_selector'}
I0714 12:05:17.526638 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.932, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0714 12:05:18.844771 132935198687872 run.py:687] Algo activity_selector step 1450 current loss 1.288137, current_train_items 57792.
I0714 12:05:18.888590 132935198687872 run.py:722] (val) algo activity_selector step 1450: {'selected': 0.8290155440414508, 'score': 0.8290155440414508, 'examples_seen': 57792, 'step': 1450, 'algorithm': 'activity_selector'}
I0714 12:05:18.888806 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.933, current avg val score is 0.829, val scores are: activity_selector: 0.829
I0714 12:05:20.179835 132935198687872 run.py:687] Algo activity_selector step 1500 current loss 0.415385, current_train_items 59792.
I0714 12:05:20.223233 132935198687872 run.py:722] (val) algo activity_selector step 1500: {'selected': 0.9216757741347905, 'score': 0.9216757741347905, 'examples_seen': 59792, 'step': 1500, 'algorithm': 'activity_selector'}
I0714 12:05:20.223472 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.933, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0714 12:05:21.498455 132935198687872 run.py:687] Algo activity_selector step 1550 current loss 0.849489, current_train_items 61744.
I0714 12:05:21.547811 132935198687872 run.py:722] (val) algo activity_selector step 1550: {'selected': 0.9304174950298212, 'score': 0.9304174950298212, 'examples_seen': 61744, 'step': 1550, 'algorithm': 'activity_selector'}
I0714 12:05:21.548073 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.933, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0714 12:05:22.840373 132935198687872 run.py:687] Algo activity_selector step 1600 current loss 2.089458, current_train_items 63712.
I0714 12:05:22.892546 132935198687872 run.py:722] (val) algo activity_selector step 1600: {'selected': 0.9060773480662984, 'score': 0.9060773480662984, 'examples_seen': 63712, 'step': 1600, 'algorithm': 'activity_selector'}
I0714 12:05:22.892756 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.933, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0714 12:05:24.154547 132935198687872 run.py:687] Algo activity_selector step 1650 current loss 4.355936, current_train_items 65712.
I0714 12:05:24.215234 132935198687872 run.py:722] (val) algo activity_selector step 1650: {'selected': 0.8923076923076924, 'score': 0.8923076923076924, 'examples_seen': 65712, 'step': 1650, 'algorithm': 'activity_selector'}
I0714 12:05:24.215468 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.933, current avg val score is 0.892, val scores are: activity_selector: 0.892
I0714 12:05:25.474146 132935198687872 run.py:687] Algo activity_selector step 1700 current loss 0.421174, current_train_items 67712.
I0714 12:05:25.516967 132935198687872 run.py:722] (val) algo activity_selector step 1700: {'selected': 0.9310986964618251, 'score': 0.9310986964618251, 'examples_seen': 67712, 'step': 1700, 'algorithm': 'activity_selector'}
I0714 12:05:25.517194 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.933, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0714 12:05:27.094543 132935198687872 run.py:687] Algo activity_selector step 1750 current loss 0.337396, current_train_items 69744.
I0714 12:05:27.189755 132935198687872 run.py:722] (val) algo activity_selector step 1750: {'selected': 0.9155722326454033, 'score': 0.9155722326454033, 'examples_seen': 69744, 'step': 1750, 'algorithm': 'activity_selector'}
I0714 12:05:27.189985 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.933, current avg val score is 0.916, val scores are: activity_selector: 0.916
I0714 12:05:29.069413 132935198687872 run.py:687] Algo activity_selector step 1800 current loss 0.278725, current_train_items 71728.
I0714 12:05:29.115746 132935198687872 run.py:722] (val) algo activity_selector step 1800: {'selected': 0.9160583941605839, 'score': 0.9160583941605839, 'examples_seen': 71728, 'step': 1800, 'algorithm': 'activity_selector'}
I0714 12:05:29.115932 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.933, current avg val score is 0.916, val scores are: activity_selector: 0.916
I0714 12:05:30.413210 132935198687872 run.py:687] Algo activity_selector step 1850 current loss 0.466357, current_train_items 73712.
I0714 12:05:30.458630 132935198687872 run.py:722] (val) algo activity_selector step 1850: {'selected': 0.9432485322896281, 'score': 0.9432485322896281, 'examples_seen': 73712, 'step': 1850, 'algorithm': 'activity_selector'}
I0714 12:05:30.458845 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.933, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0714 12:05:31.743367 132935198687872 run.py:687] Algo activity_selector step 1900 current loss 1.852824, current_train_items 75712.
I0714 12:05:31.797053 132935198687872 run.py:722] (val) algo activity_selector step 1900: {'selected': 0.9440298507462686, 'score': 0.9440298507462686, 'examples_seen': 75712, 'step': 1900, 'algorithm': 'activity_selector'}
I0714 12:05:31.797250 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.943, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0714 12:05:33.109977 132935198687872 run.py:687] Algo activity_selector step 1950 current loss 1.872083, current_train_items 77664.
I0714 12:05:33.162248 132935198687872 run.py:722] (val) algo activity_selector step 1950: {'selected': 0.9335863377609108, 'score': 0.9335863377609108, 'examples_seen': 77664, 'step': 1950, 'algorithm': 'activity_selector'}
I0714 12:05:33.162505 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.944, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0714 12:05:34.441546 132935198687872 run.py:687] Algo activity_selector step 2000 current loss 3.977821, current_train_items 79632.
I0714 12:05:34.502499 132935198687872 run.py:722] (val) algo activity_selector step 2000: {'selected': 0.9314516129032258, 'score': 0.9314516129032258, 'examples_seen': 79632, 'step': 2000, 'algorithm': 'activity_selector'}
I0714 12:05:34.502705 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.944, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0714 12:05:35.810198 132935198687872 run.py:687] Algo activity_selector step 2050 current loss 0.264454, current_train_items 81680.
I0714 12:05:35.851765 132935198687872 run.py:722] (val) algo activity_selector step 2050: {'selected': 0.9313543599257884, 'score': 0.9313543599257884, 'examples_seen': 81680, 'step': 2050, 'algorithm': 'activity_selector'}
I0714 12:05:35.851948 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.944, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0714 12:05:37.110391 132935198687872 run.py:687] Algo activity_selector step 2100 current loss 0.277171, current_train_items 83680.
I0714 12:05:37.151027 132935198687872 run.py:722] (val) algo activity_selector step 2100: {'selected': 0.932806324110672, 'score': 0.932806324110672, 'examples_seen': 83680, 'step': 2100, 'algorithm': 'activity_selector'}
I0714 12:05:37.151283 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.944, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0714 12:05:38.433132 132935198687872 run.py:687] Algo activity_selector step 2150 current loss 1.200065, current_train_items 85680.
I0714 12:05:38.479179 132935198687872 run.py:722] (val) algo activity_selector step 2150: {'selected': 0.906930693069307, 'score': 0.906930693069307, 'examples_seen': 85680, 'step': 2150, 'algorithm': 'activity_selector'}
I0714 12:05:38.479431 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.944, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0714 12:05:40.617251 132935198687872 run.py:687] Algo activity_selector step 2200 current loss 0.635136, current_train_items 87664.
I0714 12:05:40.698165 132935198687872 run.py:722] (val) algo activity_selector step 2200: {'selected': 0.9295238095238096, 'score': 0.9295238095238096, 'examples_seen': 87664, 'step': 2200, 'algorithm': 'activity_selector'}
I0714 12:05:40.698485 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.944, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0714 12:05:42.016689 132935198687872 run.py:687] Algo activity_selector step 2250 current loss 2.374113, current_train_items 89632.
I0714 12:05:42.066221 132935198687872 run.py:722] (val) algo activity_selector step 2250: {'selected': 0.9354207436399217, 'score': 0.9354207436399217, 'examples_seen': 89632, 'step': 2250, 'algorithm': 'activity_selector'}
I0714 12:05:42.066441 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.944, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0714 12:05:43.329089 132935198687872 run.py:687] Algo activity_selector step 2300 current loss 0.399216, current_train_items 91616.
I0714 12:05:43.382864 132935198687872 run.py:722] (val) algo activity_selector step 2300: {'selected': 0.9502762430939227, 'score': 0.9502762430939227, 'examples_seen': 91616, 'step': 2300, 'algorithm': 'activity_selector'}
I0714 12:05:43.383076 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.944, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0714 12:05:44.665145 132935198687872 run.py:687] Algo activity_selector step 2350 current loss 3.303145, current_train_items 93568.
I0714 12:05:44.721771 132935198687872 run.py:722] (val) algo activity_selector step 2350: {'selected': 0.9371633752244166, 'score': 0.9371633752244166, 'examples_seen': 93568, 'step': 2350, 'algorithm': 'activity_selector'}
I0714 12:05:44.721976 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.950, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0714 12:05:45.999563 132935198687872 run.py:687] Algo activity_selector step 2400 current loss 0.436973, current_train_items 95600.
I0714 12:05:46.041090 132935198687872 run.py:722] (val) algo activity_selector step 2400: {'selected': 0.926829268292683, 'score': 0.926829268292683, 'examples_seen': 95600, 'step': 2400, 'algorithm': 'activity_selector'}
I0714 12:05:46.041273 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.950, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0714 12:05:47.324493 132935198687872 run.py:687] Algo activity_selector step 2450 current loss 0.154878, current_train_items 97632.
I0714 12:05:47.367840 132935198687872 run.py:722] (val) algo activity_selector step 2450: {'selected': 0.8702290076335878, 'score': 0.8702290076335878, 'examples_seen': 97632, 'step': 2450, 'algorithm': 'activity_selector'}
I0714 12:05:47.368028 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.950, current avg val score is 0.870, val scores are: activity_selector: 0.870
I0714 12:05:48.642220 132935198687872 run.py:687] Algo activity_selector step 2500 current loss 1.262928, current_train_items 99600.
I0714 12:05:48.687466 132935198687872 run.py:722] (val) algo activity_selector step 2500: {'selected': 0.9404517453798769, 'score': 0.9404517453798769, 'examples_seen': 99600, 'step': 2500, 'algorithm': 'activity_selector'}
I0714 12:05:48.687683 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.950, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0714 12:05:49.934103 132935198687872 run.py:687] Algo activity_selector step 2550 current loss 0.257718, current_train_items 101600.
I0714 12:05:49.977116 132935198687872 run.py:722] (val) algo activity_selector step 2550: {'selected': 0.9612403100775193, 'score': 0.9612403100775193, 'examples_seen': 101600, 'step': 2550, 'algorithm': 'activity_selector'}
I0714 12:05:49.977297 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.950, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0714 12:05:51.547097 132935198687872 run.py:687] Algo activity_selector step 2600 current loss 0.586416, current_train_items 103568.
I0714 12:05:51.616030 132935198687872 run.py:722] (val) algo activity_selector step 2600: {'selected': 0.9404990403071017, 'score': 0.9404990403071017, 'examples_seen': 103568, 'step': 2600, 'algorithm': 'activity_selector'}
I0714 12:05:51.616263 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.961, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0714 12:05:53.438397 132935198687872 run.py:687] Algo activity_selector step 2650 current loss 3.438538, current_train_items 105520.
I0714 12:05:53.492889 132935198687872 run.py:722] (val) algo activity_selector step 2650: {'selected': 0.9710144927536232, 'score': 0.9710144927536232, 'examples_seen': 105520, 'step': 2650, 'algorithm': 'activity_selector'}
I0714 12:05:53.493066 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.961, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0714 12:05:54.744825 132935198687872 run.py:687] Algo activity_selector step 2700 current loss 2.916255, current_train_items 107520.
I0714 12:05:54.804041 132935198687872 run.py:722] (val) algo activity_selector step 2700: {'selected': 0.9360902255639098, 'score': 0.9360902255639098, 'examples_seen': 107520, 'step': 2700, 'algorithm': 'activity_selector'}
I0714 12:05:54.804232 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.971, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0714 12:05:56.077615 132935198687872 run.py:687] Algo activity_selector step 2750 current loss 0.457928, current_train_items 109520.
I0714 12:05:56.119250 132935198687872 run.py:722] (val) algo activity_selector step 2750: {'selected': 0.9400386847195358, 'score': 0.9400386847195358, 'examples_seen': 109520, 'step': 2750, 'algorithm': 'activity_selector'}
I0714 12:05:56.119477 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.971, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0714 12:05:57.389419 132935198687872 run.py:687] Algo activity_selector step 2800 current loss 0.178049, current_train_items 111552.
I0714 12:05:57.430676 132935198687872 run.py:722] (val) algo activity_selector step 2800: {'selected': 0.9376181474480152, 'score': 0.9376181474480152, 'examples_seen': 111552, 'step': 2800, 'algorithm': 'activity_selector'}
I0714 12:05:57.430872 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.971, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0714 12:05:58.697212 132935198687872 run.py:687] Algo activity_selector step 2850 current loss 0.443461, current_train_items 113552.
I0714 12:05:58.739045 132935198687872 run.py:722] (val) algo activity_selector step 2850: {'selected': 0.9431818181818181, 'score': 0.9431818181818181, 'examples_seen': 113552, 'step': 2850, 'algorithm': 'activity_selector'}
I0714 12:05:58.739229 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.971, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0714 12:06:00.032076 132935198687872 run.py:687] Algo activity_selector step 2900 current loss 0.461829, current_train_items 115520.
I0714 12:06:00.097097 132935198687872 run.py:722] (val) algo activity_selector step 2900: {'selected': 0.9302325581395349, 'score': 0.9302325581395349, 'examples_seen': 115520, 'step': 2900, 'algorithm': 'activity_selector'}
I0714 12:06:00.097287 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.971, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0714 12:06:01.348601 132935198687872 run.py:687] Algo activity_selector step 2950 current loss 2.104002, current_train_items 117520.
I0714 12:06:01.398382 132935198687872 run.py:722] (val) algo activity_selector step 2950: {'selected': 0.9003984063745021, 'score': 0.9003984063745021, 'examples_seen': 117520, 'step': 2950, 'algorithm': 'activity_selector'}
I0714 12:06:01.398579 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.971, current avg val score is 0.900, val scores are: activity_selector: 0.900
I0714 12:06:02.648612 132935198687872 run.py:687] Algo activity_selector step 3000 current loss 2.491288, current_train_items 119456.
I0714 12:06:02.703034 132935198687872 run.py:722] (val) algo activity_selector step 3000: {'selected': 0.8929889298892988, 'score': 0.8929889298892988, 'examples_seen': 119456, 'step': 3000, 'algorithm': 'activity_selector'}
I0714 12:06:02.703222 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.971, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0714 12:06:04.640932 132935198687872 run.py:687] Algo activity_selector step 3050 current loss 2.995909, current_train_items 121424.
I0714 12:06:04.746209 132935198687872 run.py:722] (val) algo activity_selector step 3050: {'selected': 0.96875, 'score': 0.96875, 'examples_seen': 121424, 'step': 3050, 'algorithm': 'activity_selector'}
I0714 12:06:04.746478 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.971, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0714 12:06:06.221292 132935198687872 run.py:687] Algo activity_selector step 3100 current loss 0.198223, current_train_items 123472.
I0714 12:06:06.263359 132935198687872 run.py:722] (val) algo activity_selector step 3100: {'selected': 0.9527559055118111, 'score': 0.9527559055118111, 'examples_seen': 123472, 'step': 3100, 'algorithm': 'activity_selector'}
I0714 12:06:06.263567 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.971, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0714 12:06:07.555517 132935198687872 run.py:687] Algo activity_selector step 3150 current loss 0.511839, current_train_items 125472.
I0714 12:06:07.599947 132935198687872 run.py:722] (val) algo activity_selector step 3150: {'selected': 0.8843283582089552, 'score': 0.8843283582089552, 'examples_seen': 125472, 'step': 3150, 'algorithm': 'activity_selector'}
I0714 12:06:07.600163 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.971, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0714 12:06:08.901960 132935198687872 run.py:687] Algo activity_selector step 3200 current loss 1.218593, current_train_items 127488.
I0714 12:06:08.946641 132935198687872 run.py:722] (val) algo activity_selector step 3200: {'selected': 0.9655172413793103, 'score': 0.9655172413793103, 'examples_seen': 127488, 'step': 3200, 'algorithm': 'activity_selector'}
I0714 12:06:08.946857 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.971, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0714 12:06:10.265107 132935198687872 run.py:687] Algo activity_selector step 3250 current loss 0.388881, current_train_items 129456.
I0714 12:06:10.312165 132935198687872 run.py:722] (val) algo activity_selector step 3250: {'selected': 0.9222011385199241, 'score': 0.9222011385199241, 'examples_seen': 129456, 'step': 3250, 'algorithm': 'activity_selector'}
I0714 12:06:10.312370 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.971, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0714 12:06:11.596774 132935198687872 run.py:687] Algo activity_selector step 3300 current loss 1.887280, current_train_items 131424.
I0714 12:06:11.645918 132935198687872 run.py:722] (val) algo activity_selector step 3300: {'selected': 0.935064935064935, 'score': 0.935064935064935, 'examples_seen': 131424, 'step': 3300, 'algorithm': 'activity_selector'}
I0714 12:06:11.646114 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.971, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0714 12:06:12.945289 132935198687872 run.py:687] Algo activity_selector step 3350 current loss 2.351141, current_train_items 133408.
I0714 12:06:12.998051 132935198687872 run.py:722] (val) algo activity_selector step 3350: {'selected': 0.915129151291513, 'score': 0.915129151291513, 'examples_seen': 133408, 'step': 3350, 'algorithm': 'activity_selector'}
I0714 12:06:12.998275 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.971, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0714 12:06:14.312147 132935198687872 run.py:687] Algo activity_selector step 3400 current loss 2.402190, current_train_items 135360.
I0714 12:06:14.373815 132935198687872 run.py:722] (val) algo activity_selector step 3400: {'selected': 0.9672447013487475, 'score': 0.9672447013487475, 'examples_seen': 135360, 'step': 3400, 'algorithm': 'activity_selector'}
I0714 12:06:14.374019 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.971, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0714 12:06:15.958015 132935198687872 run.py:687] Algo activity_selector step 3450 current loss 0.414882, current_train_items 137392.
I0714 12:06:16.056148 132935198687872 run.py:722] (val) algo activity_selector step 3450: {'selected': 0.9351145038167938, 'score': 0.9351145038167938, 'examples_seen': 137392, 'step': 3450, 'algorithm': 'activity_selector'}
I0714 12:06:16.056397 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.971, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0714 12:06:17.887381 132935198687872 run.py:687] Algo activity_selector step 3500 current loss 0.066582, current_train_items 139424.
I0714 12:06:17.928460 132935198687872 run.py:722] (val) algo activity_selector step 3500: {'selected': 0.970178926441352, 'score': 0.970178926441352, 'examples_seen': 139424, 'step': 3500, 'algorithm': 'activity_selector'}
I0714 12:06:17.928644 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.971, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0714 12:06:19.305356 132935198687872 run.py:687] Algo activity_selector step 3550 current loss 1.089761, current_train_items 141408.
I0714 12:06:19.351090 132935198687872 run.py:722] (val) algo activity_selector step 3550: {'selected': 0.9514563106796117, 'score': 0.9514563106796117, 'examples_seen': 141408, 'step': 3550, 'algorithm': 'activity_selector'}
I0714 12:06:19.351334 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.971, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0714 12:06:20.655246 132935198687872 run.py:687] Algo activity_selector step 3600 current loss 0.384271, current_train_items 143392.
I0714 12:06:20.700144 132935198687872 run.py:722] (val) algo activity_selector step 3600: {'selected': 0.9732824427480916, 'score': 0.9732824427480916, 'examples_seen': 143392, 'step': 3600, 'algorithm': 'activity_selector'}
I0714 12:06:20.700393 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.971, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0714 12:06:21.963907 132935198687872 run.py:687] Algo activity_selector step 3650 current loss 0.637849, current_train_items 145360.
I0714 12:06:22.032366 132935198687872 run.py:722] (val) algo activity_selector step 3650: {'selected': 0.9520153550863724, 'score': 0.9520153550863724, 'examples_seen': 145360, 'step': 3650, 'algorithm': 'activity_selector'}
I0714 12:06:22.032577 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.973, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0714 12:06:23.260576 132935198687872 run.py:687] Algo activity_selector step 3700 current loss 2.028198, current_train_items 147312.
I0714 12:06:23.312804 132935198687872 run.py:722] (val) algo activity_selector step 3700: {'selected': 0.9431818181818182, 'score': 0.9431818181818182, 'examples_seen': 147312, 'step': 3700, 'algorithm': 'activity_selector'}
I0714 12:06:23.312986 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.973, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0714 12:06:24.553398 132935198687872 run.py:687] Algo activity_selector step 3750 current loss 2.224149, current_train_items 149312.
I0714 12:06:24.611151 132935198687872 run.py:722] (val) algo activity_selector step 3750: {'selected': 0.9358490566037736, 'score': 0.9358490566037736, 'examples_seen': 149312, 'step': 3750, 'algorithm': 'activity_selector'}
I0714 12:06:24.611364 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.973, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0714 12:06:25.900061 132935198687872 run.py:687] Algo activity_selector step 3800 current loss 0.461129, current_train_items 151328.
I0714 12:06:25.940241 132935198687872 run.py:722] (val) algo activity_selector step 3800: {'selected': 0.9163498098859315, 'score': 0.9163498098859315, 'examples_seen': 151328, 'step': 3800, 'algorithm': 'activity_selector'}
I0714 12:06:25.940475 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.973, current avg val score is 0.916, val scores are: activity_selector: 0.916
I0714 12:06:27.223252 132935198687872 run.py:687] Algo activity_selector step 3850 current loss 0.186886, current_train_items 153344.
I0714 12:06:27.267324 132935198687872 run.py:722] (val) algo activity_selector step 3850: {'selected': 0.952029520295203, 'score': 0.952029520295203, 'examples_seen': 153344, 'step': 3850, 'algorithm': 'activity_selector'}
I0714 12:06:27.267554 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.973, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0714 12:06:29.348255 132935198687872 run.py:687] Algo activity_selector step 3900 current loss 0.461534, current_train_items 155344.
I0714 12:06:29.419379 132935198687872 run.py:722] (val) algo activity_selector step 3900: {'selected': 0.9351145038167938, 'score': 0.9351145038167938, 'examples_seen': 155344, 'step': 3900, 'algorithm': 'activity_selector'}
I0714 12:06:29.419648 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.973, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0714 12:06:30.786249 132935198687872 run.py:687] Algo activity_selector step 3950 current loss 0.307445, current_train_items 157312.
I0714 12:06:30.829949 132935198687872 run.py:722] (val) algo activity_selector step 3950: {'selected': 0.9328358208955223, 'score': 0.9328358208955223, 'examples_seen': 157312, 'step': 3950, 'algorithm': 'activity_selector'}
I0714 12:06:30.830127 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.973, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0714 12:06:32.105315 132935198687872 run.py:687] Algo activity_selector step 4000 current loss 1.559566, current_train_items 159312.
I0714 12:06:32.153063 132935198687872 run.py:722] (val) algo activity_selector step 4000: {'selected': 0.9593810444874274, 'score': 0.9593810444874274, 'examples_seen': 159312, 'step': 4000, 'algorithm': 'activity_selector'}
I0714 12:06:32.153265 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.973, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0714 12:06:33.390536 132935198687872 run.py:687] Algo activity_selector step 4050 current loss 1.710391, current_train_items 161248.
I0714 12:06:33.448702 132935198687872 run.py:722] (val) algo activity_selector step 4050: {'selected': 0.9496981891348089, 'score': 0.9496981891348089, 'examples_seen': 161248, 'step': 4050, 'algorithm': 'activity_selector'}
I0714 12:06:33.448960 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.973, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0714 12:06:34.682641 132935198687872 run.py:687] Algo activity_selector step 4100 current loss 1.946718, current_train_items 163216.
I0714 12:06:34.742965 132935198687872 run.py:722] (val) algo activity_selector step 4100: {'selected': 0.9734848484848485, 'score': 0.9734848484848485, 'examples_seen': 163216, 'step': 4100, 'algorithm': 'activity_selector'}
I0714 12:06:34.743149 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.973, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0714 12:06:36.000611 132935198687872 run.py:687] Algo activity_selector step 4150 current loss 0.199538, current_train_items 165280.
I0714 12:06:36.044999 132935198687872 run.py:722] (val) algo activity_selector step 4150: {'selected': 0.9523809523809523, 'score': 0.9523809523809523, 'examples_seen': 165280, 'step': 4150, 'algorithm': 'activity_selector'}
I0714 12:06:36.045197 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.973, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0714 12:06:37.281618 132935198687872 run.py:687] Algo activity_selector step 4200 current loss 0.085079, current_train_items 167264.
I0714 12:06:37.324863 132935198687872 run.py:722] (val) algo activity_selector step 4200: {'selected': 0.9465648854961832, 'score': 0.9465648854961832, 'examples_seen': 167264, 'step': 4200, 'algorithm': 'activity_selector'}
I0714 12:06:37.325046 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.973, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0714 12:06:38.576294 132935198687872 run.py:687] Algo activity_selector step 4250 current loss 1.112398, current_train_items 169280.
I0714 12:06:38.628213 132935198687872 run.py:722] (val) algo activity_selector step 4250: {'selected': 0.9595375722543352, 'score': 0.9595375722543352, 'examples_seen': 169280, 'step': 4250, 'algorithm': 'activity_selector'}
I0714 12:06:38.628525 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.973, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0714 12:06:40.067896 132935198687872 run.py:687] Algo activity_selector step 4300 current loss 0.471782, current_train_items 171248.
I0714 12:06:40.152494 132935198687872 run.py:722] (val) algo activity_selector step 4300: {'selected': 0.9529190207156308, 'score': 0.9529190207156308, 'examples_seen': 171248, 'step': 4300, 'algorithm': 'activity_selector'}
I0714 12:06:40.152728 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.973, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0714 12:06:42.163952 132935198687872 run.py:687] Algo activity_selector step 4350 current loss 2.045868, current_train_items 173216.
I0714 12:06:42.216389 132935198687872 run.py:722] (val) algo activity_selector step 4350: {'selected': 0.9301397205588823, 'score': 0.9301397205588823, 'examples_seen': 173216, 'step': 4350, 'algorithm': 'activity_selector'}
I0714 12:06:42.216615 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.973, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0714 12:06:43.516045 132935198687872 run.py:687] Algo activity_selector step 4400 current loss 1.261300, current_train_items 175232.
I0714 12:06:43.568121 132935198687872 run.py:722] (val) algo activity_selector step 4400: {'selected': 0.9660678642714571, 'score': 0.9660678642714571, 'examples_seen': 175232, 'step': 4400, 'algorithm': 'activity_selector'}
I0714 12:06:43.568323 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.973, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0714 12:06:44.812834 132935198687872 run.py:687] Algo activity_selector step 4450 current loss 1.899914, current_train_items 177168.
I0714 12:06:44.871450 132935198687872 run.py:722] (val) algo activity_selector step 4450: {'selected': 0.9743589743589743, 'score': 0.9743589743589743, 'examples_seen': 177168, 'step': 4450, 'algorithm': 'activity_selector'}
I0714 12:06:44.871621 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.973, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0714 12:06:46.169317 132935198687872 run.py:687] Algo activity_selector step 4500 current loss 0.450088, current_train_items 179216.
I0714 12:06:46.209986 132935198687872 run.py:722] (val) algo activity_selector step 4500: {'selected': 0.9548133595284872, 'score': 0.9548133595284872, 'examples_seen': 179216, 'step': 4500, 'algorithm': 'activity_selector'}
I0714 12:06:46.210183 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.974, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0714 12:06:47.448813 132935198687872 run.py:687] Algo activity_selector step 4550 current loss 0.344410, current_train_items 181232.
I0714 12:06:47.491987 132935198687872 run.py:722] (val) algo activity_selector step 4550: {'selected': 0.937142857142857, 'score': 0.937142857142857, 'examples_seen': 181232, 'step': 4550, 'algorithm': 'activity_selector'}
I0714 12:06:47.492182 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.974, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0714 12:06:48.749804 132935198687872 run.py:687] Algo activity_selector step 4600 current loss 1.468832, current_train_items 183216.
I0714 12:06:48.793489 132935198687872 run.py:722] (val) algo activity_selector step 4600: {'selected': 0.9386138613861386, 'score': 0.9386138613861386, 'examples_seen': 183216, 'step': 4600, 'algorithm': 'activity_selector'}
I0714 12:06:48.793686 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.974, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0714 12:06:50.057770 132935198687872 run.py:687] Algo activity_selector step 4650 current loss 0.315012, current_train_items 185200.
I0714 12:06:50.116543 132935198687872 run.py:722] (val) algo activity_selector step 4650: {'selected': 0.9786407766990292, 'score': 0.9786407766990292, 'examples_seen': 185200, 'step': 4650, 'algorithm': 'activity_selector'}
I0714 12:06:50.116760 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.974, current avg val score is 0.979, val scores are: activity_selector: 0.979
I0714 12:06:51.389097 132935198687872 run.py:687] Algo activity_selector step 4700 current loss 0.338562, current_train_items 187168.
I0714 12:06:51.436316 132935198687872 run.py:722] (val) algo activity_selector step 4700: {'selected': 0.9520000000000001, 'score': 0.9520000000000001, 'examples_seen': 187168, 'step': 4700, 'algorithm': 'activity_selector'}
I0714 12:06:51.436538 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.979, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0714 12:06:53.215794 132935198687872 run.py:687] Algo activity_selector step 4750 current loss 0.389922, current_train_items 189136.
I0714 12:06:53.318305 132935198687872 run.py:722] (val) algo activity_selector step 4750: {'selected': 0.982725527831094, 'score': 0.982725527831094, 'examples_seen': 189136, 'step': 4750, 'algorithm': 'activity_selector'}
I0714 12:06:53.318562 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.979, current avg val score is 0.983, val scores are: activity_selector: 0.983
I0714 12:06:54.937913 132935198687872 run.py:687] Algo activity_selector step 4800 current loss 1.814949, current_train_items 191120.
I0714 12:06:54.996686 132935198687872 run.py:722] (val) algo activity_selector step 4800: {'selected': 0.9660377358490566, 'score': 0.9660377358490566, 'examples_seen': 191120, 'step': 4800, 'algorithm': 'activity_selector'}
I0714 12:06:54.996874 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0714 12:06:56.248112 132935198687872 run.py:687] Algo activity_selector step 4850 current loss 0.327795, current_train_items 193136.
I0714 12:06:56.288708 132935198687872 run.py:722] (val) algo activity_selector step 4850: {'selected': 0.960747663551402, 'score': 0.960747663551402, 'examples_seen': 193136, 'step': 4850, 'algorithm': 'activity_selector'}
I0714 12:06:56.288884 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0714 12:06:57.522572 132935198687872 run.py:687] Algo activity_selector step 4900 current loss 0.096972, current_train_items 195152.
I0714 12:06:57.565023 132935198687872 run.py:722] (val) algo activity_selector step 4900: {'selected': 0.9514563106796117, 'score': 0.9514563106796117, 'examples_seen': 195152, 'step': 4900, 'algorithm': 'activity_selector'}
I0714 12:06:57.565204 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0714 12:06:58.793655 132935198687872 run.py:687] Algo activity_selector step 4950 current loss 0.261646, current_train_items 197152.
I0714 12:06:58.835921 132935198687872 run.py:722] (val) algo activity_selector step 4950: {'selected': 0.9380863039399624, 'score': 0.9380863039399624, 'examples_seen': 197152, 'step': 4950, 'algorithm': 'activity_selector'}
I0714 12:06:58.836090 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0714 12:07:00.081203 132935198687872 run.py:687] Algo activity_selector step 5000 current loss 0.295962, current_train_items 199120.
I0714 12:07:00.127128 132935198687872 run.py:722] (val) algo activity_selector step 5000: {'selected': 0.9644268774703556, 'score': 0.9644268774703556, 'examples_seen': 199120, 'step': 5000, 'algorithm': 'activity_selector'}
I0714 12:07:00.127324 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0714 12:07:01.348463 132935198687872 run.py:687] Algo activity_selector step 5050 current loss 1.377964, current_train_items 201120.
I0714 12:07:01.397633 132935198687872 run.py:722] (val) algo activity_selector step 5050: {'selected': 0.946360153256705, 'score': 0.946360153256705, 'examples_seen': 201120, 'step': 5050, 'algorithm': 'activity_selector'}
I0714 12:07:01.397877 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0714 12:07:02.672063 132935198687872 run.py:687] Algo activity_selector step 5100 current loss 2.938107, current_train_items 203072.
I0714 12:07:02.726685 132935198687872 run.py:722] (val) algo activity_selector step 5100: {'selected': 0.9560229445506692, 'score': 0.9560229445506692, 'examples_seen': 203072, 'step': 5100, 'algorithm': 'activity_selector'}
I0714 12:07:02.726881 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0714 12:07:04.004178 132935198687872 run.py:687] Algo activity_selector step 5150 current loss 1.847781, current_train_items 205024.
I0714 12:07:04.063547 132935198687872 run.py:722] (val) algo activity_selector step 5150: {'selected': 0.9663366336633663, 'score': 0.9663366336633663, 'examples_seen': 205024, 'step': 5150, 'algorithm': 'activity_selector'}
I0714 12:07:04.063731 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0714 12:07:06.248211 132935198687872 run.py:687] Algo activity_selector step 5200 current loss 0.215682, current_train_items 207088.
I0714 12:07:06.359194 132935198687872 run.py:722] (val) algo activity_selector step 5200: {'selected': 0.9494163424124513, 'score': 0.9494163424124513, 'examples_seen': 207088, 'step': 5200, 'algorithm': 'activity_selector'}
I0714 12:07:06.359523 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0714 12:07:07.609254 132935198687872 run.py:687] Algo activity_selector step 5250 current loss 0.347732, current_train_items 209072.
I0714 12:07:07.651713 132935198687872 run.py:722] (val) algo activity_selector step 5250: {'selected': 0.9442379182156134, 'score': 0.9442379182156134, 'examples_seen': 209072, 'step': 5250, 'algorithm': 'activity_selector'}
I0714 12:07:07.651911 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0714 12:07:08.916876 132935198687872 run.py:687] Algo activity_selector step 5300 current loss 1.044675, current_train_items 211088.
I0714 12:07:08.959615 132935198687872 run.py:722] (val) algo activity_selector step 5300: {'selected': 0.9669902912621358, 'score': 0.9669902912621358, 'examples_seen': 211088, 'step': 5300, 'algorithm': 'activity_selector'}
I0714 12:07:08.959824 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0714 12:07:10.182576 132935198687872 run.py:687] Algo activity_selector step 5350 current loss 0.403459, current_train_items 213072.
I0714 12:07:10.228877 132935198687872 run.py:722] (val) algo activity_selector step 5350: {'selected': 0.9604743083003954, 'score': 0.9604743083003954, 'examples_seen': 213072, 'step': 5350, 'algorithm': 'activity_selector'}
I0714 12:07:10.229069 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0714 12:07:11.490085 132935198687872 run.py:687] Algo activity_selector step 5400 current loss 1.912976, current_train_items 215024.
I0714 12:07:11.540036 132935198687872 run.py:722] (val) algo activity_selector step 5400: {'selected': 0.9295238095238095, 'score': 0.9295238095238095, 'examples_seen': 215024, 'step': 5400, 'algorithm': 'activity_selector'}
I0714 12:07:11.540225 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0714 12:07:12.801632 132935198687872 run.py:687] Algo activity_selector step 5450 current loss 2.491086, current_train_items 217024.
I0714 12:07:12.857488 132935198687872 run.py:722] (val) algo activity_selector step 5450: {'selected': 0.9512670565302145, 'score': 0.9512670565302145, 'examples_seen': 217024, 'step': 5450, 'algorithm': 'activity_selector'}
I0714 12:07:12.857664 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0714 12:07:14.194411 132935198687872 run.py:687] Algo activity_selector step 5500 current loss 1.815271, current_train_items 218960.
I0714 12:07:14.255220 132935198687872 run.py:722] (val) algo activity_selector step 5500: {'selected': 0.9725490196078431, 'score': 0.9725490196078431, 'examples_seen': 218960, 'step': 5500, 'algorithm': 'activity_selector'}
I0714 12:07:14.255480 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0714 12:07:15.568413 132935198687872 run.py:687] Algo activity_selector step 5550 current loss 0.372349, current_train_items 221008.
I0714 12:07:15.613411 132935198687872 run.py:722] (val) algo activity_selector step 5550: {'selected': 0.9323308270676692, 'score': 0.9323308270676692, 'examples_seen': 221008, 'step': 5550, 'algorithm': 'activity_selector'}
I0714 12:07:15.613629 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0714 12:07:17.229916 132935198687872 run.py:687] Algo activity_selector step 5600 current loss 0.044581, current_train_items 223024.
I0714 12:07:17.323436 132935198687872 run.py:722] (val) algo activity_selector step 5600: {'selected': 0.9581749049429658, 'score': 0.9581749049429658, 'examples_seen': 223024, 'step': 5600, 'algorithm': 'activity_selector'}
I0714 12:07:17.323723 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0714 12:07:19.158446 132935198687872 run.py:687] Algo activity_selector step 5650 current loss 1.146227, current_train_items 225008.
I0714 12:07:19.201089 132935198687872 run.py:722] (val) algo activity_selector step 5650: {'selected': 0.9666011787819253, 'score': 0.9666011787819253, 'examples_seen': 225008, 'step': 5650, 'algorithm': 'activity_selector'}
I0714 12:07:19.201285 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0714 12:07:20.473971 132935198687872 run.py:687] Algo activity_selector step 5700 current loss 0.349108, current_train_items 227008.
I0714 12:07:20.520576 132935198687872 run.py:722] (val) algo activity_selector step 5700: {'selected': 0.9601449275362318, 'score': 0.9601449275362318, 'examples_seen': 227008, 'step': 5700, 'algorithm': 'activity_selector'}
I0714 12:07:20.520775 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0714 12:07:21.761456 132935198687872 run.py:687] Algo activity_selector step 5750 current loss 0.348636, current_train_items 228960.
I0714 12:07:21.809281 132935198687872 run.py:722] (val) algo activity_selector step 5750: {'selected': 0.9668615984405458, 'score': 0.9668615984405458, 'examples_seen': 228960, 'step': 5750, 'algorithm': 'activity_selector'}
I0714 12:07:21.809512 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0714 12:07:23.063910 132935198687872 run.py:687] Algo activity_selector step 5800 current loss 2.153469, current_train_items 230928.
I0714 12:07:23.116540 132935198687872 run.py:722] (val) algo activity_selector step 5800: {'selected': 0.9511278195488722, 'score': 0.9511278195488722, 'examples_seen': 230928, 'step': 5800, 'algorithm': 'activity_selector'}
I0714 12:07:23.116732 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0714 12:07:24.315669 132935198687872 run.py:687] Algo activity_selector step 5850 current loss 1.659719, current_train_items 232912.
I0714 12:07:24.375964 132935198687872 run.py:722] (val) algo activity_selector step 5850: {'selected': 0.9613899613899615, 'score': 0.9613899613899615, 'examples_seen': 232912, 'step': 5850, 'algorithm': 'activity_selector'}
I0714 12:07:24.376146 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0714 12:07:25.733054 132935198687872 run.py:687] Algo activity_selector step 5900 current loss 0.275070, current_train_items 234928.
I0714 12:07:25.777091 132935198687872 run.py:722] (val) algo activity_selector step 5900: {'selected': 0.9619771863117872, 'score': 0.9619771863117872, 'examples_seen': 234928, 'step': 5900, 'algorithm': 'activity_selector'}
I0714 12:07:25.777280 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0714 12:07:27.043623 132935198687872 run.py:687] Algo activity_selector step 5950 current loss 0.068195, current_train_items 236944.
I0714 12:07:27.087218 132935198687872 run.py:722] (val) algo activity_selector step 5950: {'selected': 0.9612403100775193, 'score': 0.9612403100775193, 'examples_seen': 236944, 'step': 5950, 'algorithm': 'activity_selector'}
I0714 12:07:27.087462 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0714 12:07:28.368531 132935198687872 run.py:687] Algo activity_selector step 6000 current loss 0.233964, current_train_items 238944.
I0714 12:07:28.414777 132935198687872 run.py:722] (val) algo activity_selector step 6000: {'selected': 0.951310861423221, 'score': 0.951310861423221, 'examples_seen': 238944, 'step': 6000, 'algorithm': 'activity_selector'}
I0714 12:07:28.414968 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0714 12:07:30.506399 132935198687872 run.py:687] Algo activity_selector step 6050 current loss 0.214290, current_train_items 240928.
I0714 12:07:30.613434 132935198687872 run.py:722] (val) algo activity_selector step 6050: {'selected': 0.9610894941634242, 'score': 0.9610894941634242, 'examples_seen': 240928, 'step': 6050, 'algorithm': 'activity_selector'}
I0714 12:07:30.613708 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0714 12:07:31.908917 132935198687872 run.py:687] Algo activity_selector step 6100 current loss 1.270236, current_train_items 242912.
I0714 12:07:31.958880 132935198687872 run.py:722] (val) algo activity_selector step 6100: {'selected': 0.9723756906077348, 'score': 0.9723756906077348, 'examples_seen': 242912, 'step': 6100, 'algorithm': 'activity_selector'}
I0714 12:07:31.959069 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0714 12:07:33.205839 132935198687872 run.py:687] Algo activity_selector step 6150 current loss 1.689267, current_train_items 244864.
I0714 12:07:33.262301 132935198687872 run.py:722] (val) algo activity_selector step 6150: {'selected': 0.9672447013487475, 'score': 0.9672447013487475, 'examples_seen': 244864, 'step': 6150, 'algorithm': 'activity_selector'}
I0714 12:07:33.262580 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.983, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0714 12:07:34.488996 132935198687872 run.py:687] Algo activity_selector step 6200 current loss 1.241700, current_train_items 246816.
I0714 12:07:34.549870 132935198687872 run.py:722] (val) algo activity_selector step 6200: {'selected': 0.9923954372623575, 'score': 0.9923954372623575, 'examples_seen': 246816, 'step': 6200, 'algorithm': 'activity_selector'}
I0714 12:07:34.550090 132935198687872 run.py:743] Checkpointing best model, best avg val score was 0.983, current avg val score is 0.992, val scores are: activity_selector: 0.992
I0714 12:07:35.845049 132935198687872 run.py:687] Algo activity_selector step 6250 current loss 0.062288, current_train_items 248880.
I0714 12:07:35.897996 132935198687872 run.py:722] (val) algo activity_selector step 6250: {'selected': 0.9611829944547134, 'score': 0.9611829944547134, 'examples_seen': 248880, 'step': 6250, 'algorithm': 'activity_selector'}
I0714 12:07:35.898181 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0714 12:07:37.138701 132935198687872 run.py:687] Algo activity_selector step 6300 current loss 0.539941, current_train_items 250880.
I0714 12:07:37.182039 132935198687872 run.py:722] (val) algo activity_selector step 6300: {'selected': 0.9058823529411766, 'score': 0.9058823529411766, 'examples_seen': 250880, 'step': 6300, 'algorithm': 'activity_selector'}
I0714 12:07:37.182227 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0714 12:07:38.433907 132935198687872 run.py:687] Algo activity_selector step 6350 current loss 1.123437, current_train_items 252880.
I0714 12:07:38.474796 132935198687872 run.py:722] (val) algo activity_selector step 6350: {'selected': 0.9717514124293785, 'score': 0.9717514124293785, 'examples_seen': 252880, 'step': 6350, 'algorithm': 'activity_selector'}
I0714 12:07:38.474982 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0714 12:07:39.800390 132935198687872 run.py:687] Algo activity_selector step 6400 current loss 0.168638, current_train_items 254864.
I0714 12:07:39.849376 132935198687872 run.py:722] (val) algo activity_selector step 6400: {'selected': 0.9585798816568047, 'score': 0.9585798816568047, 'examples_seen': 254864, 'step': 6400, 'algorithm': 'activity_selector'}
I0714 12:07:39.849617 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0714 12:07:41.505731 132935198687872 run.py:687] Algo activity_selector step 6450 current loss 2.318072, current_train_items 256816.
I0714 12:07:41.594430 132935198687872 run.py:722] (val) algo activity_selector step 6450: {'selected': 0.9555555555555556, 'score': 0.9555555555555556, 'examples_seen': 256816, 'step': 6450, 'algorithm': 'activity_selector'}
I0714 12:07:41.594683 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0714 12:07:43.360808 132935198687872 run.py:687] Algo activity_selector step 6500 current loss 1.920629, current_train_items 258816.
I0714 12:07:43.416020 132935198687872 run.py:722] (val) algo activity_selector step 6500: {'selected': 0.972972972972973, 'score': 0.972972972972973, 'examples_seen': 258816, 'step': 6500, 'algorithm': 'activity_selector'}
I0714 12:07:43.416196 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0714 12:07:44.651888 132935198687872 run.py:687] Algo activity_selector step 6550 current loss 1.828250, current_train_items 260752.
I0714 12:07:44.711459 132935198687872 run.py:722] (val) algo activity_selector step 6550: {'selected': 0.9520295202952029, 'score': 0.9520295202952029, 'examples_seen': 260752, 'step': 6550, 'algorithm': 'activity_selector'}
I0714 12:07:44.711652 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0714 12:07:46.024233 132935198687872 run.py:687] Algo activity_selector step 6600 current loss 0.458442, current_train_items 262800.
I0714 12:07:46.066535 132935198687872 run.py:722] (val) algo activity_selector step 6600: {'selected': 0.8904847396768402, 'score': 0.8904847396768402, 'examples_seen': 262800, 'step': 6600, 'algorithm': 'activity_selector'}
I0714 12:07:46.066738 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.890, val scores are: activity_selector: 0.890
I0714 12:07:47.311181 132935198687872 run.py:687] Algo activity_selector step 6650 current loss 0.067680, current_train_items 264832.
I0714 12:07:47.357378 132935198687872 run.py:722] (val) algo activity_selector step 6650: {'selected': 0.9433962264150944, 'score': 0.9433962264150944, 'examples_seen': 264832, 'step': 6650, 'algorithm': 'activity_selector'}
I0714 12:07:47.357588 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0714 12:07:48.589824 132935198687872 run.py:687] Algo activity_selector step 6700 current loss 1.041147, current_train_items 266800.
I0714 12:07:48.633978 132935198687872 run.py:722] (val) algo activity_selector step 6700: {'selected': 0.9439071566731141, 'score': 0.9439071566731141, 'examples_seen': 266800, 'step': 6700, 'algorithm': 'activity_selector'}
I0714 12:07:48.634170 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0714 12:07:49.867175 132935198687872 run.py:687] Algo activity_selector step 6750 current loss 0.326458, current_train_items 268800.
I0714 12:07:49.912735 132935198687872 run.py:722] (val) algo activity_selector step 6750: {'selected': 0.9602888086642599, 'score': 0.9602888086642599, 'examples_seen': 268800, 'step': 6750, 'algorithm': 'activity_selector'}
I0714 12:07:49.912924 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0714 12:07:51.163726 132935198687872 run.py:687] Algo activity_selector step 6800 current loss 0.483003, current_train_items 270752.
I0714 12:07:51.211644 132935198687872 run.py:722] (val) algo activity_selector step 6800: {'selected': 0.9642184557438795, 'score': 0.9642184557438795, 'examples_seen': 270752, 'step': 6800, 'algorithm': 'activity_selector'}
I0714 12:07:51.211846 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0714 12:07:52.490984 132935198687872 run.py:687] Algo activity_selector step 6850 current loss 1.641488, current_train_items 272736.
I0714 12:07:52.544689 132935198687872 run.py:722] (val) algo activity_selector step 6850: {'selected': 0.9453125000000001, 'score': 0.9453125000000001, 'examples_seen': 272736, 'step': 6850, 'algorithm': 'activity_selector'}
I0714 12:07:52.544878 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0714 12:07:54.567447 132935198687872 run.py:687] Algo activity_selector step 6900 current loss 0.586847, current_train_items 274720.
I0714 12:07:54.677217 132935198687872 run.py:722] (val) algo activity_selector step 6900: {'selected': 0.9489603024574669, 'score': 0.9489603024574669, 'examples_seen': 274720, 'step': 6900, 'algorithm': 'activity_selector'}
I0714 12:07:54.677452 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0714 12:07:55.946723 132935198687872 run.py:687] Algo activity_selector step 6950 current loss 0.368769, current_train_items 276736.
I0714 12:07:55.990322 132935198687872 run.py:722] (val) algo activity_selector step 6950: {'selected': 0.9789674952198854, 'score': 0.9789674952198854, 'examples_seen': 276736, 'step': 6950, 'algorithm': 'activity_selector'}
I0714 12:07:55.990554 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.979, val scores are: activity_selector: 0.979
I0714 12:07:57.248753 132935198687872 run.py:687] Algo activity_selector step 7000 current loss 0.288327, current_train_items 278768.
I0714 12:07:57.291086 132935198687872 run.py:722] (val) algo activity_selector step 7000: {'selected': 0.9716446124763705, 'score': 0.9716446124763705, 'examples_seen': 278768, 'step': 7000, 'algorithm': 'activity_selector'}
I0714 12:07:57.291297 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0714 12:07:58.519506 132935198687872 run.py:687] Algo activity_selector step 7050 current loss 0.286190, current_train_items 280752.
I0714 12:07:58.564980 132935198687872 run.py:722] (val) algo activity_selector step 7050: {'selected': 0.9625246548323471, 'score': 0.9625246548323471, 'examples_seen': 280752, 'step': 7050, 'algorithm': 'activity_selector'}
I0714 12:07:58.565177 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0714 12:07:59.894150 132935198687872 run.py:687] Algo activity_selector step 7100 current loss 0.167439, current_train_items 282736.
I0714 12:07:59.940504 132935198687872 run.py:722] (val) algo activity_selector step 7100: {'selected': 0.9651162790697675, 'score': 0.9651162790697675, 'examples_seen': 282736, 'step': 7100, 'algorithm': 'activity_selector'}
I0714 12:07:59.940714 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0714 12:08:01.186614 132935198687872 run.py:687] Algo activity_selector step 7150 current loss 1.527970, current_train_items 284720.
I0714 12:08:01.235911 132935198687872 run.py:722] (val) algo activity_selector step 7150: {'selected': 0.9441233140655106, 'score': 0.9441233140655106, 'examples_seen': 284720, 'step': 7150, 'algorithm': 'activity_selector'}
I0714 12:08:01.236115 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0714 12:08:02.514776 132935198687872 run.py:687] Algo activity_selector step 7200 current loss 0.241745, current_train_items 286672.
I0714 12:08:02.568803 132935198687872 run.py:722] (val) algo activity_selector step 7200: {'selected': 0.940952380952381, 'score': 0.940952380952381, 'examples_seen': 286672, 'step': 7200, 'algorithm': 'activity_selector'}
I0714 12:08:02.569000 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0714 12:08:03.821763 132935198687872 run.py:687] Algo activity_selector step 7250 current loss 3.520137, current_train_items 288640.
I0714 12:08:03.889968 132935198687872 run.py:722] (val) algo activity_selector step 7250: {'selected': 0.9638095238095239, 'score': 0.9638095238095239, 'examples_seen': 288640, 'step': 7250, 'algorithm': 'activity_selector'}
I0714 12:08:03.890171 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0714 12:08:05.553026 132935198687872 run.py:687] Algo activity_selector step 7300 current loss 0.223402, current_train_items 290688.
I0714 12:08:05.645070 132935198687872 run.py:722] (val) algo activity_selector step 7300: {'selected': 0.955223880597015, 'score': 0.955223880597015, 'examples_seen': 290688, 'step': 7300, 'algorithm': 'activity_selector'}
I0714 12:08:05.645320 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0714 12:08:07.404184 132935198687872 run.py:687] Algo activity_selector step 7350 current loss 0.163598, current_train_items 292688.
I0714 12:08:07.444923 132935198687872 run.py:722] (val) algo activity_selector step 7350: {'selected': 0.9649805447470817, 'score': 0.9649805447470817, 'examples_seen': 292688, 'step': 7350, 'algorithm': 'activity_selector'}
I0714 12:08:07.445102 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0714 12:08:08.684771 132935198687872 run.py:687] Algo activity_selector step 7400 current loss 0.878855, current_train_items 294688.
I0714 12:08:08.730384 132935198687872 run.py:722] (val) algo activity_selector step 7400: {'selected': 0.9642857142857142, 'score': 0.9642857142857142, 'examples_seen': 294688, 'step': 7400, 'algorithm': 'activity_selector'}
I0714 12:08:08.730585 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0714 12:08:10.007251 132935198687872 run.py:687] Algo activity_selector step 7450 current loss 0.319690, current_train_items 296672.
I0714 12:08:10.052665 132935198687872 run.py:722] (val) algo activity_selector step 7450: {'selected': 0.974559686888454, 'score': 0.974559686888454, 'examples_seen': 296672, 'step': 7450, 'algorithm': 'activity_selector'}
I0714 12:08:10.052860 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0714 12:08:11.293632 132935198687872 run.py:687] Algo activity_selector step 7500 current loss 1.989866, current_train_items 298624.
I0714 12:08:11.343070 132935198687872 run.py:722] (val) algo activity_selector step 7500: {'selected': 0.9809160305343511, 'score': 0.9809160305343511, 'examples_seen': 298624, 'step': 7500, 'algorithm': 'activity_selector'}
I0714 12:08:11.343257 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0714 12:08:12.590102 132935198687872 run.py:687] Algo activity_selector step 7550 current loss 4.677483, current_train_items 300624.
I0714 12:08:12.641756 132935198687872 run.py:722] (val) algo activity_selector step 7550: {'selected': 0.9779559118236473, 'score': 0.9779559118236473, 'examples_seen': 300624, 'step': 7550, 'algorithm': 'activity_selector'}
I0714 12:08:12.641958 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.978, val scores are: activity_selector: 0.978
I0714 12:08:13.939859 132935198687872 run.py:687] Algo activity_selector step 7600 current loss 3.312641, current_train_items 302576.
I0714 12:08:14.002628 132935198687872 run.py:722] (val) algo activity_selector step 7600: {'selected': 0.9765625, 'score': 0.9765625, 'examples_seen': 302576, 'step': 7600, 'algorithm': 'activity_selector'}
I0714 12:08:14.002839 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0714 12:08:15.303571 132935198687872 run.py:687] Algo activity_selector step 7650 current loss 0.458125, current_train_items 304608.
I0714 12:08:15.345514 132935198687872 run.py:722] (val) algo activity_selector step 7650: {'selected': 0.9402061855670104, 'score': 0.9402061855670104, 'examples_seen': 304608, 'step': 7650, 'algorithm': 'activity_selector'}
I0714 12:08:15.345710 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0714 12:08:16.614446 132935198687872 run.py:687] Algo activity_selector step 7700 current loss 0.124564, current_train_items 306640.
I0714 12:08:16.656215 132935198687872 run.py:722] (val) algo activity_selector step 7700: {'selected': 0.976, 'score': 0.976, 'examples_seen': 306640, 'step': 7700, 'algorithm': 'activity_selector'}
I0714 12:08:16.656466 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0714 12:08:18.739915 132935198687872 run.py:687] Algo activity_selector step 7750 current loss 0.839578, current_train_items 308608.
I0714 12:08:18.813199 132935198687872 run.py:722] (val) algo activity_selector step 7750: {'selected': 0.9383177570093457, 'score': 0.9383177570093457, 'examples_seen': 308608, 'step': 7750, 'algorithm': 'activity_selector'}
I0714 12:08:18.813444 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0714 12:08:20.059954 132935198687872 run.py:687] Algo activity_selector step 7800 current loss 0.144279, current_train_items 310608.
I0714 12:08:20.103977 132935198687872 run.py:722] (val) algo activity_selector step 7800: {'selected': 0.9098360655737705, 'score': 0.9098360655737705, 'examples_seen': 310608, 'step': 7800, 'algorithm': 'activity_selector'}
I0714 12:08:20.104155 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0714 12:08:21.309816 132935198687872 run.py:687] Algo activity_selector step 7850 current loss 0.397704, current_train_items 312576.
I0714 12:08:21.358452 132935198687872 run.py:722] (val) algo activity_selector step 7850: {'selected': 0.9607843137254902, 'score': 0.9607843137254902, 'examples_seen': 312576, 'step': 7850, 'algorithm': 'activity_selector'}
I0714 12:08:21.358660 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0714 12:08:22.560071 132935198687872 run.py:687] Algo activity_selector step 7900 current loss 2.379618, current_train_items 314528.
I0714 12:08:22.613470 132935198687872 run.py:722] (val) algo activity_selector step 7900: {'selected': 0.9823874755381604, 'score': 0.9823874755381604, 'examples_seen': 314528, 'step': 7900, 'algorithm': 'activity_selector'}
I0714 12:08:22.613647 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.982, val scores are: activity_selector: 0.982
I0714 12:08:23.851532 132935198687872 run.py:687] Algo activity_selector step 7950 current loss 3.255164, current_train_items 316528.
I0714 12:08:23.908194 132935198687872 run.py:722] (val) algo activity_selector step 7950: {'selected': 0.9749999999999999, 'score': 0.9749999999999999, 'examples_seen': 316528, 'step': 7950, 'algorithm': 'activity_selector'}
I0714 12:08:23.908420 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0714 12:08:25.160376 132935198687872 run.py:687] Algo activity_selector step 8000 current loss 0.371505, current_train_items 318528.
I0714 12:08:25.202363 132935198687872 run.py:722] (val) algo activity_selector step 8000: {'selected': 0.9383177570093458, 'score': 0.9383177570093458, 'examples_seen': 318528, 'step': 8000, 'algorithm': 'activity_selector'}
I0714 12:08:25.202572 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0714 12:08:26.448186 132935198687872 run.py:687] Algo activity_selector step 8050 current loss 0.182519, current_train_items 320560.
I0714 12:08:26.489991 132935198687872 run.py:722] (val) algo activity_selector step 8050: {'selected': 0.9566929133858267, 'score': 0.9566929133858267, 'examples_seen': 320560, 'step': 8050, 'algorithm': 'activity_selector'}
I0714 12:08:26.490181 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0714 12:08:27.710424 132935198687872 run.py:687] Algo activity_selector step 8100 current loss 0.310275, current_train_items 322544.
I0714 12:08:27.756785 132935198687872 run.py:722] (val) algo activity_selector step 8100: {'selected': 0.9809885931558935, 'score': 0.9809885931558935, 'examples_seen': 322544, 'step': 8100, 'algorithm': 'activity_selector'}
I0714 12:08:27.756985 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0714 12:08:29.157726 132935198687872 run.py:687] Algo activity_selector step 8150 current loss 0.259117, current_train_items 324528.
I0714 12:08:29.252399 132935198687872 run.py:722] (val) algo activity_selector step 8150: {'selected': 0.9736842105263158, 'score': 0.9736842105263158, 'examples_seen': 324528, 'step': 8150, 'algorithm': 'activity_selector'}
I0714 12:08:29.252666 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0714 12:08:31.177176 132935198687872 run.py:687] Algo activity_selector step 8200 current loss 1.446338, current_train_items 326528.
I0714 12:08:31.225492 132935198687872 run.py:722] (val) algo activity_selector step 8200: {'selected': 0.9484126984126985, 'score': 0.9484126984126985, 'examples_seen': 326528, 'step': 8200, 'algorithm': 'activity_selector'}
I0714 12:08:31.225673 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0714 12:08:32.465427 132935198687872 run.py:687] Algo activity_selector step 8250 current loss 2.352318, current_train_items 328464.
I0714 12:08:32.517766 132935198687872 run.py:722] (val) algo activity_selector step 8250: {'selected': 0.9685767097966729, 'score': 0.9685767097966729, 'examples_seen': 328464, 'step': 8250, 'algorithm': 'activity_selector'}
I0714 12:08:32.517943 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0714 12:08:33.749226 132935198687872 run.py:687] Algo activity_selector step 8300 current loss 3.446861, current_train_items 330432.
I0714 12:08:33.808887 132935198687872 run.py:722] (val) algo activity_selector step 8300: {'selected': 0.9746588693957116, 'score': 0.9746588693957116, 'examples_seen': 330432, 'step': 8300, 'algorithm': 'activity_selector'}
I0714 12:08:33.809091 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0714 12:08:35.015236 132935198687872 run.py:687] Algo activity_selector step 8350 current loss 0.063332, current_train_items 332480.
I0714 12:08:35.057597 132935198687872 run.py:722] (val) algo activity_selector step 8350: {'selected': 0.9248554913294799, 'score': 0.9248554913294799, 'examples_seen': 332480, 'step': 8350, 'algorithm': 'activity_selector'}
I0714 12:08:35.057782 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0714 12:08:36.296874 132935198687872 run.py:687] Algo activity_selector step 8400 current loss 0.034781, current_train_items 334480.
I0714 12:08:36.347357 132935198687872 run.py:722] (val) algo activity_selector step 8400: {'selected': 0.9341085271317829, 'score': 0.9341085271317829, 'examples_seen': 334480, 'step': 8400, 'algorithm': 'activity_selector'}
I0714 12:08:36.347563 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0714 12:08:37.582150 132935198687872 run.py:687] Algo activity_selector step 8450 current loss 1.054692, current_train_items 336480.
I0714 12:08:37.628561 132935198687872 run.py:722] (val) algo activity_selector step 8450: {'selected': 0.9900596421471173, 'score': 0.9900596421471173, 'examples_seen': 336480, 'step': 8450, 'algorithm': 'activity_selector'}
I0714 12:08:37.628752 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.990, val scores are: activity_selector: 0.990
I0714 12:08:38.833040 132935198687872 run.py:687] Algo activity_selector step 8500 current loss 0.150595, current_train_items 338464.
I0714 12:08:38.879148 132935198687872 run.py:722] (val) algo activity_selector step 8500: {'selected': 0.9749518304431599, 'score': 0.9749518304431599, 'examples_seen': 338464, 'step': 8500, 'algorithm': 'activity_selector'}
I0714 12:08:38.879325 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0714 12:08:40.119113 132935198687872 run.py:687] Algo activity_selector step 8550 current loss 2.495132, current_train_items 340432.
I0714 12:08:40.168159 132935198687872 run.py:722] (val) algo activity_selector step 8550: {'selected': 0.9368029739776952, 'score': 0.9368029739776952, 'examples_seen': 340432, 'step': 8550, 'algorithm': 'activity_selector'}
I0714 12:08:40.168374 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0714 12:08:41.756592 132935198687872 run.py:687] Algo activity_selector step 8600 current loss 1.744104, current_train_items 342416.
I0714 12:08:41.858783 132935198687872 run.py:722] (val) algo activity_selector step 8600: {'selected': 0.9737827715355805, 'score': 0.9737827715355805, 'examples_seen': 342416, 'step': 8600, 'algorithm': 'activity_selector'}
I0714 12:08:41.859023 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0714 12:08:43.578910 132935198687872 run.py:687] Algo activity_selector step 8650 current loss 2.793161, current_train_items 344368.
I0714 12:08:43.636990 132935198687872 run.py:722] (val) algo activity_selector step 8650: {'selected': 0.9590643274853802, 'score': 0.9590643274853802, 'examples_seen': 344368, 'step': 8650, 'algorithm': 'activity_selector'}
I0714 12:08:43.637170 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0714 12:08:44.873566 132935198687872 run.py:687] Algo activity_selector step 8700 current loss 0.329840, current_train_items 346400.
I0714 12:08:44.915820 132935198687872 run.py:722] (val) algo activity_selector step 8700: {'selected': 0.972972972972973, 'score': 0.972972972972973, 'examples_seen': 346400, 'step': 8700, 'algorithm': 'activity_selector'}
I0714 12:08:44.916007 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0714 12:08:46.157206 132935198687872 run.py:687] Algo activity_selector step 8750 current loss 0.360038, current_train_items 348432.
I0714 12:08:46.199515 132935198687872 run.py:722] (val) algo activity_selector step 8750: {'selected': 0.9695817490494296, 'score': 0.9695817490494296, 'examples_seen': 348432, 'step': 8750, 'algorithm': 'activity_selector'}
I0714 12:08:46.199701 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0714 12:08:47.434969 132935198687872 run.py:687] Algo activity_selector step 8800 current loss 0.678153, current_train_items 350416.
I0714 12:08:47.479891 132935198687872 run.py:722] (val) algo activity_selector step 8800: {'selected': 0.972, 'score': 0.972, 'examples_seen': 350416, 'step': 8800, 'algorithm': 'activity_selector'}
I0714 12:08:47.480067 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0714 12:08:48.714488 132935198687872 run.py:687] Algo activity_selector step 8850 current loss 0.241142, current_train_items 352400.
I0714 12:08:48.781622 132935198687872 run.py:722] (val) algo activity_selector step 8850: {'selected': 0.9616858237547893, 'score': 0.9616858237547893, 'examples_seen': 352400, 'step': 8850, 'algorithm': 'activity_selector'}
I0714 12:08:48.781868 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0714 12:08:50.061082 132935198687872 run.py:687] Algo activity_selector step 8900 current loss 0.334405, current_train_items 354368.
I0714 12:08:50.110585 132935198687872 run.py:722] (val) algo activity_selector step 8900: {'selected': 0.9479768786127168, 'score': 0.9479768786127168, 'examples_seen': 354368, 'step': 8900, 'algorithm': 'activity_selector'}
I0714 12:08:50.110795 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0714 12:08:51.321296 132935198687872 run.py:687] Algo activity_selector step 8950 current loss 1.553678, current_train_items 356320.
I0714 12:08:51.378956 132935198687872 run.py:722] (val) algo activity_selector step 8950: {'selected': 0.9506903353057199, 'score': 0.9506903353057199, 'examples_seen': 356320, 'step': 8950, 'algorithm': 'activity_selector'}
I0714 12:08:51.379190 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0714 12:08:52.628908 132935198687872 run.py:687] Algo activity_selector step 9000 current loss 2.538040, current_train_items 358320.
I0714 12:08:52.689003 132935198687872 run.py:722] (val) algo activity_selector step 9000: {'selected': 0.9824561403508771, 'score': 0.9824561403508771, 'examples_seen': 358320, 'step': 9000, 'algorithm': 'activity_selector'}
I0714 12:08:52.689189 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.982, val scores are: activity_selector: 0.982
I0714 12:08:54.696677 132935198687872 run.py:687] Algo activity_selector step 9050 current loss 0.261119, current_train_items 360320.
I0714 12:08:54.791591 132935198687872 run.py:722] (val) algo activity_selector step 9050: {'selected': 0.942084942084942, 'score': 0.942084942084942, 'examples_seen': 360320, 'step': 9050, 'algorithm': 'activity_selector'}
I0714 12:08:54.791895 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0714 12:08:56.111087 132935198687872 run.py:687] Algo activity_selector step 9100 current loss 0.094483, current_train_items 362352.
I0714 12:08:56.152782 132935198687872 run.py:722] (val) algo activity_selector step 9100: {'selected': 0.9652351738241308, 'score': 0.9652351738241308, 'examples_seen': 362352, 'step': 9100, 'algorithm': 'activity_selector'}
I0714 12:08:56.152987 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0714 12:08:57.410596 132935198687872 run.py:687] Algo activity_selector step 9150 current loss 0.179349, current_train_items 364352.
I0714 12:08:57.452063 132935198687872 run.py:722] (val) algo activity_selector step 9150: {'selected': 0.9354207436399218, 'score': 0.9354207436399218, 'examples_seen': 364352, 'step': 9150, 'algorithm': 'activity_selector'}
I0714 12:08:57.452247 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0714 12:08:58.690358 132935198687872 run.py:687] Algo activity_selector step 9200 current loss 0.305198, current_train_items 366320.
I0714 12:08:58.736247 132935198687872 run.py:722] (val) algo activity_selector step 9200: {'selected': 0.9606299212598425, 'score': 0.9606299212598425, 'examples_seen': 366320, 'step': 9200, 'algorithm': 'activity_selector'}
I0714 12:08:58.736482 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0714 12:09:00.029274 132935198687872 run.py:687] Algo activity_selector step 9250 current loss 1.424956, current_train_items 368320.
I0714 12:09:00.080279 132935198687872 run.py:722] (val) algo activity_selector step 9250: {'selected': 0.9860834990059641, 'score': 0.9860834990059641, 'examples_seen': 368320, 'step': 9250, 'algorithm': 'activity_selector'}
I0714 12:09:00.080529 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.986, val scores are: activity_selector: 0.986
I0714 12:09:01.444276 132935198687872 run.py:687] Algo activity_selector step 9300 current loss 1.037253, current_train_items 370272.
I0714 12:09:01.496334 132935198687872 run.py:722] (val) algo activity_selector step 9300: {'selected': 0.967984934086629, 'score': 0.967984934086629, 'examples_seen': 370272, 'step': 9300, 'algorithm': 'activity_selector'}
I0714 12:09:01.496577 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0714 12:09:02.735203 132935198687872 run.py:687] Algo activity_selector step 9350 current loss 2.325464, current_train_items 372240.
I0714 12:09:02.793583 132935198687872 run.py:722] (val) algo activity_selector step 9350: {'selected': 0.965648854961832, 'score': 0.965648854961832, 'examples_seen': 372240, 'step': 9350, 'algorithm': 'activity_selector'}
I0714 12:09:02.793797 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0714 12:09:04.051815 132935198687872 run.py:687] Algo activity_selector step 9400 current loss 0.133142, current_train_items 374288.
I0714 12:09:04.092635 132935198687872 run.py:722] (val) algo activity_selector step 9400: {'selected': 0.9168356997971602, 'score': 0.9168356997971602, 'examples_seen': 374288, 'step': 9400, 'algorithm': 'activity_selector'}
I0714 12:09:04.092818 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0714 12:09:05.713954 132935198687872 run.py:687] Algo activity_selector step 9450 current loss 0.046387, current_train_items 376288.
I0714 12:09:05.810456 132935198687872 run.py:722] (val) algo activity_selector step 9450: {'selected': 0.9555125725338491, 'score': 0.9555125725338491, 'examples_seen': 376288, 'step': 9450, 'algorithm': 'activity_selector'}
I0714 12:09:05.810725 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0714 12:09:07.555751 132935198687872 run.py:687] Algo activity_selector step 9500 current loss 0.737118, current_train_items 378304.
I0714 12:09:07.602013 132935198687872 run.py:722] (val) algo activity_selector step 9500: {'selected': 0.9607476635514018, 'score': 0.9607476635514018, 'examples_seen': 378304, 'step': 9500, 'algorithm': 'activity_selector'}
I0714 12:09:07.602196 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0714 12:09:08.859232 132935198687872 run.py:687] Algo activity_selector step 9550 current loss 0.412893, current_train_items 380272.
I0714 12:09:08.904995 132935198687872 run.py:722] (val) algo activity_selector step 9550: {'selected': 0.9333333333333333, 'score': 0.9333333333333333, 'examples_seen': 380272, 'step': 9550, 'algorithm': 'activity_selector'}
I0714 12:09:08.905182 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0714 12:09:10.189963 132935198687872 run.py:687] Algo activity_selector step 9600 current loss 1.872769, current_train_items 382240.
I0714 12:09:10.239619 132935198687872 run.py:722] (val) algo activity_selector step 9600: {'selected': 0.9694656488549618, 'score': 0.9694656488549618, 'examples_seen': 382240, 'step': 9600, 'algorithm': 'activity_selector'}
I0714 12:09:10.239827 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0714 12:09:11.489637 132935198687872 run.py:687] Algo activity_selector step 9650 current loss 0.337888, current_train_items 384224.
I0714 12:09:11.541897 132935198687872 run.py:722] (val) algo activity_selector step 9650: {'selected': 0.9347826086956521, 'score': 0.9347826086956521, 'examples_seen': 384224, 'step': 9650, 'algorithm': 'activity_selector'}
I0714 12:09:11.542090 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0714 12:09:12.827719 132935198687872 run.py:687] Algo activity_selector step 9700 current loss 2.234597, current_train_items 386176.
I0714 12:09:12.883950 132935198687872 run.py:722] (val) algo activity_selector step 9700: {'selected': 0.9582504970178927, 'score': 0.9582504970178927, 'examples_seen': 386176, 'step': 9700, 'algorithm': 'activity_selector'}
I0714 12:09:12.884143 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0714 12:09:14.187396 132935198687872 run.py:687] Algo activity_selector step 9750 current loss 0.330633, current_train_items 388224.
I0714 12:09:14.227952 132935198687872 run.py:722] (val) algo activity_selector step 9750: {'selected': 0.9465648854961831, 'score': 0.9465648854961831, 'examples_seen': 388224, 'step': 9750, 'algorithm': 'activity_selector'}
I0714 12:09:14.228137 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0714 12:09:15.487617 132935198687872 run.py:687] Algo activity_selector step 9800 current loss 0.079126, current_train_items 390240.
I0714 12:09:15.530840 132935198687872 run.py:722] (val) algo activity_selector step 9800: {'selected': 0.9677419354838709, 'score': 0.9677419354838709, 'examples_seen': 390240, 'step': 9800, 'algorithm': 'activity_selector'}
I0714 12:09:15.531041 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0714 12:09:16.793877 132935198687872 run.py:687] Algo activity_selector step 9850 current loss 0.717512, current_train_items 392224.
I0714 12:09:16.835559 132935198687872 run.py:722] (val) algo activity_selector step 9850: {'selected': 0.9724409448818898, 'score': 0.9724409448818898, 'examples_seen': 392224, 'step': 9850, 'algorithm': 'activity_selector'}
I0714 12:09:16.835751 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0714 12:09:18.879494 132935198687872 run.py:687] Algo activity_selector step 9900 current loss 0.172109, current_train_items 394208.
I0714 12:09:18.987055 132935198687872 run.py:722] (val) algo activity_selector step 9900: {'selected': 0.9727626459143969, 'score': 0.9727626459143969, 'examples_seen': 394208, 'step': 9900, 'algorithm': 'activity_selector'}
I0714 12:09:18.987351 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0714 12:09:20.261267 132935198687872 run.py:687] Algo activity_selector step 9950 current loss 0.387722, current_train_items 396176.
I0714 12:09:20.309216 132935198687872 run.py:722] (val) algo activity_selector step 9950: {'selected': 0.9606299212598425, 'score': 0.9606299212598425, 'examples_seen': 396176, 'step': 9950, 'algorithm': 'activity_selector'}
I0714 12:09:20.309472 132935198687872 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0714 12:09:21.517801 132935198687872 run.py:752] Restoring best model from checkpoint...
I0714 12:09:23.650401 132935198687872 run.py:767] (test) algo activity_selector : {'selected': 0.9522058823529412, 'score': 0.9522058823529412, 'examples_seen': 398112, 'step': 10000, 'algorithm': 'activity_selector'}
I0714 12:09:23.650590 132935198687872 run.py:769] Done!
