I0810 12:11:11.429372 125868344960512 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0810 12:11:11.430078 125868344960512 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0810 12:11:11.657297 125868344960512 run.py:410] Model: f2 ['find_maximum_subarray_kadane']
I0810 12:11:11.657396 125868344960512 run.py:412] algorithms ['find_maximum_subarray_kadane']
I0810 12:11:11.657584 125868344960512 run.py:413] train_lengths [-1]
I0810 12:11:11.657621 125868344960512 run.py:414] train_batch_size 16
I0810 12:11:11.657716 125868344960512 run.py:415] val_batch_size 8
I0810 12:11:11.657747 125868344960512 run.py:416] test_batch_size 8
I0810 12:11:11.657776 125868344960512 run.py:417] chunked_training True
I0810 12:11:11.657900 125868344960512 run.py:418] chunk_length 16
I0810 12:11:11.657930 125868344960512 run.py:419] train_steps 10000
I0810 12:11:11.657960 125868344960512 run.py:420] eval_every 50
I0810 12:11:11.657989 125868344960512 run.py:421] test_every 500
I0810 12:11:11.658020 125868344960512 run.py:422] learning_rate 0.001
I0810 12:11:11.658106 125868344960512 run.py:423] grad_clip_max_norm 1.0
I0810 12:11:11.658135 125868344960512 run.py:424] dropout_prob 0.1
I0810 12:11:11.658164 125868344960512 run.py:425] hint_teacher_forcing 0.0
I0810 12:11:11.658194 125868344960512 run.py:426] hint_mode encoded_decoded
I0810 12:11:11.658299 125868344960512 run.py:427] hint_repred_mode hard_on_eval
I0810 12:11:11.658331 125868344960512 run.py:428] use_ln False
I0810 12:11:11.658362 125868344960512 run.py:429] use_lstm True
I0810 12:11:11.658390 125868344960512 run.py:430] nb_triplet_fts 8
I0810 12:11:11.658418 125868344960512 run.py:431] encoder_init xavier_on_scalars
I0810 12:11:11.658446 125868344960512 run.py:432] processor_type f2
I0810 12:11:11.658473 125868344960512 run.py:433] checkpoint_path CLRS30
I0810 12:11:11.658501 125868344960512 run.py:434] dataset_path CLRS30
I0810 12:11:11.658540 125868344960512 run.py:435] freeze_processor False
I0810 12:11:11.658571 125868344960512 run.py:436] reduction max
I0810 12:11:11.658600 125868344960512 run.py:437] activation elu
I0810 12:11:11.658627 125868344960512 run.py:438] restore_model 
I0810 12:11:11.658655 125868344960512 run.py:439] gated True
I0810 12:11:11.658683 125868344960512 run.py:440] gated_activation sigmoid
I0810 12:11:11.661312 125868344960512 run.py:466] Creating samplers for algo find_maximum_subarray_kadane
I0810 12:11:11.661425 125868344960512 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0810 12:11:11.662079 125868344960512 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/find_maximum_subarray_kadane_train/1.0.0
I0810 12:11:11.665874 125868344960512 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/find_maximum_subarray_kadane_train/1.0.0
I0810 12:11:11.669586 125868344960512 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/find_maximum_subarray_kadane_train/1.0.0.
I0810 12:11:11.729355 125868344960512 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split train, from CLRS30/CLRS30_v1.0.0/clrs_dataset/find_maximum_subarray_kadane_train/1.0.0
W0810 12:11:11.750539 125868344960512 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x72797d78ee80> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0810 12:11:11.844732 125868344960512 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0810 12:11:11.845337 125868344960512 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/find_maximum_subarray_kadane_val/1.0.0
I0810 12:11:11.848432 125868344960512 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/find_maximum_subarray_kadane_val/1.0.0
I0810 12:11:11.850370 125868344960512 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/find_maximum_subarray_kadane_val/1.0.0.
I0810 12:11:11.888219 125868344960512 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split val, from CLRS30/CLRS30_v1.0.0/clrs_dataset/find_maximum_subarray_kadane_val/1.0.0
I0810 12:11:11.983651 125868344960512 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0810 12:11:11.984208 125868344960512 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/find_maximum_subarray_kadane_test/1.0.0
I0810 12:11:11.987220 125868344960512 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/find_maximum_subarray_kadane_test/1.0.0
I0810 12:11:11.989320 125868344960512 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/find_maximum_subarray_kadane_test/1.0.0.
I0810 12:11:12.026817 125868344960512 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/find_maximum_subarray_kadane_test/1.0.0
I0810 12:11:35.808912 125868344960512 run.py:689] Algo find_maximum_subarray_kadane step 0 current loss 23.269957, current_train_items 16.
