I0810 14:03:58.213894 140715125806592 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0810 14:03:58.214513 140715125806592 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0810 14:03:58.448896 140715125806592 run.py:410] Model: f2 ['optimal_bst']
I0810 14:03:58.448994 140715125806592 run.py:412] algorithms ['optimal_bst']
I0810 14:03:58.449169 140715125806592 run.py:413] train_lengths [-1]
I0810 14:03:58.449206 140715125806592 run.py:414] train_batch_size 16
I0810 14:03:58.449302 140715125806592 run.py:415] val_batch_size 8
I0810 14:03:58.449334 140715125806592 run.py:416] test_batch_size 8
I0810 14:03:58.449363 140715125806592 run.py:417] chunked_training True
I0810 14:03:58.449481 140715125806592 run.py:418] chunk_length 16
I0810 14:03:58.449511 140715125806592 run.py:419] train_steps 10000
I0810 14:03:58.449550 140715125806592 run.py:420] eval_every 50
I0810 14:03:58.449582 140715125806592 run.py:421] test_every 500
I0810 14:03:58.449612 140715125806592 run.py:422] learning_rate 0.001
I0810 14:03:58.449705 140715125806592 run.py:423] grad_clip_max_norm 1.0
I0810 14:03:58.449735 140715125806592 run.py:424] dropout_prob 0.1
I0810 14:03:58.449764 140715125806592 run.py:425] hint_teacher_forcing 0.0
I0810 14:03:58.449795 140715125806592 run.py:426] hint_mode encoded_decoded
I0810 14:03:58.449900 140715125806592 run.py:427] hint_repred_mode hard_on_eval
I0810 14:03:58.449929 140715125806592 run.py:428] use_ln False
I0810 14:03:58.449958 140715125806592 run.py:429] use_lstm True
I0810 14:03:58.449986 140715125806592 run.py:430] nb_triplet_fts 8
I0810 14:03:58.450017 140715125806592 run.py:431] encoder_init xavier_on_scalars
I0810 14:03:58.450045 140715125806592 run.py:432] processor_type f2
I0810 14:03:58.450073 140715125806592 run.py:433] checkpoint_path CLRS30
I0810 14:03:58.450100 140715125806592 run.py:434] dataset_path CLRS30
I0810 14:03:58.450129 140715125806592 run.py:435] freeze_processor False
I0810 14:03:58.450157 140715125806592 run.py:436] reduction max
I0810 14:03:58.450186 140715125806592 run.py:437] activation elu
I0810 14:03:58.450214 140715125806592 run.py:438] restore_model 
I0810 14:03:58.450241 140715125806592 run.py:439] gated True
I0810 14:03:58.450272 140715125806592 run.py:440] gated_activation sigmoid
I0810 14:03:58.452939 140715125806592 run.py:466] Creating samplers for algo optimal_bst
I0810 14:03:58.453061 140715125806592 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0810 14:03:58.453741 140715125806592 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/optimal_bst_train/1.0.0
I0810 14:03:58.456916 140715125806592 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/optimal_bst_train/1.0.0
I0810 14:03:58.460233 140715125806592 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/optimal_bst_train/1.0.0.
I0810 14:03:58.512753 140715125806592 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split train, from CLRS30/CLRS30_v1.0.0/clrs_dataset/optimal_bst_train/1.0.0
W0810 14:03:58.533621 140715125806592 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x7ffa4689ae80> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0810 14:03:58.616251 140715125806592 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0810 14:03:58.616866 140715125806592 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/optimal_bst_val/1.0.0
I0810 14:03:58.619755 140715125806592 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/optimal_bst_val/1.0.0
I0810 14:03:58.621868 140715125806592 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/optimal_bst_val/1.0.0.
I0810 14:03:58.656630 140715125806592 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split val, from CLRS30/CLRS30_v1.0.0/clrs_dataset/optimal_bst_val/1.0.0
I0810 14:03:58.740169 140715125806592 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0810 14:03:58.740736 140715125806592 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/optimal_bst_test/1.0.0
I0810 14:03:58.743493 140715125806592 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/optimal_bst_test/1.0.0
I0810 14:03:58.745637 140715125806592 reader.py:262] Creating a tf.data.Dataset reading 2 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/optimal_bst_test/1.0.0.
I0810 14:03:58.780250 140715125806592 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/optimal_bst_test/1.0.0
I0810 14:04:28.855003 140715125806592 run.py:689] Algo optimal_bst step 0 current loss 8.276656, current_train_items 16.
