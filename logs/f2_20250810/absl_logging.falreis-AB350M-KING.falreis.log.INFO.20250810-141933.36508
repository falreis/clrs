I0810 14:19:35.596719 127327579846144 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0810 14:19:35.597413 127327579846144 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0810 14:19:35.829766 127327579846144 run.py:410] Model: f2 ['segments_intersect']
I0810 14:19:35.829870 127327579846144 run.py:412] algorithms ['segments_intersect']
I0810 14:19:35.830045 127327579846144 run.py:413] train_lengths [-1]
I0810 14:19:35.830083 127327579846144 run.py:414] train_batch_size 16
I0810 14:19:35.830178 127327579846144 run.py:415] val_batch_size 8
I0810 14:19:35.830210 127327579846144 run.py:416] test_batch_size 8
I0810 14:19:35.830240 127327579846144 run.py:417] chunked_training True
I0810 14:19:35.830367 127327579846144 run.py:418] chunk_length 16
I0810 14:19:35.830397 127327579846144 run.py:419] train_steps 10000
I0810 14:19:35.830430 127327579846144 run.py:420] eval_every 50
I0810 14:19:35.830460 127327579846144 run.py:421] test_every 500
I0810 14:19:35.830490 127327579846144 run.py:422] learning_rate 0.001
I0810 14:19:35.830595 127327579846144 run.py:423] grad_clip_max_norm 1.0
I0810 14:19:35.830628 127327579846144 run.py:424] dropout_prob 0.1
I0810 14:19:35.830659 127327579846144 run.py:425] hint_teacher_forcing 0.0
I0810 14:19:35.830688 127327579846144 run.py:426] hint_mode encoded_decoded
I0810 14:19:35.830795 127327579846144 run.py:427] hint_repred_mode hard_on_eval
I0810 14:19:35.830825 127327579846144 run.py:428] use_ln False
I0810 14:19:35.830853 127327579846144 run.py:429] use_lstm True
I0810 14:19:35.830882 127327579846144 run.py:430] nb_triplet_fts 8
I0810 14:19:35.830909 127327579846144 run.py:431] encoder_init xavier_on_scalars
I0810 14:19:35.830937 127327579846144 run.py:432] processor_type f2
I0810 14:19:35.830967 127327579846144 run.py:433] checkpoint_path CLRS30
I0810 14:19:35.830996 127327579846144 run.py:434] dataset_path CLRS30
I0810 14:19:35.831024 127327579846144 run.py:435] freeze_processor False
I0810 14:19:35.831053 127327579846144 run.py:436] reduction max
I0810 14:19:35.831082 127327579846144 run.py:437] activation elu
I0810 14:19:35.831113 127327579846144 run.py:438] restore_model 
I0810 14:19:35.831142 127327579846144 run.py:439] gated True
I0810 14:19:35.831170 127327579846144 run.py:440] gated_activation sigmoid
I0810 14:19:35.833910 127327579846144 run.py:466] Creating samplers for algo segments_intersect
I0810 14:19:35.834020 127327579846144 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0810 14:19:35.834682 127327579846144 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/segments_intersect_train/1.0.0
I0810 14:19:35.838074 127327579846144 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/segments_intersect_train/1.0.0
I0810 14:19:35.841407 127327579846144 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/segments_intersect_train/1.0.0.
I0810 14:19:35.895308 127327579846144 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split train, from CLRS30/CLRS30_v1.0.0/clrs_dataset/segments_intersect_train/1.0.0
W0810 14:19:35.916269 127327579846144 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x73cd3e9bed40> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0810 14:19:36.002579 127327579846144 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0810 14:19:36.003187 127327579846144 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/segments_intersect_val/1.0.0
I0810 14:19:36.006199 127327579846144 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/segments_intersect_val/1.0.0
I0810 14:19:36.008822 127327579846144 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/segments_intersect_val/1.0.0.
I0810 14:19:36.043480 127327579846144 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split val, from CLRS30/CLRS30_v1.0.0/clrs_dataset/segments_intersect_val/1.0.0
I0810 14:19:36.127156 127327579846144 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0810 14:19:36.127731 127327579846144 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/segments_intersect_test/1.0.0
I0810 14:19:36.130419 127327579846144 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/segments_intersect_test/1.0.0
I0810 14:19:36.132400 127327579846144 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/segments_intersect_test/1.0.0.
I0810 14:19:36.166812 127327579846144 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/segments_intersect_test/1.0.0
