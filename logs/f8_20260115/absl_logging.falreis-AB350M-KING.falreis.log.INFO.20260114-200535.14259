I0114 20:05:38.617734 125612664464896 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0114 20:05:38.618525 125612664464896 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0114 20:05:38.856405 125612664464896 run.py:462] Model: f8 ['activity_selector']
I0114 20:05:38.856518 125612664464896 run.py:464] algorithms ['activity_selector']
I0114 20:05:38.856746 125612664464896 run.py:465] train_lengths ['4', '7', '11', '13', '16']
I0114 20:05:38.856799 125612664464896 run.py:466] train_batch_size 16
I0114 20:05:38.856931 125612664464896 run.py:467] val_batch_size 16
I0114 20:05:38.856976 125612664464896 run.py:468] test_batch_size 16
I0114 20:05:38.857016 125612664464896 run.py:469] chunked_training True
I0114 20:05:38.857194 125612664464896 run.py:470] chunk_length 16
I0114 20:05:38.857239 125612664464896 run.py:471] train_steps 10000
I0114 20:05:38.857281 125612664464896 run.py:472] eval_every 50
I0114 20:05:38.857320 125612664464896 run.py:473] test_every 500
I0114 20:05:38.857359 125612664464896 run.py:474] hidden_size 256
I0114 20:05:38.857402 125612664464896 run.py:475] nb_msg_passing_steps 1
I0114 20:05:38.857442 125612664464896 run.py:476] learning_rate 0.001
I0114 20:05:38.857568 125612664464896 run.py:477] grad_clip_max_norm 1.0
I0114 20:05:38.857609 125612664464896 run.py:478] dropout_prob 0.0
I0114 20:05:38.857648 125612664464896 run.py:479] hint_teacher_forcing 0.0
I0114 20:05:38.857691 125612664464896 run.py:480] hint_mode encoded_decoded
I0114 20:05:38.857838 125612664464896 run.py:481] hint_repred_mode soft
I0114 20:05:38.857878 125612664464896 run.py:482] use_ln True
I0114 20:05:38.857917 125612664464896 run.py:483] use_lstm True
I0114 20:05:38.857954 125612664464896 run.py:484] nb_triplet_fts 16
I0114 20:05:38.857998 125612664464896 run.py:485] encoder_init xavier_on_scalars
I0114 20:05:38.858037 125612664464896 run.py:486] processor_type f8
I0114 20:05:38.858086 125612664464896 run.py:487] checkpoint_path CLRS30
I0114 20:05:38.858127 125612664464896 run.py:488] dataset_path CLRS30
I0114 20:05:38.858170 125612664464896 run.py:489] freeze_processor False
I0114 20:05:38.858210 125612664464896 run.py:490] reduction min
I0114 20:05:38.858249 125612664464896 run.py:491] activation elu
I0114 20:05:38.858291 125612664464896 run.py:492] restore_model 
I0114 20:05:38.858331 125612664464896 run.py:493] gated True
I0114 20:05:38.858370 125612664464896 run.py:494] gated_activation tanh
I0114 20:05:38.858408 125612664464896 run.py:495] memory_type mha
I0114 20:05:38.858452 125612664464896 run.py:496] memory_size 16
I0114 20:05:38.861203 125612664464896 run.py:522] Creating samplers for algo activity_selector
W0114 20:05:38.861416 125612664464896 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0114 20:05:38.861734 125612664464896 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0114 20:05:39.072413 125612664464896 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0114 20:05:39.317755 125612664464896 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0114 20:05:39.619562 125612664464896 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0114 20:05:39.955080 125612664464896 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0114 20:05:40.341857 125612664464896 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0114 20:05:40.342168 125612664464896 samplers.py:124] Creating a dataset with 64 samples.
I0114 20:05:40.368373 125612664464896 run.py:306] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0114 20:05:40.369083 125612664464896 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0114 20:05:40.372358 125612664464896 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0114 20:05:40.375497 125612664464896 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0114 20:05:40.427344 125612664464896 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W0114 20:05:40.448504 125612664464896 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x723df5ac14e0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0114 20:06:26.016947 125612664464896 run.py:748] Algo activity_selector step 0 current loss 5.365570, current_train_items 32.
I0114 20:06:34.734666 125612664464896 run.py:783] (val) algo activity_selector step 0: {'selected': 0.12541254125412543, 'score': 0.12541254125412543, 'examples_seen': 32, 'step': 0, 'algorithm': 'activity_selector'}
I0114 20:06:34.734872 125612664464896 run.py:804] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.125, val scores are: activity_selector: 0.125
I0114 20:07:52.295991 125612664464896 run.py:748] Algo activity_selector step 50 current loss 3.769551, current_train_items 1408.
I0114 20:07:52.499332 125612664464896 run.py:783] (val) algo activity_selector step 50: {'selected': 0.718052738336714, 'score': 0.718052738336714, 'examples_seen': 1408, 'step': 50, 'algorithm': 'activity_selector'}
I0114 20:07:52.499576 125612664464896 run.py:804] Checkpointing best model, best avg val score was 0.125, current avg val score is 0.718, val scores are: activity_selector: 0.718
I0114 20:07:54.109363 125612664464896 run.py:748] Algo activity_selector step 100 current loss 3.598384, current_train_items 2800.
I0114 20:07:54.329741 125612664464896 run.py:783] (val) algo activity_selector step 100: {'selected': 0.7099567099567099, 'score': 0.7099567099567099, 'examples_seen': 2800, 'step': 100, 'algorithm': 'activity_selector'}
I0114 20:07:54.329975 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.718, current avg val score is 0.710, val scores are: activity_selector: 0.710
I0114 20:07:55.769981 125612664464896 run.py:748] Algo activity_selector step 150 current loss 3.035319, current_train_items 4176.
I0114 20:07:55.979266 125612664464896 run.py:783] (val) algo activity_selector step 150: {'selected': 0.7408906882591093, 'score': 0.7408906882591093, 'examples_seen': 4176, 'step': 150, 'algorithm': 'activity_selector'}
I0114 20:07:55.979527 125612664464896 run.py:804] Checkpointing best model, best avg val score was 0.718, current avg val score is 0.741, val scores are: activity_selector: 0.741
I0114 20:07:57.544582 125612664464896 run.py:748] Algo activity_selector step 200 current loss 2.486023, current_train_items 5536.
I0114 20:07:57.777113 125612664464896 run.py:783] (val) algo activity_selector step 200: {'selected': 0.7901234567901234, 'score': 0.7901234567901234, 'examples_seen': 5536, 'step': 200, 'algorithm': 'activity_selector'}
I0114 20:07:57.777351 125612664464896 run.py:804] Checkpointing best model, best avg val score was 0.741, current avg val score is 0.790, val scores are: activity_selector: 0.790
I0114 20:07:59.382175 125612664464896 run.py:748] Algo activity_selector step 250 current loss 3.014295, current_train_items 6944.
I0114 20:07:59.586122 125612664464896 run.py:783] (val) algo activity_selector step 250: {'selected': 0.6774193548387097, 'score': 0.6774193548387097, 'examples_seen': 6944, 'step': 250, 'algorithm': 'activity_selector'}
I0114 20:07:59.586411 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.790, current avg val score is 0.677, val scores are: activity_selector: 0.677
I0114 20:08:01.042671 125612664464896 run.py:748] Algo activity_selector step 300 current loss 2.138549, current_train_items 8304.
I0114 20:08:01.230152 125612664464896 run.py:783] (val) algo activity_selector step 300: {'selected': 0.7224489795918368, 'score': 0.7224489795918368, 'examples_seen': 8304, 'step': 300, 'algorithm': 'activity_selector'}
I0114 20:08:01.230514 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.790, current avg val score is 0.722, val scores are: activity_selector: 0.722
I0114 20:08:02.653232 125612664464896 run.py:748] Algo activity_selector step 350 current loss 1.800263, current_train_items 9680.
I0114 20:08:02.857697 125612664464896 run.py:783] (val) algo activity_selector step 350: {'selected': 0.8357588357588357, 'score': 0.8357588357588357, 'examples_seen': 9680, 'step': 350, 'algorithm': 'activity_selector'}
I0114 20:08:02.857961 125612664464896 run.py:804] Checkpointing best model, best avg val score was 0.790, current avg val score is 0.836, val scores are: activity_selector: 0.836
I0114 20:08:04.450404 125612664464896 run.py:748] Algo activity_selector step 400 current loss 2.070817, current_train_items 11072.
I0114 20:08:04.661448 125612664464896 run.py:783] (val) algo activity_selector step 400: {'selected': 0.8290909090909091, 'score': 0.8290909090909091, 'examples_seen': 11072, 'step': 400, 'algorithm': 'activity_selector'}
I0114 20:08:04.661769 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.836, current avg val score is 0.829, val scores are: activity_selector: 0.829
I0114 20:08:06.068703 125612664464896 run.py:748] Algo activity_selector step 450 current loss 1.654485, current_train_items 12448.
I0114 20:08:06.306828 125612664464896 run.py:783] (val) algo activity_selector step 450: {'selected': 0.8560885608856088, 'score': 0.8560885608856088, 'examples_seen': 12448, 'step': 450, 'algorithm': 'activity_selector'}
I0114 20:08:06.307083 125612664464896 run.py:804] Checkpointing best model, best avg val score was 0.836, current avg val score is 0.856, val scores are: activity_selector: 0.856
I0114 20:08:07.875774 125612664464896 run.py:748] Algo activity_selector step 500 current loss 1.867046, current_train_items 13824.
I0114 20:08:08.102894 125612664464896 run.py:783] (val) algo activity_selector step 500: {'selected': 0.8201160541586073, 'score': 0.8201160541586073, 'examples_seen': 13824, 'step': 500, 'algorithm': 'activity_selector'}
I0114 20:08:08.103061 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.856, current avg val score is 0.820, val scores are: activity_selector: 0.820
I0114 20:08:09.526573 125612664464896 run.py:748] Algo activity_selector step 550 current loss 2.052486, current_train_items 15200.
I0114 20:08:09.727226 125612664464896 run.py:783] (val) algo activity_selector step 550: {'selected': 0.8257261410788382, 'score': 0.8257261410788382, 'examples_seen': 15200, 'step': 550, 'algorithm': 'activity_selector'}
I0114 20:08:09.727565 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.856, current avg val score is 0.826, val scores are: activity_selector: 0.826
I0114 20:08:11.132218 125612664464896 run.py:748] Algo activity_selector step 600 current loss 1.494945, current_train_items 16576.
I0114 20:08:11.372825 125612664464896 run.py:783] (val) algo activity_selector step 600: {'selected': 0.9052224371373307, 'score': 0.9052224371373307, 'examples_seen': 16576, 'step': 600, 'algorithm': 'activity_selector'}
I0114 20:08:11.373075 125612664464896 run.py:804] Checkpointing best model, best avg val score was 0.856, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0114 20:08:12.967500 125612664464896 run.py:748] Algo activity_selector step 650 current loss 1.669789, current_train_items 17952.
I0114 20:08:13.172628 125612664464896 run.py:783] (val) algo activity_selector step 650: {'selected': 0.9024856596558316, 'score': 0.9024856596558316, 'examples_seen': 17952, 'step': 650, 'algorithm': 'activity_selector'}
I0114 20:08:13.172859 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.905, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0114 20:08:14.584494 125612664464896 run.py:748] Algo activity_selector step 700 current loss 1.648267, current_train_items 19344.
I0114 20:08:14.804193 125612664464896 run.py:783] (val) algo activity_selector step 700: {'selected': 0.8301158301158301, 'score': 0.8301158301158301, 'examples_seen': 19344, 'step': 700, 'algorithm': 'activity_selector'}
I0114 20:08:14.804420 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.905, current avg val score is 0.830, val scores are: activity_selector: 0.830
I0114 20:08:16.209975 125612664464896 run.py:748] Algo activity_selector step 750 current loss 1.574021, current_train_items 20720.
I0114 20:08:16.451860 125612664464896 run.py:783] (val) algo activity_selector step 750: {'selected': 0.8428571428571427, 'score': 0.8428571428571427, 'examples_seen': 20720, 'step': 750, 'algorithm': 'activity_selector'}
I0114 20:08:16.452119 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.905, current avg val score is 0.843, val scores are: activity_selector: 0.843
I0114 20:08:17.877402 125612664464896 run.py:748] Algo activity_selector step 800 current loss 1.605210, current_train_items 22096.
I0114 20:08:18.091142 125612664464896 run.py:783] (val) algo activity_selector step 800: {'selected': 0.919626168224299, 'score': 0.919626168224299, 'examples_seen': 22096, 'step': 800, 'algorithm': 'activity_selector'}
I0114 20:08:18.091372 125612664464896 run.py:804] Checkpointing best model, best avg val score was 0.905, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0114 20:08:19.662072 125612664464896 run.py:748] Algo activity_selector step 850 current loss 1.498566, current_train_items 23472.
I0114 20:08:19.891745 125612664464896 run.py:783] (val) algo activity_selector step 850: {'selected': 0.8280254777070063, 'score': 0.8280254777070063, 'examples_seen': 23472, 'step': 850, 'algorithm': 'activity_selector'}
I0114 20:08:19.891985 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.920, current avg val score is 0.828, val scores are: activity_selector: 0.828
I0114 20:08:21.332048 125612664464896 run.py:748] Algo activity_selector step 900 current loss 1.647150, current_train_items 24848.
I0114 20:08:21.544636 125612664464896 run.py:783] (val) algo activity_selector step 900: {'selected': 0.8628230616302187, 'score': 0.8628230616302187, 'examples_seen': 24848, 'step': 900, 'algorithm': 'activity_selector'}
I0114 20:08:21.544867 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.920, current avg val score is 0.863, val scores are: activity_selector: 0.863
I0114 20:08:22.946259 125612664464896 run.py:748] Algo activity_selector step 950 current loss 1.317713, current_train_items 26224.
I0114 20:08:23.184941 125612664464896 run.py:783] (val) algo activity_selector step 950: {'selected': 0.8862745098039215, 'score': 0.8862745098039215, 'examples_seen': 26224, 'step': 950, 'algorithm': 'activity_selector'}
I0114 20:08:23.185199 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.920, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0114 20:08:24.583800 125612664464896 run.py:748] Algo activity_selector step 1000 current loss 1.441715, current_train_items 27616.
I0114 20:08:24.820462 125612664464896 run.py:783] (val) algo activity_selector step 1000: {'selected': 0.9051094890510948, 'score': 0.9051094890510948, 'examples_seen': 27616, 'step': 1000, 'algorithm': 'activity_selector'}
I0114 20:08:24.820690 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.920, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0114 20:08:26.272871 125612664464896 run.py:748] Algo activity_selector step 1050 current loss 1.784129, current_train_items 28992.
I0114 20:08:26.467502 125612664464896 run.py:783] (val) algo activity_selector step 1050: {'selected': 0.896551724137931, 'score': 0.896551724137931, 'examples_seen': 28992, 'step': 1050, 'algorithm': 'activity_selector'}
I0114 20:08:26.467760 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.920, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0114 20:08:27.867522 125612664464896 run.py:748] Algo activity_selector step 1100 current loss 1.254966, current_train_items 30368.
I0114 20:08:28.104547 125612664464896 run.py:783] (val) algo activity_selector step 1100: {'selected': 0.8312757201646092, 'score': 0.8312757201646092, 'examples_seen': 30368, 'step': 1100, 'algorithm': 'activity_selector'}
I0114 20:08:28.104775 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.920, current avg val score is 0.831, val scores are: activity_selector: 0.831
I0114 20:08:29.529289 125612664464896 run.py:748] Algo activity_selector step 1150 current loss 1.530229, current_train_items 31760.
I0114 20:08:29.741719 125612664464896 run.py:783] (val) algo activity_selector step 1150: {'selected': 0.8773946360153256, 'score': 0.8773946360153256, 'examples_seen': 31760, 'step': 1150, 'algorithm': 'activity_selector'}
I0114 20:08:29.741948 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.920, current avg val score is 0.877, val scores are: activity_selector: 0.877
I0114 20:08:31.176699 125612664464896 run.py:748] Algo activity_selector step 1200 current loss 1.288696, current_train_items 33120.
I0114 20:08:31.397148 125612664464896 run.py:783] (val) algo activity_selector step 1200: {'selected': 0.9037328094302554, 'score': 0.9037328094302554, 'examples_seen': 33120, 'step': 1200, 'algorithm': 'activity_selector'}
I0114 20:08:31.397400 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.920, current avg val score is 0.904, val scores are: activity_selector: 0.904
I0114 20:08:32.806535 125612664464896 run.py:748] Algo activity_selector step 1250 current loss 1.273066, current_train_items 34496.
I0114 20:08:33.039423 125612664464896 run.py:783] (val) algo activity_selector step 1250: {'selected': 0.8798370672097761, 'score': 0.8798370672097761, 'examples_seen': 34496, 'step': 1250, 'algorithm': 'activity_selector'}
I0114 20:08:33.039652 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.920, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0114 20:08:34.439116 125612664464896 run.py:748] Algo activity_selector step 1300 current loss 1.257062, current_train_items 35888.
I0114 20:08:34.682881 125612664464896 run.py:783] (val) algo activity_selector step 1300: {'selected': 0.896551724137931, 'score': 0.896551724137931, 'examples_seen': 35888, 'step': 1300, 'algorithm': 'activity_selector'}
I0114 20:08:34.683129 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.920, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0114 20:08:36.130971 125612664464896 run.py:748] Algo activity_selector step 1350 current loss 1.136881, current_train_items 37264.
I0114 20:08:36.327473 125612664464896 run.py:783] (val) algo activity_selector step 1350: {'selected': 0.8457350272232305, 'score': 0.8457350272232305, 'examples_seen': 37264, 'step': 1350, 'algorithm': 'activity_selector'}
I0114 20:08:36.327702 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.920, current avg val score is 0.846, val scores are: activity_selector: 0.846
I0114 20:08:37.758148 125612664464896 run.py:748] Algo activity_selector step 1400 current loss 1.269132, current_train_items 38640.
I0114 20:08:37.963650 125612664464896 run.py:783] (val) algo activity_selector step 1400: {'selected': 0.9383177570093458, 'score': 0.9383177570093458, 'examples_seen': 38640, 'step': 1400, 'algorithm': 'activity_selector'}
I0114 20:08:37.963891 125612664464896 run.py:804] Checkpointing best model, best avg val score was 0.920, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0114 20:08:39.540731 125612664464896 run.py:748] Algo activity_selector step 1450 current loss 1.308440, current_train_items 40016.
I0114 20:08:39.771988 125612664464896 run.py:783] (val) algo activity_selector step 1450: {'selected': 0.8810408921933085, 'score': 0.8810408921933085, 'examples_seen': 40016, 'step': 1450, 'algorithm': 'activity_selector'}
I0114 20:08:39.772238 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.881, val scores are: activity_selector: 0.881
I0114 20:08:41.215750 125612664464896 run.py:748] Algo activity_selector step 1500 current loss 1.299215, current_train_items 41408.
I0114 20:08:41.430105 125612664464896 run.py:783] (val) algo activity_selector step 1500: {'selected': 0.8553719008264463, 'score': 0.8553719008264463, 'examples_seen': 41408, 'step': 1500, 'algorithm': 'activity_selector'}
I0114 20:08:41.430362 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.855, val scores are: activity_selector: 0.855
I0114 20:08:42.827743 125612664464896 run.py:748] Algo activity_selector step 1550 current loss 1.354517, current_train_items 42768.
I0114 20:08:43.064957 125612664464896 run.py:783] (val) algo activity_selector step 1550: {'selected': 0.9279437609841827, 'score': 0.9279437609841827, 'examples_seen': 42768, 'step': 1550, 'algorithm': 'activity_selector'}
I0114 20:08:43.065211 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0114 20:08:44.503201 125612664464896 run.py:748] Algo activity_selector step 1600 current loss 1.055417, current_train_items 44160.
I0114 20:08:44.702321 125612664464896 run.py:783] (val) algo activity_selector step 1600: {'selected': 0.8662674650698602, 'score': 0.8662674650698602, 'examples_seen': 44160, 'step': 1600, 'algorithm': 'activity_selector'}
I0114 20:08:44.702555 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.866, val scores are: activity_selector: 0.866
I0114 20:08:46.126543 125612664464896 run.py:748] Algo activity_selector step 1650 current loss 1.093047, current_train_items 45536.
I0114 20:08:46.343839 125612664464896 run.py:783] (val) algo activity_selector step 1650: {'selected': 0.8979591836734694, 'score': 0.8979591836734694, 'examples_seen': 45536, 'step': 1650, 'algorithm': 'activity_selector'}
I0114 20:08:46.344233 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0114 20:08:47.762200 125612664464896 run.py:748] Algo activity_selector step 1700 current loss 0.873723, current_train_items 46896.
I0114 20:08:47.981891 125612664464896 run.py:783] (val) algo activity_selector step 1700: {'selected': 0.9378757515030061, 'score': 0.9378757515030061, 'examples_seen': 46896, 'step': 1700, 'algorithm': 'activity_selector'}
I0114 20:08:47.982135 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0114 20:08:49.407648 125612664464896 run.py:748] Algo activity_selector step 1750 current loss 1.445580, current_train_items 48304.
I0114 20:08:49.622917 125612664464896 run.py:783] (val) algo activity_selector step 1750: {'selected': 0.9108910891089109, 'score': 0.9108910891089109, 'examples_seen': 48304, 'step': 1750, 'algorithm': 'activity_selector'}
I0114 20:08:49.623202 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0114 20:08:51.057659 125612664464896 run.py:748] Algo activity_selector step 1800 current loss 1.281671, current_train_items 49664.
I0114 20:08:51.261474 125612664464896 run.py:783] (val) algo activity_selector step 1800: {'selected': 0.9323308270676692, 'score': 0.9323308270676692, 'examples_seen': 49664, 'step': 1800, 'algorithm': 'activity_selector'}
I0114 20:08:51.261790 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0114 20:08:52.671477 125612664464896 run.py:748] Algo activity_selector step 1850 current loss 0.940764, current_train_items 51056.
I0114 20:08:52.888091 125612664464896 run.py:783] (val) algo activity_selector step 1850: {'selected': 0.8496503496503496, 'score': 0.8496503496503496, 'examples_seen': 51056, 'step': 1850, 'algorithm': 'activity_selector'}
I0114 20:08:52.888325 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.850, val scores are: activity_selector: 0.850
I0114 20:08:54.286725 125612664464896 run.py:748] Algo activity_selector step 1900 current loss 0.930386, current_train_items 52432.
I0114 20:08:54.525332 125612664464896 run.py:783] (val) algo activity_selector step 1900: {'selected': 0.8686131386861313, 'score': 0.8686131386861313, 'examples_seen': 52432, 'step': 1900, 'algorithm': 'activity_selector'}
I0114 20:08:54.525566 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.938, current avg val score is 0.869, val scores are: activity_selector: 0.869
I0114 20:08:55.973729 125612664464896 run.py:748] Algo activity_selector step 1950 current loss 1.047663, current_train_items 53808.
I0114 20:08:56.175489 125612664464896 run.py:783] (val) algo activity_selector step 1950: {'selected': 0.9455909943714822, 'score': 0.9455909943714822, 'examples_seen': 53808, 'step': 1950, 'algorithm': 'activity_selector'}
I0114 20:08:56.175734 125612664464896 run.py:804] Checkpointing best model, best avg val score was 0.938, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0114 20:08:57.754427 125612664464896 run.py:748] Algo activity_selector step 2000 current loss 0.983328, current_train_items 55184.
I0114 20:08:57.986873 125612664464896 run.py:783] (val) algo activity_selector step 2000: {'selected': 0.9260700389105058, 'score': 0.9260700389105058, 'examples_seen': 55184, 'step': 2000, 'algorithm': 'activity_selector'}
I0114 20:08:57.987123 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.946, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0114 20:08:59.412027 125612664464896 run.py:748] Algo activity_selector step 2050 current loss 0.866802, current_train_items 56560.
I0114 20:08:59.620985 125612664464896 run.py:783] (val) algo activity_selector step 2050: {'selected': 0.9118198874296435, 'score': 0.9118198874296435, 'examples_seen': 56560, 'step': 2050, 'algorithm': 'activity_selector'}
I0114 20:08:59.621236 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.946, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0114 20:09:01.060903 125612664464896 run.py:748] Algo activity_selector step 2100 current loss 1.120690, current_train_items 57952.
I0114 20:09:01.272187 125612664464896 run.py:783] (val) algo activity_selector step 2100: {'selected': 0.8754863813229572, 'score': 0.8754863813229572, 'examples_seen': 57952, 'step': 2100, 'algorithm': 'activity_selector'}
I0114 20:09:01.272435 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.946, current avg val score is 0.875, val scores are: activity_selector: 0.875
I0114 20:09:02.699876 125612664464896 run.py:748] Algo activity_selector step 2150 current loss 1.060974, current_train_items 59312.
I0114 20:09:02.911935 125612664464896 run.py:783] (val) algo activity_selector step 2150: {'selected': 0.8844036697247707, 'score': 0.8844036697247707, 'examples_seen': 59312, 'step': 2150, 'algorithm': 'activity_selector'}
I0114 20:09:02.912187 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.946, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0114 20:09:04.327376 125612664464896 run.py:748] Algo activity_selector step 2200 current loss 1.176117, current_train_items 60720.
I0114 20:09:04.550262 125612664464896 run.py:783] (val) algo activity_selector step 2200: {'selected': 0.8952772073921972, 'score': 0.8952772073921972, 'examples_seen': 60720, 'step': 2200, 'algorithm': 'activity_selector'}
I0114 20:09:04.550488 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.946, current avg val score is 0.895, val scores are: activity_selector: 0.895
I0114 20:09:05.973899 125612664464896 run.py:748] Algo activity_selector step 2250 current loss 0.976857, current_train_items 62080.
I0114 20:09:06.197479 125612664464896 run.py:783] (val) algo activity_selector step 2250: {'selected': 0.9185185185185185, 'score': 0.9185185185185185, 'examples_seen': 62080, 'step': 2250, 'algorithm': 'activity_selector'}
I0114 20:09:06.197705 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.946, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0114 20:09:07.622828 125612664464896 run.py:748] Algo activity_selector step 2300 current loss 1.185953, current_train_items 63440.
I0114 20:09:07.831253 125612664464896 run.py:783] (val) algo activity_selector step 2300: {'selected': 0.875, 'score': 0.875, 'examples_seen': 63440, 'step': 2300, 'algorithm': 'activity_selector'}
I0114 20:09:07.831503 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.946, current avg val score is 0.875, val scores are: activity_selector: 0.875
I0114 20:09:09.221207 125612664464896 run.py:748] Algo activity_selector step 2350 current loss 0.994245, current_train_items 64848.
I0114 20:09:09.459674 125612664464896 run.py:783] (val) algo activity_selector step 2350: {'selected': 0.9716446124763706, 'score': 0.9716446124763706, 'examples_seen': 64848, 'step': 2350, 'algorithm': 'activity_selector'}
I0114 20:09:09.459906 125612664464896 run.py:804] Checkpointing best model, best avg val score was 0.946, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0114 20:09:11.074697 125612664464896 run.py:748] Algo activity_selector step 2400 current loss 0.901245, current_train_items 66208.
I0114 20:09:11.275319 125612664464896 run.py:783] (val) algo activity_selector step 2400: {'selected': 0.9283018867924527, 'score': 0.9283018867924527, 'examples_seen': 66208, 'step': 2400, 'algorithm': 'activity_selector'}
I0114 20:09:11.275551 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0114 20:09:12.679106 125612664464896 run.py:748] Algo activity_selector step 2450 current loss 1.165883, current_train_items 67600.
I0114 20:09:12.918402 125612664464896 run.py:783] (val) algo activity_selector step 2450: {'selected': 0.9369024856596557, 'score': 0.9369024856596557, 'examples_seen': 67600, 'step': 2450, 'algorithm': 'activity_selector'}
I0114 20:09:12.918635 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0114 20:09:14.342638 125612664464896 run.py:748] Algo activity_selector step 2500 current loss 0.949258, current_train_items 68976.
I0114 20:09:14.555527 125612664464896 run.py:783] (val) algo activity_selector step 2500: {'selected': 0.9369024856596558, 'score': 0.9369024856596558, 'examples_seen': 68976, 'step': 2500, 'algorithm': 'activity_selector'}
I0114 20:09:14.555777 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0114 20:09:15.992720 125612664464896 run.py:748] Algo activity_selector step 2550 current loss 1.033071, current_train_items 70352.
I0114 20:09:16.204791 125612664464896 run.py:783] (val) algo activity_selector step 2550: {'selected': 0.9256505576208178, 'score': 0.9256505576208178, 'examples_seen': 70352, 'step': 2550, 'algorithm': 'activity_selector'}
I0114 20:09:16.205043 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0114 20:09:17.619957 125612664464896 run.py:748] Algo activity_selector step 2600 current loss 0.928236, current_train_items 71728.
I0114 20:09:17.840970 125612664464896 run.py:783] (val) algo activity_selector step 2600: {'selected': 0.9065606361829026, 'score': 0.9065606361829026, 'examples_seen': 71728, 'step': 2600, 'algorithm': 'activity_selector'}
I0114 20:09:17.841216 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0114 20:09:19.245140 125612664464896 run.py:748] Algo activity_selector step 2650 current loss 0.985891, current_train_items 73104.
I0114 20:09:19.484910 125612664464896 run.py:783] (val) algo activity_selector step 2650: {'selected': 0.9101338432122371, 'score': 0.9101338432122371, 'examples_seen': 73104, 'step': 2650, 'algorithm': 'activity_selector'}
I0114 20:09:19.485160 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0114 20:09:20.899016 125612664464896 run.py:748] Algo activity_selector step 2700 current loss 1.041477, current_train_items 74496.
I0114 20:09:21.139634 125612664464896 run.py:783] (val) algo activity_selector step 2700: {'selected': 0.912280701754386, 'score': 0.912280701754386, 'examples_seen': 74496, 'step': 2700, 'algorithm': 'activity_selector'}
I0114 20:09:21.139861 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0114 20:09:22.571071 125612664464896 run.py:748] Algo activity_selector step 2750 current loss 0.971032, current_train_items 75856.
I0114 20:09:22.785046 125612664464896 run.py:783] (val) algo activity_selector step 2750: {'selected': 0.9152542372881356, 'score': 0.9152542372881356, 'examples_seen': 75856, 'step': 2750, 'algorithm': 'activity_selector'}
I0114 20:09:22.785314 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0114 20:09:24.189549 125612664464896 run.py:748] Algo activity_selector step 2800 current loss 0.801058, current_train_items 77264.
I0114 20:09:24.421560 125612664464896 run.py:783] (val) algo activity_selector step 2800: {'selected': 0.9041095890410958, 'score': 0.9041095890410958, 'examples_seen': 77264, 'step': 2800, 'algorithm': 'activity_selector'}
I0114 20:09:24.421789 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.904, val scores are: activity_selector: 0.904
I0114 20:09:25.835461 125612664464896 run.py:748] Algo activity_selector step 2850 current loss 0.997215, current_train_items 78624.
I0114 20:09:26.073888 125612664464896 run.py:783] (val) algo activity_selector step 2850: {'selected': 0.937007874015748, 'score': 0.937007874015748, 'examples_seen': 78624, 'step': 2850, 'algorithm': 'activity_selector'}
I0114 20:09:26.074041 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0114 20:09:27.477307 125612664464896 run.py:748] Algo activity_selector step 2900 current loss 0.924894, current_train_items 80000.
I0114 20:09:27.716132 125612664464896 run.py:783] (val) algo activity_selector step 2900: {'selected': 0.9022556390977443, 'score': 0.9022556390977443, 'examples_seen': 80000, 'step': 2900, 'algorithm': 'activity_selector'}
I0114 20:09:27.716475 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0114 20:09:29.148386 125612664464896 run.py:748] Algo activity_selector step 2950 current loss 0.821891, current_train_items 81392.
I0114 20:09:29.357978 125612664464896 run.py:783] (val) algo activity_selector step 2950: {'selected': 0.911764705882353, 'score': 0.911764705882353, 'examples_seen': 81392, 'step': 2950, 'algorithm': 'activity_selector'}
I0114 20:09:29.358223 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0114 20:09:30.799500 125612664464896 run.py:748] Algo activity_selector step 3000 current loss 1.230203, current_train_items 82752.
I0114 20:09:31.010188 125612664464896 run.py:783] (val) algo activity_selector step 3000: {'selected': 0.9384057971014493, 'score': 0.9384057971014493, 'examples_seen': 82752, 'step': 3000, 'algorithm': 'activity_selector'}
I0114 20:09:31.010376 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0114 20:09:32.425832 125612664464896 run.py:748] Algo activity_selector step 3050 current loss 0.755074, current_train_items 84144.
I0114 20:09:32.646628 125612664464896 run.py:783] (val) algo activity_selector step 3050: {'selected': 0.9608247422680413, 'score': 0.9608247422680413, 'examples_seen': 84144, 'step': 3050, 'algorithm': 'activity_selector'}
I0114 20:09:32.646864 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0114 20:09:34.077849 125612664464896 run.py:748] Algo activity_selector step 3100 current loss 0.900073, current_train_items 85520.
I0114 20:09:34.286942 125612664464896 run.py:783] (val) algo activity_selector step 3100: {'selected': 0.9007936507936508, 'score': 0.9007936507936508, 'examples_seen': 85520, 'step': 3100, 'algorithm': 'activity_selector'}
I0114 20:09:34.287188 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.901, val scores are: activity_selector: 0.901
I0114 20:09:35.727229 125612664464896 run.py:748] Algo activity_selector step 3150 current loss 0.892366, current_train_items 86896.
I0114 20:09:35.948466 125612664464896 run.py:783] (val) algo activity_selector step 3150: {'selected': 0.9205776173285198, 'score': 0.9205776173285198, 'examples_seen': 86896, 'step': 3150, 'algorithm': 'activity_selector'}
I0114 20:09:35.948701 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0114 20:09:37.394738 125612664464896 run.py:748] Algo activity_selector step 3200 current loss 1.020542, current_train_items 88272.
I0114 20:09:37.588513 125612664464896 run.py:783] (val) algo activity_selector step 3200: {'selected': 0.9243027888446216, 'score': 0.9243027888446216, 'examples_seen': 88272, 'step': 3200, 'algorithm': 'activity_selector'}
I0114 20:09:37.588764 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0114 20:09:39.024148 125612664464896 run.py:748] Algo activity_selector step 3250 current loss 1.085850, current_train_items 89664.
I0114 20:09:39.235525 125612664464896 run.py:783] (val) algo activity_selector step 3250: {'selected': 0.9153225806451613, 'score': 0.9153225806451613, 'examples_seen': 89664, 'step': 3250, 'algorithm': 'activity_selector'}
I0114 20:09:39.235677 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0114 20:09:40.676255 125612664464896 run.py:748] Algo activity_selector step 3300 current loss 0.852646, current_train_items 91040.
I0114 20:09:40.880851 125612664464896 run.py:783] (val) algo activity_selector step 3300: {'selected': 0.9362549800796812, 'score': 0.9362549800796812, 'examples_seen': 91040, 'step': 3300, 'algorithm': 'activity_selector'}
I0114 20:09:40.881091 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0114 20:09:42.310870 125612664464896 run.py:748] Algo activity_selector step 3350 current loss 0.956459, current_train_items 92400.
I0114 20:09:42.521654 125612664464896 run.py:783] (val) algo activity_selector step 3350: {'selected': 0.9083665338645419, 'score': 0.9083665338645419, 'examples_seen': 92400, 'step': 3350, 'algorithm': 'activity_selector'}
I0114 20:09:42.521846 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0114 20:09:43.954200 125612664464896 run.py:748] Algo activity_selector step 3400 current loss 1.204048, current_train_items 93792.
I0114 20:09:44.166016 125612664464896 run.py:783] (val) algo activity_selector step 3400: {'selected': 0.9233716475095785, 'score': 0.9233716475095785, 'examples_seen': 93792, 'step': 3400, 'algorithm': 'activity_selector'}
I0114 20:09:44.166266 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.923, val scores are: activity_selector: 0.923
I0114 20:09:45.604004 125612664464896 run.py:748] Algo activity_selector step 3450 current loss 1.054543, current_train_items 95168.
I0114 20:09:45.815531 125612664464896 run.py:783] (val) algo activity_selector step 3450: {'selected': 0.9080234833659491, 'score': 0.9080234833659491, 'examples_seen': 95168, 'step': 3450, 'algorithm': 'activity_selector'}
I0114 20:09:45.815693 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0114 20:09:47.211095 125612664464896 run.py:748] Algo activity_selector step 3500 current loss 0.755325, current_train_items 96544.
I0114 20:09:47.448865 125612664464896 run.py:783] (val) algo activity_selector step 3500: {'selected': 0.8990476190476191, 'score': 0.8990476190476191, 'examples_seen': 96544, 'step': 3500, 'algorithm': 'activity_selector'}
I0114 20:09:47.449116 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0114 20:09:48.853882 125612664464896 run.py:748] Algo activity_selector step 3550 current loss 0.935839, current_train_items 97936.
I0114 20:09:49.095872 125612664464896 run.py:783] (val) algo activity_selector step 3550: {'selected': 0.9178356713426853, 'score': 0.9178356713426853, 'examples_seen': 97936, 'step': 3550, 'algorithm': 'activity_selector'}
I0114 20:09:49.096225 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.918, val scores are: activity_selector: 0.918
I0114 20:09:50.528144 125612664464896 run.py:748] Algo activity_selector step 3600 current loss 0.962059, current_train_items 99312.
I0114 20:09:50.737702 125612664464896 run.py:783] (val) algo activity_selector step 3600: {'selected': 0.9430255402750491, 'score': 0.9430255402750491, 'examples_seen': 99312, 'step': 3600, 'algorithm': 'activity_selector'}
I0114 20:09:50.737937 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0114 20:09:52.170068 125612664464896 run.py:748] Algo activity_selector step 3650 current loss 1.022320, current_train_items 100688.
I0114 20:09:52.372995 125612664464896 run.py:783] (val) algo activity_selector step 3650: {'selected': 0.9254302103250478, 'score': 0.9254302103250478, 'examples_seen': 100688, 'step': 3650, 'algorithm': 'activity_selector'}
I0114 20:09:52.373253 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0114 20:09:53.819617 125612664464896 run.py:748] Algo activity_selector step 3700 current loss 0.714752, current_train_items 102064.
I0114 20:09:54.016579 125612664464896 run.py:783] (val) algo activity_selector step 3700: {'selected': 0.9671179883945841, 'score': 0.9671179883945841, 'examples_seen': 102064, 'step': 3700, 'algorithm': 'activity_selector'}
I0114 20:09:54.016847 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0114 20:09:55.444072 125612664464896 run.py:748] Algo activity_selector step 3750 current loss 0.796516, current_train_items 103440.
I0114 20:09:55.665514 125612664464896 run.py:783] (val) algo activity_selector step 3750: {'selected': 0.9224806201550387, 'score': 0.9224806201550387, 'examples_seen': 103440, 'step': 3750, 'algorithm': 'activity_selector'}
I0114 20:09:55.665742 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0114 20:09:57.123223 125612664464896 run.py:748] Algo activity_selector step 3800 current loss 0.687843, current_train_items 104816.
I0114 20:09:57.312566 125612664464896 run.py:783] (val) algo activity_selector step 3800: {'selected': 0.9543726235741444, 'score': 0.9543726235741444, 'examples_seen': 104816, 'step': 3800, 'algorithm': 'activity_selector'}
I0114 20:09:57.312805 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0114 20:09:58.744580 125612664464896 run.py:748] Algo activity_selector step 3850 current loss 0.925567, current_train_items 106208.
I0114 20:09:58.953453 125612664464896 run.py:783] (val) algo activity_selector step 3850: {'selected': 0.950943396226415, 'score': 0.950943396226415, 'examples_seen': 106208, 'step': 3850, 'algorithm': 'activity_selector'}
I0114 20:09:58.953787 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0114 20:10:00.396849 125612664464896 run.py:748] Algo activity_selector step 3900 current loss 1.075291, current_train_items 107584.
I0114 20:10:00.611947 125612664464896 run.py:783] (val) algo activity_selector step 3900: {'selected': 0.9303201506591336, 'score': 0.9303201506591336, 'examples_seen': 107584, 'step': 3900, 'algorithm': 'activity_selector'}
I0114 20:10:00.612193 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0114 20:10:02.018597 125612664464896 run.py:748] Algo activity_selector step 3950 current loss 1.002083, current_train_items 108960.
I0114 20:10:02.252712 125612664464896 run.py:783] (val) algo activity_selector step 3950: {'selected': 0.9142857142857143, 'score': 0.9142857142857143, 'examples_seen': 108960, 'step': 3950, 'algorithm': 'activity_selector'}
I0114 20:10:02.252942 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0114 20:10:03.685379 125612664464896 run.py:748] Algo activity_selector step 4000 current loss 1.278493, current_train_items 110336.
I0114 20:10:03.890026 125612664464896 run.py:783] (val) algo activity_selector step 4000: {'selected': 0.893939393939394, 'score': 0.893939393939394, 'examples_seen': 110336, 'step': 4000, 'algorithm': 'activity_selector'}
I0114 20:10:03.890290 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0114 20:10:05.322031 125612664464896 run.py:748] Algo activity_selector step 4050 current loss 0.886550, current_train_items 111712.
I0114 20:10:05.528981 125612664464896 run.py:783] (val) algo activity_selector step 4050: {'selected': 0.9227871939736346, 'score': 0.9227871939736346, 'examples_seen': 111712, 'step': 4050, 'algorithm': 'activity_selector'}
I0114 20:10:05.529238 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.923, val scores are: activity_selector: 0.923
I0114 20:10:06.994967 125612664464896 run.py:748] Algo activity_selector step 4100 current loss 0.963068, current_train_items 113088.
I0114 20:10:07.168939 125612664464896 run.py:783] (val) algo activity_selector step 4100: {'selected': 0.9398907103825136, 'score': 0.9398907103825136, 'examples_seen': 113088, 'step': 4100, 'algorithm': 'activity_selector'}
I0114 20:10:07.169200 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0114 20:10:08.573471 125612664464896 run.py:748] Algo activity_selector step 4150 current loss 0.748238, current_train_items 114480.
I0114 20:10:08.809571 125612664464896 run.py:783] (val) algo activity_selector step 4150: {'selected': 0.9284403669724771, 'score': 0.9284403669724771, 'examples_seen': 114480, 'step': 4150, 'algorithm': 'activity_selector'}
I0114 20:10:08.809834 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0114 20:10:10.239133 125612664464896 run.py:748] Algo activity_selector step 4200 current loss 1.092652, current_train_items 115856.
I0114 20:10:10.458546 125612664464896 run.py:783] (val) algo activity_selector step 4200: {'selected': 0.8910891089108911, 'score': 0.8910891089108911, 'examples_seen': 115856, 'step': 4200, 'algorithm': 'activity_selector'}
I0114 20:10:10.458738 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0114 20:10:11.893103 125612664464896 run.py:748] Algo activity_selector step 4250 current loss 1.050070, current_train_items 117216.
I0114 20:10:12.095270 125612664464896 run.py:783] (val) algo activity_selector step 4250: {'selected': 0.924770642201835, 'score': 0.924770642201835, 'examples_seen': 117216, 'step': 4250, 'algorithm': 'activity_selector'}
I0114 20:10:12.095501 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0114 20:10:13.537739 125612664464896 run.py:748] Algo activity_selector step 4300 current loss 1.400080, current_train_items 118624.
I0114 20:10:13.741321 125612664464896 run.py:783] (val) algo activity_selector step 4300: {'selected': 0.8919449901768172, 'score': 0.8919449901768172, 'examples_seen': 118624, 'step': 4300, 'algorithm': 'activity_selector'}
I0114 20:10:13.741634 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.892, val scores are: activity_selector: 0.892
I0114 20:10:15.174126 125612664464896 run.py:748] Algo activity_selector step 4350 current loss 0.657856, current_train_items 119984.
I0114 20:10:15.394726 125612664464896 run.py:783] (val) algo activity_selector step 4350: {'selected': 0.9444444444444445, 'score': 0.9444444444444445, 'examples_seen': 119984, 'step': 4350, 'algorithm': 'activity_selector'}
I0114 20:10:15.394969 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0114 20:10:16.817916 125612664464896 run.py:748] Algo activity_selector step 4400 current loss 0.873003, current_train_items 121360.
I0114 20:10:17.040884 125612664464896 run.py:783] (val) algo activity_selector step 4400: {'selected': 0.9316546762589928, 'score': 0.9316546762589928, 'examples_seen': 121360, 'step': 4400, 'algorithm': 'activity_selector'}
I0114 20:10:17.041136 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0114 20:10:18.470255 125612664464896 run.py:748] Algo activity_selector step 4450 current loss 1.230879, current_train_items 122752.
I0114 20:10:18.682106 125612664464896 run.py:783] (val) algo activity_selector step 4450: {'selected': 0.9330708661417322, 'score': 0.9330708661417322, 'examples_seen': 122752, 'step': 4450, 'algorithm': 'activity_selector'}
I0114 20:10:18.682355 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0114 20:10:20.114472 125612664464896 run.py:748] Algo activity_selector step 4500 current loss 0.801632, current_train_items 124128.
I0114 20:10:20.331661 125612664464896 run.py:783] (val) algo activity_selector step 4500: {'selected': 0.9616858237547892, 'score': 0.9616858237547892, 'examples_seen': 124128, 'step': 4500, 'algorithm': 'activity_selector'}
I0114 20:10:20.331888 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0114 20:10:21.763767 125612664464896 run.py:748] Algo activity_selector step 4550 current loss 0.838534, current_train_items 125504.
I0114 20:10:21.976885 125612664464896 run.py:783] (val) algo activity_selector step 4550: {'selected': 0.8796992481203008, 'score': 0.8796992481203008, 'examples_seen': 125504, 'step': 4550, 'algorithm': 'activity_selector'}
I0114 20:10:21.977145 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0114 20:10:23.423412 125612664464896 run.py:748] Algo activity_selector step 4600 current loss 0.939104, current_train_items 126880.
I0114 20:10:23.621767 125612664464896 run.py:783] (val) algo activity_selector step 4600: {'selected': 0.9354207436399217, 'score': 0.9354207436399217, 'examples_seen': 126880, 'step': 4600, 'algorithm': 'activity_selector'}
I0114 20:10:23.621999 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0114 20:10:25.039965 125612664464896 run.py:748] Algo activity_selector step 4650 current loss 0.673438, current_train_items 128272.
I0114 20:10:25.278492 125612664464896 run.py:783] (val) algo activity_selector step 4650: {'selected': 0.9581749049429659, 'score': 0.9581749049429659, 'examples_seen': 128272, 'step': 4650, 'algorithm': 'activity_selector'}
I0114 20:10:25.278725 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0114 20:10:26.683516 125612664464896 run.py:748] Algo activity_selector step 4700 current loss 0.918102, current_train_items 129632.
I0114 20:10:26.922886 125612664464896 run.py:783] (val) algo activity_selector step 4700: {'selected': 0.8793103448275862, 'score': 0.8793103448275862, 'examples_seen': 129632, 'step': 4700, 'algorithm': 'activity_selector'}
I0114 20:10:26.923162 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0114 20:10:28.353507 125612664464896 run.py:748] Algo activity_selector step 4750 current loss 0.944912, current_train_items 131024.
I0114 20:10:28.567533 125612664464896 run.py:783] (val) algo activity_selector step 4750: {'selected': 0.9390018484288354, 'score': 0.9390018484288354, 'examples_seen': 131024, 'step': 4750, 'algorithm': 'activity_selector'}
I0114 20:10:28.567762 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0114 20:10:30.023908 125612664464896 run.py:748] Algo activity_selector step 4800 current loss 1.213491, current_train_items 132400.
I0114 20:10:30.225155 125612664464896 run.py:783] (val) algo activity_selector step 4800: {'selected': 0.9244935543278083, 'score': 0.9244935543278083, 'examples_seen': 132400, 'step': 4800, 'algorithm': 'activity_selector'}
I0114 20:10:30.225384 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0114 20:10:31.661772 125612664464896 run.py:748] Algo activity_selector step 4850 current loss 0.673150, current_train_items 133760.
I0114 20:10:31.876752 125612664464896 run.py:783] (val) algo activity_selector step 4850: {'selected': 0.9366197183098591, 'score': 0.9366197183098591, 'examples_seen': 133760, 'step': 4850, 'algorithm': 'activity_selector'}
I0114 20:10:31.876981 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0114 20:10:33.314580 125612664464896 run.py:748] Algo activity_selector step 4900 current loss 0.567833, current_train_items 135168.
I0114 20:10:33.528046 125612664464896 run.py:783] (val) algo activity_selector step 4900: {'selected': 0.9411764705882353, 'score': 0.9411764705882353, 'examples_seen': 135168, 'step': 4900, 'algorithm': 'activity_selector'}
I0114 20:10:33.528304 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0114 20:10:34.976112 125612664464896 run.py:748] Algo activity_selector step 4950 current loss 0.721759, current_train_items 136528.
I0114 20:10:35.185290 125612664464896 run.py:783] (val) algo activity_selector step 4950: {'selected': 0.9593810444874274, 'score': 0.9593810444874274, 'examples_seen': 136528, 'step': 4950, 'algorithm': 'activity_selector'}
I0114 20:10:35.185583 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0114 20:10:36.615198 125612664464896 run.py:748] Algo activity_selector step 5000 current loss 0.588336, current_train_items 137920.
I0114 20:10:36.830576 125612664464896 run.py:783] (val) algo activity_selector step 5000: {'selected': 0.9646182495344505, 'score': 0.9646182495344505, 'examples_seen': 137920, 'step': 5000, 'algorithm': 'activity_selector'}
I0114 20:10:36.830808 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0114 20:10:38.250843 125612664464896 run.py:748] Algo activity_selector step 5050 current loss 0.758631, current_train_items 139296.
I0114 20:10:38.475776 125612664464896 run.py:783] (val) algo activity_selector step 5050: {'selected': 0.9361702127659575, 'score': 0.9361702127659575, 'examples_seen': 139296, 'step': 5050, 'algorithm': 'activity_selector'}
I0114 20:10:38.476104 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0114 20:10:39.889559 125612664464896 run.py:748] Algo activity_selector step 5100 current loss 0.779574, current_train_items 140656.
I0114 20:10:40.128293 125612664464896 run.py:783] (val) algo activity_selector step 5100: {'selected': 0.9303201506591336, 'score': 0.9303201506591336, 'examples_seen': 140656, 'step': 5100, 'algorithm': 'activity_selector'}
I0114 20:10:40.128636 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0114 20:10:41.549255 125612664464896 run.py:748] Algo activity_selector step 5150 current loss 0.788821, current_train_items 142048.
I0114 20:10:41.770834 125612664464896 run.py:783] (val) algo activity_selector step 5150: {'selected': 0.9302325581395349, 'score': 0.9302325581395349, 'examples_seen': 142048, 'step': 5150, 'algorithm': 'activity_selector'}
I0114 20:10:41.771080 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0114 20:10:43.201871 125612664464896 run.py:748] Algo activity_selector step 5200 current loss 0.495034, current_train_items 143424.
I0114 20:10:43.412292 125612664464896 run.py:783] (val) algo activity_selector step 5200: {'selected': 0.95703125, 'score': 0.95703125, 'examples_seen': 143424, 'step': 5200, 'algorithm': 'activity_selector'}
I0114 20:10:43.412526 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0114 20:10:44.825425 125612664464896 run.py:748] Algo activity_selector step 5250 current loss 0.803618, current_train_items 144816.
I0114 20:10:45.059070 125612664464896 run.py:783] (val) algo activity_selector step 5250: {'selected': 0.9595588235294117, 'score': 0.9595588235294117, 'examples_seen': 144816, 'step': 5250, 'algorithm': 'activity_selector'}
I0114 20:10:45.059269 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0114 20:10:46.459210 125612664464896 run.py:748] Algo activity_selector step 5300 current loss 0.857719, current_train_items 146176.
I0114 20:10:46.702364 125612664464896 run.py:783] (val) algo activity_selector step 5300: {'selected': 0.9057301293900184, 'score': 0.9057301293900184, 'examples_seen': 146176, 'step': 5300, 'algorithm': 'activity_selector'}
I0114 20:10:46.702602 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0114 20:10:48.123041 125612664464896 run.py:748] Algo activity_selector step 5350 current loss 0.687474, current_train_items 147584.
I0114 20:10:48.344321 125612664464896 run.py:783] (val) algo activity_selector step 5350: {'selected': 0.9558823529411765, 'score': 0.9558823529411765, 'examples_seen': 147584, 'step': 5350, 'algorithm': 'activity_selector'}
I0114 20:10:48.344562 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0114 20:10:49.793048 125612664464896 run.py:748] Algo activity_selector step 5400 current loss 0.797194, current_train_items 148944.
I0114 20:10:49.998382 125612664464896 run.py:783] (val) algo activity_selector step 5400: {'selected': 0.9615384615384616, 'score': 0.9615384615384616, 'examples_seen': 148944, 'step': 5400, 'algorithm': 'activity_selector'}
I0114 20:10:49.998571 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0114 20:10:51.424803 125612664464896 run.py:748] Algo activity_selector step 5450 current loss 0.700679, current_train_items 150304.
I0114 20:10:51.636489 125612664464896 run.py:783] (val) algo activity_selector step 5450: {'selected': 0.9709864603481625, 'score': 0.9709864603481625, 'examples_seen': 150304, 'step': 5450, 'algorithm': 'activity_selector'}
I0114 20:10:51.636727 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0114 20:10:53.065959 125612664464896 run.py:748] Algo activity_selector step 5500 current loss 0.892137, current_train_items 151712.
I0114 20:10:53.278109 125612664464896 run.py:783] (val) algo activity_selector step 5500: {'selected': 0.8739837398373984, 'score': 0.8739837398373984, 'examples_seen': 151712, 'step': 5500, 'algorithm': 'activity_selector'}
I0114 20:10:53.278364 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.874, val scores are: activity_selector: 0.874
I0114 20:10:54.695039 125612664464896 run.py:748] Algo activity_selector step 5550 current loss 0.666703, current_train_items 153072.
I0114 20:10:54.931107 125612664464896 run.py:783] (val) algo activity_selector step 5550: {'selected': 0.9451327433628318, 'score': 0.9451327433628318, 'examples_seen': 153072, 'step': 5550, 'algorithm': 'activity_selector'}
I0114 20:10:54.931340 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.972, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0114 20:10:56.363301 125612664464896 run.py:748] Algo activity_selector step 5600 current loss 0.561777, current_train_items 154464.
I0114 20:10:56.577495 125612664464896 run.py:783] (val) algo activity_selector step 5600: {'selected': 0.9786324786324786, 'score': 0.9786324786324786, 'examples_seen': 154464, 'step': 5600, 'algorithm': 'activity_selector'}
I0114 20:10:56.577748 125612664464896 run.py:804] Checkpointing best model, best avg val score was 0.972, current avg val score is 0.979, val scores are: activity_selector: 0.979
I0114 20:10:58.159754 125612664464896 run.py:748] Algo activity_selector step 5650 current loss 0.749123, current_train_items 155840.
I0114 20:10:58.392927 125612664464896 run.py:783] (val) algo activity_selector step 5650: {'selected': 0.9563636363636364, 'score': 0.9563636363636364, 'examples_seen': 155840, 'step': 5650, 'algorithm': 'activity_selector'}
I0114 20:10:58.393181 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0114 20:10:59.822828 125612664464896 run.py:748] Algo activity_selector step 5700 current loss 0.650707, current_train_items 157216.
I0114 20:11:00.044117 125612664464896 run.py:783] (val) algo activity_selector step 5700: {'selected': 0.9419354838709678, 'score': 0.9419354838709678, 'examples_seen': 157216, 'step': 5700, 'algorithm': 'activity_selector'}
I0114 20:11:00.044445 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0114 20:11:01.498803 125612664464896 run.py:748] Algo activity_selector step 5750 current loss 0.856753, current_train_items 158592.
I0114 20:11:01.692994 125612664464896 run.py:783] (val) algo activity_selector step 5750: {'selected': 0.9256198347107438, 'score': 0.9256198347107438, 'examples_seen': 158592, 'step': 5750, 'algorithm': 'activity_selector'}
I0114 20:11:01.693245 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0114 20:11:03.102005 125612664464896 run.py:748] Algo activity_selector step 5800 current loss 0.761368, current_train_items 159968.
I0114 20:11:03.340798 125612664464896 run.py:783] (val) algo activity_selector step 5800: {'selected': 0.9345794392523364, 'score': 0.9345794392523364, 'examples_seen': 159968, 'step': 5800, 'algorithm': 'activity_selector'}
I0114 20:11:03.341079 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0114 20:11:04.753045 125612664464896 run.py:748] Algo activity_selector step 5850 current loss 0.991497, current_train_items 161360.
I0114 20:11:04.990463 125612664464896 run.py:783] (val) algo activity_selector step 5850: {'selected': 0.9455252918287936, 'score': 0.9455252918287936, 'examples_seen': 161360, 'step': 5850, 'algorithm': 'activity_selector'}
I0114 20:11:04.990698 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0114 20:11:06.438507 125612664464896 run.py:748] Algo activity_selector step 5900 current loss 0.688714, current_train_items 162720.
I0114 20:11:06.624011 125612664464896 run.py:783] (val) algo activity_selector step 5900: {'selected': 0.9265536723163841, 'score': 0.9265536723163841, 'examples_seen': 162720, 'step': 5900, 'algorithm': 'activity_selector'}
I0114 20:11:06.624255 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0114 20:11:08.055764 125612664464896 run.py:748] Algo activity_selector step 5950 current loss 0.504649, current_train_items 164112.
I0114 20:11:08.269249 125612664464896 run.py:783] (val) algo activity_selector step 5950: {'selected': 0.9118198874296435, 'score': 0.9118198874296435, 'examples_seen': 164112, 'step': 5950, 'algorithm': 'activity_selector'}
I0114 20:11:08.269484 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0114 20:11:09.709587 125612664464896 run.py:748] Algo activity_selector step 6000 current loss 0.594802, current_train_items 165488.
I0114 20:11:09.913686 125612664464896 run.py:783] (val) algo activity_selector step 6000: {'selected': 0.9455184534270651, 'score': 0.9455184534270651, 'examples_seen': 165488, 'step': 6000, 'algorithm': 'activity_selector'}
I0114 20:11:09.913956 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0114 20:11:11.341878 125612664464896 run.py:748] Algo activity_selector step 6050 current loss 0.893804, current_train_items 166864.
I0114 20:11:11.545345 125612664464896 run.py:783] (val) algo activity_selector step 6050: {'selected': 0.9083820662768032, 'score': 0.9083820662768032, 'examples_seen': 166864, 'step': 6050, 'algorithm': 'activity_selector'}
I0114 20:11:11.545650 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0114 20:11:12.946113 125612664464896 run.py:748] Algo activity_selector step 6100 current loss 0.801378, current_train_items 168256.
I0114 20:11:13.185283 125612664464896 run.py:783] (val) algo activity_selector step 6100: {'selected': 0.9634146341463414, 'score': 0.9634146341463414, 'examples_seen': 168256, 'step': 6100, 'algorithm': 'activity_selector'}
I0114 20:11:13.185529 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0114 20:11:14.624578 125612664464896 run.py:748] Algo activity_selector step 6150 current loss 0.825726, current_train_items 169616.
I0114 20:11:14.838573 125612664464896 run.py:783] (val) algo activity_selector step 6150: {'selected': 0.9079229122055674, 'score': 0.9079229122055674, 'examples_seen': 169616, 'step': 6150, 'algorithm': 'activity_selector'}
I0114 20:11:14.838800 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0114 20:11:16.259983 125612664464896 run.py:748] Algo activity_selector step 6200 current loss 0.628228, current_train_items 171008.
I0114 20:11:16.481162 125612664464896 run.py:783] (val) algo activity_selector step 6200: {'selected': 0.9377593360995852, 'score': 0.9377593360995852, 'examples_seen': 171008, 'step': 6200, 'algorithm': 'activity_selector'}
I0114 20:11:16.481465 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0114 20:11:17.934695 125612664464896 run.py:748] Algo activity_selector step 6250 current loss 0.577549, current_train_items 172384.
I0114 20:11:18.129409 125612664464896 run.py:783] (val) algo activity_selector step 6250: {'selected': 0.9606003752345216, 'score': 0.9606003752345216, 'examples_seen': 172384, 'step': 6250, 'algorithm': 'activity_selector'}
I0114 20:11:18.129640 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0114 20:11:19.573597 125612664464896 run.py:748] Algo activity_selector step 6300 current loss 0.658193, current_train_items 173760.
I0114 20:11:19.787736 125612664464896 run.py:783] (val) algo activity_selector step 6300: {'selected': 0.9140767824497257, 'score': 0.9140767824497257, 'examples_seen': 173760, 'step': 6300, 'algorithm': 'activity_selector'}
I0114 20:11:19.787991 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0114 20:11:21.233763 125612664464896 run.py:748] Algo activity_selector step 6350 current loss 0.525019, current_train_items 175136.
I0114 20:11:21.427443 125612664464896 run.py:783] (val) algo activity_selector step 6350: {'selected': 0.963855421686747, 'score': 0.963855421686747, 'examples_seen': 175136, 'step': 6350, 'algorithm': 'activity_selector'}
I0114 20:11:21.427692 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0114 20:11:22.832424 125612664464896 run.py:748] Algo activity_selector step 6400 current loss 0.880149, current_train_items 176528.
I0114 20:11:23.077351 125612664464896 run.py:783] (val) algo activity_selector step 6400: {'selected': 0.9252525252525253, 'score': 0.9252525252525253, 'examples_seen': 176528, 'step': 6400, 'algorithm': 'activity_selector'}
I0114 20:11:23.077586 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0114 20:11:24.493960 125612664464896 run.py:748] Algo activity_selector step 6450 current loss 0.742827, current_train_items 177904.
I0114 20:11:24.732453 125612664464896 run.py:783] (val) algo activity_selector step 6450: {'selected': 0.9611829944547134, 'score': 0.9611829944547134, 'examples_seen': 177904, 'step': 6450, 'algorithm': 'activity_selector'}
I0114 20:11:24.732686 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0114 20:11:26.134816 125612664464896 run.py:748] Algo activity_selector step 6500 current loss 0.824338, current_train_items 179264.
I0114 20:11:26.374646 125612664464896 run.py:783] (val) algo activity_selector step 6500: {'selected': 0.9520426287744227, 'score': 0.9520426287744227, 'examples_seen': 179264, 'step': 6500, 'algorithm': 'activity_selector'}
I0114 20:11:26.374836 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0114 20:11:27.802919 125612664464896 run.py:748] Algo activity_selector step 6550 current loss 0.728704, current_train_items 180656.
I0114 20:11:28.013590 125612664464896 run.py:783] (val) algo activity_selector step 6550: {'selected': 0.9379562043795621, 'score': 0.9379562043795621, 'examples_seen': 180656, 'step': 6550, 'algorithm': 'activity_selector'}
I0114 20:11:28.013823 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0114 20:11:29.452495 125612664464896 run.py:748] Algo activity_selector step 6600 current loss 0.901248, current_train_items 182032.
I0114 20:11:29.662014 125612664464896 run.py:783] (val) algo activity_selector step 6600: {'selected': 0.9160583941605839, 'score': 0.9160583941605839, 'examples_seen': 182032, 'step': 6600, 'algorithm': 'activity_selector'}
I0114 20:11:29.662275 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.916, val scores are: activity_selector: 0.916
I0114 20:11:31.065561 125612664464896 run.py:748] Algo activity_selector step 6650 current loss 0.910003, current_train_items 183408.
I0114 20:11:31.303350 125612664464896 run.py:783] (val) algo activity_selector step 6650: {'selected': 0.9362549800796813, 'score': 0.9362549800796813, 'examples_seen': 183408, 'step': 6650, 'algorithm': 'activity_selector'}
I0114 20:11:31.303580 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0114 20:11:32.736351 125612664464896 run.py:748] Algo activity_selector step 6700 current loss 0.665558, current_train_items 184800.
I0114 20:11:32.946596 125612664464896 run.py:783] (val) algo activity_selector step 6700: {'selected': 0.9414141414141414, 'score': 0.9414141414141414, 'examples_seen': 184800, 'step': 6700, 'algorithm': 'activity_selector'}
I0114 20:11:32.946844 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0114 20:11:34.388624 125612664464896 run.py:748] Algo activity_selector step 6750 current loss 0.524454, current_train_items 186176.
I0114 20:11:34.596696 125612664464896 run.py:783] (val) algo activity_selector step 6750: {'selected': 0.970178926441352, 'score': 0.970178926441352, 'examples_seen': 186176, 'step': 6750, 'algorithm': 'activity_selector'}
I0114 20:11:34.596938 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0114 20:11:36.018681 125612664464896 run.py:748] Algo activity_selector step 6800 current loss 0.717083, current_train_items 187536.
I0114 20:11:36.240854 125612664464896 run.py:783] (val) algo activity_selector step 6800: {'selected': 0.8946395563770795, 'score': 0.8946395563770795, 'examples_seen': 187536, 'step': 6800, 'algorithm': 'activity_selector'}
I0114 20:11:36.241131 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.895, val scores are: activity_selector: 0.895
I0114 20:11:37.641877 125612664464896 run.py:748] Algo activity_selector step 6850 current loss 0.922574, current_train_items 188928.
I0114 20:11:37.884129 125612664464896 run.py:783] (val) algo activity_selector step 6850: {'selected': 0.9169675090252708, 'score': 0.9169675090252708, 'examples_seen': 188928, 'step': 6850, 'algorithm': 'activity_selector'}
I0114 20:11:37.884360 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0114 20:11:39.323671 125612664464896 run.py:748] Algo activity_selector step 6900 current loss 0.583470, current_train_items 190304.
I0114 20:11:39.536693 125612664464896 run.py:783] (val) algo activity_selector step 6900: {'selected': 0.9534883720930233, 'score': 0.9534883720930233, 'examples_seen': 190304, 'step': 6900, 'algorithm': 'activity_selector'}
I0114 20:11:39.536923 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0114 20:11:40.968107 125612664464896 run.py:748] Algo activity_selector step 6950 current loss 0.708600, current_train_items 191680.
I0114 20:11:41.179040 125612664464896 run.py:783] (val) algo activity_selector step 6950: {'selected': 0.959349593495935, 'score': 0.959349593495935, 'examples_seen': 191680, 'step': 6950, 'algorithm': 'activity_selector'}
I0114 20:11:41.179293 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0114 20:11:42.602026 125612664464896 run.py:748] Algo activity_selector step 7000 current loss 0.622947, current_train_items 193072.
I0114 20:11:42.823138 125612664464896 run.py:783] (val) algo activity_selector step 7000: {'selected': 0.9516129032258065, 'score': 0.9516129032258065, 'examples_seen': 193072, 'step': 7000, 'algorithm': 'activity_selector'}
I0114 20:11:42.823368 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0114 20:11:44.263762 125612664464896 run.py:748] Algo activity_selector step 7050 current loss 0.749359, current_train_items 194448.
I0114 20:11:44.473135 125612664464896 run.py:783] (val) algo activity_selector step 7050: {'selected': 0.9542961608775137, 'score': 0.9542961608775137, 'examples_seen': 194448, 'step': 7050, 'algorithm': 'activity_selector'}
I0114 20:11:44.473377 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0114 20:11:45.879814 125612664464896 run.py:748] Algo activity_selector step 7100 current loss 0.845411, current_train_items 195824.
I0114 20:11:46.115984 125612664464896 run.py:783] (val) algo activity_selector step 7100: {'selected': 0.9416195856873824, 'score': 0.9416195856873824, 'examples_seen': 195824, 'step': 7100, 'algorithm': 'activity_selector'}
I0114 20:11:46.116229 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0114 20:11:47.548454 125612664464896 run.py:748] Algo activity_selector step 7150 current loss 0.673895, current_train_items 197200.
I0114 20:11:47.761543 125612664464896 run.py:783] (val) algo activity_selector step 7150: {'selected': 0.9090909090909092, 'score': 0.9090909090909092, 'examples_seen': 197200, 'step': 7150, 'algorithm': 'activity_selector'}
I0114 20:11:47.761783 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0114 20:11:49.203365 125612664464896 run.py:748] Algo activity_selector step 7200 current loss 0.660993, current_train_items 198576.
I0114 20:11:49.416589 125612664464896 run.py:783] (val) algo activity_selector step 7200: {'selected': 0.9496981891348089, 'score': 0.9496981891348089, 'examples_seen': 198576, 'step': 7200, 'algorithm': 'activity_selector'}
I0114 20:11:49.416819 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0114 20:11:50.846573 125612664464896 run.py:748] Algo activity_selector step 7250 current loss 0.745722, current_train_items 199952.
I0114 20:11:51.056648 125612664464896 run.py:783] (val) algo activity_selector step 7250: {'selected': 0.9411764705882353, 'score': 0.9411764705882353, 'examples_seen': 199952, 'step': 7250, 'algorithm': 'activity_selector'}
I0114 20:11:51.056878 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0114 20:11:52.489138 125612664464896 run.py:748] Algo activity_selector step 7300 current loss 0.717313, current_train_items 201344.
I0114 20:11:52.703258 125612664464896 run.py:783] (val) algo activity_selector step 7300: {'selected': 0.9388560157790926, 'score': 0.9388560157790926, 'examples_seen': 201344, 'step': 7300, 'algorithm': 'activity_selector'}
I0114 20:11:52.703442 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0114 20:11:54.134691 125612664464896 run.py:748] Algo activity_selector step 7350 current loss 0.770030, current_train_items 202720.
I0114 20:11:54.346252 125612664464896 run.py:783] (val) algo activity_selector step 7350: {'selected': 0.9525773195876287, 'score': 0.9525773195876287, 'examples_seen': 202720, 'step': 7350, 'algorithm': 'activity_selector'}
I0114 20:11:54.346483 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0114 20:11:55.745024 125612664464896 run.py:748] Algo activity_selector step 7400 current loss 0.633999, current_train_items 204080.
I0114 20:11:55.988666 125612664464896 run.py:783] (val) algo activity_selector step 7400: {'selected': 0.9498997995991985, 'score': 0.9498997995991985, 'examples_seen': 204080, 'step': 7400, 'algorithm': 'activity_selector'}
I0114 20:11:55.988899 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0114 20:11:57.393794 125612664464896 run.py:748] Algo activity_selector step 7450 current loss 0.725467, current_train_items 205488.
I0114 20:11:57.629307 125612664464896 run.py:783] (val) algo activity_selector step 7450: {'selected': 0.9504587155963303, 'score': 0.9504587155963303, 'examples_seen': 205488, 'step': 7450, 'algorithm': 'activity_selector'}
I0114 20:11:57.629463 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0114 20:11:59.040488 125612664464896 run.py:748] Algo activity_selector step 7500 current loss 0.518664, current_train_items 206848.
I0114 20:11:59.279046 125612664464896 run.py:783] (val) algo activity_selector step 7500: {'selected': 0.9072978303747534, 'score': 0.9072978303747534, 'examples_seen': 206848, 'step': 7500, 'algorithm': 'activity_selector'}
I0114 20:11:59.279312 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0114 20:12:00.717827 125612664464896 run.py:748] Algo activity_selector step 7550 current loss 0.752580, current_train_items 208224.
I0114 20:12:00.927373 125612664464896 run.py:783] (val) algo activity_selector step 7550: {'selected': 0.9153225806451614, 'score': 0.9153225806451614, 'examples_seen': 208224, 'step': 7550, 'algorithm': 'activity_selector'}
I0114 20:12:00.927634 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0114 20:12:02.330836 125612664464896 run.py:748] Algo activity_selector step 7600 current loss 0.788596, current_train_items 209616.
I0114 20:12:02.568377 125612664464896 run.py:783] (val) algo activity_selector step 7600: {'selected': 0.9660377358490565, 'score': 0.9660377358490565, 'examples_seen': 209616, 'step': 7600, 'algorithm': 'activity_selector'}
I0114 20:12:02.568609 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0114 20:12:04.011312 125612664464896 run.py:748] Algo activity_selector step 7650 current loss 0.681086, current_train_items 210976.
I0114 20:12:04.224654 125612664464896 run.py:783] (val) algo activity_selector step 7650: {'selected': 0.9087523277467411, 'score': 0.9087523277467411, 'examples_seen': 210976, 'step': 7650, 'algorithm': 'activity_selector'}
I0114 20:12:04.224893 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0114 20:12:05.628165 125612664464896 run.py:748] Algo activity_selector step 7700 current loss 0.715877, current_train_items 212368.
I0114 20:12:05.868847 125612664464896 run.py:783] (val) algo activity_selector step 7700: {'selected': 0.9467455621301775, 'score': 0.9467455621301775, 'examples_seen': 212368, 'step': 7700, 'algorithm': 'activity_selector'}
I0114 20:12:05.869100 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0114 20:12:07.316001 125612664464896 run.py:748] Algo activity_selector step 7750 current loss 0.626891, current_train_items 213744.
I0114 20:12:07.512404 125612664464896 run.py:783] (val) algo activity_selector step 7750: {'selected': 0.9365671641791044, 'score': 0.9365671641791044, 'examples_seen': 213744, 'step': 7750, 'algorithm': 'activity_selector'}
I0114 20:12:07.512636 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0114 20:12:08.944969 125612664464896 run.py:748] Algo activity_selector step 7800 current loss 0.601061, current_train_items 215136.
I0114 20:12:09.166157 125612664464896 run.py:783] (val) algo activity_selector step 7800: {'selected': 0.9219330855018587, 'score': 0.9219330855018587, 'examples_seen': 215136, 'step': 7800, 'algorithm': 'activity_selector'}
I0114 20:12:09.166398 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0114 20:12:10.601664 125612664464896 run.py:748] Algo activity_selector step 7850 current loss 0.677017, current_train_items 216496.
I0114 20:12:10.809999 125612664464896 run.py:783] (val) algo activity_selector step 7850: {'selected': 0.9525691699604744, 'score': 0.9525691699604744, 'examples_seen': 216496, 'step': 7850, 'algorithm': 'activity_selector'}
I0114 20:12:10.810257 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0114 20:12:12.234342 125612664464896 run.py:748] Algo activity_selector step 7900 current loss 0.553313, current_train_items 217888.
I0114 20:12:12.454953 125612664464896 run.py:783] (val) algo activity_selector step 7900: {'selected': 0.9259259259259259, 'score': 0.9259259259259259, 'examples_seen': 217888, 'step': 7900, 'algorithm': 'activity_selector'}
I0114 20:12:12.455198 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0114 20:12:13.871251 125612664464896 run.py:748] Algo activity_selector step 7950 current loss 0.569756, current_train_items 219264.
I0114 20:12:14.108732 125612664464896 run.py:783] (val) algo activity_selector step 7950: {'selected': 0.9682242990654205, 'score': 0.9682242990654205, 'examples_seen': 219264, 'step': 7950, 'algorithm': 'activity_selector'}
I0114 20:12:14.109085 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0114 20:12:15.529231 125612664464896 run.py:748] Algo activity_selector step 8000 current loss 0.541931, current_train_items 220624.
I0114 20:12:15.752443 125612664464896 run.py:783] (val) algo activity_selector step 8000: {'selected': 0.974757281553398, 'score': 0.974757281553398, 'examples_seen': 220624, 'step': 8000, 'algorithm': 'activity_selector'}
I0114 20:12:15.752619 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.979, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0114 20:12:17.194993 125612664464896 run.py:748] Algo activity_selector step 8050 current loss 0.649241, current_train_items 222032.
I0114 20:12:17.396425 125612664464896 run.py:783] (val) algo activity_selector step 8050: {'selected': 0.9127272727272727, 'score': 0.9127272727272727, 'examples_seen': 222032, 'step': 8050, 'algorithm': 'activity_selector'}
I0114 20:12:17.396740 125612664464896 run.py:804] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0114 20:12:19.013451 125612664464896 run.py:748] Algo activity_selector step 8100 current loss 0.632269, current_train_items 223392.
I0114 20:12:19.220123 125612664464896 run.py:783] (val) algo activity_selector step 8100: {'selected': 0.9174664107485604, 'score': 0.9174664107485604, 'examples_seen': 223392, 'step': 8100, 'algorithm': 'activity_selector'}
I0114 20:12:19.220421 125612664464896 run.py:804] Checkpointing best model, best avg val score was 0.913, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0114 20:12:20.828344 125612664464896 run.py:748] Algo activity_selector step 8150 current loss 0.594534, current_train_items 224784.
I0114 20:12:21.031801 125612664464896 run.py:783] (val) algo activity_selector step 8150: {'selected': 0.9320754716981131, 'score': 0.9320754716981131, 'examples_seen': 224784, 'step': 8150, 'algorithm': 'activity_selector'}
I0114 20:12:21.032029 125612664464896 run.py:804] Checkpointing best model, best avg val score was 0.917, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0114 20:12:22.628517 125612664464896 run.py:748] Algo activity_selector step 8200 current loss 0.743142, current_train_items 226160.
I0114 20:12:22.840607 125612664464896 run.py:783] (val) algo activity_selector step 8200: {'selected': 0.9639468690702088, 'score': 0.9639468690702088, 'examples_seen': 226160, 'step': 8200, 'algorithm': 'activity_selector'}
I0114 20:12:22.840756 125612664464896 run.py:804] Checkpointing best model, best avg val score was 0.932, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0114 20:12:24.439134 125612664464896 run.py:748] Algo activity_selector step 8250 current loss 0.620225, current_train_items 227520.
I0114 20:12:24.650315 125612664464896 run.py:783] (val) algo activity_selector step 8250: {'selected': 0.9712092130518234, 'score': 0.9712092130518234, 'examples_seen': 227520, 'step': 8250, 'algorithm': 'activity_selector'}
I0114 20:12:24.650595 125612664464896 run.py:804] Checkpointing best model, best avg val score was 0.964, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0114 20:12:26.262545 125612664464896 run.py:748] Algo activity_selector step 8300 current loss 0.590114, current_train_items 228912.
I0114 20:12:26.462781 125612664464896 run.py:783] (val) algo activity_selector step 8300: {'selected': 0.9536679536679535, 'score': 0.9536679536679535, 'examples_seen': 228912, 'step': 8300, 'algorithm': 'activity_selector'}
I0114 20:12:26.463028 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0114 20:12:27.867114 125612664464896 run.py:748] Algo activity_selector step 8350 current loss 0.475193, current_train_items 230288.
I0114 20:12:28.109539 125612664464896 run.py:783] (val) algo activity_selector step 8350: {'selected': 0.9463955637707948, 'score': 0.9463955637707948, 'examples_seen': 230288, 'step': 8350, 'algorithm': 'activity_selector'}
I0114 20:12:28.109781 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0114 20:12:29.550466 125612664464896 run.py:748] Algo activity_selector step 8400 current loss 0.515126, current_train_items 231680.
I0114 20:12:29.762128 125612664464896 run.py:783] (val) algo activity_selector step 8400: {'selected': 0.9511278195488722, 'score': 0.9511278195488722, 'examples_seen': 231680, 'step': 8400, 'algorithm': 'activity_selector'}
I0114 20:12:29.762354 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0114 20:12:31.191805 125612664464896 run.py:748] Algo activity_selector step 8450 current loss 0.571505, current_train_items 233040.
I0114 20:12:31.407753 125612664464896 run.py:783] (val) algo activity_selector step 8450: {'selected': 0.921904761904762, 'score': 0.921904761904762, 'examples_seen': 233040, 'step': 8450, 'algorithm': 'activity_selector'}
I0114 20:12:31.407985 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0114 20:12:32.838891 125612664464896 run.py:748] Algo activity_selector step 8500 current loss 0.886766, current_train_items 234432.
I0114 20:12:33.052666 125612664464896 run.py:783] (val) algo activity_selector step 8500: {'selected': 0.9573283858998145, 'score': 0.9573283858998145, 'examples_seen': 234432, 'step': 8500, 'algorithm': 'activity_selector'}
I0114 20:12:33.052893 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0114 20:12:34.494375 125612664464896 run.py:748] Algo activity_selector step 8550 current loss 0.471336, current_train_items 235808.
I0114 20:12:34.715288 125612664464896 run.py:783] (val) algo activity_selector step 8550: {'selected': 0.8880733944954128, 'score': 0.8880733944954128, 'examples_seen': 235808, 'step': 8550, 'algorithm': 'activity_selector'}
I0114 20:12:34.715644 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.888, val scores are: activity_selector: 0.888
I0114 20:12:36.143899 125612664464896 run.py:748] Algo activity_selector step 8600 current loss 0.594364, current_train_items 237168.
I0114 20:12:36.357358 125612664464896 run.py:783] (val) algo activity_selector step 8600: {'selected': 0.9512670565302144, 'score': 0.9512670565302144, 'examples_seen': 237168, 'step': 8600, 'algorithm': 'activity_selector'}
I0114 20:12:36.357649 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0114 20:12:37.797992 125612664464896 run.py:748] Algo activity_selector step 8650 current loss 0.639799, current_train_items 238576.
I0114 20:12:38.011002 125612664464896 run.py:783] (val) algo activity_selector step 8650: {'selected': 0.9362549800796813, 'score': 0.9362549800796813, 'examples_seen': 238576, 'step': 8650, 'algorithm': 'activity_selector'}
I0114 20:12:38.011260 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0114 20:12:39.481903 125612664464896 run.py:748] Algo activity_selector step 8700 current loss 0.609159, current_train_items 239936.
I0114 20:12:39.665556 125612664464896 run.py:783] (val) algo activity_selector step 8700: {'selected': 0.9521988527724665, 'score': 0.9521988527724665, 'examples_seen': 239936, 'step': 8700, 'algorithm': 'activity_selector'}
I0114 20:12:39.665806 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0114 20:12:41.144674 125612664464896 run.py:748] Algo activity_selector step 8750 current loss 0.945433, current_train_items 241328.
I0114 20:12:41.359529 125612664464896 run.py:783] (val) algo activity_selector step 8750: {'selected': 0.9396226415094341, 'score': 0.9396226415094341, 'examples_seen': 241328, 'step': 8750, 'algorithm': 'activity_selector'}
I0114 20:12:41.359784 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0114 20:12:42.809669 125612664464896 run.py:748] Algo activity_selector step 8800 current loss 0.573477, current_train_items 242704.
I0114 20:12:43.000745 125612664464896 run.py:783] (val) algo activity_selector step 8800: {'selected': 0.9693486590038314, 'score': 0.9693486590038314, 'examples_seen': 242704, 'step': 8800, 'algorithm': 'activity_selector'}
I0114 20:12:43.000979 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0114 20:12:44.456922 125612664464896 run.py:748] Algo activity_selector step 8850 current loss 0.752496, current_train_items 244080.
I0114 20:12:44.650578 125612664464896 run.py:783] (val) algo activity_selector step 8850: {'selected': 0.9250936329588015, 'score': 0.9250936329588015, 'examples_seen': 244080, 'step': 8850, 'algorithm': 'activity_selector'}
I0114 20:12:44.650807 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0114 20:12:46.086923 125612664464896 run.py:748] Algo activity_selector step 8900 current loss 0.716094, current_train_items 245456.
I0114 20:12:46.291725 125612664464896 run.py:783] (val) algo activity_selector step 8900: {'selected': 0.9508840864440079, 'score': 0.9508840864440079, 'examples_seen': 245456, 'step': 8900, 'algorithm': 'activity_selector'}
I0114 20:12:46.291955 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0114 20:12:47.727414 125612664464896 run.py:748] Algo activity_selector step 8950 current loss 0.580622, current_train_items 246832.
I0114 20:12:47.932369 125612664464896 run.py:783] (val) algo activity_selector step 8950: {'selected': 0.9325626204238922, 'score': 0.9325626204238922, 'examples_seen': 246832, 'step': 8950, 'algorithm': 'activity_selector'}
I0114 20:12:47.932597 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0114 20:12:49.376964 125612664464896 run.py:748] Algo activity_selector step 9000 current loss 0.784505, current_train_items 248224.
I0114 20:12:49.582818 125612664464896 run.py:783] (val) algo activity_selector step 9000: {'selected': 0.9219330855018587, 'score': 0.9219330855018587, 'examples_seen': 248224, 'step': 9000, 'algorithm': 'activity_selector'}
I0114 20:12:49.583049 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0114 20:12:51.016456 125612664464896 run.py:748] Algo activity_selector step 9050 current loss 0.746717, current_train_items 249584.
I0114 20:12:51.221820 125612664464896 run.py:783] (val) algo activity_selector step 9050: {'selected': 0.9497206703910613, 'score': 0.9497206703910613, 'examples_seen': 249584, 'step': 9050, 'algorithm': 'activity_selector'}
I0114 20:12:51.222071 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0114 20:12:52.672533 125612664464896 run.py:748] Algo activity_selector step 9100 current loss 0.675942, current_train_items 250976.
I0114 20:12:52.863168 125612664464896 run.py:783] (val) algo activity_selector step 9100: {'selected': 0.9587426326129667, 'score': 0.9587426326129667, 'examples_seen': 250976, 'step': 9100, 'algorithm': 'activity_selector'}
I0114 20:12:52.863398 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0114 20:12:54.309755 125612664464896 run.py:748] Algo activity_selector step 9150 current loss 0.513864, current_train_items 252352.
I0114 20:12:54.514348 125612664464896 run.py:783] (val) algo activity_selector step 9150: {'selected': 0.928440366972477, 'score': 0.928440366972477, 'examples_seen': 252352, 'step': 9150, 'algorithm': 'activity_selector'}
I0114 20:12:54.514579 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0114 20:12:55.964720 125612664464896 run.py:748] Algo activity_selector step 9200 current loss 0.490127, current_train_items 253728.
I0114 20:12:56.155789 125612664464896 run.py:783] (val) algo activity_selector step 9200: {'selected': 0.9465930018416207, 'score': 0.9465930018416207, 'examples_seen': 253728, 'step': 9200, 'algorithm': 'activity_selector'}
I0114 20:12:56.156019 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0114 20:12:57.590504 125612664464896 run.py:748] Algo activity_selector step 9250 current loss 0.607789, current_train_items 255120.
I0114 20:12:57.796006 125612664464896 run.py:783] (val) algo activity_selector step 9250: {'selected': 0.9346153846153846, 'score': 0.9346153846153846, 'examples_seen': 255120, 'step': 9250, 'algorithm': 'activity_selector'}
I0114 20:12:57.796247 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0114 20:12:59.257330 125612664464896 run.py:748] Algo activity_selector step 9300 current loss 0.540445, current_train_items 256480.
I0114 20:12:59.447093 125612664464896 run.py:783] (val) algo activity_selector step 9300: {'selected': 0.9581749049429658, 'score': 0.9581749049429658, 'examples_seen': 256480, 'step': 9300, 'algorithm': 'activity_selector'}
I0114 20:12:59.447323 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0114 20:13:00.882421 125612664464896 run.py:748] Algo activity_selector step 9350 current loss 0.778105, current_train_items 257856.
I0114 20:13:01.087755 125612664464896 run.py:783] (val) algo activity_selector step 9350: {'selected': 0.9506398537477149, 'score': 0.9506398537477149, 'examples_seen': 257856, 'step': 9350, 'algorithm': 'activity_selector'}
I0114 20:13:01.087989 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0114 20:13:02.522559 125612664464896 run.py:748] Algo activity_selector step 9400 current loss 0.435250, current_train_items 259248.
I0114 20:13:02.727526 125612664464896 run.py:783] (val) algo activity_selector step 9400: {'selected': 0.9040590405904059, 'score': 0.9040590405904059, 'examples_seen': 259248, 'step': 9400, 'algorithm': 'activity_selector'}
I0114 20:13:02.727788 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.904, val scores are: activity_selector: 0.904
I0114 20:13:04.171014 125612664464896 run.py:748] Algo activity_selector step 9450 current loss 0.555858, current_train_items 260624.
I0114 20:13:04.376110 125612664464896 run.py:783] (val) algo activity_selector step 9450: {'selected': 0.9504132231404958, 'score': 0.9504132231404958, 'examples_seen': 260624, 'step': 9450, 'algorithm': 'activity_selector'}
I0114 20:13:04.376339 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0114 20:13:05.786810 125612664464896 run.py:748] Algo activity_selector step 9500 current loss 0.575021, current_train_items 262000.
I0114 20:13:06.016601 125612664464896 run.py:783] (val) algo activity_selector step 9500: {'selected': 0.9431818181818181, 'score': 0.9431818181818181, 'examples_seen': 262000, 'step': 9500, 'algorithm': 'activity_selector'}
I0114 20:13:06.016764 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0114 20:13:07.422833 125612664464896 run.py:748] Algo activity_selector step 9550 current loss 0.409289, current_train_items 263392.
I0114 20:13:07.654209 125612664464896 run.py:783] (val) algo activity_selector step 9550: {'selected': 0.9635627530364372, 'score': 0.9635627530364372, 'examples_seen': 263392, 'step': 9550, 'algorithm': 'activity_selector'}
I0114 20:13:07.654453 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0114 20:13:09.079351 125612664464896 run.py:748] Algo activity_selector step 9600 current loss 0.767856, current_train_items 264768.
I0114 20:13:09.313003 125612664464896 run.py:783] (val) algo activity_selector step 9600: {'selected': 0.9595141700404859, 'score': 0.9595141700404859, 'examples_seen': 264768, 'step': 9600, 'algorithm': 'activity_selector'}
I0114 20:13:09.313296 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0114 20:13:10.764938 125612664464896 run.py:748] Algo activity_selector step 9650 current loss 0.792579, current_train_items 266128.
I0114 20:13:10.956367 125612664464896 run.py:783] (val) algo activity_selector step 9650: {'selected': 0.9074074074074074, 'score': 0.9074074074074074, 'examples_seen': 266128, 'step': 9650, 'algorithm': 'activity_selector'}
I0114 20:13:10.956602 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0114 20:13:12.408805 125612664464896 run.py:748] Algo activity_selector step 9700 current loss 0.451240, current_train_items 267520.
I0114 20:13:12.618617 125612664464896 run.py:783] (val) algo activity_selector step 9700: {'selected': 0.966542750929368, 'score': 0.966542750929368, 'examples_seen': 267520, 'step': 9700, 'algorithm': 'activity_selector'}
I0114 20:13:12.619014 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0114 20:13:14.038845 125612664464896 run.py:748] Algo activity_selector step 9750 current loss 0.643938, current_train_items 268896.
I0114 20:13:14.272147 125612664464896 run.py:783] (val) algo activity_selector step 9750: {'selected': 0.8916155419222904, 'score': 0.8916155419222904, 'examples_seen': 268896, 'step': 9750, 'algorithm': 'activity_selector'}
I0114 20:13:14.272433 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.892, val scores are: activity_selector: 0.892
I0114 20:13:15.657998 125612664464896 run.py:748] Algo activity_selector step 9800 current loss 0.584669, current_train_items 270272.
I0114 20:13:15.902889 125612664464896 run.py:783] (val) algo activity_selector step 9800: {'selected': 0.9317269076305221, 'score': 0.9317269076305221, 'examples_seen': 270272, 'step': 9800, 'algorithm': 'activity_selector'}
I0114 20:13:15.903212 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0114 20:13:17.301338 125612664464896 run.py:748] Algo activity_selector step 9850 current loss 0.765076, current_train_items 271664.
I0114 20:13:17.531477 125612664464896 run.py:783] (val) algo activity_selector step 9850: {'selected': 0.9139784946236558, 'score': 0.9139784946236558, 'examples_seen': 271664, 'step': 9850, 'algorithm': 'activity_selector'}
I0114 20:13:17.531723 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0114 20:13:18.963461 125612664464896 run.py:748] Algo activity_selector step 9900 current loss 0.639367, current_train_items 273040.
I0114 20:13:19.154671 125612664464896 run.py:783] (val) algo activity_selector step 9900: {'selected': 0.9242424242424242, 'score': 0.9242424242424242, 'examples_seen': 273040, 'step': 9900, 'algorithm': 'activity_selector'}
I0114 20:13:19.154958 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0114 20:13:20.557693 125612664464896 run.py:748] Algo activity_selector step 9950 current loss 0.570871, current_train_items 274400.
I0114 20:13:20.761629 125612664464896 run.py:783] (val) algo activity_selector step 9950: {'selected': 0.9549902152641878, 'score': 0.9549902152641878, 'examples_seen': 274400, 'step': 9950, 'algorithm': 'activity_selector'}
I0114 20:13:20.761880 125612664464896 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0114 20:13:22.149305 125612664464896 run.py:813] Restoring best model from checkpoint...
I0114 20:13:31.803597 125612664464896 run.py:828] (test) algo activity_selector : {'selected': 0.8648648648648649, 'score': 0.8648648648648649, 'examples_seen': 275760, 'step': 10000, 'algorithm': 'activity_selector'}
I0114 20:13:31.803777 125612664464896 run.py:830] Done!
