I0716 18:19:09.330557 124088241030656 run.py:687] Algo activity_selector step 0 current loss 3.747048, current_train_items 64.
I0716 18:19:15.383601 124088241030656 run.py:722] (val) algo activity_selector step 0: {'selected': 0.18060200668896323, 'score': 0.18060200668896323, 'examples_seen': 64, 'step': 0, 'algorithm': 'activity_selector'}
I0716 18:19:15.383766 124088241030656 run.py:743] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.181, val scores are: activity_selector: 0.181
I0716 18:20:22.015661 124088241030656 run.py:687] Algo activity_selector step 50 current loss 3.637001, current_train_items 2080.
I0716 18:20:22.039808 124088241030656 run.py:722] (val) algo activity_selector step 50: {'selected': 0.7269303201506592, 'score': 0.7269303201506592, 'examples_seen': 2080, 'step': 50, 'algorithm': 'activity_selector'}
I0716 18:20:22.039984 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.181, current avg val score is 0.727, val scores are: activity_selector: 0.727
I0716 18:20:23.050532 124088241030656 run.py:687] Algo activity_selector step 100 current loss 3.513079, current_train_items 4064.
I0716 18:20:23.075610 124088241030656 run.py:722] (val) algo activity_selector step 100: {'selected': 0.5938144329896906, 'score': 0.5938144329896906, 'examples_seen': 4064, 'step': 100, 'algorithm': 'activity_selector'}
I0716 18:20:23.075759 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.727, current avg val score is 0.594, val scores are: activity_selector: 0.594
I0716 18:20:24.063281 124088241030656 run.py:687] Algo activity_selector step 150 current loss 4.592587, current_train_items 6016.
I0716 18:20:24.090921 124088241030656 run.py:722] (val) algo activity_selector step 150: {'selected': 0.6666666666666666, 'score': 0.6666666666666666, 'examples_seen': 6016, 'step': 150, 'algorithm': 'activity_selector'}
I0716 18:20:24.091068 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.727, current avg val score is 0.667, val scores are: activity_selector: 0.667
I0716 18:20:25.094872 124088241030656 run.py:687] Algo activity_selector step 200 current loss 4.327739, current_train_items 8016.
I0716 18:20:25.124093 124088241030656 run.py:722] (val) algo activity_selector step 200: {'selected': 0.7282415630550622, 'score': 0.7282415630550622, 'examples_seen': 8016, 'step': 200, 'algorithm': 'activity_selector'}
I0716 18:20:25.124241 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.727, current avg val score is 0.728, val scores are: activity_selector: 0.728
I0716 18:20:26.130028 124088241030656 run.py:687] Algo activity_selector step 250 current loss 4.610170, current_train_items 9952.
I0716 18:20:26.162445 124088241030656 run.py:722] (val) algo activity_selector step 250: {'selected': 0.625615763546798, 'score': 0.625615763546798, 'examples_seen': 9952, 'step': 250, 'algorithm': 'activity_selector'}
I0716 18:20:26.162613 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.728, current avg val score is 0.626, val scores are: activity_selector: 0.626
I0716 18:20:27.172578 124088241030656 run.py:687] Algo activity_selector step 300 current loss 1.624282, current_train_items 12000.
I0716 18:20:27.194408 124088241030656 run.py:722] (val) algo activity_selector step 300: {'selected': 0.7179487179487181, 'score': 0.7179487179487181, 'examples_seen': 12000, 'step': 300, 'algorithm': 'activity_selector'}
I0716 18:20:27.194574 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.728, current avg val score is 0.718, val scores are: activity_selector: 0.718
I0716 18:20:28.184395 124088241030656 run.py:687] Algo activity_selector step 350 current loss 1.417308, current_train_items 14032.
I0716 18:20:28.206792 124088241030656 run.py:722] (val) algo activity_selector step 350: {'selected': 0.6339285714285714, 'score': 0.6339285714285714, 'examples_seen': 14032, 'step': 350, 'algorithm': 'activity_selector'}
I0716 18:20:28.206940 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.728, current avg val score is 0.634, val scores are: activity_selector: 0.634
I0716 18:20:29.212493 124088241030656 run.py:687] Algo activity_selector step 400 current loss 2.343980, current_train_items 16000.
I0716 18:20:29.235802 124088241030656 run.py:722] (val) algo activity_selector step 400: {'selected': 0.738362760834671, 'score': 0.738362760834671, 'examples_seen': 16000, 'step': 400, 'algorithm': 'activity_selector'}
I0716 18:20:29.235948 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.728, current avg val score is 0.738, val scores are: activity_selector: 0.738
I0716 18:20:30.252894 124088241030656 run.py:687] Algo activity_selector step 450 current loss 2.062234, current_train_items 18000.
I0716 18:20:30.277336 124088241030656 run.py:722] (val) algo activity_selector step 450: {'selected': 0.8122743682310469, 'score': 0.8122743682310469, 'examples_seen': 18000, 'step': 450, 'algorithm': 'activity_selector'}
I0716 18:20:30.277485 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.738, current avg val score is 0.812, val scores are: activity_selector: 0.812
I0716 18:20:31.290741 124088241030656 run.py:687] Algo activity_selector step 500 current loss 2.881125, current_train_items 19952.
I0716 18:20:31.318236 124088241030656 run.py:722] (val) algo activity_selector step 500: {'selected': 0.792763157894737, 'score': 0.792763157894737, 'examples_seen': 19952, 'step': 500, 'algorithm': 'activity_selector'}
I0716 18:20:31.318382 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.812, current avg val score is 0.793, val scores are: activity_selector: 0.793
I0716 18:20:32.322221 124088241030656 run.py:687] Algo activity_selector step 550 current loss 3.407188, current_train_items 21920.
I0716 18:20:32.351616 124088241030656 run.py:722] (val) algo activity_selector step 550: {'selected': 0.771875, 'score': 0.771875, 'examples_seen': 21920, 'step': 550, 'algorithm': 'activity_selector'}
I0716 18:20:32.351766 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.812, current avg val score is 0.772, val scores are: activity_selector: 0.772
I0716 18:20:33.333436 124088241030656 run.py:687] Algo activity_selector step 600 current loss 3.346095, current_train_items 23904.
I0716 18:20:33.365471 124088241030656 run.py:722] (val) algo activity_selector step 600: {'selected': 0.7811934900542494, 'score': 0.7811934900542494, 'examples_seen': 23904, 'step': 600, 'algorithm': 'activity_selector'}
I0716 18:20:33.365624 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.812, current avg val score is 0.781, val scores are: activity_selector: 0.781
I0716 18:20:34.384242 124088241030656 run.py:687] Algo activity_selector step 650 current loss 1.096954, current_train_items 25920.
I0716 18:20:34.406377 124088241030656 run.py:722] (val) algo activity_selector step 650: {'selected': 0.8407871198568874, 'score': 0.8407871198568874, 'examples_seen': 25920, 'step': 650, 'algorithm': 'activity_selector'}
I0716 18:20:34.406533 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.812, current avg val score is 0.841, val scores are: activity_selector: 0.841
I0716 18:20:35.438645 124088241030656 run.py:687] Algo activity_selector step 700 current loss 0.840597, current_train_items 27952.
I0716 18:20:35.461118 124088241030656 run.py:722] (val) algo activity_selector step 700: {'selected': 0.8386023294509151, 'score': 0.8386023294509151, 'examples_seen': 27952, 'step': 700, 'algorithm': 'activity_selector'}
I0716 18:20:35.461267 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.841, current avg val score is 0.839, val scores are: activity_selector: 0.839
I0716 18:20:36.450381 124088241030656 run.py:687] Algo activity_selector step 750 current loss 1.647362, current_train_items 29936.
I0716 18:20:36.473751 124088241030656 run.py:722] (val) algo activity_selector step 750: {'selected': 0.8132231404958677, 'score': 0.8132231404958677, 'examples_seen': 29936, 'step': 750, 'algorithm': 'activity_selector'}
I0716 18:20:36.473897 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.841, current avg val score is 0.813, val scores are: activity_selector: 0.813
I0716 18:20:37.477721 124088241030656 run.py:687] Algo activity_selector step 800 current loss 0.916687, current_train_items 31920.
I0716 18:20:37.502281 124088241030656 run.py:722] (val) algo activity_selector step 800: {'selected': 0.8443649373881933, 'score': 0.8443649373881933, 'examples_seen': 31920, 'step': 800, 'algorithm': 'activity_selector'}
I0716 18:20:37.502430 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.841, current avg val score is 0.844, val scores are: activity_selector: 0.844
I0716 18:20:38.498557 124088241030656 run.py:687] Algo activity_selector step 850 current loss 2.885971, current_train_items 33904.
I0716 18:20:38.525557 124088241030656 run.py:722] (val) algo activity_selector step 850: {'selected': 0.8604651162790697, 'score': 0.8604651162790697, 'examples_seen': 33904, 'step': 850, 'algorithm': 'activity_selector'}
I0716 18:20:38.525702 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.844, current avg val score is 0.860, val scores are: activity_selector: 0.860
I0716 18:20:39.546572 124088241030656 run.py:687] Algo activity_selector step 900 current loss 2.798396, current_train_items 35856.
I0716 18:20:39.575223 124088241030656 run.py:722] (val) algo activity_selector step 900: {'selected': 0.8695652173913043, 'score': 0.8695652173913043, 'examples_seen': 35856, 'step': 900, 'algorithm': 'activity_selector'}
I0716 18:20:39.575372 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.860, current avg val score is 0.870, val scores are: activity_selector: 0.870
I0716 18:20:40.580634 124088241030656 run.py:687] Algo activity_selector step 950 current loss 1.696184, current_train_items 37808.
I0716 18:20:40.614553 124088241030656 run.py:722] (val) algo activity_selector step 950: {'selected': 0.8909774436090225, 'score': 0.8909774436090225, 'examples_seen': 37808, 'step': 950, 'algorithm': 'activity_selector'}
I0716 18:20:40.614701 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.870, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0716 18:20:41.643548 124088241030656 run.py:687] Algo activity_selector step 1000 current loss 0.574007, current_train_items 39872.
I0716 18:20:41.665487 124088241030656 run.py:722] (val) algo activity_selector step 1000: {'selected': 0.898876404494382, 'score': 0.898876404494382, 'examples_seen': 39872, 'step': 1000, 'algorithm': 'activity_selector'}
I0716 18:20:41.665641 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.891, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0716 18:20:42.700259 124088241030656 run.py:687] Algo activity_selector step 1050 current loss 0.467282, current_train_items 41872.
I0716 18:20:42.722570 124088241030656 run.py:722] (val) algo activity_selector step 1050: {'selected': 0.926829268292683, 'score': 0.926829268292683, 'examples_seen': 41872, 'step': 1050, 'algorithm': 'activity_selector'}
I0716 18:20:42.722720 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.899, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0716 18:20:43.734215 124088241030656 run.py:687] Algo activity_selector step 1100 current loss 1.723588, current_train_items 43872.
I0716 18:20:43.757625 124088241030656 run.py:722] (val) algo activity_selector step 1100: {'selected': 0.8914285714285713, 'score': 0.8914285714285713, 'examples_seen': 43872, 'step': 1100, 'algorithm': 'activity_selector'}
I0716 18:20:43.757771 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.927, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0716 18:20:44.765987 124088241030656 run.py:687] Algo activity_selector step 1150 current loss 1.815398, current_train_items 45856.
I0716 18:20:44.790212 124088241030656 run.py:722] (val) algo activity_selector step 1150: {'selected': 0.8512820512820513, 'score': 0.8512820512820513, 'examples_seen': 45856, 'step': 1150, 'algorithm': 'activity_selector'}
I0716 18:20:44.790359 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.927, current avg val score is 0.851, val scores are: activity_selector: 0.851
I0716 18:20:45.795132 124088241030656 run.py:687] Algo activity_selector step 1200 current loss 2.473866, current_train_items 47808.
I0716 18:20:45.822122 124088241030656 run.py:722] (val) algo activity_selector step 1200: {'selected': 0.9050279329608939, 'score': 0.9050279329608939, 'examples_seen': 47808, 'step': 1200, 'algorithm': 'activity_selector'}
I0716 18:20:45.822269 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.927, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0716 18:20:46.817673 124088241030656 run.py:687] Algo activity_selector step 1250 current loss 2.400683, current_train_items 49808.
I0716 18:20:46.847064 124088241030656 run.py:722] (val) algo activity_selector step 1250: {'selected': 0.865064695009242, 'score': 0.865064695009242, 'examples_seen': 49808, 'step': 1250, 'algorithm': 'activity_selector'}
I0716 18:20:46.847216 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.927, current avg val score is 0.865, val scores are: activity_selector: 0.865
I0716 18:20:47.851885 124088241030656 run.py:687] Algo activity_selector step 1300 current loss 4.027923, current_train_items 51760.
I0716 18:20:47.889791 124088241030656 run.py:722] (val) algo activity_selector step 1300: {'selected': 0.8992248062015505, 'score': 0.8992248062015505, 'examples_seen': 51760, 'step': 1300, 'algorithm': 'activity_selector'}
I0716 18:20:47.889941 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.927, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0716 18:20:48.910078 124088241030656 run.py:687] Algo activity_selector step 1350 current loss 0.535337, current_train_items 53792.
I0716 18:20:48.931650 124088241030656 run.py:722] (val) algo activity_selector step 1350: {'selected': 0.9119373776908023, 'score': 0.9119373776908023, 'examples_seen': 53792, 'step': 1350, 'algorithm': 'activity_selector'}
I0716 18:20:48.931796 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.927, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0716 18:20:49.938790 124088241030656 run.py:687] Algo activity_selector step 1400 current loss 0.563652, current_train_items 55824.
I0716 18:20:49.961427 124088241030656 run.py:722] (val) algo activity_selector step 1400: {'selected': 0.942271880819367, 'score': 0.942271880819367, 'examples_seen': 55824, 'step': 1400, 'algorithm': 'activity_selector'}
I0716 18:20:49.961594 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.927, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0716 18:20:50.984454 124088241030656 run.py:687] Algo activity_selector step 1450 current loss 1.323951, current_train_items 57792.
I0716 18:20:51.009683 124088241030656 run.py:722] (val) algo activity_selector step 1450: {'selected': 0.9477756286266924, 'score': 0.9477756286266924, 'examples_seen': 57792, 'step': 1450, 'algorithm': 'activity_selector'}
I0716 18:20:51.009828 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.942, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0716 18:20:52.025278 124088241030656 run.py:687] Algo activity_selector step 1500 current loss 0.412347, current_train_items 59792.
I0716 18:20:52.050009 124088241030656 run.py:722] (val) algo activity_selector step 1500: {'selected': 0.9041591320072333, 'score': 0.9041591320072333, 'examples_seen': 59792, 'step': 1500, 'algorithm': 'activity_selector'}
I0716 18:20:52.050156 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.948, current avg val score is 0.904, val scores are: activity_selector: 0.904
I0716 18:20:53.046103 124088241030656 run.py:687] Algo activity_selector step 1550 current loss 0.688894, current_train_items 61744.
I0716 18:20:53.073686 124088241030656 run.py:722] (val) algo activity_selector step 1550: {'selected': 0.9233870967741935, 'score': 0.9233870967741935, 'examples_seen': 61744, 'step': 1550, 'algorithm': 'activity_selector'}
I0716 18:20:53.073836 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.948, current avg val score is 0.923, val scores are: activity_selector: 0.923
I0716 18:20:54.077763 124088241030656 run.py:687] Algo activity_selector step 1600 current loss 2.029214, current_train_items 63712.
I0716 18:20:54.106745 124088241030656 run.py:722] (val) algo activity_selector step 1600: {'selected': 0.9130434782608695, 'score': 0.9130434782608695, 'examples_seen': 63712, 'step': 1600, 'algorithm': 'activity_selector'}
I0716 18:20:54.106891 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.948, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0716 18:20:55.103366 124088241030656 run.py:687] Algo activity_selector step 1650 current loss 4.489625, current_train_items 65712.
I0716 18:20:55.135322 124088241030656 run.py:722] (val) algo activity_selector step 1650: {'selected': 0.9273743016759777, 'score': 0.9273743016759777, 'examples_seen': 65712, 'step': 1650, 'algorithm': 'activity_selector'}
I0716 18:20:55.135472 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.948, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0716 18:20:56.190131 124088241030656 run.py:687] Algo activity_selector step 1700 current loss 0.382573, current_train_items 67712.
I0716 18:20:56.212468 124088241030656 run.py:722] (val) algo activity_selector step 1700: {'selected': 0.9132075471698113, 'score': 0.9132075471698113, 'examples_seen': 67712, 'step': 1700, 'algorithm': 'activity_selector'}
I0716 18:20:56.212622 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.948, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0716 18:20:57.212283 124088241030656 run.py:687] Algo activity_selector step 1750 current loss 0.439554, current_train_items 69744.
I0716 18:20:57.234452 124088241030656 run.py:722] (val) algo activity_selector step 1750: {'selected': 0.9664179104477612, 'score': 0.9664179104477612, 'examples_seen': 69744, 'step': 1750, 'algorithm': 'activity_selector'}
I0716 18:20:57.234607 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.948, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0716 18:20:58.232221 124088241030656 run.py:687] Algo activity_selector step 1800 current loss 0.474230, current_train_items 71728.
I0716 18:20:58.255758 124088241030656 run.py:722] (val) algo activity_selector step 1800: {'selected': 0.906764168190128, 'score': 0.906764168190128, 'examples_seen': 71728, 'step': 1800, 'algorithm': 'activity_selector'}
I0716 18:20:58.255906 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.966, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0716 18:20:59.247927 124088241030656 run.py:687] Algo activity_selector step 1850 current loss 0.536617, current_train_items 73712.
I0716 18:20:59.272656 124088241030656 run.py:722] (val) algo activity_selector step 1850: {'selected': 0.9325396825396824, 'score': 0.9325396825396824, 'examples_seen': 73712, 'step': 1850, 'algorithm': 'activity_selector'}
I0716 18:20:59.272802 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.966, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0716 18:21:00.240356 124088241030656 run.py:687] Algo activity_selector step 1900 current loss 2.294566, current_train_items 75712.
I0716 18:21:00.267843 124088241030656 run.py:722] (val) algo activity_selector step 1900: {'selected': 0.940952380952381, 'score': 0.940952380952381, 'examples_seen': 75712, 'step': 1900, 'algorithm': 'activity_selector'}
I0716 18:21:00.267991 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.966, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0716 18:21:01.300439 124088241030656 run.py:687] Algo activity_selector step 1950 current loss 1.661929, current_train_items 77664.
I0716 18:21:01.330201 124088241030656 run.py:722] (val) algo activity_selector step 1950: {'selected': 0.9320754716981132, 'score': 0.9320754716981132, 'examples_seen': 77664, 'step': 1950, 'algorithm': 'activity_selector'}
I0716 18:21:01.330352 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.966, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0716 18:21:02.337090 124088241030656 run.py:687] Algo activity_selector step 2000 current loss 4.042192, current_train_items 79632.
I0716 18:21:02.371366 124088241030656 run.py:722] (val) algo activity_selector step 2000: {'selected': 0.8991596638655462, 'score': 0.8991596638655462, 'examples_seen': 79632, 'step': 2000, 'algorithm': 'activity_selector'}
I0716 18:21:02.371512 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.966, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0716 18:21:03.384230 124088241030656 run.py:687] Algo activity_selector step 2050 current loss 0.224853, current_train_items 81680.
I0716 18:21:03.408524 124088241030656 run.py:722] (val) algo activity_selector step 2050: {'selected': 0.9271028037383177, 'score': 0.9271028037383177, 'examples_seen': 81680, 'step': 2050, 'algorithm': 'activity_selector'}
I0716 18:21:03.408674 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.966, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0716 18:21:04.432056 124088241030656 run.py:687] Algo activity_selector step 2100 current loss 0.238147, current_train_items 83680.
I0716 18:21:04.454640 124088241030656 run.py:722] (val) algo activity_selector step 2100: {'selected': 0.9322709163346614, 'score': 0.9322709163346614, 'examples_seen': 83680, 'step': 2100, 'algorithm': 'activity_selector'}
I0716 18:21:04.454787 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.966, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0716 18:21:05.452624 124088241030656 run.py:687] Algo activity_selector step 2150 current loss 1.724382, current_train_items 85680.
I0716 18:21:05.476124 124088241030656 run.py:722] (val) algo activity_selector step 2150: {'selected': 0.8628158844765342, 'score': 0.8628158844765342, 'examples_seen': 85680, 'step': 2150, 'algorithm': 'activity_selector'}
I0716 18:21:05.476271 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.966, current avg val score is 0.863, val scores are: activity_selector: 0.863
I0716 18:21:06.505999 124088241030656 run.py:687] Algo activity_selector step 2200 current loss 0.548224, current_train_items 87664.
I0716 18:21:06.530758 124088241030656 run.py:722] (val) algo activity_selector step 2200: {'selected': 0.9565217391304347, 'score': 0.9565217391304347, 'examples_seen': 87664, 'step': 2200, 'algorithm': 'activity_selector'}
I0716 18:21:06.530906 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.966, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0716 18:21:07.542104 124088241030656 run.py:687] Algo activity_selector step 2250 current loss 2.399754, current_train_items 89632.
I0716 18:21:07.569366 124088241030656 run.py:722] (val) algo activity_selector step 2250: {'selected': 0.9194499017681729, 'score': 0.9194499017681729, 'examples_seen': 89632, 'step': 2250, 'algorithm': 'activity_selector'}
I0716 18:21:07.569513 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.966, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0716 18:21:08.565266 124088241030656 run.py:687] Algo activity_selector step 2300 current loss 0.663105, current_train_items 91616.
I0716 18:21:08.594054 124088241030656 run.py:722] (val) algo activity_selector step 2300: {'selected': 0.9495327102803739, 'score': 0.9495327102803739, 'examples_seen': 91616, 'step': 2300, 'algorithm': 'activity_selector'}
I0716 18:21:08.594204 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.966, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0716 18:21:09.604159 124088241030656 run.py:687] Algo activity_selector step 2350 current loss 3.916729, current_train_items 93568.
I0716 18:21:09.635954 124088241030656 run.py:722] (val) algo activity_selector step 2350: {'selected': 0.9271758436944938, 'score': 0.9271758436944938, 'examples_seen': 93568, 'step': 2350, 'algorithm': 'activity_selector'}
I0716 18:21:09.636118 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.966, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0716 18:21:10.655847 124088241030656 run.py:687] Algo activity_selector step 2400 current loss 0.454545, current_train_items 95600.
I0716 18:21:10.678116 124088241030656 run.py:722] (val) algo activity_selector step 2400: {'selected': 0.9508840864440079, 'score': 0.9508840864440079, 'examples_seen': 95600, 'step': 2400, 'algorithm': 'activity_selector'}
I0716 18:21:10.678264 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.966, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0716 18:21:11.720603 124088241030656 run.py:687] Algo activity_selector step 2450 current loss 0.167589, current_train_items 97632.
I0716 18:21:11.744796 124088241030656 run.py:722] (val) algo activity_selector step 2450: {'selected': 0.9402061855670103, 'score': 0.9402061855670103, 'examples_seen': 97632, 'step': 2450, 'algorithm': 'activity_selector'}
I0716 18:21:11.744945 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.966, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0716 18:21:12.752541 124088241030656 run.py:687] Algo activity_selector step 2500 current loss 1.337559, current_train_items 99600.
I0716 18:21:12.776196 124088241030656 run.py:722] (val) algo activity_selector step 2500: {'selected': 0.9539078156312626, 'score': 0.9539078156312626, 'examples_seen': 99600, 'step': 2500, 'algorithm': 'activity_selector'}
I0716 18:21:12.776355 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.966, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0716 18:21:13.780879 124088241030656 run.py:687] Algo activity_selector step 2550 current loss 0.327642, current_train_items 101600.
I0716 18:21:13.805677 124088241030656 run.py:722] (val) algo activity_selector step 2550: {'selected': 0.944337811900192, 'score': 0.944337811900192, 'examples_seen': 101600, 'step': 2550, 'algorithm': 'activity_selector'}
I0716 18:21:13.805835 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.966, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0716 18:21:14.817430 124088241030656 run.py:687] Algo activity_selector step 2600 current loss 0.697590, current_train_items 103568.
I0716 18:21:14.845304 124088241030656 run.py:722] (val) algo activity_selector step 2600: {'selected': 0.9575289575289575, 'score': 0.9575289575289575, 'examples_seen': 103568, 'step': 2600, 'algorithm': 'activity_selector'}
I0716 18:21:14.845453 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.966, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0716 18:21:15.836273 124088241030656 run.py:687] Algo activity_selector step 2650 current loss 3.993713, current_train_items 105520.
I0716 18:21:15.865463 124088241030656 run.py:722] (val) algo activity_selector step 2650: {'selected': 0.9618874773139745, 'score': 0.9618874773139745, 'examples_seen': 105520, 'step': 2650, 'algorithm': 'activity_selector'}
I0716 18:21:15.865624 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.966, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0716 18:21:16.892364 124088241030656 run.py:687] Algo activity_selector step 2700 current loss 3.645962, current_train_items 107520.
I0716 18:21:16.925540 124088241030656 run.py:722] (val) algo activity_selector step 2700: {'selected': 0.8937007874015748, 'score': 0.8937007874015748, 'examples_seen': 107520, 'step': 2700, 'algorithm': 'activity_selector'}
I0716 18:21:16.925686 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.966, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0716 18:21:17.931768 124088241030656 run.py:687] Algo activity_selector step 2750 current loss 0.497356, current_train_items 109520.
I0716 18:21:17.953397 124088241030656 run.py:722] (val) algo activity_selector step 2750: {'selected': 0.9748549323017409, 'score': 0.9748549323017409, 'examples_seen': 109520, 'step': 2750, 'algorithm': 'activity_selector'}
I0716 18:21:17.953552 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.966, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0716 18:21:18.971770 124088241030656 run.py:687] Algo activity_selector step 2800 current loss 0.176139, current_train_items 111552.
I0716 18:21:18.994380 124088241030656 run.py:722] (val) algo activity_selector step 2800: {'selected': 0.9584905660377359, 'score': 0.9584905660377359, 'examples_seen': 111552, 'step': 2800, 'algorithm': 'activity_selector'}
I0716 18:21:18.994548 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0716 18:21:19.983812 124088241030656 run.py:687] Algo activity_selector step 2850 current loss 0.380668, current_train_items 113552.
I0716 18:21:20.007236 124088241030656 run.py:722] (val) algo activity_selector step 2850: {'selected': 0.9453860640301318, 'score': 0.9453860640301318, 'examples_seen': 113552, 'step': 2850, 'algorithm': 'activity_selector'}
I0716 18:21:20.007382 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0716 18:21:21.005996 124088241030656 run.py:687] Algo activity_selector step 2900 current loss 0.315209, current_train_items 115520.
I0716 18:21:21.030577 124088241030656 run.py:722] (val) algo activity_selector step 2900: {'selected': 0.9061371841155236, 'score': 0.9061371841155236, 'examples_seen': 115520, 'step': 2900, 'algorithm': 'activity_selector'}
I0716 18:21:21.030723 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0716 18:21:22.030417 124088241030656 run.py:687] Algo activity_selector step 2950 current loss 1.971057, current_train_items 117520.
I0716 18:21:22.057875 124088241030656 run.py:722] (val) algo activity_selector step 2950: {'selected': 0.9254901960784314, 'score': 0.9254901960784314, 'examples_seen': 117520, 'step': 2950, 'algorithm': 'activity_selector'}
I0716 18:21:22.058022 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0716 18:21:23.048438 124088241030656 run.py:687] Algo activity_selector step 3000 current loss 2.703684, current_train_items 119456.
I0716 18:21:23.077686 124088241030656 run.py:722] (val) algo activity_selector step 3000: {'selected': 0.8796992481203009, 'score': 0.8796992481203009, 'examples_seen': 119456, 'step': 3000, 'algorithm': 'activity_selector'}
I0716 18:21:23.077832 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0716 18:21:24.073857 124088241030656 run.py:687] Algo activity_selector step 3050 current loss 2.854991, current_train_items 121424.
I0716 18:21:24.106067 124088241030656 run.py:722] (val) algo activity_selector step 3050: {'selected': 0.9541984732824428, 'score': 0.9541984732824428, 'examples_seen': 121424, 'step': 3050, 'algorithm': 'activity_selector'}
I0716 18:21:24.106215 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0716 18:21:25.100837 124088241030656 run.py:687] Algo activity_selector step 3100 current loss 0.276002, current_train_items 123472.
I0716 18:21:25.122741 124088241030656 run.py:722] (val) algo activity_selector step 3100: {'selected': 0.9343629343629344, 'score': 0.9343629343629344, 'examples_seen': 123472, 'step': 3100, 'algorithm': 'activity_selector'}
I0716 18:21:25.122886 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0716 18:21:26.135203 124088241030656 run.py:687] Algo activity_selector step 3150 current loss 0.202025, current_train_items 125472.
I0716 18:21:26.157405 124088241030656 run.py:722] (val) algo activity_selector step 3150: {'selected': 0.9576923076923076, 'score': 0.9576923076923076, 'examples_seen': 125472, 'step': 3150, 'algorithm': 'activity_selector'}
I0716 18:21:26.157560 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0716 18:21:27.166388 124088241030656 run.py:687] Algo activity_selector step 3200 current loss 1.252020, current_train_items 127488.
I0716 18:21:27.190839 124088241030656 run.py:722] (val) algo activity_selector step 3200: {'selected': 0.9511278195488722, 'score': 0.9511278195488722, 'examples_seen': 127488, 'step': 3200, 'algorithm': 'activity_selector'}
I0716 18:21:27.190993 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0716 18:21:28.190001 124088241030656 run.py:687] Algo activity_selector step 3250 current loss 0.280814, current_train_items 129456.
I0716 18:21:28.214805 124088241030656 run.py:722] (val) algo activity_selector step 3250: {'selected': 0.8950276243093923, 'score': 0.8950276243093923, 'examples_seen': 129456, 'step': 3250, 'algorithm': 'activity_selector'}
I0716 18:21:28.214951 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.895, val scores are: activity_selector: 0.895
I0716 18:21:29.219537 124088241030656 run.py:687] Algo activity_selector step 3300 current loss 2.340975, current_train_items 131424.
I0716 18:21:29.247113 124088241030656 run.py:722] (val) algo activity_selector step 3300: {'selected': 0.946360153256705, 'score': 0.946360153256705, 'examples_seen': 131424, 'step': 3300, 'algorithm': 'activity_selector'}
I0716 18:21:29.247282 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0716 18:21:30.219857 124088241030656 run.py:687] Algo activity_selector step 3350 current loss 2.296740, current_train_items 133408.
I0716 18:21:30.249080 124088241030656 run.py:722] (val) algo activity_selector step 3350: {'selected': 0.9411764705882354, 'score': 0.9411764705882354, 'examples_seen': 133408, 'step': 3350, 'algorithm': 'activity_selector'}
I0716 18:21:30.249227 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0716 18:21:31.260919 124088241030656 run.py:687] Algo activity_selector step 3400 current loss 2.591536, current_train_items 135360.
I0716 18:21:31.292985 124088241030656 run.py:722] (val) algo activity_selector step 3400: {'selected': 0.9516441005802708, 'score': 0.9516441005802708, 'examples_seen': 135360, 'step': 3400, 'algorithm': 'activity_selector'}
I0716 18:21:31.293131 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0716 18:21:32.306041 124088241030656 run.py:687] Algo activity_selector step 3450 current loss 0.416928, current_train_items 137392.
I0716 18:21:32.329786 124088241030656 run.py:722] (val) algo activity_selector step 3450: {'selected': 0.968342644320298, 'score': 0.968342644320298, 'examples_seen': 137392, 'step': 3450, 'algorithm': 'activity_selector'}
I0716 18:21:32.329942 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0716 18:21:33.343879 124088241030656 run.py:687] Algo activity_selector step 3500 current loss 0.081775, current_train_items 139424.
I0716 18:21:33.368423 124088241030656 run.py:722] (val) algo activity_selector step 3500: {'selected': 0.97165991902834, 'score': 0.97165991902834, 'examples_seen': 139424, 'step': 3500, 'algorithm': 'activity_selector'}
I0716 18:21:33.368577 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0716 18:21:34.382625 124088241030656 run.py:687] Algo activity_selector step 3550 current loss 1.406111, current_train_items 141408.
I0716 18:21:34.405664 124088241030656 run.py:722] (val) algo activity_selector step 3550: {'selected': 0.9543726235741444, 'score': 0.9543726235741444, 'examples_seen': 141408, 'step': 3550, 'algorithm': 'activity_selector'}
I0716 18:21:34.405819 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0716 18:21:35.395256 124088241030656 run.py:687] Algo activity_selector step 3600 current loss 0.394076, current_train_items 143392.
I0716 18:21:35.419826 124088241030656 run.py:722] (val) algo activity_selector step 3600: {'selected': 0.9669902912621359, 'score': 0.9669902912621359, 'examples_seen': 143392, 'step': 3600, 'algorithm': 'activity_selector'}
I0716 18:21:35.419975 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0716 18:21:36.429949 124088241030656 run.py:687] Algo activity_selector step 3650 current loss 0.663024, current_train_items 145360.
I0716 18:21:36.457291 124088241030656 run.py:722] (val) algo activity_selector step 3650: {'selected': 0.9667318982387475, 'score': 0.9667318982387475, 'examples_seen': 145360, 'step': 3650, 'algorithm': 'activity_selector'}
I0716 18:21:36.457439 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0716 18:21:37.453343 124088241030656 run.py:687] Algo activity_selector step 3700 current loss 2.202545, current_train_items 147312.
I0716 18:21:37.485305 124088241030656 run.py:722] (val) algo activity_selector step 3700: {'selected': 0.9491525423728815, 'score': 0.9491525423728815, 'examples_seen': 147312, 'step': 3700, 'algorithm': 'activity_selector'}
I0716 18:21:37.485451 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0716 18:21:38.479372 124088241030656 run.py:687] Algo activity_selector step 3750 current loss 2.336404, current_train_items 149312.
I0716 18:21:38.512613 124088241030656 run.py:722] (val) algo activity_selector step 3750: {'selected': 0.9736842105263158, 'score': 0.9736842105263158, 'examples_seen': 149312, 'step': 3750, 'algorithm': 'activity_selector'}
I0716 18:21:38.512765 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0716 18:21:39.529251 124088241030656 run.py:687] Algo activity_selector step 3800 current loss 0.567852, current_train_items 151328.
I0716 18:21:39.551447 124088241030656 run.py:722] (val) algo activity_selector step 3800: {'selected': 0.9108159392789373, 'score': 0.9108159392789373, 'examples_seen': 151328, 'step': 3800, 'algorithm': 'activity_selector'}
I0716 18:21:39.551609 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0716 18:21:40.564377 124088241030656 run.py:687] Algo activity_selector step 3850 current loss 0.210257, current_train_items 153344.
I0716 18:21:40.587078 124088241030656 run.py:722] (val) algo activity_selector step 3850: {'selected': 0.912280701754386, 'score': 0.912280701754386, 'examples_seen': 153344, 'step': 3850, 'algorithm': 'activity_selector'}
I0716 18:21:40.587227 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0716 18:21:41.596381 124088241030656 run.py:687] Algo activity_selector step 3900 current loss 0.312943, current_train_items 155344.
I0716 18:21:41.620213 124088241030656 run.py:722] (val) algo activity_selector step 3900: {'selected': 0.9714285714285714, 'score': 0.9714285714285714, 'examples_seen': 155344, 'step': 3900, 'algorithm': 'activity_selector'}
I0716 18:21:41.620359 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0716 18:21:42.623318 124088241030656 run.py:687] Algo activity_selector step 3950 current loss 0.727966, current_train_items 157312.
I0716 18:21:42.653568 124088241030656 run.py:722] (val) algo activity_selector step 3950: {'selected': 0.9420560747663551, 'score': 0.9420560747663551, 'examples_seen': 157312, 'step': 3950, 'algorithm': 'activity_selector'}
I0716 18:21:42.653750 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0716 18:21:43.658328 124088241030656 run.py:687] Algo activity_selector step 4000 current loss 1.858747, current_train_items 159312.
I0716 18:21:43.684846 124088241030656 run.py:722] (val) algo activity_selector step 4000: {'selected': 0.9285714285714286, 'score': 0.9285714285714286, 'examples_seen': 159312, 'step': 4000, 'algorithm': 'activity_selector'}
I0716 18:21:43.684994 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0716 18:21:44.676111 124088241030656 run.py:687] Algo activity_selector step 4050 current loss 1.587852, current_train_items 161248.
I0716 18:21:44.704777 124088241030656 run.py:722] (val) algo activity_selector step 4050: {'selected': 0.9761904761904762, 'score': 0.9761904761904762, 'examples_seen': 161248, 'step': 4050, 'algorithm': 'activity_selector'}
I0716 18:21:44.704927 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.975, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0716 18:21:45.713273 124088241030656 run.py:687] Algo activity_selector step 4100 current loss 1.968797, current_train_items 163216.
I0716 18:21:45.745017 124088241030656 run.py:722] (val) algo activity_selector step 4100: {'selected': 0.9603024574669187, 'score': 0.9603024574669187, 'examples_seen': 163216, 'step': 4100, 'algorithm': 'activity_selector'}
I0716 18:21:45.745162 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.976, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0716 18:21:46.750011 124088241030656 run.py:687] Algo activity_selector step 4150 current loss 0.254727, current_train_items 165280.
I0716 18:21:46.772378 124088241030656 run.py:722] (val) algo activity_selector step 4150: {'selected': 0.9190207156308852, 'score': 0.9190207156308852, 'examples_seen': 165280, 'step': 4150, 'algorithm': 'activity_selector'}
I0716 18:21:46.772533 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.976, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0716 18:21:47.786915 124088241030656 run.py:687] Algo activity_selector step 4200 current loss 0.224825, current_train_items 167264.
I0716 18:21:47.810124 124088241030656 run.py:722] (val) algo activity_selector step 4200: {'selected': 0.9669902912621359, 'score': 0.9669902912621359, 'examples_seen': 167264, 'step': 4200, 'algorithm': 'activity_selector'}
I0716 18:21:47.810284 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.976, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0716 18:21:48.830834 124088241030656 run.py:687] Algo activity_selector step 4250 current loss 1.319418, current_train_items 169280.
I0716 18:21:48.854932 124088241030656 run.py:722] (val) algo activity_selector step 4250: {'selected': 0.9346153846153846, 'score': 0.9346153846153846, 'examples_seen': 169280, 'step': 4250, 'algorithm': 'activity_selector'}
I0716 18:21:48.855082 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.976, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0716 18:21:49.859721 124088241030656 run.py:687] Algo activity_selector step 4300 current loss 0.485600, current_train_items 171248.
I0716 18:21:49.884586 124088241030656 run.py:722] (val) algo activity_selector step 4300: {'selected': 0.9603024574669187, 'score': 0.9603024574669187, 'examples_seen': 171248, 'step': 4300, 'algorithm': 'activity_selector'}
I0716 18:21:49.884733 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.976, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0716 18:21:50.890506 124088241030656 run.py:687] Algo activity_selector step 4350 current loss 1.948466, current_train_items 173216.
I0716 18:21:50.918500 124088241030656 run.py:722] (val) algo activity_selector step 4350: {'selected': 0.9146341463414634, 'score': 0.9146341463414634, 'examples_seen': 173216, 'step': 4350, 'algorithm': 'activity_selector'}
I0716 18:21:50.918654 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.976, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0716 18:21:51.905772 124088241030656 run.py:687] Algo activity_selector step 4400 current loss 1.246482, current_train_items 175232.
I0716 18:21:51.934731 124088241030656 run.py:722] (val) algo activity_selector step 4400: {'selected': 0.9558232931726908, 'score': 0.9558232931726908, 'examples_seen': 175232, 'step': 4400, 'algorithm': 'activity_selector'}
I0716 18:21:51.934880 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.976, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0716 18:21:52.946948 124088241030656 run.py:687] Algo activity_selector step 4450 current loss 2.365833, current_train_items 177168.
I0716 18:21:52.980801 124088241030656 run.py:722] (val) algo activity_selector step 4450: {'selected': 0.9440000000000001, 'score': 0.9440000000000001, 'examples_seen': 177168, 'step': 4450, 'algorithm': 'activity_selector'}
I0716 18:21:52.980962 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.976, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0716 18:21:54.003731 124088241030656 run.py:687] Algo activity_selector step 4500 current loss 0.367357, current_train_items 179216.
I0716 18:21:54.025948 124088241030656 run.py:722] (val) algo activity_selector step 4500: {'selected': 0.9471544715447154, 'score': 0.9471544715447154, 'examples_seen': 179216, 'step': 4500, 'algorithm': 'activity_selector'}
I0716 18:21:54.026097 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.976, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0716 18:21:55.032309 124088241030656 run.py:687] Algo activity_selector step 4550 current loss 0.326758, current_train_items 181232.
I0716 18:21:55.054914 124088241030656 run.py:722] (val) algo activity_selector step 4550: {'selected': 0.9330783938814532, 'score': 0.9330783938814532, 'examples_seen': 181232, 'step': 4550, 'algorithm': 'activity_selector'}
I0716 18:21:55.055064 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.976, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0716 18:21:56.069212 124088241030656 run.py:687] Algo activity_selector step 4600 current loss 1.251217, current_train_items 183216.
I0716 18:21:56.092769 124088241030656 run.py:722] (val) algo activity_selector step 4600: {'selected': 0.94, 'score': 0.94, 'examples_seen': 183216, 'step': 4600, 'algorithm': 'activity_selector'}
I0716 18:21:56.092915 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.976, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0716 18:21:57.081543 124088241030656 run.py:687] Algo activity_selector step 4650 current loss 0.205199, current_train_items 185200.
I0716 18:21:57.106325 124088241030656 run.py:722] (val) algo activity_selector step 4650: {'selected': 0.9803149606299213, 'score': 0.9803149606299213, 'examples_seen': 185200, 'step': 4650, 'algorithm': 'activity_selector'}
I0716 18:21:57.106487 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.976, current avg val score is 0.980, val scores are: activity_selector: 0.980
I0716 18:21:58.125626 124088241030656 run.py:687] Algo activity_selector step 4700 current loss 0.663269, current_train_items 187168.
I0716 18:21:58.153515 124088241030656 run.py:722] (val) algo activity_selector step 4700: {'selected': 0.9843137254901961, 'score': 0.9843137254901961, 'examples_seen': 187168, 'step': 4700, 'algorithm': 'activity_selector'}
I0716 18:21:58.153683 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.980, current avg val score is 0.984, val scores are: activity_selector: 0.984
I0716 18:21:59.165363 124088241030656 run.py:687] Algo activity_selector step 4750 current loss 0.294498, current_train_items 189136.
I0716 18:21:59.194837 124088241030656 run.py:722] (val) algo activity_selector step 4750: {'selected': 0.9733840304182511, 'score': 0.9733840304182511, 'examples_seen': 189136, 'step': 4750, 'algorithm': 'activity_selector'}
I0716 18:21:59.194981 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0716 18:22:00.175735 124088241030656 run.py:687] Algo activity_selector step 4800 current loss 2.587678, current_train_items 191120.
I0716 18:22:00.207820 124088241030656 run.py:722] (val) algo activity_selector step 4800: {'selected': 0.9546351084812623, 'score': 0.9546351084812623, 'examples_seen': 191120, 'step': 4800, 'algorithm': 'activity_selector'}
I0716 18:22:00.207969 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0716 18:22:01.233887 124088241030656 run.py:687] Algo activity_selector step 4850 current loss 0.375919, current_train_items 193136.
I0716 18:22:01.256528 124088241030656 run.py:722] (val) algo activity_selector step 4850: {'selected': 0.8994307400379505, 'score': 0.8994307400379505, 'examples_seen': 193136, 'step': 4850, 'algorithm': 'activity_selector'}
I0716 18:22:01.256676 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0716 18:22:02.261617 124088241030656 run.py:687] Algo activity_selector step 4900 current loss 0.203130, current_train_items 195152.
I0716 18:22:02.284347 124088241030656 run.py:722] (val) algo activity_selector step 4900: {'selected': 0.9592233009708738, 'score': 0.9592233009708738, 'examples_seen': 195152, 'step': 4900, 'algorithm': 'activity_selector'}
I0716 18:22:02.284494 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0716 18:22:03.290137 124088241030656 run.py:687] Algo activity_selector step 4950 current loss 0.215050, current_train_items 197152.
I0716 18:22:03.314213 124088241030656 run.py:722] (val) algo activity_selector step 4950: {'selected': 0.9709864603481625, 'score': 0.9709864603481625, 'examples_seen': 197152, 'step': 4950, 'algorithm': 'activity_selector'}
I0716 18:22:03.314365 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0716 18:22:04.310457 124088241030656 run.py:687] Algo activity_selector step 5000 current loss 0.182611, current_train_items 199120.
I0716 18:22:04.336741 124088241030656 run.py:722] (val) algo activity_selector step 5000: {'selected': 0.9488188976377951, 'score': 0.9488188976377951, 'examples_seen': 199120, 'step': 5000, 'algorithm': 'activity_selector'}
I0716 18:22:04.336890 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0716 18:22:05.326002 124088241030656 run.py:687] Algo activity_selector step 5050 current loss 1.315094, current_train_items 201120.
I0716 18:22:05.353563 124088241030656 run.py:722] (val) algo activity_selector step 5050: {'selected': 0.9160305343511451, 'score': 0.9160305343511451, 'examples_seen': 201120, 'step': 5050, 'algorithm': 'activity_selector'}
I0716 18:22:05.353714 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.916, val scores are: activity_selector: 0.916
I0716 18:22:06.354870 124088241030656 run.py:687] Algo activity_selector step 5100 current loss 2.795016, current_train_items 203072.
I0716 18:22:06.384212 124088241030656 run.py:722] (val) algo activity_selector step 5100: {'selected': 0.9558541266794626, 'score': 0.9558541266794626, 'examples_seen': 203072, 'step': 5100, 'algorithm': 'activity_selector'}
I0716 18:22:06.384359 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0716 18:22:07.371663 124088241030656 run.py:687] Algo activity_selector step 5150 current loss 2.149266, current_train_items 205024.
I0716 18:22:07.403570 124088241030656 run.py:722] (val) algo activity_selector step 5150: {'selected': 0.9018789144050104, 'score': 0.9018789144050104, 'examples_seen': 205024, 'step': 5150, 'algorithm': 'activity_selector'}
I0716 18:22:07.403719 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0716 18:22:08.417664 124088241030656 run.py:687] Algo activity_selector step 5200 current loss 0.213068, current_train_items 207088.
I0716 18:22:08.441366 124088241030656 run.py:722] (val) algo activity_selector step 5200: {'selected': 0.9486166007905138, 'score': 0.9486166007905138, 'examples_seen': 207088, 'step': 5200, 'algorithm': 'activity_selector'}
I0716 18:22:08.441537 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0716 18:22:09.449677 124088241030656 run.py:687] Algo activity_selector step 5250 current loss 0.334601, current_train_items 209072.
I0716 18:22:09.471948 124088241030656 run.py:722] (val) algo activity_selector step 5250: {'selected': 0.9735849056603774, 'score': 0.9735849056603774, 'examples_seen': 209072, 'step': 5250, 'algorithm': 'activity_selector'}
I0716 18:22:09.472093 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0716 18:22:10.472805 124088241030656 run.py:687] Algo activity_selector step 5300 current loss 1.028366, current_train_items 211088.
I0716 18:22:10.496423 124088241030656 run.py:722] (val) algo activity_selector step 5300: {'selected': 0.9298597194388777, 'score': 0.9298597194388777, 'examples_seen': 211088, 'step': 5300, 'algorithm': 'activity_selector'}
I0716 18:22:10.496582 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0716 18:22:11.489764 124088241030656 run.py:687] Algo activity_selector step 5350 current loss 0.275246, current_train_items 213072.
I0716 18:22:11.514092 124088241030656 run.py:722] (val) algo activity_selector step 5350: {'selected': 0.95703125, 'score': 0.95703125, 'examples_seen': 213072, 'step': 5350, 'algorithm': 'activity_selector'}
I0716 18:22:11.514237 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0716 18:22:12.516686 124088241030656 run.py:687] Algo activity_selector step 5400 current loss 1.906497, current_train_items 215024.
I0716 18:22:12.544499 124088241030656 run.py:722] (val) algo activity_selector step 5400: {'selected': 0.9669902912621358, 'score': 0.9669902912621358, 'examples_seen': 215024, 'step': 5400, 'algorithm': 'activity_selector'}
I0716 18:22:12.544651 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0716 18:22:13.529360 124088241030656 run.py:687] Algo activity_selector step 5450 current loss 2.292513, current_train_items 217024.
I0716 18:22:13.558322 124088241030656 run.py:722] (val) algo activity_selector step 5450: {'selected': 0.9336016096579477, 'score': 0.9336016096579477, 'examples_seen': 217024, 'step': 5450, 'algorithm': 'activity_selector'}
I0716 18:22:13.558472 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0716 18:22:14.556208 124088241030656 run.py:687] Algo activity_selector step 5500 current loss 1.773550, current_train_items 218960.
I0716 18:22:14.588364 124088241030656 run.py:722] (val) algo activity_selector step 5500: {'selected': 0.9785575048732943, 'score': 0.9785575048732943, 'examples_seen': 218960, 'step': 5500, 'algorithm': 'activity_selector'}
I0716 18:22:14.588512 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.979, val scores are: activity_selector: 0.979
I0716 18:22:15.600528 124088241030656 run.py:687] Algo activity_selector step 5550 current loss 0.445253, current_train_items 221008.
I0716 18:22:15.622839 124088241030656 run.py:722] (val) algo activity_selector step 5550: {'selected': 0.9609375, 'score': 0.9609375, 'examples_seen': 221008, 'step': 5550, 'algorithm': 'activity_selector'}
I0716 18:22:15.622988 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0716 18:22:16.609166 124088241030656 run.py:687] Algo activity_selector step 5600 current loss 0.156800, current_train_items 223024.
I0716 18:22:16.631611 124088241030656 run.py:722] (val) algo activity_selector step 5600: {'selected': 0.9165048543689319, 'score': 0.9165048543689319, 'examples_seen': 223024, 'step': 5600, 'algorithm': 'activity_selector'}
I0716 18:22:16.631771 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0716 18:22:17.632848 124088241030656 run.py:687] Algo activity_selector step 5650 current loss 1.293438, current_train_items 225008.
I0716 18:22:17.656979 124088241030656 run.py:722] (val) algo activity_selector step 5650: {'selected': 0.9582504970178926, 'score': 0.9582504970178926, 'examples_seen': 225008, 'step': 5650, 'algorithm': 'activity_selector'}
I0716 18:22:17.657122 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0716 18:22:18.641193 124088241030656 run.py:687] Algo activity_selector step 5700 current loss 0.339473, current_train_items 227008.
I0716 18:22:18.665886 124088241030656 run.py:722] (val) algo activity_selector step 5700: {'selected': 0.9736842105263158, 'score': 0.9736842105263158, 'examples_seen': 227008, 'step': 5700, 'algorithm': 'activity_selector'}
I0716 18:22:18.666033 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0716 18:22:19.661696 124088241030656 run.py:687] Algo activity_selector step 5750 current loss 0.359988, current_train_items 228960.
I0716 18:22:19.689020 124088241030656 run.py:722] (val) algo activity_selector step 5750: {'selected': 0.9188118811881187, 'score': 0.9188118811881187, 'examples_seen': 228960, 'step': 5750, 'algorithm': 'activity_selector'}
I0716 18:22:19.689166 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0716 18:22:20.680497 124088241030656 run.py:687] Algo activity_selector step 5800 current loss 2.171424, current_train_items 230928.
I0716 18:22:20.709263 124088241030656 run.py:722] (val) algo activity_selector step 5800: {'selected': 0.9358490566037736, 'score': 0.9358490566037736, 'examples_seen': 230928, 'step': 5800, 'algorithm': 'activity_selector'}
I0716 18:22:20.709412 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0716 18:22:21.682028 124088241030656 run.py:687] Algo activity_selector step 5850 current loss 1.723114, current_train_items 232912.
I0716 18:22:21.714184 124088241030656 run.py:722] (val) algo activity_selector step 5850: {'selected': 0.9674952198852772, 'score': 0.9674952198852772, 'examples_seen': 232912, 'step': 5850, 'algorithm': 'activity_selector'}
I0716 18:22:21.714334 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0716 18:22:22.727929 124088241030656 run.py:687] Algo activity_selector step 5900 current loss 0.279105, current_train_items 234928.
I0716 18:22:22.749795 124088241030656 run.py:722] (val) algo activity_selector step 5900: {'selected': 0.9689922480620156, 'score': 0.9689922480620156, 'examples_seen': 234928, 'step': 5900, 'algorithm': 'activity_selector'}
I0716 18:22:22.749941 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0716 18:22:23.741333 124088241030656 run.py:687] Algo activity_selector step 5950 current loss 0.118774, current_train_items 236944.
I0716 18:22:23.763425 124088241030656 run.py:722] (val) algo activity_selector step 5950: {'selected': 0.9384615384615385, 'score': 0.9384615384615385, 'examples_seen': 236944, 'step': 5950, 'algorithm': 'activity_selector'}
I0716 18:22:23.763583 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0716 18:22:24.774543 124088241030656 run.py:687] Algo activity_selector step 6000 current loss 0.210669, current_train_items 238944.
I0716 18:22:24.797743 124088241030656 run.py:722] (val) algo activity_selector step 6000: {'selected': 0.935361216730038, 'score': 0.935361216730038, 'examples_seen': 238944, 'step': 6000, 'algorithm': 'activity_selector'}
I0716 18:22:24.797893 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0716 18:22:25.797502 124088241030656 run.py:687] Algo activity_selector step 6050 current loss 0.135227, current_train_items 240928.
I0716 18:22:25.821746 124088241030656 run.py:722] (val) algo activity_selector step 6050: {'selected': 0.9656565656565655, 'score': 0.9656565656565655, 'examples_seen': 240928, 'step': 6050, 'algorithm': 'activity_selector'}
I0716 18:22:25.821908 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.984, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0716 18:22:26.792963 124088241030656 run.py:687] Algo activity_selector step 6100 current loss 1.254337, current_train_items 242912.
I0716 18:22:26.820307 124088241030656 run.py:722] (val) algo activity_selector step 6100: {'selected': 0.9850746268656717, 'score': 0.9850746268656717, 'examples_seen': 242912, 'step': 6100, 'algorithm': 'activity_selector'}
I0716 18:22:26.820452 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.984, current avg val score is 0.985, val scores are: activity_selector: 0.985
I0716 18:22:27.834738 124088241030656 run.py:687] Algo activity_selector step 6150 current loss 2.046596, current_train_items 244864.
I0716 18:22:27.863351 124088241030656 run.py:722] (val) algo activity_selector step 6150: {'selected': 0.9328063241106718, 'score': 0.9328063241106718, 'examples_seen': 244864, 'step': 6150, 'algorithm': 'activity_selector'}
I0716 18:22:27.863502 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0716 18:22:28.841942 124088241030656 run.py:687] Algo activity_selector step 6200 current loss 1.257394, current_train_items 246816.
I0716 18:22:28.873535 124088241030656 run.py:722] (val) algo activity_selector step 6200: {'selected': 0.979047619047619, 'score': 0.979047619047619, 'examples_seen': 246816, 'step': 6200, 'algorithm': 'activity_selector'}
I0716 18:22:28.873681 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.979, val scores are: activity_selector: 0.979
I0716 18:22:29.894780 124088241030656 run.py:687] Algo activity_selector step 6250 current loss 0.036052, current_train_items 248880.
I0716 18:22:29.916557 124088241030656 run.py:722] (val) algo activity_selector step 6250: {'selected': 0.9774436090225563, 'score': 0.9774436090225563, 'examples_seen': 248880, 'step': 6250, 'algorithm': 'activity_selector'}
I0716 18:22:29.916707 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0716 18:22:30.927076 124088241030656 run.py:687] Algo activity_selector step 6300 current loss 0.178977, current_train_items 250880.
I0716 18:22:30.948817 124088241030656 run.py:722] (val) algo activity_selector step 6300: {'selected': 0.9087136929460582, 'score': 0.9087136929460582, 'examples_seen': 250880, 'step': 6300, 'algorithm': 'activity_selector'}
I0716 18:22:30.948968 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0716 18:22:31.954051 124088241030656 run.py:687] Algo activity_selector step 6350 current loss 1.032919, current_train_items 252880.
I0716 18:22:31.976890 124088241030656 run.py:722] (val) algo activity_selector step 6350: {'selected': 0.9770992366412214, 'score': 0.9770992366412214, 'examples_seen': 252880, 'step': 6350, 'algorithm': 'activity_selector'}
I0716 18:22:31.977058 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0716 18:22:32.988395 124088241030656 run.py:687] Algo activity_selector step 6400 current loss 0.227687, current_train_items 254864.
I0716 18:22:33.013311 124088241030656 run.py:722] (val) algo activity_selector step 6400: {'selected': 0.9705304518664046, 'score': 0.9705304518664046, 'examples_seen': 254864, 'step': 6400, 'algorithm': 'activity_selector'}
I0716 18:22:33.013456 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0716 18:22:34.013500 124088241030656 run.py:687] Algo activity_selector step 6450 current loss 2.269581, current_train_items 256816.
I0716 18:22:34.040418 124088241030656 run.py:722] (val) algo activity_selector step 6450: {'selected': 0.9552238805970149, 'score': 0.9552238805970149, 'examples_seen': 256816, 'step': 6450, 'algorithm': 'activity_selector'}
I0716 18:22:34.040575 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0716 18:22:35.087215 124088241030656 run.py:687] Algo activity_selector step 6500 current loss 1.645921, current_train_items 258816.
I0716 18:22:35.115873 124088241030656 run.py:722] (val) algo activity_selector step 6500: {'selected': 0.984313725490196, 'score': 0.984313725490196, 'examples_seen': 258816, 'step': 6500, 'algorithm': 'activity_selector'}
I0716 18:22:35.116019 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.984, val scores are: activity_selector: 0.984
I0716 18:22:36.108382 124088241030656 run.py:687] Algo activity_selector step 6550 current loss 1.782073, current_train_items 260752.
I0716 18:22:36.140303 124088241030656 run.py:722] (val) algo activity_selector step 6550: {'selected': 0.9537892791127542, 'score': 0.9537892791127542, 'examples_seen': 260752, 'step': 6550, 'algorithm': 'activity_selector'}
I0716 18:22:36.140452 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0716 18:22:37.160807 124088241030656 run.py:687] Algo activity_selector step 6600 current loss 0.376705, current_train_items 262800.
I0716 18:22:37.182624 124088241030656 run.py:722] (val) algo activity_selector step 6600: {'selected': 0.9681050656660414, 'score': 0.9681050656660414, 'examples_seen': 262800, 'step': 6600, 'algorithm': 'activity_selector'}
I0716 18:22:37.182770 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0716 18:22:38.191905 124088241030656 run.py:687] Algo activity_selector step 6650 current loss 0.077842, current_train_items 264832.
I0716 18:22:38.214488 124088241030656 run.py:722] (val) algo activity_selector step 6650: {'selected': 0.9465346534653465, 'score': 0.9465346534653465, 'examples_seen': 264832, 'step': 6650, 'algorithm': 'activity_selector'}
I0716 18:22:38.214647 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0716 18:22:39.217284 124088241030656 run.py:687] Algo activity_selector step 6700 current loss 0.956530, current_train_items 266800.
I0716 18:22:39.240325 124088241030656 run.py:722] (val) algo activity_selector step 6700: {'selected': 0.9593495934959351, 'score': 0.9593495934959351, 'examples_seen': 266800, 'step': 6700, 'algorithm': 'activity_selector'}
I0716 18:22:39.240474 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0716 18:22:40.253702 124088241030656 run.py:687] Algo activity_selector step 6750 current loss 0.284675, current_train_items 268800.
I0716 18:22:40.278597 124088241030656 run.py:722] (val) algo activity_selector step 6750: {'selected': 0.9766606822262119, 'score': 0.9766606822262119, 'examples_seen': 268800, 'step': 6750, 'algorithm': 'activity_selector'}
I0716 18:22:40.278744 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0716 18:22:41.276050 124088241030656 run.py:687] Algo activity_selector step 6800 current loss 0.525470, current_train_items 270752.
I0716 18:22:41.302485 124088241030656 run.py:722] (val) algo activity_selector step 6800: {'selected': 0.9512670565302144, 'score': 0.9512670565302144, 'examples_seen': 270752, 'step': 6800, 'algorithm': 'activity_selector'}
I0716 18:22:41.302644 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0716 18:22:42.302676 124088241030656 run.py:687] Algo activity_selector step 6850 current loss 1.121494, current_train_items 272736.
I0716 18:22:42.331201 124088241030656 run.py:722] (val) algo activity_selector step 6850: {'selected': 0.9683794466403162, 'score': 0.9683794466403162, 'examples_seen': 272736, 'step': 6850, 'algorithm': 'activity_selector'}
I0716 18:22:42.331348 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0716 18:22:43.313438 124088241030656 run.py:687] Algo activity_selector step 6900 current loss 0.661244, current_train_items 274720.
I0716 18:22:43.345393 124088241030656 run.py:722] (val) algo activity_selector step 6900: {'selected': 0.9520153550863724, 'score': 0.9520153550863724, 'examples_seen': 274720, 'step': 6900, 'algorithm': 'activity_selector'}
I0716 18:22:43.345546 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0716 18:22:44.369250 124088241030656 run.py:687] Algo activity_selector step 6950 current loss 0.317327, current_train_items 276736.
I0716 18:22:44.391754 124088241030656 run.py:722] (val) algo activity_selector step 6950: {'selected': 0.9681050656660413, 'score': 0.9681050656660413, 'examples_seen': 276736, 'step': 6950, 'algorithm': 'activity_selector'}
I0716 18:22:44.391900 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0716 18:22:45.426197 124088241030656 run.py:687] Algo activity_selector step 7000 current loss 0.189275, current_train_items 278768.
I0716 18:22:45.448707 124088241030656 run.py:722] (val) algo activity_selector step 7000: {'selected': 0.9576923076923077, 'score': 0.9576923076923077, 'examples_seen': 278768, 'step': 7000, 'algorithm': 'activity_selector'}
I0716 18:22:45.448856 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0716 18:22:46.445665 124088241030656 run.py:687] Algo activity_selector step 7050 current loss 0.345437, current_train_items 280752.
I0716 18:22:46.469432 124088241030656 run.py:722] (val) algo activity_selector step 7050: {'selected': 0.97165991902834, 'score': 0.97165991902834, 'examples_seen': 280752, 'step': 7050, 'algorithm': 'activity_selector'}
I0716 18:22:46.469592 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0716 18:22:47.480621 124088241030656 run.py:687] Algo activity_selector step 7100 current loss 0.131319, current_train_items 282736.
I0716 18:22:47.505299 124088241030656 run.py:722] (val) algo activity_selector step 7100: {'selected': 0.9609375, 'score': 0.9609375, 'examples_seen': 282736, 'step': 7100, 'algorithm': 'activity_selector'}
I0716 18:22:47.505446 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0716 18:22:48.488570 124088241030656 run.py:687] Algo activity_selector step 7150 current loss 1.607608, current_train_items 284720.
I0716 18:22:48.515330 124088241030656 run.py:722] (val) algo activity_selector step 7150: {'selected': 0.9722222222222222, 'score': 0.9722222222222222, 'examples_seen': 284720, 'step': 7150, 'algorithm': 'activity_selector'}
I0716 18:22:48.515476 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0716 18:22:49.527860 124088241030656 run.py:687] Algo activity_selector step 7200 current loss 0.360168, current_train_items 286672.
I0716 18:22:49.556338 124088241030656 run.py:722] (val) algo activity_selector step 7200: {'selected': 0.9596928982725527, 'score': 0.9596928982725527, 'examples_seen': 286672, 'step': 7200, 'algorithm': 'activity_selector'}
I0716 18:22:49.556485 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0716 18:22:50.584036 124088241030656 run.py:687] Algo activity_selector step 7250 current loss 3.335930, current_train_items 288640.
I0716 18:22:50.621681 124088241030656 run.py:722] (val) algo activity_selector step 7250: {'selected': 0.9831144465290806, 'score': 0.9831144465290806, 'examples_seen': 288640, 'step': 7250, 'algorithm': 'activity_selector'}
I0716 18:22:50.621832 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.983, val scores are: activity_selector: 0.983
I0716 18:22:51.649874 124088241030656 run.py:687] Algo activity_selector step 7300 current loss 0.287471, current_train_items 290688.
I0716 18:22:51.673888 124088241030656 run.py:722] (val) algo activity_selector step 7300: {'selected': 0.9500924214417745, 'score': 0.9500924214417745, 'examples_seen': 290688, 'step': 7300, 'algorithm': 'activity_selector'}
I0716 18:22:51.674041 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0716 18:22:52.700123 124088241030656 run.py:687] Algo activity_selector step 7350 current loss 0.207964, current_train_items 292688.
I0716 18:22:52.723256 124088241030656 run.py:722] (val) algo activity_selector step 7350: {'selected': 0.9585798816568047, 'score': 0.9585798816568047, 'examples_seen': 292688, 'step': 7350, 'algorithm': 'activity_selector'}
I0716 18:22:52.723405 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0716 18:22:53.714780 124088241030656 run.py:687] Algo activity_selector step 7400 current loss 0.944117, current_train_items 294688.
I0716 18:22:53.737825 124088241030656 run.py:722] (val) algo activity_selector step 7400: {'selected': 0.9674796747967479, 'score': 0.9674796747967479, 'examples_seen': 294688, 'step': 7400, 'algorithm': 'activity_selector'}
I0716 18:22:53.737971 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0716 18:22:54.745825 124088241030656 run.py:687] Algo activity_selector step 7450 current loss 0.305184, current_train_items 296672.
I0716 18:22:54.770147 124088241030656 run.py:722] (val) algo activity_selector step 7450: {'selected': 0.9685039370078741, 'score': 0.9685039370078741, 'examples_seen': 296672, 'step': 7450, 'algorithm': 'activity_selector'}
I0716 18:22:54.770294 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0716 18:22:55.795191 124088241030656 run.py:687] Algo activity_selector step 7500 current loss 1.885324, current_train_items 298624.
I0716 18:22:55.822247 124088241030656 run.py:722] (val) algo activity_selector step 7500: {'selected': 0.9844961240310077, 'score': 0.9844961240310077, 'examples_seen': 298624, 'step': 7500, 'algorithm': 'activity_selector'}
I0716 18:22:55.822407 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.984, val scores are: activity_selector: 0.984
I0716 18:22:56.811444 124088241030656 run.py:687] Algo activity_selector step 7550 current loss 4.434858, current_train_items 300624.
I0716 18:22:56.840152 124088241030656 run.py:722] (val) algo activity_selector step 7550: {'selected': 0.9774127310061602, 'score': 0.9774127310061602, 'examples_seen': 300624, 'step': 7550, 'algorithm': 'activity_selector'}
I0716 18:22:56.840300 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0716 18:22:57.835114 124088241030656 run.py:687] Algo activity_selector step 7600 current loss 3.371222, current_train_items 302576.
I0716 18:22:57.866783 124088241030656 run.py:722] (val) algo activity_selector step 7600: {'selected': 0.9361702127659575, 'score': 0.9361702127659575, 'examples_seen': 302576, 'step': 7600, 'algorithm': 'activity_selector'}
I0716 18:22:57.866929 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.985, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0716 18:22:58.864726 124088241030656 run.py:687] Algo activity_selector step 7650 current loss 0.361047, current_train_items 304608.
I0716 18:22:58.886867 124088241030656 run.py:722] (val) algo activity_selector step 7650: {'selected': 0.9939393939393938, 'score': 0.9939393939393938, 'examples_seen': 304608, 'step': 7650, 'algorithm': 'activity_selector'}
I0716 18:22:58.887013 124088241030656 run.py:743] Checkpointing best model, best avg val score was 0.985, current avg val score is 0.994, val scores are: activity_selector: 0.994
I0716 18:22:59.899562 124088241030656 run.py:687] Algo activity_selector step 7700 current loss 0.111754, current_train_items 306640.
I0716 18:22:59.922018 124088241030656 run.py:722] (val) algo activity_selector step 7700: {'selected': 0.973630831643002, 'score': 0.973630831643002, 'examples_seen': 306640, 'step': 7700, 'algorithm': 'activity_selector'}
I0716 18:22:59.922165 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0716 18:23:00.936962 124088241030656 run.py:687] Algo activity_selector step 7750 current loss 0.893057, current_train_items 308608.
I0716 18:23:00.961726 124088241030656 run.py:722] (val) algo activity_selector step 7750: {'selected': 0.9770114942528735, 'score': 0.9770114942528735, 'examples_seen': 308608, 'step': 7750, 'algorithm': 'activity_selector'}
I0716 18:23:00.961874 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0716 18:23:01.961921 124088241030656 run.py:687] Algo activity_selector step 7800 current loss 0.166794, current_train_items 310608.
I0716 18:23:01.986394 124088241030656 run.py:722] (val) algo activity_selector step 7800: {'selected': 0.930327868852459, 'score': 0.930327868852459, 'examples_seen': 310608, 'step': 7800, 'algorithm': 'activity_selector'}
I0716 18:23:01.986552 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0716 18:23:02.982705 124088241030656 run.py:687] Algo activity_selector step 7850 current loss 0.322743, current_train_items 312576.
I0716 18:23:03.009555 124088241030656 run.py:722] (val) algo activity_selector step 7850: {'selected': 0.9728682170542636, 'score': 0.9728682170542636, 'examples_seen': 312576, 'step': 7850, 'algorithm': 'activity_selector'}
I0716 18:23:03.009701 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0716 18:23:04.006977 124088241030656 run.py:687] Algo activity_selector step 7900 current loss 2.292627, current_train_items 314528.
I0716 18:23:04.035696 124088241030656 run.py:722] (val) algo activity_selector step 7900: {'selected': 0.9563492063492063, 'score': 0.9563492063492063, 'examples_seen': 314528, 'step': 7900, 'algorithm': 'activity_selector'}
I0716 18:23:04.035840 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0716 18:23:05.028195 124088241030656 run.py:687] Algo activity_selector step 7950 current loss 3.080359, current_train_items 316528.
I0716 18:23:05.060173 124088241030656 run.py:722] (val) algo activity_selector step 7950: {'selected': 0.9694793536804308, 'score': 0.9694793536804308, 'examples_seen': 316528, 'step': 7950, 'algorithm': 'activity_selector'}
I0716 18:23:05.060333 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0716 18:23:06.097051 124088241030656 run.py:687] Algo activity_selector step 8000 current loss 0.576554, current_train_items 318528.
I0716 18:23:06.119726 124088241030656 run.py:722] (val) algo activity_selector step 8000: {'selected': 0.9715370018975333, 'score': 0.9715370018975333, 'examples_seen': 318528, 'step': 8000, 'algorithm': 'activity_selector'}
I0716 18:23:06.119878 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0716 18:23:07.129200 124088241030656 run.py:687] Algo activity_selector step 8050 current loss 0.145161, current_train_items 320560.
I0716 18:23:07.151630 124088241030656 run.py:722] (val) algo activity_selector step 8050: {'selected': 0.934131736526946, 'score': 0.934131736526946, 'examples_seen': 320560, 'step': 8050, 'algorithm': 'activity_selector'}
I0716 18:23:07.151780 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0716 18:23:08.138748 124088241030656 run.py:687] Algo activity_selector step 8100 current loss 0.246389, current_train_items 322544.
I0716 18:23:08.162257 124088241030656 run.py:722] (val) algo activity_selector step 8100: {'selected': 0.9771863117870724, 'score': 0.9771863117870724, 'examples_seen': 322544, 'step': 8100, 'algorithm': 'activity_selector'}
I0716 18:23:08.162401 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0716 18:23:09.162951 124088241030656 run.py:687] Algo activity_selector step 8150 current loss 0.118710, current_train_items 324528.
I0716 18:23:09.187554 124088241030656 run.py:722] (val) algo activity_selector step 8150: {'selected': 0.9681050656660413, 'score': 0.9681050656660413, 'examples_seen': 324528, 'step': 8150, 'algorithm': 'activity_selector'}
I0716 18:23:09.187700 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0716 18:23:10.178542 124088241030656 run.py:687] Algo activity_selector step 8200 current loss 1.490160, current_train_items 326528.
I0716 18:23:10.205592 124088241030656 run.py:722] (val) algo activity_selector step 8200: {'selected': 0.96484375, 'score': 0.96484375, 'examples_seen': 326528, 'step': 8200, 'algorithm': 'activity_selector'}
I0716 18:23:10.205741 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0716 18:23:11.216914 124088241030656 run.py:687] Algo activity_selector step 8250 current loss 2.062606, current_train_items 328464.
I0716 18:23:11.247090 124088241030656 run.py:722] (val) algo activity_selector step 8250: {'selected': 0.9366602687140115, 'score': 0.9366602687140115, 'examples_seen': 328464, 'step': 8250, 'algorithm': 'activity_selector'}
I0716 18:23:11.247254 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0716 18:23:12.258090 124088241030656 run.py:687] Algo activity_selector step 8300 current loss 3.014616, current_train_items 330432.
I0716 18:23:12.289806 124088241030656 run.py:722] (val) algo activity_selector step 8300: {'selected': 0.9689922480620156, 'score': 0.9689922480620156, 'examples_seen': 330432, 'step': 8300, 'algorithm': 'activity_selector'}
I0716 18:23:12.289955 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0716 18:23:13.301090 124088241030656 run.py:687] Algo activity_selector step 8350 current loss 0.014853, current_train_items 332480.
I0716 18:23:13.323381 124088241030656 run.py:722] (val) algo activity_selector step 8350: {'selected': 0.9310344827586207, 'score': 0.9310344827586207, 'examples_seen': 332480, 'step': 8350, 'algorithm': 'activity_selector'}
I0716 18:23:13.323538 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0716 18:23:14.348086 124088241030656 run.py:687] Algo activity_selector step 8400 current loss 0.075155, current_train_items 334480.
I0716 18:23:14.370336 124088241030656 run.py:722] (val) algo activity_selector step 8400: {'selected': 0.9551656920077972, 'score': 0.9551656920077972, 'examples_seen': 334480, 'step': 8400, 'algorithm': 'activity_selector'}
I0716 18:23:14.370482 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0716 18:23:15.369090 124088241030656 run.py:687] Algo activity_selector step 8450 current loss 0.767067, current_train_items 336480.
I0716 18:23:15.392590 124088241030656 run.py:722] (val) algo activity_selector step 8450: {'selected': 0.98, 'score': 0.98, 'examples_seen': 336480, 'step': 8450, 'algorithm': 'activity_selector'}
I0716 18:23:15.392742 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.980, val scores are: activity_selector: 0.980
I0716 18:23:16.425089 124088241030656 run.py:687] Algo activity_selector step 8500 current loss 0.249499, current_train_items 338464.
I0716 18:23:16.449988 124088241030656 run.py:722] (val) algo activity_selector step 8500: {'selected': 0.9688715953307394, 'score': 0.9688715953307394, 'examples_seen': 338464, 'step': 8500, 'algorithm': 'activity_selector'}
I0716 18:23:16.450141 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0716 18:23:17.448878 124088241030656 run.py:687] Algo activity_selector step 8550 current loss 1.884658, current_train_items 340432.
I0716 18:23:17.476160 124088241030656 run.py:722] (val) algo activity_selector step 8550: {'selected': 0.9818181818181818, 'score': 0.9818181818181818, 'examples_seen': 340432, 'step': 8550, 'algorithm': 'activity_selector'}
I0716 18:23:17.476310 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.982, val scores are: activity_selector: 0.982
I0716 18:23:18.447661 124088241030656 run.py:687] Algo activity_selector step 8600 current loss 1.684156, current_train_items 342416.
I0716 18:23:18.476425 124088241030656 run.py:722] (val) algo activity_selector step 8600: {'selected': 0.967741935483871, 'score': 0.967741935483871, 'examples_seen': 342416, 'step': 8600, 'algorithm': 'activity_selector'}
I0716 18:23:18.476579 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0716 18:23:19.475187 124088241030656 run.py:687] Algo activity_selector step 8650 current loss 3.036053, current_train_items 344368.
I0716 18:23:19.507087 124088241030656 run.py:722] (val) algo activity_selector step 8650: {'selected': 0.9540918163672655, 'score': 0.9540918163672655, 'examples_seen': 344368, 'step': 8650, 'algorithm': 'activity_selector'}
I0716 18:23:19.507233 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0716 18:23:20.503975 124088241030656 run.py:687] Algo activity_selector step 8700 current loss 0.356926, current_train_items 346400.
I0716 18:23:20.526199 124088241030656 run.py:722] (val) algo activity_selector step 8700: {'selected': 0.9651162790697674, 'score': 0.9651162790697674, 'examples_seen': 346400, 'step': 8700, 'algorithm': 'activity_selector'}
I0716 18:23:20.526346 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0716 18:23:21.533344 124088241030656 run.py:687] Algo activity_selector step 8750 current loss 0.070292, current_train_items 348432.
I0716 18:23:21.556612 124088241030656 run.py:722] (val) algo activity_selector step 8750: {'selected': 0.9808429118773947, 'score': 0.9808429118773947, 'examples_seen': 348432, 'step': 8750, 'algorithm': 'activity_selector'}
I0716 18:23:21.556757 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0716 18:23:22.551791 124088241030656 run.py:687] Algo activity_selector step 8800 current loss 0.788173, current_train_items 350416.
I0716 18:23:22.574718 124088241030656 run.py:722] (val) algo activity_selector step 8800: {'selected': 0.984, 'score': 0.984, 'examples_seen': 350416, 'step': 8800, 'algorithm': 'activity_selector'}
I0716 18:23:22.574865 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.984, val scores are: activity_selector: 0.984
I0716 18:23:23.558682 124088241030656 run.py:687] Algo activity_selector step 8850 current loss 0.261384, current_train_items 352400.
I0716 18:23:23.583127 124088241030656 run.py:722] (val) algo activity_selector step 8850: {'selected': 0.9383177570093457, 'score': 0.9383177570093457, 'examples_seen': 352400, 'step': 8850, 'algorithm': 'activity_selector'}
I0716 18:23:23.583271 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0716 18:23:24.579427 124088241030656 run.py:687] Algo activity_selector step 8900 current loss 0.261942, current_train_items 354368.
I0716 18:23:24.606173 124088241030656 run.py:722] (val) algo activity_selector step 8900: {'selected': 0.9534883720930232, 'score': 0.9534883720930232, 'examples_seen': 354368, 'step': 8900, 'algorithm': 'activity_selector'}
I0716 18:23:24.606320 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0716 18:23:25.582851 124088241030656 run.py:687] Algo activity_selector step 8950 current loss 1.332926, current_train_items 356320.
I0716 18:23:25.611760 124088241030656 run.py:722] (val) algo activity_selector step 8950: {'selected': 0.9748549323017408, 'score': 0.9748549323017408, 'examples_seen': 356320, 'step': 8950, 'algorithm': 'activity_selector'}
I0716 18:23:25.611908 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0716 18:23:26.601447 124088241030656 run.py:687] Algo activity_selector step 9000 current loss 2.657455, current_train_items 358320.
I0716 18:23:26.635736 124088241030656 run.py:722] (val) algo activity_selector step 9000: {'selected': 0.974459724950884, 'score': 0.974459724950884, 'examples_seen': 358320, 'step': 9000, 'algorithm': 'activity_selector'}
I0716 18:23:26.635885 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0716 18:23:27.673549 124088241030656 run.py:687] Algo activity_selector step 9050 current loss 0.270275, current_train_items 360320.
I0716 18:23:27.695727 124088241030656 run.py:722] (val) algo activity_selector step 9050: {'selected': 0.9769230769230769, 'score': 0.9769230769230769, 'examples_seen': 360320, 'step': 9050, 'algorithm': 'activity_selector'}
I0716 18:23:27.695874 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0716 18:23:28.702166 124088241030656 run.py:687] Algo activity_selector step 9100 current loss 0.257790, current_train_items 362352.
I0716 18:23:28.723995 124088241030656 run.py:722] (val) algo activity_selector step 9100: {'selected': 0.9775967413441955, 'score': 0.9775967413441955, 'examples_seen': 362352, 'step': 9100, 'algorithm': 'activity_selector'}
I0716 18:23:28.724154 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.978, val scores are: activity_selector: 0.978
I0716 18:23:29.723881 124088241030656 run.py:687] Algo activity_selector step 9150 current loss 0.118412, current_train_items 364352.
I0716 18:23:29.746321 124088241030656 run.py:722] (val) algo activity_selector step 9150: {'selected': 0.9215686274509804, 'score': 0.9215686274509804, 'examples_seen': 364352, 'step': 9150, 'algorithm': 'activity_selector'}
I0716 18:23:29.746481 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0716 18:23:30.744470 124088241030656 run.py:687] Algo activity_selector step 9200 current loss 0.076508, current_train_items 366320.
I0716 18:23:30.771376 124088241030656 run.py:722] (val) algo activity_selector step 9200: {'selected': 0.984313725490196, 'score': 0.984313725490196, 'examples_seen': 366320, 'step': 9200, 'algorithm': 'activity_selector'}
I0716 18:23:30.771532 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.984, val scores are: activity_selector: 0.984
I0716 18:23:31.773608 124088241030656 run.py:687] Algo activity_selector step 9250 current loss 1.284130, current_train_items 368320.
I0716 18:23:31.802113 124088241030656 run.py:722] (val) algo activity_selector step 9250: {'selected': 0.9860279441117764, 'score': 0.9860279441117764, 'examples_seen': 368320, 'step': 9250, 'algorithm': 'activity_selector'}
I0716 18:23:31.802267 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.986, val scores are: activity_selector: 0.986
I0716 18:23:32.807238 124088241030656 run.py:687] Algo activity_selector step 9300 current loss 1.034617, current_train_items 370272.
I0716 18:23:32.835803 124088241030656 run.py:722] (val) algo activity_selector step 9300: {'selected': 0.9618320610687024, 'score': 0.9618320610687024, 'examples_seen': 370272, 'step': 9300, 'algorithm': 'activity_selector'}
I0716 18:23:32.835950 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0716 18:23:33.892691 124088241030656 run.py:687] Algo activity_selector step 9350 current loss 2.319371, current_train_items 372240.
I0716 18:23:33.925858 124088241030656 run.py:722] (val) algo activity_selector step 9350: {'selected': 0.9715370018975333, 'score': 0.9715370018975333, 'examples_seen': 372240, 'step': 9350, 'algorithm': 'activity_selector'}
I0716 18:23:33.926004 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0716 18:23:34.932378 124088241030656 run.py:687] Algo activity_selector step 9400 current loss 0.109068, current_train_items 374288.
I0716 18:23:34.953945 124088241030656 run.py:722] (val) algo activity_selector step 9400: {'selected': 0.9370078740157479, 'score': 0.9370078740157479, 'examples_seen': 374288, 'step': 9400, 'algorithm': 'activity_selector'}
I0716 18:23:34.954125 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0716 18:23:35.977409 124088241030656 run.py:687] Algo activity_selector step 9450 current loss 0.056179, current_train_items 376288.
I0716 18:23:35.998910 124088241030656 run.py:722] (val) algo activity_selector step 9450: {'selected': 0.935672514619883, 'score': 0.935672514619883, 'examples_seen': 376288, 'step': 9450, 'algorithm': 'activity_selector'}
I0716 18:23:35.999057 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0716 18:23:36.995253 124088241030656 run.py:687] Algo activity_selector step 9500 current loss 0.686436, current_train_items 378304.
I0716 18:23:37.018239 124088241030656 run.py:722] (val) algo activity_selector step 9500: {'selected': 0.9810606060606061, 'score': 0.9810606060606061, 'examples_seen': 378304, 'step': 9500, 'algorithm': 'activity_selector'}
I0716 18:23:37.018385 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0716 18:23:37.998926 124088241030656 run.py:687] Algo activity_selector step 9550 current loss 0.149658, current_train_items 380272.
I0716 18:23:38.023184 124088241030656 run.py:722] (val) algo activity_selector step 9550: {'selected': 0.9636711281070747, 'score': 0.9636711281070747, 'examples_seen': 380272, 'step': 9550, 'algorithm': 'activity_selector'}
I0716 18:23:38.023331 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0716 18:23:39.018830 124088241030656 run.py:687] Algo activity_selector step 9600 current loss 1.925855, current_train_items 382240.
I0716 18:23:39.045617 124088241030656 run.py:722] (val) algo activity_selector step 9600: {'selected': 0.9749518304431599, 'score': 0.9749518304431599, 'examples_seen': 382240, 'step': 9600, 'algorithm': 'activity_selector'}
I0716 18:23:39.045765 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0716 18:23:40.020247 124088241030656 run.py:687] Algo activity_selector step 9650 current loss 0.470114, current_train_items 384224.
I0716 18:23:40.048861 124088241030656 run.py:722] (val) algo activity_selector step 9650: {'selected': 0.9732824427480916, 'score': 0.9732824427480916, 'examples_seen': 384224, 'step': 9650, 'algorithm': 'activity_selector'}
I0716 18:23:40.049011 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0716 18:23:41.044827 124088241030656 run.py:687] Algo activity_selector step 9700 current loss 2.228325, current_train_items 386176.
I0716 18:23:41.076656 124088241030656 run.py:722] (val) algo activity_selector step 9700: {'selected': 0.972, 'score': 0.972, 'examples_seen': 386176, 'step': 9700, 'algorithm': 'activity_selector'}
I0716 18:23:41.076803 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0716 18:23:42.085297 124088241030656 run.py:687] Algo activity_selector step 9750 current loss 0.344994, current_train_items 388224.
I0716 18:23:42.106998 124088241030656 run.py:722] (val) algo activity_selector step 9750: {'selected': 0.9616858237547893, 'score': 0.9616858237547893, 'examples_seen': 388224, 'step': 9750, 'algorithm': 'activity_selector'}
I0716 18:23:42.107148 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0716 18:23:43.105026 124088241030656 run.py:687] Algo activity_selector step 9800 current loss 0.084017, current_train_items 390240.
I0716 18:23:43.127337 124088241030656 run.py:722] (val) algo activity_selector step 9800: {'selected': 0.9810606060606061, 'score': 0.9810606060606061, 'examples_seen': 390240, 'step': 9800, 'algorithm': 'activity_selector'}
I0716 18:23:43.127483 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0716 18:23:44.133264 124088241030656 run.py:687] Algo activity_selector step 9850 current loss 0.680375, current_train_items 392224.
I0716 18:23:44.157233 124088241030656 run.py:722] (val) algo activity_selector step 9850: {'selected': 0.9901380670611438, 'score': 0.9901380670611438, 'examples_seen': 392224, 'step': 9850, 'algorithm': 'activity_selector'}
I0716 18:23:44.157380 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.990, val scores are: activity_selector: 0.990
I0716 18:23:45.132537 124088241030656 run.py:687] Algo activity_selector step 9900 current loss 0.243017, current_train_items 394208.
I0716 18:23:45.157026 124088241030656 run.py:722] (val) algo activity_selector step 9900: {'selected': 0.9568627450980393, 'score': 0.9568627450980393, 'examples_seen': 394208, 'step': 9900, 'algorithm': 'activity_selector'}
I0716 18:23:45.157175 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0716 18:23:46.156886 124088241030656 run.py:687] Algo activity_selector step 9950 current loss 0.277631, current_train_items 396176.
I0716 18:23:46.183864 124088241030656 run.py:722] (val) algo activity_selector step 9950: {'selected': 0.9603174603174602, 'score': 0.9603174603174602, 'examples_seen': 396176, 'step': 9950, 'algorithm': 'activity_selector'}
I0716 18:23:46.184014 124088241030656 run.py:746] Not saving new best model, best avg val score was 0.994, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0716 18:23:47.148017 124088241030656 run.py:752] Restoring best model from checkpoint...
I0716 18:23:53.837694 124088241030656 run.py:767] (test) algo activity_selector : {'selected': 0.8812260536398469, 'score': 0.8812260536398469, 'examples_seen': 398112, 'step': 10000, 'algorithm': 'activity_selector'}
I0716 18:23:53.837835 124088241030656 run.py:769] Done!
