I0714 16:19:56.459008 133500379165312 xla_bridge.py:924] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0714 16:19:56.489722 133500379165312 xla_bridge.py:924] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0714 16:19:57.800926 133500379165312 run.py:415] Model: triplet_gmpnn ['activity_selector']
I0714 16:19:57.801072 133500379165312 run.py:417] algorithms ['activity_selector']
I0714 16:19:57.801441 133500379165312 run.py:418] train_lengths ['2', '3', '5', '7', '11', '13', '16']
I0714 16:19:57.801497 133500379165312 run.py:419] train_batch_size 16
I0714 16:19:57.801658 133500379165312 run.py:420] val_batch_size 8
I0714 16:19:57.801707 133500379165312 run.py:421] test_batch_size 8
I0714 16:19:57.801757 133500379165312 run.py:422] chunked_training True
I0714 16:19:57.802141 133500379165312 run.py:423] chunk_length 16
I0714 16:19:57.802194 133500379165312 run.py:424] train_steps 10000
I0714 16:19:57.802228 133500379165312 run.py:425] eval_every 50
I0714 16:19:57.802260 133500379165312 run.py:426] test_every 500
I0714 16:19:57.802304 133500379165312 run.py:427] learning_rate 0.001
I0714 16:19:57.802450 133500379165312 run.py:428] grad_clip_max_norm 1.0
I0714 16:19:57.802482 133500379165312 run.py:429] dropout_prob 0.1
I0714 16:19:57.802512 133500379165312 run.py:430] hint_teacher_forcing 0.0
I0714 16:19:57.802542 133500379165312 run.py:431] hint_mode encoded_decoded
I0714 16:19:57.802686 133500379165312 run.py:432] hint_repred_mode hard_on_eval
I0714 16:19:57.802717 133500379165312 run.py:433] use_ln False
I0714 16:19:57.802748 133500379165312 run.py:434] use_lstm True
I0714 16:19:57.802777 133500379165312 run.py:435] nb_triplet_fts 8
I0714 16:19:57.802807 133500379165312 run.py:436] encoder_init xavier_on_scalars
I0714 16:19:57.802835 133500379165312 run.py:437] processor_type triplet_gmpnn
I0714 16:19:57.802864 133500379165312 run.py:438] checkpoint_path CLRS30
I0714 16:19:57.802892 133500379165312 run.py:439] dataset_path CLRS30
I0714 16:19:57.802920 133500379165312 run.py:440] freeze_processor False
I0714 16:19:57.802947 133500379165312 run.py:441] reduction min
I0714 16:19:57.802976 133500379165312 run.py:442] activation elu
I0714 16:19:57.803004 133500379165312 run.py:443] algorithm_models ['F1', 'F2']
I0714 16:19:57.803035 133500379165312 run.py:444] restore_model 
I0714 16:19:57.803064 133500379165312 run.py:445] gated True
I0714 16:19:57.803093 133500379165312 run.py:446] gated_activation sigmoid
I0714 16:19:57.805231 133500379165312 run.py:472] Creating samplers for algo activity_selector
W0714 16:19:57.805544 133500379165312 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0714 16:19:57.805944 133500379165312 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0714 16:19:58.056871 133500379165312 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0714 16:19:58.315938 133500379165312 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0714 16:19:58.594440 133500379165312 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0714 16:19:58.909413 133500379165312 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0714 16:19:59.327192 133500379165312 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0714 16:19:59.777490 133500379165312 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0714 16:20:00.284631 133500379165312 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0714 16:20:00.284997 133500379165312 samplers.py:124] Creating a dataset with 64 samples.
I0714 16:20:00.318513 133500379165312 run.py:261] Dataset not found in CLRS30/CLRS30_v1.0.0. Downloading...
I0714 16:20:24.578697 133500379165312 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0714 16:20:24.582089 133500379165312 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0714 16:20:24.598672 133500379165312 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0714 16:20:24.692877 133500379165312 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0714 16:21:06.749202 133500379165312 run.py:687] Algo activity_selector step 0 current loss 3.769885, current_train_items 64.
I0714 16:21:07.946504 133500379165312 run.py:722] (val) algo activity_selector step 0: {'selected': 0.18348623853211013, 'score': 0.18348623853211013, 'examples_seen': 64, 'step': 0, 'algorithm': 'activity_selector'}
I0714 16:21:07.946718 133500379165312 run.py:743] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.183, val scores are: activity_selector: 0.183
I0714 16:22:05.655457 133500379165312 run.py:687] Algo activity_selector step 50 current loss 3.645041, current_train_items 2080.
I0714 16:22:05.701303 133500379165312 run.py:722] (val) algo activity_selector step 50: {'selected': 0.6716981132075471, 'score': 0.6716981132075471, 'examples_seen': 2080, 'step': 50, 'algorithm': 'activity_selector'}
I0714 16:22:05.701518 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.183, current avg val score is 0.672, val scores are: activity_selector: 0.672
I0714 16:22:07.136041 133500379165312 run.py:687] Algo activity_selector step 100 current loss 3.409696, current_train_items 4064.
I0714 16:22:07.206211 133500379165312 run.py:722] (val) algo activity_selector step 100: {'selected': 0.7255639097744361, 'score': 0.7255639097744361, 'examples_seen': 4064, 'step': 100, 'algorithm': 'activity_selector'}
I0714 16:22:07.206465 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.672, current avg val score is 0.726, val scores are: activity_selector: 0.726
I0714 16:22:08.639362 133500379165312 run.py:687] Algo activity_selector step 150 current loss 4.418337, current_train_items 6016.
I0714 16:22:08.689040 133500379165312 run.py:722] (val) algo activity_selector step 150: {'selected': 0.7145557655954631, 'score': 0.7145557655954631, 'examples_seen': 6016, 'step': 150, 'algorithm': 'activity_selector'}
I0714 16:22:08.689232 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.726, current avg val score is 0.715, val scores are: activity_selector: 0.715
I0714 16:22:10.105469 133500379165312 run.py:687] Algo activity_selector step 200 current loss 4.711551, current_train_items 8016.
I0714 16:22:10.162224 133500379165312 run.py:722] (val) algo activity_selector step 200: {'selected': 0.7447154471544715, 'score': 0.7447154471544715, 'examples_seen': 8016, 'step': 200, 'algorithm': 'activity_selector'}
I0714 16:22:10.162476 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.726, current avg val score is 0.745, val scores are: activity_selector: 0.745
I0714 16:22:11.609035 133500379165312 run.py:687] Algo activity_selector step 250 current loss 4.400616, current_train_items 9952.
I0714 16:22:11.666438 133500379165312 run.py:722] (val) algo activity_selector step 250: {'selected': 0.732, 'score': 0.732, 'examples_seen': 9952, 'step': 250, 'algorithm': 'activity_selector'}
I0714 16:22:11.666655 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.745, current avg val score is 0.732, val scores are: activity_selector: 0.732
I0714 16:22:13.094770 133500379165312 run.py:687] Algo activity_selector step 300 current loss 1.478356, current_train_items 12000.
I0714 16:22:13.138974 133500379165312 run.py:722] (val) algo activity_selector step 300: {'selected': 0.7679180887372015, 'score': 0.7679180887372015, 'examples_seen': 12000, 'step': 300, 'algorithm': 'activity_selector'}
I0714 16:22:13.139209 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.745, current avg val score is 0.768, val scores are: activity_selector: 0.768
I0714 16:22:14.625292 133500379165312 run.py:687] Algo activity_selector step 350 current loss 1.268971, current_train_items 14032.
I0714 16:22:14.667083 133500379165312 run.py:722] (val) algo activity_selector step 350: {'selected': 0.7822878228782288, 'score': 0.7822878228782288, 'examples_seen': 14032, 'step': 350, 'algorithm': 'activity_selector'}
I0714 16:22:14.667330 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.768, current avg val score is 0.782, val scores are: activity_selector: 0.782
I0714 16:22:16.702780 133500379165312 run.py:687] Algo activity_selector step 400 current loss 2.383381, current_train_items 16000.
I0714 16:22:16.803282 133500379165312 run.py:722] (val) algo activity_selector step 400: {'selected': 0.7603603603603604, 'score': 0.7603603603603604, 'examples_seen': 16000, 'step': 400, 'algorithm': 'activity_selector'}
I0714 16:22:16.803531 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.782, current avg val score is 0.760, val scores are: activity_selector: 0.760
I0714 16:22:18.553616 133500379165312 run.py:687] Algo activity_selector step 450 current loss 2.187440, current_train_items 18000.
I0714 16:22:18.602473 133500379165312 run.py:722] (val) algo activity_selector step 450: {'selected': 0.7514231499051235, 'score': 0.7514231499051235, 'examples_seen': 18000, 'step': 450, 'algorithm': 'activity_selector'}
I0714 16:22:18.602664 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.782, current avg val score is 0.751, val scores are: activity_selector: 0.751
I0714 16:22:20.041563 133500379165312 run.py:687] Algo activity_selector step 500 current loss 2.120928, current_train_items 19952.
I0714 16:22:20.097025 133500379165312 run.py:722] (val) algo activity_selector step 500: {'selected': 0.8405797101449276, 'score': 0.8405797101449276, 'examples_seen': 19952, 'step': 500, 'algorithm': 'activity_selector'}
I0714 16:22:20.097218 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.782, current avg val score is 0.841, val scores are: activity_selector: 0.841
I0714 16:22:21.536048 133500379165312 run.py:687] Algo activity_selector step 550 current loss 3.239021, current_train_items 21920.
I0714 16:22:21.593868 133500379165312 run.py:722] (val) algo activity_selector step 550: {'selected': 0.8576850094876661, 'score': 0.8576850094876661, 'examples_seen': 21920, 'step': 550, 'algorithm': 'activity_selector'}
I0714 16:22:21.594058 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.841, current avg val score is 0.858, val scores are: activity_selector: 0.858
I0714 16:22:23.055173 133500379165312 run.py:687] Algo activity_selector step 600 current loss 3.421326, current_train_items 23904.
I0714 16:22:23.112498 133500379165312 run.py:722] (val) algo activity_selector step 600: {'selected': 0.8092691622103386, 'score': 0.8092691622103386, 'examples_seen': 23904, 'step': 600, 'algorithm': 'activity_selector'}
I0714 16:22:23.112725 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.858, current avg val score is 0.809, val scores are: activity_selector: 0.809
I0714 16:22:24.579757 133500379165312 run.py:687] Algo activity_selector step 650 current loss 1.098802, current_train_items 25920.
I0714 16:22:24.621472 133500379165312 run.py:722] (val) algo activity_selector step 650: {'selected': 0.8038897893030794, 'score': 0.8038897893030794, 'examples_seen': 25920, 'step': 650, 'algorithm': 'activity_selector'}
I0714 16:22:24.621691 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.858, current avg val score is 0.804, val scores are: activity_selector: 0.804
I0714 16:22:26.056766 133500379165312 run.py:687] Algo activity_selector step 700 current loss 0.886494, current_train_items 27952.
I0714 16:22:26.099143 133500379165312 run.py:722] (val) algo activity_selector step 700: {'selected': 0.875, 'score': 0.875, 'examples_seen': 27952, 'step': 700, 'algorithm': 'activity_selector'}
I0714 16:22:26.099364 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.858, current avg val score is 0.875, val scores are: activity_selector: 0.875
I0714 16:22:27.520690 133500379165312 run.py:687] Algo activity_selector step 750 current loss 1.198828, current_train_items 29936.
I0714 16:22:27.564558 133500379165312 run.py:722] (val) algo activity_selector step 750: {'selected': 0.8415672913117546, 'score': 0.8415672913117546, 'examples_seen': 29936, 'step': 750, 'algorithm': 'activity_selector'}
I0714 16:22:27.564764 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.875, current avg val score is 0.842, val scores are: activity_selector: 0.842
I0714 16:22:30.016136 133500379165312 run.py:687] Algo activity_selector step 800 current loss 1.124611, current_train_items 31920.
I0714 16:22:30.068760 133500379165312 run.py:722] (val) algo activity_selector step 800: {'selected': 0.8681318681318682, 'score': 0.8681318681318682, 'examples_seen': 31920, 'step': 800, 'algorithm': 'activity_selector'}
I0714 16:22:30.068963 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.875, current avg val score is 0.868, val scores are: activity_selector: 0.868
I0714 16:22:31.530314 133500379165312 run.py:687] Algo activity_selector step 850 current loss 2.589476, current_train_items 33904.
I0714 16:22:31.583997 133500379165312 run.py:722] (val) algo activity_selector step 850: {'selected': 0.8640595903165735, 'score': 0.8640595903165735, 'examples_seen': 33904, 'step': 850, 'algorithm': 'activity_selector'}
I0714 16:22:31.584185 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.875, current avg val score is 0.864, val scores are: activity_selector: 0.864
I0714 16:22:33.035647 133500379165312 run.py:687] Algo activity_selector step 900 current loss 2.678660, current_train_items 35856.
I0714 16:22:33.092084 133500379165312 run.py:722] (val) algo activity_selector step 900: {'selected': 0.9193245778611633, 'score': 0.9193245778611633, 'examples_seen': 35856, 'step': 900, 'algorithm': 'activity_selector'}
I0714 16:22:33.092307 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.875, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0714 16:22:34.570923 133500379165312 run.py:687] Algo activity_selector step 950 current loss 2.332178, current_train_items 37808.
I0714 16:22:34.629667 133500379165312 run.py:722] (val) algo activity_selector step 950: {'selected': 0.9136276391554702, 'score': 0.9136276391554702, 'examples_seen': 37808, 'step': 950, 'algorithm': 'activity_selector'}
I0714 16:22:34.629902 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.919, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0714 16:22:36.040464 133500379165312 run.py:687] Algo activity_selector step 1000 current loss 0.537531, current_train_items 39872.
I0714 16:22:36.083050 133500379165312 run.py:722] (val) algo activity_selector step 1000: {'selected': 0.8810408921933086, 'score': 0.8810408921933086, 'examples_seen': 39872, 'step': 1000, 'algorithm': 'activity_selector'}
I0714 16:22:36.083261 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.919, current avg val score is 0.881, val scores are: activity_selector: 0.881
I0714 16:22:37.545479 133500379165312 run.py:687] Algo activity_selector step 1050 current loss 0.410589, current_train_items 41872.
I0714 16:22:37.591487 133500379165312 run.py:722] (val) algo activity_selector step 1050: {'selected': 0.8730434782608696, 'score': 0.8730434782608696, 'examples_seen': 41872, 'step': 1050, 'algorithm': 'activity_selector'}
I0714 16:22:37.591695 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.919, current avg val score is 0.873, val scores are: activity_selector: 0.873
I0714 16:22:38.986499 133500379165312 run.py:687] Algo activity_selector step 1100 current loss 1.483980, current_train_items 43872.
I0714 16:22:39.028509 133500379165312 run.py:722] (val) algo activity_selector step 1100: {'selected': 0.9233791748526523, 'score': 0.9233791748526523, 'examples_seen': 43872, 'step': 1100, 'algorithm': 'activity_selector'}
I0714 16:22:39.028716 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.919, current avg val score is 0.923, val scores are: activity_selector: 0.923
I0714 16:22:40.893955 133500379165312 run.py:687] Algo activity_selector step 1150 current loss 1.544153, current_train_items 45856.
I0714 16:22:40.988672 133500379165312 run.py:722] (val) algo activity_selector step 1150: {'selected': 0.9108159392789373, 'score': 0.9108159392789373, 'examples_seen': 45856, 'step': 1150, 'algorithm': 'activity_selector'}
I0714 16:22:40.988914 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.923, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0714 16:22:42.963457 133500379165312 run.py:687] Algo activity_selector step 1200 current loss 2.620770, current_train_items 47808.
I0714 16:22:43.013151 133500379165312 run.py:722] (val) algo activity_selector step 1200: {'selected': 0.8653500897666069, 'score': 0.8653500897666069, 'examples_seen': 47808, 'step': 1200, 'algorithm': 'activity_selector'}
I0714 16:22:43.013396 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.923, current avg val score is 0.865, val scores are: activity_selector: 0.865
I0714 16:22:44.426332 133500379165312 run.py:687] Algo activity_selector step 1250 current loss 2.185706, current_train_items 49808.
I0714 16:22:44.481541 133500379165312 run.py:722] (val) algo activity_selector step 1250: {'selected': 0.8500881834215168, 'score': 0.8500881834215168, 'examples_seen': 49808, 'step': 1250, 'algorithm': 'activity_selector'}
I0714 16:22:44.481732 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.923, current avg val score is 0.850, val scores are: activity_selector: 0.850
I0714 16:22:45.926199 133500379165312 run.py:687] Algo activity_selector step 1300 current loss 4.480808, current_train_items 51760.
I0714 16:22:45.993802 133500379165312 run.py:722] (val) algo activity_selector step 1300: {'selected': 0.8667992047713717, 'score': 0.8667992047713717, 'examples_seen': 51760, 'step': 1300, 'algorithm': 'activity_selector'}
I0714 16:22:45.994041 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.923, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0714 16:22:47.434052 133500379165312 run.py:687] Algo activity_selector step 1350 current loss 0.533919, current_train_items 53792.
I0714 16:22:47.477843 133500379165312 run.py:722] (val) algo activity_selector step 1350: {'selected': 0.8987566607460035, 'score': 0.8987566607460035, 'examples_seen': 53792, 'step': 1350, 'algorithm': 'activity_selector'}
I0714 16:22:47.478071 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.923, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0714 16:22:48.889109 133500379165312 run.py:687] Algo activity_selector step 1400 current loss 0.371192, current_train_items 55824.
I0714 16:22:48.930620 133500379165312 run.py:722] (val) algo activity_selector step 1400: {'selected': 0.9125874125874126, 'score': 0.9125874125874126, 'examples_seen': 55824, 'step': 1400, 'algorithm': 'activity_selector'}
I0714 16:22:48.930937 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.923, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0714 16:22:50.391558 133500379165312 run.py:687] Algo activity_selector step 1450 current loss 1.263213, current_train_items 57792.
I0714 16:22:50.439704 133500379165312 run.py:722] (val) algo activity_selector step 1450: {'selected': 0.9191321499013807, 'score': 0.9191321499013807, 'examples_seen': 57792, 'step': 1450, 'algorithm': 'activity_selector'}
I0714 16:22:50.439940 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.923, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0714 16:22:51.848521 133500379165312 run.py:687] Algo activity_selector step 1500 current loss 0.480099, current_train_items 59792.
I0714 16:22:51.897555 133500379165312 run.py:722] (val) algo activity_selector step 1500: {'selected': 0.9309090909090909, 'score': 0.9309090909090909, 'examples_seen': 59792, 'step': 1500, 'algorithm': 'activity_selector'}
I0714 16:22:51.897751 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.923, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0714 16:22:54.095831 133500379165312 run.py:687] Algo activity_selector step 1550 current loss 0.813764, current_train_items 61744.
I0714 16:22:54.212665 133500379165312 run.py:722] (val) algo activity_selector step 1550: {'selected': 0.9166666666666666, 'score': 0.9166666666666666, 'examples_seen': 61744, 'step': 1550, 'algorithm': 'activity_selector'}
I0714 16:22:54.212967 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.931, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0714 16:22:55.884112 133500379165312 run.py:687] Algo activity_selector step 1600 current loss 1.963861, current_train_items 63712.
I0714 16:22:55.936691 133500379165312 run.py:722] (val) algo activity_selector step 1600: {'selected': 0.8880994671403196, 'score': 0.8880994671403196, 'examples_seen': 63712, 'step': 1600, 'algorithm': 'activity_selector'}
I0714 16:22:55.936886 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.931, current avg val score is 0.888, val scores are: activity_selector: 0.888
I0714 16:22:57.355891 133500379165312 run.py:687] Algo activity_selector step 1650 current loss 4.906595, current_train_items 65712.
I0714 16:22:57.411891 133500379165312 run.py:722] (val) algo activity_selector step 1650: {'selected': 0.9178571428571428, 'score': 0.9178571428571428, 'examples_seen': 65712, 'step': 1650, 'algorithm': 'activity_selector'}
I0714 16:22:57.412128 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.931, current avg val score is 0.918, val scores are: activity_selector: 0.918
I0714 16:22:58.868937 133500379165312 run.py:687] Algo activity_selector step 1700 current loss 0.435423, current_train_items 67712.
I0714 16:22:58.914538 133500379165312 run.py:722] (val) algo activity_selector step 1700: {'selected': 0.9314079422382673, 'score': 0.9314079422382673, 'examples_seen': 67712, 'step': 1700, 'algorithm': 'activity_selector'}
I0714 16:22:58.914721 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.931, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0714 16:23:00.419658 133500379165312 run.py:687] Algo activity_selector step 1750 current loss 0.292242, current_train_items 69744.
I0714 16:23:00.482769 133500379165312 run.py:722] (val) algo activity_selector step 1750: {'selected': 0.9187145557655955, 'score': 0.9187145557655955, 'examples_seen': 69744, 'step': 1750, 'algorithm': 'activity_selector'}
I0714 16:23:00.482963 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.931, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0714 16:23:01.883028 133500379165312 run.py:687] Algo activity_selector step 1800 current loss 0.323670, current_train_items 71728.
I0714 16:23:01.930519 133500379165312 run.py:722] (val) algo activity_selector step 1800: {'selected': 0.9147286821705427, 'score': 0.9147286821705427, 'examples_seen': 71728, 'step': 1800, 'algorithm': 'activity_selector'}
I0714 16:23:01.930707 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.931, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0714 16:23:03.327385 133500379165312 run.py:687] Algo activity_selector step 1850 current loss 0.483679, current_train_items 73712.
I0714 16:23:03.375193 133500379165312 run.py:722] (val) algo activity_selector step 1850: {'selected': 0.9006085192697769, 'score': 0.9006085192697769, 'examples_seen': 73712, 'step': 1850, 'algorithm': 'activity_selector'}
I0714 16:23:03.375442 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.931, current avg val score is 0.901, val scores are: activity_selector: 0.901
I0714 16:23:04.862567 133500379165312 run.py:687] Algo activity_selector step 1900 current loss 1.997083, current_train_items 75712.
I0714 16:23:04.943790 133500379165312 run.py:722] (val) algo activity_selector step 1900: {'selected': 0.9491525423728815, 'score': 0.9491525423728815, 'examples_seen': 75712, 'step': 1900, 'algorithm': 'activity_selector'}
I0714 16:23:04.944041 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.931, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0714 16:23:07.228499 133500379165312 run.py:687] Algo activity_selector step 1950 current loss 1.680641, current_train_items 77664.
I0714 16:23:07.282072 133500379165312 run.py:722] (val) algo activity_selector step 1950: {'selected': 0.974757281553398, 'score': 0.974757281553398, 'examples_seen': 77664, 'step': 1950, 'algorithm': 'activity_selector'}
I0714 16:23:07.282313 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.949, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0714 16:23:08.709882 133500379165312 run.py:687] Algo activity_selector step 2000 current loss 4.138160, current_train_items 79632.
I0714 16:23:08.771083 133500379165312 run.py:722] (val) algo activity_selector step 2000: {'selected': 0.9343936381709742, 'score': 0.9343936381709742, 'examples_seen': 79632, 'step': 2000, 'algorithm': 'activity_selector'}
I0714 16:23:08.771306 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0714 16:23:10.279334 133500379165312 run.py:687] Algo activity_selector step 2050 current loss 0.173484, current_train_items 81680.
I0714 16:23:10.322287 133500379165312 run.py:722] (val) algo activity_selector step 2050: {'selected': 0.9420560747663552, 'score': 0.9420560747663552, 'examples_seen': 81680, 'step': 2050, 'algorithm': 'activity_selector'}
I0714 16:23:10.322524 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0714 16:23:11.785665 133500379165312 run.py:687] Algo activity_selector step 2100 current loss 0.230108, current_train_items 83680.
I0714 16:23:11.831581 133500379165312 run.py:722] (val) algo activity_selector step 2100: {'selected': 0.9409368635437881, 'score': 0.9409368635437881, 'examples_seen': 83680, 'step': 2100, 'algorithm': 'activity_selector'}
I0714 16:23:11.831812 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0714 16:23:13.246033 133500379165312 run.py:687] Algo activity_selector step 2150 current loss 1.386892, current_train_items 85680.
I0714 16:23:13.289144 133500379165312 run.py:722] (val) algo activity_selector step 2150: {'selected': 0.9304174950298211, 'score': 0.9304174950298211, 'examples_seen': 85680, 'step': 2150, 'algorithm': 'activity_selector'}
I0714 16:23:13.289368 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0714 16:23:14.694953 133500379165312 run.py:687] Algo activity_selector step 2200 current loss 0.273479, current_train_items 87664.
I0714 16:23:14.744012 133500379165312 run.py:722] (val) algo activity_selector step 2200: {'selected': 0.950381679389313, 'score': 0.950381679389313, 'examples_seen': 87664, 'step': 2200, 'algorithm': 'activity_selector'}
I0714 16:23:14.744235 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0714 16:23:16.179769 133500379165312 run.py:687] Algo activity_selector step 2250 current loss 2.342373, current_train_items 89632.
I0714 16:23:16.231515 133500379165312 run.py:722] (val) algo activity_selector step 2250: {'selected': 0.946969696969697, 'score': 0.946969696969697, 'examples_seen': 89632, 'step': 2250, 'algorithm': 'activity_selector'}
I0714 16:23:16.231726 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0714 16:23:18.052620 133500379165312 run.py:687] Algo activity_selector step 2300 current loss 0.494989, current_train_items 91616.
I0714 16:23:18.143703 133500379165312 run.py:722] (val) algo activity_selector step 2300: {'selected': 0.9330922242314647, 'score': 0.9330922242314647, 'examples_seen': 91616, 'step': 2300, 'algorithm': 'activity_selector'}
I0714 16:23:18.143943 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0714 16:23:20.037438 133500379165312 run.py:687] Algo activity_selector step 2350 current loss 3.035053, current_train_items 93568.
I0714 16:23:20.096037 133500379165312 run.py:722] (val) algo activity_selector step 2350: {'selected': 0.931098696461825, 'score': 0.931098696461825, 'examples_seen': 93568, 'step': 2350, 'algorithm': 'activity_selector'}
I0714 16:23:20.096246 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0714 16:23:21.571404 133500379165312 run.py:687] Algo activity_selector step 2400 current loss 0.504369, current_train_items 95600.
I0714 16:23:21.613315 133500379165312 run.py:722] (val) algo activity_selector step 2400: {'selected': 0.9169811320754716, 'score': 0.9169811320754716, 'examples_seen': 95600, 'step': 2400, 'algorithm': 'activity_selector'}
I0714 16:23:21.613529 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0714 16:23:23.068161 133500379165312 run.py:687] Algo activity_selector step 2450 current loss 0.144737, current_train_items 97632.
I0714 16:23:23.110826 133500379165312 run.py:722] (val) algo activity_selector step 2450: {'selected': 0.9094736842105264, 'score': 0.9094736842105264, 'examples_seen': 97632, 'step': 2450, 'algorithm': 'activity_selector'}
I0714 16:23:23.111025 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0714 16:23:24.639611 133500379165312 run.py:687] Algo activity_selector step 2500 current loss 1.315528, current_train_items 99600.
I0714 16:23:24.685748 133500379165312 run.py:722] (val) algo activity_selector step 2500: {'selected': 0.9284332688588008, 'score': 0.9284332688588008, 'examples_seen': 99600, 'step': 2500, 'algorithm': 'activity_selector'}
I0714 16:23:24.685950 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0714 16:23:26.114439 133500379165312 run.py:687] Algo activity_selector step 2550 current loss 0.422095, current_train_items 101600.
I0714 16:23:26.160614 133500379165312 run.py:722] (val) algo activity_selector step 2550: {'selected': 0.8776978417266186, 'score': 0.8776978417266186, 'examples_seen': 101600, 'step': 2550, 'algorithm': 'activity_selector'}
I0714 16:23:26.160820 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.878, val scores are: activity_selector: 0.878
I0714 16:23:27.621575 133500379165312 run.py:687] Algo activity_selector step 2600 current loss 0.754813, current_train_items 103568.
I0714 16:23:27.673009 133500379165312 run.py:722] (val) algo activity_selector step 2600: {'selected': 0.9669902912621359, 'score': 0.9669902912621359, 'examples_seen': 103568, 'step': 2600, 'algorithm': 'activity_selector'}
I0714 16:23:27.673265 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0714 16:23:29.112594 133500379165312 run.py:687] Algo activity_selector step 2650 current loss 3.514342, current_train_items 105520.
I0714 16:23:29.167988 133500379165312 run.py:722] (val) algo activity_selector step 2650: {'selected': 0.9330985915492958, 'score': 0.9330985915492958, 'examples_seen': 105520, 'step': 2650, 'algorithm': 'activity_selector'}
I0714 16:23:29.168187 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0714 16:23:31.609000 133500379165312 run.py:687] Algo activity_selector step 2700 current loss 2.919505, current_train_items 107520.
I0714 16:23:31.674535 133500379165312 run.py:722] (val) algo activity_selector step 2700: {'selected': 0.9026217228464419, 'score': 0.9026217228464419, 'examples_seen': 107520, 'step': 2700, 'algorithm': 'activity_selector'}
I0714 16:23:31.674786 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.903, val scores are: activity_selector: 0.903
I0714 16:23:33.162355 133500379165312 run.py:687] Algo activity_selector step 2750 current loss 0.604457, current_train_items 109520.
I0714 16:23:33.204999 133500379165312 run.py:722] (val) algo activity_selector step 2750: {'selected': 0.9449715370018975, 'score': 0.9449715370018975, 'examples_seen': 109520, 'step': 2750, 'algorithm': 'activity_selector'}
I0714 16:23:33.205214 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0714 16:23:34.649471 133500379165312 run.py:687] Algo activity_selector step 2800 current loss 0.169682, current_train_items 111552.
I0714 16:23:34.700759 133500379165312 run.py:722] (val) algo activity_selector step 2800: {'selected': 0.9373814041745729, 'score': 0.9373814041745729, 'examples_seen': 111552, 'step': 2800, 'algorithm': 'activity_selector'}
I0714 16:23:34.700959 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0714 16:23:36.131049 133500379165312 run.py:687] Algo activity_selector step 2850 current loss 0.307084, current_train_items 113552.
I0714 16:23:36.177198 133500379165312 run.py:722] (val) algo activity_selector step 2850: {'selected': 0.9273743016759777, 'score': 0.9273743016759777, 'examples_seen': 113552, 'step': 2850, 'algorithm': 'activity_selector'}
I0714 16:23:36.177445 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0714 16:23:37.623597 133500379165312 run.py:687] Algo activity_selector step 2900 current loss 0.311059, current_train_items 115520.
I0714 16:23:37.672879 133500379165312 run.py:722] (val) algo activity_selector step 2900: {'selected': 0.9719626168224298, 'score': 0.9719626168224298, 'examples_seen': 115520, 'step': 2900, 'algorithm': 'activity_selector'}
I0714 16:23:37.673088 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0714 16:23:39.104518 133500379165312 run.py:687] Algo activity_selector step 2950 current loss 1.791752, current_train_items 117520.
I0714 16:23:39.174572 133500379165312 run.py:722] (val) algo activity_selector step 2950: {'selected': 0.8942115768463075, 'score': 0.8942115768463075, 'examples_seen': 117520, 'step': 2950, 'algorithm': 'activity_selector'}
I0714 16:23:39.174787 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0714 16:23:40.610388 133500379165312 run.py:687] Algo activity_selector step 3000 current loss 2.447785, current_train_items 119456.
I0714 16:23:40.663694 133500379165312 run.py:722] (val) algo activity_selector step 3000: {'selected': 0.943327239488117, 'score': 0.943327239488117, 'examples_seen': 119456, 'step': 3000, 'algorithm': 'activity_selector'}
I0714 16:23:40.663900 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0714 16:23:42.526932 133500379165312 run.py:687] Algo activity_selector step 3050 current loss 3.171064, current_train_items 121424.
I0714 16:23:42.637900 133500379165312 run.py:722] (val) algo activity_selector step 3050: {'selected': 0.9465648854961831, 'score': 0.9465648854961831, 'examples_seen': 121424, 'step': 3050, 'algorithm': 'activity_selector'}
I0714 16:23:42.638143 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0714 16:23:44.636800 133500379165312 run.py:687] Algo activity_selector step 3100 current loss 0.266145, current_train_items 123472.
I0714 16:23:44.679656 133500379165312 run.py:722] (val) algo activity_selector step 3100: {'selected': 0.9236641221374046, 'score': 0.9236641221374046, 'examples_seen': 123472, 'step': 3100, 'algorithm': 'activity_selector'}
I0714 16:23:44.679864 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0714 16:23:46.189670 133500379165312 run.py:687] Algo activity_selector step 3150 current loss 0.189796, current_train_items 125472.
I0714 16:23:46.233995 133500379165312 run.py:722] (val) algo activity_selector step 3150: {'selected': 0.9477756286266924, 'score': 0.9477756286266924, 'examples_seen': 125472, 'step': 3150, 'algorithm': 'activity_selector'}
I0714 16:23:46.234200 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0714 16:23:47.711150 133500379165312 run.py:687] Algo activity_selector step 3200 current loss 1.154643, current_train_items 127488.
I0714 16:23:47.757284 133500379165312 run.py:722] (val) algo activity_selector step 3200: {'selected': 0.9479768786127167, 'score': 0.9479768786127167, 'examples_seen': 127488, 'step': 3200, 'algorithm': 'activity_selector'}
I0714 16:23:47.757497 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0714 16:23:49.174406 133500379165312 run.py:687] Algo activity_selector step 3250 current loss 0.320723, current_train_items 129456.
I0714 16:23:49.227548 133500379165312 run.py:722] (val) algo activity_selector step 3250: {'selected': 0.9121495327102804, 'score': 0.9121495327102804, 'examples_seen': 129456, 'step': 3250, 'algorithm': 'activity_selector'}
I0714 16:23:49.227771 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0714 16:23:50.729978 133500379165312 run.py:687] Algo activity_selector step 3300 current loss 1.873570, current_train_items 131424.
I0714 16:23:50.782657 133500379165312 run.py:722] (val) algo activity_selector step 3300: {'selected': 0.9598470363288719, 'score': 0.9598470363288719, 'examples_seen': 131424, 'step': 3300, 'algorithm': 'activity_selector'}
I0714 16:23:50.782853 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0714 16:23:52.171435 133500379165312 run.py:687] Algo activity_selector step 3350 current loss 2.457171, current_train_items 133408.
I0714 16:23:52.228953 133500379165312 run.py:722] (val) algo activity_selector step 3350: {'selected': 0.9285714285714287, 'score': 0.9285714285714287, 'examples_seen': 133408, 'step': 3350, 'algorithm': 'activity_selector'}
I0714 16:23:52.229169 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.975, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0714 16:23:53.664390 133500379165312 run.py:687] Algo activity_selector step 3400 current loss 2.290645, current_train_items 135360.
I0714 16:23:53.733948 133500379165312 run.py:722] (val) algo activity_selector step 3400: {'selected': 0.9807692307692308, 'score': 0.9807692307692308, 'examples_seen': 135360, 'step': 3400, 'algorithm': 'activity_selector'}
I0714 16:23:53.734166 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.975, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0714 16:23:56.202170 133500379165312 run.py:687] Algo activity_selector step 3450 current loss 0.477680, current_train_items 137392.
I0714 16:23:56.248686 133500379165312 run.py:722] (val) algo activity_selector step 3450: {'selected': 0.9129662522202486, 'score': 0.9129662522202486, 'examples_seen': 137392, 'step': 3450, 'algorithm': 'activity_selector'}
I0714 16:23:56.248877 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0714 16:23:57.684696 133500379165312 run.py:687] Algo activity_selector step 3500 current loss 0.121604, current_train_items 139424.
I0714 16:23:57.728319 133500379165312 run.py:722] (val) algo activity_selector step 3500: {'selected': 0.9529411764705883, 'score': 0.9529411764705883, 'examples_seen': 139424, 'step': 3500, 'algorithm': 'activity_selector'}
I0714 16:23:57.728545 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0714 16:23:59.185900 133500379165312 run.py:687] Algo activity_selector step 3550 current loss 1.106535, current_train_items 141408.
I0714 16:23:59.230624 133500379165312 run.py:722] (val) algo activity_selector step 3550: {'selected': 0.9483747609942638, 'score': 0.9483747609942638, 'examples_seen': 141408, 'step': 3550, 'algorithm': 'activity_selector'}
I0714 16:23:59.230836 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0714 16:24:00.630802 133500379165312 run.py:687] Algo activity_selector step 3600 current loss 0.369118, current_train_items 143392.
I0714 16:24:00.675702 133500379165312 run.py:722] (val) algo activity_selector step 3600: {'selected': 0.9465346534653465, 'score': 0.9465346534653465, 'examples_seen': 143392, 'step': 3600, 'algorithm': 'activity_selector'}
I0714 16:24:00.675901 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0714 16:24:02.101447 133500379165312 run.py:687] Algo activity_selector step 3650 current loss 0.743988, current_train_items 145360.
I0714 16:24:02.154881 133500379165312 run.py:722] (val) algo activity_selector step 3650: {'selected': 0.9471624266144814, 'score': 0.9471624266144814, 'examples_seen': 145360, 'step': 3650, 'algorithm': 'activity_selector'}
I0714 16:24:02.155085 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0714 16:24:03.554952 133500379165312 run.py:687] Algo activity_selector step 3700 current loss 2.333755, current_train_items 147312.
I0714 16:24:03.606556 133500379165312 run.py:722] (val) algo activity_selector step 3700: {'selected': 0.9494163424124514, 'score': 0.9494163424124514, 'examples_seen': 147312, 'step': 3700, 'algorithm': 'activity_selector'}
I0714 16:24:03.606770 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0714 16:24:05.021978 133500379165312 run.py:687] Algo activity_selector step 3750 current loss 2.476311, current_train_items 149312.
I0714 16:24:05.085329 133500379165312 run.py:722] (val) algo activity_selector step 3750: {'selected': 0.9543726235741445, 'score': 0.9543726235741445, 'examples_seen': 149312, 'step': 3750, 'algorithm': 'activity_selector'}
I0714 16:24:05.085560 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0714 16:24:06.845212 133500379165312 run.py:687] Algo activity_selector step 3800 current loss 0.457839, current_train_items 151328.
I0714 16:24:06.948948 133500379165312 run.py:722] (val) algo activity_selector step 3800: {'selected': 0.9257142857142858, 'score': 0.9257142857142858, 'examples_seen': 151328, 'step': 3800, 'algorithm': 'activity_selector'}
I0714 16:24:06.949199 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0714 16:24:08.978816 133500379165312 run.py:687] Algo activity_selector step 3850 current loss 0.229939, current_train_items 153344.
I0714 16:24:09.021086 133500379165312 run.py:722] (val) algo activity_selector step 3850: {'selected': 0.9527272727272726, 'score': 0.9527272727272726, 'examples_seen': 153344, 'step': 3850, 'algorithm': 'activity_selector'}
I0714 16:24:09.021307 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0714 16:24:10.426020 133500379165312 run.py:687] Algo activity_selector step 3900 current loss 0.324162, current_train_items 155344.
I0714 16:24:10.470788 133500379165312 run.py:722] (val) algo activity_selector step 3900: {'selected': 0.9446494464944649, 'score': 0.9446494464944649, 'examples_seen': 155344, 'step': 3900, 'algorithm': 'activity_selector'}
I0714 16:24:10.470963 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0714 16:24:11.853110 133500379165312 run.py:687] Algo activity_selector step 3950 current loss 0.540491, current_train_items 157312.
I0714 16:24:11.901047 133500379165312 run.py:722] (val) algo activity_selector step 3950: {'selected': 0.9487666034155597, 'score': 0.9487666034155597, 'examples_seen': 157312, 'step': 3950, 'algorithm': 'activity_selector'}
I0714 16:24:11.901229 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0714 16:24:13.228426 133500379165312 run.py:687] Algo activity_selector step 4000 current loss 1.732960, current_train_items 159312.
I0714 16:24:13.282630 133500379165312 run.py:722] (val) algo activity_selector step 4000: {'selected': 0.9489603024574669, 'score': 0.9489603024574669, 'examples_seen': 159312, 'step': 4000, 'algorithm': 'activity_selector'}
I0714 16:24:13.282815 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0714 16:24:14.630874 133500379165312 run.py:687] Algo activity_selector step 4050 current loss 1.889269, current_train_items 161248.
I0714 16:24:14.684995 133500379165312 run.py:722] (val) algo activity_selector step 4050: {'selected': 0.9371196754563894, 'score': 0.9371196754563894, 'examples_seen': 161248, 'step': 4050, 'algorithm': 'activity_selector'}
I0714 16:24:14.685225 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0714 16:24:16.101639 133500379165312 run.py:687] Algo activity_selector step 4100 current loss 2.108168, current_train_items 163216.
I0714 16:24:16.164694 133500379165312 run.py:722] (val) algo activity_selector step 4100: {'selected': 0.9770114942528736, 'score': 0.9770114942528736, 'examples_seen': 163216, 'step': 4100, 'algorithm': 'activity_selector'}
I0714 16:24:16.164892 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0714 16:24:17.561610 133500379165312 run.py:687] Algo activity_selector step 4150 current loss 0.166083, current_train_items 165280.
I0714 16:24:17.603494 133500379165312 run.py:722] (val) algo activity_selector step 4150: {'selected': 0.9376181474480152, 'score': 0.9376181474480152, 'examples_seen': 165280, 'step': 4150, 'algorithm': 'activity_selector'}
I0714 16:24:17.603688 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0714 16:24:19.448751 133500379165312 run.py:687] Algo activity_selector step 4200 current loss 0.170247, current_train_items 167264.
I0714 16:24:19.557740 133500379165312 run.py:722] (val) algo activity_selector step 4200: {'selected': 0.9540229885057472, 'score': 0.9540229885057472, 'examples_seen': 167264, 'step': 4200, 'algorithm': 'activity_selector'}
I0714 16:24:19.558002 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0714 16:24:21.425498 133500379165312 run.py:687] Algo activity_selector step 4250 current loss 1.151955, current_train_items 169280.
I0714 16:24:21.468448 133500379165312 run.py:722] (val) algo activity_selector step 4250: {'selected': 0.9359223300970874, 'score': 0.9359223300970874, 'examples_seen': 169280, 'step': 4250, 'algorithm': 'activity_selector'}
I0714 16:24:21.468650 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0714 16:24:22.820190 133500379165312 run.py:687] Algo activity_selector step 4300 current loss 0.421486, current_train_items 171248.
I0714 16:24:22.870132 133500379165312 run.py:722] (val) algo activity_selector step 4300: {'selected': 0.9632352941176471, 'score': 0.9632352941176471, 'examples_seen': 171248, 'step': 4300, 'algorithm': 'activity_selector'}
I0714 16:24:22.870363 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0714 16:24:24.253119 133500379165312 run.py:687] Algo activity_selector step 4350 current loss 1.940397, current_train_items 173216.
I0714 16:24:24.306894 133500379165312 run.py:722] (val) algo activity_selector step 4350: {'selected': 0.9698189134808854, 'score': 0.9698189134808854, 'examples_seen': 173216, 'step': 4350, 'algorithm': 'activity_selector'}
I0714 16:24:24.307074 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0714 16:24:25.710637 133500379165312 run.py:687] Algo activity_selector step 4400 current loss 1.138781, current_train_items 175232.
I0714 16:24:25.764102 133500379165312 run.py:722] (val) algo activity_selector step 4400: {'selected': 0.9523809523809523, 'score': 0.9523809523809523, 'examples_seen': 175232, 'step': 4400, 'algorithm': 'activity_selector'}
I0714 16:24:25.764343 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.981, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0714 16:24:27.136929 133500379165312 run.py:687] Algo activity_selector step 4450 current loss 1.930128, current_train_items 177168.
I0714 16:24:27.196409 133500379165312 run.py:722] (val) algo activity_selector step 4450: {'selected': 0.9881422924901185, 'score': 0.9881422924901185, 'examples_seen': 177168, 'step': 4450, 'algorithm': 'activity_selector'}
I0714 16:24:27.196590 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.981, current avg val score is 0.988, val scores are: activity_selector: 0.988
I0714 16:24:28.761229 133500379165312 run.py:687] Algo activity_selector step 4500 current loss 0.345627, current_train_items 179216.
I0714 16:24:28.804548 133500379165312 run.py:722] (val) algo activity_selector step 4500: {'selected': 0.948, 'score': 0.948, 'examples_seen': 179216, 'step': 4500, 'algorithm': 'activity_selector'}
I0714 16:24:28.804838 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0714 16:24:30.331198 133500379165312 run.py:687] Algo activity_selector step 4550 current loss 0.270211, current_train_items 181232.
I0714 16:24:30.374350 133500379165312 run.py:722] (val) algo activity_selector step 4550: {'selected': 0.969811320754717, 'score': 0.969811320754717, 'examples_seen': 181232, 'step': 4550, 'algorithm': 'activity_selector'}
I0714 16:24:30.374685 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0714 16:24:32.810591 133500379165312 run.py:687] Algo activity_selector step 4600 current loss 1.653085, current_train_items 183216.
I0714 16:24:32.909542 133500379165312 run.py:722] (val) algo activity_selector step 4600: {'selected': 0.9, 'score': 0.9, 'examples_seen': 183216, 'step': 4600, 'algorithm': 'activity_selector'}
I0714 16:24:32.909847 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.900, val scores are: activity_selector: 0.900
I0714 16:24:34.471301 133500379165312 run.py:687] Algo activity_selector step 4650 current loss 0.255793, current_train_items 185200.
I0714 16:24:34.523755 133500379165312 run.py:722] (val) algo activity_selector step 4650: {'selected': 0.9520153550863724, 'score': 0.9520153550863724, 'examples_seen': 185200, 'step': 4650, 'algorithm': 'activity_selector'}
I0714 16:24:34.523985 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0714 16:24:36.229825 133500379165312 run.py:687] Algo activity_selector step 4700 current loss 0.333235, current_train_items 187168.
I0714 16:24:36.283299 133500379165312 run.py:722] (val) algo activity_selector step 4700: {'selected': 0.9784735812133073, 'score': 0.9784735812133073, 'examples_seen': 187168, 'step': 4700, 'algorithm': 'activity_selector'}
I0714 16:24:36.283543 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.978, val scores are: activity_selector: 0.978
I0714 16:24:37.912093 133500379165312 run.py:687] Algo activity_selector step 4750 current loss 0.744349, current_train_items 189136.
I0714 16:24:37.966801 133500379165312 run.py:722] (val) algo activity_selector step 4750: {'selected': 0.9391634980988595, 'score': 0.9391634980988595, 'examples_seen': 189136, 'step': 4750, 'algorithm': 'activity_selector'}
I0714 16:24:37.967012 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0714 16:24:39.519245 133500379165312 run.py:687] Algo activity_selector step 4800 current loss 1.813943, current_train_items 191120.
I0714 16:24:39.580694 133500379165312 run.py:722] (val) algo activity_selector step 4800: {'selected': 0.9391634980988594, 'score': 0.9391634980988594, 'examples_seen': 191120, 'step': 4800, 'algorithm': 'activity_selector'}
I0714 16:24:39.580916 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0714 16:24:41.222700 133500379165312 run.py:687] Algo activity_selector step 4850 current loss 0.345678, current_train_items 193136.
I0714 16:24:41.268396 133500379165312 run.py:722] (val) algo activity_selector step 4850: {'selected': 0.9285714285714286, 'score': 0.9285714285714286, 'examples_seen': 193136, 'step': 4850, 'algorithm': 'activity_selector'}
I0714 16:24:41.268613 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0714 16:24:42.876307 133500379165312 run.py:687] Algo activity_selector step 4900 current loss 0.156196, current_train_items 195152.
I0714 16:24:42.922628 133500379165312 run.py:722] (val) algo activity_selector step 4900: {'selected': 0.9338521400778209, 'score': 0.9338521400778209, 'examples_seen': 195152, 'step': 4900, 'algorithm': 'activity_selector'}
I0714 16:24:42.922873 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0714 16:24:45.617078 133500379165312 run.py:687] Algo activity_selector step 4950 current loss 0.279691, current_train_items 197152.
I0714 16:24:45.676113 133500379165312 run.py:722] (val) algo activity_selector step 4950: {'selected': 0.9578544061302683, 'score': 0.9578544061302683, 'examples_seen': 197152, 'step': 4950, 'algorithm': 'activity_selector'}
I0714 16:24:45.676395 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0714 16:24:47.274146 133500379165312 run.py:687] Algo activity_selector step 5000 current loss 0.262949, current_train_items 199120.
I0714 16:24:47.325072 133500379165312 run.py:722] (val) algo activity_selector step 5000: {'selected': 0.9455252918287937, 'score': 0.9455252918287937, 'examples_seen': 199120, 'step': 5000, 'algorithm': 'activity_selector'}
I0714 16:24:47.325333 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0714 16:24:48.905701 133500379165312 run.py:687] Algo activity_selector step 5050 current loss 1.286382, current_train_items 201120.
I0714 16:24:48.959152 133500379165312 run.py:722] (val) algo activity_selector step 5050: {'selected': 0.9612403100775194, 'score': 0.9612403100775194, 'examples_seen': 201120, 'step': 5050, 'algorithm': 'activity_selector'}
I0714 16:24:48.959390 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0714 16:24:50.607477 133500379165312 run.py:687] Algo activity_selector step 5100 current loss 2.733707, current_train_items 203072.
I0714 16:24:50.665534 133500379165312 run.py:722] (val) algo activity_selector step 5100: {'selected': 0.9694656488549619, 'score': 0.9694656488549619, 'examples_seen': 203072, 'step': 5100, 'algorithm': 'activity_selector'}
I0714 16:24:50.665767 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0714 16:24:52.292086 133500379165312 run.py:687] Algo activity_selector step 5150 current loss 2.041902, current_train_items 205024.
I0714 16:24:52.352553 133500379165312 run.py:722] (val) algo activity_selector step 5150: {'selected': 0.9762845849802372, 'score': 0.9762845849802372, 'examples_seen': 205024, 'step': 5150, 'algorithm': 'activity_selector'}
I0714 16:24:52.352773 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0714 16:24:54.011725 133500379165312 run.py:687] Algo activity_selector step 5200 current loss 0.123948, current_train_items 207088.
I0714 16:24:54.058005 133500379165312 run.py:722] (val) algo activity_selector step 5200: {'selected': 0.9101338432122371, 'score': 0.9101338432122371, 'examples_seen': 207088, 'step': 5200, 'algorithm': 'activity_selector'}
I0714 16:24:54.058232 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0714 16:24:55.916460 133500379165312 run.py:687] Algo activity_selector step 5250 current loss 0.217626, current_train_items 209072.
I0714 16:24:56.004143 133500379165312 run.py:722] (val) algo activity_selector step 5250: {'selected': 0.9659090909090909, 'score': 0.9659090909090909, 'examples_seen': 209072, 'step': 5250, 'algorithm': 'activity_selector'}
I0714 16:24:56.004492 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0714 16:24:58.529314 133500379165312 run.py:687] Algo activity_selector step 5300 current loss 0.916811, current_train_items 211088.
I0714 16:24:58.578965 133500379165312 run.py:722] (val) algo activity_selector step 5300: {'selected': 0.9447619047619048, 'score': 0.9447619047619048, 'examples_seen': 211088, 'step': 5300, 'algorithm': 'activity_selector'}
I0714 16:24:58.579186 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0714 16:25:00.212381 133500379165312 run.py:687] Algo activity_selector step 5350 current loss 0.529189, current_train_items 213072.
I0714 16:25:00.262007 133500379165312 run.py:722] (val) algo activity_selector step 5350: {'selected': 0.9485714285714286, 'score': 0.9485714285714286, 'examples_seen': 213072, 'step': 5350, 'algorithm': 'activity_selector'}
I0714 16:25:00.262223 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0714 16:25:01.912646 133500379165312 run.py:687] Algo activity_selector step 5400 current loss 1.943906, current_train_items 215024.
I0714 16:25:01.967466 133500379165312 run.py:722] (val) algo activity_selector step 5400: {'selected': 0.974559686888454, 'score': 0.974559686888454, 'examples_seen': 215024, 'step': 5400, 'algorithm': 'activity_selector'}
I0714 16:25:01.967701 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0714 16:25:03.520236 133500379165312 run.py:687] Algo activity_selector step 5450 current loss 2.499508, current_train_items 217024.
I0714 16:25:03.575868 133500379165312 run.py:722] (val) algo activity_selector step 5450: {'selected': 0.962671905697446, 'score': 0.962671905697446, 'examples_seen': 217024, 'step': 5450, 'algorithm': 'activity_selector'}
I0714 16:25:03.576171 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0714 16:25:05.159430 133500379165312 run.py:687] Algo activity_selector step 5500 current loss 2.048316, current_train_items 218960.
I0714 16:25:05.221318 133500379165312 run.py:722] (val) algo activity_selector step 5500: {'selected': 0.9578544061302683, 'score': 0.9578544061302683, 'examples_seen': 218960, 'step': 5500, 'algorithm': 'activity_selector'}
I0714 16:25:05.221656 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0714 16:25:06.843057 133500379165312 run.py:687] Algo activity_selector step 5550 current loss 0.404128, current_train_items 221008.
I0714 16:25:06.886164 133500379165312 run.py:722] (val) algo activity_selector step 5550: {'selected': 0.9315589353612167, 'score': 0.9315589353612167, 'examples_seen': 221008, 'step': 5550, 'algorithm': 'activity_selector'}
I0714 16:25:06.886459 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0714 16:25:08.695526 133500379165312 run.py:687] Algo activity_selector step 5600 current loss 0.153126, current_train_items 223024.
I0714 16:25:08.806934 133500379165312 run.py:722] (val) algo activity_selector step 5600: {'selected': 0.9540229885057471, 'score': 0.9540229885057471, 'examples_seen': 223024, 'step': 5600, 'algorithm': 'activity_selector'}
I0714 16:25:08.807190 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0714 16:25:11.115952 133500379165312 run.py:687] Algo activity_selector step 5650 current loss 1.301900, current_train_items 225008.
I0714 16:25:11.168027 133500379165312 run.py:722] (val) algo activity_selector step 5650: {'selected': 0.9688715953307393, 'score': 0.9688715953307393, 'examples_seen': 225008, 'step': 5650, 'algorithm': 'activity_selector'}
I0714 16:25:11.168241 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0714 16:25:12.784790 133500379165312 run.py:687] Algo activity_selector step 5700 current loss 0.429630, current_train_items 227008.
I0714 16:25:12.831293 133500379165312 run.py:722] (val) algo activity_selector step 5700: {'selected': 0.9199255121042832, 'score': 0.9199255121042832, 'examples_seen': 227008, 'step': 5700, 'algorithm': 'activity_selector'}
I0714 16:25:12.831537 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0714 16:25:14.437546 133500379165312 run.py:687] Algo activity_selector step 5750 current loss 0.391767, current_train_items 228960.
I0714 16:25:14.510604 133500379165312 run.py:722] (val) algo activity_selector step 5750: {'selected': 0.9584905660377359, 'score': 0.9584905660377359, 'examples_seen': 228960, 'step': 5750, 'algorithm': 'activity_selector'}
I0714 16:25:14.510840 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0714 16:25:16.111495 133500379165312 run.py:687] Algo activity_selector step 5800 current loss 2.371784, current_train_items 230928.
I0714 16:25:16.166531 133500379165312 run.py:722] (val) algo activity_selector step 5800: {'selected': 0.9308411214953272, 'score': 0.9308411214953272, 'examples_seen': 230928, 'step': 5800, 'algorithm': 'activity_selector'}
I0714 16:25:16.166779 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0714 16:25:17.839385 133500379165312 run.py:687] Algo activity_selector step 5850 current loss 1.627878, current_train_items 232912.
I0714 16:25:17.899774 133500379165312 run.py:722] (val) algo activity_selector step 5850: {'selected': 0.9418386491557224, 'score': 0.9418386491557224, 'examples_seen': 232912, 'step': 5850, 'algorithm': 'activity_selector'}
I0714 16:25:17.899998 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0714 16:25:19.609810 133500379165312 run.py:687] Algo activity_selector step 5900 current loss 0.358665, current_train_items 234928.
I0714 16:25:19.658691 133500379165312 run.py:722] (val) algo activity_selector step 5900: {'selected': 0.9534450651769089, 'score': 0.9534450651769089, 'examples_seen': 234928, 'step': 5900, 'algorithm': 'activity_selector'}
I0714 16:25:19.659021 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0714 16:25:21.460105 133500379165312 run.py:687] Algo activity_selector step 5950 current loss 0.110847, current_train_items 236944.
I0714 16:25:21.549099 133500379165312 run.py:722] (val) algo activity_selector step 5950: {'selected': 0.9366602687140115, 'score': 0.9366602687140115, 'examples_seen': 236944, 'step': 5950, 'algorithm': 'activity_selector'}
I0714 16:25:21.549385 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0714 16:25:23.483630 133500379165312 run.py:687] Algo activity_selector step 6000 current loss 0.223488, current_train_items 238944.
I0714 16:25:23.525643 133500379165312 run.py:722] (val) algo activity_selector step 6000: {'selected': 0.9489603024574669, 'score': 0.9489603024574669, 'examples_seen': 238944, 'step': 6000, 'algorithm': 'activity_selector'}
I0714 16:25:23.525840 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0714 16:25:24.964745 133500379165312 run.py:687] Algo activity_selector step 6050 current loss 0.177284, current_train_items 240928.
I0714 16:25:25.015493 133500379165312 run.py:722] (val) algo activity_selector step 6050: {'selected': 0.9840637450199203, 'score': 0.9840637450199203, 'examples_seen': 240928, 'step': 6050, 'algorithm': 'activity_selector'}
I0714 16:25:25.015706 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.984, val scores are: activity_selector: 0.984
I0714 16:25:26.418254 133500379165312 run.py:687] Algo activity_selector step 6100 current loss 1.481716, current_train_items 242912.
I0714 16:25:26.467571 133500379165312 run.py:722] (val) algo activity_selector step 6100: {'selected': 0.9582577132486388, 'score': 0.9582577132486388, 'examples_seen': 242912, 'step': 6100, 'algorithm': 'activity_selector'}
I0714 16:25:26.467769 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0714 16:25:27.855058 133500379165312 run.py:687] Algo activity_selector step 6150 current loss 1.914355, current_train_items 244864.
I0714 16:25:27.912158 133500379165312 run.py:722] (val) algo activity_selector step 6150: {'selected': 0.9510763209393347, 'score': 0.9510763209393347, 'examples_seen': 244864, 'step': 6150, 'algorithm': 'activity_selector'}
I0714 16:25:27.912450 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0714 16:25:29.306826 133500379165312 run.py:687] Algo activity_selector step 6200 current loss 1.510166, current_train_items 246816.
I0714 16:25:29.367046 133500379165312 run.py:722] (val) algo activity_selector step 6200: {'selected': 0.9752380952380953, 'score': 0.9752380952380953, 'examples_seen': 246816, 'step': 6200, 'algorithm': 'activity_selector'}
I0714 16:25:29.367275 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0714 16:25:30.820564 133500379165312 run.py:687] Algo activity_selector step 6250 current loss 0.063066, current_train_items 248880.
I0714 16:25:30.866902 133500379165312 run.py:722] (val) algo activity_selector step 6250: {'selected': 0.9555555555555555, 'score': 0.9555555555555555, 'examples_seen': 248880, 'step': 6250, 'algorithm': 'activity_selector'}
I0714 16:25:30.867084 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0714 16:25:32.277849 133500379165312 run.py:687] Algo activity_selector step 6300 current loss 0.449315, current_train_items 250880.
I0714 16:25:32.323719 133500379165312 run.py:722] (val) algo activity_selector step 6300: {'selected': 0.9673469387755103, 'score': 0.9673469387755103, 'examples_seen': 250880, 'step': 6300, 'algorithm': 'activity_selector'}
I0714 16:25:32.323912 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0714 16:25:34.421345 133500379165312 run.py:687] Algo activity_selector step 6350 current loss 1.062625, current_train_items 252880.
I0714 16:25:34.512506 133500379165312 run.py:722] (val) algo activity_selector step 6350: {'selected': 0.9485294117647058, 'score': 0.9485294117647058, 'examples_seen': 252880, 'step': 6350, 'algorithm': 'activity_selector'}
I0714 16:25:34.512823 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0714 16:25:36.120759 133500379165312 run.py:687] Algo activity_selector step 6400 current loss 0.251902, current_train_items 254864.
I0714 16:25:36.171148 133500379165312 run.py:722] (val) algo activity_selector step 6400: {'selected': 0.9620758483033932, 'score': 0.9620758483033932, 'examples_seen': 254864, 'step': 6400, 'algorithm': 'activity_selector'}
I0714 16:25:36.171415 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0714 16:25:37.535876 133500379165312 run.py:687] Algo activity_selector step 6450 current loss 2.227772, current_train_items 256816.
I0714 16:25:37.588297 133500379165312 run.py:722] (val) algo activity_selector step 6450: {'selected': 0.9668615984405458, 'score': 0.9668615984405458, 'examples_seen': 256816, 'step': 6450, 'algorithm': 'activity_selector'}
I0714 16:25:37.588525 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0714 16:25:38.986404 133500379165312 run.py:687] Algo activity_selector step 6500 current loss 1.642828, current_train_items 258816.
I0714 16:25:39.040176 133500379165312 run.py:722] (val) algo activity_selector step 6500: {'selected': 0.9824561403508771, 'score': 0.9824561403508771, 'examples_seen': 258816, 'step': 6500, 'algorithm': 'activity_selector'}
I0714 16:25:39.040397 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.982, val scores are: activity_selector: 0.982
I0714 16:25:40.408162 133500379165312 run.py:687] Algo activity_selector step 6550 current loss 1.594362, current_train_items 260752.
I0714 16:25:40.465591 133500379165312 run.py:722] (val) algo activity_selector step 6550: {'selected': 0.9435336976320583, 'score': 0.9435336976320583, 'examples_seen': 260752, 'step': 6550, 'algorithm': 'activity_selector'}
I0714 16:25:40.465813 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0714 16:25:41.865112 133500379165312 run.py:687] Algo activity_selector step 6600 current loss 0.488132, current_train_items 262800.
I0714 16:25:41.907024 133500379165312 run.py:722] (val) algo activity_selector step 6600: {'selected': 0.9792843691148777, 'score': 0.9792843691148777, 'examples_seen': 262800, 'step': 6600, 'algorithm': 'activity_selector'}
I0714 16:25:41.907224 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.979, val scores are: activity_selector: 0.979
I0714 16:25:43.285718 133500379165312 run.py:687] Algo activity_selector step 6650 current loss 0.088598, current_train_items 264832.
I0714 16:25:43.329760 133500379165312 run.py:722] (val) algo activity_selector step 6650: {'selected': 0.9449715370018976, 'score': 0.9449715370018976, 'examples_seen': 264832, 'step': 6650, 'algorithm': 'activity_selector'}
I0714 16:25:43.329957 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0714 16:25:44.706146 133500379165312 run.py:687] Algo activity_selector step 6700 current loss 0.824117, current_train_items 266800.
I0714 16:25:44.768624 133500379165312 run.py:722] (val) algo activity_selector step 6700: {'selected': 0.98, 'score': 0.98, 'examples_seen': 266800, 'step': 6700, 'algorithm': 'activity_selector'}
I0714 16:25:44.768805 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.980, val scores are: activity_selector: 0.980
I0714 16:25:46.903394 133500379165312 run.py:687] Algo activity_selector step 6750 current loss 0.194404, current_train_items 268800.
I0714 16:25:46.984632 133500379165312 run.py:722] (val) algo activity_selector step 6750: {'selected': 0.9522123893805311, 'score': 0.9522123893805311, 'examples_seen': 268800, 'step': 6750, 'algorithm': 'activity_selector'}
I0714 16:25:46.984904 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0714 16:25:48.442294 133500379165312 run.py:687] Algo activity_selector step 6800 current loss 0.366235, current_train_items 270752.
I0714 16:25:48.493366 133500379165312 run.py:722] (val) algo activity_selector step 6800: {'selected': 0.935361216730038, 'score': 0.935361216730038, 'examples_seen': 270752, 'step': 6800, 'algorithm': 'activity_selector'}
I0714 16:25:48.493570 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0714 16:25:49.861164 133500379165312 run.py:687] Algo activity_selector step 6850 current loss 1.738073, current_train_items 272736.
I0714 16:25:49.914633 133500379165312 run.py:722] (val) algo activity_selector step 6850: {'selected': 0.9302325581395349, 'score': 0.9302325581395349, 'examples_seen': 272736, 'step': 6850, 'algorithm': 'activity_selector'}
I0714 16:25:49.914820 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0714 16:25:51.342144 133500379165312 run.py:687] Algo activity_selector step 6900 current loss 0.822286, current_train_items 274720.
I0714 16:25:51.408969 133500379165312 run.py:722] (val) algo activity_selector step 6900: {'selected': 0.9184060721062619, 'score': 0.9184060721062619, 'examples_seen': 274720, 'step': 6900, 'algorithm': 'activity_selector'}
I0714 16:25:51.409231 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.918, val scores are: activity_selector: 0.918
I0714 16:25:52.784479 133500379165312 run.py:687] Algo activity_selector step 6950 current loss 0.305018, current_train_items 276736.
I0714 16:25:52.829488 133500379165312 run.py:722] (val) algo activity_selector step 6950: {'selected': 0.9809160305343513, 'score': 0.9809160305343513, 'examples_seen': 276736, 'step': 6950, 'algorithm': 'activity_selector'}
I0714 16:25:52.829688 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0714 16:25:54.198421 133500379165312 run.py:687] Algo activity_selector step 7000 current loss 0.441480, current_train_items 278768.
I0714 16:25:54.240881 133500379165312 run.py:722] (val) algo activity_selector step 7000: {'selected': 0.9413919413919414, 'score': 0.9413919413919414, 'examples_seen': 278768, 'step': 7000, 'algorithm': 'activity_selector'}
I0714 16:25:54.241069 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0714 16:25:55.604072 133500379165312 run.py:687] Algo activity_selector step 7050 current loss 0.136303, current_train_items 280752.
I0714 16:25:55.648812 133500379165312 run.py:722] (val) algo activity_selector step 7050: {'selected': 0.9670781893004115, 'score': 0.9670781893004115, 'examples_seen': 280752, 'step': 7050, 'algorithm': 'activity_selector'}
I0714 16:25:55.648997 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0714 16:25:57.014868 133500379165312 run.py:687] Algo activity_selector step 7100 current loss 0.369353, current_train_items 282736.
I0714 16:25:57.059667 133500379165312 run.py:722] (val) algo activity_selector step 7100: {'selected': 0.96875, 'score': 0.96875, 'examples_seen': 282736, 'step': 7100, 'algorithm': 'activity_selector'}
I0714 16:25:57.059844 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0714 16:25:59.283896 133500379165312 run.py:687] Algo activity_selector step 7150 current loss 1.391268, current_train_items 284720.
I0714 16:25:59.411575 133500379165312 run.py:722] (val) algo activity_selector step 7150: {'selected': 0.96579476861167, 'score': 0.96579476861167, 'examples_seen': 284720, 'step': 7150, 'algorithm': 'activity_selector'}
I0714 16:25:59.411992 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0714 16:26:00.786078 133500379165312 run.py:687] Algo activity_selector step 7200 current loss 0.215898, current_train_items 286672.
I0714 16:26:00.839423 133500379165312 run.py:722] (val) algo activity_selector step 7200: {'selected': 0.9746588693957114, 'score': 0.9746588693957114, 'examples_seen': 286672, 'step': 7200, 'algorithm': 'activity_selector'}
I0714 16:26:00.839613 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0714 16:26:02.169929 133500379165312 run.py:687] Algo activity_selector step 7250 current loss 3.225674, current_train_items 288640.
I0714 16:26:02.239965 133500379165312 run.py:722] (val) algo activity_selector step 7250: {'selected': 0.96045197740113, 'score': 0.96045197740113, 'examples_seen': 288640, 'step': 7250, 'algorithm': 'activity_selector'}
I0714 16:26:02.240155 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0714 16:26:03.612829 133500379165312 run.py:687] Algo activity_selector step 7300 current loss 0.254581, current_train_items 290688.
I0714 16:26:03.656536 133500379165312 run.py:722] (val) algo activity_selector step 7300: {'selected': 0.9628252788104089, 'score': 0.9628252788104089, 'examples_seen': 290688, 'step': 7300, 'algorithm': 'activity_selector'}
I0714 16:26:03.656756 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0714 16:26:05.014801 133500379165312 run.py:687] Algo activity_selector step 7350 current loss 0.153703, current_train_items 292688.
I0714 16:26:05.056613 133500379165312 run.py:722] (val) algo activity_selector step 7350: {'selected': 0.9764705882352941, 'score': 0.9764705882352941, 'examples_seen': 292688, 'step': 7350, 'algorithm': 'activity_selector'}
I0714 16:26:05.056791 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0714 16:26:06.380438 133500379165312 run.py:687] Algo activity_selector step 7400 current loss 0.922550, current_train_items 294688.
I0714 16:26:06.425692 133500379165312 run.py:722] (val) algo activity_selector step 7400: {'selected': 0.9695740365111561, 'score': 0.9695740365111561, 'examples_seen': 294688, 'step': 7400, 'algorithm': 'activity_selector'}
I0714 16:26:06.425899 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0714 16:26:07.787516 133500379165312 run.py:687] Algo activity_selector step 7450 current loss 0.551320, current_train_items 296672.
I0714 16:26:07.830872 133500379165312 run.py:722] (val) algo activity_selector step 7450: {'selected': 0.9277566539923955, 'score': 0.9277566539923955, 'examples_seen': 296672, 'step': 7450, 'algorithm': 'activity_selector'}
I0714 16:26:07.831047 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.988, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0714 16:26:09.136551 133500379165312 run.py:687] Algo activity_selector step 7500 current loss 2.096038, current_train_items 298624.
I0714 16:26:09.188453 133500379165312 run.py:722] (val) algo activity_selector step 7500: {'selected': 0.9885057471264367, 'score': 0.9885057471264367, 'examples_seen': 298624, 'step': 7500, 'algorithm': 'activity_selector'}
I0714 16:26:09.188654 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.988, current avg val score is 0.989, val scores are: activity_selector: 0.989
I0714 16:26:11.335686 133500379165312 run.py:687] Algo activity_selector step 7550 current loss 4.717299, current_train_items 300624.
I0714 16:26:11.447762 133500379165312 run.py:722] (val) algo activity_selector step 7550: {'selected': 0.969450101832994, 'score': 0.969450101832994, 'examples_seen': 300624, 'step': 7550, 'algorithm': 'activity_selector'}
I0714 16:26:11.448056 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.989, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0714 16:26:12.885656 133500379165312 run.py:687] Algo activity_selector step 7600 current loss 3.301847, current_train_items 302576.
I0714 16:26:12.943491 133500379165312 run.py:722] (val) algo activity_selector step 7600: {'selected': 0.9713193116634798, 'score': 0.9713193116634798, 'examples_seen': 302576, 'step': 7600, 'algorithm': 'activity_selector'}
I0714 16:26:12.943679 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.989, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0714 16:26:14.305495 133500379165312 run.py:687] Algo activity_selector step 7650 current loss 0.433014, current_train_items 304608.
I0714 16:26:14.348494 133500379165312 run.py:722] (val) algo activity_selector step 7650: {'selected': 0.9798387096774194, 'score': 0.9798387096774194, 'examples_seen': 304608, 'step': 7650, 'algorithm': 'activity_selector'}
I0714 16:26:14.348719 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.989, current avg val score is 0.980, val scores are: activity_selector: 0.980
I0714 16:26:15.712831 133500379165312 run.py:687] Algo activity_selector step 7700 current loss 0.169777, current_train_items 306640.
I0714 16:26:15.756867 133500379165312 run.py:722] (val) algo activity_selector step 7700: {'selected': 0.9899799599198397, 'score': 0.9899799599198397, 'examples_seen': 306640, 'step': 7700, 'algorithm': 'activity_selector'}
I0714 16:26:15.757054 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.989, current avg val score is 0.990, val scores are: activity_selector: 0.990
I0714 16:26:17.104822 133500379165312 run.py:687] Algo activity_selector step 7750 current loss 0.977241, current_train_items 308608.
I0714 16:26:17.175205 133500379165312 run.py:722] (val) algo activity_selector step 7750: {'selected': 0.9442379182156133, 'score': 0.9442379182156133, 'examples_seen': 308608, 'step': 7750, 'algorithm': 'activity_selector'}
I0714 16:26:17.175454 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0714 16:26:18.515157 133500379165312 run.py:687] Algo activity_selector step 7800 current loss 0.178356, current_train_items 310608.
I0714 16:26:18.561639 133500379165312 run.py:722] (val) algo activity_selector step 7800: {'selected': 0.9598393574297188, 'score': 0.9598393574297188, 'examples_seen': 310608, 'step': 7800, 'algorithm': 'activity_selector'}
I0714 16:26:18.561881 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0714 16:26:19.930174 133500379165312 run.py:687] Algo activity_selector step 7850 current loss 0.555515, current_train_items 312576.
I0714 16:26:19.979469 133500379165312 run.py:722] (val) algo activity_selector step 7850: {'selected': 0.965648854961832, 'score': 0.965648854961832, 'examples_seen': 312576, 'step': 7850, 'algorithm': 'activity_selector'}
I0714 16:26:19.979664 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0714 16:26:21.330819 133500379165312 run.py:687] Algo activity_selector step 7900 current loss 2.572233, current_train_items 314528.
I0714 16:26:21.386643 133500379165312 run.py:722] (val) algo activity_selector step 7900: {'selected': 0.9746588693957114, 'score': 0.9746588693957114, 'examples_seen': 314528, 'step': 7900, 'algorithm': 'activity_selector'}
I0714 16:26:21.386826 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0714 16:26:23.504155 133500379165312 run.py:687] Algo activity_selector step 7950 current loss 3.316305, current_train_items 316528.
I0714 16:26:23.608070 133500379165312 run.py:722] (val) algo activity_selector step 7950: {'selected': 0.9733570159857906, 'score': 0.9733570159857906, 'examples_seen': 316528, 'step': 7950, 'algorithm': 'activity_selector'}
I0714 16:26:23.608356 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0714 16:26:25.034630 133500379165312 run.py:687] Algo activity_selector step 8000 current loss 0.409483, current_train_items 318528.
I0714 16:26:25.079640 133500379165312 run.py:722] (val) algo activity_selector step 8000: {'selected': 0.9589552238805971, 'score': 0.9589552238805971, 'examples_seen': 318528, 'step': 8000, 'algorithm': 'activity_selector'}
I0714 16:26:25.079865 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0714 16:26:26.429973 133500379165312 run.py:687] Algo activity_selector step 8050 current loss 0.096285, current_train_items 320560.
I0714 16:26:26.473679 133500379165312 run.py:722] (val) algo activity_selector step 8050: {'selected': 0.9825242718446603, 'score': 0.9825242718446603, 'examples_seen': 320560, 'step': 8050, 'algorithm': 'activity_selector'}
I0714 16:26:26.473838 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.983, val scores are: activity_selector: 0.983
I0714 16:26:27.855810 133500379165312 run.py:687] Algo activity_selector step 8100 current loss 0.190236, current_train_items 322544.
I0714 16:26:27.902126 133500379165312 run.py:722] (val) algo activity_selector step 8100: {'selected': 0.9615384615384616, 'score': 0.9615384615384616, 'examples_seen': 322544, 'step': 8100, 'algorithm': 'activity_selector'}
I0714 16:26:27.902342 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0714 16:26:29.265960 133500379165312 run.py:687] Algo activity_selector step 8150 current loss 0.149868, current_train_items 324528.
I0714 16:26:29.314659 133500379165312 run.py:722] (val) algo activity_selector step 8150: {'selected': 0.9650092081031308, 'score': 0.9650092081031308, 'examples_seen': 324528, 'step': 8150, 'algorithm': 'activity_selector'}
I0714 16:26:29.314850 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0714 16:26:30.646681 133500379165312 run.py:687] Algo activity_selector step 8200 current loss 1.536732, current_train_items 326528.
I0714 16:26:30.711820 133500379165312 run.py:722] (val) algo activity_selector step 8200: {'selected': 0.9565217391304348, 'score': 0.9565217391304348, 'examples_seen': 326528, 'step': 8200, 'algorithm': 'activity_selector'}
I0714 16:26:30.712002 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0714 16:26:32.024579 133500379165312 run.py:687] Algo activity_selector step 8250 current loss 2.190325, current_train_items 328464.
I0714 16:26:32.080240 133500379165312 run.py:722] (val) algo activity_selector step 8250: {'selected': 0.9640831758034027, 'score': 0.9640831758034027, 'examples_seen': 328464, 'step': 8250, 'algorithm': 'activity_selector'}
I0714 16:26:32.080500 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0714 16:26:33.429225 133500379165312 run.py:687] Algo activity_selector step 8300 current loss 3.305215, current_train_items 330432.
I0714 16:26:33.486717 133500379165312 run.py:722] (val) algo activity_selector step 8300: {'selected': 0.9245283018867925, 'score': 0.9245283018867925, 'examples_seen': 330432, 'step': 8300, 'algorithm': 'activity_selector'}
I0714 16:26:33.486902 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0714 16:26:35.552298 133500379165312 run.py:687] Algo activity_selector step 8350 current loss 0.030765, current_train_items 332480.
I0714 16:26:35.635924 133500379165312 run.py:722] (val) algo activity_selector step 8350: {'selected': 0.9317738791423001, 'score': 0.9317738791423001, 'examples_seen': 332480, 'step': 8350, 'algorithm': 'activity_selector'}
I0714 16:26:35.636179 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0714 16:26:37.144090 133500379165312 run.py:687] Algo activity_selector step 8400 current loss 0.026914, current_train_items 334480.
I0714 16:26:37.186618 133500379165312 run.py:722] (val) algo activity_selector step 8400: {'selected': 0.968503937007874, 'score': 0.968503937007874, 'examples_seen': 334480, 'step': 8400, 'algorithm': 'activity_selector'}
I0714 16:26:37.186813 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0714 16:26:38.491753 133500379165312 run.py:687] Algo activity_selector step 8450 current loss 0.915289, current_train_items 336480.
I0714 16:26:38.535733 133500379165312 run.py:722] (val) algo activity_selector step 8450: {'selected': 0.9900596421471173, 'score': 0.9900596421471173, 'examples_seen': 336480, 'step': 8450, 'algorithm': 'activity_selector'}
I0714 16:26:38.535916 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.990, current avg val score is 0.990, val scores are: activity_selector: 0.990
I0714 16:26:39.907180 133500379165312 run.py:687] Algo activity_selector step 8500 current loss 0.098504, current_train_items 338464.
I0714 16:26:39.952591 133500379165312 run.py:722] (val) algo activity_selector step 8500: {'selected': 0.9750479846449136, 'score': 0.9750479846449136, 'examples_seen': 338464, 'step': 8500, 'algorithm': 'activity_selector'}
I0714 16:26:39.952782 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0714 16:26:41.263014 133500379165312 run.py:687] Algo activity_selector step 8550 current loss 2.260697, current_train_items 340432.
I0714 16:26:41.315659 133500379165312 run.py:722] (val) algo activity_selector step 8550: {'selected': 0.964879852125693, 'score': 0.964879852125693, 'examples_seen': 340432, 'step': 8550, 'algorithm': 'activity_selector'}
I0714 16:26:41.315827 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0714 16:26:42.629155 133500379165312 run.py:687] Algo activity_selector step 8600 current loss 1.822426, current_train_items 342416.
I0714 16:26:42.684000 133500379165312 run.py:722] (val) algo activity_selector step 8600: {'selected': 0.9813432835820896, 'score': 0.9813432835820896, 'examples_seen': 342416, 'step': 8600, 'algorithm': 'activity_selector'}
I0714 16:26:42.684173 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0714 16:26:43.986150 133500379165312 run.py:687] Algo activity_selector step 8650 current loss 2.926230, current_train_items 344368.
I0714 16:26:44.046602 133500379165312 run.py:722] (val) algo activity_selector step 8650: {'selected': 0.9529411764705882, 'score': 0.9529411764705882, 'examples_seen': 344368, 'step': 8650, 'algorithm': 'activity_selector'}
I0714 16:26:44.046821 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0714 16:26:45.375363 133500379165312 run.py:687] Algo activity_selector step 8700 current loss 0.313164, current_train_items 346400.
I0714 16:26:45.415682 133500379165312 run.py:722] (val) algo activity_selector step 8700: {'selected': 0.9674952198852773, 'score': 0.9674952198852773, 'examples_seen': 346400, 'step': 8700, 'algorithm': 'activity_selector'}
I0714 16:26:45.415890 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0714 16:26:47.194948 133500379165312 run.py:687] Algo activity_selector step 8750 current loss 0.068778, current_train_items 348432.
I0714 16:26:47.293493 133500379165312 run.py:722] (val) algo activity_selector step 8750: {'selected': 0.9377431906614787, 'score': 0.9377431906614787, 'examples_seen': 348432, 'step': 8750, 'algorithm': 'activity_selector'}
I0714 16:26:47.293742 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0714 16:26:49.005666 133500379165312 run.py:687] Algo activity_selector step 8800 current loss 0.753910, current_train_items 350416.
I0714 16:26:49.049459 133500379165312 run.py:722] (val) algo activity_selector step 8800: {'selected': 0.9740518962075848, 'score': 0.9740518962075848, 'examples_seen': 350416, 'step': 8800, 'algorithm': 'activity_selector'}
I0714 16:26:49.049644 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0714 16:26:50.391684 133500379165312 run.py:687] Algo activity_selector step 8850 current loss 0.202781, current_train_items 352400.
I0714 16:26:50.438915 133500379165312 run.py:722] (val) algo activity_selector step 8850: {'selected': 0.9825918762088974, 'score': 0.9825918762088974, 'examples_seen': 352400, 'step': 8850, 'algorithm': 'activity_selector'}
I0714 16:26:50.439097 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.983, val scores are: activity_selector: 0.983
I0714 16:26:51.763139 133500379165312 run.py:687] Algo activity_selector step 8900 current loss 0.274162, current_train_items 354368.
I0714 16:26:51.813412 133500379165312 run.py:722] (val) algo activity_selector step 8900: {'selected': 0.9555125725338491, 'score': 0.9555125725338491, 'examples_seen': 354368, 'step': 8900, 'algorithm': 'activity_selector'}
I0714 16:26:51.813657 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0714 16:26:53.109901 133500379165312 run.py:687] Algo activity_selector step 8950 current loss 1.397105, current_train_items 356320.
I0714 16:26:53.162928 133500379165312 run.py:722] (val) algo activity_selector step 8950: {'selected': 0.9575289575289575, 'score': 0.9575289575289575, 'examples_seen': 356320, 'step': 8950, 'algorithm': 'activity_selector'}
I0714 16:26:53.163107 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0714 16:26:54.459066 133500379165312 run.py:687] Algo activity_selector step 9000 current loss 2.540219, current_train_items 358320.
I0714 16:26:54.517678 133500379165312 run.py:722] (val) algo activity_selector step 9000: {'selected': 0.9666011787819253, 'score': 0.9666011787819253, 'examples_seen': 358320, 'step': 9000, 'algorithm': 'activity_selector'}
I0714 16:26:54.517854 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0714 16:26:55.842794 133500379165312 run.py:687] Algo activity_selector step 9050 current loss 0.279076, current_train_items 360320.
I0714 16:26:55.888493 133500379165312 run.py:722] (val) algo activity_selector step 9050: {'selected': 0.9845559845559846, 'score': 0.9845559845559846, 'examples_seen': 360320, 'step': 9050, 'algorithm': 'activity_selector'}
I0714 16:26:55.888669 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.985, val scores are: activity_selector: 0.985
I0714 16:26:57.193848 133500379165312 run.py:687] Algo activity_selector step 9100 current loss 0.058806, current_train_items 362352.
I0714 16:26:57.235651 133500379165312 run.py:722] (val) algo activity_selector step 9100: {'selected': 0.9506172839506174, 'score': 0.9506172839506174, 'examples_seen': 362352, 'step': 9100, 'algorithm': 'activity_selector'}
I0714 16:26:57.235841 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0714 16:26:58.915162 133500379165312 run.py:687] Algo activity_selector step 9150 current loss 0.150885, current_train_items 364352.
I0714 16:26:59.003065 133500379165312 run.py:722] (val) algo activity_selector step 9150: {'selected': 0.9421157684630739, 'score': 0.9421157684630739, 'examples_seen': 364352, 'step': 9150, 'algorithm': 'activity_selector'}
I0714 16:26:59.003314 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0714 16:27:00.871912 133500379165312 run.py:687] Algo activity_selector step 9200 current loss 0.274792, current_train_items 366320.
I0714 16:27:00.916518 133500379165312 run.py:722] (val) algo activity_selector step 9200: {'selected': 0.9644268774703557, 'score': 0.9644268774703557, 'examples_seen': 366320, 'step': 9200, 'algorithm': 'activity_selector'}
I0714 16:27:00.916685 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0714 16:27:02.242004 133500379165312 run.py:687] Algo activity_selector step 9250 current loss 1.227240, current_train_items 368320.
I0714 16:27:02.291832 133500379165312 run.py:722] (val) algo activity_selector step 9250: {'selected': 0.9760956175298805, 'score': 0.9760956175298805, 'examples_seen': 368320, 'step': 9250, 'algorithm': 'activity_selector'}
I0714 16:27:02.292034 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0714 16:27:03.577174 133500379165312 run.py:687] Algo activity_selector step 9300 current loss 1.023511, current_train_items 370272.
I0714 16:27:03.629152 133500379165312 run.py:722] (val) algo activity_selector step 9300: {'selected': 0.9809160305343512, 'score': 0.9809160305343512, 'examples_seen': 370272, 'step': 9300, 'algorithm': 'activity_selector'}
I0714 16:27:03.629380 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0714 16:27:04.956294 133500379165312 run.py:687] Algo activity_selector step 9350 current loss 2.257911, current_train_items 372240.
I0714 16:27:05.017069 133500379165312 run.py:722] (val) algo activity_selector step 9350: {'selected': 0.9657794676806084, 'score': 0.9657794676806084, 'examples_seen': 372240, 'step': 9350, 'algorithm': 'activity_selector'}
I0714 16:27:05.017250 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0714 16:27:06.314985 133500379165312 run.py:687] Algo activity_selector step 9400 current loss 0.152040, current_train_items 374288.
I0714 16:27:06.360321 133500379165312 run.py:722] (val) algo activity_selector step 9400: {'selected': 0.9488188976377954, 'score': 0.9488188976377954, 'examples_seen': 374288, 'step': 9400, 'algorithm': 'activity_selector'}
I0714 16:27:06.360487 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0714 16:27:07.664912 133500379165312 run.py:687] Algo activity_selector step 9450 current loss 0.035020, current_train_items 376288.
I0714 16:27:07.709118 133500379165312 run.py:722] (val) algo activity_selector step 9450: {'selected': 0.9904397705544934, 'score': 0.9904397705544934, 'examples_seen': 376288, 'step': 9450, 'algorithm': 'activity_selector'}
I0714 16:27:07.709362 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.990, current avg val score is 0.990, val scores are: activity_selector: 0.990
I0714 16:27:09.029652 133500379165312 run.py:687] Algo activity_selector step 9500 current loss 0.738653, current_train_items 378304.
I0714 16:27:09.076350 133500379165312 run.py:722] (val) algo activity_selector step 9500: {'selected': 0.975517890772128, 'score': 0.975517890772128, 'examples_seen': 378304, 'step': 9500, 'algorithm': 'activity_selector'}
I0714 16:27:09.076549 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0714 16:27:10.423417 133500379165312 run.py:687] Algo activity_selector step 9550 current loss 0.382388, current_train_items 380272.
I0714 16:27:10.487217 133500379165312 run.py:722] (val) algo activity_selector step 9550: {'selected': 0.9586466165413534, 'score': 0.9586466165413534, 'examples_seen': 380272, 'step': 9550, 'algorithm': 'activity_selector'}
I0714 16:27:10.487511 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0714 16:27:12.650999 133500379165312 run.py:687] Algo activity_selector step 9600 current loss 2.098400, current_train_items 382240.
I0714 16:27:12.703668 133500379165312 run.py:722] (val) algo activity_selector step 9600: {'selected': 0.9660377358490566, 'score': 0.9660377358490566, 'examples_seen': 382240, 'step': 9600, 'algorithm': 'activity_selector'}
I0714 16:27:12.703866 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0714 16:27:13.970284 133500379165312 run.py:687] Algo activity_selector step 9650 current loss 0.247148, current_train_items 384224.
I0714 16:27:14.020742 133500379165312 run.py:722] (val) algo activity_selector step 9650: {'selected': 0.9548872180451128, 'score': 0.9548872180451128, 'examples_seen': 384224, 'step': 9650, 'algorithm': 'activity_selector'}
I0714 16:27:14.020922 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0714 16:27:15.360570 133500379165312 run.py:687] Algo activity_selector step 9700 current loss 2.078613, current_train_items 386176.
I0714 16:27:15.416694 133500379165312 run.py:722] (val) algo activity_selector step 9700: {'selected': 0.967871485943775, 'score': 0.967871485943775, 'examples_seen': 386176, 'step': 9700, 'algorithm': 'activity_selector'}
I0714 16:27:15.416857 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.990, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0714 16:27:16.733717 133500379165312 run.py:687] Algo activity_selector step 9750 current loss 0.317944, current_train_items 388224.
I0714 16:27:16.775624 133500379165312 run.py:722] (val) algo activity_selector step 9750: {'selected': 0.9924528301886791, 'score': 0.9924528301886791, 'examples_seen': 388224, 'step': 9750, 'algorithm': 'activity_selector'}
I0714 16:27:16.775800 133500379165312 run.py:743] Checkpointing best model, best avg val score was 0.990, current avg val score is 0.992, val scores are: activity_selector: 0.992
I0714 16:27:18.091554 133500379165312 run.py:687] Algo activity_selector step 9800 current loss 0.066953, current_train_items 390240.
I0714 16:27:18.132956 133500379165312 run.py:722] (val) algo activity_selector step 9800: {'selected': 0.9792843691148775, 'score': 0.9792843691148775, 'examples_seen': 390240, 'step': 9800, 'algorithm': 'activity_selector'}
I0714 16:27:18.133138 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.979, val scores are: activity_selector: 0.979
I0714 16:27:19.465030 133500379165312 run.py:687] Algo activity_selector step 9850 current loss 0.701675, current_train_items 392224.
I0714 16:27:19.510479 133500379165312 run.py:722] (val) algo activity_selector step 9850: {'selected': 0.9824561403508771, 'score': 0.9824561403508771, 'examples_seen': 392224, 'step': 9850, 'algorithm': 'activity_selector'}
I0714 16:27:19.510695 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.982, val scores are: activity_selector: 0.982
I0714 16:27:20.845707 133500379165312 run.py:687] Algo activity_selector step 9900 current loss 0.187089, current_train_items 394208.
I0714 16:27:20.891306 133500379165312 run.py:722] (val) algo activity_selector step 9900: {'selected': 0.9729729729729729, 'score': 0.9729729729729729, 'examples_seen': 394208, 'step': 9900, 'algorithm': 'activity_selector'}
I0714 16:27:20.891480 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0714 16:27:22.191893 133500379165312 run.py:687] Algo activity_selector step 9950 current loss 0.542177, current_train_items 396176.
I0714 16:27:22.242707 133500379165312 run.py:722] (val) algo activity_selector step 9950: {'selected': 0.9580838323353292, 'score': 0.9580838323353292, 'examples_seen': 396176, 'step': 9950, 'algorithm': 'activity_selector'}
I0714 16:27:22.242885 133500379165312 run.py:746] Not saving new best model, best avg val score was 0.992, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0714 16:27:24.261893 133500379165312 run.py:752] Restoring best model from checkpoint...
I0714 16:27:26.125299 133500379165312 run.py:767] (test) algo activity_selector : {'selected': 0.8715953307392996, 'score': 0.8715953307392996, 'examples_seen': 398112, 'step': 10000, 'algorithm': 'activity_selector'}
I0714 16:27:26.125461 133500379165312 run.py:769] Done!
