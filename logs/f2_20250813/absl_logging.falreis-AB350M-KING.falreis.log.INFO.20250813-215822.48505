I0813 21:58:25.199369 138121668994560 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0813 21:58:25.199958 138121668994560 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0813 21:58:25.435737 138121668994560 run.py:411] Model: f2 ['activity_selector']
I0813 21:58:25.435838 138121668994560 run.py:413] algorithms ['activity_selector']
I0813 21:58:25.436012 138121668994560 run.py:414] train_lengths ['4', '7', '11', '13', '16']
I0813 21:58:25.436048 138121668994560 run.py:415] train_batch_size 32
I0813 21:58:25.436153 138121668994560 run.py:416] val_batch_size 16
I0813 21:58:25.436184 138121668994560 run.py:417] test_batch_size 16
I0813 21:58:25.436213 138121668994560 run.py:418] chunked_training True
I0813 21:58:25.436331 138121668994560 run.py:419] chunk_length 8
I0813 21:58:25.436362 138121668994560 run.py:420] train_steps 10000
I0813 21:58:25.436391 138121668994560 run.py:421] eval_every 50
I0813 21:58:25.436420 138121668994560 run.py:422] test_every 500
I0813 21:58:25.436448 138121668994560 run.py:423] hidden_size 256
I0813 21:58:25.436478 138121668994560 run.py:424] nb_msg_passing_steps 1
I0813 21:58:25.436506 138121668994560 run.py:425] learning_rate 0.001
I0813 21:58:25.436601 138121668994560 run.py:426] grad_clip_max_norm 1.0
I0813 21:58:25.436633 138121668994560 run.py:427] dropout_prob 0.1
I0813 21:58:25.436663 138121668994560 run.py:428] hint_teacher_forcing 0.0
I0813 21:58:25.436691 138121668994560 run.py:429] hint_mode encoded_decoded
I0813 21:58:25.436797 138121668994560 run.py:430] hint_repred_mode soft
I0813 21:58:25.436833 138121668994560 run.py:431] use_ln False
I0813 21:58:25.436861 138121668994560 run.py:432] use_lstm True
I0813 21:58:25.436888 138121668994560 run.py:433] nb_triplet_fts 8
I0813 21:58:25.436915 138121668994560 run.py:434] encoder_init xavier_on_scalars
I0813 21:58:25.436942 138121668994560 run.py:435] processor_type f2
I0813 21:58:25.436974 138121668994560 run.py:436] checkpoint_path CLRS30
I0813 21:58:25.437002 138121668994560 run.py:437] dataset_path CLRS30
I0813 21:58:25.437030 138121668994560 run.py:438] freeze_processor False
I0813 21:58:25.437057 138121668994560 run.py:439] reduction min
I0813 21:58:25.437084 138121668994560 run.py:440] activation elu
I0813 21:58:25.437119 138121668994560 run.py:441] restore_model 
I0813 21:58:25.437150 138121668994560 run.py:442] gated True
I0813 21:58:25.437182 138121668994560 run.py:443] gated_activation sigmoid
I0813 21:58:25.439884 138121668994560 run.py:469] Creating samplers for algo activity_selector
W0813 21:58:25.440077 138121668994560 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0813 21:58:25.440340 138121668994560 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0813 21:58:25.663129 138121668994560 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0813 21:58:25.906336 138121668994560 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0813 21:58:26.208508 138121668994560 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0813 21:58:26.540991 138121668994560 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0813 21:58:26.925129 138121668994560 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0813 21:58:26.925436 138121668994560 samplers.py:124] Creating a dataset with 64 samples.
I0813 21:58:26.951406 138121668994560 run.py:255] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0813 21:58:26.952094 138121668994560 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0813 21:58:26.955458 138121668994560 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0813 21:58:26.958536 138121668994560 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0813 21:58:27.009662 138121668994560 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W0813 21:58:27.030276 138121668994560 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x7d9e70786de0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0813 21:58:59.754875 138121668994560 run.py:692] Algo activity_selector step 0 current loss 5.548767, current_train_items 32.
I0813 21:59:04.811868 138121668994560 run.py:727] (val) algo activity_selector step 0: {'selected': 0.28421052631578947, 'score': 0.28421052631578947, 'examples_seen': 32, 'step': 0, 'algorithm': 'activity_selector'}
I0813 21:59:04.812031 138121668994560 run.py:748] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.284, val scores are: activity_selector: 0.284
I0813 21:59:57.849318 138121668994560 run.py:692] Algo activity_selector step 50 current loss 4.258724, current_train_items 1440.
I0813 21:59:57.879140 138121668994560 run.py:727] (val) algo activity_selector step 50: {'selected': 0.5786452353616532, 'score': 0.5786452353616532, 'examples_seen': 1440, 'step': 50, 'algorithm': 'activity_selector'}
I0813 21:59:57.879296 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.284, current avg val score is 0.579, val scores are: activity_selector: 0.579
I0813 21:59:58.812027 138121668994560 run.py:692] Algo activity_selector step 100 current loss 3.232424, current_train_items 2816.
I0813 21:59:58.842671 138121668994560 run.py:727] (val) algo activity_selector step 100: {'selected': 0.6680244399185337, 'score': 0.6680244399185337, 'examples_seen': 2816, 'step': 100, 'algorithm': 'activity_selector'}
I0813 21:59:58.842821 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.579, current avg val score is 0.668, val scores are: activity_selector: 0.668
I0813 21:59:59.808983 138121668994560 run.py:692] Algo activity_selector step 150 current loss 3.138541, current_train_items 4160.
I0813 21:59:59.839525 138121668994560 run.py:727] (val) algo activity_selector step 150: {'selected': 0.7555555555555556, 'score': 0.7555555555555556, 'examples_seen': 4160, 'step': 150, 'algorithm': 'activity_selector'}
I0813 21:59:59.839681 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.668, current avg val score is 0.756, val scores are: activity_selector: 0.756
I0813 22:00:00.813311 138121668994560 run.py:692] Algo activity_selector step 200 current loss 2.738193, current_train_items 5568.
I0813 22:00:00.843091 138121668994560 run.py:727] (val) algo activity_selector step 200: {'selected': 0.7317073170731707, 'score': 0.7317073170731707, 'examples_seen': 5568, 'step': 200, 'algorithm': 'activity_selector'}
I0813 22:00:00.843259 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.756, current avg val score is 0.732, val scores are: activity_selector: 0.732
I0813 22:00:01.743546 138121668994560 run.py:692] Algo activity_selector step 250 current loss 2.633642, current_train_items 6976.
I0813 22:00:01.774155 138121668994560 run.py:727] (val) algo activity_selector step 250: {'selected': 0.7433333333333333, 'score': 0.7433333333333333, 'examples_seen': 6976, 'step': 250, 'algorithm': 'activity_selector'}
I0813 22:00:01.774308 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.756, current avg val score is 0.743, val scores are: activity_selector: 0.743
I0813 22:00:02.688274 138121668994560 run.py:692] Algo activity_selector step 300 current loss 3.044345, current_train_items 8288.
I0813 22:00:02.719607 138121668994560 run.py:727] (val) algo activity_selector step 300: {'selected': 0.7233115468409586, 'score': 0.7233115468409586, 'examples_seen': 8288, 'step': 300, 'algorithm': 'activity_selector'}
I0813 22:00:02.719769 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.756, current avg val score is 0.723, val scores are: activity_selector: 0.723
I0813 22:00:03.647872 138121668994560 run.py:692] Algo activity_selector step 350 current loss 2.267819, current_train_items 9696.
I0813 22:00:03.678756 138121668994560 run.py:727] (val) algo activity_selector step 350: {'selected': 0.7680000000000001, 'score': 0.7680000000000001, 'examples_seen': 9696, 'step': 350, 'algorithm': 'activity_selector'}
I0813 22:00:03.678906 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.756, current avg val score is 0.768, val scores are: activity_selector: 0.768
I0813 22:00:04.636235 138121668994560 run.py:692] Algo activity_selector step 400 current loss 2.382105, current_train_items 11104.
I0813 22:00:04.666699 138121668994560 run.py:727] (val) algo activity_selector step 400: {'selected': 0.7617328519855596, 'score': 0.7617328519855596, 'examples_seen': 11104, 'step': 400, 'algorithm': 'activity_selector'}
I0813 22:00:04.666845 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.768, current avg val score is 0.762, val scores are: activity_selector: 0.762
I0813 22:00:05.565077 138121668994560 run.py:692] Algo activity_selector step 450 current loss 2.164673, current_train_items 12448.
I0813 22:00:05.596663 138121668994560 run.py:727] (val) algo activity_selector step 450: {'selected': 0.8007246376811594, 'score': 0.8007246376811594, 'examples_seen': 12448, 'step': 450, 'algorithm': 'activity_selector'}
I0813 22:00:05.596809 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.768, current avg val score is 0.801, val scores are: activity_selector: 0.801
I0813 22:00:06.568472 138121668994560 run.py:692] Algo activity_selector step 500 current loss 2.218693, current_train_items 13824.
I0813 22:00:06.598882 138121668994560 run.py:727] (val) algo activity_selector step 500: {'selected': 0.7578558225508317, 'score': 0.7578558225508317, 'examples_seen': 13824, 'step': 500, 'algorithm': 'activity_selector'}
I0813 22:00:06.599030 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.801, current avg val score is 0.758, val scores are: activity_selector: 0.758
I0813 22:00:07.517708 138121668994560 run.py:692] Algo activity_selector step 550 current loss 1.772127, current_train_items 15232.
I0813 22:00:07.548216 138121668994560 run.py:727] (val) algo activity_selector step 550: {'selected': 0.7890295358649789, 'score': 0.7890295358649789, 'examples_seen': 15232, 'step': 550, 'algorithm': 'activity_selector'}
I0813 22:00:07.548369 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.801, current avg val score is 0.789, val scores are: activity_selector: 0.789
I0813 22:00:08.451790 138121668994560 run.py:692] Algo activity_selector step 600 current loss 1.916105, current_train_items 16576.
I0813 22:00:08.482613 138121668994560 run.py:727] (val) algo activity_selector step 600: {'selected': 0.7850098619329389, 'score': 0.7850098619329389, 'examples_seen': 16576, 'step': 600, 'algorithm': 'activity_selector'}
I0813 22:00:08.482776 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.801, current avg val score is 0.785, val scores are: activity_selector: 0.785
I0813 22:00:09.405538 138121668994560 run.py:692] Algo activity_selector step 650 current loss 1.851197, current_train_items 17952.
I0813 22:00:09.436692 138121668994560 run.py:727] (val) algo activity_selector step 650: {'selected': 0.816546762589928, 'score': 0.816546762589928, 'examples_seen': 17952, 'step': 650, 'algorithm': 'activity_selector'}
I0813 22:00:09.436871 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.801, current avg val score is 0.817, val scores are: activity_selector: 0.817
I0813 22:00:10.393612 138121668994560 run.py:692] Algo activity_selector step 700 current loss 1.587674, current_train_items 19360.
I0813 22:00:10.423946 138121668994560 run.py:727] (val) algo activity_selector step 700: {'selected': 0.838475499092559, 'score': 0.838475499092559, 'examples_seen': 19360, 'step': 700, 'algorithm': 'activity_selector'}
I0813 22:00:10.424098 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.817, current avg val score is 0.838, val scores are: activity_selector: 0.838
I0813 22:00:11.403198 138121668994560 run.py:692] Algo activity_selector step 750 current loss 1.476351, current_train_items 20736.
I0813 22:00:11.433980 138121668994560 run.py:727] (val) algo activity_selector step 750: {'selected': 0.8101761252446185, 'score': 0.8101761252446185, 'examples_seen': 20736, 'step': 750, 'algorithm': 'activity_selector'}
I0813 22:00:11.434143 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.838, current avg val score is 0.810, val scores are: activity_selector: 0.810
I0813 22:00:12.327589 138121668994560 run.py:692] Algo activity_selector step 800 current loss 1.478650, current_train_items 22112.
I0813 22:00:12.360164 138121668994560 run.py:727] (val) algo activity_selector step 800: {'selected': 0.8430656934306568, 'score': 0.8430656934306568, 'examples_seen': 22112, 'step': 800, 'algorithm': 'activity_selector'}
I0813 22:00:12.360317 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.838, current avg val score is 0.843, val scores are: activity_selector: 0.843
I0813 22:00:13.330532 138121668994560 run.py:692] Algo activity_selector step 850 current loss 1.356408, current_train_items 23488.
I0813 22:00:13.360742 138121668994560 run.py:727] (val) algo activity_selector step 850: {'selected': 0.7862068965517243, 'score': 0.7862068965517243, 'examples_seen': 23488, 'step': 850, 'algorithm': 'activity_selector'}
I0813 22:00:13.360900 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.843, current avg val score is 0.786, val scores are: activity_selector: 0.786
I0813 22:00:14.301689 138121668994560 run.py:692] Algo activity_selector step 900 current loss 1.732551, current_train_items 24864.
I0813 22:00:14.332169 138121668994560 run.py:727] (val) algo activity_selector step 900: {'selected': 0.8068833652007649, 'score': 0.8068833652007649, 'examples_seen': 24864, 'step': 900, 'algorithm': 'activity_selector'}
I0813 22:00:14.332332 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.843, current avg val score is 0.807, val scores are: activity_selector: 0.807
I0813 22:00:15.240708 138121668994560 run.py:692] Algo activity_selector step 950 current loss 1.331007, current_train_items 26240.
I0813 22:00:15.273271 138121668994560 run.py:727] (val) algo activity_selector step 950: {'selected': 0.8007518796992481, 'score': 0.8007518796992481, 'examples_seen': 26240, 'step': 950, 'algorithm': 'activity_selector'}
I0813 22:00:15.273421 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.843, current avg val score is 0.801, val scores are: activity_selector: 0.801
I0813 22:00:16.190271 138121668994560 run.py:692] Algo activity_selector step 1000 current loss 1.813169, current_train_items 27616.
I0813 22:00:16.221706 138121668994560 run.py:727] (val) algo activity_selector step 1000: {'selected': 0.8127340823970038, 'score': 0.8127340823970038, 'examples_seen': 27616, 'step': 1000, 'algorithm': 'activity_selector'}
I0813 22:00:16.221857 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.843, current avg val score is 0.813, val scores are: activity_selector: 0.813
I0813 22:00:17.166372 138121668994560 run.py:692] Algo activity_selector step 1050 current loss 1.789062, current_train_items 28992.
I0813 22:00:17.195761 138121668994560 run.py:727] (val) algo activity_selector step 1050: {'selected': 0.7942122186495176, 'score': 0.7942122186495176, 'examples_seen': 28992, 'step': 1050, 'algorithm': 'activity_selector'}
I0813 22:00:17.195911 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.843, current avg val score is 0.794, val scores are: activity_selector: 0.794
I0813 22:00:18.131410 138121668994560 run.py:692] Algo activity_selector step 1100 current loss 1.538501, current_train_items 30400.
I0813 22:00:18.162047 138121668994560 run.py:727] (val) algo activity_selector step 1100: {'selected': 0.8123791102514507, 'score': 0.8123791102514507, 'examples_seen': 30400, 'step': 1100, 'algorithm': 'activity_selector'}
I0813 22:00:18.162209 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.843, current avg val score is 0.812, val scores are: activity_selector: 0.812
I0813 22:00:19.087034 138121668994560 run.py:692] Algo activity_selector step 1150 current loss 2.178740, current_train_items 31776.
I0813 22:00:19.116194 138121668994560 run.py:727] (val) algo activity_selector step 1150: {'selected': 0.7962962962962963, 'score': 0.7962962962962963, 'examples_seen': 31776, 'step': 1150, 'algorithm': 'activity_selector'}
I0813 22:00:19.116344 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.843, current avg val score is 0.796, val scores are: activity_selector: 0.796
I0813 22:00:20.036068 138121668994560 run.py:692] Algo activity_selector step 1200 current loss 1.108994, current_train_items 33120.
I0813 22:00:20.065847 138121668994560 run.py:727] (val) algo activity_selector step 1200: {'selected': 0.8532289628180039, 'score': 0.8532289628180039, 'examples_seen': 33120, 'step': 1200, 'algorithm': 'activity_selector'}
I0813 22:00:20.065991 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.843, current avg val score is 0.853, val scores are: activity_selector: 0.853
I0813 22:00:21.042502 138121668994560 run.py:692] Algo activity_selector step 1250 current loss 1.107430, current_train_items 34528.
I0813 22:00:21.071804 138121668994560 run.py:727] (val) algo activity_selector step 1250: {'selected': 0.8488160291438979, 'score': 0.8488160291438979, 'examples_seen': 34528, 'step': 1250, 'algorithm': 'activity_selector'}
I0813 22:00:21.071962 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.853, current avg val score is 0.849, val scores are: activity_selector: 0.849
I0813 22:00:21.963966 138121668994560 run.py:692] Algo activity_selector step 1300 current loss 1.918745, current_train_items 35904.
I0813 22:00:21.995689 138121668994560 run.py:727] (val) algo activity_selector step 1300: {'selected': 0.8133802816901409, 'score': 0.8133802816901409, 'examples_seen': 35904, 'step': 1300, 'algorithm': 'activity_selector'}
I0813 22:00:21.995852 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.853, current avg val score is 0.813, val scores are: activity_selector: 0.813
I0813 22:00:22.909050 138121668994560 run.py:692] Algo activity_selector step 1350 current loss 1.154509, current_train_items 37248.
I0813 22:00:22.938356 138121668994560 run.py:727] (val) algo activity_selector step 1350: {'selected': 0.8243478260869564, 'score': 0.8243478260869564, 'examples_seen': 37248, 'step': 1350, 'algorithm': 'activity_selector'}
I0813 22:00:22.938502 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.853, current avg val score is 0.824, val scores are: activity_selector: 0.824
I0813 22:00:23.854172 138121668994560 run.py:692] Algo activity_selector step 1400 current loss 0.999328, current_train_items 38656.
I0813 22:00:23.884750 138121668994560 run.py:727] (val) algo activity_selector step 1400: {'selected': 0.8216432865731463, 'score': 0.8216432865731463, 'examples_seen': 38656, 'step': 1400, 'algorithm': 'activity_selector'}
I0813 22:00:23.884893 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.853, current avg val score is 0.822, val scores are: activity_selector: 0.822
I0813 22:00:24.767978 138121668994560 run.py:692] Algo activity_selector step 1450 current loss 1.266672, current_train_items 40032.
I0813 22:00:24.797482 138121668994560 run.py:727] (val) algo activity_selector step 1450: {'selected': 0.8225255972696246, 'score': 0.8225255972696246, 'examples_seen': 40032, 'step': 1450, 'algorithm': 'activity_selector'}
I0813 22:00:24.797634 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.853, current avg val score is 0.823, val scores are: activity_selector: 0.823
I0813 22:00:25.703285 138121668994560 run.py:692] Algo activity_selector step 1500 current loss 1.084153, current_train_items 41408.
I0813 22:00:25.732632 138121668994560 run.py:727] (val) algo activity_selector step 1500: {'selected': 0.8994307400379508, 'score': 0.8994307400379508, 'examples_seen': 41408, 'step': 1500, 'algorithm': 'activity_selector'}
I0813 22:00:25.732795 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.853, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0813 22:00:26.729354 138121668994560 run.py:692] Algo activity_selector step 1550 current loss 1.169366, current_train_items 42784.
I0813 22:00:26.758846 138121668994560 run.py:727] (val) algo activity_selector step 1550: {'selected': 0.8729281767955802, 'score': 0.8729281767955802, 'examples_seen': 42784, 'step': 1550, 'algorithm': 'activity_selector'}
I0813 22:00:26.758989 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.873, val scores are: activity_selector: 0.873
I0813 22:00:27.678822 138121668994560 run.py:692] Algo activity_selector step 1600 current loss 1.100035, current_train_items 44192.
I0813 22:00:27.708513 138121668994560 run.py:727] (val) algo activity_selector step 1600: {'selected': 0.8446069469835465, 'score': 0.8446069469835465, 'examples_seen': 44192, 'step': 1600, 'algorithm': 'activity_selector'}
I0813 22:00:27.708688 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.845, val scores are: activity_selector: 0.845
I0813 22:00:28.610840 138121668994560 run.py:692] Algo activity_selector step 1650 current loss 1.098224, current_train_items 45536.
I0813 22:00:28.639786 138121668994560 run.py:727] (val) algo activity_selector step 1650: {'selected': 0.867704280155642, 'score': 0.867704280155642, 'examples_seen': 45536, 'step': 1650, 'algorithm': 'activity_selector'}
I0813 22:00:28.639929 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.868, val scores are: activity_selector: 0.868
I0813 22:00:29.552916 138121668994560 run.py:692] Algo activity_selector step 1700 current loss 0.980365, current_train_items 46912.
I0813 22:00:29.582624 138121668994560 run.py:727] (val) algo activity_selector step 1700: {'selected': 0.8863636363636364, 'score': 0.8863636363636364, 'examples_seen': 46912, 'step': 1700, 'algorithm': 'activity_selector'}
I0813 22:00:29.582786 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0813 22:00:30.502396 138121668994560 run.py:692] Algo activity_selector step 1750 current loss 1.405773, current_train_items 48320.
I0813 22:00:30.532367 138121668994560 run.py:727] (val) algo activity_selector step 1750: {'selected': 0.8373831775700935, 'score': 0.8373831775700935, 'examples_seen': 48320, 'step': 1750, 'algorithm': 'activity_selector'}
I0813 22:00:30.532519 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.837, val scores are: activity_selector: 0.837
I0813 22:00:31.429713 138121668994560 run.py:692] Algo activity_selector step 1800 current loss 0.950234, current_train_items 49664.
I0813 22:00:31.459247 138121668994560 run.py:727] (val) algo activity_selector step 1800: {'selected': 0.864963503649635, 'score': 0.864963503649635, 'examples_seen': 49664, 'step': 1800, 'algorithm': 'activity_selector'}
I0813 22:00:31.459404 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.865, val scores are: activity_selector: 0.865
I0813 22:00:32.372042 138121668994560 run.py:692] Algo activity_selector step 1850 current loss 1.082970, current_train_items 51072.
I0813 22:00:32.400797 138121668994560 run.py:727] (val) algo activity_selector step 1850: {'selected': 0.8345323741007195, 'score': 0.8345323741007195, 'examples_seen': 51072, 'step': 1850, 'algorithm': 'activity_selector'}
I0813 22:00:32.400946 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.835, val scores are: activity_selector: 0.835
I0813 22:00:33.308710 138121668994560 run.py:692] Algo activity_selector step 1900 current loss 0.997131, current_train_items 52448.
I0813 22:00:33.338327 138121668994560 run.py:727] (val) algo activity_selector step 1900: {'selected': 0.8576449912126538, 'score': 0.8576449912126538, 'examples_seen': 52448, 'step': 1900, 'algorithm': 'activity_selector'}
I0813 22:00:33.338490 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.858, val scores are: activity_selector: 0.858
I0813 22:00:34.250485 138121668994560 run.py:692] Algo activity_selector step 1950 current loss 1.408009, current_train_items 53824.
I0813 22:00:34.280068 138121668994560 run.py:727] (val) algo activity_selector step 1950: {'selected': 0.7867298578199052, 'score': 0.7867298578199052, 'examples_seen': 53824, 'step': 1950, 'algorithm': 'activity_selector'}
I0813 22:00:34.280242 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.787, val scores are: activity_selector: 0.787
I0813 22:00:35.207205 138121668994560 run.py:692] Algo activity_selector step 2000 current loss 1.275144, current_train_items 55200.
I0813 22:00:35.236818 138121668994560 run.py:727] (val) algo activity_selector step 2000: {'selected': 0.8468158347676419, 'score': 0.8468158347676419, 'examples_seen': 55200, 'step': 2000, 'algorithm': 'activity_selector'}
I0813 22:00:35.236983 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.847, val scores are: activity_selector: 0.847
I0813 22:00:36.134375 138121668994560 run.py:692] Algo activity_selector step 2050 current loss 0.739704, current_train_items 56576.
I0813 22:00:36.164017 138121668994560 run.py:727] (val) algo activity_selector step 2050: {'selected': 0.8431001890359168, 'score': 0.8431001890359168, 'examples_seen': 56576, 'step': 2050, 'algorithm': 'activity_selector'}
I0813 22:00:36.164175 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.843, val scores are: activity_selector: 0.843
I0813 22:00:37.080652 138121668994560 run.py:692] Algo activity_selector step 2100 current loss 1.194806, current_train_items 57952.
I0813 22:00:37.109720 138121668994560 run.py:727] (val) algo activity_selector step 2100: {'selected': 0.8642857142857143, 'score': 0.8642857142857143, 'examples_seen': 57952, 'step': 2100, 'algorithm': 'activity_selector'}
I0813 22:00:37.109865 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.864, val scores are: activity_selector: 0.864
I0813 22:00:38.013147 138121668994560 run.py:692] Algo activity_selector step 2150 current loss 1.215379, current_train_items 59328.
I0813 22:00:38.042536 138121668994560 run.py:727] (val) algo activity_selector step 2150: {'selected': 0.8316008316008316, 'score': 0.8316008316008316, 'examples_seen': 59328, 'step': 2150, 'algorithm': 'activity_selector'}
I0813 22:00:38.042684 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.832, val scores are: activity_selector: 0.832
I0813 22:00:38.933633 138121668994560 run.py:692] Algo activity_selector step 2200 current loss 1.062136, current_train_items 60736.
I0813 22:00:38.963235 138121668994560 run.py:727] (val) algo activity_selector step 2200: {'selected': 0.860952380952381, 'score': 0.860952380952381, 'examples_seen': 60736, 'step': 2200, 'algorithm': 'activity_selector'}
I0813 22:00:38.963385 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.861, val scores are: activity_selector: 0.861
I0813 22:00:39.877875 138121668994560 run.py:692] Algo activity_selector step 2250 current loss 0.881806, current_train_items 62080.
I0813 22:00:39.907444 138121668994560 run.py:727] (val) algo activity_selector step 2250: {'selected': 0.816793893129771, 'score': 0.816793893129771, 'examples_seen': 62080, 'step': 2250, 'algorithm': 'activity_selector'}
I0813 22:00:39.907591 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.817, val scores are: activity_selector: 0.817
I0813 22:00:40.808022 138121668994560 run.py:692] Algo activity_selector step 2300 current loss 1.562307, current_train_items 63456.
I0813 22:00:40.837380 138121668994560 run.py:727] (val) algo activity_selector step 2300: {'selected': 0.8843283582089553, 'score': 0.8843283582089553, 'examples_seen': 63456, 'step': 2300, 'algorithm': 'activity_selector'}
I0813 22:00:40.837526 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0813 22:00:41.744140 138121668994560 run.py:692] Algo activity_selector step 2350 current loss 0.816923, current_train_items 64864.
I0813 22:00:41.773367 138121668994560 run.py:727] (val) algo activity_selector step 2350: {'selected': 0.8896551724137932, 'score': 0.8896551724137932, 'examples_seen': 64864, 'step': 2350, 'algorithm': 'activity_selector'}
I0813 22:00:41.773513 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.890, val scores are: activity_selector: 0.890
I0813 22:00:42.672748 138121668994560 run.py:692] Algo activity_selector step 2400 current loss 1.174196, current_train_items 66208.
I0813 22:00:42.702129 138121668994560 run.py:727] (val) algo activity_selector step 2400: {'selected': 0.8456140350877193, 'score': 0.8456140350877193, 'examples_seen': 66208, 'step': 2400, 'algorithm': 'activity_selector'}
I0813 22:00:42.702288 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.846, val scores are: activity_selector: 0.846
I0813 22:00:43.627603 138121668994560 run.py:692] Algo activity_selector step 2450 current loss 1.140426, current_train_items 67616.
I0813 22:00:43.656832 138121668994560 run.py:727] (val) algo activity_selector step 2450: {'selected': 0.8990825688073394, 'score': 0.8990825688073394, 'examples_seen': 67616, 'step': 2450, 'algorithm': 'activity_selector'}
I0813 22:00:43.656977 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0813 22:00:44.555072 138121668994560 run.py:692] Algo activity_selector step 2500 current loss 0.733623, current_train_items 68992.
I0813 22:00:44.584352 138121668994560 run.py:727] (val) algo activity_selector step 2500: {'selected': 0.8792079207920792, 'score': 0.8792079207920792, 'examples_seen': 68992, 'step': 2500, 'algorithm': 'activity_selector'}
I0813 22:00:44.584498 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0813 22:00:45.486699 138121668994560 run.py:692] Algo activity_selector step 2550 current loss 0.881186, current_train_items 70368.
I0813 22:00:45.515780 138121668994560 run.py:727] (val) algo activity_selector step 2550: {'selected': 0.8326848249027237, 'score': 0.8326848249027237, 'examples_seen': 70368, 'step': 2550, 'algorithm': 'activity_selector'}
I0813 22:00:45.515955 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.833, val scores are: activity_selector: 0.833
I0813 22:00:46.455508 138121668994560 run.py:692] Algo activity_selector step 2600 current loss 0.831499, current_train_items 71744.
I0813 22:00:46.485984 138121668994560 run.py:727] (val) algo activity_selector step 2600: {'selected': 0.8931297709923665, 'score': 0.8931297709923665, 'examples_seen': 71744, 'step': 2600, 'algorithm': 'activity_selector'}
I0813 22:00:46.486155 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0813 22:00:47.378034 138121668994560 run.py:692] Algo activity_selector step 2650 current loss 0.801242, current_train_items 73120.
I0813 22:00:47.406939 138121668994560 run.py:727] (val) algo activity_selector step 2650: {'selected': 0.8727272727272728, 'score': 0.8727272727272728, 'examples_seen': 73120, 'step': 2650, 'algorithm': 'activity_selector'}
I0813 22:00:47.407084 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.873, val scores are: activity_selector: 0.873
I0813 22:00:48.316545 138121668994560 run.py:692] Algo activity_selector step 2700 current loss 0.942953, current_train_items 74496.
I0813 22:00:48.346030 138121668994560 run.py:727] (val) algo activity_selector step 2700: {'selected': 0.8772563176895307, 'score': 0.8772563176895307, 'examples_seen': 74496, 'step': 2700, 'algorithm': 'activity_selector'}
I0813 22:00:48.346183 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.877, val scores are: activity_selector: 0.877
I0813 22:00:49.258507 138121668994560 run.py:692] Algo activity_selector step 2750 current loss 0.814453, current_train_items 75872.
I0813 22:00:49.288148 138121668994560 run.py:727] (val) algo activity_selector step 2750: {'selected': 0.8195615514333896, 'score': 0.8195615514333896, 'examples_seen': 75872, 'step': 2750, 'algorithm': 'activity_selector'}
I0813 22:00:49.288308 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.820, val scores are: activity_selector: 0.820
I0813 22:00:50.183358 138121668994560 run.py:692] Algo activity_selector step 2800 current loss 1.040156, current_train_items 77280.
I0813 22:00:50.213264 138121668994560 run.py:727] (val) algo activity_selector step 2800: {'selected': 0.8339483394833949, 'score': 0.8339483394833949, 'examples_seen': 77280, 'step': 2800, 'algorithm': 'activity_selector'}
I0813 22:00:50.213431 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.834, val scores are: activity_selector: 0.834
I0813 22:00:51.146321 138121668994560 run.py:692] Algo activity_selector step 2850 current loss 1.026895, current_train_items 78624.
I0813 22:00:51.176227 138121668994560 run.py:727] (val) algo activity_selector step 2850: {'selected': 0.8932038834951457, 'score': 0.8932038834951457, 'examples_seen': 78624, 'step': 2850, 'algorithm': 'activity_selector'}
I0813 22:00:51.176390 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0813 22:00:52.086297 138121668994560 run.py:692] Algo activity_selector step 2900 current loss 0.936620, current_train_items 80032.
I0813 22:00:52.115764 138121668994560 run.py:727] (val) algo activity_selector step 2900: {'selected': 0.8679245283018868, 'score': 0.8679245283018868, 'examples_seen': 80032, 'step': 2900, 'algorithm': 'activity_selector'}
I0813 22:00:52.115910 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.899, current avg val score is 0.868, val scores are: activity_selector: 0.868
I0813 22:00:53.024519 138121668994560 run.py:692] Algo activity_selector step 2950 current loss 1.041810, current_train_items 81408.
I0813 22:00:53.054280 138121668994560 run.py:727] (val) algo activity_selector step 2950: {'selected': 0.9122807017543859, 'score': 0.9122807017543859, 'examples_seen': 81408, 'step': 2950, 'algorithm': 'activity_selector'}
I0813 22:00:53.054446 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.899, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0813 22:00:54.000927 138121668994560 run.py:692] Algo activity_selector step 3000 current loss 0.908624, current_train_items 82752.
I0813 22:00:54.029833 138121668994560 run.py:727] (val) algo activity_selector step 3000: {'selected': 0.8556149732620321, 'score': 0.8556149732620321, 'examples_seen': 82752, 'step': 3000, 'algorithm': 'activity_selector'}
I0813 22:00:54.029979 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.856, val scores are: activity_selector: 0.856
I0813 22:00:54.953089 138121668994560 run.py:692] Algo activity_selector step 3050 current loss 0.937231, current_train_items 84160.
I0813 22:00:54.982326 138121668994560 run.py:727] (val) algo activity_selector step 3050: {'selected': 0.86652977412731, 'score': 0.86652977412731, 'examples_seen': 84160, 'step': 3050, 'algorithm': 'activity_selector'}
I0813 22:00:54.982477 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0813 22:00:55.873706 138121668994560 run.py:692] Algo activity_selector step 3100 current loss 0.941902, current_train_items 85536.
I0813 22:00:55.902987 138121668994560 run.py:727] (val) algo activity_selector step 3100: {'selected': 0.8489208633093526, 'score': 0.8489208633093526, 'examples_seen': 85536, 'step': 3100, 'algorithm': 'activity_selector'}
I0813 22:00:55.903146 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.849, val scores are: activity_selector: 0.849
I0813 22:00:56.804300 138121668994560 run.py:692] Algo activity_selector step 3150 current loss 0.736143, current_train_items 86880.
I0813 22:00:56.833956 138121668994560 run.py:727] (val) algo activity_selector step 3150: {'selected': 0.8121827411167514, 'score': 0.8121827411167514, 'examples_seen': 86880, 'step': 3150, 'algorithm': 'activity_selector'}
I0813 22:00:56.834115 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.812, val scores are: activity_selector: 0.812
I0813 22:00:57.763138 138121668994560 run.py:692] Algo activity_selector step 3200 current loss 0.636358, current_train_items 88288.
I0813 22:00:57.792582 138121668994560 run.py:727] (val) algo activity_selector step 3200: {'selected': 0.9098196392785571, 'score': 0.9098196392785571, 'examples_seen': 88288, 'step': 3200, 'algorithm': 'activity_selector'}
I0813 22:00:57.792729 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0813 22:00:58.684795 138121668994560 run.py:692] Algo activity_selector step 3250 current loss 1.065273, current_train_items 89696.
I0813 22:00:58.714257 138121668994560 run.py:727] (val) algo activity_selector step 3250: {'selected': 0.8780487804878048, 'score': 0.8780487804878048, 'examples_seen': 89696, 'step': 3250, 'algorithm': 'activity_selector'}
I0813 22:00:58.714400 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.878, val scores are: activity_selector: 0.878
I0813 22:00:59.635479 138121668994560 run.py:692] Algo activity_selector step 3300 current loss 0.778227, current_train_items 91040.
I0813 22:00:59.664819 138121668994560 run.py:727] (val) algo activity_selector step 3300: {'selected': 0.88, 'score': 0.88, 'examples_seen': 91040, 'step': 3300, 'algorithm': 'activity_selector'}
I0813 22:00:59.664963 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0813 22:01:00.572423 138121668994560 run.py:692] Algo activity_selector step 3350 current loss 0.832235, current_train_items 92416.
I0813 22:01:00.601752 138121668994560 run.py:727] (val) algo activity_selector step 3350: {'selected': 0.858195211786372, 'score': 0.858195211786372, 'examples_seen': 92416, 'step': 3350, 'algorithm': 'activity_selector'}
I0813 22:01:00.601901 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.858, val scores are: activity_selector: 0.858
I0813 22:01:01.505726 138121668994560 run.py:692] Algo activity_selector step 3400 current loss 0.898936, current_train_items 93824.
I0813 22:01:01.535126 138121668994560 run.py:727] (val) algo activity_selector step 3400: {'selected': 0.8964285714285715, 'score': 0.8964285714285715, 'examples_seen': 93824, 'step': 3400, 'algorithm': 'activity_selector'}
I0813 22:01:01.535306 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0813 22:01:02.440925 138121668994560 run.py:692] Algo activity_selector step 3450 current loss 0.738343, current_train_items 95168.
I0813 22:01:02.470249 138121668994560 run.py:727] (val) algo activity_selector step 3450: {'selected': 0.8989690721649485, 'score': 0.8989690721649485, 'examples_seen': 95168, 'step': 3450, 'algorithm': 'activity_selector'}
I0813 22:01:02.470397 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0813 22:01:03.366768 138121668994560 run.py:692] Algo activity_selector step 3500 current loss 0.906590, current_train_items 96544.
I0813 22:01:03.395951 138121668994560 run.py:727] (val) algo activity_selector step 3500: {'selected': 0.9090909090909091, 'score': 0.9090909090909091, 'examples_seen': 96544, 'step': 3500, 'algorithm': 'activity_selector'}
I0813 22:01:03.396147 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0813 22:01:04.308451 138121668994560 run.py:692] Algo activity_selector step 3550 current loss 0.874618, current_train_items 97952.
I0813 22:01:04.337761 138121668994560 run.py:727] (val) algo activity_selector step 3550: {'selected': 0.8848263254113347, 'score': 0.8848263254113347, 'examples_seen': 97952, 'step': 3550, 'algorithm': 'activity_selector'}
I0813 22:01:04.337921 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0813 22:01:05.248079 138121668994560 run.py:692] Algo activity_selector step 3600 current loss 0.983067, current_train_items 99328.
I0813 22:01:05.277698 138121668994560 run.py:727] (val) algo activity_selector step 3600: {'selected': 0.867383512544803, 'score': 0.867383512544803, 'examples_seen': 99328, 'step': 3600, 'algorithm': 'activity_selector'}
I0813 22:01:05.277861 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0813 22:01:06.181225 138121668994560 run.py:692] Algo activity_selector step 3650 current loss 0.730270, current_train_items 100704.
I0813 22:01:06.210548 138121668994560 run.py:727] (val) algo activity_selector step 3650: {'selected': 0.8939929328621907, 'score': 0.8939929328621907, 'examples_seen': 100704, 'step': 3650, 'algorithm': 'activity_selector'}
I0813 22:01:06.210747 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0813 22:01:07.122403 138121668994560 run.py:692] Algo activity_selector step 3700 current loss 0.604000, current_train_items 102080.
I0813 22:01:07.151480 138121668994560 run.py:727] (val) algo activity_selector step 3700: {'selected': 0.8851224105461393, 'score': 0.8851224105461393, 'examples_seen': 102080, 'step': 3700, 'algorithm': 'activity_selector'}
I0813 22:01:07.151644 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0813 22:01:08.070950 138121668994560 run.py:692] Algo activity_selector step 3750 current loss 0.919694, current_train_items 103456.
I0813 22:01:08.100227 138121668994560 run.py:727] (val) algo activity_selector step 3750: {'selected': 0.8648648648648648, 'score': 0.8648648648648648, 'examples_seen': 103456, 'step': 3750, 'algorithm': 'activity_selector'}
I0813 22:01:08.100373 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.865, val scores are: activity_selector: 0.865
I0813 22:01:09.013806 138121668994560 run.py:692] Algo activity_selector step 3800 current loss 0.751444, current_train_items 104832.
I0813 22:01:09.043376 138121668994560 run.py:727] (val) algo activity_selector step 3800: {'selected': 0.8888888888888888, 'score': 0.8888888888888888, 'examples_seen': 104832, 'step': 3800, 'algorithm': 'activity_selector'}
I0813 22:01:09.043523 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.889, val scores are: activity_selector: 0.889
I0813 22:01:09.932687 138121668994560 run.py:692] Algo activity_selector step 3850 current loss 0.910597, current_train_items 106208.
I0813 22:01:09.962225 138121668994560 run.py:727] (val) algo activity_selector step 3850: {'selected': 0.8247422680412372, 'score': 0.8247422680412372, 'examples_seen': 106208, 'step': 3850, 'algorithm': 'activity_selector'}
I0813 22:01:09.962387 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.825, val scores are: activity_selector: 0.825
I0813 22:01:10.892467 138121668994560 run.py:692] Algo activity_selector step 3900 current loss 0.844412, current_train_items 107584.
I0813 22:01:10.921448 138121668994560 run.py:727] (val) algo activity_selector step 3900: {'selected': 0.858195211786372, 'score': 0.858195211786372, 'examples_seen': 107584, 'step': 3900, 'algorithm': 'activity_selector'}
I0813 22:01:10.921593 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.858, val scores are: activity_selector: 0.858
I0813 22:01:11.841217 138121668994560 run.py:692] Algo activity_selector step 3950 current loss 0.583404, current_train_items 108992.
I0813 22:01:11.870336 138121668994560 run.py:727] (val) algo activity_selector step 3950: {'selected': 0.8805460750853242, 'score': 0.8805460750853242, 'examples_seen': 108992, 'step': 3950, 'algorithm': 'activity_selector'}
I0813 22:01:11.870527 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.881, val scores are: activity_selector: 0.881
I0813 22:01:12.761012 138121668994560 run.py:692] Algo activity_selector step 4000 current loss 0.950629, current_train_items 110336.
I0813 22:01:12.792347 138121668994560 run.py:727] (val) algo activity_selector step 4000: {'selected': 0.8721174004192872, 'score': 0.8721174004192872, 'examples_seen': 110336, 'step': 4000, 'algorithm': 'activity_selector'}
I0813 22:01:12.792496 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.872, val scores are: activity_selector: 0.872
I0813 22:01:13.739892 138121668994560 run.py:692] Algo activity_selector step 4050 current loss 0.852563, current_train_items 111712.
I0813 22:01:13.769148 138121668994560 run.py:727] (val) algo activity_selector step 4050: {'selected': 0.8758865248226949, 'score': 0.8758865248226949, 'examples_seen': 111712, 'step': 4050, 'algorithm': 'activity_selector'}
I0813 22:01:13.769297 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.876, val scores are: activity_selector: 0.876
I0813 22:01:14.685849 138121668994560 run.py:692] Algo activity_selector step 4100 current loss 0.655308, current_train_items 113120.
I0813 22:01:14.716352 138121668994560 run.py:727] (val) algo activity_selector step 4100: {'selected': 0.9077490774907748, 'score': 0.9077490774907748, 'examples_seen': 113120, 'step': 4100, 'algorithm': 'activity_selector'}
I0813 22:01:14.716496 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0813 22:01:15.608596 138121668994560 run.py:692] Algo activity_selector step 4150 current loss 0.896464, current_train_items 114496.
I0813 22:01:15.638159 138121668994560 run.py:727] (val) algo activity_selector step 4150: {'selected': 0.9027522935779817, 'score': 0.9027522935779817, 'examples_seen': 114496, 'step': 4150, 'algorithm': 'activity_selector'}
I0813 22:01:15.638309 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.903, val scores are: activity_selector: 0.903
I0813 22:01:16.535152 138121668994560 run.py:692] Algo activity_selector step 4200 current loss 1.151271, current_train_items 115840.
I0813 22:01:16.564745 138121668994560 run.py:727] (val) algo activity_selector step 4200: {'selected': 0.8884688090737239, 'score': 0.8884688090737239, 'examples_seen': 115840, 'step': 4200, 'algorithm': 'activity_selector'}
I0813 22:01:16.564896 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.888, val scores are: activity_selector: 0.888
I0813 22:01:17.491966 138121668994560 run.py:692] Algo activity_selector step 4250 current loss 0.563035, current_train_items 117248.
I0813 22:01:17.521065 138121668994560 run.py:727] (val) algo activity_selector step 4250: {'selected': 0.9077212806026366, 'score': 0.9077212806026366, 'examples_seen': 117248, 'step': 4250, 'algorithm': 'activity_selector'}
I0813 22:01:17.521223 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0813 22:01:18.417620 138121668994560 run.py:692] Algo activity_selector step 4300 current loss 1.075651, current_train_items 118656.
I0813 22:01:18.446856 138121668994560 run.py:727] (val) algo activity_selector step 4300: {'selected': 0.8966789667896679, 'score': 0.8966789667896679, 'examples_seen': 118656, 'step': 4300, 'algorithm': 'activity_selector'}
I0813 22:01:18.447005 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0813 22:01:19.336945 138121668994560 run.py:692] Algo activity_selector step 4350 current loss 0.457525, current_train_items 119968.
I0813 22:01:19.365896 138121668994560 run.py:727] (val) algo activity_selector step 4350: {'selected': 0.9070208728652751, 'score': 0.9070208728652751, 'examples_seen': 119968, 'step': 4350, 'algorithm': 'activity_selector'}
I0813 22:01:19.366042 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0813 22:01:20.287586 138121668994560 run.py:692] Algo activity_selector step 4400 current loss 0.977238, current_train_items 121376.
I0813 22:01:20.316931 138121668994560 run.py:727] (val) algo activity_selector step 4400: {'selected': 0.8927203065134101, 'score': 0.8927203065134101, 'examples_seen': 121376, 'step': 4400, 'algorithm': 'activity_selector'}
I0813 22:01:20.317082 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0813 22:01:21.217396 138121668994560 run.py:692] Algo activity_selector step 4450 current loss 1.096562, current_train_items 122784.
I0813 22:01:21.246752 138121668994560 run.py:727] (val) algo activity_selector step 4450: {'selected': 0.8411552346570397, 'score': 0.8411552346570397, 'examples_seen': 122784, 'step': 4450, 'algorithm': 'activity_selector'}
I0813 22:01:21.246896 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.841, val scores are: activity_selector: 0.841
I0813 22:01:22.129949 138121668994560 run.py:692] Algo activity_selector step 4500 current loss 0.988278, current_train_items 124128.
I0813 22:01:22.159258 138121668994560 run.py:727] (val) algo activity_selector step 4500: {'selected': 0.8988764044943819, 'score': 0.8988764044943819, 'examples_seen': 124128, 'step': 4500, 'algorithm': 'activity_selector'}
I0813 22:01:22.159402 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0813 22:01:23.075167 138121668994560 run.py:692] Algo activity_selector step 4550 current loss 0.571892, current_train_items 125504.
I0813 22:01:23.104483 138121668994560 run.py:727] (val) algo activity_selector step 4550: {'selected': 0.8480300187617261, 'score': 0.8480300187617261, 'examples_seen': 125504, 'step': 4550, 'algorithm': 'activity_selector'}
I0813 22:01:23.104629 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.848, val scores are: activity_selector: 0.848
I0813 22:01:24.007352 138121668994560 run.py:692] Algo activity_selector step 4600 current loss 0.965306, current_train_items 126912.
I0813 22:01:24.036637 138121668994560 run.py:727] (val) algo activity_selector step 4600: {'selected': 0.8542024013722127, 'score': 0.8542024013722127, 'examples_seen': 126912, 'step': 4600, 'algorithm': 'activity_selector'}
I0813 22:01:24.036782 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.854, val scores are: activity_selector: 0.854
I0813 22:01:24.946284 138121668994560 run.py:692] Algo activity_selector step 4650 current loss 0.702683, current_train_items 128288.
I0813 22:01:24.975548 138121668994560 run.py:727] (val) algo activity_selector step 4650: {'selected': 0.9148148148148149, 'score': 0.9148148148148149, 'examples_seen': 128288, 'step': 4650, 'algorithm': 'activity_selector'}
I0813 22:01:24.975701 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.912, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0813 22:01:25.919317 138121668994560 run.py:692] Algo activity_selector step 4700 current loss 0.649078, current_train_items 129632.
I0813 22:01:25.948429 138121668994560 run.py:727] (val) algo activity_selector step 4700: {'selected': 0.8778761061946903, 'score': 0.8778761061946903, 'examples_seen': 129632, 'step': 4700, 'algorithm': 'activity_selector'}
I0813 22:01:25.948581 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.915, current avg val score is 0.878, val scores are: activity_selector: 0.878
I0813 22:01:26.866968 138121668994560 run.py:692] Algo activity_selector step 4750 current loss 1.006958, current_train_items 131040.
I0813 22:01:26.896328 138121668994560 run.py:727] (val) algo activity_selector step 4750: {'selected': 0.8641509433962264, 'score': 0.8641509433962264, 'examples_seen': 131040, 'step': 4750, 'algorithm': 'activity_selector'}
I0813 22:01:26.896506 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.915, current avg val score is 0.864, val scores are: activity_selector: 0.864
I0813 22:01:27.821337 138121668994560 run.py:692] Algo activity_selector step 4800 current loss 0.751281, current_train_items 132416.
I0813 22:01:27.850623 138121668994560 run.py:727] (val) algo activity_selector step 4800: {'selected': 0.8978805394990366, 'score': 0.8978805394990366, 'examples_seen': 132416, 'step': 4800, 'algorithm': 'activity_selector'}
I0813 22:01:27.850769 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.915, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0813 22:01:28.737076 138121668994560 run.py:692] Algo activity_selector step 4850 current loss 0.817076, current_train_items 133760.
I0813 22:01:28.766343 138121668994560 run.py:727] (val) algo activity_selector step 4850: {'selected': 0.9264214046822743, 'score': 0.9264214046822743, 'examples_seen': 133760, 'step': 4850, 'algorithm': 'activity_selector'}
I0813 22:01:28.766504 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.915, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0813 22:01:29.735961 138121668994560 run.py:692] Algo activity_selector step 4900 current loss 0.390413, current_train_items 135168.
I0813 22:01:29.765749 138121668994560 run.py:727] (val) algo activity_selector step 4900: {'selected': 0.9197860962566845, 'score': 0.9197860962566845, 'examples_seen': 135168, 'step': 4900, 'algorithm': 'activity_selector'}
I0813 22:01:29.765911 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.926, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0813 22:01:30.685701 138121668994560 run.py:692] Algo activity_selector step 4950 current loss 0.753132, current_train_items 136544.
I0813 22:01:30.714649 138121668994560 run.py:727] (val) algo activity_selector step 4950: {'selected': 0.8329809725158562, 'score': 0.8329809725158562, 'examples_seen': 136544, 'step': 4950, 'algorithm': 'activity_selector'}
I0813 22:01:30.714793 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.926, current avg val score is 0.833, val scores are: activity_selector: 0.833
I0813 22:01:31.631507 138121668994560 run.py:692] Algo activity_selector step 5000 current loss 0.461145, current_train_items 137952.
I0813 22:01:31.660540 138121668994560 run.py:727] (val) algo activity_selector step 5000: {'selected': 0.8825622775800712, 'score': 0.8825622775800712, 'examples_seen': 137952, 'step': 5000, 'algorithm': 'activity_selector'}
I0813 22:01:31.660687 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.926, current avg val score is 0.883, val scores are: activity_selector: 0.883
I0813 22:01:32.548740 138121668994560 run.py:692] Algo activity_selector step 5050 current loss 0.606857, current_train_items 139296.
I0813 22:01:32.578073 138121668994560 run.py:727] (val) algo activity_selector step 5050: {'selected': 0.8893360160965795, 'score': 0.8893360160965795, 'examples_seen': 139296, 'step': 5050, 'algorithm': 'activity_selector'}
I0813 22:01:32.578230 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.926, current avg val score is 0.889, val scores are: activity_selector: 0.889
I0813 22:01:33.500356 138121668994560 run.py:692] Algo activity_selector step 5100 current loss 0.696648, current_train_items 140672.
I0813 22:01:33.529601 138121668994560 run.py:727] (val) algo activity_selector step 5100: {'selected': 0.8842504743833018, 'score': 0.8842504743833018, 'examples_seen': 140672, 'step': 5100, 'algorithm': 'activity_selector'}
I0813 22:01:33.529751 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.926, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0813 22:01:34.457609 138121668994560 run.py:692] Algo activity_selector step 5150 current loss 0.651235, current_train_items 142080.
I0813 22:01:34.487056 138121668994560 run.py:727] (val) algo activity_selector step 5150: {'selected': 0.88468809073724, 'score': 0.88468809073724, 'examples_seen': 142080, 'step': 5150, 'algorithm': 'activity_selector'}
I0813 22:01:34.487213 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.926, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0813 22:01:35.358235 138121668994560 run.py:692] Algo activity_selector step 5200 current loss 0.544753, current_train_items 143424.
I0813 22:01:35.387187 138121668994560 run.py:727] (val) algo activity_selector step 5200: {'selected': 0.9299610894941635, 'score': 0.9299610894941635, 'examples_seen': 143424, 'step': 5200, 'algorithm': 'activity_selector'}
I0813 22:01:35.387332 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.926, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0813 22:01:36.347676 138121668994560 run.py:692] Algo activity_selector step 5250 current loss 0.554392, current_train_items 144800.
I0813 22:01:36.377263 138121668994560 run.py:727] (val) algo activity_selector step 5250: {'selected': 0.8700173310225303, 'score': 0.8700173310225303, 'examples_seen': 144800, 'step': 5250, 'algorithm': 'activity_selector'}
I0813 22:01:36.377429 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.870, val scores are: activity_selector: 0.870
I0813 22:01:37.299127 138121668994560 run.py:692] Algo activity_selector step 5300 current loss 1.016940, current_train_items 146208.
I0813 22:01:37.327902 138121668994560 run.py:727] (val) algo activity_selector step 5300: {'selected': 0.8912280701754387, 'score': 0.8912280701754387, 'examples_seen': 146208, 'step': 5300, 'algorithm': 'activity_selector'}
I0813 22:01:37.328047 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0813 22:01:38.203146 138121668994560 run.py:692] Algo activity_selector step 5350 current loss 0.667519, current_train_items 147616.
I0813 22:01:38.232168 138121668994560 run.py:727] (val) algo activity_selector step 5350: {'selected': 0.8440677966101695, 'score': 0.8440677966101695, 'examples_seen': 147616, 'step': 5350, 'algorithm': 'activity_selector'}
I0813 22:01:38.232315 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.844, val scores are: activity_selector: 0.844
I0813 22:01:39.146910 138121668994560 run.py:692] Algo activity_selector step 5400 current loss 0.766273, current_train_items 148928.
I0813 22:01:39.175983 138121668994560 run.py:727] (val) algo activity_selector step 5400: {'selected': 0.8831168831168832, 'score': 0.8831168831168832, 'examples_seen': 148928, 'step': 5400, 'algorithm': 'activity_selector'}
I0813 22:01:39.176156 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.883, val scores are: activity_selector: 0.883
I0813 22:01:40.096665 138121668994560 run.py:692] Algo activity_selector step 5450 current loss 0.468160, current_train_items 150336.
I0813 22:01:40.125761 138121668994560 run.py:727] (val) algo activity_selector step 5450: {'selected': 0.9118198874296435, 'score': 0.9118198874296435, 'examples_seen': 150336, 'step': 5450, 'algorithm': 'activity_selector'}
I0813 22:01:40.125924 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0813 22:01:41.037008 138121668994560 run.py:692] Algo activity_selector step 5500 current loss 0.588739, current_train_items 151744.
I0813 22:01:41.066168 138121668994560 run.py:727] (val) algo activity_selector step 5500: {'selected': 0.8984375, 'score': 0.8984375, 'examples_seen': 151744, 'step': 5500, 'algorithm': 'activity_selector'}
I0813 22:01:41.066329 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0813 22:01:41.947936 138121668994560 run.py:692] Algo activity_selector step 5550 current loss 0.762556, current_train_items 153056.
I0813 22:01:41.977093 138121668994560 run.py:727] (val) algo activity_selector step 5550: {'selected': 0.9029982363315696, 'score': 0.9029982363315696, 'examples_seen': 153056, 'step': 5550, 'algorithm': 'activity_selector'}
I0813 22:01:41.977251 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.903, val scores are: activity_selector: 0.903
I0813 22:01:42.901623 138121668994560 run.py:692] Algo activity_selector step 5600 current loss 0.629708, current_train_items 154464.
I0813 22:01:42.930870 138121668994560 run.py:727] (val) algo activity_selector step 5600: {'selected': 0.8812877263581489, 'score': 0.8812877263581489, 'examples_seen': 154464, 'step': 5600, 'algorithm': 'activity_selector'}
I0813 22:01:42.931045 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.881, val scores are: activity_selector: 0.881
I0813 22:01:43.844099 138121668994560 run.py:692] Algo activity_selector step 5650 current loss 0.726591, current_train_items 155872.
I0813 22:01:43.873553 138121668994560 run.py:727] (val) algo activity_selector step 5650: {'selected': 0.9003436426116839, 'score': 0.9003436426116839, 'examples_seen': 155872, 'step': 5650, 'algorithm': 'activity_selector'}
I0813 22:01:43.873701 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.900, val scores are: activity_selector: 0.900
I0813 22:01:44.761730 138121668994560 run.py:692] Algo activity_selector step 5700 current loss 0.693108, current_train_items 157216.
I0813 22:01:44.790914 138121668994560 run.py:727] (val) algo activity_selector step 5700: {'selected': 0.8682170542635658, 'score': 0.8682170542635658, 'examples_seen': 157216, 'step': 5700, 'algorithm': 'activity_selector'}
I0813 22:01:44.791060 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.868, val scores are: activity_selector: 0.868
I0813 22:01:45.732303 138121668994560 run.py:692] Algo activity_selector step 5750 current loss 0.898196, current_train_items 158592.
I0813 22:01:45.761420 138121668994560 run.py:727] (val) algo activity_selector step 5750: {'selected': 0.8919449901768173, 'score': 0.8919449901768173, 'examples_seen': 158592, 'step': 5750, 'algorithm': 'activity_selector'}
I0813 22:01:45.761569 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.892, val scores are: activity_selector: 0.892
I0813 22:01:46.662266 138121668994560 run.py:692] Algo activity_selector step 5800 current loss 0.741274, current_train_items 160000.
I0813 22:01:46.692730 138121668994560 run.py:727] (val) algo activity_selector step 5800: {'selected': 0.8979591836734694, 'score': 0.8979591836734694, 'examples_seen': 160000, 'step': 5800, 'algorithm': 'activity_selector'}
I0813 22:01:46.692889 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0813 22:01:47.617357 138121668994560 run.py:692] Algo activity_selector step 5850 current loss 1.048073, current_train_items 161376.
I0813 22:01:47.646235 138121668994560 run.py:727] (val) algo activity_selector step 5850: {'selected': 0.8902439024390244, 'score': 0.8902439024390244, 'examples_seen': 161376, 'step': 5850, 'algorithm': 'activity_selector'}
I0813 22:01:47.646398 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.890, val scores are: activity_selector: 0.890
I0813 22:01:48.543379 138121668994560 run.py:692] Algo activity_selector step 5900 current loss 0.735333, current_train_items 162720.
I0813 22:01:48.572869 138121668994560 run.py:727] (val) algo activity_selector step 5900: {'selected': 0.875239923224568, 'score': 0.875239923224568, 'examples_seen': 162720, 'step': 5900, 'algorithm': 'activity_selector'}
I0813 22:01:48.573016 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.875, val scores are: activity_selector: 0.875
I0813 22:01:49.478629 138121668994560 run.py:692] Algo activity_selector step 5950 current loss 0.795622, current_train_items 164128.
I0813 22:01:49.507619 138121668994560 run.py:727] (val) algo activity_selector step 5950: {'selected': 0.8932806324110673, 'score': 0.8932806324110673, 'examples_seen': 164128, 'step': 5950, 'algorithm': 'activity_selector'}
I0813 22:01:49.507766 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0813 22:01:50.427561 138121668994560 run.py:692] Algo activity_selector step 6000 current loss 0.691321, current_train_items 165504.
I0813 22:01:50.457127 138121668994560 run.py:727] (val) algo activity_selector step 6000: {'selected': 0.9230769230769232, 'score': 0.9230769230769232, 'examples_seen': 165504, 'step': 6000, 'algorithm': 'activity_selector'}
I0813 22:01:50.457288 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.923, val scores are: activity_selector: 0.923
I0813 22:01:51.351986 138121668994560 run.py:692] Algo activity_selector step 6050 current loss 0.840737, current_train_items 166880.
I0813 22:01:51.381757 138121668994560 run.py:727] (val) algo activity_selector step 6050: {'selected': 0.8185053380782918, 'score': 0.8185053380782918, 'examples_seen': 166880, 'step': 6050, 'algorithm': 'activity_selector'}
I0813 22:01:51.381920 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.819, val scores are: activity_selector: 0.819
I0813 22:01:52.290673 138121668994560 run.py:692] Algo activity_selector step 6100 current loss 1.080361, current_train_items 168256.
I0813 22:01:52.319766 138121668994560 run.py:727] (val) algo activity_selector step 6100: {'selected': 0.883629191321499, 'score': 0.883629191321499, 'examples_seen': 168256, 'step': 6100, 'algorithm': 'activity_selector'}
I0813 22:01:52.319929 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0813 22:01:53.239776 138121668994560 run.py:692] Algo activity_selector step 6150 current loss 0.699095, current_train_items 169632.
I0813 22:01:53.269144 138121668994560 run.py:727] (val) algo activity_selector step 6150: {'selected': 0.8729508196721312, 'score': 0.8729508196721312, 'examples_seen': 169632, 'step': 6150, 'algorithm': 'activity_selector'}
I0813 22:01:53.269292 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.873, val scores are: activity_selector: 0.873
I0813 22:01:54.167038 138121668994560 run.py:692] Algo activity_selector step 6200 current loss 1.310121, current_train_items 171040.
I0813 22:01:54.196048 138121668994560 run.py:727] (val) algo activity_selector step 6200: {'selected': 0.8269230769230769, 'score': 0.8269230769230769, 'examples_seen': 171040, 'step': 6200, 'algorithm': 'activity_selector'}
I0813 22:01:54.196204 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.827, val scores are: activity_selector: 0.827
I0813 22:01:55.082780 138121668994560 run.py:692] Algo activity_selector step 6250 current loss 0.741396, current_train_items 172384.
I0813 22:01:55.111927 138121668994560 run.py:727] (val) algo activity_selector step 6250: {'selected': 0.8807692307692307, 'score': 0.8807692307692307, 'examples_seen': 172384, 'step': 6250, 'algorithm': 'activity_selector'}
I0813 22:01:55.112072 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.881, val scores are: activity_selector: 0.881
I0813 22:01:56.020943 138121668994560 run.py:692] Algo activity_selector step 6300 current loss 0.604433, current_train_items 173760.
I0813 22:01:56.050376 138121668994560 run.py:727] (val) algo activity_selector step 6300: {'selected': 0.8880733944954129, 'score': 0.8880733944954129, 'examples_seen': 173760, 'step': 6300, 'algorithm': 'activity_selector'}
I0813 22:01:56.050538 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.888, val scores are: activity_selector: 0.888
I0813 22:01:56.977148 138121668994560 run.py:692] Algo activity_selector step 6350 current loss 0.765549, current_train_items 175168.
I0813 22:01:57.006501 138121668994560 run.py:727] (val) algo activity_selector step 6350: {'selected': 0.874296435272045, 'score': 0.874296435272045, 'examples_seen': 175168, 'step': 6350, 'algorithm': 'activity_selector'}
I0813 22:01:57.006648 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.874, val scores are: activity_selector: 0.874
I0813 22:01:57.885294 138121668994560 run.py:692] Algo activity_selector step 6400 current loss 1.099892, current_train_items 176544.
I0813 22:01:57.913981 138121668994560 run.py:727] (val) algo activity_selector step 6400: {'selected': 0.8852459016393442, 'score': 0.8852459016393442, 'examples_seen': 176544, 'step': 6400, 'algorithm': 'activity_selector'}
I0813 22:01:57.914137 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0813 22:01:58.840267 138121668994560 run.py:692] Algo activity_selector step 6450 current loss 0.618475, current_train_items 177888.
I0813 22:01:58.869485 138121668994560 run.py:727] (val) algo activity_selector step 6450: {'selected': 0.8483816013628619, 'score': 0.8483816013628619, 'examples_seen': 177888, 'step': 6450, 'algorithm': 'activity_selector'}
I0813 22:01:58.869633 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.848, val scores are: activity_selector: 0.848
I0813 22:01:59.796154 138121668994560 run.py:692] Algo activity_selector step 6500 current loss 0.443417, current_train_items 179296.
I0813 22:01:59.825084 138121668994560 run.py:727] (val) algo activity_selector step 6500: {'selected': 0.8806722689075631, 'score': 0.8806722689075631, 'examples_seen': 179296, 'step': 6500, 'algorithm': 'activity_selector'}
I0813 22:01:59.825239 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.881, val scores are: activity_selector: 0.881
I0813 22:02:00.711672 138121668994560 run.py:692] Algo activity_selector step 6550 current loss 0.587340, current_train_items 180672.
I0813 22:02:00.741458 138121668994560 run.py:727] (val) algo activity_selector step 6550: {'selected': 0.8856088560885608, 'score': 0.8856088560885608, 'examples_seen': 180672, 'step': 6550, 'algorithm': 'activity_selector'}
I0813 22:02:00.741605 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0813 22:02:01.649686 138121668994560 run.py:692] Algo activity_selector step 6600 current loss 0.802306, current_train_items 182016.
I0813 22:02:01.679027 138121668994560 run.py:727] (val) algo activity_selector step 6600: {'selected': 0.8618181818181818, 'score': 0.8618181818181818, 'examples_seen': 182016, 'step': 6600, 'algorithm': 'activity_selector'}
I0813 22:02:01.679182 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.862, val scores are: activity_selector: 0.862
I0813 22:02:02.603914 138121668994560 run.py:692] Algo activity_selector step 6650 current loss 0.727221, current_train_items 183424.
I0813 22:02:02.633439 138121668994560 run.py:727] (val) algo activity_selector step 6650: {'selected': 0.87109375, 'score': 0.87109375, 'examples_seen': 183424, 'step': 6650, 'algorithm': 'activity_selector'}
I0813 22:02:02.633584 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.871, val scores are: activity_selector: 0.871
I0813 22:02:03.550504 138121668994560 run.py:692] Algo activity_selector step 6700 current loss 0.452403, current_train_items 184832.
I0813 22:02:03.579845 138121668994560 run.py:727] (val) algo activity_selector step 6700: {'selected': 0.9080675422138836, 'score': 0.9080675422138836, 'examples_seen': 184832, 'step': 6700, 'algorithm': 'activity_selector'}
I0813 22:02:03.579990 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0813 22:02:04.464598 138121668994560 run.py:692] Algo activity_selector step 6750 current loss 0.756080, current_train_items 186176.
I0813 22:02:04.493608 138121668994560 run.py:727] (val) algo activity_selector step 6750: {'selected': 0.8976377952755905, 'score': 0.8976377952755905, 'examples_seen': 186176, 'step': 6750, 'algorithm': 'activity_selector'}
I0813 22:02:04.493770 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0813 22:02:05.410574 138121668994560 run.py:692] Algo activity_selector step 6800 current loss 0.602809, current_train_items 187552.
I0813 22:02:05.439339 138121668994560 run.py:727] (val) algo activity_selector step 6800: {'selected': 0.9060773480662982, 'score': 0.9060773480662982, 'examples_seen': 187552, 'step': 6800, 'algorithm': 'activity_selector'}
I0813 22:02:05.439489 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0813 22:02:06.355393 138121668994560 run.py:692] Algo activity_selector step 6850 current loss 0.910077, current_train_items 188960.
I0813 22:02:06.384365 138121668994560 run.py:727] (val) algo activity_selector step 6850: {'selected': 0.8625429553264604, 'score': 0.8625429553264604, 'examples_seen': 188960, 'step': 6850, 'algorithm': 'activity_selector'}
I0813 22:02:06.384515 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.863, val scores are: activity_selector: 0.863
I0813 22:02:07.283008 138121668994560 run.py:692] Algo activity_selector step 6900 current loss 0.897076, current_train_items 190304.
I0813 22:02:07.312215 138121668994560 run.py:727] (val) algo activity_selector step 6900: {'selected': 0.8957528957528959, 'score': 0.8957528957528959, 'examples_seen': 190304, 'step': 6900, 'algorithm': 'activity_selector'}
I0813 22:02:07.312363 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0813 22:02:08.227081 138121668994560 run.py:692] Algo activity_selector step 6950 current loss 0.598519, current_train_items 191680.
I0813 22:02:08.256158 138121668994560 run.py:727] (val) algo activity_selector step 6950: {'selected': 0.8477064220183486, 'score': 0.8477064220183486, 'examples_seen': 191680, 'step': 6950, 'algorithm': 'activity_selector'}
I0813 22:02:08.256303 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.848, val scores are: activity_selector: 0.848
I0813 22:02:09.153717 138121668994560 run.py:692] Algo activity_selector step 7000 current loss 0.636941, current_train_items 193088.
I0813 22:02:09.183062 138121668994560 run.py:727] (val) algo activity_selector step 7000: {'selected': 0.9023437500000001, 'score': 0.9023437500000001, 'examples_seen': 193088, 'step': 7000, 'algorithm': 'activity_selector'}
I0813 22:02:09.183216 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0813 22:02:10.076426 138121668994560 run.py:692] Algo activity_selector step 7050 current loss 0.920857, current_train_items 194464.
I0813 22:02:10.105090 138121668994560 run.py:727] (val) algo activity_selector step 7050: {'selected': 0.8672897196261682, 'score': 0.8672897196261682, 'examples_seen': 194464, 'step': 7050, 'algorithm': 'activity_selector'}
I0813 22:02:10.105244 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0813 22:02:11.002743 138121668994560 run.py:692] Algo activity_selector step 7100 current loss 0.424219, current_train_items 195840.
I0813 22:02:11.032060 138121668994560 run.py:727] (val) algo activity_selector step 7100: {'selected': 0.9071038251366119, 'score': 0.9071038251366119, 'examples_seen': 195840, 'step': 7100, 'algorithm': 'activity_selector'}
I0813 22:02:11.032214 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0813 22:02:11.928694 138121668994560 run.py:692] Algo activity_selector step 7150 current loss 0.869905, current_train_items 197216.
I0813 22:02:11.958205 138121668994560 run.py:727] (val) algo activity_selector step 7150: {'selected': 0.845878136200717, 'score': 0.845878136200717, 'examples_seen': 197216, 'step': 7150, 'algorithm': 'activity_selector'}
I0813 22:02:11.958351 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.846, val scores are: activity_selector: 0.846
I0813 22:02:12.871572 138121668994560 run.py:692] Algo activity_selector step 7200 current loss 0.739923, current_train_items 198592.
I0813 22:02:12.900830 138121668994560 run.py:727] (val) algo activity_selector step 7200: {'selected': 0.8690702087286527, 'score': 0.8690702087286527, 'examples_seen': 198592, 'step': 7200, 'algorithm': 'activity_selector'}
I0813 22:02:12.900974 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.869, val scores are: activity_selector: 0.869
I0813 22:02:13.790832 138121668994560 run.py:692] Algo activity_selector step 7250 current loss 0.657937, current_train_items 199968.
I0813 22:02:13.820068 138121668994560 run.py:727] (val) algo activity_selector step 7250: {'selected': 0.9206963249516441, 'score': 0.9206963249516441, 'examples_seen': 199968, 'step': 7250, 'algorithm': 'activity_selector'}
I0813 22:02:13.820219 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0813 22:02:14.724477 138121668994560 run.py:692] Algo activity_selector step 7300 current loss 0.801431, current_train_items 201344.
I0813 22:02:14.753871 138121668994560 run.py:727] (val) algo activity_selector step 7300: {'selected': 0.9019607843137255, 'score': 0.9019607843137255, 'examples_seen': 201344, 'step': 7300, 'algorithm': 'activity_selector'}
I0813 22:02:14.754018 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0813 22:02:15.665372 138121668994560 run.py:692] Algo activity_selector step 7350 current loss 0.771692, current_train_items 202720.
I0813 22:02:15.694293 138121668994560 run.py:727] (val) algo activity_selector step 7350: {'selected': 0.8749999999999999, 'score': 0.8749999999999999, 'examples_seen': 202720, 'step': 7350, 'algorithm': 'activity_selector'}
I0813 22:02:15.694438 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.875, val scores are: activity_selector: 0.875
I0813 22:02:16.589056 138121668994560 run.py:692] Algo activity_selector step 7400 current loss 0.986629, current_train_items 204096.
I0813 22:02:16.618553 138121668994560 run.py:727] (val) algo activity_selector step 7400: {'selected': 0.8969465648854962, 'score': 0.8969465648854962, 'examples_seen': 204096, 'step': 7400, 'algorithm': 'activity_selector'}
I0813 22:02:16.618695 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0813 22:02:17.510306 138121668994560 run.py:692] Algo activity_selector step 7450 current loss 0.691195, current_train_items 205504.
I0813 22:02:17.539434 138121668994560 run.py:727] (val) algo activity_selector step 7450: {'selected': 0.8765217391304347, 'score': 0.8765217391304347, 'examples_seen': 205504, 'step': 7450, 'algorithm': 'activity_selector'}
I0813 22:02:17.539606 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.930, current avg val score is 0.877, val scores are: activity_selector: 0.877
I0813 22:02:18.451500 138121668994560 run.py:692] Algo activity_selector step 7500 current loss 0.776321, current_train_items 206848.
I0813 22:02:18.481067 138121668994560 run.py:727] (val) algo activity_selector step 7500: {'selected': 0.9325842696629213, 'score': 0.9325842696629213, 'examples_seen': 206848, 'step': 7500, 'algorithm': 'activity_selector'}
I0813 22:02:18.481274 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.930, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0813 22:02:19.444074 138121668994560 run.py:692] Algo activity_selector step 7550 current loss 0.691690, current_train_items 208256.
I0813 22:02:19.475349 138121668994560 run.py:727] (val) algo activity_selector step 7550: {'selected': 0.8994307400379505, 'score': 0.8994307400379505, 'examples_seen': 208256, 'step': 7550, 'algorithm': 'activity_selector'}
I0813 22:02:19.475495 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.933, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0813 22:02:20.355214 138121668994560 run.py:692] Algo activity_selector step 7600 current loss 0.562404, current_train_items 209632.
I0813 22:02:20.384658 138121668994560 run.py:727] (val) algo activity_selector step 7600: {'selected': 0.9163498098859315, 'score': 0.9163498098859315, 'examples_seen': 209632, 'step': 7600, 'algorithm': 'activity_selector'}
I0813 22:02:20.384838 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.933, current avg val score is 0.916, val scores are: activity_selector: 0.916
I0813 22:02:21.285933 138121668994560 run.py:692] Algo activity_selector step 7650 current loss 0.683779, current_train_items 210976.
I0813 22:02:21.315545 138121668994560 run.py:727] (val) algo activity_selector step 7650: {'selected': 0.878136200716846, 'score': 0.878136200716846, 'examples_seen': 210976, 'step': 7650, 'algorithm': 'activity_selector'}
I0813 22:02:21.315690 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.933, current avg val score is 0.878, val scores are: activity_selector: 0.878
I0813 22:02:22.241943 138121668994560 run.py:692] Algo activity_selector step 7700 current loss 0.682896, current_train_items 212384.
I0813 22:02:22.270865 138121668994560 run.py:727] (val) algo activity_selector step 7700: {'selected': 0.920696324951644, 'score': 0.920696324951644, 'examples_seen': 212384, 'step': 7700, 'algorithm': 'activity_selector'}
I0813 22:02:22.271011 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.933, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0813 22:02:23.157199 138121668994560 run.py:692] Algo activity_selector step 7750 current loss 0.743994, current_train_items 213760.
I0813 22:02:23.186530 138121668994560 run.py:727] (val) algo activity_selector step 7750: {'selected': 0.8969465648854962, 'score': 0.8969465648854962, 'examples_seen': 213760, 'step': 7750, 'algorithm': 'activity_selector'}
I0813 22:02:23.186676 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.933, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0813 22:02:24.095391 138121668994560 run.py:692] Algo activity_selector step 7800 current loss 1.060439, current_train_items 215136.
I0813 22:02:24.125246 138121668994560 run.py:727] (val) algo activity_selector step 7800: {'selected': 0.8862745098039215, 'score': 0.8862745098039215, 'examples_seen': 215136, 'step': 7800, 'algorithm': 'activity_selector'}
I0813 22:02:24.125394 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.933, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0813 22:02:25.041319 138121668994560 run.py:692] Algo activity_selector step 7850 current loss 0.362839, current_train_items 216512.
I0813 22:02:25.070876 138121668994560 run.py:727] (val) algo activity_selector step 7850: {'selected': 0.8832684824902725, 'score': 0.8832684824902725, 'examples_seen': 216512, 'step': 7850, 'algorithm': 'activity_selector'}
I0813 22:02:25.071022 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.933, current avg val score is 0.883, val scores are: activity_selector: 0.883
I0813 22:02:25.955258 138121668994560 run.py:692] Algo activity_selector step 7900 current loss 0.523400, current_train_items 217920.
I0813 22:02:25.984880 138121668994560 run.py:727] (val) algo activity_selector step 7900: {'selected': 0.8853615520282186, 'score': 0.8853615520282186, 'examples_seen': 217920, 'step': 7900, 'algorithm': 'activity_selector'}
I0813 22:02:25.985036 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.933, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0813 22:02:26.892142 138121668994560 run.py:692] Algo activity_selector step 7950 current loss 0.493386, current_train_items 219264.
I0813 22:02:26.921337 138121668994560 run.py:727] (val) algo activity_selector step 7950: {'selected': 0.9565217391304347, 'score': 0.9565217391304347, 'examples_seen': 219264, 'step': 7950, 'algorithm': 'activity_selector'}
I0813 22:02:26.921480 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.933, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0813 22:02:27.859671 138121668994560 run.py:692] Algo activity_selector step 8000 current loss 0.475214, current_train_items 220640.
I0813 22:02:27.888497 138121668994560 run.py:727] (val) algo activity_selector step 8000: {'selected': 0.9124767225325885, 'score': 0.9124767225325885, 'examples_seen': 220640, 'step': 8000, 'algorithm': 'activity_selector'}
I0813 22:02:27.888645 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.957, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0813 22:02:28.789252 138121668994560 run.py:692] Algo activity_selector step 8050 current loss 0.556015, current_train_items 222048.
I0813 22:02:28.819526 138121668994560 run.py:727] (val) algo activity_selector step 8050: {'selected': 0.9042553191489362, 'score': 0.9042553191489362, 'examples_seen': 222048, 'step': 8050, 'algorithm': 'activity_selector'}
I0813 22:02:28.819673 138121668994560 run.py:748] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.904, val scores are: activity_selector: 0.904
I0813 22:02:29.791816 138121668994560 run.py:692] Algo activity_selector step 8100 current loss 1.058695, current_train_items 223392.
I0813 22:02:29.821019 138121668994560 run.py:727] (val) algo activity_selector step 8100: {'selected': 0.8927875243664718, 'score': 0.8927875243664718, 'examples_seen': 223392, 'step': 8100, 'algorithm': 'activity_selector'}
I0813 22:02:29.821174 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.904, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0813 22:02:30.740316 138121668994560 run.py:692] Algo activity_selector step 8150 current loss 0.665941, current_train_items 224800.
I0813 22:02:30.769986 138121668994560 run.py:727] (val) algo activity_selector step 8150: {'selected': 0.8910133843212237, 'score': 0.8910133843212237, 'examples_seen': 224800, 'step': 8150, 'algorithm': 'activity_selector'}
I0813 22:02:30.770139 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.904, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0813 22:02:31.673185 138121668994560 run.py:692] Algo activity_selector step 8200 current loss 0.706324, current_train_items 226176.
I0813 22:02:31.702055 138121668994560 run.py:727] (val) algo activity_selector step 8200: {'selected': 0.8984375, 'score': 0.8984375, 'examples_seen': 226176, 'step': 8200, 'algorithm': 'activity_selector'}
I0813 22:02:31.702211 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.904, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0813 22:02:32.596867 138121668994560 run.py:692] Algo activity_selector step 8250 current loss 0.521662, current_train_items 227520.
I0813 22:02:32.625745 138121668994560 run.py:727] (val) algo activity_selector step 8250: {'selected': 0.8994708994708996, 'score': 0.8994708994708996, 'examples_seen': 227520, 'step': 8250, 'algorithm': 'activity_selector'}
I0813 22:02:32.625890 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.904, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0813 22:02:33.546459 138121668994560 run.py:692] Algo activity_selector step 8300 current loss 0.719444, current_train_items 228928.
I0813 22:02:33.575623 138121668994560 run.py:727] (val) algo activity_selector step 8300: {'selected': 0.9101338432122371, 'score': 0.9101338432122371, 'examples_seen': 228928, 'step': 8300, 'algorithm': 'activity_selector'}
I0813 22:02:33.575770 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.904, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0813 22:02:34.512753 138121668994560 run.py:692] Algo activity_selector step 8350 current loss 0.834032, current_train_items 230304.
I0813 22:02:34.542016 138121668994560 run.py:727] (val) algo activity_selector step 8350: {'selected': 0.9120287253141832, 'score': 0.9120287253141832, 'examples_seen': 230304, 'step': 8350, 'algorithm': 'activity_selector'}
I0813 22:02:34.542170 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.910, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0813 22:02:35.504374 138121668994560 run.py:692] Algo activity_selector step 8400 current loss 0.614569, current_train_items 231680.
I0813 22:02:35.533470 138121668994560 run.py:727] (val) algo activity_selector step 8400: {'selected': 0.8864468864468864, 'score': 0.8864468864468864, 'examples_seen': 231680, 'step': 8400, 'algorithm': 'activity_selector'}
I0813 22:02:35.533615 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0813 22:02:36.442374 138121668994560 run.py:692] Algo activity_selector step 8450 current loss 0.805939, current_train_items 233056.
I0813 22:02:36.471730 138121668994560 run.py:727] (val) algo activity_selector step 8450: {'selected': 0.8927875243664718, 'score': 0.8927875243664718, 'examples_seen': 233056, 'step': 8450, 'algorithm': 'activity_selector'}
I0813 22:02:36.471879 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0813 22:02:37.361893 138121668994560 run.py:692] Algo activity_selector step 8500 current loss 0.544633, current_train_items 234464.
I0813 22:02:37.391123 138121668994560 run.py:727] (val) algo activity_selector step 8500: {'selected': 0.8801431127012521, 'score': 0.8801431127012521, 'examples_seen': 234464, 'step': 8500, 'algorithm': 'activity_selector'}
I0813 22:02:37.391273 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0813 22:02:38.309293 138121668994560 run.py:692] Algo activity_selector step 8550 current loss 0.687406, current_train_items 235808.
I0813 22:02:38.338711 138121668994560 run.py:727] (val) algo activity_selector step 8550: {'selected': 0.8354430379746836, 'score': 0.8354430379746836, 'examples_seen': 235808, 'step': 8550, 'algorithm': 'activity_selector'}
I0813 22:02:38.338857 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.835, val scores are: activity_selector: 0.835
I0813 22:02:39.246873 138121668994560 run.py:692] Algo activity_selector step 8600 current loss 0.531516, current_train_items 237184.
I0813 22:02:39.276277 138121668994560 run.py:727] (val) algo activity_selector step 8600: {'selected': 0.9094269870609982, 'score': 0.9094269870609982, 'examples_seen': 237184, 'step': 8600, 'algorithm': 'activity_selector'}
I0813 22:02:39.276428 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0813 22:02:40.187671 138121668994560 run.py:692] Algo activity_selector step 8650 current loss 0.578505, current_train_items 238592.
I0813 22:02:40.219096 138121668994560 run.py:727] (val) algo activity_selector step 8650: {'selected': 0.8327402135231317, 'score': 0.8327402135231317, 'examples_seen': 238592, 'step': 8650, 'algorithm': 'activity_selector'}
I0813 22:02:40.219265 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.833, val scores are: activity_selector: 0.833
I0813 22:02:41.122992 138121668994560 run.py:692] Algo activity_selector step 8700 current loss 0.416148, current_train_items 239936.
I0813 22:02:41.151818 138121668994560 run.py:727] (val) algo activity_selector step 8700: {'selected': 0.8872458410351202, 'score': 0.8872458410351202, 'examples_seen': 239936, 'step': 8700, 'algorithm': 'activity_selector'}
I0813 22:02:41.151962 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.887, val scores are: activity_selector: 0.887
I0813 22:02:42.059453 138121668994560 run.py:692] Algo activity_selector step 8750 current loss 0.576246, current_train_items 241344.
I0813 22:02:42.088618 138121668994560 run.py:727] (val) algo activity_selector step 8750: {'selected': 0.8817204301075269, 'score': 0.8817204301075269, 'examples_seen': 241344, 'step': 8750, 'algorithm': 'activity_selector'}
I0813 22:02:42.088764 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.882, val scores are: activity_selector: 0.882
I0813 22:02:43.007536 138121668994560 run.py:692] Algo activity_selector step 8800 current loss 0.624936, current_train_items 242720.
I0813 22:02:43.036867 138121668994560 run.py:727] (val) algo activity_selector step 8800: {'selected': 0.8834586466165413, 'score': 0.8834586466165413, 'examples_seen': 242720, 'step': 8800, 'algorithm': 'activity_selector'}
I0813 22:02:43.037030 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.883, val scores are: activity_selector: 0.883
I0813 22:02:43.945071 138121668994560 run.py:692] Algo activity_selector step 8850 current loss 0.673677, current_train_items 244096.
I0813 22:02:43.974532 138121668994560 run.py:727] (val) algo activity_selector step 8850: {'selected': 0.901669758812616, 'score': 0.901669758812616, 'examples_seen': 244096, 'step': 8850, 'algorithm': 'activity_selector'}
I0813 22:02:43.974687 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0813 22:02:44.923524 138121668994560 run.py:692] Algo activity_selector step 8900 current loss 0.582645, current_train_items 245472.
I0813 22:02:44.952493 138121668994560 run.py:727] (val) algo activity_selector step 8900: {'selected': 0.8854368932038834, 'score': 0.8854368932038834, 'examples_seen': 245472, 'step': 8900, 'algorithm': 'activity_selector'}
I0813 22:02:44.952660 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0813 22:02:45.853227 138121668994560 run.py:692] Algo activity_selector step 8950 current loss 0.466328, current_train_items 246848.
I0813 22:02:45.882282 138121668994560 run.py:727] (val) algo activity_selector step 8950: {'selected': 0.898876404494382, 'score': 0.898876404494382, 'examples_seen': 246848, 'step': 8950, 'algorithm': 'activity_selector'}
I0813 22:02:45.882444 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0813 22:02:46.809900 138121668994560 run.py:692] Algo activity_selector step 9000 current loss 0.831370, current_train_items 248224.
I0813 22:02:46.838998 138121668994560 run.py:727] (val) algo activity_selector step 9000: {'selected': 0.8853046594982079, 'score': 0.8853046594982079, 'examples_seen': 248224, 'step': 9000, 'algorithm': 'activity_selector'}
I0813 22:02:46.839183 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0813 22:02:47.759609 138121668994560 run.py:692] Algo activity_selector step 9050 current loss 0.651492, current_train_items 249600.
I0813 22:02:47.788771 138121668994560 run.py:727] (val) algo activity_selector step 9050: {'selected': 0.8875968992248061, 'score': 0.8875968992248061, 'examples_seen': 249600, 'step': 9050, 'algorithm': 'activity_selector'}
I0813 22:02:47.788932 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.888, val scores are: activity_selector: 0.888
I0813 22:02:48.678201 138121668994560 run.py:692] Algo activity_selector step 9100 current loss 0.749067, current_train_items 250976.
I0813 22:02:48.706926 138121668994560 run.py:727] (val) algo activity_selector step 9100: {'selected': 0.9056603773584905, 'score': 0.9056603773584905, 'examples_seen': 250976, 'step': 9100, 'algorithm': 'activity_selector'}
I0813 22:02:48.707072 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0813 22:02:49.640969 138121668994560 run.py:692] Algo activity_selector step 9150 current loss 0.539185, current_train_items 252352.
I0813 22:02:49.670291 138121668994560 run.py:727] (val) algo activity_selector step 9150: {'selected': 0.8822429906542056, 'score': 0.8822429906542056, 'examples_seen': 252352, 'step': 9150, 'algorithm': 'activity_selector'}
I0813 22:02:49.670437 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.882, val scores are: activity_selector: 0.882
I0813 22:02:50.585992 138121668994560 run.py:692] Algo activity_selector step 9200 current loss 0.437579, current_train_items 253760.
I0813 22:02:50.614890 138121668994560 run.py:727] (val) algo activity_selector step 9200: {'selected': 0.9118773946360154, 'score': 0.9118773946360154, 'examples_seen': 253760, 'step': 9200, 'algorithm': 'activity_selector'}
I0813 22:02:50.615038 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0813 22:02:51.528743 138121668994560 run.py:692] Algo activity_selector step 9250 current loss 0.718058, current_train_items 255136.
I0813 22:02:51.557740 138121668994560 run.py:727] (val) algo activity_selector step 9250: {'selected': 0.8917910447761195, 'score': 0.8917910447761195, 'examples_seen': 255136, 'step': 9250, 'algorithm': 'activity_selector'}
I0813 22:02:51.557886 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.912, current avg val score is 0.892, val scores are: activity_selector: 0.892
I0813 22:02:52.460628 138121668994560 run.py:692] Algo activity_selector step 9300 current loss 0.587743, current_train_items 256480.
I0813 22:02:52.489731 138121668994560 run.py:727] (val) algo activity_selector step 9300: {'selected': 0.9158878504672896, 'score': 0.9158878504672896, 'examples_seen': 256480, 'step': 9300, 'algorithm': 'activity_selector'}
I0813 22:02:52.489878 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.912, current avg val score is 0.916, val scores are: activity_selector: 0.916
I0813 22:02:53.447824 138121668994560 run.py:692] Algo activity_selector step 9350 current loss 0.651834, current_train_items 257888.
I0813 22:02:53.477139 138121668994560 run.py:727] (val) algo activity_selector step 9350: {'selected': 0.9078014184397162, 'score': 0.9078014184397162, 'examples_seen': 257888, 'step': 9350, 'algorithm': 'activity_selector'}
I0813 22:02:53.477287 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.916, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0813 22:02:54.380793 138121668994560 run.py:692] Algo activity_selector step 9400 current loss 0.527806, current_train_items 259264.
I0813 22:02:54.409697 138121668994560 run.py:727] (val) algo activity_selector step 9400: {'selected': 0.8498168498168498, 'score': 0.8498168498168498, 'examples_seen': 259264, 'step': 9400, 'algorithm': 'activity_selector'}
I0813 22:02:54.409843 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.916, current avg val score is 0.850, val scores are: activity_selector: 0.850
I0813 22:02:55.306067 138121668994560 run.py:692] Algo activity_selector step 9450 current loss 0.641618, current_train_items 260608.
I0813 22:02:55.335232 138121668994560 run.py:727] (val) algo activity_selector step 9450: {'selected': 0.856610800744879, 'score': 0.856610800744879, 'examples_seen': 260608, 'step': 9450, 'algorithm': 'activity_selector'}
I0813 22:02:55.335378 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.916, current avg val score is 0.857, val scores are: activity_selector: 0.857
I0813 22:02:56.265482 138121668994560 run.py:692] Algo activity_selector step 9500 current loss 0.494102, current_train_items 262016.
I0813 22:02:56.295274 138121668994560 run.py:727] (val) algo activity_selector step 9500: {'selected': 0.897485493230174, 'score': 0.897485493230174, 'examples_seen': 262016, 'step': 9500, 'algorithm': 'activity_selector'}
I0813 22:02:56.295423 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.916, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0813 22:02:57.187071 138121668994560 run.py:692] Algo activity_selector step 9550 current loss 0.794368, current_train_items 263424.
I0813 22:02:57.216592 138121668994560 run.py:727] (val) algo activity_selector step 9550: {'selected': 0.8457350272232305, 'score': 0.8457350272232305, 'examples_seen': 263424, 'step': 9550, 'algorithm': 'activity_selector'}
I0813 22:02:57.216739 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.916, current avg val score is 0.846, val scores are: activity_selector: 0.846
I0813 22:02:58.113001 138121668994560 run.py:692] Algo activity_selector step 9600 current loss 0.657350, current_train_items 264768.
I0813 22:02:58.142254 138121668994560 run.py:727] (val) algo activity_selector step 9600: {'selected': 0.9255533199195171, 'score': 0.9255533199195171, 'examples_seen': 264768, 'step': 9600, 'algorithm': 'activity_selector'}
I0813 22:02:58.142399 138121668994560 run.py:748] Checkpointing best model, best avg val score was 0.916, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0813 22:02:59.126542 138121668994560 run.py:692] Algo activity_selector step 9650 current loss 0.599354, current_train_items 266144.
I0813 22:02:59.156277 138121668994560 run.py:727] (val) algo activity_selector step 9650: {'selected': 0.9152542372881355, 'score': 0.9152542372881355, 'examples_seen': 266144, 'step': 9650, 'algorithm': 'activity_selector'}
I0813 22:02:59.156425 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.926, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0813 22:03:00.058504 138121668994560 run.py:692] Algo activity_selector step 9700 current loss 0.608759, current_train_items 267552.
I0813 22:03:00.087904 138121668994560 run.py:727] (val) algo activity_selector step 9700: {'selected': 0.9007092198581561, 'score': 0.9007092198581561, 'examples_seen': 267552, 'step': 9700, 'algorithm': 'activity_selector'}
I0813 22:03:00.088051 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.926, current avg val score is 0.901, val scores are: activity_selector: 0.901
I0813 22:03:00.997135 138121668994560 run.py:692] Algo activity_selector step 9750 current loss 0.588744, current_train_items 268896.
I0813 22:03:01.026160 138121668994560 run.py:727] (val) algo activity_selector step 9750: {'selected': 0.9195402298850576, 'score': 0.9195402298850576, 'examples_seen': 268896, 'step': 9750, 'algorithm': 'activity_selector'}
I0813 22:03:01.026310 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.926, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0813 22:03:01.930213 138121668994560 run.py:692] Algo activity_selector step 9800 current loss 0.624540, current_train_items 270272.
I0813 22:03:01.959085 138121668994560 run.py:727] (val) algo activity_selector step 9800: {'selected': 0.8921933085501859, 'score': 0.8921933085501859, 'examples_seen': 270272, 'step': 9800, 'algorithm': 'activity_selector'}
I0813 22:03:01.959254 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.926, current avg val score is 0.892, val scores are: activity_selector: 0.892
I0813 22:03:02.873892 138121668994560 run.py:692] Algo activity_selector step 9850 current loss 0.599640, current_train_items 271680.
I0813 22:03:02.903226 138121668994560 run.py:727] (val) algo activity_selector step 9850: {'selected': 0.8836363636363638, 'score': 0.8836363636363638, 'examples_seen': 271680, 'step': 9850, 'algorithm': 'activity_selector'}
I0813 22:03:02.903373 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.926, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0813 22:03:03.810468 138121668994560 run.py:692] Algo activity_selector step 9900 current loss 0.589618, current_train_items 273056.
I0813 22:03:03.841204 138121668994560 run.py:727] (val) algo activity_selector step 9900: {'selected': 0.8998109640831758, 'score': 0.8998109640831758, 'examples_seen': 273056, 'step': 9900, 'algorithm': 'activity_selector'}
I0813 22:03:03.841351 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.926, current avg val score is 0.900, val scores are: activity_selector: 0.900
I0813 22:03:04.744058 138121668994560 run.py:692] Algo activity_selector step 9950 current loss 0.636841, current_train_items 274400.
I0813 22:03:04.773336 138121668994560 run.py:727] (val) algo activity_selector step 9950: {'selected': 0.896421845574388, 'score': 0.896421845574388, 'examples_seen': 274400, 'step': 9950, 'algorithm': 'activity_selector'}
I0813 22:03:04.773479 138121668994560 run.py:751] Not saving new best model, best avg val score was 0.926, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0813 22:03:05.681038 138121668994560 run.py:757] Restoring best model from checkpoint...
I0813 22:03:11.320151 138121668994560 run.py:772] (test) algo activity_selector : {'selected': 0.6859083191850595, 'score': 0.6859083191850595, 'examples_seen': 275776, 'step': 10000, 'algorithm': 'activity_selector'}
I0813 22:03:11.320273 138121668994560 run.py:774] Done!
