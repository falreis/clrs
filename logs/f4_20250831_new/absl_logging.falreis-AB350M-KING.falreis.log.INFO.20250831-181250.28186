I0831 18:12:53.142532 138047105189376 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0831 18:12:53.143371 138047105189376 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0831 18:12:53.372540 138047105189376 run.py:426] Model: f4 ['activity_selector', 'task_scheduling']
I0831 18:12:53.372639 138047105189376 run.py:428] algorithms ['activity_selector', 'task_scheduling']
I0831 18:12:53.372814 138047105189376 run.py:429] train_lengths ['4', '7', '11', '13', '16']
I0831 18:12:53.372857 138047105189376 run.py:430] train_batch_size 16
I0831 18:12:53.372959 138047105189376 run.py:431] val_batch_size 16
I0831 18:12:53.372991 138047105189376 run.py:432] test_batch_size 16
I0831 18:12:53.373020 138047105189376 run.py:433] chunked_training True
I0831 18:12:53.373135 138047105189376 run.py:434] chunk_length 8
I0831 18:12:53.373168 138047105189376 run.py:435] train_steps 10000
I0831 18:12:53.373198 138047105189376 run.py:436] eval_every 50
I0831 18:12:53.373227 138047105189376 run.py:437] test_every 500
I0831 18:12:53.373256 138047105189376 run.py:438] hidden_size 128
I0831 18:12:53.373283 138047105189376 run.py:439] nb_msg_passing_steps 1
I0831 18:12:53.373311 138047105189376 run.py:440] learning_rate 0.001
I0831 18:12:53.373402 138047105189376 run.py:441] grad_clip_max_norm 1.0
I0831 18:12:53.373432 138047105189376 run.py:442] dropout_prob 0.0
I0831 18:12:53.373460 138047105189376 run.py:443] hint_teacher_forcing 0.0
I0831 18:12:53.373487 138047105189376 run.py:444] hint_mode encoded_decoded
I0831 18:12:53.373590 138047105189376 run.py:445] hint_repred_mode soft
I0831 18:12:53.373621 138047105189376 run.py:446] use_ln False
I0831 18:12:53.373649 138047105189376 run.py:447] use_lstm True
I0831 18:12:53.373677 138047105189376 run.py:448] nb_triplet_fts 8
I0831 18:12:53.373704 138047105189376 run.py:449] encoder_init xavier_on_scalars
I0831 18:12:53.373731 138047105189376 run.py:450] processor_type f4
I0831 18:12:53.373759 138047105189376 run.py:451] checkpoint_path CLRS30
I0831 18:12:53.373787 138047105189376 run.py:452] dataset_path CLRS30
I0831 18:12:53.373818 138047105189376 run.py:453] freeze_processor False
I0831 18:12:53.373846 138047105189376 run.py:454] reduction min
I0831 18:12:53.373873 138047105189376 run.py:455] activation elu
I0831 18:12:53.373901 138047105189376 run.py:456] restore_model 
I0831 18:12:53.373934 138047105189376 run.py:457] gated False
I0831 18:12:53.373964 138047105189376 run.py:458] gated_activation sigmoid
I0831 18:12:53.376771 138047105189376 run.py:484] Creating samplers for algo activity_selector
W0831 18:12:53.377008 138047105189376 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0831 18:12:53.377261 138047105189376 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0831 18:12:53.579791 138047105189376 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0831 18:12:53.817404 138047105189376 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0831 18:12:54.118570 138047105189376 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0831 18:12:54.444152 138047105189376 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0831 18:12:54.827617 138047105189376 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0831 18:12:54.827901 138047105189376 samplers.py:124] Creating a dataset with 64 samples.
I0831 18:12:54.854319 138047105189376 run.py:270] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0831 18:12:54.855056 138047105189376 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0831 18:12:54.858702 138047105189376 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0831 18:12:54.862151 138047105189376 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0831 18:12:54.916266 138047105189376 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W0831 18:12:54.937965 138047105189376 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x7d8d141b3920> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0831 18:12:55.020462 138047105189376 run.py:484] Creating samplers for algo task_scheduling
W0831 18:12:55.020700 138047105189376 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.TaskSampler'>
W0831 18:12:55.216670 138047105189376 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.TaskSampler'>
W0831 18:12:55.442023 138047105189376 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.TaskSampler'>
W0831 18:12:55.720639 138047105189376 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.TaskSampler'>
W0831 18:12:56.047769 138047105189376 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.TaskSampler'>
W0831 18:12:56.411826 138047105189376 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.TaskSampler'>
I0831 18:12:56.412139 138047105189376 samplers.py:124] Creating a dataset with 64 samples.
I0831 18:12:56.436765 138047105189376 run.py:270] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0831 18:12:56.437383 138047105189376 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/task_scheduling_test/1.0.0
I0831 18:12:56.440150 138047105189376 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/task_scheduling_test/1.0.0
I0831 18:12:56.442567 138047105189376 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/task_scheduling_test/1.0.0.
I0831 18:12:56.477708 138047105189376 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/task_scheduling_test/1.0.0
I0831 18:13:21.350068 138047105189376 run.py:707] Algo activity_selector step 0 current loss 6.127175, current_train_items 16.
I0831 18:13:26.738666 138047105189376 run.py:707] Algo task_scheduling step 0 current loss 6.653667, current_train_items 16.
I0831 18:13:29.165525 138047105189376 run.py:742] (val) algo activity_selector step 0: {'selected': 0.4271047227926078, 'score': 0.4271047227926078, 'examples_seen': 16, 'step': 0, 'algorithm': 'activity_selector'}
I0831 18:13:30.624138 138047105189376 run.py:742] (val) algo task_scheduling step 0: {'selected': 0.0, 'score': 0.0, 'examples_seen': 16, 'step': 0, 'algorithm': 'task_scheduling'}
I0831 18:13:30.624295 138047105189376 run.py:763] Checkpointing best model, best avg val score was -0.500, current avg val score is 0.214, val scores are: activity_selector: 0.427, task_scheduling: 0.000
I0831 18:14:22.772033 138047105189376 run.py:707] Algo activity_selector step 50 current loss 4.165008, current_train_items 720.
I0831 18:14:22.776525 138047105189376 run.py:707] Algo task_scheduling step 50 current loss 3.429828, current_train_items 720.
I0831 18:14:22.793788 138047105189376 run.py:742] (val) algo activity_selector step 50: {'selected': 0.6980392156862745, 'score': 0.6980392156862745, 'examples_seen': 720, 'step': 50, 'algorithm': 'activity_selector'}
I0831 18:14:22.801686 138047105189376 run.py:742] (val) algo task_scheduling step 50: {'selected': 0.8526930564568462, 'score': 0.8526930564568462, 'examples_seen': 720, 'step': 50, 'algorithm': 'task_scheduling'}
I0831 18:14:22.801838 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.214, current avg val score is 0.775, val scores are: activity_selector: 0.698, task_scheduling: 0.853
I0831 18:14:23.829361 138047105189376 run.py:707] Algo activity_selector step 100 current loss 3.520272, current_train_items 1408.
I0831 18:14:23.834224 138047105189376 run.py:707] Algo task_scheduling step 100 current loss 3.607952, current_train_items 1408.
I0831 18:14:23.850388 138047105189376 run.py:742] (val) algo activity_selector step 100: {'selected': 0.7343485617597293, 'score': 0.7343485617597293, 'examples_seen': 1408, 'step': 100, 'algorithm': 'activity_selector'}
I0831 18:14:23.858003 138047105189376 run.py:742] (val) algo task_scheduling step 100: {'selected': 0.8608082103912764, 'score': 0.8608082103912764, 'examples_seen': 1408, 'step': 100, 'algorithm': 'task_scheduling'}
I0831 18:14:23.858144 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.775, current avg val score is 0.798, val scores are: activity_selector: 0.734, task_scheduling: 0.861
I0831 18:14:24.948348 138047105189376 run.py:707] Algo activity_selector step 150 current loss 3.136530, current_train_items 2080.
I0831 18:14:24.952884 138047105189376 run.py:707] Algo task_scheduling step 150 current loss 3.312793, current_train_items 2080.
I0831 18:14:24.969604 138047105189376 run.py:742] (val) algo activity_selector step 150: {'selected': 0.7674418604651163, 'score': 0.7674418604651163, 'examples_seen': 2080, 'step': 150, 'algorithm': 'activity_selector'}
I0831 18:14:24.977253 138047105189376 run.py:742] (val) algo task_scheduling step 150: {'selected': 0.8729427254772877, 'score': 0.8729427254772877, 'examples_seen': 2080, 'step': 150, 'algorithm': 'task_scheduling'}
I0831 18:14:24.977393 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.798, current avg val score is 0.820, val scores are: activity_selector: 0.767, task_scheduling: 0.873
I0831 18:14:26.042755 138047105189376 run.py:707] Algo activity_selector step 200 current loss 2.646219, current_train_items 2784.
I0831 18:14:26.047817 138047105189376 run.py:707] Algo task_scheduling step 200 current loss 3.757482, current_train_items 2784.
I0831 18:14:26.063768 138047105189376 run.py:742] (val) algo activity_selector step 200: {'selected': 0.7231833910034601, 'score': 0.7231833910034601, 'examples_seen': 2784, 'step': 200, 'algorithm': 'activity_selector'}
I0831 18:14:26.071451 138047105189376 run.py:742] (val) algo task_scheduling step 200: {'selected': 0.8873720136518771, 'score': 0.8873720136518771, 'examples_seen': 2784, 'step': 200, 'algorithm': 'task_scheduling'}
I0831 18:14:26.071596 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.820, current avg val score is 0.805, val scores are: activity_selector: 0.723, task_scheduling: 0.887
I0831 18:14:27.112158 138047105189376 run.py:707] Algo activity_selector step 250 current loss 2.817858, current_train_items 3488.
I0831 18:14:27.116886 138047105189376 run.py:707] Algo task_scheduling step 250 current loss 3.364336, current_train_items 3488.
I0831 18:14:27.133750 138047105189376 run.py:742] (val) algo activity_selector step 250: {'selected': 0.7272727272727273, 'score': 0.7272727272727273, 'examples_seen': 3488, 'step': 250, 'algorithm': 'activity_selector'}
I0831 18:14:27.141364 138047105189376 run.py:742] (val) algo task_scheduling step 250: {'selected': 0.8486842105263158, 'score': 0.8486842105263158, 'examples_seen': 3488, 'step': 250, 'algorithm': 'task_scheduling'}
I0831 18:14:27.141507 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.820, current avg val score is 0.788, val scores are: activity_selector: 0.727, task_scheduling: 0.849
I0831 18:14:28.190702 138047105189376 run.py:707] Algo activity_selector step 300 current loss 2.759076, current_train_items 4144.
I0831 18:14:28.195182 138047105189376 run.py:707] Algo task_scheduling step 300 current loss 2.908880, current_train_items 4144.
I0831 18:14:28.211501 138047105189376 run.py:742] (val) algo activity_selector step 300: {'selected': 0.7714748784440844, 'score': 0.7714748784440844, 'examples_seen': 4144, 'step': 300, 'algorithm': 'activity_selector'}
I0831 18:14:28.219027 138047105189376 run.py:742] (val) algo task_scheduling step 300: {'selected': 0.8951724137931035, 'score': 0.8951724137931035, 'examples_seen': 4144, 'step': 300, 'algorithm': 'task_scheduling'}
I0831 18:14:28.219174 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.820, current avg val score is 0.833, val scores are: activity_selector: 0.771, task_scheduling: 0.895
I0831 18:14:29.291462 138047105189376 run.py:707] Algo activity_selector step 350 current loss 3.056064, current_train_items 4848.
I0831 18:14:29.296252 138047105189376 run.py:707] Algo task_scheduling step 350 current loss 2.938940, current_train_items 4848.
I0831 18:14:29.312613 138047105189376 run.py:742] (val) algo activity_selector step 350: {'selected': 0.6741573033707865, 'score': 0.6741573033707865, 'examples_seen': 4848, 'step': 350, 'algorithm': 'activity_selector'}
I0831 18:14:29.320290 138047105189376 run.py:742] (val) algo task_scheduling step 350: {'selected': 0.8900804289544236, 'score': 0.8900804289544236, 'examples_seen': 4848, 'step': 350, 'algorithm': 'task_scheduling'}
I0831 18:14:29.320445 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.833, current avg val score is 0.782, val scores are: activity_selector: 0.674, task_scheduling: 0.890
I0831 18:14:30.370394 138047105189376 run.py:707] Algo activity_selector step 400 current loss 2.175489, current_train_items 5552.
I0831 18:14:30.374949 138047105189376 run.py:707] Algo task_scheduling step 400 current loss 4.160185, current_train_items 5552.
I0831 18:14:30.391449 138047105189376 run.py:742] (val) algo activity_selector step 400: {'selected': 0.751304347826087, 'score': 0.751304347826087, 'examples_seen': 5552, 'step': 400, 'algorithm': 'activity_selector'}
I0831 18:14:30.399012 138047105189376 run.py:742] (val) algo task_scheduling step 400: {'selected': 0.861598440545809, 'score': 0.861598440545809, 'examples_seen': 5552, 'step': 400, 'algorithm': 'task_scheduling'}
I0831 18:14:30.399152 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.833, current avg val score is 0.806, val scores are: activity_selector: 0.751, task_scheduling: 0.862
I0831 18:14:31.422857 138047105189376 run.py:707] Algo activity_selector step 450 current loss 2.339302, current_train_items 6224.
I0831 18:14:31.427855 138047105189376 run.py:707] Algo task_scheduling step 450 current loss 2.773389, current_train_items 6224.
I0831 18:14:31.444539 138047105189376 run.py:742] (val) algo activity_selector step 450: {'selected': 0.7666666666666665, 'score': 0.7666666666666665, 'examples_seen': 6224, 'step': 450, 'algorithm': 'activity_selector'}
I0831 18:14:31.452350 138047105189376 run.py:742] (val) algo task_scheduling step 450: {'selected': 0.8969283276450513, 'score': 0.8969283276450513, 'examples_seen': 6224, 'step': 450, 'algorithm': 'task_scheduling'}
I0831 18:14:31.452492 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.833, current avg val score is 0.832, val scores are: activity_selector: 0.767, task_scheduling: 0.897
I0831 18:14:32.515224 138047105189376 run.py:707] Algo activity_selector step 500 current loss 2.323624, current_train_items 6912.
I0831 18:14:32.519964 138047105189376 run.py:707] Algo task_scheduling step 500 current loss 2.366865, current_train_items 6912.
I0831 18:14:32.535627 138047105189376 run.py:742] (val) algo activity_selector step 500: {'selected': 0.7122736418511065, 'score': 0.7122736418511065, 'examples_seen': 6912, 'step': 500, 'algorithm': 'activity_selector'}
I0831 18:14:32.543341 138047105189376 run.py:742] (val) algo task_scheduling step 500: {'selected': 0.896457765667575, 'score': 0.896457765667575, 'examples_seen': 6912, 'step': 500, 'algorithm': 'task_scheduling'}
I0831 18:14:32.543478 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.833, current avg val score is 0.804, val scores are: activity_selector: 0.712, task_scheduling: 0.896
I0831 18:14:33.590403 138047105189376 run.py:707] Algo activity_selector step 550 current loss 1.830600, current_train_items 7616.
I0831 18:14:33.595114 138047105189376 run.py:707] Algo task_scheduling step 550 current loss 3.130281, current_train_items 7616.
I0831 18:14:33.611573 138047105189376 run.py:742] (val) algo activity_selector step 550: {'selected': 0.768361581920904, 'score': 0.768361581920904, 'examples_seen': 7616, 'step': 550, 'algorithm': 'activity_selector'}
I0831 18:14:33.619196 138047105189376 run.py:742] (val) algo task_scheduling step 550: {'selected': 0.9040717736369911, 'score': 0.9040717736369911, 'examples_seen': 7616, 'step': 550, 'algorithm': 'task_scheduling'}
I0831 18:14:33.619351 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.833, current avg val score is 0.836, val scores are: activity_selector: 0.768, task_scheduling: 0.904
I0831 18:14:34.667418 138047105189376 run.py:707] Algo activity_selector step 600 current loss 2.756535, current_train_items 8288.
I0831 18:14:34.671860 138047105189376 run.py:707] Algo task_scheduling step 600 current loss 3.188985, current_train_items 8288.
I0831 18:14:34.687965 138047105189376 run.py:742] (val) algo activity_selector step 600: {'selected': 0.7878787878787877, 'score': 0.7878787878787877, 'examples_seen': 8288, 'step': 600, 'algorithm': 'activity_selector'}
I0831 18:14:34.695499 138047105189376 run.py:742] (val) algo task_scheduling step 600: {'selected': 0.8928818244644091, 'score': 0.8928818244644091, 'examples_seen': 8288, 'step': 600, 'algorithm': 'task_scheduling'}
I0831 18:14:34.695640 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.836, current avg val score is 0.840, val scores are: activity_selector: 0.788, task_scheduling: 0.893
I0831 18:14:35.772017 138047105189376 run.py:707] Algo activity_selector step 650 current loss 1.764264, current_train_items 8976.
I0831 18:14:35.776693 138047105189376 run.py:707] Algo task_scheduling step 650 current loss 2.737480, current_train_items 8976.
I0831 18:14:35.793091 138047105189376 run.py:742] (val) algo activity_selector step 650: {'selected': 0.7553191489361702, 'score': 0.7553191489361702, 'examples_seen': 8976, 'step': 650, 'algorithm': 'activity_selector'}
I0831 18:14:35.800762 138047105189376 run.py:742] (val) algo task_scheduling step 650: {'selected': 0.9017857142857143, 'score': 0.9017857142857143, 'examples_seen': 8976, 'step': 650, 'algorithm': 'task_scheduling'}
I0831 18:14:35.800917 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.840, current avg val score is 0.829, val scores are: activity_selector: 0.755, task_scheduling: 0.902
I0831 18:14:36.844280 138047105189376 run.py:707] Algo activity_selector step 700 current loss 1.484233, current_train_items 9680.
I0831 18:14:36.848892 138047105189376 run.py:707] Algo task_scheduling step 700 current loss 2.645278, current_train_items 9680.
I0831 18:14:36.865274 138047105189376 run.py:742] (val) algo activity_selector step 700: {'selected': 0.8101761252446182, 'score': 0.8101761252446182, 'examples_seen': 9680, 'step': 700, 'algorithm': 'activity_selector'}
I0831 18:14:36.872958 138047105189376 run.py:742] (val) algo task_scheduling step 700: {'selected': 0.9234012649332396, 'score': 0.9234012649332396, 'examples_seen': 9680, 'step': 700, 'algorithm': 'task_scheduling'}
I0831 18:14:36.873104 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.840, current avg val score is 0.867, val scores are: activity_selector: 0.810, task_scheduling: 0.923
I0831 18:14:37.939776 138047105189376 run.py:707] Algo activity_selector step 750 current loss 1.792640, current_train_items 10368.
I0831 18:14:37.944347 138047105189376 run.py:707] Algo task_scheduling step 750 current loss 2.781963, current_train_items 10368.
I0831 18:14:37.960937 138047105189376 run.py:742] (val) algo activity_selector step 750: {'selected': 0.7810650887573963, 'score': 0.7810650887573963, 'examples_seen': 10368, 'step': 750, 'algorithm': 'activity_selector'}
I0831 18:14:37.968449 138047105189376 run.py:742] (val) algo task_scheduling step 750: {'selected': 0.9130434782608696, 'score': 0.9130434782608696, 'examples_seen': 10368, 'step': 750, 'algorithm': 'task_scheduling'}
I0831 18:14:37.968592 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.867, current avg val score is 0.847, val scores are: activity_selector: 0.781, task_scheduling: 0.913
I0831 18:14:39.006765 138047105189376 run.py:707] Algo activity_selector step 800 current loss 1.713640, current_train_items 11056.
I0831 18:14:39.011801 138047105189376 run.py:707] Algo task_scheduling step 800 current loss 2.320710, current_train_items 11056.
I0831 18:14:39.028843 138047105189376 run.py:742] (val) algo activity_selector step 800: {'selected': 0.8592321755027421, 'score': 0.8592321755027421, 'examples_seen': 11056, 'step': 800, 'algorithm': 'activity_selector'}
I0831 18:14:39.036583 138047105189376 run.py:742] (val) algo task_scheduling step 800: {'selected': 0.9207853757616791, 'score': 0.9207853757616791, 'examples_seen': 11056, 'step': 800, 'algorithm': 'task_scheduling'}
I0831 18:14:39.036736 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.867, current avg val score is 0.890, val scores are: activity_selector: 0.859, task_scheduling: 0.921
I0831 18:14:40.090528 138047105189376 run.py:707] Algo activity_selector step 850 current loss 2.185591, current_train_items 11744.
I0831 18:14:40.095293 138047105189376 run.py:707] Algo task_scheduling step 850 current loss 2.232267, current_train_items 11744.
I0831 18:14:40.111372 138047105189376 run.py:742] (val) algo activity_selector step 850: {'selected': 0.7862903225806452, 'score': 0.7862903225806452, 'examples_seen': 11744, 'step': 850, 'algorithm': 'activity_selector'}
I0831 18:14:40.118995 138047105189376 run.py:742] (val) algo task_scheduling step 850: {'selected': 0.9092250922509226, 'score': 0.9092250922509226, 'examples_seen': 11744, 'step': 850, 'algorithm': 'task_scheduling'}
I0831 18:14:40.119141 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.848, val scores are: activity_selector: 0.786, task_scheduling: 0.909
I0831 18:14:41.177762 138047105189376 run.py:707] Algo activity_selector step 900 current loss 1.320596, current_train_items 12432.
I0831 18:14:41.182208 138047105189376 run.py:707] Algo task_scheduling step 900 current loss 2.336044, current_train_items 12432.
I0831 18:14:41.198746 138047105189376 run.py:742] (val) algo activity_selector step 900: {'selected': 0.8089887640449438, 'score': 0.8089887640449438, 'examples_seen': 12432, 'step': 900, 'algorithm': 'activity_selector'}
I0831 18:14:41.206267 138047105189376 run.py:742] (val) algo task_scheduling step 900: {'selected': 0.9147851420247634, 'score': 0.9147851420247634, 'examples_seen': 12432, 'step': 900, 'algorithm': 'task_scheduling'}
I0831 18:14:41.206411 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.862, val scores are: activity_selector: 0.809, task_scheduling: 0.915
I0831 18:14:42.241868 138047105189376 run.py:707] Algo activity_selector step 950 current loss 1.324088, current_train_items 13120.
I0831 18:14:42.246871 138047105189376 run.py:707] Algo task_scheduling step 950 current loss 3.192797, current_train_items 13120.
I0831 18:14:42.263373 138047105189376 run.py:742] (val) algo activity_selector step 950: {'selected': 0.7936507936507937, 'score': 0.7936507936507937, 'examples_seen': 13120, 'step': 950, 'algorithm': 'activity_selector'}
I0831 18:14:42.270914 138047105189376 run.py:742] (val) algo task_scheduling step 950: {'selected': 0.9238578680203045, 'score': 0.9238578680203045, 'examples_seen': 13120, 'step': 950, 'algorithm': 'task_scheduling'}
I0831 18:14:42.271066 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.859, val scores are: activity_selector: 0.794, task_scheduling: 0.924
I0831 18:14:43.307260 138047105189376 run.py:707] Algo activity_selector step 1000 current loss 1.767853, current_train_items 13808.
I0831 18:14:43.311475 138047105189376 run.py:707] Algo task_scheduling step 1000 current loss 2.255371, current_train_items 13808.
I0831 18:14:43.327994 138047105189376 run.py:742] (val) algo activity_selector step 1000: {'selected': 0.7601246105919003, 'score': 0.7601246105919003, 'examples_seen': 13808, 'step': 1000, 'algorithm': 'activity_selector'}
I0831 18:14:43.335722 138047105189376 run.py:742] (val) algo task_scheduling step 1000: {'selected': 0.9356032568467801, 'score': 0.9356032568467801, 'examples_seen': 13808, 'step': 1000, 'algorithm': 'task_scheduling'}
I0831 18:14:43.335868 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.848, val scores are: activity_selector: 0.760, task_scheduling: 0.936
I0831 18:14:44.388597 138047105189376 run.py:707] Algo activity_selector step 1050 current loss 1.398363, current_train_items 14496.
I0831 18:14:44.393153 138047105189376 run.py:707] Algo task_scheduling step 1050 current loss 2.717913, current_train_items 14496.
I0831 18:14:44.409448 138047105189376 run.py:742] (val) algo activity_selector step 1050: {'selected': 0.7818791946308724, 'score': 0.7818791946308724, 'examples_seen': 14496, 'step': 1050, 'algorithm': 'activity_selector'}
I0831 18:14:44.416987 138047105189376 run.py:742] (val) algo task_scheduling step 1050: {'selected': 0.9027397260273973, 'score': 0.9027397260273973, 'examples_seen': 14496, 'step': 1050, 'algorithm': 'task_scheduling'}
I0831 18:14:44.417130 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.842, val scores are: activity_selector: 0.782, task_scheduling: 0.903
I0831 18:14:45.452001 138047105189376 run.py:707] Algo activity_selector step 1100 current loss 1.478250, current_train_items 15200.
I0831 18:14:45.456651 138047105189376 run.py:707] Algo task_scheduling step 1100 current loss 2.303632, current_train_items 15200.
I0831 18:14:45.473429 138047105189376 run.py:742] (val) algo activity_selector step 1100: {'selected': 0.7923728813559322, 'score': 0.7923728813559322, 'examples_seen': 15200, 'step': 1100, 'algorithm': 'activity_selector'}
I0831 18:14:45.481005 138047105189376 run.py:742] (val) algo task_scheduling step 1100: {'selected': 0.9166666666666669, 'score': 0.9166666666666669, 'examples_seen': 15200, 'step': 1100, 'algorithm': 'task_scheduling'}
I0831 18:14:45.481145 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.855, val scores are: activity_selector: 0.792, task_scheduling: 0.917
I0831 18:14:46.511432 138047105189376 run.py:707] Algo activity_selector step 1150 current loss 1.660282, current_train_items 15888.
I0831 18:14:46.515982 138047105189376 run.py:707] Algo task_scheduling step 1150 current loss 3.117295, current_train_items 15888.
I0831 18:14:46.533110 138047105189376 run.py:742] (val) algo activity_selector step 1150: {'selected': 0.8086642599277979, 'score': 0.8086642599277979, 'examples_seen': 15888, 'step': 1150, 'algorithm': 'activity_selector'}
I0831 18:14:46.540718 138047105189376 run.py:742] (val) algo task_scheduling step 1150: {'selected': 0.9144421629021218, 'score': 0.9144421629021218, 'examples_seen': 15888, 'step': 1150, 'algorithm': 'task_scheduling'}
I0831 18:14:46.540859 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.862, val scores are: activity_selector: 0.809, task_scheduling: 0.914
I0831 18:14:47.600624 138047105189376 run.py:707] Algo activity_selector step 1200 current loss 1.274229, current_train_items 16560.
I0831 18:14:47.605613 138047105189376 run.py:707] Algo task_scheduling step 1200 current loss 2.476606, current_train_items 16560.
I0831 18:14:47.622014 138047105189376 run.py:742] (val) algo activity_selector step 1200: {'selected': 0.8388349514563106, 'score': 0.8388349514563106, 'examples_seen': 16560, 'step': 1200, 'algorithm': 'activity_selector'}
I0831 18:14:47.629558 138047105189376 run.py:742] (val) algo task_scheduling step 1200: {'selected': 0.9226145755071374, 'score': 0.9226145755071374, 'examples_seen': 16560, 'step': 1200, 'algorithm': 'task_scheduling'}
I0831 18:14:47.629700 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.881, val scores are: activity_selector: 0.839, task_scheduling: 0.923
I0831 18:14:48.702176 138047105189376 run.py:707] Algo activity_selector step 1250 current loss 1.078201, current_train_items 17264.
I0831 18:14:48.706609 138047105189376 run.py:707] Algo task_scheduling step 1250 current loss 2.839639, current_train_items 17264.
I0831 18:14:48.723363 138047105189376 run.py:742] (val) algo activity_selector step 1250: {'selected': 0.8488160291438979, 'score': 0.8488160291438979, 'examples_seen': 17264, 'step': 1250, 'algorithm': 'activity_selector'}
I0831 18:14:48.730981 138047105189376 run.py:742] (val) algo task_scheduling step 1250: {'selected': 0.9305555555555556, 'score': 0.9305555555555556, 'examples_seen': 17264, 'step': 1250, 'algorithm': 'task_scheduling'}
I0831 18:14:48.731123 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.890, val scores are: activity_selector: 0.849, task_scheduling: 0.931
I0831 18:14:49.763542 138047105189376 run.py:707] Algo activity_selector step 1300 current loss 1.860415, current_train_items 17952.
I0831 18:14:49.767990 138047105189376 run.py:707] Algo task_scheduling step 1300 current loss 2.656311, current_train_items 17952.
I0831 18:14:49.784770 138047105189376 run.py:742] (val) algo activity_selector step 1300: {'selected': 0.7956204379562044, 'score': 0.7956204379562044, 'examples_seen': 17952, 'step': 1300, 'algorithm': 'activity_selector'}
I0831 18:14:49.792325 138047105189376 run.py:742] (val) algo task_scheduling step 1300: {'selected': 0.9339080459770114, 'score': 0.9339080459770114, 'examples_seen': 17952, 'step': 1300, 'algorithm': 'task_scheduling'}
I0831 18:14:49.792467 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.865, val scores are: activity_selector: 0.796, task_scheduling: 0.934
I0831 18:14:50.896553 138047105189376 run.py:707] Algo activity_selector step 1350 current loss 1.199348, current_train_items 18624.
I0831 18:14:50.900904 138047105189376 run.py:707] Algo task_scheduling step 1350 current loss 1.997982, current_train_items 18624.
I0831 18:14:50.916676 138047105189376 run.py:742] (val) algo activity_selector step 1350: {'selected': 0.8048359240069085, 'score': 0.8048359240069085, 'examples_seen': 18624, 'step': 1350, 'algorithm': 'activity_selector'}
I0831 18:14:50.924303 138047105189376 run.py:742] (val) algo task_scheduling step 1350: {'selected': 0.9116347569955817, 'score': 0.9116347569955817, 'examples_seen': 18624, 'step': 1350, 'algorithm': 'task_scheduling'}
I0831 18:14:50.924451 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.858, val scores are: activity_selector: 0.805, task_scheduling: 0.912
I0831 18:14:51.981393 138047105189376 run.py:707] Algo activity_selector step 1400 current loss 0.942545, current_train_items 19328.
I0831 18:14:51.985805 138047105189376 run.py:707] Algo task_scheduling step 1400 current loss 2.218750, current_train_items 19328.
I0831 18:14:52.002137 138047105189376 run.py:742] (val) algo activity_selector step 1400: {'selected': 0.8022813688212928, 'score': 0.8022813688212928, 'examples_seen': 19328, 'step': 1400, 'algorithm': 'activity_selector'}
I0831 18:14:52.009788 138047105189376 run.py:742] (val) algo task_scheduling step 1400: {'selected': 0.918486171761281, 'score': 0.918486171761281, 'examples_seen': 19328, 'step': 1400, 'algorithm': 'task_scheduling'}
I0831 18:14:52.009954 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.860, val scores are: activity_selector: 0.802, task_scheduling: 0.918
I0831 18:14:53.047614 138047105189376 run.py:707] Algo activity_selector step 1450 current loss 1.255908, current_train_items 20016.
I0831 18:14:53.052156 138047105189376 run.py:707] Algo task_scheduling step 1450 current loss 2.082685, current_train_items 20016.
I0831 18:14:53.068642 138047105189376 run.py:742] (val) algo activity_selector step 1450: {'selected': 0.8110236220472441, 'score': 0.8110236220472441, 'examples_seen': 20016, 'step': 1450, 'algorithm': 'activity_selector'}
I0831 18:14:53.076263 138047105189376 run.py:742] (val) algo task_scheduling step 1450: {'selected': 0.9396681749622927, 'score': 0.9396681749622927, 'examples_seen': 20016, 'step': 1450, 'algorithm': 'task_scheduling'}
I0831 18:14:53.076408 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.875, val scores are: activity_selector: 0.811, task_scheduling: 0.940
I0831 18:14:54.141098 138047105189376 run.py:707] Algo activity_selector step 1500 current loss 1.024888, current_train_items 20704.
I0831 18:14:54.145844 138047105189376 run.py:707] Algo task_scheduling step 1500 current loss 2.317247, current_train_items 20704.
I0831 18:14:54.161786 138047105189376 run.py:742] (val) algo activity_selector step 1500: {'selected': 0.8226415094339623, 'score': 0.8226415094339623, 'examples_seen': 20704, 'step': 1500, 'algorithm': 'activity_selector'}
I0831 18:14:54.169365 138047105189376 run.py:742] (val) algo task_scheduling step 1500: {'selected': 0.9421245421245421, 'score': 0.9421245421245421, 'examples_seen': 20704, 'step': 1500, 'algorithm': 'task_scheduling'}
I0831 18:14:54.169509 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.882, val scores are: activity_selector: 0.823, task_scheduling: 0.942
I0831 18:14:55.251196 138047105189376 run.py:707] Algo activity_selector step 1550 current loss 0.952267, current_train_items 21392.
I0831 18:14:55.255726 138047105189376 run.py:707] Algo task_scheduling step 1550 current loss 2.186204, current_train_items 21392.
I0831 18:14:55.272156 138047105189376 run.py:742] (val) algo activity_selector step 1550: {'selected': 0.8473282442748091, 'score': 0.8473282442748091, 'examples_seen': 21392, 'step': 1550, 'algorithm': 'activity_selector'}
I0831 18:14:55.279717 138047105189376 run.py:742] (val) algo task_scheduling step 1550: {'selected': 0.9228486646884273, 'score': 0.9228486646884273, 'examples_seen': 21392, 'step': 1550, 'algorithm': 'task_scheduling'}
I0831 18:14:55.279860 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.885, val scores are: activity_selector: 0.847, task_scheduling: 0.923
I0831 18:14:56.332251 138047105189376 run.py:707] Algo activity_selector step 1600 current loss 0.882935, current_train_items 22096.
I0831 18:14:56.336662 138047105189376 run.py:707] Algo task_scheduling step 1600 current loss 2.112070, current_train_items 22096.
I0831 18:14:56.353339 138047105189376 run.py:742] (val) algo activity_selector step 1600: {'selected': 0.8460111317254174, 'score': 0.8460111317254174, 'examples_seen': 22096, 'step': 1600, 'algorithm': 'activity_selector'}
I0831 18:14:56.360965 138047105189376 run.py:742] (val) algo task_scheduling step 1600: {'selected': 0.9264705882352942, 'score': 0.9264705882352942, 'examples_seen': 22096, 'step': 1600, 'algorithm': 'task_scheduling'}
I0831 18:14:56.361107 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.886, val scores are: activity_selector: 0.846, task_scheduling: 0.926
I0831 18:14:57.410287 138047105189376 run.py:707] Algo activity_selector step 1650 current loss 1.117715, current_train_items 22768.
I0831 18:14:57.415156 138047105189376 run.py:707] Algo task_scheduling step 1650 current loss 2.438815, current_train_items 22768.
I0831 18:14:57.432042 138047105189376 run.py:742] (val) algo activity_selector step 1650: {'selected': 0.8084291187739463, 'score': 0.8084291187739463, 'examples_seen': 22768, 'step': 1650, 'algorithm': 'activity_selector'}
I0831 18:14:57.439621 138047105189376 run.py:742] (val) algo task_scheduling step 1650: {'selected': 0.9455630126771065, 'score': 0.9455630126771065, 'examples_seen': 22768, 'step': 1650, 'algorithm': 'task_scheduling'}
I0831 18:14:57.439775 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.877, val scores are: activity_selector: 0.808, task_scheduling: 0.946
I0831 18:14:58.502935 138047105189376 run.py:707] Algo activity_selector step 1700 current loss 0.830582, current_train_items 23456.
I0831 18:14:58.507449 138047105189376 run.py:707] Algo task_scheduling step 1700 current loss 2.222587, current_train_items 23456.
I0831 18:14:58.523914 138047105189376 run.py:742] (val) algo activity_selector step 1700: {'selected': 0.8016877637130801, 'score': 0.8016877637130801, 'examples_seen': 23456, 'step': 1700, 'algorithm': 'activity_selector'}
I0831 18:14:58.531468 138047105189376 run.py:742] (val) algo task_scheduling step 1700: {'selected': 0.9316420014094432, 'score': 0.9316420014094432, 'examples_seen': 23456, 'step': 1700, 'algorithm': 'task_scheduling'}
I0831 18:14:58.531610 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.867, val scores are: activity_selector: 0.802, task_scheduling: 0.932
I0831 18:14:59.582980 138047105189376 run.py:707] Algo activity_selector step 1750 current loss 1.279581, current_train_items 24160.
I0831 18:14:59.587486 138047105189376 run.py:707] Algo task_scheduling step 1750 current loss 1.938554, current_train_items 24160.
I0831 18:14:59.604154 138047105189376 run.py:742] (val) algo activity_selector step 1750: {'selected': 0.8283185840707965, 'score': 0.8283185840707965, 'examples_seen': 24160, 'step': 1750, 'algorithm': 'activity_selector'}
I0831 18:14:59.611761 138047105189376 run.py:742] (val) algo task_scheduling step 1750: {'selected': 0.9092169092169092, 'score': 0.9092169092169092, 'examples_seen': 24160, 'step': 1750, 'algorithm': 'task_scheduling'}
I0831 18:14:59.611903 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.869, val scores are: activity_selector: 0.828, task_scheduling: 0.909
I0831 18:15:00.670217 138047105189376 run.py:707] Algo activity_selector step 1800 current loss 1.198871, current_train_items 24832.
I0831 18:15:00.674608 138047105189376 run.py:707] Algo task_scheduling step 1800 current loss 3.386278, current_train_items 24832.
I0831 18:15:00.691570 138047105189376 run.py:742] (val) algo activity_selector step 1800: {'selected': 0.8273092369477912, 'score': 0.8273092369477912, 'examples_seen': 24832, 'step': 1800, 'algorithm': 'activity_selector'}
I0831 18:15:00.699391 138047105189376 run.py:742] (val) algo task_scheduling step 1800: {'selected': 0.9381818181818182, 'score': 0.9381818181818182, 'examples_seen': 24832, 'step': 1800, 'algorithm': 'task_scheduling'}
I0831 18:15:00.699545 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.883, val scores are: activity_selector: 0.827, task_scheduling: 0.938
I0831 18:15:01.761732 138047105189376 run.py:707] Algo activity_selector step 1850 current loss 0.640267, current_train_items 25536.
I0831 18:15:01.766334 138047105189376 run.py:707] Algo task_scheduling step 1850 current loss 3.367856, current_train_items 25536.
I0831 18:15:01.782034 138047105189376 run.py:742] (val) algo activity_selector step 1850: {'selected': 0.822857142857143, 'score': 0.822857142857143, 'examples_seen': 25536, 'step': 1850, 'algorithm': 'activity_selector'}
I0831 18:15:01.789585 138047105189376 run.py:742] (val) algo task_scheduling step 1850: {'selected': 0.9301340860973888, 'score': 0.9301340860973888, 'examples_seen': 25536, 'step': 1850, 'algorithm': 'task_scheduling'}
I0831 18:15:01.789730 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.876, val scores are: activity_selector: 0.823, task_scheduling: 0.930
I0831 18:15:02.843726 138047105189376 run.py:707] Algo activity_selector step 1900 current loss 0.966326, current_train_items 26224.
I0831 18:15:02.848014 138047105189376 run.py:707] Algo task_scheduling step 1900 current loss 2.599183, current_train_items 26224.
I0831 18:15:02.865122 138047105189376 run.py:742] (val) algo activity_selector step 1900: {'selected': 0.8180242634315424, 'score': 0.8180242634315424, 'examples_seen': 26224, 'step': 1900, 'algorithm': 'activity_selector'}
I0831 18:15:02.872682 138047105189376 run.py:742] (val) algo task_scheduling step 1900: {'selected': 0.9359406608226568, 'score': 0.9359406608226568, 'examples_seen': 26224, 'step': 1900, 'algorithm': 'task_scheduling'}
I0831 18:15:02.872830 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.877, val scores are: activity_selector: 0.818, task_scheduling: 0.936
I0831 18:15:03.916865 138047105189376 run.py:707] Algo activity_selector step 1950 current loss 0.607980, current_train_items 26912.
I0831 18:15:03.921273 138047105189376 run.py:707] Algo task_scheduling step 1950 current loss 2.613509, current_train_items 26912.
I0831 18:15:03.938006 138047105189376 run.py:742] (val) algo activity_selector step 1950: {'selected': 0.8333333333333334, 'score': 0.8333333333333334, 'examples_seen': 26912, 'step': 1950, 'algorithm': 'activity_selector'}
I0831 18:15:03.945600 138047105189376 run.py:742] (val) algo task_scheduling step 1950: {'selected': 0.9320809248554913, 'score': 0.9320809248554913, 'examples_seen': 26912, 'step': 1950, 'algorithm': 'task_scheduling'}
I0831 18:15:03.945744 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.883, val scores are: activity_selector: 0.833, task_scheduling: 0.932
I0831 18:15:05.000818 138047105189376 run.py:707] Algo activity_selector step 2000 current loss 0.933104, current_train_items 27600.
I0831 18:15:05.005244 138047105189376 run.py:707] Algo task_scheduling step 2000 current loss 2.393757, current_train_items 27600.
I0831 18:15:05.021971 138047105189376 run.py:742] (val) algo activity_selector step 2000: {'selected': 0.8404255319148937, 'score': 0.8404255319148937, 'examples_seen': 27600, 'step': 2000, 'algorithm': 'activity_selector'}
I0831 18:15:05.029522 138047105189376 run.py:742] (val) algo task_scheduling step 2000: {'selected': 0.9300998573466476, 'score': 0.9300998573466476, 'examples_seen': 27600, 'step': 2000, 'algorithm': 'task_scheduling'}
I0831 18:15:05.029669 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.885, val scores are: activity_selector: 0.840, task_scheduling: 0.930
I0831 18:15:06.051867 138047105189376 run.py:707] Algo activity_selector step 2050 current loss 1.120328, current_train_items 28288.
I0831 18:15:06.056660 138047105189376 run.py:707] Algo task_scheduling step 2050 current loss 2.790047, current_train_items 28288.
I0831 18:15:06.072857 138047105189376 run.py:742] (val) algo activity_selector step 2050: {'selected': 0.8253968253968255, 'score': 0.8253968253968255, 'examples_seen': 28288, 'step': 2050, 'algorithm': 'activity_selector'}
I0831 18:15:06.080433 138047105189376 run.py:742] (val) algo task_scheduling step 2050: {'selected': 0.9274755927475593, 'score': 0.9274755927475593, 'examples_seen': 28288, 'step': 2050, 'algorithm': 'task_scheduling'}
I0831 18:15:06.080574 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.890, current avg val score is 0.876, val scores are: activity_selector: 0.825, task_scheduling: 0.927
I0831 18:15:07.124955 138047105189376 run.py:707] Algo activity_selector step 2100 current loss 1.098535, current_train_items 28976.
I0831 18:15:07.129330 138047105189376 run.py:707] Algo task_scheduling step 2100 current loss 3.222408, current_train_items 28976.
I0831 18:15:07.145232 138047105189376 run.py:742] (val) algo activity_selector step 2100: {'selected': 0.8422939068100358, 'score': 0.8422939068100358, 'examples_seen': 28976, 'step': 2100, 'algorithm': 'activity_selector'}
I0831 18:15:07.152804 138047105189376 run.py:742] (val) algo task_scheduling step 2100: {'selected': 0.9399855386840202, 'score': 0.9399855386840202, 'examples_seen': 28976, 'step': 2100, 'algorithm': 'task_scheduling'}
I0831 18:15:07.152956 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.890, current avg val score is 0.891, val scores are: activity_selector: 0.842, task_scheduling: 0.940
I0831 18:15:08.208012 138047105189376 run.py:707] Algo activity_selector step 2150 current loss 1.009769, current_train_items 29664.
I0831 18:15:08.212316 138047105189376 run.py:707] Algo task_scheduling step 2150 current loss 2.267934, current_train_items 29664.
I0831 18:15:08.229003 138047105189376 run.py:742] (val) algo activity_selector step 2150: {'selected': 0.8317214700193424, 'score': 0.8317214700193424, 'examples_seen': 29664, 'step': 2150, 'algorithm': 'activity_selector'}
I0831 18:15:08.236546 138047105189376 run.py:742] (val) algo task_scheduling step 2150: {'selected': 0.9353383458646617, 'score': 0.9353383458646617, 'examples_seen': 29664, 'step': 2150, 'algorithm': 'task_scheduling'}
I0831 18:15:08.236688 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.891, current avg val score is 0.884, val scores are: activity_selector: 0.832, task_scheduling: 0.935
I0831 18:15:09.262877 138047105189376 run.py:707] Algo activity_selector step 2200 current loss 0.976082, current_train_items 30368.
I0831 18:15:09.267181 138047105189376 run.py:707] Algo task_scheduling step 2200 current loss 2.242949, current_train_items 30368.
I0831 18:15:09.283953 138047105189376 run.py:742] (val) algo activity_selector step 2200: {'selected': 0.8226691042047531, 'score': 0.8226691042047531, 'examples_seen': 30368, 'step': 2200, 'algorithm': 'activity_selector'}
I0831 18:15:09.291666 138047105189376 run.py:742] (val) algo task_scheduling step 2200: {'selected': 0.9353717859624738, 'score': 0.9353717859624738, 'examples_seen': 30368, 'step': 2200, 'algorithm': 'task_scheduling'}
I0831 18:15:09.291820 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.891, current avg val score is 0.879, val scores are: activity_selector: 0.823, task_scheduling: 0.935
I0831 18:15:10.342902 138047105189376 run.py:707] Algo activity_selector step 2250 current loss 0.740874, current_train_items 31040.
I0831 18:15:10.347341 138047105189376 run.py:707] Algo task_scheduling step 2250 current loss 2.012554, current_train_items 31040.
I0831 18:15:10.364925 138047105189376 run.py:742] (val) algo activity_selector step 2250: {'selected': 0.8159392789373815, 'score': 0.8159392789373815, 'examples_seen': 31040, 'step': 2250, 'algorithm': 'activity_selector'}
I0831 18:15:10.372582 138047105189376 run.py:742] (val) algo task_scheduling step 2250: {'selected': 0.9448818897637794, 'score': 0.9448818897637794, 'examples_seen': 31040, 'step': 2250, 'algorithm': 'task_scheduling'}
I0831 18:15:10.372727 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.891, current avg val score is 0.880, val scores are: activity_selector: 0.816, task_scheduling: 0.945
I0831 18:15:11.409184 138047105189376 run.py:707] Algo activity_selector step 2300 current loss 0.823178, current_train_items 31728.
I0831 18:15:11.413657 138047105189376 run.py:707] Algo task_scheduling step 2300 current loss 1.688311, current_train_items 31728.
I0831 18:15:11.429836 138047105189376 run.py:742] (val) algo activity_selector step 2300: {'selected': 0.8775137111517368, 'score': 0.8775137111517368, 'examples_seen': 31728, 'step': 2300, 'algorithm': 'activity_selector'}
I0831 18:15:11.437396 138047105189376 run.py:742] (val) algo task_scheduling step 2300: {'selected': 0.9202200825309491, 'score': 0.9202200825309491, 'examples_seen': 31728, 'step': 2300, 'algorithm': 'task_scheduling'}
I0831 18:15:11.437539 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.891, current avg val score is 0.899, val scores are: activity_selector: 0.878, task_scheduling: 0.920
I0831 18:15:12.497551 138047105189376 run.py:707] Algo activity_selector step 2350 current loss 0.746823, current_train_items 32432.
I0831 18:15:12.502022 138047105189376 run.py:707] Algo task_scheduling step 2350 current loss 1.906916, current_train_items 32432.
I0831 18:15:12.518142 138047105189376 run.py:742] (val) algo activity_selector step 2350: {'selected': 0.8522920203735145, 'score': 0.8522920203735145, 'examples_seen': 32432, 'step': 2350, 'algorithm': 'activity_selector'}
I0831 18:15:12.525721 138047105189376 run.py:742] (val) algo task_scheduling step 2350: {'selected': 0.9260808926080893, 'score': 0.9260808926080893, 'examples_seen': 32432, 'step': 2350, 'algorithm': 'task_scheduling'}
I0831 18:15:12.525864 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.899, current avg val score is 0.889, val scores are: activity_selector: 0.852, task_scheduling: 0.926
I0831 18:15:13.582735 138047105189376 run.py:707] Algo activity_selector step 2400 current loss 1.070842, current_train_items 33104.
I0831 18:15:13.587295 138047105189376 run.py:707] Algo task_scheduling step 2400 current loss 2.330871, current_train_items 33104.
I0831 18:15:13.603797 138047105189376 run.py:742] (val) algo activity_selector step 2400: {'selected': 0.804642166344294, 'score': 0.804642166344294, 'examples_seen': 33104, 'step': 2400, 'algorithm': 'activity_selector'}
I0831 18:15:13.611434 138047105189376 run.py:742] (val) algo task_scheduling step 2400: {'selected': 0.9456598447424136, 'score': 0.9456598447424136, 'examples_seen': 33104, 'step': 2400, 'algorithm': 'task_scheduling'}
I0831 18:15:13.611578 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.899, current avg val score is 0.875, val scores are: activity_selector: 0.805, task_scheduling: 0.946
I0831 18:15:14.667956 138047105189376 run.py:707] Algo activity_selector step 2450 current loss 0.818398, current_train_items 33808.
I0831 18:15:14.672524 138047105189376 run.py:707] Algo task_scheduling step 2450 current loss 1.984573, current_train_items 33808.
I0831 18:15:14.688443 138047105189376 run.py:742] (val) algo activity_selector step 2450: {'selected': 0.8633093525179856, 'score': 0.8633093525179856, 'examples_seen': 33808, 'step': 2450, 'algorithm': 'activity_selector'}
I0831 18:15:14.696054 138047105189376 run.py:742] (val) algo task_scheduling step 2450: {'selected': 0.9294605809128631, 'score': 0.9294605809128631, 'examples_seen': 33808, 'step': 2450, 'algorithm': 'task_scheduling'}
I0831 18:15:14.696198 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.899, current avg val score is 0.896, val scores are: activity_selector: 0.863, task_scheduling: 0.929
I0831 18:15:15.725381 138047105189376 run.py:707] Algo activity_selector step 2500 current loss 0.808745, current_train_items 34496.
I0831 18:15:15.729990 138047105189376 run.py:707] Algo task_scheduling step 2500 current loss 2.444259, current_train_items 34496.
I0831 18:15:15.746907 138047105189376 run.py:742] (val) algo activity_selector step 2500: {'selected': 0.8221343873517787, 'score': 0.8221343873517787, 'examples_seen': 34496, 'step': 2500, 'algorithm': 'activity_selector'}
I0831 18:15:15.754475 138047105189376 run.py:742] (val) algo task_scheduling step 2500: {'selected': 0.9384615384615385, 'score': 0.9384615384615385, 'examples_seen': 34496, 'step': 2500, 'algorithm': 'task_scheduling'}
I0831 18:15:15.754619 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.899, current avg val score is 0.880, val scores are: activity_selector: 0.822, task_scheduling: 0.938
I0831 18:15:16.791632 138047105189376 run.py:707] Algo activity_selector step 2550 current loss 0.793507, current_train_items 35184.
I0831 18:15:16.797033 138047105189376 run.py:707] Algo task_scheduling step 2550 current loss 2.039851, current_train_items 35184.
I0831 18:15:16.812952 138047105189376 run.py:742] (val) algo activity_selector step 2550: {'selected': 0.8429118773946361, 'score': 0.8429118773946361, 'examples_seen': 35184, 'step': 2550, 'algorithm': 'activity_selector'}
I0831 18:15:16.820486 138047105189376 run.py:742] (val) algo task_scheduling step 2550: {'selected': 0.9394366197183098, 'score': 0.9394366197183098, 'examples_seen': 35184, 'step': 2550, 'algorithm': 'task_scheduling'}
I0831 18:15:16.820631 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.899, current avg val score is 0.891, val scores are: activity_selector: 0.843, task_scheduling: 0.939
I0831 18:15:17.880261 138047105189376 run.py:707] Algo activity_selector step 2600 current loss 0.852057, current_train_items 35872.
I0831 18:15:17.884697 138047105189376 run.py:707] Algo task_scheduling step 2600 current loss 2.327156, current_train_items 35872.
I0831 18:15:17.901233 138047105189376 run.py:742] (val) algo activity_selector step 2600: {'selected': 0.8183421516754851, 'score': 0.8183421516754851, 'examples_seen': 35872, 'step': 2600, 'algorithm': 'activity_selector'}
I0831 18:15:17.908780 138047105189376 run.py:742] (val) algo task_scheduling step 2600: {'selected': 0.9258698940998488, 'score': 0.9258698940998488, 'examples_seen': 35872, 'step': 2600, 'algorithm': 'task_scheduling'}
I0831 18:15:17.908921 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.899, current avg val score is 0.872, val scores are: activity_selector: 0.818, task_scheduling: 0.926
I0831 18:15:18.924310 138047105189376 run.py:707] Algo activity_selector step 2650 current loss 0.829915, current_train_items 36560.
I0831 18:15:18.928763 138047105189376 run.py:707] Algo task_scheduling step 2650 current loss 1.927600, current_train_items 36560.
I0831 18:15:18.945442 138047105189376 run.py:742] (val) algo activity_selector step 2650: {'selected': 0.864376130198915, 'score': 0.864376130198915, 'examples_seen': 36560, 'step': 2650, 'algorithm': 'activity_selector'}
I0831 18:15:18.952955 138047105189376 run.py:742] (val) algo task_scheduling step 2650: {'selected': 0.9411764705882353, 'score': 0.9411764705882353, 'examples_seen': 36560, 'step': 2650, 'algorithm': 'task_scheduling'}
I0831 18:15:18.953098 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.899, current avg val score is 0.903, val scores are: activity_selector: 0.864, task_scheduling: 0.941
I0831 18:15:20.018059 138047105189376 run.py:707] Algo activity_selector step 2700 current loss 0.939560, current_train_items 37248.
I0831 18:15:20.022365 138047105189376 run.py:707] Algo task_scheduling step 2700 current loss 2.318992, current_train_items 37248.
I0831 18:15:20.039134 138047105189376 run.py:742] (val) algo activity_selector step 2700: {'selected': 0.9013035381750466, 'score': 0.9013035381750466, 'examples_seen': 37248, 'step': 2700, 'algorithm': 'activity_selector'}
I0831 18:15:20.046706 138047105189376 run.py:742] (val) algo task_scheduling step 2700: {'selected': 0.924907063197026, 'score': 0.924907063197026, 'examples_seen': 37248, 'step': 2700, 'algorithm': 'task_scheduling'}
I0831 18:15:20.046850 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.903, current avg val score is 0.913, val scores are: activity_selector: 0.901, task_scheduling: 0.925
I0831 18:15:21.108503 138047105189376 run.py:707] Algo activity_selector step 2750 current loss 1.333898, current_train_items 37936.
I0831 18:15:21.112947 138047105189376 run.py:707] Algo task_scheduling step 2750 current loss 2.026318, current_train_items 37936.
I0831 18:15:21.129329 138047105189376 run.py:742] (val) algo activity_selector step 2750: {'selected': 0.8330404217926187, 'score': 0.8330404217926187, 'examples_seen': 37936, 'step': 2750, 'algorithm': 'activity_selector'}
I0831 18:15:21.136924 138047105189376 run.py:742] (val) algo task_scheduling step 2750: {'selected': 0.920656634746922, 'score': 0.920656634746922, 'examples_seen': 37936, 'step': 2750, 'algorithm': 'task_scheduling'}
I0831 18:15:21.137075 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.913, current avg val score is 0.877, val scores are: activity_selector: 0.833, task_scheduling: 0.921
I0831 18:15:22.178133 138047105189376 run.py:707] Algo activity_selector step 2800 current loss 0.599852, current_train_items 38640.
I0831 18:15:22.182813 138047105189376 run.py:707] Algo task_scheduling step 2800 current loss 1.758877, current_train_items 38640.
I0831 18:15:22.201268 138047105189376 run.py:742] (val) algo activity_selector step 2800: {'selected': 0.837121212121212, 'score': 0.837121212121212, 'examples_seen': 38640, 'step': 2800, 'algorithm': 'activity_selector'}
I0831 18:15:22.208854 138047105189376 run.py:742] (val) algo task_scheduling step 2800: {'selected': 0.9393290506780871, 'score': 0.9393290506780871, 'examples_seen': 38640, 'step': 2800, 'algorithm': 'task_scheduling'}
I0831 18:15:22.209027 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.913, current avg val score is 0.888, val scores are: activity_selector: 0.837, task_scheduling: 0.939
I0831 18:15:23.327031 138047105189376 run.py:707] Algo activity_selector step 2850 current loss 0.613581, current_train_items 39312.
I0831 18:15:23.331367 138047105189376 run.py:707] Algo task_scheduling step 2850 current loss 2.269870, current_train_items 39312.
I0831 18:15:23.347793 138047105189376 run.py:742] (val) algo activity_selector step 2850: {'selected': 0.8754716981132076, 'score': 0.8754716981132076, 'examples_seen': 39312, 'step': 2850, 'algorithm': 'activity_selector'}
I0831 18:15:23.355314 138047105189376 run.py:742] (val) algo task_scheduling step 2850: {'selected': 0.927877947295423, 'score': 0.927877947295423, 'examples_seen': 39312, 'step': 2850, 'algorithm': 'task_scheduling'}
I0831 18:15:23.355458 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.913, current avg val score is 0.902, val scores are: activity_selector: 0.875, task_scheduling: 0.928
I0831 18:15:24.409157 138047105189376 run.py:707] Algo activity_selector step 2900 current loss 0.771884, current_train_items 40016.
I0831 18:15:24.413863 138047105189376 run.py:707] Algo task_scheduling step 2900 current loss 1.972226, current_train_items 40016.
I0831 18:15:24.430000 138047105189376 run.py:742] (val) algo activity_selector step 2900: {'selected': 0.8571428571428571, 'score': 0.8571428571428571, 'examples_seen': 40016, 'step': 2900, 'algorithm': 'activity_selector'}
I0831 18:15:24.437514 138047105189376 run.py:742] (val) algo task_scheduling step 2900: {'selected': 0.9434250764525994, 'score': 0.9434250764525994, 'examples_seen': 40016, 'step': 2900, 'algorithm': 'task_scheduling'}
I0831 18:15:24.437656 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.913, current avg val score is 0.900, val scores are: activity_selector: 0.857, task_scheduling: 0.943
I0831 18:15:25.483610 138047105189376 run.py:707] Algo activity_selector step 2950 current loss 0.509775, current_train_items 40704.
I0831 18:15:25.488012 138047105189376 run.py:707] Algo task_scheduling step 2950 current loss 1.733484, current_train_items 40704.
I0831 18:15:25.504899 138047105189376 run.py:742] (val) algo activity_selector step 2950: {'selected': 0.8736462093862815, 'score': 0.8736462093862815, 'examples_seen': 40704, 'step': 2950, 'algorithm': 'activity_selector'}
I0831 18:15:25.512397 138047105189376 run.py:742] (val) algo task_scheduling step 2950: {'selected': 0.9554597701149425, 'score': 0.9554597701149425, 'examples_seen': 40704, 'step': 2950, 'algorithm': 'task_scheduling'}
I0831 18:15:25.512535 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.913, current avg val score is 0.915, val scores are: activity_selector: 0.874, task_scheduling: 0.955
I0831 18:15:26.551645 138047105189376 run.py:707] Algo activity_selector step 3000 current loss 0.772531, current_train_items 41376.
I0831 18:15:26.556049 138047105189376 run.py:707] Algo task_scheduling step 3000 current loss 2.552492, current_train_items 41376.
I0831 18:15:26.574146 138047105189376 run.py:742] (val) algo activity_selector step 3000: {'selected': 0.8484848484848485, 'score': 0.8484848484848485, 'examples_seen': 41376, 'step': 3000, 'algorithm': 'activity_selector'}
I0831 18:15:26.581639 138047105189376 run.py:742] (val) algo task_scheduling step 3000: {'selected': 0.8989966555183946, 'score': 0.8989966555183946, 'examples_seen': 41376, 'step': 3000, 'algorithm': 'task_scheduling'}
I0831 18:15:26.581783 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.915, current avg val score is 0.874, val scores are: activity_selector: 0.848, task_scheduling: 0.899
I0831 18:15:27.654056 138047105189376 run.py:707] Algo activity_selector step 3050 current loss 1.190396, current_train_items 42080.
I0831 18:15:27.658516 138047105189376 run.py:707] Algo task_scheduling step 3050 current loss 1.678941, current_train_items 42080.
I0831 18:15:27.675398 138047105189376 run.py:742] (val) algo activity_selector step 3050: {'selected': 0.8346774193548387, 'score': 0.8346774193548387, 'examples_seen': 42080, 'step': 3050, 'algorithm': 'activity_selector'}
I0831 18:15:27.682980 138047105189376 run.py:742] (val) algo task_scheduling step 3050: {'selected': 0.9452954048140044, 'score': 0.9452954048140044, 'examples_seen': 42080, 'step': 3050, 'algorithm': 'task_scheduling'}
I0831 18:15:27.683124 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.915, current avg val score is 0.890, val scores are: activity_selector: 0.835, task_scheduling: 0.945
I0831 18:15:28.731099 138047105189376 run.py:707] Algo activity_selector step 3100 current loss 0.648259, current_train_items 42768.
I0831 18:15:28.735926 138047105189376 run.py:707] Algo task_scheduling step 3100 current loss 1.811803, current_train_items 42768.
I0831 18:15:28.752217 138047105189376 run.py:742] (val) algo activity_selector step 3100: {'selected': 0.8208695652173913, 'score': 0.8208695652173913, 'examples_seen': 42768, 'step': 3100, 'algorithm': 'activity_selector'}
I0831 18:15:28.759803 138047105189376 run.py:742] (val) algo task_scheduling step 3100: {'selected': 0.9430656934306569, 'score': 0.9430656934306569, 'examples_seen': 42768, 'step': 3100, 'algorithm': 'task_scheduling'}
I0831 18:15:28.759956 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.915, current avg val score is 0.882, val scores are: activity_selector: 0.821, task_scheduling: 0.943
I0831 18:15:29.798527 138047105189376 run.py:707] Algo activity_selector step 3150 current loss 0.813059, current_train_items 43440.
I0831 18:15:29.802766 138047105189376 run.py:707] Algo task_scheduling step 3150 current loss 1.896465, current_train_items 43440.
I0831 18:15:29.819159 138047105189376 run.py:742] (val) algo activity_selector step 3150: {'selected': 0.8350515463917525, 'score': 0.8350515463917525, 'examples_seen': 43440, 'step': 3150, 'algorithm': 'activity_selector'}
I0831 18:15:29.826874 138047105189376 run.py:742] (val) algo task_scheduling step 3150: {'selected': 0.9467275494672756, 'score': 0.9467275494672756, 'examples_seen': 43440, 'step': 3150, 'algorithm': 'task_scheduling'}
I0831 18:15:29.827028 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.915, current avg val score is 0.891, val scores are: activity_selector: 0.835, task_scheduling: 0.947
I0831 18:15:30.888792 138047105189376 run.py:707] Algo activity_selector step 3200 current loss 1.032264, current_train_items 44144.
I0831 18:15:30.893370 138047105189376 run.py:707] Algo task_scheduling step 3200 current loss 1.870027, current_train_items 44144.
I0831 18:15:30.909911 138047105189376 run.py:742] (val) algo activity_selector step 3200: {'selected': 0.8244274809160305, 'score': 0.8244274809160305, 'examples_seen': 44144, 'step': 3200, 'algorithm': 'activity_selector'}
I0831 18:15:30.917455 138047105189376 run.py:742] (val) algo task_scheduling step 3200: {'selected': 0.9108910891089108, 'score': 0.9108910891089108, 'examples_seen': 44144, 'step': 3200, 'algorithm': 'task_scheduling'}
I0831 18:15:30.917599 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.915, current avg val score is 0.868, val scores are: activity_selector: 0.824, task_scheduling: 0.911
I0831 18:15:31.943254 138047105189376 run.py:707] Algo activity_selector step 3250 current loss 0.979639, current_train_items 44848.
I0831 18:15:31.947624 138047105189376 run.py:707] Algo task_scheduling step 3250 current loss 2.058371, current_train_items 44848.
I0831 18:15:31.963569 138047105189376 run.py:742] (val) algo activity_selector step 3250: {'selected': 0.8346153846153846, 'score': 0.8346153846153846, 'examples_seen': 44848, 'step': 3250, 'algorithm': 'activity_selector'}
I0831 18:15:31.971197 138047105189376 run.py:742] (val) algo task_scheduling step 3250: {'selected': 0.9257460097154754, 'score': 0.9257460097154754, 'examples_seen': 44848, 'step': 3250, 'algorithm': 'task_scheduling'}
I0831 18:15:31.971340 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.915, current avg val score is 0.880, val scores are: activity_selector: 0.835, task_scheduling: 0.926
I0831 18:15:33.024750 138047105189376 run.py:707] Algo activity_selector step 3300 current loss 1.183922, current_train_items 45520.
I0831 18:15:33.029077 138047105189376 run.py:707] Algo task_scheduling step 3300 current loss 1.610413, current_train_items 45520.
I0831 18:15:33.045562 138047105189376 run.py:742] (val) algo activity_selector step 3300: {'selected': 0.8548057259713701, 'score': 0.8548057259713701, 'examples_seen': 45520, 'step': 3300, 'algorithm': 'activity_selector'}
I0831 18:15:33.053124 138047105189376 run.py:742] (val) algo task_scheduling step 3300: {'selected': 0.8852883992222943, 'score': 0.8852883992222943, 'examples_seen': 45520, 'step': 3300, 'algorithm': 'task_scheduling'}
I0831 18:15:33.053269 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.915, current avg val score is 0.870, val scores are: activity_selector: 0.855, task_scheduling: 0.885
I0831 18:15:34.094570 138047105189376 run.py:707] Algo activity_selector step 3350 current loss 0.811216, current_train_items 46208.
I0831 18:15:34.099172 138047105189376 run.py:707] Algo task_scheduling step 3350 current loss 1.911013, current_train_items 46208.
I0831 18:15:34.115484 138047105189376 run.py:742] (val) algo activity_selector step 3350: {'selected': 0.8848920863309353, 'score': 0.8848920863309353, 'examples_seen': 46208, 'step': 3350, 'algorithm': 'activity_selector'}
I0831 18:15:34.123034 138047105189376 run.py:742] (val) algo task_scheduling step 3350: {'selected': 0.9434752267969294, 'score': 0.9434752267969294, 'examples_seen': 46208, 'step': 3350, 'algorithm': 'task_scheduling'}
I0831 18:15:34.123178 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.915, current avg val score is 0.914, val scores are: activity_selector: 0.885, task_scheduling: 0.943
I0831 18:15:35.160498 138047105189376 run.py:707] Algo activity_selector step 3400 current loss 0.888903, current_train_items 46912.
I0831 18:15:35.164867 138047105189376 run.py:707] Algo task_scheduling step 3400 current loss 1.653355, current_train_items 46912.
I0831 18:15:35.180996 138047105189376 run.py:742] (val) algo activity_selector step 3400: {'selected': 0.8760907504363002, 'score': 0.8760907504363002, 'examples_seen': 46912, 'step': 3400, 'algorithm': 'activity_selector'}
I0831 18:15:35.188826 138047105189376 run.py:742] (val) algo task_scheduling step 3400: {'selected': 0.9581804842259721, 'score': 0.9581804842259721, 'examples_seen': 46912, 'step': 3400, 'algorithm': 'task_scheduling'}
I0831 18:15:35.188977 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.915, current avg val score is 0.917, val scores are: activity_selector: 0.876, task_scheduling: 0.958
I0831 18:15:36.246240 138047105189376 run.py:707] Algo activity_selector step 3450 current loss 0.496086, current_train_items 47584.
I0831 18:15:36.250754 138047105189376 run.py:707] Algo task_scheduling step 3450 current loss 2.073923, current_train_items 47584.
I0831 18:15:36.269825 138047105189376 run.py:742] (val) algo activity_selector step 3450: {'selected': 0.850828729281768, 'score': 0.850828729281768, 'examples_seen': 47584, 'step': 3450, 'algorithm': 'activity_selector'}
I0831 18:15:36.277527 138047105189376 run.py:742] (val) algo task_scheduling step 3450: {'selected': 0.9369747899159664, 'score': 0.9369747899159664, 'examples_seen': 47584, 'step': 3450, 'algorithm': 'task_scheduling'}
I0831 18:15:36.277686 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.917, current avg val score is 0.894, val scores are: activity_selector: 0.851, task_scheduling: 0.937
I0831 18:15:37.315599 138047105189376 run.py:707] Algo activity_selector step 3500 current loss 0.663812, current_train_items 48272.
I0831 18:15:37.319884 138047105189376 run.py:707] Algo task_scheduling step 3500 current loss 1.827552, current_train_items 48272.
I0831 18:15:37.336306 138047105189376 run.py:742] (val) algo activity_selector step 3500: {'selected': 0.8776699029126213, 'score': 0.8776699029126213, 'examples_seen': 48272, 'step': 3500, 'algorithm': 'activity_selector'}
I0831 18:15:37.343973 138047105189376 run.py:742] (val) algo task_scheduling step 3500: {'selected': 0.955096222380613, 'score': 0.955096222380613, 'examples_seen': 48272, 'step': 3500, 'algorithm': 'task_scheduling'}
I0831 18:15:37.344120 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.917, current avg val score is 0.916, val scores are: activity_selector: 0.878, task_scheduling: 0.955
I0831 18:15:38.395251 138047105189376 run.py:707] Algo activity_selector step 3550 current loss 0.527159, current_train_items 48976.
I0831 18:15:38.399751 138047105189376 run.py:707] Algo task_scheduling step 3550 current loss 1.802379, current_train_items 48976.
I0831 18:15:38.416232 138047105189376 run.py:742] (val) algo activity_selector step 3550: {'selected': 0.8465804066543438, 'score': 0.8465804066543438, 'examples_seen': 48976, 'step': 3550, 'algorithm': 'activity_selector'}
I0831 18:15:38.423845 138047105189376 run.py:742] (val) algo task_scheduling step 3550: {'selected': 0.9447236180904522, 'score': 0.9447236180904522, 'examples_seen': 48976, 'step': 3550, 'algorithm': 'task_scheduling'}
I0831 18:15:38.423999 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.917, current avg val score is 0.896, val scores are: activity_selector: 0.847, task_scheduling: 0.945
I0831 18:15:39.474865 138047105189376 run.py:707] Algo activity_selector step 3600 current loss 0.975613, current_train_items 49664.
I0831 18:15:39.479559 138047105189376 run.py:707] Algo task_scheduling step 3600 current loss 2.523388, current_train_items 49664.
I0831 18:15:39.496632 138047105189376 run.py:742] (val) algo activity_selector step 3600: {'selected': 0.8850574712643678, 'score': 0.8850574712643678, 'examples_seen': 49664, 'step': 3600, 'algorithm': 'activity_selector'}
I0831 18:15:39.504379 138047105189376 run.py:742] (val) algo task_scheduling step 3600: {'selected': 0.9339622641509434, 'score': 0.9339622641509434, 'examples_seen': 49664, 'step': 3600, 'algorithm': 'task_scheduling'}
I0831 18:15:39.504523 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.917, current avg val score is 0.910, val scores are: activity_selector: 0.885, task_scheduling: 0.934
I0831 18:15:40.551226 138047105189376 run.py:707] Algo activity_selector step 3650 current loss 0.739202, current_train_items 50352.
I0831 18:15:40.555754 138047105189376 run.py:707] Algo task_scheduling step 3650 current loss 1.736373, current_train_items 50352.
I0831 18:15:40.573246 138047105189376 run.py:742] (val) algo activity_selector step 3650: {'selected': 0.9123434704830055, 'score': 0.9123434704830055, 'examples_seen': 50352, 'step': 3650, 'algorithm': 'activity_selector'}
I0831 18:15:40.580986 138047105189376 run.py:742] (val) algo task_scheduling step 3650: {'selected': 0.9433170048985304, 'score': 0.9433170048985304, 'examples_seen': 50352, 'step': 3650, 'algorithm': 'task_scheduling'}
I0831 18:15:40.581131 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.917, current avg val score is 0.928, val scores are: activity_selector: 0.912, task_scheduling: 0.943
I0831 18:15:41.639298 138047105189376 run.py:707] Algo activity_selector step 3700 current loss 0.860274, current_train_items 51040.
I0831 18:15:41.643706 138047105189376 run.py:707] Algo task_scheduling step 3700 current loss 1.871462, current_train_items 51040.
I0831 18:15:41.659978 138047105189376 run.py:742] (val) algo activity_selector step 3700: {'selected': 0.8823529411764706, 'score': 0.8823529411764706, 'examples_seen': 51040, 'step': 3700, 'algorithm': 'activity_selector'}
I0831 18:15:41.667534 138047105189376 run.py:742] (val) algo task_scheduling step 3700: {'selected': 0.9324804548685146, 'score': 0.9324804548685146, 'examples_seen': 51040, 'step': 3700, 'algorithm': 'task_scheduling'}
I0831 18:15:41.667677 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.907, val scores are: activity_selector: 0.882, task_scheduling: 0.932
I0831 18:15:42.726495 138047105189376 run.py:707] Algo activity_selector step 3750 current loss 0.739004, current_train_items 51728.
I0831 18:15:42.730974 138047105189376 run.py:707] Algo task_scheduling step 3750 current loss 1.573137, current_train_items 51728.
I0831 18:15:42.747179 138047105189376 run.py:742] (val) algo activity_selector step 3750: {'selected': 0.850987432675045, 'score': 0.850987432675045, 'examples_seen': 51728, 'step': 3750, 'algorithm': 'activity_selector'}
I0831 18:15:42.754723 138047105189376 run.py:742] (val) algo task_scheduling step 3750: {'selected': 0.9518248175182481, 'score': 0.9518248175182481, 'examples_seen': 51728, 'step': 3750, 'algorithm': 'task_scheduling'}
I0831 18:15:42.754864 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.901, val scores are: activity_selector: 0.851, task_scheduling: 0.952
I0831 18:15:43.817946 138047105189376 run.py:707] Algo activity_selector step 3800 current loss 0.558706, current_train_items 52416.
I0831 18:15:43.822416 138047105189376 run.py:707] Algo task_scheduling step 3800 current loss 1.781186, current_train_items 52416.
I0831 18:15:43.840934 138047105189376 run.py:742] (val) algo activity_selector step 3800: {'selected': 0.8840579710144927, 'score': 0.8840579710144927, 'examples_seen': 52416, 'step': 3800, 'algorithm': 'activity_selector'}
I0831 18:15:43.848502 138047105189376 run.py:742] (val) algo task_scheduling step 3800: {'selected': 0.939521800281294, 'score': 0.939521800281294, 'examples_seen': 52416, 'step': 3800, 'algorithm': 'task_scheduling'}
I0831 18:15:43.848644 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.912, val scores are: activity_selector: 0.884, task_scheduling: 0.940
I0831 18:15:44.860636 138047105189376 run.py:707] Algo activity_selector step 3850 current loss 1.194652, current_train_items 53104.
I0831 18:15:44.865167 138047105189376 run.py:707] Algo task_scheduling step 3850 current loss 1.243635, current_train_items 53104.
I0831 18:15:44.881938 138047105189376 run.py:742] (val) algo activity_selector step 3850: {'selected': 0.8112874779541446, 'score': 0.8112874779541446, 'examples_seen': 53104, 'step': 3850, 'algorithm': 'activity_selector'}
I0831 18:15:44.889464 138047105189376 run.py:742] (val) algo task_scheduling step 3850: {'selected': 0.9452449567723341, 'score': 0.9452449567723341, 'examples_seen': 53104, 'step': 3850, 'algorithm': 'task_scheduling'}
I0831 18:15:44.889617 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.878, val scores are: activity_selector: 0.811, task_scheduling: 0.945
I0831 18:15:45.961194 138047105189376 run.py:707] Algo activity_selector step 3900 current loss 0.444574, current_train_items 53792.
I0831 18:15:45.965769 138047105189376 run.py:707] Algo task_scheduling step 3900 current loss 1.585593, current_train_items 53792.
I0831 18:15:45.982275 138047105189376 run.py:742] (val) algo activity_selector step 3900: {'selected': 0.8626760563380281, 'score': 0.8626760563380281, 'examples_seen': 53792, 'step': 3900, 'algorithm': 'activity_selector'}
I0831 18:15:45.989837 138047105189376 run.py:742] (val) algo task_scheduling step 3900: {'selected': 0.9430656934306569, 'score': 0.9430656934306569, 'examples_seen': 53792, 'step': 3900, 'algorithm': 'task_scheduling'}
I0831 18:15:45.989984 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.903, val scores are: activity_selector: 0.863, task_scheduling: 0.943
I0831 18:15:47.058573 138047105189376 run.py:707] Algo activity_selector step 3950 current loss 0.614945, current_train_items 54496.
I0831 18:15:47.063396 138047105189376 run.py:707] Algo task_scheduling step 3950 current loss 1.986663, current_train_items 54496.
I0831 18:15:47.078871 138047105189376 run.py:742] (val) algo activity_selector step 3950: {'selected': 0.8818011257035648, 'score': 0.8818011257035648, 'examples_seen': 54496, 'step': 3950, 'algorithm': 'activity_selector'}
I0831 18:15:47.086581 138047105189376 run.py:742] (val) algo task_scheduling step 3950: {'selected': 0.9404255319148936, 'score': 0.9404255319148936, 'examples_seen': 54496, 'step': 3950, 'algorithm': 'task_scheduling'}
I0831 18:15:47.086732 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.911, val scores are: activity_selector: 0.882, task_scheduling: 0.940
I0831 18:15:48.114825 138047105189376 run.py:707] Algo activity_selector step 4000 current loss 1.250671, current_train_items 55168.
I0831 18:15:48.119487 138047105189376 run.py:707] Algo task_scheduling step 4000 current loss 1.887329, current_train_items 55168.
I0831 18:15:48.136317 138047105189376 run.py:742] (val) algo activity_selector step 4000: {'selected': 0.8410852713178295, 'score': 0.8410852713178295, 'examples_seen': 55168, 'step': 4000, 'algorithm': 'activity_selector'}
I0831 18:15:48.143961 138047105189376 run.py:742] (val) algo task_scheduling step 4000: {'selected': 0.9379014989293362, 'score': 0.9379014989293362, 'examples_seen': 55168, 'step': 4000, 'algorithm': 'task_scheduling'}
I0831 18:15:48.144107 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.889, val scores are: activity_selector: 0.841, task_scheduling: 0.938
I0831 18:15:49.213634 138047105189376 run.py:707] Algo activity_selector step 4050 current loss 1.194584, current_train_items 55856.
I0831 18:15:49.218190 138047105189376 run.py:707] Algo task_scheduling step 4050 current loss 1.434218, current_train_items 55856.
I0831 18:15:49.236903 138047105189376 run.py:742] (val) algo activity_selector step 4050: {'selected': 0.8700361010830325, 'score': 0.8700361010830325, 'examples_seen': 55856, 'step': 4050, 'algorithm': 'activity_selector'}
I0831 18:15:49.244539 138047105189376 run.py:742] (val) algo task_scheduling step 4050: {'selected': 0.9292786421499293, 'score': 0.9292786421499293, 'examples_seen': 55856, 'step': 4050, 'algorithm': 'task_scheduling'}
I0831 18:15:49.244698 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.900, val scores are: activity_selector: 0.870, task_scheduling: 0.929
I0831 18:15:50.293872 138047105189376 run.py:707] Algo activity_selector step 4100 current loss 0.540415, current_train_items 56560.
I0831 18:15:50.298379 138047105189376 run.py:707] Algo task_scheduling step 4100 current loss 1.233802, current_train_items 56560.
I0831 18:15:50.315036 138047105189376 run.py:742] (val) algo activity_selector step 4100: {'selected': 0.8956834532374102, 'score': 0.8956834532374102, 'examples_seen': 56560, 'step': 4100, 'algorithm': 'activity_selector'}
I0831 18:15:50.322640 138047105189376 run.py:742] (val) algo task_scheduling step 4100: {'selected': 0.9404761904761905, 'score': 0.9404761904761905, 'examples_seen': 56560, 'step': 4100, 'algorithm': 'task_scheduling'}
I0831 18:15:50.322788 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.918, val scores are: activity_selector: 0.896, task_scheduling: 0.940
I0831 18:15:51.360028 138047105189376 run.py:707] Algo activity_selector step 4150 current loss 1.161186, current_train_items 57248.
I0831 18:15:51.365050 138047105189376 run.py:707] Algo task_scheduling step 4150 current loss 1.459414, current_train_items 57248.
I0831 18:15:51.381634 138047105189376 run.py:742] (val) algo activity_selector step 4150: {'selected': 0.8535714285714286, 'score': 0.8535714285714286, 'examples_seen': 57248, 'step': 4150, 'algorithm': 'activity_selector'}
I0831 18:15:51.389199 138047105189376 run.py:742] (val) algo task_scheduling step 4150: {'selected': 0.9328358208955224, 'score': 0.9328358208955224, 'examples_seen': 57248, 'step': 4150, 'algorithm': 'task_scheduling'}
I0831 18:15:51.389356 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.893, val scores are: activity_selector: 0.854, task_scheduling: 0.933
I0831 18:15:52.430401 138047105189376 run.py:707] Algo activity_selector step 4200 current loss 0.768880, current_train_items 57920.
I0831 18:15:52.434813 138047105189376 run.py:707] Algo task_scheduling step 4200 current loss 1.340608, current_train_items 57920.
I0831 18:15:52.451428 138047105189376 run.py:742] (val) algo activity_selector step 4200: {'selected': 0.8641975308641976, 'score': 0.8641975308641976, 'examples_seen': 57920, 'step': 4200, 'algorithm': 'activity_selector'}
I0831 18:15:52.459089 138047105189376 run.py:742] (val) algo task_scheduling step 4200: {'selected': 0.9469090909090909, 'score': 0.9469090909090909, 'examples_seen': 57920, 'step': 4200, 'algorithm': 'task_scheduling'}
I0831 18:15:52.459248 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.906, val scores are: activity_selector: 0.864, task_scheduling: 0.947
I0831 18:15:53.523936 138047105189376 run.py:707] Algo activity_selector step 4250 current loss 0.643355, current_train_items 58624.
I0831 18:15:53.528384 138047105189376 run.py:707] Algo task_scheduling step 4250 current loss 1.621595, current_train_items 58624.
I0831 18:15:53.545085 138047105189376 run.py:742] (val) algo activity_selector step 4250: {'selected': 0.8832116788321168, 'score': 0.8832116788321168, 'examples_seen': 58624, 'step': 4250, 'algorithm': 'activity_selector'}
I0831 18:15:53.552639 138047105189376 run.py:742] (val) algo task_scheduling step 4250: {'selected': 0.9544807965860598, 'score': 0.9544807965860598, 'examples_seen': 58624, 'step': 4250, 'algorithm': 'task_scheduling'}
I0831 18:15:53.552783 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.919, val scores are: activity_selector: 0.883, task_scheduling: 0.954
I0831 18:15:54.601877 138047105189376 run.py:707] Algo activity_selector step 4300 current loss 0.804088, current_train_items 59328.
I0831 18:15:54.606437 138047105189376 run.py:707] Algo task_scheduling step 4300 current loss 1.674424, current_train_items 59328.
I0831 18:15:54.622116 138047105189376 run.py:742] (val) algo activity_selector step 4300: {'selected': 0.8717948717948718, 'score': 0.8717948717948718, 'examples_seen': 59328, 'step': 4300, 'algorithm': 'activity_selector'}
I0831 18:15:54.629587 138047105189376 run.py:742] (val) algo task_scheduling step 4300: {'selected': 0.9272727272727272, 'score': 0.9272727272727272, 'examples_seen': 59328, 'step': 4300, 'algorithm': 'task_scheduling'}
I0831 18:15:54.629727 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.900, val scores are: activity_selector: 0.872, task_scheduling: 0.927
I0831 18:15:55.658828 138047105189376 run.py:707] Algo activity_selector step 4350 current loss 1.129156, current_train_items 59984.
I0831 18:15:55.663181 138047105189376 run.py:707] Algo task_scheduling step 4350 current loss 2.474919, current_train_items 59984.
I0831 18:15:55.679141 138047105189376 run.py:742] (val) algo activity_selector step 4350: {'selected': 0.8703703703703703, 'score': 0.8703703703703703, 'examples_seen': 59984, 'step': 4350, 'algorithm': 'activity_selector'}
I0831 18:15:55.686760 138047105189376 run.py:742] (val) algo task_scheduling step 4350: {'selected': 0.9416974169741696, 'score': 0.9416974169741696, 'examples_seen': 59984, 'step': 4350, 'algorithm': 'task_scheduling'}
I0831 18:15:55.686905 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.906, val scores are: activity_selector: 0.870, task_scheduling: 0.942
I0831 18:15:56.747205 138047105189376 run.py:707] Algo activity_selector step 4400 current loss 1.073532, current_train_items 60688.
I0831 18:15:56.751356 138047105189376 run.py:707] Algo task_scheduling step 4400 current loss 1.706933, current_train_items 60688.
I0831 18:15:56.767685 138047105189376 run.py:742] (val) algo activity_selector step 4400: {'selected': 0.8729281767955802, 'score': 0.8729281767955802, 'examples_seen': 60688, 'step': 4400, 'algorithm': 'activity_selector'}
I0831 18:15:56.775282 138047105189376 run.py:742] (val) algo task_scheduling step 4400: {'selected': 0.8928809048569527, 'score': 0.8928809048569527, 'examples_seen': 60688, 'step': 4400, 'algorithm': 'task_scheduling'}
I0831 18:15:56.775429 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.883, val scores are: activity_selector: 0.873, task_scheduling: 0.893
I0831 18:15:57.811740 138047105189376 run.py:707] Algo activity_selector step 4450 current loss 0.965002, current_train_items 61392.
I0831 18:15:57.816331 138047105189376 run.py:707] Algo task_scheduling step 4450 current loss 1.692937, current_train_items 61392.
I0831 18:15:57.833307 138047105189376 run.py:742] (val) algo activity_selector step 4450: {'selected': 0.8809073724007561, 'score': 0.8809073724007561, 'examples_seen': 61392, 'step': 4450, 'algorithm': 'activity_selector'}
I0831 18:15:57.841161 138047105189376 run.py:742] (val) algo task_scheduling step 4450: {'selected': 0.9445214979195563, 'score': 0.9445214979195563, 'examples_seen': 61392, 'step': 4450, 'algorithm': 'task_scheduling'}
I0831 18:15:57.841315 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.913, val scores are: activity_selector: 0.881, task_scheduling: 0.945
I0831 18:15:58.864268 138047105189376 run.py:707] Algo activity_selector step 4500 current loss 0.693396, current_train_items 62064.
I0831 18:15:58.869137 138047105189376 run.py:707] Algo task_scheduling step 4500 current loss 1.645210, current_train_items 62064.
I0831 18:15:58.885622 138047105189376 run.py:742] (val) algo activity_selector step 4500: {'selected': 0.8839779005524863, 'score': 0.8839779005524863, 'examples_seen': 62064, 'step': 4500, 'algorithm': 'activity_selector'}
I0831 18:15:58.893225 138047105189376 run.py:742] (val) algo task_scheduling step 4500: {'selected': 0.9191780821917808, 'score': 0.9191780821917808, 'examples_seen': 62064, 'step': 4500, 'algorithm': 'task_scheduling'}
I0831 18:15:58.893369 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.902, val scores are: activity_selector: 0.884, task_scheduling: 0.919
I0831 18:15:59.945722 138047105189376 run.py:707] Algo activity_selector step 4550 current loss 1.396452, current_train_items 62752.
I0831 18:15:59.950345 138047105189376 run.py:707] Algo task_scheduling step 4550 current loss 1.277587, current_train_items 62752.
I0831 18:15:59.966706 138047105189376 run.py:742] (val) algo activity_selector step 4550: {'selected': 0.8354430379746836, 'score': 0.8354430379746836, 'examples_seen': 62752, 'step': 4550, 'algorithm': 'activity_selector'}
I0831 18:15:59.974318 138047105189376 run.py:742] (val) algo task_scheduling step 4550: {'selected': 0.9384083044982698, 'score': 0.9384083044982698, 'examples_seen': 62752, 'step': 4550, 'algorithm': 'task_scheduling'}
I0831 18:15:59.974463 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.887, val scores are: activity_selector: 0.835, task_scheduling: 0.938
I0831 18:16:01.016139 138047105189376 run.py:707] Algo activity_selector step 4600 current loss 0.659842, current_train_items 63456.
I0831 18:16:01.020617 138047105189376 run.py:707] Algo task_scheduling step 4600 current loss 1.599774, current_train_items 63456.
I0831 18:16:01.037317 138047105189376 run.py:742] (val) algo activity_selector step 4600: {'selected': 0.8770642201834863, 'score': 0.8770642201834863, 'examples_seen': 63456, 'step': 4600, 'algorithm': 'activity_selector'}
I0831 18:16:01.044969 138047105189376 run.py:742] (val) algo task_scheduling step 4600: {'selected': 0.940014114326041, 'score': 0.940014114326041, 'examples_seen': 63456, 'step': 4600, 'algorithm': 'task_scheduling'}
I0831 18:16:01.045112 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.909, val scores are: activity_selector: 0.877, task_scheduling: 0.940
I0831 18:16:02.087866 138047105189376 run.py:707] Algo activity_selector step 4650 current loss 0.979993, current_train_items 64144.
I0831 18:16:02.092919 138047105189376 run.py:707] Algo task_scheduling step 4650 current loss 1.118522, current_train_items 64144.
I0831 18:16:02.110073 138047105189376 run.py:742] (val) algo activity_selector step 4650: {'selected': 0.8609022556390976, 'score': 0.8609022556390976, 'examples_seen': 64144, 'step': 4650, 'algorithm': 'activity_selector'}
I0831 18:16:02.117783 138047105189376 run.py:742] (val) algo task_scheduling step 4650: {'selected': 0.9420186113099498, 'score': 0.9420186113099498, 'examples_seen': 64144, 'step': 4650, 'algorithm': 'task_scheduling'}
I0831 18:16:02.117944 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.901, val scores are: activity_selector: 0.861, task_scheduling: 0.942
I0831 18:16:03.156477 138047105189376 run.py:707] Algo activity_selector step 4700 current loss 0.869505, current_train_items 64816.
I0831 18:16:03.160942 138047105189376 run.py:707] Algo task_scheduling step 4700 current loss 2.213032, current_train_items 64816.
I0831 18:16:03.177870 138047105189376 run.py:742] (val) algo activity_selector step 4700: {'selected': 0.8581314878892734, 'score': 0.8581314878892734, 'examples_seen': 64816, 'step': 4700, 'algorithm': 'activity_selector'}
I0831 18:16:03.185560 138047105189376 run.py:742] (val) algo task_scheduling step 4700: {'selected': 0.9230769230769231, 'score': 0.9230769230769231, 'examples_seen': 64816, 'step': 4700, 'algorithm': 'task_scheduling'}
I0831 18:16:03.185718 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.891, val scores are: activity_selector: 0.858, task_scheduling: 0.923
I0831 18:16:04.260437 138047105189376 run.py:707] Algo activity_selector step 4750 current loss 1.269572, current_train_items 65520.
I0831 18:16:04.264690 138047105189376 run.py:707] Algo task_scheduling step 4750 current loss 1.683978, current_train_items 65520.
I0831 18:16:04.282294 138047105189376 run.py:742] (val) algo activity_selector step 4750: {'selected': 0.8759689922480621, 'score': 0.8759689922480621, 'examples_seen': 65520, 'step': 4750, 'algorithm': 'activity_selector'}
I0831 18:16:04.289927 138047105189376 run.py:742] (val) algo task_scheduling step 4750: {'selected': 0.962857142857143, 'score': 0.962857142857143, 'examples_seen': 65520, 'step': 4750, 'algorithm': 'task_scheduling'}
I0831 18:16:04.290077 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.919, val scores are: activity_selector: 0.876, task_scheduling: 0.963
I0831 18:16:05.340375 138047105189376 run.py:707] Algo activity_selector step 4800 current loss 0.467643, current_train_items 66208.
I0831 18:16:05.345154 138047105189376 run.py:707] Algo task_scheduling step 4800 current loss 1.767709, current_train_items 66208.
I0831 18:16:05.361317 138047105189376 run.py:742] (val) algo activity_selector step 4800: {'selected': 0.8623853211009175, 'score': 0.8623853211009175, 'examples_seen': 66208, 'step': 4800, 'algorithm': 'activity_selector'}
I0831 18:16:05.368916 138047105189376 run.py:742] (val) algo task_scheduling step 4800: {'selected': 0.9147609147609147, 'score': 0.9147609147609147, 'examples_seen': 66208, 'step': 4800, 'algorithm': 'task_scheduling'}
I0831 18:16:05.369069 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.889, val scores are: activity_selector: 0.862, task_scheduling: 0.915
I0831 18:16:06.394715 138047105189376 run.py:707] Algo activity_selector step 4850 current loss 0.794975, current_train_items 66880.
I0831 18:16:06.399163 138047105189376 run.py:707] Algo task_scheduling step 4850 current loss 1.535166, current_train_items 66880.
I0831 18:16:06.415483 138047105189376 run.py:742] (val) algo activity_selector step 4850: {'selected': 0.8737541528239202, 'score': 0.8737541528239202, 'examples_seen': 66880, 'step': 4850, 'algorithm': 'activity_selector'}
I0831 18:16:06.423110 138047105189376 run.py:742] (val) algo task_scheduling step 4850: {'selected': 0.9317548746518106, 'score': 0.9317548746518106, 'examples_seen': 66880, 'step': 4850, 'algorithm': 'task_scheduling'}
I0831 18:16:06.423254 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.903, val scores are: activity_selector: 0.874, task_scheduling: 0.932
I0831 18:16:07.466130 138047105189376 run.py:707] Algo activity_selector step 4900 current loss 0.537364, current_train_items 67584.
I0831 18:16:07.470565 138047105189376 run.py:707] Algo task_scheduling step 4900 current loss 1.348479, current_train_items 67584.
I0831 18:16:07.488240 138047105189376 run.py:742] (val) algo activity_selector step 4900: {'selected': 0.8989169675090253, 'score': 0.8989169675090253, 'examples_seen': 67584, 'step': 4900, 'algorithm': 'activity_selector'}
I0831 18:16:07.495978 138047105189376 run.py:742] (val) algo task_scheduling step 4900: {'selected': 0.9283228949199722, 'score': 0.9283228949199722, 'examples_seen': 67584, 'step': 4900, 'algorithm': 'task_scheduling'}
I0831 18:16:07.496140 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.914, val scores are: activity_selector: 0.899, task_scheduling: 0.928
I0831 18:16:08.622588 138047105189376 run.py:707] Algo activity_selector step 4950 current loss 0.527253, current_train_items 68272.
I0831 18:16:08.627253 138047105189376 run.py:707] Algo task_scheduling step 4950 current loss 2.148478, current_train_items 68272.
I0831 18:16:08.643697 138047105189376 run.py:742] (val) algo activity_selector step 4950: {'selected': 0.8609022556390977, 'score': 0.8609022556390977, 'examples_seen': 68272, 'step': 4950, 'algorithm': 'activity_selector'}
I0831 18:16:08.651279 138047105189376 run.py:742] (val) algo task_scheduling step 4950: {'selected': 0.9367088607594937, 'score': 0.9367088607594937, 'examples_seen': 68272, 'step': 4950, 'algorithm': 'task_scheduling'}
I0831 18:16:08.651422 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.899, val scores are: activity_selector: 0.861, task_scheduling: 0.937
I0831 18:16:09.707245 138047105189376 run.py:707] Algo activity_selector step 5000 current loss 0.811822, current_train_items 68976.
I0831 18:16:09.711883 138047105189376 run.py:707] Algo task_scheduling step 5000 current loss 1.330698, current_train_items 68976.
I0831 18:16:09.728492 138047105189376 run.py:742] (val) algo activity_selector step 5000: {'selected': 0.8561759729272419, 'score': 0.8561759729272419, 'examples_seen': 68976, 'step': 5000, 'algorithm': 'activity_selector'}
I0831 18:16:09.736106 138047105189376 run.py:742] (val) algo task_scheduling step 5000: {'selected': 0.9195088676671214, 'score': 0.9195088676671214, 'examples_seen': 68976, 'step': 5000, 'algorithm': 'task_scheduling'}
I0831 18:16:09.736250 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.888, val scores are: activity_selector: 0.856, task_scheduling: 0.920
I0831 18:16:10.750695 138047105189376 run.py:707] Algo activity_selector step 5050 current loss 0.800350, current_train_items 69648.
I0831 18:16:10.755315 138047105189376 run.py:707] Algo task_scheduling step 5050 current loss 1.593057, current_train_items 69648.
I0831 18:16:10.771742 138047105189376 run.py:742] (val) algo activity_selector step 5050: {'selected': 0.8548707753479126, 'score': 0.8548707753479126, 'examples_seen': 69648, 'step': 5050, 'algorithm': 'activity_selector'}
I0831 18:16:10.779293 138047105189376 run.py:742] (val) algo task_scheduling step 5050: {'selected': 0.927208480565371, 'score': 0.927208480565371, 'examples_seen': 69648, 'step': 5050, 'algorithm': 'task_scheduling'}
I0831 18:16:10.779431 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.891, val scores are: activity_selector: 0.855, task_scheduling: 0.927
I0831 18:16:11.829536 138047105189376 run.py:707] Algo activity_selector step 5100 current loss 0.505441, current_train_items 70336.
I0831 18:16:11.833853 138047105189376 run.py:707] Algo task_scheduling step 5100 current loss 1.135076, current_train_items 70336.
I0831 18:16:11.850301 138047105189376 run.py:742] (val) algo activity_selector step 5100: {'selected': 0.9016100178890877, 'score': 0.9016100178890877, 'examples_seen': 70336, 'step': 5100, 'algorithm': 'activity_selector'}
I0831 18:16:11.857896 138047105189376 run.py:742] (val) algo task_scheduling step 5100: {'selected': 0.9364406779661018, 'score': 0.9364406779661018, 'examples_seen': 70336, 'step': 5100, 'algorithm': 'task_scheduling'}
I0831 18:16:11.858042 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.919, val scores are: activity_selector: 0.902, task_scheduling: 0.936
I0831 18:16:12.900348 138047105189376 run.py:707] Algo activity_selector step 5150 current loss 0.997432, current_train_items 71040.
I0831 18:16:12.905034 138047105189376 run.py:707] Algo task_scheduling step 5150 current loss 1.495080, current_train_items 71040.
I0831 18:16:12.920879 138047105189376 run.py:742] (val) algo activity_selector step 5150: {'selected': 0.8381294964028777, 'score': 0.8381294964028777, 'examples_seen': 71040, 'step': 5150, 'algorithm': 'activity_selector'}
I0831 18:16:12.928454 138047105189376 run.py:742] (val) algo task_scheduling step 5150: {'selected': 0.9515545914678236, 'score': 0.9515545914678236, 'examples_seen': 71040, 'step': 5150, 'algorithm': 'task_scheduling'}
I0831 18:16:12.928595 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.895, val scores are: activity_selector: 0.838, task_scheduling: 0.952
I0831 18:16:13.923706 138047105189376 run.py:707] Algo activity_selector step 5200 current loss 1.303466, current_train_items 71712.
I0831 18:16:13.928323 138047105189376 run.py:707] Algo task_scheduling step 5200 current loss 1.704921, current_train_items 71712.
I0831 18:16:13.944165 138047105189376 run.py:742] (val) algo activity_selector step 5200: {'selected': 0.8830715532286213, 'score': 0.8830715532286213, 'examples_seen': 71712, 'step': 5200, 'algorithm': 'activity_selector'}
I0831 18:16:13.951647 138047105189376 run.py:742] (val) algo task_scheduling step 5200: {'selected': 0.9080553295362083, 'score': 0.9080553295362083, 'examples_seen': 71712, 'step': 5200, 'algorithm': 'task_scheduling'}
I0831 18:16:13.951789 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.896, val scores are: activity_selector: 0.883, task_scheduling: 0.908
I0831 18:16:14.993486 138047105189376 run.py:707] Algo activity_selector step 5250 current loss 0.788406, current_train_items 72400.
I0831 18:16:14.998170 138047105189376 run.py:707] Algo task_scheduling step 5250 current loss 1.210690, current_train_items 72400.
I0831 18:16:15.014950 138047105189376 run.py:742] (val) algo activity_selector step 5250: {'selected': 0.845117845117845, 'score': 0.845117845117845, 'examples_seen': 72400, 'step': 5250, 'algorithm': 'activity_selector'}
I0831 18:16:15.022530 138047105189376 run.py:742] (val) algo task_scheduling step 5250: {'selected': 0.9422936449963477, 'score': 0.9422936449963477, 'examples_seen': 72400, 'step': 5250, 'algorithm': 'task_scheduling'}
I0831 18:16:15.022669 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.928, current avg val score is 0.894, val scores are: activity_selector: 0.845, task_scheduling: 0.942
I0831 18:16:16.084633 138047105189376 run.py:707] Algo activity_selector step 5300 current loss 0.820867, current_train_items 73104.
I0831 18:16:16.089038 138047105189376 run.py:707] Algo task_scheduling step 5300 current loss 1.103337, current_train_items 73104.
I0831 18:16:16.105120 138047105189376 run.py:742] (val) algo activity_selector step 5300: {'selected': 0.9064220183486239, 'score': 0.9064220183486239, 'examples_seen': 73104, 'step': 5300, 'algorithm': 'activity_selector'}
I0831 18:16:16.112655 138047105189376 run.py:742] (val) algo task_scheduling step 5300: {'selected': 0.960116026105874, 'score': 0.960116026105874, 'examples_seen': 73104, 'step': 5300, 'algorithm': 'task_scheduling'}
I0831 18:16:16.112797 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.928, current avg val score is 0.933, val scores are: activity_selector: 0.906, task_scheduling: 0.960
I0831 18:16:17.137611 138047105189376 run.py:707] Algo activity_selector step 5350 current loss 0.668591, current_train_items 73808.
I0831 18:16:17.142148 138047105189376 run.py:707] Algo task_scheduling step 5350 current loss 1.393676, current_train_items 73808.
I0831 18:16:17.158461 138047105189376 run.py:742] (val) algo activity_selector step 5350: {'selected': 0.8631578947368421, 'score': 0.8631578947368421, 'examples_seen': 73808, 'step': 5350, 'algorithm': 'activity_selector'}
I0831 18:16:17.166002 138047105189376 run.py:742] (val) algo task_scheduling step 5350: {'selected': 0.9454287739192062, 'score': 0.9454287739192062, 'examples_seen': 73808, 'step': 5350, 'algorithm': 'task_scheduling'}
I0831 18:16:17.166142 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.904, val scores are: activity_selector: 0.863, task_scheduling: 0.945
I0831 18:16:18.212541 138047105189376 run.py:707] Algo activity_selector step 5400 current loss 0.787099, current_train_items 74464.
I0831 18:16:18.217046 138047105189376 run.py:707] Algo task_scheduling step 5400 current loss 1.556468, current_train_items 74464.
I0831 18:16:18.233609 138047105189376 run.py:742] (val) algo activity_selector step 5400: {'selected': 0.8838951310861424, 'score': 0.8838951310861424, 'examples_seen': 74464, 'step': 5400, 'algorithm': 'activity_selector'}
I0831 18:16:18.241219 138047105189376 run.py:742] (val) algo task_scheduling step 5400: {'selected': 0.9323741007194245, 'score': 0.9323741007194245, 'examples_seen': 74464, 'step': 5400, 'algorithm': 'task_scheduling'}
I0831 18:16:18.241356 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.908, val scores are: activity_selector: 0.884, task_scheduling: 0.932
I0831 18:16:19.284658 138047105189376 run.py:707] Algo activity_selector step 5450 current loss 0.324089, current_train_items 75168.
I0831 18:16:19.288826 138047105189376 run.py:707] Algo task_scheduling step 5450 current loss 1.301523, current_train_items 75168.
I0831 18:16:19.305411 138047105189376 run.py:742] (val) algo activity_selector step 5450: {'selected': 0.8762677484787019, 'score': 0.8762677484787019, 'examples_seen': 75168, 'step': 5450, 'algorithm': 'activity_selector'}
I0831 18:16:19.313005 138047105189376 run.py:742] (val) algo task_scheduling step 5450: {'selected': 0.9427753934191702, 'score': 0.9427753934191702, 'examples_seen': 75168, 'step': 5450, 'algorithm': 'task_scheduling'}
I0831 18:16:19.313149 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.910, val scores are: activity_selector: 0.876, task_scheduling: 0.943
I0831 18:16:20.345668 138047105189376 run.py:707] Algo activity_selector step 5500 current loss 0.922079, current_train_items 75872.
I0831 18:16:20.350143 138047105189376 run.py:707] Algo task_scheduling step 5500 current loss 1.400651, current_train_items 75872.
I0831 18:16:20.366176 138047105189376 run.py:742] (val) algo activity_selector step 5500: {'selected': 0.8707753479125249, 'score': 0.8707753479125249, 'examples_seen': 75872, 'step': 5500, 'algorithm': 'activity_selector'}
I0831 18:16:20.373754 138047105189376 run.py:742] (val) algo task_scheduling step 5500: {'selected': 0.9186935371785963, 'score': 0.9186935371785963, 'examples_seen': 75872, 'step': 5500, 'algorithm': 'task_scheduling'}
I0831 18:16:20.373893 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.895, val scores are: activity_selector: 0.871, task_scheduling: 0.919
I0831 18:16:21.390513 138047105189376 run.py:707] Algo activity_selector step 5550 current loss 0.872551, current_train_items 76528.
I0831 18:16:21.394859 138047105189376 run.py:707] Algo task_scheduling step 5550 current loss 0.956076, current_train_items 76528.
I0831 18:16:21.411140 138047105189376 run.py:742] (val) algo activity_selector step 5550: {'selected': 0.8850174216027875, 'score': 0.8850174216027875, 'examples_seen': 76528, 'step': 5550, 'algorithm': 'activity_selector'}
I0831 18:16:21.418640 138047105189376 run.py:742] (val) algo task_scheduling step 5550: {'selected': 0.9353301565690947, 'score': 0.9353301565690947, 'examples_seen': 76528, 'step': 5550, 'algorithm': 'task_scheduling'}
I0831 18:16:21.418783 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.910, val scores are: activity_selector: 0.885, task_scheduling: 0.935
I0831 18:16:22.474311 138047105189376 run.py:707] Algo activity_selector step 5600 current loss 1.005034, current_train_items 77232.
I0831 18:16:22.478734 138047105189376 run.py:707] Algo task_scheduling step 5600 current loss 1.457390, current_train_items 77232.
I0831 18:16:22.494898 138047105189376 run.py:742] (val) algo activity_selector step 5600: {'selected': 0.870967741935484, 'score': 0.870967741935484, 'examples_seen': 77232, 'step': 5600, 'algorithm': 'activity_selector'}
I0831 18:16:22.502438 138047105189376 run.py:742] (val) algo task_scheduling step 5600: {'selected': 0.9540481400437637, 'score': 0.9540481400437637, 'examples_seen': 77232, 'step': 5600, 'algorithm': 'task_scheduling'}
I0831 18:16:22.502579 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.913, val scores are: activity_selector: 0.871, task_scheduling: 0.954
I0831 18:16:23.545962 138047105189376 run.py:707] Algo activity_selector step 5650 current loss 0.733896, current_train_items 77936.
I0831 18:16:23.550215 138047105189376 run.py:707] Algo task_scheduling step 5650 current loss 3.003728, current_train_items 77936.
I0831 18:16:23.566462 138047105189376 run.py:742] (val) algo activity_selector step 5650: {'selected': 0.8799999999999999, 'score': 0.8799999999999999, 'examples_seen': 77936, 'step': 5650, 'algorithm': 'activity_selector'}
I0831 18:16:23.574029 138047105189376 run.py:742] (val) algo task_scheduling step 5650: {'selected': 0.9501424501424501, 'score': 0.9501424501424501, 'examples_seen': 77936, 'step': 5650, 'algorithm': 'task_scheduling'}
I0831 18:16:23.574171 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.915, val scores are: activity_selector: 0.880, task_scheduling: 0.950
I0831 18:16:24.596516 138047105189376 run.py:707] Algo activity_selector step 5700 current loss 1.111023, current_train_items 78608.
I0831 18:16:24.601130 138047105189376 run.py:707] Algo task_scheduling step 5700 current loss 1.313052, current_train_items 78608.
I0831 18:16:24.617634 138047105189376 run.py:742] (val) algo activity_selector step 5700: {'selected': 0.8486055776892429, 'score': 0.8486055776892429, 'examples_seen': 78608, 'step': 5700, 'algorithm': 'activity_selector'}
I0831 18:16:24.625282 138047105189376 run.py:742] (val) algo task_scheduling step 5700: {'selected': 0.9608277900960829, 'score': 0.9608277900960829, 'examples_seen': 78608, 'step': 5700, 'algorithm': 'task_scheduling'}
I0831 18:16:24.625424 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.905, val scores are: activity_selector: 0.849, task_scheduling: 0.961
I0831 18:16:25.672392 138047105189376 run.py:707] Algo activity_selector step 5750 current loss 0.731447, current_train_items 79296.
I0831 18:16:25.677093 138047105189376 run.py:707] Algo task_scheduling step 5750 current loss 1.669132, current_train_items 79296.
I0831 18:16:25.693532 138047105189376 run.py:742] (val) algo activity_selector step 5750: {'selected': 0.9075630252100839, 'score': 0.9075630252100839, 'examples_seen': 79296, 'step': 5750, 'algorithm': 'activity_selector'}
I0831 18:16:25.701256 138047105189376 run.py:742] (val) algo task_scheduling step 5750: {'selected': 0.9290681502086231, 'score': 0.9290681502086231, 'examples_seen': 79296, 'step': 5750, 'algorithm': 'task_scheduling'}
I0831 18:16:25.701396 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.918, val scores are: activity_selector: 0.908, task_scheduling: 0.929
I0831 18:16:26.739228 138047105189376 run.py:707] Algo activity_selector step 5800 current loss 0.860564, current_train_items 80000.
I0831 18:16:26.743698 138047105189376 run.py:707] Algo task_scheduling step 5800 current loss 2.463839, current_train_items 80000.
I0831 18:16:26.760089 138047105189376 run.py:742] (val) algo activity_selector step 5800: {'selected': 0.8393194706994329, 'score': 0.8393194706994329, 'examples_seen': 80000, 'step': 5800, 'algorithm': 'activity_selector'}
I0831 18:16:26.767631 138047105189376 run.py:742] (val) algo task_scheduling step 5800: {'selected': 0.916030534351145, 'score': 0.916030534351145, 'examples_seen': 80000, 'step': 5800, 'algorithm': 'task_scheduling'}
I0831 18:16:26.767772 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.878, val scores are: activity_selector: 0.839, task_scheduling: 0.916
I0831 18:16:27.817440 138047105189376 run.py:707] Algo activity_selector step 5850 current loss 0.420362, current_train_items 80688.
I0831 18:16:27.822101 138047105189376 run.py:707] Algo task_scheduling step 5850 current loss 1.511831, current_train_items 80688.
I0831 18:16:27.838377 138047105189376 run.py:742] (val) algo activity_selector step 5850: {'selected': 0.8395061728395061, 'score': 0.8395061728395061, 'examples_seen': 80688, 'step': 5850, 'algorithm': 'activity_selector'}
I0831 18:16:27.845957 138047105189376 run.py:742] (val) algo task_scheduling step 5850: {'selected': 0.92404181184669, 'score': 0.92404181184669, 'examples_seen': 80688, 'step': 5850, 'algorithm': 'task_scheduling'}
I0831 18:16:27.846099 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.882, val scores are: activity_selector: 0.840, task_scheduling: 0.924
I0831 18:16:28.885888 138047105189376 run.py:707] Algo activity_selector step 5900 current loss 0.680593, current_train_items 81360.
I0831 18:16:28.890308 138047105189376 run.py:707] Algo task_scheduling step 5900 current loss 1.216918, current_train_items 81360.
I0831 18:16:28.906260 138047105189376 run.py:742] (val) algo activity_selector step 5900: {'selected': 0.7905282331511839, 'score': 0.7905282331511839, 'examples_seen': 81360, 'step': 5900, 'algorithm': 'activity_selector'}
I0831 18:16:28.913883 138047105189376 run.py:742] (val) algo task_scheduling step 5900: {'selected': 0.9464668094218416, 'score': 0.9464668094218416, 'examples_seen': 81360, 'step': 5900, 'algorithm': 'task_scheduling'}
I0831 18:16:28.914032 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.868, val scores are: activity_selector: 0.791, task_scheduling: 0.946
I0831 18:16:29.968650 138047105189376 run.py:707] Algo activity_selector step 5950 current loss 0.863361, current_train_items 82064.
I0831 18:16:29.973276 138047105189376 run.py:707] Algo task_scheduling step 5950 current loss 1.137766, current_train_items 82064.
I0831 18:16:29.989639 138047105189376 run.py:742] (val) algo activity_selector step 5950: {'selected': 0.8451242829827915, 'score': 0.8451242829827915, 'examples_seen': 82064, 'step': 5950, 'algorithm': 'activity_selector'}
I0831 18:16:29.997681 138047105189376 run.py:742] (val) algo task_scheduling step 5950: {'selected': 0.9476702508960574, 'score': 0.9476702508960574, 'examples_seen': 82064, 'step': 5950, 'algorithm': 'task_scheduling'}
I0831 18:16:29.997829 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.896, val scores are: activity_selector: 0.845, task_scheduling: 0.948
I0831 18:16:31.058819 138047105189376 run.py:707] Algo activity_selector step 6000 current loss 0.528965, current_train_items 82752.
I0831 18:16:31.063349 138047105189376 run.py:707] Algo task_scheduling step 6000 current loss 1.358464, current_train_items 82752.
I0831 18:16:31.079880 138047105189376 run.py:742] (val) algo activity_selector step 6000: {'selected': 0.8729874776386405, 'score': 0.8729874776386405, 'examples_seen': 82752, 'step': 6000, 'algorithm': 'activity_selector'}
I0831 18:16:31.087435 138047105189376 run.py:742] (val) algo task_scheduling step 6000: {'selected': 0.9234012649332395, 'score': 0.9234012649332395, 'examples_seen': 82752, 'step': 6000, 'algorithm': 'task_scheduling'}
I0831 18:16:31.087583 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.898, val scores are: activity_selector: 0.873, task_scheduling: 0.923
I0831 18:16:32.109288 138047105189376 run.py:707] Algo activity_selector step 6050 current loss 0.489352, current_train_items 83440.
I0831 18:16:32.113730 138047105189376 run.py:707] Algo task_scheduling step 6050 current loss 1.799615, current_train_items 83440.
I0831 18:16:32.133342 138047105189376 run.py:742] (val) algo activity_selector step 6050: {'selected': 0.8214285714285714, 'score': 0.8214285714285714, 'examples_seen': 83440, 'step': 6050, 'algorithm': 'activity_selector'}
I0831 18:16:32.141005 138047105189376 run.py:742] (val) algo task_scheduling step 6050: {'selected': 0.9440353460972019, 'score': 0.9440353460972019, 'examples_seen': 83440, 'step': 6050, 'algorithm': 'task_scheduling'}
I0831 18:16:32.141147 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.883, val scores are: activity_selector: 0.821, task_scheduling: 0.944
I0831 18:16:33.172961 138047105189376 run.py:707] Algo activity_selector step 6100 current loss 0.924973, current_train_items 84128.
I0831 18:16:33.177278 138047105189376 run.py:707] Algo task_scheduling step 6100 current loss 1.077331, current_train_items 84128.
I0831 18:16:33.194343 138047105189376 run.py:742] (val) algo activity_selector step 6100: {'selected': 0.8263254113345522, 'score': 0.8263254113345522, 'examples_seen': 84128, 'step': 6100, 'algorithm': 'activity_selector'}
I0831 18:16:33.202003 138047105189376 run.py:742] (val) algo task_scheduling step 6100: {'selected': 0.9308176100628931, 'score': 0.9308176100628931, 'examples_seen': 84128, 'step': 6100, 'algorithm': 'task_scheduling'}
I0831 18:16:33.202141 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.879, val scores are: activity_selector: 0.826, task_scheduling: 0.931
I0831 18:16:34.262062 138047105189376 run.py:707] Algo activity_selector step 6150 current loss 0.965403, current_train_items 84816.
I0831 18:16:34.266032 138047105189376 run.py:707] Algo task_scheduling step 6150 current loss 0.975965, current_train_items 84816.
I0831 18:16:34.282143 138047105189376 run.py:742] (val) algo activity_selector step 6150: {'selected': 0.7940074906367041, 'score': 0.7940074906367041, 'examples_seen': 84816, 'step': 6150, 'algorithm': 'activity_selector'}
I0831 18:16:34.289848 138047105189376 run.py:742] (val) algo task_scheduling step 6150: {'selected': 0.9378453038674033, 'score': 0.9378453038674033, 'examples_seen': 84816, 'step': 6150, 'algorithm': 'task_scheduling'}
I0831 18:16:34.290016 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.866, val scores are: activity_selector: 0.794, task_scheduling: 0.938
I0831 18:16:35.334634 138047105189376 run.py:707] Algo activity_selector step 6200 current loss 0.633966, current_train_items 85520.
I0831 18:16:35.339093 138047105189376 run.py:707] Algo task_scheduling step 6200 current loss 1.146119, current_train_items 85520.
I0831 18:16:35.355562 138047105189376 run.py:742] (val) algo activity_selector step 6200: {'selected': 0.8490945674044266, 'score': 0.8490945674044266, 'examples_seen': 85520, 'step': 6200, 'algorithm': 'activity_selector'}
I0831 18:16:35.363090 138047105189376 run.py:742] (val) algo task_scheduling step 6200: {'selected': 0.9242529534398889, 'score': 0.9242529534398889, 'examples_seen': 85520, 'step': 6200, 'algorithm': 'task_scheduling'}
I0831 18:16:35.363230 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.887, val scores are: activity_selector: 0.849, task_scheduling: 0.924
I0831 18:16:36.385647 138047105189376 run.py:707] Algo activity_selector step 6250 current loss 0.604599, current_train_items 86192.
I0831 18:16:36.389776 138047105189376 run.py:707] Algo task_scheduling step 6250 current loss 1.042744, current_train_items 86192.
I0831 18:16:36.406124 138047105189376 run.py:742] (val) algo activity_selector step 6250: {'selected': 0.861878453038674, 'score': 0.861878453038674, 'examples_seen': 86192, 'step': 6250, 'algorithm': 'activity_selector'}
I0831 18:16:36.413871 138047105189376 run.py:742] (val) algo task_scheduling step 6250: {'selected': 0.9423929098966027, 'score': 0.9423929098966027, 'examples_seen': 86192, 'step': 6250, 'algorithm': 'task_scheduling'}
I0831 18:16:36.414034 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.902, val scores are: activity_selector: 0.862, task_scheduling: 0.942
I0831 18:16:37.471190 138047105189376 run.py:707] Algo activity_selector step 6300 current loss 0.695865, current_train_items 86880.
I0831 18:16:37.475686 138047105189376 run.py:707] Algo task_scheduling step 6300 current loss 1.074843, current_train_items 86880.
I0831 18:16:37.491749 138047105189376 run.py:742] (val) algo activity_selector step 6300: {'selected': 0.8556149732620321, 'score': 0.8556149732620321, 'examples_seen': 86880, 'step': 6300, 'algorithm': 'activity_selector'}
I0831 18:16:37.499311 138047105189376 run.py:742] (val) algo task_scheduling step 6300: {'selected': 0.9466950959488272, 'score': 0.9466950959488272, 'examples_seen': 86880, 'step': 6300, 'algorithm': 'task_scheduling'}
I0831 18:16:37.499451 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.901, val scores are: activity_selector: 0.856, task_scheduling: 0.947
I0831 18:16:38.602412 138047105189376 run.py:707] Algo activity_selector step 6350 current loss 0.386259, current_train_items 87584.
I0831 18:16:38.606818 138047105189376 run.py:707] Algo task_scheduling step 6350 current loss 0.833283, current_train_items 87584.
I0831 18:16:38.623351 138047105189376 run.py:742] (val) algo activity_selector step 6350: {'selected': 0.8809073724007561, 'score': 0.8809073724007561, 'examples_seen': 87584, 'step': 6350, 'algorithm': 'activity_selector'}
I0831 18:16:38.631099 138047105189376 run.py:742] (val) algo task_scheduling step 6350: {'selected': 0.9451303155006859, 'score': 0.9451303155006859, 'examples_seen': 87584, 'step': 6350, 'algorithm': 'task_scheduling'}
I0831 18:16:38.631240 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.913, val scores are: activity_selector: 0.881, task_scheduling: 0.945
I0831 18:16:39.648007 138047105189376 run.py:707] Algo activity_selector step 6400 current loss 0.794538, current_train_items 88272.
I0831 18:16:39.652427 138047105189376 run.py:707] Algo task_scheduling step 6400 current loss 0.871558, current_train_items 88272.
I0831 18:16:39.668981 138047105189376 run.py:742] (val) algo activity_selector step 6400: {'selected': 0.8609022556390977, 'score': 0.8609022556390977, 'examples_seen': 88272, 'step': 6400, 'algorithm': 'activity_selector'}
I0831 18:16:39.676580 138047105189376 run.py:742] (val) algo task_scheduling step 6400: {'selected': 0.9391304347826087, 'score': 0.9391304347826087, 'examples_seen': 88272, 'step': 6400, 'algorithm': 'task_scheduling'}
I0831 18:16:39.676736 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.900, val scores are: activity_selector: 0.861, task_scheduling: 0.939
I0831 18:16:40.754645 138047105189376 run.py:707] Algo activity_selector step 6450 current loss 0.539289, current_train_items 88944.
I0831 18:16:40.759172 138047105189376 run.py:707] Algo task_scheduling step 6450 current loss 1.469999, current_train_items 88944.
I0831 18:16:40.775621 138047105189376 run.py:742] (val) algo activity_selector step 6450: {'selected': 0.8798449612403101, 'score': 0.8798449612403101, 'examples_seen': 88944, 'step': 6450, 'algorithm': 'activity_selector'}
I0831 18:16:40.783391 138047105189376 run.py:742] (val) algo task_scheduling step 6450: {'selected': 0.9507246376811593, 'score': 0.9507246376811593, 'examples_seen': 88944, 'step': 6450, 'algorithm': 'task_scheduling'}
I0831 18:16:40.783544 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.915, val scores are: activity_selector: 0.880, task_scheduling: 0.951
I0831 18:16:41.921352 138047105189376 run.py:707] Algo activity_selector step 6500 current loss 0.847199, current_train_items 89648.
I0831 18:16:41.926340 138047105189376 run.py:707] Algo task_scheduling step 6500 current loss 1.244819, current_train_items 89648.
I0831 18:16:41.944405 138047105189376 run.py:742] (val) algo activity_selector step 6500: {'selected': 0.8821548821548822, 'score': 0.8821548821548822, 'examples_seen': 89648, 'step': 6500, 'algorithm': 'activity_selector'}
I0831 18:16:41.952107 138047105189376 run.py:742] (val) algo task_scheduling step 6500: {'selected': 0.9355539464156408, 'score': 0.9355539464156408, 'examples_seen': 89648, 'step': 6500, 'algorithm': 'task_scheduling'}
I0831 18:16:41.952264 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.909, val scores are: activity_selector: 0.882, task_scheduling: 0.936
I0831 18:16:43.033767 138047105189376 run.py:707] Algo activity_selector step 6550 current loss 0.622805, current_train_items 90336.
I0831 18:16:43.038754 138047105189376 run.py:707] Algo task_scheduling step 6550 current loss 1.579100, current_train_items 90336.
I0831 18:16:43.056532 138047105189376 run.py:742] (val) algo activity_selector step 6550: {'selected': 0.8608534322820036, 'score': 0.8608534322820036, 'examples_seen': 90336, 'step': 6550, 'algorithm': 'activity_selector'}
I0831 18:16:43.064797 138047105189376 run.py:742] (val) algo task_scheduling step 6550: {'selected': 0.9375438596491228, 'score': 0.9375438596491228, 'examples_seen': 90336, 'step': 6550, 'algorithm': 'task_scheduling'}
I0831 18:16:43.064984 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.899, val scores are: activity_selector: 0.861, task_scheduling: 0.938
I0831 18:16:44.265321 138047105189376 run.py:707] Algo activity_selector step 6600 current loss 0.548103, current_train_items 91008.
I0831 18:16:44.270380 138047105189376 run.py:707] Algo task_scheduling step 6600 current loss 1.122498, current_train_items 91008.
I0831 18:16:44.290187 138047105189376 run.py:742] (val) algo activity_selector step 6600: {'selected': 0.8412162162162162, 'score': 0.8412162162162162, 'examples_seen': 91008, 'step': 6600, 'algorithm': 'activity_selector'}
I0831 18:16:44.297957 138047105189376 run.py:742] (val) algo task_scheduling step 6600: {'selected': 0.9454287739192062, 'score': 0.9454287739192062, 'examples_seen': 91008, 'step': 6600, 'algorithm': 'task_scheduling'}
I0831 18:16:44.298102 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.893, val scores are: activity_selector: 0.841, task_scheduling: 0.945
I0831 18:16:45.467002 138047105189376 run.py:707] Algo activity_selector step 6650 current loss 0.616727, current_train_items 91712.
I0831 18:16:45.471618 138047105189376 run.py:707] Algo task_scheduling step 6650 current loss 1.127280, current_train_items 91712.
I0831 18:16:45.487849 138047105189376 run.py:742] (val) algo activity_selector step 6650: {'selected': 0.8464566929133859, 'score': 0.8464566929133859, 'examples_seen': 91712, 'step': 6650, 'algorithm': 'activity_selector'}
I0831 18:16:45.495442 138047105189376 run.py:742] (val) algo task_scheduling step 6650: {'selected': 0.9581464872944695, 'score': 0.9581464872944695, 'examples_seen': 91712, 'step': 6650, 'algorithm': 'task_scheduling'}
I0831 18:16:45.495587 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.902, val scores are: activity_selector: 0.846, task_scheduling: 0.958
I0831 18:16:46.606914 138047105189376 run.py:707] Algo activity_selector step 6700 current loss 1.125053, current_train_items 92416.
I0831 18:16:46.613080 138047105189376 run.py:707] Algo task_scheduling step 6700 current loss 0.790998, current_train_items 92416.
I0831 18:16:46.630010 138047105189376 run.py:742] (val) algo activity_selector step 6700: {'selected': 0.8978805394990366, 'score': 0.8978805394990366, 'examples_seen': 92416, 'step': 6700, 'algorithm': 'activity_selector'}
I0831 18:16:46.637549 138047105189376 run.py:742] (val) algo task_scheduling step 6700: {'selected': 0.9474421864050454, 'score': 0.9474421864050454, 'examples_seen': 92416, 'step': 6700, 'algorithm': 'task_scheduling'}
I0831 18:16:46.637694 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.923, val scores are: activity_selector: 0.898, task_scheduling: 0.947
I0831 18:16:47.799830 138047105189376 run.py:707] Algo activity_selector step 6750 current loss 0.734776, current_train_items 93088.
I0831 18:16:47.804391 138047105189376 run.py:707] Algo task_scheduling step 6750 current loss 1.981416, current_train_items 93088.
I0831 18:16:47.822628 138047105189376 run.py:742] (val) algo activity_selector step 6750: {'selected': 0.8862745098039215, 'score': 0.8862745098039215, 'examples_seen': 93088, 'step': 6750, 'algorithm': 'activity_selector'}
I0831 18:16:47.830281 138047105189376 run.py:742] (val) algo task_scheduling step 6750: {'selected': 0.9405646359583952, 'score': 0.9405646359583952, 'examples_seen': 93088, 'step': 6750, 'algorithm': 'task_scheduling'}
I0831 18:16:47.830422 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.913, val scores are: activity_selector: 0.886, task_scheduling: 0.941
I0831 18:16:48.985686 138047105189376 run.py:707] Algo activity_selector step 6800 current loss 0.476241, current_train_items 93776.
I0831 18:16:48.989969 138047105189376 run.py:707] Algo task_scheduling step 6800 current loss 1.061119, current_train_items 93776.
I0831 18:16:49.006223 138047105189376 run.py:742] (val) algo activity_selector step 6800: {'selected': 0.8487229862475442, 'score': 0.8487229862475442, 'examples_seen': 93776, 'step': 6800, 'algorithm': 'activity_selector'}
I0831 18:16:49.014469 138047105189376 run.py:742] (val) algo task_scheduling step 6800: {'selected': 0.9514978601997147, 'score': 0.9514978601997147, 'examples_seen': 93776, 'step': 6800, 'algorithm': 'task_scheduling'}
I0831 18:16:49.014628 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.900, val scores are: activity_selector: 0.849, task_scheduling: 0.951
I0831 18:16:50.235130 138047105189376 run.py:707] Algo activity_selector step 6850 current loss 0.730740, current_train_items 94480.
I0831 18:16:50.240164 138047105189376 run.py:707] Algo task_scheduling step 6850 current loss 1.071485, current_train_items 94480.
I0831 18:16:50.259965 138047105189376 run.py:742] (val) algo activity_selector step 6850: {'selected': 0.8488964346349746, 'score': 0.8488964346349746, 'examples_seen': 94480, 'step': 6850, 'algorithm': 'activity_selector'}
I0831 18:16:50.268122 138047105189376 run.py:742] (val) algo task_scheduling step 6850: {'selected': 0.9515418502202644, 'score': 0.9515418502202644, 'examples_seen': 94480, 'step': 6850, 'algorithm': 'task_scheduling'}
I0831 18:16:50.268276 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.900, val scores are: activity_selector: 0.849, task_scheduling: 0.952
I0831 18:16:51.353521 138047105189376 run.py:707] Algo activity_selector step 6900 current loss 0.662171, current_train_items 95152.
I0831 18:16:51.358019 138047105189376 run.py:707] Algo task_scheduling step 6900 current loss 1.512014, current_train_items 95152.
I0831 18:16:51.376048 138047105189376 run.py:742] (val) algo activity_selector step 6900: {'selected': 0.8421052631578947, 'score': 0.8421052631578947, 'examples_seen': 95152, 'step': 6900, 'algorithm': 'activity_selector'}
I0831 18:16:51.383771 138047105189376 run.py:742] (val) algo task_scheduling step 6900: {'selected': 0.9226006191950464, 'score': 0.9226006191950464, 'examples_seen': 95152, 'step': 6900, 'algorithm': 'task_scheduling'}
I0831 18:16:51.383919 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.882, val scores are: activity_selector: 0.842, task_scheduling: 0.923
I0831 18:16:52.498092 138047105189376 run.py:707] Algo activity_selector step 6950 current loss 0.851072, current_train_items 95840.
I0831 18:16:52.502649 138047105189376 run.py:707] Algo task_scheduling step 6950 current loss 1.161796, current_train_items 95840.
I0831 18:16:52.519434 138047105189376 run.py:742] (val) algo activity_selector step 6950: {'selected': 0.8669354838709677, 'score': 0.8669354838709677, 'examples_seen': 95840, 'step': 6950, 'algorithm': 'activity_selector'}
I0831 18:16:52.527142 138047105189376 run.py:742] (val) algo task_scheduling step 6950: {'selected': 0.9423487544483985, 'score': 0.9423487544483985, 'examples_seen': 95840, 'step': 6950, 'algorithm': 'task_scheduling'}
I0831 18:16:52.527293 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.905, val scores are: activity_selector: 0.867, task_scheduling: 0.942
I0831 18:16:53.655640 138047105189376 run.py:707] Algo activity_selector step 7000 current loss 0.554833, current_train_items 96544.
I0831 18:16:53.660778 138047105189376 run.py:707] Algo task_scheduling step 7000 current loss 1.388056, current_train_items 96544.
I0831 18:16:53.678526 138047105189376 run.py:742] (val) algo activity_selector step 7000: {'selected': 0.8522072936660269, 'score': 0.8522072936660269, 'examples_seen': 96544, 'step': 7000, 'algorithm': 'activity_selector'}
I0831 18:16:53.686268 138047105189376 run.py:742] (val) algo task_scheduling step 7000: {'selected': 0.9528643944887599, 'score': 0.9528643944887599, 'examples_seen': 96544, 'step': 7000, 'algorithm': 'task_scheduling'}
I0831 18:16:53.686436 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.903, val scores are: activity_selector: 0.852, task_scheduling: 0.953
I0831 18:16:54.885861 138047105189376 run.py:707] Algo activity_selector step 7050 current loss 0.616879, current_train_items 97232.
I0831 18:16:54.890458 138047105189376 run.py:707] Algo task_scheduling step 7050 current loss 1.344108, current_train_items 97232.
I0831 18:16:54.907442 138047105189376 run.py:742] (val) algo activity_selector step 7050: {'selected': 0.8606701940035273, 'score': 0.8606701940035273, 'examples_seen': 97232, 'step': 7050, 'algorithm': 'activity_selector'}
I0831 18:16:54.915099 138047105189376 run.py:742] (val) algo task_scheduling step 7050: {'selected': 0.9440905874026893, 'score': 0.9440905874026893, 'examples_seen': 97232, 'step': 7050, 'algorithm': 'task_scheduling'}
I0831 18:16:54.915245 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.902, val scores are: activity_selector: 0.861, task_scheduling: 0.944
I0831 18:16:55.983877 138047105189376 run.py:707] Algo activity_selector step 7100 current loss 0.693891, current_train_items 97920.
I0831 18:16:55.988148 138047105189376 run.py:707] Algo task_scheduling step 7100 current loss 0.795594, current_train_items 97920.
I0831 18:16:56.006352 138047105189376 run.py:742] (val) algo activity_selector step 7100: {'selected': 0.8484848484848485, 'score': 0.8484848484848485, 'examples_seen': 97920, 'step': 7100, 'algorithm': 'activity_selector'}
I0831 18:16:56.014249 138047105189376 run.py:742] (val) algo task_scheduling step 7100: {'selected': 0.9534555712270805, 'score': 0.9534555712270805, 'examples_seen': 97920, 'step': 7100, 'algorithm': 'task_scheduling'}
I0831 18:16:56.014405 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.901, val scores are: activity_selector: 0.848, task_scheduling: 0.953
I0831 18:16:57.109645 138047105189376 run.py:707] Algo activity_selector step 7150 current loss 0.673433, current_train_items 98608.
I0831 18:16:57.114063 138047105189376 run.py:707] Algo task_scheduling step 7150 current loss 0.865751, current_train_items 98608.
I0831 18:16:57.131437 138047105189376 run.py:742] (val) algo activity_selector step 7150: {'selected': 0.8469184890656063, 'score': 0.8469184890656063, 'examples_seen': 98608, 'step': 7150, 'algorithm': 'activity_selector'}
I0831 18:16:57.139420 138047105189376 run.py:742] (val) algo task_scheduling step 7150: {'selected': 0.9408450704225353, 'score': 0.9408450704225353, 'examples_seen': 98608, 'step': 7150, 'algorithm': 'task_scheduling'}
I0831 18:16:57.139582 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.894, val scores are: activity_selector: 0.847, task_scheduling: 0.941
I0831 18:16:58.369810 138047105189376 run.py:707] Algo activity_selector step 7200 current loss 0.598484, current_train_items 99296.
I0831 18:16:58.374588 138047105189376 run.py:707] Algo task_scheduling step 7200 current loss 0.806146, current_train_items 99296.
I0831 18:16:58.399491 138047105189376 run.py:742] (val) algo activity_selector step 7200: {'selected': 0.879245283018868, 'score': 0.879245283018868, 'examples_seen': 99296, 'step': 7200, 'algorithm': 'activity_selector'}
I0831 18:16:58.409631 138047105189376 run.py:742] (val) algo task_scheduling step 7200: {'selected': 0.93974175035868, 'score': 0.93974175035868, 'examples_seen': 99296, 'step': 7200, 'algorithm': 'task_scheduling'}
I0831 18:16:58.409828 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.909, val scores are: activity_selector: 0.879, task_scheduling: 0.940
I0831 18:16:59.539477 138047105189376 run.py:707] Algo activity_selector step 7250 current loss 0.630710, current_train_items 99984.
I0831 18:16:59.544597 138047105189376 run.py:707] Algo task_scheduling step 7250 current loss 1.387145, current_train_items 99984.
I0831 18:16:59.561598 138047105189376 run.py:742] (val) algo activity_selector step 7250: {'selected': 0.882882882882883, 'score': 0.882882882882883, 'examples_seen': 99984, 'step': 7250, 'algorithm': 'activity_selector'}
I0831 18:16:59.569248 138047105189376 run.py:742] (val) algo task_scheduling step 7250: {'selected': 0.8604459124690339, 'score': 0.8604459124690339, 'examples_seen': 99984, 'step': 7250, 'algorithm': 'task_scheduling'}
I0831 18:16:59.569394 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.872, val scores are: activity_selector: 0.883, task_scheduling: 0.860
I0831 18:17:00.707463 138047105189376 run.py:707] Algo activity_selector step 7300 current loss 0.560895, current_train_items 100672.
I0831 18:17:00.712417 138047105189376 run.py:707] Algo task_scheduling step 7300 current loss 1.795811, current_train_items 100672.
I0831 18:17:00.728922 138047105189376 run.py:742] (val) algo activity_selector step 7300: {'selected': 0.8681898066783832, 'score': 0.8681898066783832, 'examples_seen': 100672, 'step': 7300, 'algorithm': 'activity_selector'}
I0831 18:17:00.736531 138047105189376 run.py:742] (val) algo task_scheduling step 7300: {'selected': 0.9342857142857143, 'score': 0.9342857142857143, 'examples_seen': 100672, 'step': 7300, 'algorithm': 'task_scheduling'}
I0831 18:17:00.736695 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.901, val scores are: activity_selector: 0.868, task_scheduling: 0.934
I0831 18:17:01.859359 138047105189376 run.py:707] Algo activity_selector step 7350 current loss 1.018503, current_train_items 101360.
I0831 18:17:01.864082 138047105189376 run.py:707] Algo task_scheduling step 7350 current loss 0.962594, current_train_items 101360.
I0831 18:17:01.880966 138047105189376 run.py:742] (val) algo activity_selector step 7350: {'selected': 0.8636363636363636, 'score': 0.8636363636363636, 'examples_seen': 101360, 'step': 7350, 'algorithm': 'activity_selector'}
I0831 18:17:01.888781 138047105189376 run.py:742] (val) algo task_scheduling step 7350: {'selected': 0.9594306049822062, 'score': 0.9594306049822062, 'examples_seen': 101360, 'step': 7350, 'algorithm': 'task_scheduling'}
I0831 18:17:01.888924 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.912, val scores are: activity_selector: 0.864, task_scheduling: 0.959
I0831 18:17:03.026269 138047105189376 run.py:707] Algo activity_selector step 7400 current loss 0.676086, current_train_items 102048.
I0831 18:17:03.030653 138047105189376 run.py:707] Algo task_scheduling step 7400 current loss 1.037514, current_train_items 102048.
I0831 18:17:03.046706 138047105189376 run.py:742] (val) algo activity_selector step 7400: {'selected': 0.8566176470588235, 'score': 0.8566176470588235, 'examples_seen': 102048, 'step': 7400, 'algorithm': 'activity_selector'}
I0831 18:17:03.054381 138047105189376 run.py:742] (val) algo task_scheduling step 7400: {'selected': 0.9359605911330049, 'score': 0.9359605911330049, 'examples_seen': 102048, 'step': 7400, 'algorithm': 'task_scheduling'}
I0831 18:17:03.054563 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.896, val scores are: activity_selector: 0.857, task_scheduling: 0.936
I0831 18:17:04.089764 138047105189376 run.py:707] Algo activity_selector step 7450 current loss 0.508756, current_train_items 102752.
I0831 18:17:04.094424 138047105189376 run.py:707] Algo task_scheduling step 7450 current loss 1.039237, current_train_items 102752.
I0831 18:17:04.110627 138047105189376 run.py:742] (val) algo activity_selector step 7450: {'selected': 0.8627450980392156, 'score': 0.8627450980392156, 'examples_seen': 102752, 'step': 7450, 'algorithm': 'activity_selector'}
I0831 18:17:04.118713 138047105189376 run.py:742] (val) algo task_scheduling step 7450: {'selected': 0.9450867052023121, 'score': 0.9450867052023121, 'examples_seen': 102752, 'step': 7450, 'algorithm': 'task_scheduling'}
I0831 18:17:04.118877 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.904, val scores are: activity_selector: 0.863, task_scheduling: 0.945
I0831 18:17:05.195319 138047105189376 run.py:707] Algo activity_selector step 7500 current loss 0.754753, current_train_items 103424.
I0831 18:17:05.199615 138047105189376 run.py:707] Algo task_scheduling step 7500 current loss 1.569521, current_train_items 103424.
I0831 18:17:05.216111 138047105189376 run.py:742] (val) algo activity_selector step 7500: {'selected': 0.8623188405797102, 'score': 0.8623188405797102, 'examples_seen': 103424, 'step': 7500, 'algorithm': 'activity_selector'}
I0831 18:17:05.224234 138047105189376 run.py:742] (val) algo task_scheduling step 7500: {'selected': 0.9401114206128135, 'score': 0.9401114206128135, 'examples_seen': 103424, 'step': 7500, 'algorithm': 'task_scheduling'}
I0831 18:17:05.224400 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.901, val scores are: activity_selector: 0.862, task_scheduling: 0.940
I0831 18:17:06.371041 138047105189376 run.py:707] Algo activity_selector step 7550 current loss 0.939604, current_train_items 104128.
I0831 18:17:06.375627 138047105189376 run.py:707] Algo task_scheduling step 7550 current loss 1.364132, current_train_items 104128.
I0831 18:17:06.392734 138047105189376 run.py:742] (val) algo activity_selector step 7550: {'selected': 0.869402985074627, 'score': 0.869402985074627, 'examples_seen': 104128, 'step': 7550, 'algorithm': 'activity_selector'}
I0831 18:17:06.400508 138047105189376 run.py:742] (val) algo task_scheduling step 7550: {'selected': 0.9443239334779464, 'score': 0.9443239334779464, 'examples_seen': 104128, 'step': 7550, 'algorithm': 'task_scheduling'}
I0831 18:17:06.400662 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.907, val scores are: activity_selector: 0.869, task_scheduling: 0.944
I0831 18:17:07.490700 138047105189376 run.py:707] Algo activity_selector step 7600 current loss 0.726377, current_train_items 104816.
I0831 18:17:07.495491 138047105189376 run.py:707] Algo task_scheduling step 7600 current loss 1.008339, current_train_items 104816.
I0831 18:17:07.512782 138047105189376 run.py:742] (val) algo activity_selector step 7600: {'selected': 0.8752136752136752, 'score': 0.8752136752136752, 'examples_seen': 104816, 'step': 7600, 'algorithm': 'activity_selector'}
I0831 18:17:07.520501 138047105189376 run.py:742] (val) algo task_scheduling step 7600: {'selected': 0.9523809523809523, 'score': 0.9523809523809523, 'examples_seen': 104816, 'step': 7600, 'algorithm': 'task_scheduling'}
I0831 18:17:07.520653 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.914, val scores are: activity_selector: 0.875, task_scheduling: 0.952
I0831 18:17:08.628167 138047105189376 run.py:707] Algo activity_selector step 7650 current loss 0.741354, current_train_items 105488.
I0831 18:17:08.633206 138047105189376 run.py:707] Algo task_scheduling step 7650 current loss 1.000708, current_train_items 105488.
I0831 18:17:08.650477 138047105189376 run.py:742] (val) algo activity_selector step 7650: {'selected': 0.9074074074074073, 'score': 0.9074074074074073, 'examples_seen': 105488, 'step': 7650, 'algorithm': 'activity_selector'}
I0831 18:17:08.658833 138047105189376 run.py:742] (val) algo task_scheduling step 7650: {'selected': 0.944767441860465, 'score': 0.944767441860465, 'examples_seen': 105488, 'step': 7650, 'algorithm': 'task_scheduling'}
I0831 18:17:08.658993 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.926, val scores are: activity_selector: 0.907, task_scheduling: 0.945
I0831 18:17:09.820547 138047105189376 run.py:707] Algo activity_selector step 7700 current loss 0.526139, current_train_items 106192.
I0831 18:17:09.825356 138047105189376 run.py:707] Algo task_scheduling step 7700 current loss 1.257042, current_train_items 106192.
I0831 18:17:09.842967 138047105189376 run.py:742] (val) algo activity_selector step 7700: {'selected': 0.8705035971223021, 'score': 0.8705035971223021, 'examples_seen': 106192, 'step': 7700, 'algorithm': 'activity_selector'}
I0831 18:17:09.850754 138047105189376 run.py:742] (val) algo task_scheduling step 7700: {'selected': 0.9440353460972016, 'score': 0.9440353460972016, 'examples_seen': 106192, 'step': 7700, 'algorithm': 'task_scheduling'}
I0831 18:17:09.850901 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.907, val scores are: activity_selector: 0.871, task_scheduling: 0.944
I0831 18:17:11.045094 138047105189376 run.py:707] Algo activity_selector step 7750 current loss 0.948380, current_train_items 106880.
I0831 18:17:11.050859 138047105189376 run.py:707] Algo task_scheduling step 7750 current loss 1.049621, current_train_items 106880.
I0831 18:17:11.071346 138047105189376 run.py:742] (val) algo activity_selector step 7750: {'selected': 0.9007633587786259, 'score': 0.9007633587786259, 'examples_seen': 106880, 'step': 7750, 'algorithm': 'activity_selector'}
I0831 18:17:11.080768 138047105189376 run.py:742] (val) algo task_scheduling step 7750: {'selected': 0.9390329362298527, 'score': 0.9390329362298527, 'examples_seen': 106880, 'step': 7750, 'algorithm': 'task_scheduling'}
I0831 18:17:11.080979 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.920, val scores are: activity_selector: 0.901, task_scheduling: 0.939
I0831 18:17:12.472703 138047105189376 run.py:707] Algo activity_selector step 7800 current loss 0.567594, current_train_items 107568.
I0831 18:17:12.478336 138047105189376 run.py:707] Algo task_scheduling step 7800 current loss 0.895644, current_train_items 107568.
I0831 18:17:12.496961 138047105189376 run.py:742] (val) algo activity_selector step 7800: {'selected': 0.8592057761732851, 'score': 0.8592057761732851, 'examples_seen': 107568, 'step': 7800, 'algorithm': 'activity_selector'}
I0831 18:17:12.505015 138047105189376 run.py:742] (val) algo task_scheduling step 7800: {'selected': 0.9521770164168452, 'score': 0.9521770164168452, 'examples_seen': 107568, 'step': 7800, 'algorithm': 'task_scheduling'}
I0831 18:17:12.505168 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.906, val scores are: activity_selector: 0.859, task_scheduling: 0.952
I0831 18:17:13.720555 138047105189376 run.py:707] Algo activity_selector step 7850 current loss 0.519539, current_train_items 108256.
I0831 18:17:13.726261 138047105189376 run.py:707] Algo task_scheduling step 7850 current loss 1.000789, current_train_items 108256.
I0831 18:17:13.746988 138047105189376 run.py:742] (val) algo activity_selector step 7850: {'selected': 0.8627450980392156, 'score': 0.8627450980392156, 'examples_seen': 108256, 'step': 7850, 'algorithm': 'activity_selector'}
I0831 18:17:13.754810 138047105189376 run.py:742] (val) algo task_scheduling step 7850: {'selected': 0.9438521677327647, 'score': 0.9438521677327647, 'examples_seen': 108256, 'step': 7850, 'algorithm': 'task_scheduling'}
I0831 18:17:13.755014 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.903, val scores are: activity_selector: 0.863, task_scheduling: 0.944
I0831 18:17:15.051855 138047105189376 run.py:707] Algo activity_selector step 7900 current loss 0.680029, current_train_items 108960.
I0831 18:17:15.057570 138047105189376 run.py:707] Algo task_scheduling step 7900 current loss 0.754556, current_train_items 108960.
I0831 18:17:15.075085 138047105189376 run.py:742] (val) algo activity_selector step 7900: {'selected': 0.8376623376623377, 'score': 0.8376623376623377, 'examples_seen': 108960, 'step': 7900, 'algorithm': 'activity_selector'}
I0831 18:17:15.083789 138047105189376 run.py:742] (val) algo task_scheduling step 7900: {'selected': 0.9455081001472755, 'score': 0.9455081001472755, 'examples_seen': 108960, 'step': 7900, 'algorithm': 'task_scheduling'}
I0831 18:17:15.083991 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.892, val scores are: activity_selector: 0.838, task_scheduling: 0.946
I0831 18:17:16.310509 138047105189376 run.py:707] Algo activity_selector step 7950 current loss 1.099524, current_train_items 109632.
I0831 18:17:16.316323 138047105189376 run.py:707] Algo task_scheduling step 7950 current loss 0.965029, current_train_items 109632.
I0831 18:17:16.334509 138047105189376 run.py:742] (val) algo activity_selector step 7950: {'selected': 0.8767123287671234, 'score': 0.8767123287671234, 'examples_seen': 109632, 'step': 7950, 'algorithm': 'activity_selector'}
I0831 18:17:16.342966 138047105189376 run.py:742] (val) algo task_scheduling step 7950: {'selected': 0.9408450704225353, 'score': 0.9408450704225353, 'examples_seen': 109632, 'step': 7950, 'algorithm': 'task_scheduling'}
I0831 18:17:16.343139 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.909, val scores are: activity_selector: 0.877, task_scheduling: 0.941
I0831 18:17:17.636513 138047105189376 run.py:707] Algo activity_selector step 8000 current loss 0.483659, current_train_items 110320.
I0831 18:17:17.643583 138047105189376 run.py:707] Algo task_scheduling step 8000 current loss 1.147570, current_train_items 110320.
I0831 18:17:17.661720 138047105189376 run.py:742] (val) algo activity_selector step 8000: {'selected': 0.8872727272727272, 'score': 0.8872727272727272, 'examples_seen': 110320, 'step': 8000, 'algorithm': 'activity_selector'}
I0831 18:17:17.670142 138047105189376 run.py:742] (val) algo task_scheduling step 8000: {'selected': 0.935483870967742, 'score': 0.935483870967742, 'examples_seen': 110320, 'step': 8000, 'algorithm': 'task_scheduling'}
I0831 18:17:17.670293 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.933, current avg val score is 0.911, val scores are: activity_selector: 0.887, task_scheduling: 0.935
I0831 18:17:19.012816 138047105189376 run.py:707] Algo activity_selector step 8050 current loss 0.336258, current_train_items 111024.
I0831 18:17:19.020413 138047105189376 run.py:707] Algo task_scheduling step 8050 current loss 0.745010, current_train_items 111024.
I0831 18:17:19.046156 138047105189376 run.py:742] (val) algo activity_selector step 8050: {'selected': 0.8727915194346291, 'score': 0.8727915194346291, 'examples_seen': 111024, 'step': 8050, 'algorithm': 'activity_selector'}
I0831 18:17:19.054785 138047105189376 run.py:742] (val) algo task_scheduling step 8050: {'selected': 0.9514978601997146, 'score': 0.9514978601997146, 'examples_seen': 111024, 'step': 8050, 'algorithm': 'task_scheduling'}
I0831 18:17:19.054972 138047105189376 run.py:763] Checkpointing best model, best avg val score was -0.500, current avg val score is 0.912, val scores are: activity_selector: 0.873, task_scheduling: 0.951
I0831 18:17:20.340082 138047105189376 run.py:707] Algo activity_selector step 8100 current loss 0.593641, current_train_items 111696.
I0831 18:17:20.346525 138047105189376 run.py:707] Algo task_scheduling step 8100 current loss 1.185930, current_train_items 111696.
I0831 18:17:20.364126 138047105189376 run.py:742] (val) algo activity_selector step 8100: {'selected': 0.8672897196261682, 'score': 0.8672897196261682, 'examples_seen': 111696, 'step': 8100, 'algorithm': 'activity_selector'}
I0831 18:17:20.372300 138047105189376 run.py:742] (val) algo task_scheduling step 8100: {'selected': 0.9444021325209444, 'score': 0.9444021325209444, 'examples_seen': 111696, 'step': 8100, 'algorithm': 'task_scheduling'}
I0831 18:17:20.372505 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.912, current avg val score is 0.906, val scores are: activity_selector: 0.867, task_scheduling: 0.944
I0831 18:17:21.554416 138047105189376 run.py:707] Algo activity_selector step 8150 current loss 0.906287, current_train_items 112400.
I0831 18:17:21.559577 138047105189376 run.py:707] Algo task_scheduling step 8150 current loss 1.230044, current_train_items 112400.
I0831 18:17:21.578216 138047105189376 run.py:742] (val) algo activity_selector step 8150: {'selected': 0.8439716312056738, 'score': 0.8439716312056738, 'examples_seen': 112400, 'step': 8150, 'algorithm': 'activity_selector'}
I0831 18:17:21.586108 138047105189376 run.py:742] (val) algo task_scheduling step 8150: {'selected': 0.9385474860335197, 'score': 0.9385474860335197, 'examples_seen': 112400, 'step': 8150, 'algorithm': 'task_scheduling'}
I0831 18:17:21.586255 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.912, current avg val score is 0.891, val scores are: activity_selector: 0.844, task_scheduling: 0.939
I0831 18:17:22.743673 138047105189376 run.py:707] Algo activity_selector step 8200 current loss 0.999708, current_train_items 113088.
I0831 18:17:22.748564 138047105189376 run.py:707] Algo task_scheduling step 8200 current loss 0.778665, current_train_items 113088.
I0831 18:17:22.765803 138047105189376 run.py:742] (val) algo activity_selector step 8200: {'selected': 0.8680688336520078, 'score': 0.8680688336520078, 'examples_seen': 113088, 'step': 8200, 'algorithm': 'activity_selector'}
I0831 18:17:22.773807 138047105189376 run.py:742] (val) algo task_scheduling step 8200: {'selected': 0.9483115093039283, 'score': 0.9483115093039283, 'examples_seen': 113088, 'step': 8200, 'algorithm': 'task_scheduling'}
I0831 18:17:22.774022 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.912, current avg val score is 0.908, val scores are: activity_selector: 0.868, task_scheduling: 0.948
I0831 18:17:23.916762 138047105189376 run.py:707] Algo activity_selector step 8250 current loss 0.615122, current_train_items 113760.
I0831 18:17:23.921062 138047105189376 run.py:707] Algo task_scheduling step 8250 current loss 2.393215, current_train_items 113760.
I0831 18:17:23.939162 138047105189376 run.py:742] (val) algo activity_selector step 8250: {'selected': 0.8373702422145329, 'score': 0.8373702422145329, 'examples_seen': 113760, 'step': 8250, 'algorithm': 'activity_selector'}
I0831 18:17:23.947014 138047105189376 run.py:742] (val) algo task_scheduling step 8250: {'selected': 0.9478390461997019, 'score': 0.9478390461997019, 'examples_seen': 113760, 'step': 8250, 'algorithm': 'task_scheduling'}
I0831 18:17:23.947172 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.912, current avg val score is 0.893, val scores are: activity_selector: 0.837, task_scheduling: 0.948
I0831 18:17:25.123865 138047105189376 run.py:707] Algo activity_selector step 8300 current loss 0.828327, current_train_items 114464.
I0831 18:17:25.129538 138047105189376 run.py:707] Algo task_scheduling step 8300 current loss 1.210046, current_train_items 114464.
I0831 18:17:25.147918 138047105189376 run.py:742] (val) algo activity_selector step 8300: {'selected': 0.877005347593583, 'score': 0.877005347593583, 'examples_seen': 114464, 'step': 8300, 'algorithm': 'activity_selector'}
I0831 18:17:25.156047 138047105189376 run.py:742] (val) algo task_scheduling step 8300: {'selected': 0.951130561633844, 'score': 0.951130561633844, 'examples_seen': 114464, 'step': 8300, 'algorithm': 'task_scheduling'}
I0831 18:17:25.156225 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.912, current avg val score is 0.914, val scores are: activity_selector: 0.877, task_scheduling: 0.951
I0831 18:17:26.377963 138047105189376 run.py:707] Algo activity_selector step 8350 current loss 0.905131, current_train_items 115152.
I0831 18:17:26.384724 138047105189376 run.py:707] Algo task_scheduling step 8350 current loss 1.620142, current_train_items 115152.
I0831 18:17:26.403510 138047105189376 run.py:742] (val) algo activity_selector step 8350: {'selected': 0.8743362831858408, 'score': 0.8743362831858408, 'examples_seen': 115152, 'step': 8350, 'algorithm': 'activity_selector'}
I0831 18:17:26.413386 138047105189376 run.py:742] (val) algo task_scheduling step 8350: {'selected': 0.9547892720306514, 'score': 0.9547892720306514, 'examples_seen': 115152, 'step': 8350, 'algorithm': 'task_scheduling'}
I0831 18:17:26.413556 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.914, current avg val score is 0.915, val scores are: activity_selector: 0.874, task_scheduling: 0.955
I0831 18:17:27.800585 138047105189376 run.py:707] Algo activity_selector step 8400 current loss 0.587899, current_train_items 115840.
I0831 18:17:27.804409 138047105189376 run.py:707] Algo task_scheduling step 8400 current loss 1.062338, current_train_items 115840.
I0831 18:17:27.823982 138047105189376 run.py:742] (val) algo activity_selector step 8400: {'selected': 0.8571428571428572, 'score': 0.8571428571428572, 'examples_seen': 115840, 'step': 8400, 'algorithm': 'activity_selector'}
I0831 18:17:27.832312 138047105189376 run.py:742] (val) algo task_scheduling step 8400: {'selected': 0.9491289198606271, 'score': 0.9491289198606271, 'examples_seen': 115840, 'step': 8400, 'algorithm': 'task_scheduling'}
I0831 18:17:27.832495 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.915, current avg val score is 0.903, val scores are: activity_selector: 0.857, task_scheduling: 0.949
I0831 18:17:28.995304 138047105189376 run.py:707] Algo activity_selector step 8450 current loss 0.756047, current_train_items 116528.
I0831 18:17:29.000045 138047105189376 run.py:707] Algo task_scheduling step 8450 current loss 1.135374, current_train_items 116528.
I0831 18:17:29.018174 138047105189376 run.py:742] (val) algo activity_selector step 8450: {'selected': 0.8860294117647058, 'score': 0.8860294117647058, 'examples_seen': 116528, 'step': 8450, 'algorithm': 'activity_selector'}
I0831 18:17:29.026610 138047105189376 run.py:742] (val) algo task_scheduling step 8450: {'selected': 0.9449793672627235, 'score': 0.9449793672627235, 'examples_seen': 116528, 'step': 8450, 'algorithm': 'task_scheduling'}
I0831 18:17:29.026766 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.915, current avg val score is 0.916, val scores are: activity_selector: 0.886, task_scheduling: 0.945
I0831 18:17:30.181330 138047105189376 run.py:707] Algo activity_selector step 8500 current loss 0.646415, current_train_items 117232.
I0831 18:17:30.186455 138047105189376 run.py:707] Algo task_scheduling step 8500 current loss 0.737483, current_train_items 117232.
I0831 18:17:30.205360 138047105189376 run.py:742] (val) algo activity_selector step 8500: {'selected': 0.8820326678765881, 'score': 0.8820326678765881, 'examples_seen': 117232, 'step': 8500, 'algorithm': 'activity_selector'}
I0831 18:17:30.213553 138047105189376 run.py:742] (val) algo task_scheduling step 8500: {'selected': 0.9309608540925266, 'score': 0.9309608540925266, 'examples_seen': 117232, 'step': 8500, 'algorithm': 'task_scheduling'}
I0831 18:17:30.213724 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.916, current avg val score is 0.906, val scores are: activity_selector: 0.882, task_scheduling: 0.931
I0831 18:17:31.375833 138047105189376 run.py:707] Algo activity_selector step 8550 current loss 0.594638, current_train_items 117904.
I0831 18:17:31.380708 138047105189376 run.py:707] Algo task_scheduling step 8550 current loss 0.846169, current_train_items 117904.
I0831 18:17:31.397700 138047105189376 run.py:742] (val) algo activity_selector step 8550: {'selected': 0.906015037593985, 'score': 0.906015037593985, 'examples_seen': 117904, 'step': 8550, 'algorithm': 'activity_selector'}
I0831 18:17:31.406228 138047105189376 run.py:742] (val) algo task_scheduling step 8550: {'selected': 0.9407514450867053, 'score': 0.9407514450867053, 'examples_seen': 117904, 'step': 8550, 'algorithm': 'task_scheduling'}
I0831 18:17:31.406435 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.916, current avg val score is 0.923, val scores are: activity_selector: 0.906, task_scheduling: 0.941
I0831 18:17:32.604126 138047105189376 run.py:707] Algo activity_selector step 8600 current loss 0.823347, current_train_items 118592.
I0831 18:17:32.608628 138047105189376 run.py:707] Algo task_scheduling step 8600 current loss 0.661162, current_train_items 118592.
I0831 18:17:32.627685 138047105189376 run.py:742] (val) algo activity_selector step 8600: {'selected': 0.8410462776659959, 'score': 0.8410462776659959, 'examples_seen': 118592, 'step': 8600, 'algorithm': 'activity_selector'}
I0831 18:17:32.636211 138047105189376 run.py:742] (val) algo task_scheduling step 8600: {'selected': 0.9465317919075145, 'score': 0.9465317919075145, 'examples_seen': 118592, 'step': 8600, 'algorithm': 'task_scheduling'}
I0831 18:17:32.636386 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.894, val scores are: activity_selector: 0.841, task_scheduling: 0.947
I0831 18:17:33.784877 138047105189376 run.py:707] Algo activity_selector step 8650 current loss 0.728981, current_train_items 119296.
I0831 18:17:33.789900 138047105189376 run.py:707] Algo task_scheduling step 8650 current loss 0.817786, current_train_items 119296.
I0831 18:17:33.808301 138047105189376 run.py:742] (val) algo activity_selector step 8650: {'selected': 0.8609022556390977, 'score': 0.8609022556390977, 'examples_seen': 119296, 'step': 8650, 'algorithm': 'activity_selector'}
I0831 18:17:33.816056 138047105189376 run.py:742] (val) algo task_scheduling step 8650: {'selected': 0.9192982456140351, 'score': 0.9192982456140351, 'examples_seen': 119296, 'step': 8650, 'algorithm': 'task_scheduling'}
I0831 18:17:33.816205 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.890, val scores are: activity_selector: 0.861, task_scheduling: 0.919
I0831 18:17:34.920395 138047105189376 run.py:707] Algo activity_selector step 8700 current loss 0.880701, current_train_items 119968.
I0831 18:17:34.925136 138047105189376 run.py:707] Algo task_scheduling step 8700 current loss 0.862385, current_train_items 119968.
I0831 18:17:34.942805 138047105189376 run.py:742] (val) algo activity_selector step 8700: {'selected': 0.8093525179856115, 'score': 0.8093525179856115, 'examples_seen': 119968, 'step': 8700, 'algorithm': 'activity_selector'}
I0831 18:17:34.950706 138047105189376 run.py:742] (val) algo task_scheduling step 8700: {'selected': 0.9541284403669725, 'score': 0.9541284403669725, 'examples_seen': 119968, 'step': 8700, 'algorithm': 'task_scheduling'}
I0831 18:17:34.950901 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.882, val scores are: activity_selector: 0.809, task_scheduling: 0.954
I0831 18:17:36.058040 138047105189376 run.py:707] Algo activity_selector step 8750 current loss 0.802762, current_train_items 120672.
I0831 18:17:36.062843 138047105189376 run.py:707] Algo task_scheduling step 8750 current loss 0.758071, current_train_items 120672.
I0831 18:17:36.080255 138047105189376 run.py:742] (val) algo activity_selector step 8750: {'selected': 0.8836363636363636, 'score': 0.8836363636363636, 'examples_seen': 120672, 'step': 8750, 'algorithm': 'activity_selector'}
I0831 18:17:36.088283 138047105189376 run.py:742] (val) algo task_scheduling step 8750: {'selected': 0.9352818371607515, 'score': 0.9352818371607515, 'examples_seen': 120672, 'step': 8750, 'algorithm': 'task_scheduling'}
I0831 18:17:36.088440 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.909, val scores are: activity_selector: 0.884, task_scheduling: 0.935
I0831 18:17:37.196317 138047105189376 run.py:707] Algo activity_selector step 8800 current loss 0.917021, current_train_items 121360.
I0831 18:17:37.201612 138047105189376 run.py:707] Algo task_scheduling step 8800 current loss 1.024648, current_train_items 121360.
I0831 18:17:37.219988 138047105189376 run.py:742] (val) algo activity_selector step 8800: {'selected': 0.8349514563106797, 'score': 0.8349514563106797, 'examples_seen': 121360, 'step': 8800, 'algorithm': 'activity_selector'}
I0831 18:17:37.228773 138047105189376 run.py:742] (val) algo task_scheduling step 8800: {'selected': 0.9342465753424657, 'score': 0.9342465753424657, 'examples_seen': 121360, 'step': 8800, 'algorithm': 'task_scheduling'}
I0831 18:17:37.228967 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.885, val scores are: activity_selector: 0.835, task_scheduling: 0.934
I0831 18:17:38.382898 138047105189376 run.py:707] Algo activity_selector step 8850 current loss 0.970139, current_train_items 122048.
I0831 18:17:38.388809 138047105189376 run.py:707] Algo task_scheduling step 8850 current loss 0.853550, current_train_items 122048.
I0831 18:17:38.409185 138047105189376 run.py:742] (val) algo activity_selector step 8850: {'selected': 0.8735632183908046, 'score': 0.8735632183908046, 'examples_seen': 122048, 'step': 8850, 'algorithm': 'activity_selector'}
I0831 18:17:38.417304 138047105189376 run.py:742] (val) algo task_scheduling step 8850: {'selected': 0.950608446671439, 'score': 0.950608446671439, 'examples_seen': 122048, 'step': 8850, 'algorithm': 'task_scheduling'}
I0831 18:17:38.417510 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.912, val scores are: activity_selector: 0.874, task_scheduling: 0.951
I0831 18:17:39.602198 138047105189376 run.py:707] Algo activity_selector step 8900 current loss 0.898583, current_train_items 122736.
I0831 18:17:39.607322 138047105189376 run.py:707] Algo task_scheduling step 8900 current loss 1.040951, current_train_items 122736.
I0831 18:17:39.626339 138047105189376 run.py:742] (val) algo activity_selector step 8900: {'selected': 0.8629629629629629, 'score': 0.8629629629629629, 'examples_seen': 122736, 'step': 8900, 'algorithm': 'activity_selector'}
I0831 18:17:39.634123 138047105189376 run.py:742] (val) algo task_scheduling step 8900: {'selected': 0.9461161651504549, 'score': 0.9461161651504549, 'examples_seen': 122736, 'step': 8900, 'algorithm': 'task_scheduling'}
I0831 18:17:39.634314 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.905, val scores are: activity_selector: 0.863, task_scheduling: 0.946
I0831 18:17:40.750153 138047105189376 run.py:707] Algo activity_selector step 8950 current loss 0.979143, current_train_items 123424.
I0831 18:17:40.755007 138047105189376 run.py:707] Algo task_scheduling step 8950 current loss 0.853768, current_train_items 123424.
I0831 18:17:40.773518 138047105189376 run.py:742] (val) algo activity_selector step 8950: {'selected': 0.8868274582560296, 'score': 0.8868274582560296, 'examples_seen': 123424, 'step': 8950, 'algorithm': 'activity_selector'}
I0831 18:17:40.781720 138047105189376 run.py:742] (val) algo task_scheduling step 8950: {'selected': 0.9415904292751583, 'score': 0.9415904292751583, 'examples_seen': 123424, 'step': 8950, 'algorithm': 'task_scheduling'}
I0831 18:17:40.781987 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.914, val scores are: activity_selector: 0.887, task_scheduling: 0.942
I0831 18:17:41.960195 138047105189376 run.py:707] Algo activity_selector step 9000 current loss 0.245771, current_train_items 124112.
I0831 18:17:41.964856 138047105189376 run.py:707] Algo task_scheduling step 9000 current loss 1.096420, current_train_items 124112.
I0831 18:17:41.982267 138047105189376 run.py:742] (val) algo activity_selector step 9000: {'selected': 0.8789571694599627, 'score': 0.8789571694599627, 'examples_seen': 124112, 'step': 9000, 'algorithm': 'activity_selector'}
I0831 18:17:41.991142 138047105189376 run.py:742] (val) algo task_scheduling step 9000: {'selected': 0.9507494646680942, 'score': 0.9507494646680942, 'examples_seen': 124112, 'step': 9000, 'algorithm': 'task_scheduling'}
I0831 18:17:41.991290 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.915, val scores are: activity_selector: 0.879, task_scheduling: 0.951
I0831 18:17:43.119978 138047105189376 run.py:707] Algo activity_selector step 9050 current loss 0.431367, current_train_items 124800.
I0831 18:17:43.125430 138047105189376 run.py:707] Algo task_scheduling step 9050 current loss 1.182119, current_train_items 124800.
I0831 18:17:43.141618 138047105189376 run.py:742] (val) algo activity_selector step 9050: {'selected': 0.8682745825602968, 'score': 0.8682745825602968, 'examples_seen': 124800, 'step': 9050, 'algorithm': 'activity_selector'}
I0831 18:17:43.149189 138047105189376 run.py:742] (val) algo task_scheduling step 9050: {'selected': 0.9445214979195563, 'score': 0.9445214979195563, 'examples_seen': 124800, 'step': 9050, 'algorithm': 'task_scheduling'}
I0831 18:17:43.149337 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.906, val scores are: activity_selector: 0.868, task_scheduling: 0.945
I0831 18:17:44.245295 138047105189376 run.py:707] Algo activity_selector step 9100 current loss 0.407669, current_train_items 125488.
I0831 18:17:44.251216 138047105189376 run.py:707] Algo task_scheduling step 9100 current loss 1.111664, current_train_items 125488.
I0831 18:17:44.268412 138047105189376 run.py:742] (val) algo activity_selector step 9100: {'selected': 0.8961748633879782, 'score': 0.8961748633879782, 'examples_seen': 125488, 'step': 9100, 'algorithm': 'activity_selector'}
I0831 18:17:44.276738 138047105189376 run.py:742] (val) algo task_scheduling step 9100: {'selected': 0.9428369795342274, 'score': 0.9428369795342274, 'examples_seen': 125488, 'step': 9100, 'algorithm': 'task_scheduling'}
I0831 18:17:44.276884 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.920, val scores are: activity_selector: 0.896, task_scheduling: 0.943
I0831 18:17:45.410420 138047105189376 run.py:707] Algo activity_selector step 9150 current loss 0.680400, current_train_items 126176.
I0831 18:17:45.416227 138047105189376 run.py:707] Algo task_scheduling step 9150 current loss 1.212925, current_train_items 126176.
I0831 18:17:45.431723 138047105189376 run.py:742] (val) algo activity_selector step 9150: {'selected': 0.8876190476190476, 'score': 0.8876190476190476, 'examples_seen': 126176, 'step': 9150, 'algorithm': 'activity_selector'}
I0831 18:17:45.440241 138047105189376 run.py:742] (val) algo task_scheduling step 9150: {'selected': 0.9493670886075949, 'score': 0.9493670886075949, 'examples_seen': 126176, 'step': 9150, 'algorithm': 'task_scheduling'}
I0831 18:17:45.440392 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.918, val scores are: activity_selector: 0.888, task_scheduling: 0.949
I0831 18:17:46.533556 138047105189376 run.py:707] Algo activity_selector step 9200 current loss 1.016726, current_train_items 126880.
I0831 18:17:46.538761 138047105189376 run.py:707] Algo task_scheduling step 9200 current loss 0.988826, current_train_items 126880.
I0831 18:17:46.555254 138047105189376 run.py:742] (val) algo activity_selector step 9200: {'selected': 0.8913443830570903, 'score': 0.8913443830570903, 'examples_seen': 126880, 'step': 9200, 'algorithm': 'activity_selector'}
I0831 18:17:46.563611 138047105189376 run.py:742] (val) algo task_scheduling step 9200: {'selected': 0.9318651066758431, 'score': 0.9318651066758431, 'examples_seen': 126880, 'step': 9200, 'algorithm': 'task_scheduling'}
I0831 18:17:46.563775 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.912, val scores are: activity_selector: 0.891, task_scheduling: 0.932
I0831 18:17:47.692952 138047105189376 run.py:707] Algo activity_selector step 9250 current loss 0.745050, current_train_items 127568.
I0831 18:17:47.697733 138047105189376 run.py:707] Algo task_scheduling step 9250 current loss 1.310642, current_train_items 127568.
I0831 18:17:47.714991 138047105189376 run.py:742] (val) algo activity_selector step 9250: {'selected': 0.7862903225806451, 'score': 0.7862903225806451, 'examples_seen': 127568, 'step': 9250, 'algorithm': 'activity_selector'}
I0831 18:17:47.722710 138047105189376 run.py:742] (val) algo task_scheduling step 9250: {'selected': 0.9443269908386187, 'score': 0.9443269908386187, 'examples_seen': 127568, 'step': 9250, 'algorithm': 'task_scheduling'}
I0831 18:17:47.722862 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.865, val scores are: activity_selector: 0.786, task_scheduling: 0.944
I0831 18:17:48.814403 138047105189376 run.py:707] Algo activity_selector step 9300 current loss 1.002353, current_train_items 128240.
I0831 18:17:48.819411 138047105189376 run.py:707] Algo task_scheduling step 9300 current loss 0.961654, current_train_items 128240.
I0831 18:17:48.836268 138047105189376 run.py:742] (val) algo activity_selector step 9300: {'selected': 0.8778761061946901, 'score': 0.8778761061946901, 'examples_seen': 128240, 'step': 9300, 'algorithm': 'activity_selector'}
I0831 18:17:48.844745 138047105189376 run.py:742] (val) algo task_scheduling step 9300: {'selected': 0.940771349862259, 'score': 0.940771349862259, 'examples_seen': 128240, 'step': 9300, 'algorithm': 'task_scheduling'}
I0831 18:17:48.844895 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.909, val scores are: activity_selector: 0.878, task_scheduling: 0.941
I0831 18:17:49.927269 138047105189376 run.py:707] Algo activity_selector step 9350 current loss 0.424777, current_train_items 128944.
I0831 18:17:49.931746 138047105189376 run.py:707] Algo task_scheduling step 9350 current loss 0.721497, current_train_items 128944.
I0831 18:17:49.947401 138047105189376 run.py:742] (val) algo activity_selector step 9350: {'selected': 0.8750000000000001, 'score': 0.8750000000000001, 'examples_seen': 128944, 'step': 9350, 'algorithm': 'activity_selector'}
I0831 18:17:49.955124 138047105189376 run.py:742] (val) algo task_scheduling step 9350: {'selected': 0.9216087252897068, 'score': 0.9216087252897068, 'examples_seen': 128944, 'step': 9350, 'algorithm': 'task_scheduling'}
I0831 18:17:49.955265 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.898, val scores are: activity_selector: 0.875, task_scheduling: 0.922
I0831 18:17:51.032027 138047105189376 run.py:707] Algo activity_selector step 9400 current loss 0.776665, current_train_items 129632.
I0831 18:17:51.036679 138047105189376 run.py:707] Algo task_scheduling step 9400 current loss 0.869269, current_train_items 129632.
I0831 18:17:51.052110 138047105189376 run.py:742] (val) algo activity_selector step 9400: {'selected': 0.8505338078291814, 'score': 0.8505338078291814, 'examples_seen': 129632, 'step': 9400, 'algorithm': 'activity_selector'}
I0831 18:17:51.059706 138047105189376 run.py:742] (val) algo task_scheduling step 9400: {'selected': 0.9337883959044369, 'score': 0.9337883959044369, 'examples_seen': 129632, 'step': 9400, 'algorithm': 'task_scheduling'}
I0831 18:17:51.059862 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.892, val scores are: activity_selector: 0.851, task_scheduling: 0.934
I0831 18:17:52.130377 138047105189376 run.py:707] Algo activity_selector step 9450 current loss 0.762149, current_train_items 130304.
I0831 18:17:52.134870 138047105189376 run.py:707] Algo task_scheduling step 9450 current loss 0.871955, current_train_items 130304.
I0831 18:17:52.151676 138047105189376 run.py:742] (val) algo activity_selector step 9450: {'selected': 0.8522727272727273, 'score': 0.8522727272727273, 'examples_seen': 130304, 'step': 9450, 'algorithm': 'activity_selector'}
I0831 18:17:52.160978 138047105189376 run.py:742] (val) algo task_scheduling step 9450: {'selected': 0.9356643356643357, 'score': 0.9356643356643357, 'examples_seen': 130304, 'step': 9450, 'algorithm': 'task_scheduling'}
I0831 18:17:52.161147 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.894, val scores are: activity_selector: 0.852, task_scheduling: 0.936
I0831 18:17:53.290246 138047105189376 run.py:707] Algo activity_selector step 9500 current loss 0.823309, current_train_items 131008.
I0831 18:17:53.294777 138047105189376 run.py:707] Algo task_scheduling step 9500 current loss 1.181650, current_train_items 131008.
I0831 18:17:53.310652 138047105189376 run.py:742] (val) algo activity_selector step 9500: {'selected': 0.8437500000000001, 'score': 0.8437500000000001, 'examples_seen': 131008, 'step': 9500, 'algorithm': 'activity_selector'}
I0831 18:17:53.318193 138047105189376 run.py:742] (val) algo task_scheduling step 9500: {'selected': 0.9289533995416349, 'score': 0.9289533995416349, 'examples_seen': 131008, 'step': 9500, 'algorithm': 'task_scheduling'}
I0831 18:17:53.318383 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.886, val scores are: activity_selector: 0.844, task_scheduling: 0.929
I0831 18:17:54.375568 138047105189376 run.py:707] Algo activity_selector step 9550 current loss 0.280322, current_train_items 131712.
I0831 18:17:54.379939 138047105189376 run.py:707] Algo task_scheduling step 9550 current loss 0.647812, current_train_items 131712.
I0831 18:17:54.395755 138047105189376 run.py:742] (val) algo activity_selector step 9550: {'selected': 0.8451242829827916, 'score': 0.8451242829827916, 'examples_seen': 131712, 'step': 9550, 'algorithm': 'activity_selector'}
I0831 18:17:54.403375 138047105189376 run.py:742] (val) algo task_scheduling step 9550: {'selected': 0.9421375085091899, 'score': 0.9421375085091899, 'examples_seen': 131712, 'step': 9550, 'algorithm': 'task_scheduling'}
I0831 18:17:54.403518 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.894, val scores are: activity_selector: 0.845, task_scheduling: 0.942
I0831 18:17:55.461428 138047105189376 run.py:707] Algo activity_selector step 9600 current loss 0.441843, current_train_items 132384.
I0831 18:17:55.466659 138047105189376 run.py:707] Algo task_scheduling step 9600 current loss 0.774540, current_train_items 132384.
I0831 18:17:55.485460 138047105189376 run.py:742] (val) algo activity_selector step 9600: {'selected': 0.8673267326732673, 'score': 0.8673267326732673, 'examples_seen': 132384, 'step': 9600, 'algorithm': 'activity_selector'}
I0831 18:17:55.493876 138047105189376 run.py:742] (val) algo task_scheduling step 9600: {'selected': 0.9117647058823529, 'score': 0.9117647058823529, 'examples_seen': 132384, 'step': 9600, 'algorithm': 'task_scheduling'}
I0831 18:17:55.494100 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.890, val scores are: activity_selector: 0.867, task_scheduling: 0.912
I0831 18:17:56.597645 138047105189376 run.py:707] Algo activity_selector step 9650 current loss 0.466035, current_train_items 133072.
I0831 18:17:56.602104 138047105189376 run.py:707] Algo task_scheduling step 9650 current loss 1.273733, current_train_items 133072.
I0831 18:17:56.618269 138047105189376 run.py:742] (val) algo activity_selector step 9650: {'selected': 0.8765652951699462, 'score': 0.8765652951699462, 'examples_seen': 133072, 'step': 9650, 'algorithm': 'activity_selector'}
I0831 18:17:56.625837 138047105189376 run.py:742] (val) algo task_scheduling step 9650: {'selected': 0.921832884097035, 'score': 0.921832884097035, 'examples_seen': 133072, 'step': 9650, 'algorithm': 'task_scheduling'}
I0831 18:17:56.625991 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.923, current avg val score is 0.899, val scores are: activity_selector: 0.877, task_scheduling: 0.922
I0831 18:17:57.711032 138047105189376 run.py:707] Algo activity_selector step 9700 current loss 0.666796, current_train_items 133776.
I0831 18:17:57.716304 138047105189376 run.py:707] Algo task_scheduling step 9700 current loss 0.713288, current_train_items 133776.
I0831 18:17:57.732674 138047105189376 run.py:742] (val) algo activity_selector step 9700: {'selected': 0.9227941176470589, 'score': 0.9227941176470589, 'examples_seen': 133776, 'step': 9700, 'algorithm': 'activity_selector'}
I0831 18:17:57.740298 138047105189376 run.py:742] (val) algo task_scheduling step 9700: {'selected': 0.9384934346924672, 'score': 0.9384934346924672, 'examples_seen': 133776, 'step': 9700, 'algorithm': 'task_scheduling'}
I0831 18:17:57.740454 138047105189376 run.py:763] Checkpointing best model, best avg val score was 0.923, current avg val score is 0.931, val scores are: activity_selector: 0.923, task_scheduling: 0.938
I0831 18:17:58.839382 138047105189376 run.py:707] Algo activity_selector step 9750 current loss 0.607109, current_train_items 134448.
I0831 18:17:58.844509 138047105189376 run.py:707] Algo task_scheduling step 9750 current loss 0.776876, current_train_items 134448.
I0831 18:17:58.862310 138047105189376 run.py:742] (val) algo activity_selector step 9750: {'selected': 0.8608534322820038, 'score': 0.8608534322820038, 'examples_seen': 134448, 'step': 9750, 'algorithm': 'activity_selector'}
I0831 18:17:58.869882 138047105189376 run.py:742] (val) algo task_scheduling step 9750: {'selected': 0.9341917024320459, 'score': 0.9341917024320459, 'examples_seen': 134448, 'step': 9750, 'algorithm': 'task_scheduling'}
I0831 18:17:58.870039 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.931, current avg val score is 0.898, val scores are: activity_selector: 0.861, task_scheduling: 0.934
I0831 18:18:00.000045 138047105189376 run.py:707] Algo activity_selector step 9800 current loss 0.738716, current_train_items 135136.
I0831 18:18:00.004888 138047105189376 run.py:707] Algo task_scheduling step 9800 current loss 1.328462, current_train_items 135136.
I0831 18:18:00.026883 138047105189376 run.py:742] (val) algo activity_selector step 9800: {'selected': 0.8867187500000001, 'score': 0.8867187500000001, 'examples_seen': 135136, 'step': 9800, 'algorithm': 'activity_selector'}
I0831 18:18:00.035659 138047105189376 run.py:742] (val) algo task_scheduling step 9800: {'selected': 0.9427374301675978, 'score': 0.9427374301675978, 'examples_seen': 135136, 'step': 9800, 'algorithm': 'task_scheduling'}
I0831 18:18:00.035822 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.931, current avg val score is 0.915, val scores are: activity_selector: 0.887, task_scheduling: 0.943
I0831 18:18:01.192396 138047105189376 run.py:707] Algo activity_selector step 9850 current loss 0.469781, current_train_items 135840.
I0831 18:18:01.196068 138047105189376 run.py:707] Algo task_scheduling step 9850 current loss 1.421286, current_train_items 135840.
I0831 18:18:01.212759 138047105189376 run.py:742] (val) algo activity_selector step 9850: {'selected': 0.8829787234042554, 'score': 0.8829787234042554, 'examples_seen': 135840, 'step': 9850, 'algorithm': 'activity_selector'}
I0831 18:18:01.220399 138047105189376 run.py:742] (val) algo task_scheduling step 9850: {'selected': 0.933426769446391, 'score': 0.933426769446391, 'examples_seen': 135840, 'step': 9850, 'algorithm': 'task_scheduling'}
I0831 18:18:01.220549 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.931, current avg val score is 0.908, val scores are: activity_selector: 0.883, task_scheduling: 0.933
I0831 18:18:02.320327 138047105189376 run.py:707] Algo activity_selector step 9900 current loss 0.600351, current_train_items 136528.
I0831 18:18:02.325103 138047105189376 run.py:707] Algo task_scheduling step 9900 current loss 1.375012, current_train_items 136528.
I0831 18:18:02.342204 138047105189376 run.py:742] (val) algo activity_selector step 9900: {'selected': 0.8724584103512015, 'score': 0.8724584103512015, 'examples_seen': 136528, 'step': 9900, 'algorithm': 'activity_selector'}
I0831 18:18:02.350034 138047105189376 run.py:742] (val) algo task_scheduling step 9900: {'selected': 0.9446391030133147, 'score': 0.9446391030133147, 'examples_seen': 136528, 'step': 9900, 'algorithm': 'task_scheduling'}
I0831 18:18:02.350228 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.931, current avg val score is 0.909, val scores are: activity_selector: 0.872, task_scheduling: 0.945
I0831 18:18:03.411814 138047105189376 run.py:707] Algo activity_selector step 9950 current loss 0.692052, current_train_items 137200.
I0831 18:18:03.417253 138047105189376 run.py:707] Algo task_scheduling step 9950 current loss 0.950430, current_train_items 137200.
I0831 18:18:03.433860 138047105189376 run.py:742] (val) algo activity_selector step 9950: {'selected': 0.8364312267657992, 'score': 0.8364312267657992, 'examples_seen': 137200, 'step': 9950, 'algorithm': 'activity_selector'}
I0831 18:18:03.442689 138047105189376 run.py:742] (val) algo task_scheduling step 9950: {'selected': 0.923076923076923, 'score': 0.923076923076923, 'examples_seen': 137200, 'step': 9950, 'algorithm': 'task_scheduling'}
I0831 18:18:03.442846 138047105189376 run.py:766] Not saving new best model, best avg val score was 0.931, current avg val score is 0.880, val scores are: activity_selector: 0.836, task_scheduling: 0.923
I0831 18:18:04.523295 138047105189376 run.py:772] Restoring best model from checkpoint...
I0831 18:18:07.441593 138047105189376 run.py:787] (test) algo activity_selector : {'selected': 0.6734992679355783, 'score': 0.6734992679355783, 'examples_seen': 137888, 'step': 10000, 'algorithm': 'activity_selector'}
I0831 18:18:08.677630 138047105189376 run.py:787] (test) algo task_scheduling : {'selected': 0.7885609978703986, 'score': 0.7885609978703986, 'examples_seen': 137888, 'step': 10000, 'algorithm': 'task_scheduling'}
I0831 18:18:08.677802 138047105189376 run.py:789] Done!
