I1007 06:43:04.723960 127508787635712 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I1007 06:43:04.726302 127508787635712 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I1007 06:43:05.041766 127508787635712 run.py:453] Model: f7 ['activity_selector']
I1007 06:43:05.041863 127508787635712 run.py:455] algorithms ['activity_selector']
I1007 06:43:05.042040 127508787635712 run.py:456] train_lengths ['4', '7', '11', '13', '16']
I1007 06:43:05.042077 127508787635712 run.py:457] train_batch_size 16
I1007 06:43:05.042166 127508787635712 run.py:458] val_batch_size 8
I1007 06:43:05.042198 127508787635712 run.py:459] test_batch_size 8
I1007 06:43:05.042227 127508787635712 run.py:460] chunked_training True
I1007 06:43:05.042353 127508787635712 run.py:461] chunk_length 16
I1007 06:43:05.042384 127508787635712 run.py:462] train_steps 10000
I1007 06:43:05.042413 127508787635712 run.py:463] eval_every 50
I1007 06:43:05.042442 127508787635712 run.py:464] test_every 500
I1007 06:43:05.042473 127508787635712 run.py:465] hidden_size 128
I1007 06:43:05.042503 127508787635712 run.py:466] nb_msg_passing_steps 1
I1007 06:43:05.042531 127508787635712 run.py:467] learning_rate 0.001
I1007 06:43:05.042618 127508787635712 run.py:468] grad_clip_max_norm 1.0
I1007 06:43:05.042649 127508787635712 run.py:469] dropout_prob 0.1
I1007 06:43:05.042679 127508787635712 run.py:470] hint_teacher_forcing 0.0
I1007 06:43:05.042707 127508787635712 run.py:471] hint_mode encoded_decoded
I1007 06:43:05.042807 127508787635712 run.py:472] hint_repred_mode soft
I1007 06:43:05.042838 127508787635712 run.py:473] use_ln True
I1007 06:43:05.042866 127508787635712 run.py:474] use_lstm True
I1007 06:43:05.042894 127508787635712 run.py:475] nb_triplet_fts 8
I1007 06:43:05.042921 127508787635712 run.py:476] encoder_init xavier_on_scalars
I1007 06:43:05.042949 127508787635712 run.py:477] processor_type f7
I1007 06:43:05.042978 127508787635712 run.py:478] checkpoint_path CLRS30
I1007 06:43:05.043009 127508787635712 run.py:479] dataset_path CLRS30
I1007 06:43:05.043037 127508787635712 run.py:480] freeze_processor False
I1007 06:43:05.043065 127508787635712 run.py:481] reduction min
I1007 06:43:05.043093 127508787635712 run.py:482] activation elu
I1007 06:43:05.043121 127508787635712 run.py:483] restore_model 
I1007 06:43:05.043148 127508787635712 run.py:484] gated True
I1007 06:43:05.043178 127508787635712 run.py:485] gated_activation tanh
I1007 06:43:05.045866 127508787635712 run.py:511] Creating samplers for algo activity_selector
W1007 06:43:05.046039 127508787635712 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1007 06:43:05.046300 127508787635712 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W1007 06:43:05.254955 127508787635712 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1007 06:43:05.493439 127508787635712 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1007 06:43:05.790871 127508787635712 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1007 06:43:06.120126 127508787635712 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1007 06:43:06.499693 127508787635712 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I1007 06:43:06.499952 127508787635712 samplers.py:124] Creating a dataset with 64 samples.
I1007 06:43:06.525811 127508787635712 run.py:297] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I1007 06:43:06.526561 127508787635712 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I1007 06:43:06.530128 127508787635712 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I1007 06:43:06.533334 127508787635712 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I1007 06:43:06.586509 127508787635712 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W1007 06:43:06.607327 127508787635712 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x73f76f6c89a0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I1007 06:43:41.695584 127508787635712 run.py:734] Algo activity_selector step 0 current loss 5.217938, current_train_items 32.
I1007 06:43:49.681893 127508787635712 run.py:769] (val) algo activity_selector step 0: {'selected': 0.0, 'score': 0.0, 'examples_seen': 32, 'step': 0, 'algorithm': 'activity_selector'}
I1007 06:43:49.682057 127508787635712 run.py:790] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.000, val scores are: activity_selector: 0.000
I1007 06:44:39.439368 127508787635712 run.py:734] Algo activity_selector step 50 current loss 3.729107, current_train_items 1408.
I1007 06:44:39.469161 127508787635712 run.py:769] (val) algo activity_selector step 50: {'selected': 0.693069306930693, 'score': 0.693069306930693, 'examples_seen': 1408, 'step': 50, 'algorithm': 'activity_selector'}
I1007 06:44:39.469327 127508787635712 run.py:790] Checkpointing best model, best avg val score was 0.000, current avg val score is 0.693, val scores are: activity_selector: 0.693
I1007 06:44:40.369025 127508787635712 run.py:734] Algo activity_selector step 100 current loss 3.274553, current_train_items 2800.
I1007 06:44:40.398087 127508787635712 run.py:769] (val) algo activity_selector step 100: {'selected': 0.7257731958762886, 'score': 0.7257731958762886, 'examples_seen': 2800, 'step': 100, 'algorithm': 'activity_selector'}
I1007 06:44:40.398242 127508787635712 run.py:790] Checkpointing best model, best avg val score was 0.693, current avg val score is 0.726, val scores are: activity_selector: 0.726
I1007 06:44:41.326178 127508787635712 run.py:734] Algo activity_selector step 150 current loss 3.248319, current_train_items 4176.
I1007 06:44:41.355373 127508787635712 run.py:769] (val) algo activity_selector step 150: {'selected': 0.7385229540918163, 'score': 0.7385229540918163, 'examples_seen': 4176, 'step': 150, 'algorithm': 'activity_selector'}
I1007 06:44:41.355524 127508787635712 run.py:790] Checkpointing best model, best avg val score was 0.726, current avg val score is 0.739, val scores are: activity_selector: 0.739
I1007 06:44:42.251406 127508787635712 run.py:734] Algo activity_selector step 200 current loss 3.087645, current_train_items 5536.
I1007 06:44:42.280728 127508787635712 run.py:769] (val) algo activity_selector step 200: {'selected': 0.7360861759425493, 'score': 0.7360861759425493, 'examples_seen': 5536, 'step': 200, 'algorithm': 'activity_selector'}
I1007 06:44:42.280880 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.739, current avg val score is 0.736, val scores are: activity_selector: 0.736
I1007 06:44:43.167842 127508787635712 run.py:734] Algo activity_selector step 250 current loss 2.682845, current_train_items 6944.
I1007 06:44:43.196877 127508787635712 run.py:769] (val) algo activity_selector step 250: {'selected': 0.7186311787072243, 'score': 0.7186311787072243, 'examples_seen': 6944, 'step': 250, 'algorithm': 'activity_selector'}
I1007 06:44:43.197026 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.739, current avg val score is 0.719, val scores are: activity_selector: 0.719
I1007 06:44:44.093874 127508787635712 run.py:734] Algo activity_selector step 300 current loss 2.446099, current_train_items 8304.
I1007 06:44:44.123430 127508787635712 run.py:769] (val) algo activity_selector step 300: {'selected': 0.7573149741824441, 'score': 0.7573149741824441, 'examples_seen': 8304, 'step': 300, 'algorithm': 'activity_selector'}
I1007 06:44:44.123582 127508787635712 run.py:790] Checkpointing best model, best avg val score was 0.739, current avg val score is 0.757, val scores are: activity_selector: 0.757
I1007 06:44:45.033229 127508787635712 run.py:734] Algo activity_selector step 350 current loss 2.204291, current_train_items 9680.
I1007 06:44:45.065802 127508787635712 run.py:769] (val) algo activity_selector step 350: {'selected': 0.8068181818181818, 'score': 0.8068181818181818, 'examples_seen': 9680, 'step': 350, 'algorithm': 'activity_selector'}
I1007 06:44:45.065962 127508787635712 run.py:790] Checkpointing best model, best avg val score was 0.757, current avg val score is 0.807, val scores are: activity_selector: 0.807
I1007 06:44:45.981107 127508787635712 run.py:734] Algo activity_selector step 400 current loss 2.209427, current_train_items 11072.
I1007 06:44:46.010500 127508787635712 run.py:769] (val) algo activity_selector step 400: {'selected': 0.7992766726943942, 'score': 0.7992766726943942, 'examples_seen': 11072, 'step': 400, 'algorithm': 'activity_selector'}
I1007 06:44:46.010651 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.807, current avg val score is 0.799, val scores are: activity_selector: 0.799
I1007 06:44:46.905707 127508787635712 run.py:734] Algo activity_selector step 450 current loss 2.024968, current_train_items 12448.
I1007 06:44:46.936098 127508787635712 run.py:769] (val) algo activity_selector step 450: {'selected': 0.826086956521739, 'score': 0.826086956521739, 'examples_seen': 12448, 'step': 450, 'algorithm': 'activity_selector'}
I1007 06:44:46.936257 127508787635712 run.py:790] Checkpointing best model, best avg val score was 0.807, current avg val score is 0.826, val scores are: activity_selector: 0.826
I1007 06:44:47.885337 127508787635712 run.py:734] Algo activity_selector step 500 current loss 2.370839, current_train_items 13824.
I1007 06:44:47.914884 127508787635712 run.py:769] (val) algo activity_selector step 500: {'selected': 0.7678244972577697, 'score': 0.7678244972577697, 'examples_seen': 13824, 'step': 500, 'algorithm': 'activity_selector'}
I1007 06:44:47.915051 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.826, current avg val score is 0.768, val scores are: activity_selector: 0.768
I1007 06:44:48.832555 127508787635712 run.py:734] Algo activity_selector step 550 current loss 1.845688, current_train_items 15200.
I1007 06:44:48.862159 127508787635712 run.py:769] (val) algo activity_selector step 550: {'selected': 0.7857142857142857, 'score': 0.7857142857142857, 'examples_seen': 15200, 'step': 550, 'algorithm': 'activity_selector'}
I1007 06:44:48.862350 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.826, current avg val score is 0.786, val scores are: activity_selector: 0.786
I1007 06:44:49.788353 127508787635712 run.py:734] Algo activity_selector step 600 current loss 2.058955, current_train_items 16576.
I1007 06:44:49.821631 127508787635712 run.py:769] (val) algo activity_selector step 600: {'selected': 0.8311195445920304, 'score': 0.8311195445920304, 'examples_seen': 16576, 'step': 600, 'algorithm': 'activity_selector'}
I1007 06:44:49.821782 127508787635712 run.py:790] Checkpointing best model, best avg val score was 0.826, current avg val score is 0.831, val scores are: activity_selector: 0.831
I1007 06:44:50.783505 127508787635712 run.py:734] Algo activity_selector step 650 current loss 1.931973, current_train_items 17952.
I1007 06:44:50.814975 127508787635712 run.py:769] (val) algo activity_selector step 650: {'selected': 0.8825757575757576, 'score': 0.8825757575757576, 'examples_seen': 17952, 'step': 650, 'algorithm': 'activity_selector'}
I1007 06:44:50.815141 127508787635712 run.py:790] Checkpointing best model, best avg val score was 0.831, current avg val score is 0.883, val scores are: activity_selector: 0.883
I1007 06:44:51.753403 127508787635712 run.py:734] Algo activity_selector step 700 current loss 1.995197, current_train_items 19344.
I1007 06:44:51.782607 127508787635712 run.py:769] (val) algo activity_selector step 700: {'selected': 0.8402366863905325, 'score': 0.8402366863905325, 'examples_seen': 19344, 'step': 700, 'algorithm': 'activity_selector'}
I1007 06:44:51.782760 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.883, current avg val score is 0.840, val scores are: activity_selector: 0.840
I1007 06:44:52.696218 127508787635712 run.py:734] Algo activity_selector step 750 current loss 1.945074, current_train_items 20720.
I1007 06:44:52.725961 127508787635712 run.py:769] (val) algo activity_selector step 750: {'selected': 0.8648648648648648, 'score': 0.8648648648648648, 'examples_seen': 20720, 'step': 750, 'algorithm': 'activity_selector'}
I1007 06:44:52.726113 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.883, current avg val score is 0.865, val scores are: activity_selector: 0.865
I1007 06:44:53.610098 127508787635712 run.py:734] Algo activity_selector step 800 current loss 1.859552, current_train_items 22096.
I1007 06:44:53.640197 127508787635712 run.py:769] (val) algo activity_selector step 800: {'selected': 0.9024856596558317, 'score': 0.9024856596558317, 'examples_seen': 22096, 'step': 800, 'algorithm': 'activity_selector'}
I1007 06:44:53.640356 127508787635712 run.py:790] Checkpointing best model, best avg val score was 0.883, current avg val score is 0.902, val scores are: activity_selector: 0.902
I1007 06:44:54.547461 127508787635712 run.py:734] Algo activity_selector step 850 current loss 1.790457, current_train_items 23472.
I1007 06:44:54.576869 127508787635712 run.py:769] (val) algo activity_selector step 850: {'selected': 0.8980392156862745, 'score': 0.8980392156862745, 'examples_seen': 23472, 'step': 850, 'algorithm': 'activity_selector'}
I1007 06:44:54.577019 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.902, current avg val score is 0.898, val scores are: activity_selector: 0.898
I1007 06:44:55.474496 127508787635712 run.py:734] Algo activity_selector step 900 current loss 1.929792, current_train_items 24848.
I1007 06:44:55.503574 127508787635712 run.py:769] (val) algo activity_selector step 900: {'selected': 0.8841698841698842, 'score': 0.8841698841698842, 'examples_seen': 24848, 'step': 900, 'algorithm': 'activity_selector'}
I1007 06:44:55.503726 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.902, current avg val score is 0.884, val scores are: activity_selector: 0.884
I1007 06:44:56.391589 127508787635712 run.py:734] Algo activity_selector step 950 current loss 1.610864, current_train_items 26224.
I1007 06:44:56.421474 127508787635712 run.py:769] (val) algo activity_selector step 950: {'selected': 0.8998178506375228, 'score': 0.8998178506375228, 'examples_seen': 26224, 'step': 950, 'algorithm': 'activity_selector'}
I1007 06:44:56.421625 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.902, current avg val score is 0.900, val scores are: activity_selector: 0.900
I1007 06:44:57.308845 127508787635712 run.py:734] Algo activity_selector step 1000 current loss 1.721019, current_train_items 27616.
I1007 06:44:57.337936 127508787635712 run.py:769] (val) algo activity_selector step 1000: {'selected': 0.871508379888268, 'score': 0.871508379888268, 'examples_seen': 27616, 'step': 1000, 'algorithm': 'activity_selector'}
I1007 06:44:57.338086 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.902, current avg val score is 0.872, val scores are: activity_selector: 0.872
I1007 06:44:58.224860 127508787635712 run.py:734] Algo activity_selector step 1050 current loss 1.764714, current_train_items 28992.
I1007 06:44:58.254759 127508787635712 run.py:769] (val) algo activity_selector step 1050: {'selected': 0.9283018867924528, 'score': 0.9283018867924528, 'examples_seen': 28992, 'step': 1050, 'algorithm': 'activity_selector'}
I1007 06:44:58.254910 127508787635712 run.py:790] Checkpointing best model, best avg val score was 0.902, current avg val score is 0.928, val scores are: activity_selector: 0.928
I1007 06:44:59.148291 127508787635712 run.py:734] Algo activity_selector step 1100 current loss 1.806992, current_train_items 30368.
I1007 06:44:59.177914 127508787635712 run.py:769] (val) algo activity_selector step 1100: {'selected': 0.8793774319066148, 'score': 0.8793774319066148, 'examples_seen': 30368, 'step': 1100, 'algorithm': 'activity_selector'}
I1007 06:44:59.178064 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.928, current avg val score is 0.879, val scores are: activity_selector: 0.879
I1007 06:45:00.085731 127508787635712 run.py:734] Algo activity_selector step 1150 current loss 1.556229, current_train_items 31760.
I1007 06:45:00.117125 127508787635712 run.py:769] (val) algo activity_selector step 1150: {'selected': 0.8824593128390598, 'score': 0.8824593128390598, 'examples_seen': 31760, 'step': 1150, 'algorithm': 'activity_selector'}
I1007 06:45:00.117290 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.928, current avg val score is 0.882, val scores are: activity_selector: 0.882
I1007 06:45:01.003644 127508787635712 run.py:734] Algo activity_selector step 1200 current loss 1.312610, current_train_items 33120.
I1007 06:45:01.033261 127508787635712 run.py:769] (val) algo activity_selector step 1200: {'selected': 0.9325842696629214, 'score': 0.9325842696629214, 'examples_seen': 33120, 'step': 1200, 'algorithm': 'activity_selector'}
I1007 06:45:01.033413 127508787635712 run.py:790] Checkpointing best model, best avg val score was 0.928, current avg val score is 0.933, val scores are: activity_selector: 0.933
I1007 06:45:01.946625 127508787635712 run.py:734] Algo activity_selector step 1250 current loss 1.379063, current_train_items 34496.
I1007 06:45:01.976294 127508787635712 run.py:769] (val) algo activity_selector step 1250: {'selected': 0.9127272727272727, 'score': 0.9127272727272727, 'examples_seen': 34496, 'step': 1250, 'algorithm': 'activity_selector'}
I1007 06:45:01.976450 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.933, current avg val score is 0.913, val scores are: activity_selector: 0.913
I1007 06:45:02.865211 127508787635712 run.py:734] Algo activity_selector step 1300 current loss 1.333830, current_train_items 35888.
I1007 06:45:02.894371 127508787635712 run.py:769] (val) algo activity_selector step 1300: {'selected': 0.944223107569721, 'score': 0.944223107569721, 'examples_seen': 35888, 'step': 1300, 'algorithm': 'activity_selector'}
I1007 06:45:02.894523 127508787635712 run.py:790] Checkpointing best model, best avg val score was 0.933, current avg val score is 0.944, val scores are: activity_selector: 0.944
I1007 06:45:03.818634 127508787635712 run.py:734] Algo activity_selector step 1350 current loss 1.481901, current_train_items 37264.
I1007 06:45:03.848018 127508787635712 run.py:769] (val) algo activity_selector step 1350: {'selected': 0.8488612836438922, 'score': 0.8488612836438922, 'examples_seen': 37264, 'step': 1350, 'algorithm': 'activity_selector'}
I1007 06:45:03.848170 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.944, current avg val score is 0.849, val scores are: activity_selector: 0.849
I1007 06:45:04.738455 127508787635712 run.py:734] Algo activity_selector step 1400 current loss 1.353163, current_train_items 38640.
I1007 06:45:04.767567 127508787635712 run.py:769] (val) algo activity_selector step 1400: {'selected': 0.8692449355432781, 'score': 0.8692449355432781, 'examples_seen': 38640, 'step': 1400, 'algorithm': 'activity_selector'}
I1007 06:45:04.767715 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.944, current avg val score is 0.869, val scores are: activity_selector: 0.869
I1007 06:45:05.649141 127508787635712 run.py:734] Algo activity_selector step 1450 current loss 1.265914, current_train_items 40016.
I1007 06:45:05.680320 127508787635712 run.py:769] (val) algo activity_selector step 1450: {'selected': 0.9076620825147349, 'score': 0.9076620825147349, 'examples_seen': 40016, 'step': 1450, 'algorithm': 'activity_selector'}
I1007 06:45:05.680472 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.944, current avg val score is 0.908, val scores are: activity_selector: 0.908
I1007 06:45:06.579417 127508787635712 run.py:734] Algo activity_selector step 1500 current loss 1.530971, current_train_items 41408.
I1007 06:45:06.608281 127508787635712 run.py:769] (val) algo activity_selector step 1500: {'selected': 0.8775137111517366, 'score': 0.8775137111517366, 'examples_seen': 41408, 'step': 1500, 'algorithm': 'activity_selector'}
I1007 06:45:06.608440 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.944, current avg val score is 0.878, val scores are: activity_selector: 0.878
I1007 06:45:07.491512 127508787635712 run.py:734] Algo activity_selector step 1550 current loss 1.466751, current_train_items 42768.
I1007 06:45:07.523376 127508787635712 run.py:769] (val) algo activity_selector step 1550: {'selected': 0.922201138519924, 'score': 0.922201138519924, 'examples_seen': 42768, 'step': 1550, 'algorithm': 'activity_selector'}
I1007 06:45:07.523528 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.944, current avg val score is 0.922, val scores are: activity_selector: 0.922
I1007 06:45:08.416319 127508787635712 run.py:734] Algo activity_selector step 1600 current loss 1.351188, current_train_items 44160.
I1007 06:45:08.445828 127508787635712 run.py:769] (val) algo activity_selector step 1600: {'selected': 0.920388349514563, 'score': 0.920388349514563, 'examples_seen': 44160, 'step': 1600, 'algorithm': 'activity_selector'}
I1007 06:45:08.445980 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.944, current avg val score is 0.920, val scores are: activity_selector: 0.920
I1007 06:45:09.330909 127508787635712 run.py:734] Algo activity_selector step 1650 current loss 1.524609, current_train_items 45536.
I1007 06:45:09.360625 127508787635712 run.py:769] (val) algo activity_selector step 1650: {'selected': 0.8232758620689655, 'score': 0.8232758620689655, 'examples_seen': 45536, 'step': 1650, 'algorithm': 'activity_selector'}
I1007 06:45:09.360776 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.944, current avg val score is 0.823, val scores are: activity_selector: 0.823
I1007 06:45:10.237532 127508787635712 run.py:734] Algo activity_selector step 1700 current loss 1.077394, current_train_items 46896.
I1007 06:45:10.266971 127508787635712 run.py:769] (val) algo activity_selector step 1700: {'selected': 0.9686274509803922, 'score': 0.9686274509803922, 'examples_seen': 46896, 'step': 1700, 'algorithm': 'activity_selector'}
I1007 06:45:10.267123 127508787635712 run.py:790] Checkpointing best model, best avg val score was 0.944, current avg val score is 0.969, val scores are: activity_selector: 0.969
I1007 06:45:11.180362 127508787635712 run.py:734] Algo activity_selector step 1750 current loss 1.216803, current_train_items 48304.
I1007 06:45:11.210167 127508787635712 run.py:769] (val) algo activity_selector step 1750: {'selected': 0.9081081081081082, 'score': 0.9081081081081082, 'examples_seen': 48304, 'step': 1750, 'algorithm': 'activity_selector'}
I1007 06:45:11.210325 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.908, val scores are: activity_selector: 0.908
I1007 06:45:12.086648 127508787635712 run.py:734] Algo activity_selector step 1800 current loss 1.200086, current_train_items 49664.
I1007 06:45:12.116820 127508787635712 run.py:769] (val) algo activity_selector step 1800: {'selected': 0.8660550458715597, 'score': 0.8660550458715597, 'examples_seen': 49664, 'step': 1800, 'algorithm': 'activity_selector'}
I1007 06:45:12.116980 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.866, val scores are: activity_selector: 0.866
I1007 06:45:13.003685 127508787635712 run.py:734] Algo activity_selector step 1850 current loss 1.319577, current_train_items 51056.
I1007 06:45:13.032998 127508787635712 run.py:769] (val) algo activity_selector step 1850: {'selected': 0.9233449477351916, 'score': 0.9233449477351916, 'examples_seen': 51056, 'step': 1850, 'algorithm': 'activity_selector'}
I1007 06:45:13.033150 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.923, val scores are: activity_selector: 0.923
I1007 06:45:13.916765 127508787635712 run.py:734] Algo activity_selector step 1900 current loss 1.135393, current_train_items 52432.
I1007 06:45:13.946205 127508787635712 run.py:769] (val) algo activity_selector step 1900: {'selected': 0.8966789667896679, 'score': 0.8966789667896679, 'examples_seen': 52432, 'step': 1900, 'algorithm': 'activity_selector'}
I1007 06:45:13.946367 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.897, val scores are: activity_selector: 0.897
I1007 06:45:14.834290 127508787635712 run.py:734] Algo activity_selector step 1950 current loss 1.213620, current_train_items 53808.
I1007 06:45:14.863852 127508787635712 run.py:769] (val) algo activity_selector step 1950: {'selected': 0.9007092198581561, 'score': 0.9007092198581561, 'examples_seen': 53808, 'step': 1950, 'algorithm': 'activity_selector'}
I1007 06:45:14.864007 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.901, val scores are: activity_selector: 0.901
I1007 06:45:15.752063 127508787635712 run.py:734] Algo activity_selector step 2000 current loss 1.074508, current_train_items 55184.
I1007 06:45:15.781344 127508787635712 run.py:769] (val) algo activity_selector step 2000: {'selected': 0.9182879377431905, 'score': 0.9182879377431905, 'examples_seen': 55184, 'step': 2000, 'algorithm': 'activity_selector'}
I1007 06:45:15.781495 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.918, val scores are: activity_selector: 0.918
I1007 06:45:16.656079 127508787635712 run.py:734] Algo activity_selector step 2050 current loss 1.115940, current_train_items 56560.
I1007 06:45:16.685861 127508787635712 run.py:769] (val) algo activity_selector step 2050: {'selected': 0.8736842105263158, 'score': 0.8736842105263158, 'examples_seen': 56560, 'step': 2050, 'algorithm': 'activity_selector'}
I1007 06:45:16.686013 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.874, val scores are: activity_selector: 0.874
I1007 06:45:17.587207 127508787635712 run.py:734] Algo activity_selector step 2100 current loss 1.279767, current_train_items 57952.
I1007 06:45:17.617350 127508787635712 run.py:769] (val) algo activity_selector step 2100: {'selected': 0.9511754068716094, 'score': 0.9511754068716094, 'examples_seen': 57952, 'step': 2100, 'algorithm': 'activity_selector'}
I1007 06:45:17.617514 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.951, val scores are: activity_selector: 0.951
I1007 06:45:18.504377 127508787635712 run.py:734] Algo activity_selector step 2150 current loss 1.540809, current_train_items 59312.
I1007 06:45:18.536876 127508787635712 run.py:769] (val) algo activity_selector step 2150: {'selected': 0.869402985074627, 'score': 0.869402985074627, 'examples_seen': 59312, 'step': 2150, 'algorithm': 'activity_selector'}
I1007 06:45:18.537029 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.869, val scores are: activity_selector: 0.869
I1007 06:45:19.431758 127508787635712 run.py:734] Algo activity_selector step 2200 current loss 1.286999, current_train_items 60720.
I1007 06:45:19.461358 127508787635712 run.py:769] (val) algo activity_selector step 2200: {'selected': 0.9009345794392524, 'score': 0.9009345794392524, 'examples_seen': 60720, 'step': 2200, 'algorithm': 'activity_selector'}
I1007 06:45:19.461508 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.901, val scores are: activity_selector: 0.901
I1007 06:45:20.360096 127508787635712 run.py:734] Algo activity_selector step 2250 current loss 1.232026, current_train_items 62080.
I1007 06:45:20.390449 127508787635712 run.py:769] (val) algo activity_selector step 2250: {'selected': 0.9128014842300556, 'score': 0.9128014842300556, 'examples_seen': 62080, 'step': 2250, 'algorithm': 'activity_selector'}
I1007 06:45:20.390600 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.913, val scores are: activity_selector: 0.913
I1007 06:45:21.276355 127508787635712 run.py:734] Algo activity_selector step 2300 current loss 1.152991, current_train_items 63440.
I1007 06:45:21.306216 127508787635712 run.py:769] (val) algo activity_selector step 2300: {'selected': 0.9520295202952029, 'score': 0.9520295202952029, 'examples_seen': 63440, 'step': 2300, 'algorithm': 'activity_selector'}
I1007 06:45:21.306378 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.952, val scores are: activity_selector: 0.952
I1007 06:45:22.208652 127508787635712 run.py:734] Algo activity_selector step 2350 current loss 0.983217, current_train_items 64848.
I1007 06:45:22.237793 127508787635712 run.py:769] (val) algo activity_selector step 2350: {'selected': 0.9568480300187617, 'score': 0.9568480300187617, 'examples_seen': 64848, 'step': 2350, 'algorithm': 'activity_selector'}
I1007 06:45:22.237943 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.957, val scores are: activity_selector: 0.957
I1007 06:45:23.123817 127508787635712 run.py:734] Algo activity_selector step 2400 current loss 1.110138, current_train_items 66208.
I1007 06:45:23.152855 127508787635712 run.py:769] (val) algo activity_selector step 2400: {'selected': 0.9364791288566242, 'score': 0.9364791288566242, 'examples_seen': 66208, 'step': 2400, 'algorithm': 'activity_selector'}
I1007 06:45:23.153006 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1007 06:45:24.055922 127508787635712 run.py:734] Algo activity_selector step 2450 current loss 1.266847, current_train_items 67600.
I1007 06:45:24.086274 127508787635712 run.py:769] (val) algo activity_selector step 2450: {'selected': 0.9678638941398866, 'score': 0.9678638941398866, 'examples_seen': 67600, 'step': 2450, 'algorithm': 'activity_selector'}
I1007 06:45:24.086424 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.968, val scores are: activity_selector: 0.968
I1007 06:45:24.975723 127508787635712 run.py:734] Algo activity_selector step 2500 current loss 0.986251, current_train_items 68976.
I1007 06:45:25.004878 127508787635712 run.py:769] (val) algo activity_selector step 2500: {'selected': 0.9269230769230768, 'score': 0.9269230769230768, 'examples_seen': 68976, 'step': 2500, 'algorithm': 'activity_selector'}
I1007 06:45:25.005033 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.927, val scores are: activity_selector: 0.927
I1007 06:45:25.889627 127508787635712 run.py:734] Algo activity_selector step 2550 current loss 1.081530, current_train_items 70352.
I1007 06:45:25.919178 127508787635712 run.py:769] (val) algo activity_selector step 2550: {'selected': 0.8888888888888888, 'score': 0.8888888888888888, 'examples_seen': 70352, 'step': 2550, 'algorithm': 'activity_selector'}
I1007 06:45:25.919338 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.889, val scores are: activity_selector: 0.889
I1007 06:45:26.818824 127508787635712 run.py:734] Algo activity_selector step 2600 current loss 0.887790, current_train_items 71728.
I1007 06:45:26.847776 127508787635712 run.py:769] (val) algo activity_selector step 2600: {'selected': 0.9201520912547528, 'score': 0.9201520912547528, 'examples_seen': 71728, 'step': 2600, 'algorithm': 'activity_selector'}
I1007 06:45:26.847927 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.920, val scores are: activity_selector: 0.920
I1007 06:45:27.728422 127508787635712 run.py:734] Algo activity_selector step 2650 current loss 0.838625, current_train_items 73104.
I1007 06:45:27.758314 127508787635712 run.py:769] (val) algo activity_selector step 2650: {'selected': 0.9510763209393347, 'score': 0.9510763209393347, 'examples_seen': 73104, 'step': 2650, 'algorithm': 'activity_selector'}
I1007 06:45:27.758465 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.951, val scores are: activity_selector: 0.951
I1007 06:45:28.672918 127508787635712 run.py:734] Algo activity_selector step 2700 current loss 0.844756, current_train_items 74496.
I1007 06:45:28.702128 127508787635712 run.py:769] (val) algo activity_selector step 2700: {'selected': 0.9674952198852772, 'score': 0.9674952198852772, 'examples_seen': 74496, 'step': 2700, 'algorithm': 'activity_selector'}
I1007 06:45:28.702303 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.967, val scores are: activity_selector: 0.967
I1007 06:45:29.588020 127508787635712 run.py:734] Algo activity_selector step 2750 current loss 1.045174, current_train_items 75856.
I1007 06:45:29.619196 127508787635712 run.py:769] (val) algo activity_selector step 2750: {'selected': 0.9378757515030062, 'score': 0.9378757515030062, 'examples_seen': 75856, 'step': 2750, 'algorithm': 'activity_selector'}
I1007 06:45:29.619355 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.938, val scores are: activity_selector: 0.938
I1007 06:45:30.509980 127508787635712 run.py:734] Algo activity_selector step 2800 current loss 1.048339, current_train_items 77264.
I1007 06:45:30.539674 127508787635712 run.py:769] (val) algo activity_selector step 2800: {'selected': 0.9165120593692022, 'score': 0.9165120593692022, 'examples_seen': 77264, 'step': 2800, 'algorithm': 'activity_selector'}
I1007 06:45:30.539826 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.917, val scores are: activity_selector: 0.917
I1007 06:45:31.435284 127508787635712 run.py:734] Algo activity_selector step 2850 current loss 1.174339, current_train_items 78624.
I1007 06:45:31.464977 127508787635712 run.py:769] (val) algo activity_selector step 2850: {'selected': 0.9606299212598425, 'score': 0.9606299212598425, 'examples_seen': 78624, 'step': 2850, 'algorithm': 'activity_selector'}
I1007 06:45:31.465126 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.961, val scores are: activity_selector: 0.961
I1007 06:45:32.344222 127508787635712 run.py:734] Algo activity_selector step 2900 current loss 1.236225, current_train_items 80000.
I1007 06:45:32.374387 127508787635712 run.py:769] (val) algo activity_selector step 2900: {'selected': 0.902970297029703, 'score': 0.902970297029703, 'examples_seen': 80000, 'step': 2900, 'algorithm': 'activity_selector'}
I1007 06:45:32.374539 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.903, val scores are: activity_selector: 0.903
I1007 06:45:33.278921 127508787635712 run.py:734] Algo activity_selector step 2950 current loss 1.078844, current_train_items 81392.
I1007 06:45:33.308316 127508787635712 run.py:769] (val) algo activity_selector step 2950: {'selected': 0.9436893203883495, 'score': 0.9436893203883495, 'examples_seen': 81392, 'step': 2950, 'algorithm': 'activity_selector'}
I1007 06:45:33.308478 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.944, val scores are: activity_selector: 0.944
I1007 06:45:34.203020 127508787635712 run.py:734] Algo activity_selector step 3000 current loss 1.235292, current_train_items 82752.
I1007 06:45:34.231941 127508787635712 run.py:769] (val) algo activity_selector step 3000: {'selected': 0.912280701754386, 'score': 0.912280701754386, 'examples_seen': 82752, 'step': 3000, 'algorithm': 'activity_selector'}
I1007 06:45:34.232096 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.912, val scores are: activity_selector: 0.912
I1007 06:45:35.126702 127508787635712 run.py:734] Algo activity_selector step 3050 current loss 0.932993, current_train_items 84144.
I1007 06:45:35.155914 127508787635712 run.py:769] (val) algo activity_selector step 3050: {'selected': 0.9582504970178927, 'score': 0.9582504970178927, 'examples_seen': 84144, 'step': 3050, 'algorithm': 'activity_selector'}
I1007 06:45:35.156061 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.958, val scores are: activity_selector: 0.958
I1007 06:45:36.050505 127508787635712 run.py:734] Algo activity_selector step 3100 current loss 0.962491, current_train_items 85520.
I1007 06:45:36.079909 127508787635712 run.py:769] (val) algo activity_selector step 3100: {'selected': 0.9402390438247012, 'score': 0.9402390438247012, 'examples_seen': 85520, 'step': 3100, 'algorithm': 'activity_selector'}
I1007 06:45:36.080061 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.940, val scores are: activity_selector: 0.940
I1007 06:45:36.980112 127508787635712 run.py:734] Algo activity_selector step 3150 current loss 0.869234, current_train_items 86896.
I1007 06:45:37.009715 127508787635712 run.py:769] (val) algo activity_selector step 3150: {'selected': 0.945179584120983, 'score': 0.945179584120983, 'examples_seen': 86896, 'step': 3150, 'algorithm': 'activity_selector'}
I1007 06:45:37.009915 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.945, val scores are: activity_selector: 0.945
I1007 06:45:37.905789 127508787635712 run.py:734] Algo activity_selector step 3200 current loss 1.022787, current_train_items 88272.
I1007 06:45:37.937806 127508787635712 run.py:769] (val) algo activity_selector step 3200: {'selected': 0.9444444444444444, 'score': 0.9444444444444444, 'examples_seen': 88272, 'step': 3200, 'algorithm': 'activity_selector'}
I1007 06:45:37.937954 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.944, val scores are: activity_selector: 0.944
I1007 06:45:38.821061 127508787635712 run.py:734] Algo activity_selector step 3250 current loss 1.077608, current_train_items 89664.
I1007 06:45:38.851678 127508787635712 run.py:769] (val) algo activity_selector step 3250: {'selected': 0.936, 'score': 0.936, 'examples_seen': 89664, 'step': 3250, 'algorithm': 'activity_selector'}
I1007 06:45:38.851825 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1007 06:45:39.779732 127508787635712 run.py:734] Algo activity_selector step 3300 current loss 1.035088, current_train_items 91040.
I1007 06:45:39.810082 127508787635712 run.py:769] (val) algo activity_selector step 3300: {'selected': 0.9455252918287939, 'score': 0.9455252918287939, 'examples_seen': 91040, 'step': 3300, 'algorithm': 'activity_selector'}
I1007 06:45:39.810255 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.946, val scores are: activity_selector: 0.946
I1007 06:45:40.705049 127508787635712 run.py:734] Algo activity_selector step 3350 current loss 0.995625, current_train_items 92400.
I1007 06:45:40.734512 127508787635712 run.py:769] (val) algo activity_selector step 3350: {'selected': 0.951830443159923, 'score': 0.951830443159923, 'examples_seen': 92400, 'step': 3350, 'algorithm': 'activity_selector'}
I1007 06:45:40.734664 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.952, val scores are: activity_selector: 0.952
I1007 06:45:41.624179 127508787635712 run.py:734] Algo activity_selector step 3400 current loss 1.189689, current_train_items 93792.
I1007 06:45:41.654100 127508787635712 run.py:769] (val) algo activity_selector step 3400: {'selected': 0.953125, 'score': 0.953125, 'examples_seen': 93792, 'step': 3400, 'algorithm': 'activity_selector'}
I1007 06:45:41.654259 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1007 06:45:42.553135 127508787635712 run.py:734] Algo activity_selector step 3450 current loss 1.174686, current_train_items 95168.
I1007 06:45:42.582383 127508787635712 run.py:769] (val) algo activity_selector step 3450: {'selected': 0.9280303030303031, 'score': 0.9280303030303031, 'examples_seen': 95168, 'step': 3450, 'algorithm': 'activity_selector'}
I1007 06:45:42.582529 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.928, val scores are: activity_selector: 0.928
I1007 06:45:43.467645 127508787635712 run.py:734] Algo activity_selector step 3500 current loss 0.987802, current_train_items 96544.
I1007 06:45:43.496963 127508787635712 run.py:769] (val) algo activity_selector step 3500: {'selected': 0.9239543726235743, 'score': 0.9239543726235743, 'examples_seen': 96544, 'step': 3500, 'algorithm': 'activity_selector'}
I1007 06:45:43.497111 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.924, val scores are: activity_selector: 0.924
I1007 06:45:44.388793 127508787635712 run.py:734] Algo activity_selector step 3550 current loss 0.895395, current_train_items 97936.
I1007 06:45:44.418563 127508787635712 run.py:769] (val) algo activity_selector step 3550: {'selected': 0.9206349206349206, 'score': 0.9206349206349206, 'examples_seen': 97936, 'step': 3550, 'algorithm': 'activity_selector'}
I1007 06:45:44.418713 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.921, val scores are: activity_selector: 0.921
I1007 06:45:45.307063 127508787635712 run.py:734] Algo activity_selector step 3600 current loss 1.319180, current_train_items 99312.
I1007 06:45:45.336231 127508787635712 run.py:769] (val) algo activity_selector step 3600: {'selected': 0.9477911646586344, 'score': 0.9477911646586344, 'examples_seen': 99312, 'step': 3600, 'algorithm': 'activity_selector'}
I1007 06:45:45.336394 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1007 06:45:46.222439 127508787635712 run.py:734] Algo activity_selector step 3650 current loss 1.071644, current_train_items 100688.
I1007 06:45:46.251628 127508787635712 run.py:769] (val) algo activity_selector step 3650: {'selected': 0.9500000000000001, 'score': 0.9500000000000001, 'examples_seen': 100688, 'step': 3650, 'algorithm': 'activity_selector'}
I1007 06:45:46.251778 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1007 06:45:47.143543 127508787635712 run.py:734] Algo activity_selector step 3700 current loss 0.815496, current_train_items 102064.
I1007 06:45:47.173608 127508787635712 run.py:769] (val) algo activity_selector step 3700: {'selected': 0.9266409266409266, 'score': 0.9266409266409266, 'examples_seen': 102064, 'step': 3700, 'algorithm': 'activity_selector'}
I1007 06:45:47.173761 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.927, val scores are: activity_selector: 0.927
I1007 06:45:48.066073 127508787635712 run.py:734] Algo activity_selector step 3750 current loss 0.873896, current_train_items 103440.
I1007 06:45:48.094931 127508787635712 run.py:769] (val) algo activity_selector step 3750: {'selected': 0.9411764705882352, 'score': 0.9411764705882352, 'examples_seen': 103440, 'step': 3750, 'algorithm': 'activity_selector'}
I1007 06:45:48.095079 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.941, val scores are: activity_selector: 0.941
I1007 06:45:48.990373 127508787635712 run.py:734] Algo activity_selector step 3800 current loss 1.418818, current_train_items 104816.
I1007 06:45:49.019912 127508787635712 run.py:769] (val) algo activity_selector step 3800: {'selected': 0.9651162790697674, 'score': 0.9651162790697674, 'examples_seen': 104816, 'step': 3800, 'algorithm': 'activity_selector'}
I1007 06:45:49.020068 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.965, val scores are: activity_selector: 0.965
I1007 06:45:49.909603 127508787635712 run.py:734] Algo activity_selector step 3850 current loss 1.043609, current_train_items 106208.
I1007 06:45:49.938653 127508787635712 run.py:769] (val) algo activity_selector step 3850: {'selected': 0.9275929549902154, 'score': 0.9275929549902154, 'examples_seen': 106208, 'step': 3850, 'algorithm': 'activity_selector'}
I1007 06:45:49.938799 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.928, val scores are: activity_selector: 0.928
I1007 06:45:50.836595 127508787635712 run.py:734] Algo activity_selector step 3900 current loss 0.905836, current_train_items 107584.
I1007 06:45:50.866270 127508787635712 run.py:769] (val) algo activity_selector step 3900: {'selected': 0.9693486590038315, 'score': 0.9693486590038315, 'examples_seen': 107584, 'step': 3900, 'algorithm': 'activity_selector'}
I1007 06:45:50.866421 127508787635712 run.py:790] Checkpointing best model, best avg val score was 0.969, current avg val score is 0.969, val scores are: activity_selector: 0.969
I1007 06:45:51.766482 127508787635712 run.py:734] Algo activity_selector step 3950 current loss 0.855798, current_train_items 108960.
I1007 06:45:51.796037 127508787635712 run.py:769] (val) algo activity_selector step 3950: {'selected': 0.9314079422382672, 'score': 0.9314079422382672, 'examples_seen': 108960, 'step': 3950, 'algorithm': 'activity_selector'}
I1007 06:45:51.796187 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1007 06:45:52.679986 127508787635712 run.py:734] Algo activity_selector step 4000 current loss 0.880779, current_train_items 110336.
I1007 06:45:52.709466 127508787635712 run.py:769] (val) algo activity_selector step 4000: {'selected': 0.8952380952380953, 'score': 0.8952380952380953, 'examples_seen': 110336, 'step': 4000, 'algorithm': 'activity_selector'}
I1007 06:45:52.709617 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.895, val scores are: activity_selector: 0.895
I1007 06:45:53.604592 127508787635712 run.py:734] Algo activity_selector step 4050 current loss 0.822618, current_train_items 111712.
I1007 06:45:53.634053 127508787635712 run.py:769] (val) algo activity_selector step 4050: {'selected': 0.946360153256705, 'score': 0.946360153256705, 'examples_seen': 111712, 'step': 4050, 'algorithm': 'activity_selector'}
I1007 06:45:53.634204 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.946, val scores are: activity_selector: 0.946
I1007 06:45:54.520383 127508787635712 run.py:734] Algo activity_selector step 4100 current loss 0.893827, current_train_items 113088.
I1007 06:45:54.549120 127508787635712 run.py:769] (val) algo activity_selector step 4100: {'selected': 0.9081455805892548, 'score': 0.9081455805892548, 'examples_seen': 113088, 'step': 4100, 'algorithm': 'activity_selector'}
I1007 06:45:54.549291 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.908, val scores are: activity_selector: 0.908
I1007 06:45:55.437776 127508787635712 run.py:734] Algo activity_selector step 4150 current loss 0.808317, current_train_items 114480.
I1007 06:45:55.467917 127508787635712 run.py:769] (val) algo activity_selector step 4150: {'selected': 0.9360146252285192, 'score': 0.9360146252285192, 'examples_seen': 114480, 'step': 4150, 'algorithm': 'activity_selector'}
I1007 06:45:55.468067 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1007 06:45:56.356071 127508787635712 run.py:734] Algo activity_selector step 4200 current loss 1.347233, current_train_items 115856.
I1007 06:45:56.384941 127508787635712 run.py:769] (val) algo activity_selector step 4200: {'selected': 0.9243353783231084, 'score': 0.9243353783231084, 'examples_seen': 115856, 'step': 4200, 'algorithm': 'activity_selector'}
I1007 06:45:56.385091 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.924, val scores are: activity_selector: 0.924
I1007 06:45:57.263000 127508787635712 run.py:734] Algo activity_selector step 4250 current loss 1.469709, current_train_items 117216.
I1007 06:45:57.292134 127508787635712 run.py:769] (val) algo activity_selector step 4250: {'selected': 0.9211009174311926, 'score': 0.9211009174311926, 'examples_seen': 117216, 'step': 4250, 'algorithm': 'activity_selector'}
I1007 06:45:57.292291 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.921, val scores are: activity_selector: 0.921
I1007 06:45:58.178938 127508787635712 run.py:734] Algo activity_selector step 4300 current loss 1.444075, current_train_items 118624.
I1007 06:45:58.208642 127508787635712 run.py:769] (val) algo activity_selector step 4300: {'selected': 0.9046728971962618, 'score': 0.9046728971962618, 'examples_seen': 118624, 'step': 4300, 'algorithm': 'activity_selector'}
I1007 06:45:58.208802 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.905, val scores are: activity_selector: 0.905
I1007 06:45:59.090358 127508787635712 run.py:734] Algo activity_selector step 4350 current loss 0.822422, current_train_items 119984.
I1007 06:45:59.120128 127508787635712 run.py:769] (val) algo activity_selector step 4350: {'selected': 0.9563567362428843, 'score': 0.9563567362428843, 'examples_seen': 119984, 'step': 4350, 'algorithm': 'activity_selector'}
I1007 06:45:59.120288 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1007 06:46:00.004041 127508787635712 run.py:734] Algo activity_selector step 4400 current loss 0.685251, current_train_items 121360.
I1007 06:46:00.033516 127508787635712 run.py:769] (val) algo activity_selector step 4400: {'selected': 0.9534450651769087, 'score': 0.9534450651769087, 'examples_seen': 121360, 'step': 4400, 'algorithm': 'activity_selector'}
I1007 06:46:00.033665 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1007 06:46:00.913074 127508787635712 run.py:734] Algo activity_selector step 4450 current loss 0.971988, current_train_items 122752.
I1007 06:46:00.942599 127508787635712 run.py:769] (val) algo activity_selector step 4450: {'selected': 0.9418604651162791, 'score': 0.9418604651162791, 'examples_seen': 122752, 'step': 4450, 'algorithm': 'activity_selector'}
I1007 06:46:00.942749 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1007 06:46:01.838130 127508787635712 run.py:734] Algo activity_selector step 4500 current loss 0.751066, current_train_items 124128.
I1007 06:46:01.867974 127508787635712 run.py:769] (val) algo activity_selector step 4500: {'selected': 0.9660678642714571, 'score': 0.9660678642714571, 'examples_seen': 124128, 'step': 4500, 'algorithm': 'activity_selector'}
I1007 06:46:01.868134 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.966, val scores are: activity_selector: 0.966
I1007 06:46:02.773867 127508787635712 run.py:734] Algo activity_selector step 4550 current loss 0.767738, current_train_items 125504.
I1007 06:46:02.803352 127508787635712 run.py:769] (val) algo activity_selector step 4550: {'selected': 0.9397590361445783, 'score': 0.9397590361445783, 'examples_seen': 125504, 'step': 4550, 'algorithm': 'activity_selector'}
I1007 06:46:02.803503 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.940, val scores are: activity_selector: 0.940
I1007 06:46:03.685370 127508787635712 run.py:734] Algo activity_selector step 4600 current loss 1.051330, current_train_items 126880.
I1007 06:46:03.714982 127508787635712 run.py:769] (val) algo activity_selector step 4600: {'selected': 0.9295774647887325, 'score': 0.9295774647887325, 'examples_seen': 126880, 'step': 4600, 'algorithm': 'activity_selector'}
I1007 06:46:03.715138 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.930, val scores are: activity_selector: 0.930
I1007 06:46:04.607544 127508787635712 run.py:734] Algo activity_selector step 4650 current loss 0.953887, current_train_items 128272.
I1007 06:46:04.637709 127508787635712 run.py:769] (val) algo activity_selector step 4650: {'selected': 0.9321100917431193, 'score': 0.9321100917431193, 'examples_seen': 128272, 'step': 4650, 'algorithm': 'activity_selector'}
I1007 06:46:04.637862 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.932, val scores are: activity_selector: 0.932
I1007 06:46:05.518292 127508787635712 run.py:734] Algo activity_selector step 4700 current loss 1.072076, current_train_items 129632.
I1007 06:46:05.549910 127508787635712 run.py:769] (val) algo activity_selector step 4700: {'selected': 0.9584905660377359, 'score': 0.9584905660377359, 'examples_seen': 129632, 'step': 4700, 'algorithm': 'activity_selector'}
I1007 06:46:05.550060 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.958, val scores are: activity_selector: 0.958
I1007 06:46:06.436821 127508787635712 run.py:734] Algo activity_selector step 4750 current loss 0.963118, current_train_items 131024.
I1007 06:46:06.466179 127508787635712 run.py:769] (val) algo activity_selector step 4750: {'selected': 0.9168207024029575, 'score': 0.9168207024029575, 'examples_seen': 131024, 'step': 4750, 'algorithm': 'activity_selector'}
I1007 06:46:06.466338 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.917, val scores are: activity_selector: 0.917
I1007 06:46:07.354374 127508787635712 run.py:734] Algo activity_selector step 4800 current loss 0.825121, current_train_items 132400.
I1007 06:46:07.383960 127508787635712 run.py:769] (val) algo activity_selector step 4800: {'selected': 0.9576923076923077, 'score': 0.9576923076923077, 'examples_seen': 132400, 'step': 4800, 'algorithm': 'activity_selector'}
I1007 06:46:07.384111 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.958, val scores are: activity_selector: 0.958
I1007 06:46:08.267819 127508787635712 run.py:734] Algo activity_selector step 4850 current loss 0.851890, current_train_items 133760.
I1007 06:46:08.297373 127508787635712 run.py:769] (val) algo activity_selector step 4850: {'selected': 0.9456521739130435, 'score': 0.9456521739130435, 'examples_seen': 133760, 'step': 4850, 'algorithm': 'activity_selector'}
I1007 06:46:08.297535 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.946, val scores are: activity_selector: 0.946
I1007 06:46:09.204358 127508787635712 run.py:734] Algo activity_selector step 4900 current loss 0.824329, current_train_items 135168.
I1007 06:46:09.233707 127508787635712 run.py:769] (val) algo activity_selector step 4900: {'selected': 0.953900709219858, 'score': 0.953900709219858, 'examples_seen': 135168, 'step': 4900, 'algorithm': 'activity_selector'}
I1007 06:46:09.233861 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.954, val scores are: activity_selector: 0.954
I1007 06:46:10.126903 127508787635712 run.py:734] Algo activity_selector step 4950 current loss 0.766558, current_train_items 136528.
I1007 06:46:10.156806 127508787635712 run.py:769] (val) algo activity_selector step 4950: {'selected': 0.9433962264150944, 'score': 0.9433962264150944, 'examples_seen': 136528, 'step': 4950, 'algorithm': 'activity_selector'}
I1007 06:46:10.156969 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1007 06:46:11.053222 127508787635712 run.py:734] Algo activity_selector step 5000 current loss 0.879648, current_train_items 137920.
I1007 06:46:11.083019 127508787635712 run.py:769] (val) algo activity_selector step 5000: {'selected': 0.9, 'score': 0.9, 'examples_seen': 137920, 'step': 5000, 'algorithm': 'activity_selector'}
I1007 06:46:11.083169 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.900, val scores are: activity_selector: 0.900
I1007 06:46:11.973609 127508787635712 run.py:734] Algo activity_selector step 5050 current loss 0.859261, current_train_items 139296.
I1007 06:46:12.006050 127508787635712 run.py:769] (val) algo activity_selector step 5050: {'selected': 0.9373737373737374, 'score': 0.9373737373737374, 'examples_seen': 139296, 'step': 5050, 'algorithm': 'activity_selector'}
I1007 06:46:12.006202 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.937, val scores are: activity_selector: 0.937
I1007 06:46:12.894214 127508787635712 run.py:734] Algo activity_selector step 5100 current loss 0.938412, current_train_items 140656.
I1007 06:46:12.923783 127508787635712 run.py:769] (val) algo activity_selector step 5100: {'selected': 0.9511278195488723, 'score': 0.9511278195488723, 'examples_seen': 140656, 'step': 5100, 'algorithm': 'activity_selector'}
I1007 06:46:12.923934 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.951, val scores are: activity_selector: 0.951
I1007 06:46:13.822454 127508787635712 run.py:734] Algo activity_selector step 5150 current loss 1.231252, current_train_items 142048.
I1007 06:46:13.852386 127508787635712 run.py:769] (val) algo activity_selector step 5150: {'selected': 0.8879668049792532, 'score': 0.8879668049792532, 'examples_seen': 142048, 'step': 5150, 'algorithm': 'activity_selector'}
I1007 06:46:13.852537 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.888, val scores are: activity_selector: 0.888
I1007 06:46:14.734889 127508787635712 run.py:734] Algo activity_selector step 5200 current loss 0.768118, current_train_items 143424.
I1007 06:46:14.765129 127508787635712 run.py:769] (val) algo activity_selector step 5200: {'selected': 0.9571984435797665, 'score': 0.9571984435797665, 'examples_seen': 143424, 'step': 5200, 'algorithm': 'activity_selector'}
I1007 06:46:14.765290 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.957, val scores are: activity_selector: 0.957
I1007 06:46:15.674385 127508787635712 run.py:734] Algo activity_selector step 5250 current loss 0.984115, current_train_items 144816.
I1007 06:46:15.704447 127508787635712 run.py:769] (val) algo activity_selector step 5250: {'selected': 0.8745387453874538, 'score': 0.8745387453874538, 'examples_seen': 144816, 'step': 5250, 'algorithm': 'activity_selector'}
I1007 06:46:15.704600 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.875, val scores are: activity_selector: 0.875
I1007 06:46:16.583212 127508787635712 run.py:734] Algo activity_selector step 5300 current loss 1.107354, current_train_items 146176.
I1007 06:46:16.612779 127508787635712 run.py:769] (val) algo activity_selector step 5300: {'selected': 0.9385474860335197, 'score': 0.9385474860335197, 'examples_seen': 146176, 'step': 5300, 'algorithm': 'activity_selector'}
I1007 06:46:16.612929 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.939, val scores are: activity_selector: 0.939
I1007 06:46:17.496342 127508787635712 run.py:734] Algo activity_selector step 5350 current loss 0.682882, current_train_items 147584.
I1007 06:46:17.525845 127508787635712 run.py:769] (val) algo activity_selector step 5350: {'selected': 0.9513513513513513, 'score': 0.9513513513513513, 'examples_seen': 147584, 'step': 5350, 'algorithm': 'activity_selector'}
I1007 06:46:17.525997 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.951, val scores are: activity_selector: 0.951
I1007 06:46:18.434012 127508787635712 run.py:734] Algo activity_selector step 5400 current loss 0.916025, current_train_items 148944.
I1007 06:46:18.463766 127508787635712 run.py:769] (val) algo activity_selector step 5400: {'selected': 0.9549902152641879, 'score': 0.9549902152641879, 'examples_seen': 148944, 'step': 5400, 'algorithm': 'activity_selector'}
I1007 06:46:18.463919 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.955, val scores are: activity_selector: 0.955
I1007 06:46:19.350514 127508787635712 run.py:734] Algo activity_selector step 5450 current loss 0.763585, current_train_items 150304.
I1007 06:46:19.380005 127508787635712 run.py:769] (val) algo activity_selector step 5450: {'selected': 0.9429097605893186, 'score': 0.9429097605893186, 'examples_seen': 150304, 'step': 5450, 'algorithm': 'activity_selector'}
I1007 06:46:19.380157 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1007 06:46:20.286152 127508787635712 run.py:734] Algo activity_selector step 5500 current loss 0.888144, current_train_items 151712.
I1007 06:46:20.315219 127508787635712 run.py:769] (val) algo activity_selector step 5500: {'selected': 0.9623762376237623, 'score': 0.9623762376237623, 'examples_seen': 151712, 'step': 5500, 'algorithm': 'activity_selector'}
I1007 06:46:20.315384 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.962, val scores are: activity_selector: 0.962
I1007 06:46:21.210118 127508787635712 run.py:734] Algo activity_selector step 5550 current loss 0.916890, current_train_items 153072.
I1007 06:46:21.240522 127508787635712 run.py:769] (val) algo activity_selector step 5550: {'selected': 0.9499072356215214, 'score': 0.9499072356215214, 'examples_seen': 153072, 'step': 5550, 'algorithm': 'activity_selector'}
I1007 06:46:21.240674 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1007 06:46:22.146153 127508787635712 run.py:734] Algo activity_selector step 5600 current loss 0.703625, current_train_items 154464.
I1007 06:46:22.176067 127508787635712 run.py:769] (val) algo activity_selector step 5600: {'selected': 0.9584158415841584, 'score': 0.9584158415841584, 'examples_seen': 154464, 'step': 5600, 'algorithm': 'activity_selector'}
I1007 06:46:22.176223 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.958, val scores are: activity_selector: 0.958
I1007 06:46:23.065681 127508787635712 run.py:734] Algo activity_selector step 5650 current loss 0.698645, current_train_items 155840.
I1007 06:46:23.095578 127508787635712 run.py:769] (val) algo activity_selector step 5650: {'selected': 0.9390962671905697, 'score': 0.9390962671905697, 'examples_seen': 155840, 'step': 5650, 'algorithm': 'activity_selector'}
I1007 06:46:23.095729 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.939, val scores are: activity_selector: 0.939
I1007 06:46:23.983908 127508787635712 run.py:734] Algo activity_selector step 5700 current loss 0.842781, current_train_items 157216.
I1007 06:46:24.014250 127508787635712 run.py:769] (val) algo activity_selector step 5700: {'selected': 0.9322033898305083, 'score': 0.9322033898305083, 'examples_seen': 157216, 'step': 5700, 'algorithm': 'activity_selector'}
I1007 06:46:24.014401 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.969, current avg val score is 0.932, val scores are: activity_selector: 0.932
I1007 06:46:24.914040 127508787635712 run.py:734] Algo activity_selector step 5750 current loss 0.969502, current_train_items 158592.
I1007 06:46:24.943889 127508787635712 run.py:769] (val) algo activity_selector step 5750: {'selected': 0.9714285714285714, 'score': 0.9714285714285714, 'examples_seen': 158592, 'step': 5750, 'algorithm': 'activity_selector'}
I1007 06:46:24.944049 127508787635712 run.py:790] Checkpointing best model, best avg val score was 0.969, current avg val score is 0.971, val scores are: activity_selector: 0.971
I1007 06:46:25.841063 127508787635712 run.py:734] Algo activity_selector step 5800 current loss 0.926921, current_train_items 159968.
I1007 06:46:25.870370 127508787635712 run.py:769] (val) algo activity_selector step 5800: {'selected': 0.9422718808193669, 'score': 0.9422718808193669, 'examples_seen': 159968, 'step': 5800, 'algorithm': 'activity_selector'}
I1007 06:46:25.870521 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.971, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1007 06:46:26.776988 127508787635712 run.py:734] Algo activity_selector step 5850 current loss 1.132448, current_train_items 161360.
I1007 06:46:26.806936 127508787635712 run.py:769] (val) algo activity_selector step 5850: {'selected': 0.9430255402750491, 'score': 0.9430255402750491, 'examples_seen': 161360, 'step': 5850, 'algorithm': 'activity_selector'}
I1007 06:46:26.807087 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.971, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1007 06:46:27.692301 127508787635712 run.py:734] Algo activity_selector step 5900 current loss 0.755630, current_train_items 162720.
I1007 06:46:27.721302 127508787635712 run.py:769] (val) algo activity_selector step 5900: {'selected': 0.9416342412451362, 'score': 0.9416342412451362, 'examples_seen': 162720, 'step': 5900, 'algorithm': 'activity_selector'}
I1007 06:46:27.721456 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.971, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1007 06:46:28.608219 127508787635712 run.py:734] Algo activity_selector step 5950 current loss 0.618705, current_train_items 164112.
I1007 06:46:28.640390 127508787635712 run.py:769] (val) algo activity_selector step 5950: {'selected': 0.9696969696969696, 'score': 0.9696969696969696, 'examples_seen': 164112, 'step': 5950, 'algorithm': 'activity_selector'}
I1007 06:46:28.640541 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.971, current avg val score is 0.970, val scores are: activity_selector: 0.970
I1007 06:46:29.540978 127508787635712 run.py:734] Algo activity_selector step 6000 current loss 0.855424, current_train_items 165488.
I1007 06:46:29.569758 127508787635712 run.py:769] (val) algo activity_selector step 6000: {'selected': 0.9760589318600369, 'score': 0.9760589318600369, 'examples_seen': 165488, 'step': 6000, 'algorithm': 'activity_selector'}
I1007 06:46:29.569922 127508787635712 run.py:790] Checkpointing best model, best avg val score was 0.971, current avg val score is 0.976, val scores are: activity_selector: 0.976
I1007 06:46:30.470903 127508787635712 run.py:734] Algo activity_selector step 6050 current loss 0.866003, current_train_items 166864.
I1007 06:46:30.500680 127508787635712 run.py:769] (val) algo activity_selector step 6050: {'selected': 0.9285714285714286, 'score': 0.9285714285714286, 'examples_seen': 166864, 'step': 6050, 'algorithm': 'activity_selector'}
I1007 06:46:30.500832 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.976, current avg val score is 0.929, val scores are: activity_selector: 0.929
I1007 06:46:31.400286 127508787635712 run.py:734] Algo activity_selector step 6100 current loss 1.035437, current_train_items 168256.
I1007 06:46:31.429619 127508787635712 run.py:769] (val) algo activity_selector step 6100: {'selected': 0.9552845528455284, 'score': 0.9552845528455284, 'examples_seen': 168256, 'step': 6100, 'algorithm': 'activity_selector'}
I1007 06:46:31.429772 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.976, current avg val score is 0.955, val scores are: activity_selector: 0.955
I1007 06:46:32.319535 127508787635712 run.py:734] Algo activity_selector step 6150 current loss 1.024370, current_train_items 169616.
I1007 06:46:32.351263 127508787635712 run.py:769] (val) algo activity_selector step 6150: {'selected': 0.946938775510204, 'score': 0.946938775510204, 'examples_seen': 169616, 'step': 6150, 'algorithm': 'activity_selector'}
I1007 06:46:32.351414 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.976, current avg val score is 0.947, val scores are: activity_selector: 0.947
I1007 06:46:33.243061 127508787635712 run.py:734] Algo activity_selector step 6200 current loss 0.777276, current_train_items 171008.
I1007 06:46:33.272022 127508787635712 run.py:769] (val) algo activity_selector step 6200: {'selected': 0.9561586638830898, 'score': 0.9561586638830898, 'examples_seen': 171008, 'step': 6200, 'algorithm': 'activity_selector'}
I1007 06:46:33.272172 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.976, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1007 06:46:34.167738 127508787635712 run.py:734] Algo activity_selector step 6250 current loss 0.936147, current_train_items 172384.
I1007 06:46:34.197471 127508787635712 run.py:769] (val) algo activity_selector step 6250: {'selected': 0.9632653061224489, 'score': 0.9632653061224489, 'examples_seen': 172384, 'step': 6250, 'algorithm': 'activity_selector'}
I1007 06:46:34.197622 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.976, current avg val score is 0.963, val scores are: activity_selector: 0.963
I1007 06:46:35.089431 127508787635712 run.py:734] Algo activity_selector step 6300 current loss 0.702971, current_train_items 173760.
I1007 06:46:35.119592 127508787635712 run.py:769] (val) algo activity_selector step 6300: {'selected': 0.9137614678899082, 'score': 0.9137614678899082, 'examples_seen': 173760, 'step': 6300, 'algorithm': 'activity_selector'}
I1007 06:46:35.119755 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.976, current avg val score is 0.914, val scores are: activity_selector: 0.914
I1007 06:46:36.019671 127508787635712 run.py:734] Algo activity_selector step 6350 current loss 0.746360, current_train_items 175136.
I1007 06:46:36.049252 127508787635712 run.py:769] (val) algo activity_selector step 6350: {'selected': 0.9094412331406552, 'score': 0.9094412331406552, 'examples_seen': 175136, 'step': 6350, 'algorithm': 'activity_selector'}
I1007 06:46:36.049422 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.976, current avg val score is 0.909, val scores are: activity_selector: 0.909
I1007 06:46:36.927241 127508787635712 run.py:734] Algo activity_selector step 6400 current loss 0.963817, current_train_items 176528.
I1007 06:46:36.956785 127508787635712 run.py:769] (val) algo activity_selector step 6400: {'selected': 0.9598393574297188, 'score': 0.9598393574297188, 'examples_seen': 176528, 'step': 6400, 'algorithm': 'activity_selector'}
I1007 06:46:36.956950 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.976, current avg val score is 0.960, val scores are: activity_selector: 0.960
I1007 06:46:37.867332 127508787635712 run.py:734] Algo activity_selector step 6450 current loss 0.672579, current_train_items 177904.
I1007 06:46:37.897303 127508787635712 run.py:769] (val) algo activity_selector step 6450: {'selected': 0.9615384615384615, 'score': 0.9615384615384615, 'examples_seen': 177904, 'step': 6450, 'algorithm': 'activity_selector'}
I1007 06:46:37.897466 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.976, current avg val score is 0.962, val scores are: activity_selector: 0.962
I1007 06:46:38.782719 127508787635712 run.py:734] Algo activity_selector step 6500 current loss 0.652702, current_train_items 179264.
I1007 06:46:38.812034 127508787635712 run.py:769] (val) algo activity_selector step 6500: {'selected': 0.9539007092198581, 'score': 0.9539007092198581, 'examples_seen': 179264, 'step': 6500, 'algorithm': 'activity_selector'}
I1007 06:46:38.812200 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.976, current avg val score is 0.954, val scores are: activity_selector: 0.954
I1007 06:46:39.694242 127508787635712 run.py:734] Algo activity_selector step 6550 current loss 0.722179, current_train_items 180656.
I1007 06:46:39.723704 127508787635712 run.py:769] (val) algo activity_selector step 6550: {'selected': 0.9574861367837337, 'score': 0.9574861367837337, 'examples_seen': 180656, 'step': 6550, 'algorithm': 'activity_selector'}
I1007 06:46:39.723868 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.976, current avg val score is 0.957, val scores are: activity_selector: 0.957
I1007 06:46:40.623856 127508787635712 run.py:734] Algo activity_selector step 6600 current loss 0.947693, current_train_items 182032.
I1007 06:46:40.653720 127508787635712 run.py:769] (val) algo activity_selector step 6600: {'selected': 0.9368029739776952, 'score': 0.9368029739776952, 'examples_seen': 182032, 'step': 6600, 'algorithm': 'activity_selector'}
I1007 06:46:40.653884 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.976, current avg val score is 0.937, val scores are: activity_selector: 0.937
I1007 06:46:41.541281 127508787635712 run.py:734] Algo activity_selector step 6650 current loss 1.320731, current_train_items 183408.
I1007 06:46:41.571315 127508787635712 run.py:769] (val) algo activity_selector step 6650: {'selected': 0.8491620111731844, 'score': 0.8491620111731844, 'examples_seen': 183408, 'step': 6650, 'algorithm': 'activity_selector'}
I1007 06:46:41.571482 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.976, current avg val score is 0.849, val scores are: activity_selector: 0.849
I1007 06:46:42.464061 127508787635712 run.py:734] Algo activity_selector step 6700 current loss 0.717953, current_train_items 184800.
I1007 06:46:42.497516 127508787635712 run.py:769] (val) algo activity_selector step 6700: {'selected': 0.9429657794676807, 'score': 0.9429657794676807, 'examples_seen': 184800, 'step': 6700, 'algorithm': 'activity_selector'}
I1007 06:46:42.497672 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.976, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1007 06:46:43.388570 127508787635712 run.py:734] Algo activity_selector step 6750 current loss 0.781781, current_train_items 186176.
I1007 06:46:43.418178 127508787635712 run.py:769] (val) algo activity_selector step 6750: {'selected': 0.861995753715499, 'score': 0.861995753715499, 'examples_seen': 186176, 'step': 6750, 'algorithm': 'activity_selector'}
I1007 06:46:43.418350 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.976, current avg val score is 0.862, val scores are: activity_selector: 0.862
I1007 06:46:44.307525 127508787635712 run.py:734] Algo activity_selector step 6800 current loss 0.854330, current_train_items 187536.
I1007 06:46:44.337919 127508787635712 run.py:769] (val) algo activity_selector step 6800: {'selected': 0.9245283018867925, 'score': 0.9245283018867925, 'examples_seen': 187536, 'step': 6800, 'algorithm': 'activity_selector'}
I1007 06:46:44.338073 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.976, current avg val score is 0.925, val scores are: activity_selector: 0.925
I1007 06:46:45.235758 127508787635712 run.py:734] Algo activity_selector step 6850 current loss 0.957562, current_train_items 188928.
I1007 06:46:45.265209 127508787635712 run.py:769] (val) algo activity_selector step 6850: {'selected': 0.9367088607594937, 'score': 0.9367088607594937, 'examples_seen': 188928, 'step': 6850, 'algorithm': 'activity_selector'}
I1007 06:46:45.265373 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.976, current avg val score is 0.937, val scores are: activity_selector: 0.937
I1007 06:46:46.158969 127508787635712 run.py:734] Algo activity_selector step 6900 current loss 0.822733, current_train_items 190304.
I1007 06:46:46.189165 127508787635712 run.py:769] (val) algo activity_selector step 6900: {'selected': 0.9843137254901961, 'score': 0.9843137254901961, 'examples_seen': 190304, 'step': 6900, 'algorithm': 'activity_selector'}
I1007 06:46:46.189338 127508787635712 run.py:790] Checkpointing best model, best avg val score was 0.976, current avg val score is 0.984, val scores are: activity_selector: 0.984
I1007 06:46:47.101001 127508787635712 run.py:734] Algo activity_selector step 6950 current loss 0.721118, current_train_items 191680.
I1007 06:46:47.131107 127508787635712 run.py:769] (val) algo activity_selector step 6950: {'selected': 0.9579158316633266, 'score': 0.9579158316633266, 'examples_seen': 191680, 'step': 6950, 'algorithm': 'activity_selector'}
I1007 06:46:47.131280 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.958, val scores are: activity_selector: 0.958
I1007 06:46:48.018170 127508787635712 run.py:734] Algo activity_selector step 7000 current loss 1.382606, current_train_items 193072.
I1007 06:46:48.047327 127508787635712 run.py:769] (val) algo activity_selector step 7000: {'selected': 0.928709055876686, 'score': 0.928709055876686, 'examples_seen': 193072, 'step': 7000, 'algorithm': 'activity_selector'}
I1007 06:46:48.047479 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.929, val scores are: activity_selector: 0.929
I1007 06:46:48.951267 127508787635712 run.py:734] Algo activity_selector step 7050 current loss 0.724159, current_train_items 194448.
I1007 06:46:48.979995 127508787635712 run.py:769] (val) algo activity_selector step 7050: {'selected': 0.9208103130755065, 'score': 0.9208103130755065, 'examples_seen': 194448, 'step': 7050, 'algorithm': 'activity_selector'}
I1007 06:46:48.980146 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.921, val scores are: activity_selector: 0.921
I1007 06:46:49.867406 127508787635712 run.py:734] Algo activity_selector step 7100 current loss 0.830851, current_train_items 195824.
I1007 06:46:49.896845 127508787635712 run.py:769] (val) algo activity_selector step 7100: {'selected': 0.9503816793893131, 'score': 0.9503816793893131, 'examples_seen': 195824, 'step': 7100, 'algorithm': 'activity_selector'}
I1007 06:46:49.896997 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1007 06:46:50.781277 127508787635712 run.py:734] Algo activity_selector step 7150 current loss 0.704033, current_train_items 197200.
I1007 06:46:50.810153 127508787635712 run.py:769] (val) algo activity_selector step 7150: {'selected': 0.9053803339517625, 'score': 0.9053803339517625, 'examples_seen': 197200, 'step': 7150, 'algorithm': 'activity_selector'}
I1007 06:46:50.810316 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.905, val scores are: activity_selector: 0.905
I1007 06:46:51.707216 127508787635712 run.py:734] Algo activity_selector step 7200 current loss 0.667445, current_train_items 198576.
I1007 06:46:51.736335 127508787635712 run.py:769] (val) algo activity_selector step 7200: {'selected': 0.9566929133858267, 'score': 0.9566929133858267, 'examples_seen': 198576, 'step': 7200, 'algorithm': 'activity_selector'}
I1007 06:46:51.736486 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.957, val scores are: activity_selector: 0.957
I1007 06:46:52.624136 127508787635712 run.py:734] Algo activity_selector step 7250 current loss 0.696129, current_train_items 199952.
I1007 06:46:52.653940 127508787635712 run.py:769] (val) algo activity_selector step 7250: {'selected': 0.9737373737373738, 'score': 0.9737373737373738, 'examples_seen': 199952, 'step': 7250, 'algorithm': 'activity_selector'}
I1007 06:46:52.654101 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.974, val scores are: activity_selector: 0.974
I1007 06:46:53.548982 127508787635712 run.py:734] Algo activity_selector step 7300 current loss 0.667240, current_train_items 201344.
I1007 06:46:53.577922 127508787635712 run.py:769] (val) algo activity_selector step 7300: {'selected': 0.9638095238095239, 'score': 0.9638095238095239, 'examples_seen': 201344, 'step': 7300, 'algorithm': 'activity_selector'}
I1007 06:46:53.578074 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.964, val scores are: activity_selector: 0.964
I1007 06:46:54.468477 127508787635712 run.py:734] Algo activity_selector step 7350 current loss 0.901640, current_train_items 202720.
I1007 06:46:54.497736 127508787635712 run.py:769] (val) algo activity_selector step 7350: {'selected': 0.956, 'score': 0.956, 'examples_seen': 202720, 'step': 7350, 'algorithm': 'activity_selector'}
I1007 06:46:54.497885 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1007 06:46:55.376863 127508787635712 run.py:734] Algo activity_selector step 7400 current loss 0.746194, current_train_items 204080.
I1007 06:46:55.405671 127508787635712 run.py:769] (val) algo activity_selector step 7400: {'selected': 0.9613899613899614, 'score': 0.9613899613899614, 'examples_seen': 204080, 'step': 7400, 'algorithm': 'activity_selector'}
I1007 06:46:55.405820 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.961, val scores are: activity_selector: 0.961
I1007 06:46:56.296229 127508787635712 run.py:734] Algo activity_selector step 7450 current loss 0.833626, current_train_items 205488.
I1007 06:46:56.325919 127508787635712 run.py:769] (val) algo activity_selector step 7450: {'selected': 0.9562043795620438, 'score': 0.9562043795620438, 'examples_seen': 205488, 'step': 7450, 'algorithm': 'activity_selector'}
I1007 06:46:56.326069 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1007 06:46:57.211517 127508787635712 run.py:734] Algo activity_selector step 7500 current loss 0.643633, current_train_items 206848.
I1007 06:46:57.240897 127508787635712 run.py:769] (val) algo activity_selector step 7500: {'selected': 0.9746588693957116, 'score': 0.9746588693957116, 'examples_seen': 206848, 'step': 7500, 'algorithm': 'activity_selector'}
I1007 06:46:57.241049 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.975, val scores are: activity_selector: 0.975
I1007 06:46:58.131971 127508787635712 run.py:734] Algo activity_selector step 7550 current loss 0.849633, current_train_items 208224.
I1007 06:46:58.161370 127508787635712 run.py:769] (val) algo activity_selector step 7550: {'selected': 0.9218436873747495, 'score': 0.9218436873747495, 'examples_seen': 208224, 'step': 7550, 'algorithm': 'activity_selector'}
I1007 06:46:58.161521 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.922, val scores are: activity_selector: 0.922
I1007 06:46:59.059977 127508787635712 run.py:734] Algo activity_selector step 7600 current loss 0.882364, current_train_items 209616.
I1007 06:46:59.089299 127508787635712 run.py:769] (val) algo activity_selector step 7600: {'selected': 0.955223880597015, 'score': 0.955223880597015, 'examples_seen': 209616, 'step': 7600, 'algorithm': 'activity_selector'}
I1007 06:46:59.089454 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.955, val scores are: activity_selector: 0.955
I1007 06:46:59.974179 127508787635712 run.py:734] Algo activity_selector step 7650 current loss 0.829281, current_train_items 210976.
I1007 06:47:00.004002 127508787635712 run.py:769] (val) algo activity_selector step 7650: {'selected': 0.9425287356321839, 'score': 0.9425287356321839, 'examples_seen': 210976, 'step': 7650, 'algorithm': 'activity_selector'}
I1007 06:47:00.004162 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1007 06:47:00.900158 127508787635712 run.py:734] Algo activity_selector step 7700 current loss 0.760047, current_train_items 212368.
I1007 06:47:00.932727 127508787635712 run.py:769] (val) algo activity_selector step 7700: {'selected': 0.9650924024640658, 'score': 0.9650924024640658, 'examples_seen': 212368, 'step': 7700, 'algorithm': 'activity_selector'}
I1007 06:47:00.932886 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.965, val scores are: activity_selector: 0.965
I1007 06:47:01.831593 127508787635712 run.py:734] Algo activity_selector step 7750 current loss 0.638062, current_train_items 213744.
I1007 06:47:01.864769 127508787635712 run.py:769] (val) algo activity_selector step 7750: {'selected': 0.9194139194139195, 'score': 0.9194139194139195, 'examples_seen': 213744, 'step': 7750, 'algorithm': 'activity_selector'}
I1007 06:47:01.864933 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.919, val scores are: activity_selector: 0.919
I1007 06:47:02.766760 127508787635712 run.py:734] Algo activity_selector step 7800 current loss 0.819457, current_train_items 215136.
I1007 06:47:02.796302 127508787635712 run.py:769] (val) algo activity_selector step 7800: {'selected': 0.9546351084812622, 'score': 0.9546351084812622, 'examples_seen': 215136, 'step': 7800, 'algorithm': 'activity_selector'}
I1007 06:47:02.796473 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.955, val scores are: activity_selector: 0.955
I1007 06:47:03.681530 127508787635712 run.py:734] Algo activity_selector step 7850 current loss 0.655966, current_train_items 216496.
I1007 06:47:03.711355 127508787635712 run.py:769] (val) algo activity_selector step 7850: {'selected': 0.9623762376237623, 'score': 0.9623762376237623, 'examples_seen': 216496, 'step': 7850, 'algorithm': 'activity_selector'}
I1007 06:47:03.711524 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.962, val scores are: activity_selector: 0.962
I1007 06:47:04.597280 127508787635712 run.py:734] Algo activity_selector step 7900 current loss 0.572788, current_train_items 217888.
I1007 06:47:04.626652 127508787635712 run.py:769] (val) algo activity_selector step 7900: {'selected': 0.9686924493554329, 'score': 0.9686924493554329, 'examples_seen': 217888, 'step': 7900, 'algorithm': 'activity_selector'}
I1007 06:47:04.626830 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.969, val scores are: activity_selector: 0.969
I1007 06:47:05.531922 127508787635712 run.py:734] Algo activity_selector step 7950 current loss 0.650306, current_train_items 219264.
I1007 06:47:05.561646 127508787635712 run.py:769] (val) algo activity_selector step 7950: {'selected': 0.9643527204502814, 'score': 0.9643527204502814, 'examples_seen': 219264, 'step': 7950, 'algorithm': 'activity_selector'}
I1007 06:47:05.561802 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.964, val scores are: activity_selector: 0.964
I1007 06:47:06.447089 127508787635712 run.py:734] Algo activity_selector step 8000 current loss 0.664343, current_train_items 220624.
I1007 06:47:06.476875 127508787635712 run.py:769] (val) algo activity_selector step 8000: {'selected': 0.9534450651769086, 'score': 0.9534450651769086, 'examples_seen': 220624, 'step': 8000, 'algorithm': 'activity_selector'}
I1007 06:47:06.477024 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1007 06:47:07.383626 127508787635712 run.py:734] Algo activity_selector step 8050 current loss 0.626633, current_train_items 222032.
I1007 06:47:07.412918 127508787635712 run.py:769] (val) algo activity_selector step 8050: {'selected': 0.9732824427480916, 'score': 0.9732824427480916, 'examples_seen': 222032, 'step': 8050, 'algorithm': 'activity_selector'}
I1007 06:47:07.413070 127508787635712 run.py:790] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.973, val scores are: activity_selector: 0.973
I1007 06:47:08.323441 127508787635712 run.py:734] Algo activity_selector step 8100 current loss 0.626816, current_train_items 223392.
I1007 06:47:08.352801 127508787635712 run.py:769] (val) algo activity_selector step 8100: {'selected': 0.9775967413441955, 'score': 0.9775967413441955, 'examples_seen': 223392, 'step': 8100, 'algorithm': 'activity_selector'}
I1007 06:47:08.352954 127508787635712 run.py:790] Checkpointing best model, best avg val score was 0.973, current avg val score is 0.978, val scores are: activity_selector: 0.978
I1007 06:47:09.269847 127508787635712 run.py:734] Algo activity_selector step 8150 current loss 0.812726, current_train_items 224784.
I1007 06:47:09.299103 127508787635712 run.py:769] (val) algo activity_selector step 8150: {'selected': 0.9532710280373832, 'score': 0.9532710280373832, 'examples_seen': 224784, 'step': 8150, 'algorithm': 'activity_selector'}
I1007 06:47:09.299265 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1007 06:47:10.187211 127508787635712 run.py:734] Algo activity_selector step 8200 current loss 0.712270, current_train_items 226160.
I1007 06:47:10.216491 127508787635712 run.py:769] (val) algo activity_selector step 8200: {'selected': 0.9528985507246377, 'score': 0.9528985507246377, 'examples_seen': 226160, 'step': 8200, 'algorithm': 'activity_selector'}
I1007 06:47:10.216642 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1007 06:47:11.098240 127508787635712 run.py:734] Algo activity_selector step 8250 current loss 0.749926, current_train_items 227520.
I1007 06:47:11.127796 127508787635712 run.py:769] (val) algo activity_selector step 8250: {'selected': 0.9592233009708738, 'score': 0.9592233009708738, 'examples_seen': 227520, 'step': 8250, 'algorithm': 'activity_selector'}
I1007 06:47:11.127945 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.959, val scores are: activity_selector: 0.959
I1007 06:47:12.022173 127508787635712 run.py:734] Algo activity_selector step 8300 current loss 0.656699, current_train_items 228912.
I1007 06:47:12.050819 127508787635712 run.py:769] (val) algo activity_selector step 8300: {'selected': 0.9590643274853802, 'score': 0.9590643274853802, 'examples_seen': 228912, 'step': 8300, 'algorithm': 'activity_selector'}
I1007 06:47:12.050969 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.959, val scores are: activity_selector: 0.959
I1007 06:47:12.930130 127508787635712 run.py:734] Algo activity_selector step 8350 current loss 0.615505, current_train_items 230288.
I1007 06:47:12.958807 127508787635712 run.py:769] (val) algo activity_selector step 8350: {'selected': 0.9664179104477612, 'score': 0.9664179104477612, 'examples_seen': 230288, 'step': 8350, 'algorithm': 'activity_selector'}
I1007 06:47:12.958956 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.966, val scores are: activity_selector: 0.966
I1007 06:47:13.861673 127508787635712 run.py:734] Algo activity_selector step 8400 current loss 0.606806, current_train_items 231680.
I1007 06:47:13.892198 127508787635712 run.py:769] (val) algo activity_selector step 8400: {'selected': 0.9333333333333333, 'score': 0.9333333333333333, 'examples_seen': 231680, 'step': 8400, 'algorithm': 'activity_selector'}
I1007 06:47:13.892360 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.933, val scores are: activity_selector: 0.933
I1007 06:47:14.775834 127508787635712 run.py:734] Algo activity_selector step 8450 current loss 0.570043, current_train_items 233040.
I1007 06:47:14.805874 127508787635712 run.py:769] (val) algo activity_selector step 8450: {'selected': 0.947565543071161, 'score': 0.947565543071161, 'examples_seen': 233040, 'step': 8450, 'algorithm': 'activity_selector'}
I1007 06:47:14.806028 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1007 06:47:15.676915 127508787635712 run.py:734] Algo activity_selector step 8500 current loss 0.868664, current_train_items 234432.
I1007 06:47:15.706208 127508787635712 run.py:769] (val) algo activity_selector step 8500: {'selected': 0.9252525252525252, 'score': 0.9252525252525252, 'examples_seen': 234432, 'step': 8500, 'algorithm': 'activity_selector'}
I1007 06:47:15.706366 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.925, val scores are: activity_selector: 0.925
I1007 06:47:16.602717 127508787635712 run.py:734] Algo activity_selector step 8550 current loss 0.881460, current_train_items 235808.
I1007 06:47:16.632232 127508787635712 run.py:769] (val) algo activity_selector step 8550: {'selected': 0.9492187500000001, 'score': 0.9492187500000001, 'examples_seen': 235808, 'step': 8550, 'algorithm': 'activity_selector'}
I1007 06:47:16.632388 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.949, val scores are: activity_selector: 0.949
I1007 06:47:17.502163 127508787635712 run.py:734] Algo activity_selector step 8600 current loss 0.566215, current_train_items 237168.
I1007 06:47:17.532273 127508787635712 run.py:769] (val) algo activity_selector step 8600: {'selected': 0.9531249999999999, 'score': 0.9531249999999999, 'examples_seen': 237168, 'step': 8600, 'algorithm': 'activity_selector'}
I1007 06:47:17.532424 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1007 06:47:18.423077 127508787635712 run.py:734] Algo activity_selector step 8650 current loss 0.593281, current_train_items 238576.
I1007 06:47:18.452682 127508787635712 run.py:769] (val) algo activity_selector step 8650: {'selected': 0.9277108433734941, 'score': 0.9277108433734941, 'examples_seen': 238576, 'step': 8650, 'algorithm': 'activity_selector'}
I1007 06:47:18.452906 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.928, val scores are: activity_selector: 0.928
I1007 06:47:19.330108 127508787635712 run.py:734] Algo activity_selector step 8700 current loss 0.747837, current_train_items 239936.
I1007 06:47:19.359450 127508787635712 run.py:769] (val) algo activity_selector step 8700: {'selected': 0.9576427255985267, 'score': 0.9576427255985267, 'examples_seen': 239936, 'step': 8700, 'algorithm': 'activity_selector'}
I1007 06:47:19.359621 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.958, val scores are: activity_selector: 0.958
I1007 06:47:20.238465 127508787635712 run.py:734] Algo activity_selector step 8750 current loss 1.040339, current_train_items 241328.
I1007 06:47:20.268154 127508787635712 run.py:769] (val) algo activity_selector step 8750: {'selected': 0.9087301587301588, 'score': 0.9087301587301588, 'examples_seen': 241328, 'step': 8750, 'algorithm': 'activity_selector'}
I1007 06:47:20.268322 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.909, val scores are: activity_selector: 0.909
I1007 06:47:21.151311 127508787635712 run.py:734] Algo activity_selector step 8800 current loss 0.545637, current_train_items 242704.
I1007 06:47:21.179992 127508787635712 run.py:769] (val) algo activity_selector step 8800: {'selected': 0.9649805447470817, 'score': 0.9649805447470817, 'examples_seen': 242704, 'step': 8800, 'algorithm': 'activity_selector'}
I1007 06:47:21.180140 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.965, val scores are: activity_selector: 0.965
I1007 06:47:22.055905 127508787635712 run.py:734] Algo activity_selector step 8850 current loss 0.854975, current_train_items 244080.
I1007 06:47:22.084769 127508787635712 run.py:769] (val) algo activity_selector step 8850: {'selected': 0.9707602339181286, 'score': 0.9707602339181286, 'examples_seen': 244080, 'step': 8850, 'algorithm': 'activity_selector'}
I1007 06:47:22.084918 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.971, val scores are: activity_selector: 0.971
I1007 06:47:22.970780 127508787635712 run.py:734] Algo activity_selector step 8900 current loss 0.659675, current_train_items 245456.
I1007 06:47:23.000856 127508787635712 run.py:769] (val) algo activity_selector step 8900: {'selected': 0.9577464788732394, 'score': 0.9577464788732394, 'examples_seen': 245456, 'step': 8900, 'algorithm': 'activity_selector'}
I1007 06:47:23.001008 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.958, val scores are: activity_selector: 0.958
I1007 06:47:23.871105 127508787635712 run.py:734] Algo activity_selector step 8950 current loss 0.836234, current_train_items 246832.
I1007 06:47:23.899984 127508787635712 run.py:769] (val) algo activity_selector step 8950: {'selected': 0.9120879120879121, 'score': 0.9120879120879121, 'examples_seen': 246832, 'step': 8950, 'algorithm': 'activity_selector'}
I1007 06:47:23.900131 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.912, val scores are: activity_selector: 0.912
I1007 06:47:24.793270 127508787635712 run.py:734] Algo activity_selector step 9000 current loss 0.714593, current_train_items 248224.
I1007 06:47:24.822852 127508787635712 run.py:769] (val) algo activity_selector step 9000: {'selected': 0.9547169811320755, 'score': 0.9547169811320755, 'examples_seen': 248224, 'step': 9000, 'algorithm': 'activity_selector'}
I1007 06:47:24.823002 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.955, val scores are: activity_selector: 0.955
I1007 06:47:25.695822 127508787635712 run.py:734] Algo activity_selector step 9050 current loss 0.880360, current_train_items 249584.
I1007 06:47:25.724823 127508787635712 run.py:769] (val) algo activity_selector step 9050: {'selected': 0.9358490566037737, 'score': 0.9358490566037737, 'examples_seen': 249584, 'step': 9050, 'algorithm': 'activity_selector'}
I1007 06:47:25.724972 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1007 06:47:26.607344 127508787635712 run.py:734] Algo activity_selector step 9100 current loss 0.842628, current_train_items 250976.
I1007 06:47:26.636456 127508787635712 run.py:769] (val) algo activity_selector step 9100: {'selected': 0.9479768786127168, 'score': 0.9479768786127168, 'examples_seen': 250976, 'step': 9100, 'algorithm': 'activity_selector'}
I1007 06:47:26.636605 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1007 06:47:27.539441 127508787635712 run.py:734] Algo activity_selector step 9150 current loss 0.991299, current_train_items 252352.
I1007 06:47:27.569208 127508787635712 run.py:769] (val) algo activity_selector step 9150: {'selected': 0.9736842105263158, 'score': 0.9736842105263158, 'examples_seen': 252352, 'step': 9150, 'algorithm': 'activity_selector'}
I1007 06:47:27.569370 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.974, val scores are: activity_selector: 0.974
I1007 06:47:28.448246 127508787635712 run.py:734] Algo activity_selector step 9200 current loss 0.593738, current_train_items 253728.
I1007 06:47:28.477748 127508787635712 run.py:769] (val) algo activity_selector step 9200: {'selected': 0.9636711281070746, 'score': 0.9636711281070746, 'examples_seen': 253728, 'step': 9200, 'algorithm': 'activity_selector'}
I1007 06:47:28.477897 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.964, val scores are: activity_selector: 0.964
I1007 06:47:29.376240 127508787635712 run.py:734] Algo activity_selector step 9250 current loss 0.736825, current_train_items 255120.
I1007 06:47:29.405111 127508787635712 run.py:769] (val) algo activity_selector step 9250: {'selected': 0.9580152671755726, 'score': 0.9580152671755726, 'examples_seen': 255120, 'step': 9250, 'algorithm': 'activity_selector'}
I1007 06:47:29.405274 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.958, val scores are: activity_selector: 0.958
I1007 06:47:30.291035 127508787635712 run.py:734] Algo activity_selector step 9300 current loss 0.853542, current_train_items 256480.
I1007 06:47:30.320296 127508787635712 run.py:769] (val) algo activity_selector step 9300: {'selected': 0.9321100917431193, 'score': 0.9321100917431193, 'examples_seen': 256480, 'step': 9300, 'algorithm': 'activity_selector'}
I1007 06:47:30.320450 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.932, val scores are: activity_selector: 0.932
I1007 06:47:31.198497 127508787635712 run.py:734] Algo activity_selector step 9350 current loss 0.749362, current_train_items 257856.
I1007 06:47:31.228111 127508787635712 run.py:769] (val) algo activity_selector step 9350: {'selected': 0.9615384615384616, 'score': 0.9615384615384616, 'examples_seen': 257856, 'step': 9350, 'algorithm': 'activity_selector'}
I1007 06:47:31.228276 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.962, val scores are: activity_selector: 0.962
I1007 06:47:32.113314 127508787635712 run.py:734] Algo activity_selector step 9400 current loss 0.722678, current_train_items 259248.
I1007 06:47:32.142267 127508787635712 run.py:769] (val) algo activity_selector step 9400: {'selected': 0.9558823529411764, 'score': 0.9558823529411764, 'examples_seen': 259248, 'step': 9400, 'algorithm': 'activity_selector'}
I1007 06:47:32.142416 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1007 06:47:33.034459 127508787635712 run.py:734] Algo activity_selector step 9450 current loss 0.676781, current_train_items 260624.
I1007 06:47:33.065984 127508787635712 run.py:769] (val) algo activity_selector step 9450: {'selected': 0.9276595744680851, 'score': 0.9276595744680851, 'examples_seen': 260624, 'step': 9450, 'algorithm': 'activity_selector'}
I1007 06:47:33.066137 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.928, val scores are: activity_selector: 0.928
I1007 06:47:33.956746 127508787635712 run.py:734] Algo activity_selector step 9500 current loss 0.667025, current_train_items 262000.
I1007 06:47:33.986771 127508787635712 run.py:769] (val) algo activity_selector step 9500: {'selected': 0.9636711281070746, 'score': 0.9636711281070746, 'examples_seen': 262000, 'step': 9500, 'algorithm': 'activity_selector'}
I1007 06:47:33.986919 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.964, val scores are: activity_selector: 0.964
I1007 06:47:34.871255 127508787635712 run.py:734] Algo activity_selector step 9550 current loss 0.726714, current_train_items 263392.
I1007 06:47:34.900651 127508787635712 run.py:769] (val) algo activity_selector step 9550: {'selected': 0.9595141700404859, 'score': 0.9595141700404859, 'examples_seen': 263392, 'step': 9550, 'algorithm': 'activity_selector'}
I1007 06:47:34.900800 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.960, val scores are: activity_selector: 0.960
I1007 06:47:35.790538 127508787635712 run.py:734] Algo activity_selector step 9600 current loss 0.937467, current_train_items 264768.
I1007 06:47:35.820257 127508787635712 run.py:769] (val) algo activity_selector step 9600: {'selected': 0.937875751503006, 'score': 0.937875751503006, 'examples_seen': 264768, 'step': 9600, 'algorithm': 'activity_selector'}
I1007 06:47:35.820411 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.938, val scores are: activity_selector: 0.938
I1007 06:47:36.709508 127508787635712 run.py:734] Algo activity_selector step 9650 current loss 0.781195, current_train_items 266128.
I1007 06:47:36.742313 127508787635712 run.py:769] (val) algo activity_selector step 9650: {'selected': 0.9338374291115311, 'score': 0.9338374291115311, 'examples_seen': 266128, 'step': 9650, 'algorithm': 'activity_selector'}
I1007 06:47:36.742462 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.934, val scores are: activity_selector: 0.934
I1007 06:47:37.628798 127508787635712 run.py:734] Algo activity_selector step 9700 current loss 0.801104, current_train_items 267520.
I1007 06:47:37.658085 127508787635712 run.py:769] (val) algo activity_selector step 9700: {'selected': 0.9750479846449136, 'score': 0.9750479846449136, 'examples_seen': 267520, 'step': 9700, 'algorithm': 'activity_selector'}
I1007 06:47:37.658244 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.975, val scores are: activity_selector: 0.975
I1007 06:47:38.556641 127508787635712 run.py:734] Algo activity_selector step 9750 current loss 0.679483, current_train_items 268896.
I1007 06:47:38.586756 127508787635712 run.py:769] (val) algo activity_selector step 9750: {'selected': 0.9877049180327869, 'score': 0.9877049180327869, 'examples_seen': 268896, 'step': 9750, 'algorithm': 'activity_selector'}
I1007 06:47:38.586903 127508787635712 run.py:790] Checkpointing best model, best avg val score was 0.978, current avg val score is 0.988, val scores are: activity_selector: 0.988
I1007 06:47:39.496906 127508787635712 run.py:734] Algo activity_selector step 9800 current loss 0.681191, current_train_items 270272.
I1007 06:47:39.525711 127508787635712 run.py:769] (val) algo activity_selector step 9800: {'selected': 0.9161793372319689, 'score': 0.9161793372319689, 'examples_seen': 270272, 'step': 9800, 'algorithm': 'activity_selector'}
I1007 06:47:39.525872 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.988, current avg val score is 0.916, val scores are: activity_selector: 0.916
I1007 06:47:40.406503 127508787635712 run.py:734] Algo activity_selector step 9850 current loss 0.627079, current_train_items 271664.
I1007 06:47:40.435858 127508787635712 run.py:769] (val) algo activity_selector step 9850: {'selected': 0.9441233140655108, 'score': 0.9441233140655108, 'examples_seen': 271664, 'step': 9850, 'algorithm': 'activity_selector'}
I1007 06:47:40.436007 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.988, current avg val score is 0.944, val scores are: activity_selector: 0.944
I1007 06:47:41.312389 127508787635712 run.py:734] Algo activity_selector step 9900 current loss 0.729776, current_train_items 273040.
I1007 06:47:41.341895 127508787635712 run.py:769] (val) algo activity_selector step 9900: {'selected': 0.9315589353612167, 'score': 0.9315589353612167, 'examples_seen': 273040, 'step': 9900, 'algorithm': 'activity_selector'}
I1007 06:47:41.342057 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.988, current avg val score is 0.932, val scores are: activity_selector: 0.932
I1007 06:47:42.217913 127508787635712 run.py:734] Algo activity_selector step 9950 current loss 0.678473, current_train_items 274400.
I1007 06:47:42.246835 127508787635712 run.py:769] (val) algo activity_selector step 9950: {'selected': 0.9788867562380038, 'score': 0.9788867562380038, 'examples_seen': 274400, 'step': 9950, 'algorithm': 'activity_selector'}
I1007 06:47:42.246981 127508787635712 run.py:793] Not saving new best model, best avg val score was 0.988, current avg val score is 0.979, val scores are: activity_selector: 0.979
I1007 06:47:43.110051 127508787635712 run.py:799] Restoring best model from checkpoint...
I1007 06:47:51.281656 127508787635712 run.py:814] (test) algo activity_selector : {'selected': 0.8500948766603416, 'score': 0.8500948766603416, 'examples_seen': 275760, 'step': 10000, 'algorithm': 'activity_selector'}
I1007 06:47:51.281776 127508787635712 run.py:816] Done!
