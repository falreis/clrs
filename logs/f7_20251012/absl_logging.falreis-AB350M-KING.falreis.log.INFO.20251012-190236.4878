I1012 19:02:45.303987 124643143087616 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I1012 19:02:45.340945 124643143087616 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I1012 19:02:45.873080 124643143087616 run.py:453] Model: f7 ['activity_selector']
I1012 19:02:45.873182 124643143087616 run.py:455] algorithms ['activity_selector']
I1012 19:02:45.873358 124643143087616 run.py:456] train_lengths ['4', '7', '11', '13', '16']
I1012 19:02:45.873398 124643143087616 run.py:457] train_batch_size 16
I1012 19:02:45.873500 124643143087616 run.py:458] val_batch_size 16
I1012 19:02:45.873532 124643143087616 run.py:459] test_batch_size 16
I1012 19:02:45.873562 124643143087616 run.py:460] chunked_training True
I1012 19:02:45.873653 124643143087616 run.py:461] chunk_length 16
I1012 19:02:45.873683 124643143087616 run.py:462] train_steps 10000
I1012 19:02:45.873713 124643143087616 run.py:463] eval_every 50
I1012 19:02:45.873753 124643143087616 run.py:464] test_every 500
I1012 19:02:45.873786 124643143087616 run.py:465] hidden_size 256
I1012 19:02:45.873815 124643143087616 run.py:466] nb_msg_passing_steps 1
I1012 19:02:45.873843 124643143087616 run.py:467] learning_rate 0.001
I1012 19:02:45.873934 124643143087616 run.py:468] grad_clip_max_norm 1.0
I1012 19:02:45.873964 124643143087616 run.py:469] dropout_prob 0.1
I1012 19:02:45.873993 124643143087616 run.py:470] hint_teacher_forcing 0.0
I1012 19:02:45.874022 124643143087616 run.py:471] hint_mode encoded_decoded
I1012 19:02:45.874128 124643143087616 run.py:472] hint_repred_mode soft
I1012 19:02:45.874160 124643143087616 run.py:473] use_ln True
I1012 19:02:45.874189 124643143087616 run.py:474] use_lstm True
I1012 19:02:45.874217 124643143087616 run.py:475] nb_triplet_fts 8
I1012 19:02:45.874245 124643143087616 run.py:476] encoder_init xavier_on_scalars
I1012 19:02:45.874273 124643143087616 run.py:477] processor_type f7
I1012 19:02:45.874304 124643143087616 run.py:478] checkpoint_path CLRS30
I1012 19:02:45.874333 124643143087616 run.py:479] dataset_path CLRS30
I1012 19:02:45.874361 124643143087616 run.py:480] freeze_processor False
I1012 19:02:45.874390 124643143087616 run.py:481] reduction min
I1012 19:02:45.874420 124643143087616 run.py:482] activation elu
I1012 19:02:45.874448 124643143087616 run.py:483] restore_model 
I1012 19:02:45.874475 124643143087616 run.py:484] gated True
I1012 19:02:45.874503 124643143087616 run.py:485] gated_activation tanh
I1012 19:02:45.877503 124643143087616 run.py:511] Creating samplers for algo activity_selector
W1012 19:02:45.877717 124643143087616 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1012 19:02:45.877983 124643143087616 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W1012 19:02:46.095227 124643143087616 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1012 19:02:46.344911 124643143087616 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1012 19:02:46.662458 124643143087616 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1012 19:02:47.002621 124643143087616 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1012 19:02:47.397843 124643143087616 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I1012 19:02:47.398151 124643143087616 samplers.py:124] Creating a dataset with 64 samples.
I1012 19:02:47.425043 124643143087616 run.py:297] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I1012 19:02:47.425897 124643143087616 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I1012 19:02:47.432326 124643143087616 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I1012 19:02:47.436790 124643143087616 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I1012 19:02:47.535100 124643143087616 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W1012 19:02:47.556954 124643143087616 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x715c39bc0a40> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I1012 19:03:24.265881 124643143087616 run.py:734] Algo activity_selector step 0 current loss 5.712032, current_train_items 32.
I1012 19:03:34.951918 124643143087616 run.py:769] (val) algo activity_selector step 0: {'selected': 0.05594405594405595, 'score': 0.05594405594405595, 'examples_seen': 32, 'step': 0, 'algorithm': 'activity_selector'}
I1012 19:03:34.952080 124643143087616 run.py:790] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.056, val scores are: activity_selector: 0.056
I1012 19:04:32.824742 124643143087616 run.py:734] Algo activity_selector step 50 current loss 3.676414, current_train_items 1408.
I1012 19:04:32.966430 124643143087616 run.py:769] (val) algo activity_selector step 50: {'selected': 0.6743119266055045, 'score': 0.6743119266055045, 'examples_seen': 1408, 'step': 50, 'algorithm': 'activity_selector'}
I1012 19:04:32.966676 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.056, current avg val score is 0.674, val scores are: activity_selector: 0.674
I1012 19:04:34.173494 124643143087616 run.py:734] Algo activity_selector step 100 current loss 3.659835, current_train_items 2800.
I1012 19:04:34.316658 124643143087616 run.py:769] (val) algo activity_selector step 100: {'selected': 0.7542213883677299, 'score': 0.7542213883677299, 'examples_seen': 2800, 'step': 100, 'algorithm': 'activity_selector'}
I1012 19:04:34.316918 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.674, current avg val score is 0.754, val scores are: activity_selector: 0.754
I1012 19:04:35.508795 124643143087616 run.py:734] Algo activity_selector step 150 current loss 2.665919, current_train_items 4176.
I1012 19:04:35.662692 124643143087616 run.py:769] (val) algo activity_selector step 150: {'selected': 0.766839378238342, 'score': 0.766839378238342, 'examples_seen': 4176, 'step': 150, 'algorithm': 'activity_selector'}
I1012 19:04:35.662865 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.754, current avg val score is 0.767, val scores are: activity_selector: 0.767
I1012 19:04:36.848028 124643143087616 run.py:734] Algo activity_selector step 200 current loss 2.841169, current_train_items 5536.
I1012 19:04:37.008525 124643143087616 run.py:769] (val) algo activity_selector step 200: {'selected': 0.7814814814814814, 'score': 0.7814814814814814, 'examples_seen': 5536, 'step': 200, 'algorithm': 'activity_selector'}
I1012 19:04:37.008803 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.767, current avg val score is 0.781, val scores are: activity_selector: 0.781
I1012 19:04:38.216638 124643143087616 run.py:734] Algo activity_selector step 250 current loss 2.320612, current_train_items 6944.
I1012 19:04:38.354335 124643143087616 run.py:769] (val) algo activity_selector step 250: {'selected': 0.6741071428571428, 'score': 0.6741071428571428, 'examples_seen': 6944, 'step': 250, 'algorithm': 'activity_selector'}
I1012 19:04:38.354502 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.781, current avg val score is 0.674, val scores are: activity_selector: 0.674
I1012 19:04:39.482015 124643143087616 run.py:734] Algo activity_selector step 300 current loss 2.468342, current_train_items 8304.
I1012 19:04:39.628877 124643143087616 run.py:769] (val) algo activity_selector step 300: {'selected': 0.8345070422535211, 'score': 0.8345070422535211, 'examples_seen': 8304, 'step': 300, 'algorithm': 'activity_selector'}
I1012 19:04:39.629132 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.781, current avg val score is 0.835, val scores are: activity_selector: 0.835
I1012 19:04:40.818218 124643143087616 run.py:734] Algo activity_selector step 350 current loss 2.169863, current_train_items 9680.
I1012 19:04:40.979644 124643143087616 run.py:769] (val) algo activity_selector step 350: {'selected': 0.7689393939393939, 'score': 0.7689393939393939, 'examples_seen': 9680, 'step': 350, 'algorithm': 'activity_selector'}
I1012 19:04:40.979845 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.835, current avg val score is 0.769, val scores are: activity_selector: 0.769
I1012 19:04:42.117116 124643143087616 run.py:734] Algo activity_selector step 400 current loss 2.020249, current_train_items 11072.
I1012 19:04:42.279654 124643143087616 run.py:769] (val) algo activity_selector step 400: {'selected': 0.8098859315589354, 'score': 0.8098859315589354, 'examples_seen': 11072, 'step': 400, 'algorithm': 'activity_selector'}
I1012 19:04:42.279905 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.835, current avg val score is 0.810, val scores are: activity_selector: 0.810
I1012 19:04:43.430318 124643143087616 run.py:734] Algo activity_selector step 450 current loss 2.056602, current_train_items 12448.
I1012 19:04:43.585028 124643143087616 run.py:769] (val) algo activity_selector step 450: {'selected': 0.8984962406015037, 'score': 0.8984962406015037, 'examples_seen': 12448, 'step': 450, 'algorithm': 'activity_selector'}
I1012 19:04:43.585295 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.835, current avg val score is 0.898, val scores are: activity_selector: 0.898
I1012 19:04:44.732453 124643143087616 run.py:734] Algo activity_selector step 500 current loss 2.125616, current_train_items 13824.
I1012 19:04:44.881008 124643143087616 run.py:769] (val) algo activity_selector step 500: {'selected': 0.8549323017408125, 'score': 0.8549323017408125, 'examples_seen': 13824, 'step': 500, 'algorithm': 'activity_selector'}
I1012 19:04:44.881233 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.898, current avg val score is 0.855, val scores are: activity_selector: 0.855
I1012 19:04:45.963917 124643143087616 run.py:734] Algo activity_selector step 550 current loss 1.822565, current_train_items 15200.
I1012 19:04:46.098083 124643143087616 run.py:769] (val) algo activity_selector step 550: {'selected': 0.8884540117416829, 'score': 0.8884540117416829, 'examples_seen': 15200, 'step': 550, 'algorithm': 'activity_selector'}
I1012 19:04:46.098310 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.898, current avg val score is 0.888, val scores are: activity_selector: 0.888
I1012 19:04:47.216802 124643143087616 run.py:734] Algo activity_selector step 600 current loss 1.862348, current_train_items 16576.
I1012 19:04:47.354629 124643143087616 run.py:769] (val) algo activity_selector step 600: {'selected': 0.8324514991181658, 'score': 0.8324514991181658, 'examples_seen': 16576, 'step': 600, 'algorithm': 'activity_selector'}
I1012 19:04:47.354902 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.898, current avg val score is 0.832, val scores are: activity_selector: 0.832
I1012 19:04:48.466292 124643143087616 run.py:734] Algo activity_selector step 650 current loss 2.042159, current_train_items 17952.
I1012 19:04:48.626257 124643143087616 run.py:769] (val) algo activity_selector step 650: {'selected': 0.9054545454545454, 'score': 0.9054545454545454, 'examples_seen': 17952, 'step': 650, 'algorithm': 'activity_selector'}
I1012 19:04:48.626502 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.898, current avg val score is 0.905, val scores are: activity_selector: 0.905
I1012 19:04:49.810617 124643143087616 run.py:734] Algo activity_selector step 700 current loss 1.624273, current_train_items 19344.
I1012 19:04:49.955674 124643143087616 run.py:769] (val) algo activity_selector step 700: {'selected': 0.8352941176470589, 'score': 0.8352941176470589, 'examples_seen': 19344, 'step': 700, 'algorithm': 'activity_selector'}
I1012 19:04:49.955918 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.905, current avg val score is 0.835, val scores are: activity_selector: 0.835
I1012 19:04:51.046633 124643143087616 run.py:734] Algo activity_selector step 750 current loss 1.755840, current_train_items 20720.
I1012 19:04:51.187850 124643143087616 run.py:769] (val) algo activity_selector step 750: {'selected': 0.8779527559055118, 'score': 0.8779527559055118, 'examples_seen': 20720, 'step': 750, 'algorithm': 'activity_selector'}
I1012 19:04:51.188074 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.905, current avg val score is 0.878, val scores are: activity_selector: 0.878
I1012 19:04:52.293661 124643143087616 run.py:734] Algo activity_selector step 800 current loss 1.685626, current_train_items 22096.
I1012 19:04:52.432497 124643143087616 run.py:769] (val) algo activity_selector step 800: {'selected': 0.9498069498069499, 'score': 0.9498069498069499, 'examples_seen': 22096, 'step': 800, 'algorithm': 'activity_selector'}
I1012 19:04:52.432745 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.905, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1012 19:04:53.568549 124643143087616 run.py:734] Algo activity_selector step 850 current loss 1.880934, current_train_items 23472.
I1012 19:04:53.722142 124643143087616 run.py:769] (val) algo activity_selector step 850: {'selected': 0.8545454545454545, 'score': 0.8545454545454545, 'examples_seen': 23472, 'step': 850, 'algorithm': 'activity_selector'}
I1012 19:04:53.722440 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.855, val scores are: activity_selector: 0.855
I1012 19:04:54.825957 124643143087616 run.py:734] Algo activity_selector step 900 current loss 2.262548, current_train_items 24848.
I1012 19:04:54.963046 124643143087616 run.py:769] (val) algo activity_selector step 900: {'selected': 0.827977315689981, 'score': 0.827977315689981, 'examples_seen': 24848, 'step': 900, 'algorithm': 'activity_selector'}
I1012 19:04:54.963273 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.828, val scores are: activity_selector: 0.828
I1012 19:04:56.055250 124643143087616 run.py:734] Algo activity_selector step 950 current loss 1.690620, current_train_items 26224.
I1012 19:04:56.195009 124643143087616 run.py:769] (val) algo activity_selector step 950: {'selected': 0.8370221327967806, 'score': 0.8370221327967806, 'examples_seen': 26224, 'step': 950, 'algorithm': 'activity_selector'}
I1012 19:04:56.195231 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.837, val scores are: activity_selector: 0.837
I1012 19:04:57.287460 124643143087616 run.py:734] Algo activity_selector step 1000 current loss 1.917109, current_train_items 27616.
I1012 19:04:57.428252 124643143087616 run.py:769] (val) algo activity_selector step 1000: {'selected': 0.8273244781783682, 'score': 0.8273244781783682, 'examples_seen': 27616, 'step': 1000, 'algorithm': 'activity_selector'}
I1012 19:04:57.428478 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.827, val scores are: activity_selector: 0.827
I1012 19:04:58.518832 124643143087616 run.py:734] Algo activity_selector step 1050 current loss 1.747097, current_train_items 28992.
I1012 19:04:58.673459 124643143087616 run.py:769] (val) algo activity_selector step 1050: {'selected': 0.9296875, 'score': 0.9296875, 'examples_seen': 28992, 'step': 1050, 'algorithm': 'activity_selector'}
I1012 19:04:58.673686 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.930, val scores are: activity_selector: 0.930
I1012 19:04:59.752278 124643143087616 run.py:734] Algo activity_selector step 1100 current loss 1.433349, current_train_items 30368.
I1012 19:04:59.908548 124643143087616 run.py:769] (val) algo activity_selector step 1100: {'selected': 0.8737060041407868, 'score': 0.8737060041407868, 'examples_seen': 30368, 'step': 1100, 'algorithm': 'activity_selector'}
I1012 19:04:59.908793 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.874, val scores are: activity_selector: 0.874
I1012 19:05:01.002454 124643143087616 run.py:734] Algo activity_selector step 1150 current loss 1.412194, current_train_items 31760.
I1012 19:05:01.143719 124643143087616 run.py:769] (val) algo activity_selector step 1150: {'selected': 0.9242144177449169, 'score': 0.9242144177449169, 'examples_seen': 31760, 'step': 1150, 'algorithm': 'activity_selector'}
I1012 19:05:01.143957 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.924, val scores are: activity_selector: 0.924
I1012 19:05:02.268198 124643143087616 run.py:734] Algo activity_selector step 1200 current loss 1.184487, current_train_items 33120.
I1012 19:05:02.409507 124643143087616 run.py:769] (val) algo activity_selector step 1200: {'selected': 0.912878787878788, 'score': 0.912878787878788, 'examples_seen': 33120, 'step': 1200, 'algorithm': 'activity_selector'}
I1012 19:05:02.409747 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.913, val scores are: activity_selector: 0.913
I1012 19:05:03.496458 124643143087616 run.py:734] Algo activity_selector step 1250 current loss 1.543268, current_train_items 34496.
I1012 19:05:03.653713 124643143087616 run.py:769] (val) algo activity_selector step 1250: {'selected': 0.9244935543278084, 'score': 0.9244935543278084, 'examples_seen': 34496, 'step': 1250, 'algorithm': 'activity_selector'}
I1012 19:05:03.653959 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.924, val scores are: activity_selector: 0.924
I1012 19:05:04.746759 124643143087616 run.py:734] Algo activity_selector step 1300 current loss 1.418293, current_train_items 35888.
I1012 19:05:04.885492 124643143087616 run.py:769] (val) algo activity_selector step 1300: {'selected': 0.9132947976878611, 'score': 0.9132947976878611, 'examples_seen': 35888, 'step': 1300, 'algorithm': 'activity_selector'}
I1012 19:05:04.885725 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.913, val scores are: activity_selector: 0.913
I1012 19:05:06.027510 124643143087616 run.py:734] Algo activity_selector step 1350 current loss 1.186033, current_train_items 37264.
I1012 19:05:06.187048 124643143087616 run.py:769] (val) algo activity_selector step 1350: {'selected': 0.9073724007561437, 'score': 0.9073724007561437, 'examples_seen': 37264, 'step': 1350, 'algorithm': 'activity_selector'}
I1012 19:05:06.187301 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.907, val scores are: activity_selector: 0.907
I1012 19:05:07.292246 124643143087616 run.py:734] Algo activity_selector step 1400 current loss 1.246881, current_train_items 38640.
I1012 19:05:07.431558 124643143087616 run.py:769] (val) algo activity_selector step 1400: {'selected': 0.922201138519924, 'score': 0.922201138519924, 'examples_seen': 38640, 'step': 1400, 'algorithm': 'activity_selector'}
I1012 19:05:07.431820 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.922, val scores are: activity_selector: 0.922
I1012 19:05:08.534768 124643143087616 run.py:734] Algo activity_selector step 1450 current loss 0.929660, current_train_items 40016.
I1012 19:05:08.667333 124643143087616 run.py:769] (val) algo activity_selector step 1450: {'selected': 0.9046653144016227, 'score': 0.9046653144016227, 'examples_seen': 40016, 'step': 1450, 'algorithm': 'activity_selector'}
I1012 19:05:08.667564 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.905, val scores are: activity_selector: 0.905
I1012 19:05:09.768869 124643143087616 run.py:734] Algo activity_selector step 1500 current loss 1.194205, current_train_items 41408.
I1012 19:05:09.927227 124643143087616 run.py:769] (val) algo activity_selector step 1500: {'selected': 0.90625, 'score': 0.90625, 'examples_seen': 41408, 'step': 1500, 'algorithm': 'activity_selector'}
I1012 19:05:09.927453 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.906, val scores are: activity_selector: 0.906
I1012 19:05:11.023598 124643143087616 run.py:734] Algo activity_selector step 1550 current loss 1.306413, current_train_items 42768.
I1012 19:05:11.162185 124643143087616 run.py:769] (val) algo activity_selector step 1550: {'selected': 0.9416058394160584, 'score': 0.9416058394160584, 'examples_seen': 42768, 'step': 1550, 'algorithm': 'activity_selector'}
I1012 19:05:11.162423 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1012 19:05:12.291988 124643143087616 run.py:734] Algo activity_selector step 1600 current loss 1.478716, current_train_items 44160.
I1012 19:05:12.428704 124643143087616 run.py:769] (val) algo activity_selector step 1600: {'selected': 0.8436213991769547, 'score': 0.8436213991769547, 'examples_seen': 44160, 'step': 1600, 'algorithm': 'activity_selector'}
I1012 19:05:12.428956 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.844, val scores are: activity_selector: 0.844
I1012 19:05:13.536815 124643143087616 run.py:734] Algo activity_selector step 1650 current loss 1.311808, current_train_items 45536.
I1012 19:05:13.674429 124643143087616 run.py:769] (val) algo activity_selector step 1650: {'selected': 0.9224652087475149, 'score': 0.9224652087475149, 'examples_seen': 45536, 'step': 1650, 'algorithm': 'activity_selector'}
I1012 19:05:13.674673 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.922, val scores are: activity_selector: 0.922
I1012 19:05:14.781782 124643143087616 run.py:734] Algo activity_selector step 1700 current loss 1.434310, current_train_items 46896.
I1012 19:05:14.922235 124643143087616 run.py:769] (val) algo activity_selector step 1700: {'selected': 0.9142857142857143, 'score': 0.9142857142857143, 'examples_seen': 46896, 'step': 1700, 'algorithm': 'activity_selector'}
I1012 19:05:14.922463 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.914, val scores are: activity_selector: 0.914
I1012 19:05:16.017166 124643143087616 run.py:734] Algo activity_selector step 1750 current loss 1.318810, current_train_items 48304.
I1012 19:05:16.156569 124643143087616 run.py:769] (val) algo activity_selector step 1750: {'selected': 0.9318181818181819, 'score': 0.9318181818181819, 'examples_seen': 48304, 'step': 1750, 'algorithm': 'activity_selector'}
I1012 19:05:16.156817 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.932, val scores are: activity_selector: 0.932
I1012 19:05:17.297883 124643143087616 run.py:734] Algo activity_selector step 1800 current loss 1.258118, current_train_items 49664.
I1012 19:05:17.426964 124643143087616 run.py:769] (val) algo activity_selector step 1800: {'selected': 0.9488188976377951, 'score': 0.9488188976377951, 'examples_seen': 49664, 'step': 1800, 'algorithm': 'activity_selector'}
I1012 19:05:17.427139 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.949, val scores are: activity_selector: 0.949
I1012 19:05:18.502332 124643143087616 run.py:734] Algo activity_selector step 1850 current loss 1.076526, current_train_items 51056.
I1012 19:05:18.635120 124643143087616 run.py:769] (val) algo activity_selector step 1850: {'selected': 0.9117647058823529, 'score': 0.9117647058823529, 'examples_seen': 51056, 'step': 1850, 'algorithm': 'activity_selector'}
I1012 19:05:18.635367 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.912, val scores are: activity_selector: 0.912
I1012 19:05:19.711898 124643143087616 run.py:734] Algo activity_selector step 1900 current loss 1.086750, current_train_items 52432.
I1012 19:05:19.856440 124643143087616 run.py:769] (val) algo activity_selector step 1900: {'selected': 0.898336414048059, 'score': 0.898336414048059, 'examples_seen': 52432, 'step': 1900, 'algorithm': 'activity_selector'}
I1012 19:05:19.856679 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.898, val scores are: activity_selector: 0.898
I1012 19:05:21.010834 124643143087616 run.py:734] Algo activity_selector step 1950 current loss 1.328350, current_train_items 53808.
I1012 19:05:21.151866 124643143087616 run.py:769] (val) algo activity_selector step 1950: {'selected': 0.9163346613545817, 'score': 0.9163346613545817, 'examples_seen': 53808, 'step': 1950, 'algorithm': 'activity_selector'}
I1012 19:05:21.152091 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.916, val scores are: activity_selector: 0.916
I1012 19:05:22.245570 124643143087616 run.py:734] Algo activity_selector step 2000 current loss 1.099386, current_train_items 55184.
I1012 19:05:22.384039 124643143087616 run.py:769] (val) algo activity_selector step 2000: {'selected': 0.8970873786407766, 'score': 0.8970873786407766, 'examples_seen': 55184, 'step': 2000, 'algorithm': 'activity_selector'}
I1012 19:05:22.384266 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.897, val scores are: activity_selector: 0.897
I1012 19:05:23.507941 124643143087616 run.py:734] Algo activity_selector step 2050 current loss 1.107717, current_train_items 56560.
I1012 19:05:23.655800 124643143087616 run.py:769] (val) algo activity_selector step 2050: {'selected': 0.846286701208981, 'score': 0.846286701208981, 'examples_seen': 56560, 'step': 2050, 'algorithm': 'activity_selector'}
I1012 19:05:23.656006 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.846, val scores are: activity_selector: 0.846
I1012 19:05:24.753855 124643143087616 run.py:734] Algo activity_selector step 2100 current loss 1.260041, current_train_items 57952.
I1012 19:05:24.902253 124643143087616 run.py:769] (val) algo activity_selector step 2100: {'selected': 0.8782435129740519, 'score': 0.8782435129740519, 'examples_seen': 57952, 'step': 2100, 'algorithm': 'activity_selector'}
I1012 19:05:24.902480 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.878, val scores are: activity_selector: 0.878
I1012 19:05:26.004261 124643143087616 run.py:734] Algo activity_selector step 2150 current loss 1.332771, current_train_items 59312.
I1012 19:05:26.143670 124643143087616 run.py:769] (val) algo activity_selector step 2150: {'selected': 0.9042145593869733, 'score': 0.9042145593869733, 'examples_seen': 59312, 'step': 2150, 'algorithm': 'activity_selector'}
I1012 19:05:26.143917 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.904, val scores are: activity_selector: 0.904
I1012 19:05:27.233291 124643143087616 run.py:734] Algo activity_selector step 2200 current loss 1.353429, current_train_items 60720.
I1012 19:05:27.377028 124643143087616 run.py:769] (val) algo activity_selector step 2200: {'selected': 0.9400386847195359, 'score': 0.9400386847195359, 'examples_seen': 60720, 'step': 2200, 'algorithm': 'activity_selector'}
I1012 19:05:27.377262 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.940, val scores are: activity_selector: 0.940
I1012 19:05:28.454859 124643143087616 run.py:734] Algo activity_selector step 2250 current loss 1.083732, current_train_items 62080.
I1012 19:05:28.607010 124643143087616 run.py:769] (val) algo activity_selector step 2250: {'selected': 0.8802946593001842, 'score': 0.8802946593001842, 'examples_seen': 62080, 'step': 2250, 'algorithm': 'activity_selector'}
I1012 19:05:28.607244 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.880, val scores are: activity_selector: 0.880
I1012 19:05:29.742423 124643143087616 run.py:734] Algo activity_selector step 2300 current loss 1.052318, current_train_items 63440.
I1012 19:05:29.883001 124643143087616 run.py:769] (val) algo activity_selector step 2300: {'selected': 0.9216417910447761, 'score': 0.9216417910447761, 'examples_seen': 63440, 'step': 2300, 'algorithm': 'activity_selector'}
I1012 19:05:29.883238 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.922, val scores are: activity_selector: 0.922
I1012 19:05:30.993538 124643143087616 run.py:734] Algo activity_selector step 2350 current loss 0.907946, current_train_items 64848.
I1012 19:05:31.136482 124643143087616 run.py:769] (val) algo activity_selector step 2350: {'selected': 0.9489603024574669, 'score': 0.9489603024574669, 'examples_seen': 64848, 'step': 2350, 'algorithm': 'activity_selector'}
I1012 19:05:31.136760 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.949, val scores are: activity_selector: 0.949
I1012 19:05:32.249902 124643143087616 run.py:734] Algo activity_selector step 2400 current loss 1.100916, current_train_items 66208.
I1012 19:05:32.398279 124643143087616 run.py:769] (val) algo activity_selector step 2400: {'selected': 0.9253187613843351, 'score': 0.9253187613843351, 'examples_seen': 66208, 'step': 2400, 'algorithm': 'activity_selector'}
I1012 19:05:32.398506 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.925, val scores are: activity_selector: 0.925
I1012 19:05:33.459517 124643143087616 run.py:734] Algo activity_selector step 2450 current loss 1.089144, current_train_items 67600.
I1012 19:05:33.604170 124643143087616 run.py:769] (val) algo activity_selector step 2450: {'selected': 0.9467680608365019, 'score': 0.9467680608365019, 'examples_seen': 67600, 'step': 2450, 'algorithm': 'activity_selector'}
I1012 19:05:33.604397 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.947, val scores are: activity_selector: 0.947
I1012 19:05:34.690302 124643143087616 run.py:734] Algo activity_selector step 2500 current loss 1.300071, current_train_items 68976.
I1012 19:05:34.846170 124643143087616 run.py:769] (val) algo activity_selector step 2500: {'selected': 0.9040590405904059, 'score': 0.9040590405904059, 'examples_seen': 68976, 'step': 2500, 'algorithm': 'activity_selector'}
I1012 19:05:34.846411 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.904, val scores are: activity_selector: 0.904
I1012 19:05:35.934303 124643143087616 run.py:734] Algo activity_selector step 2550 current loss 0.885802, current_train_items 70352.
I1012 19:05:36.079441 124643143087616 run.py:769] (val) algo activity_selector step 2550: {'selected': 0.9147286821705426, 'score': 0.9147286821705426, 'examples_seen': 70352, 'step': 2550, 'algorithm': 'activity_selector'}
I1012 19:05:36.079671 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.915, val scores are: activity_selector: 0.915
I1012 19:05:37.194782 124643143087616 run.py:734] Algo activity_selector step 2600 current loss 1.055949, current_train_items 71728.
I1012 19:05:37.330135 124643143087616 run.py:769] (val) algo activity_selector step 2600: {'selected': 0.9083665338645418, 'score': 0.9083665338645418, 'examples_seen': 71728, 'step': 2600, 'algorithm': 'activity_selector'}
I1012 19:05:37.330361 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.908, val scores are: activity_selector: 0.908
I1012 19:05:38.416354 124643143087616 run.py:734] Algo activity_selector step 2650 current loss 0.802964, current_train_items 73104.
I1012 19:05:38.557353 124643143087616 run.py:769] (val) algo activity_selector step 2650: {'selected': 0.9314516129032259, 'score': 0.9314516129032259, 'examples_seen': 73104, 'step': 2650, 'algorithm': 'activity_selector'}
I1012 19:05:38.557632 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.950, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1012 19:05:39.690286 124643143087616 run.py:734] Algo activity_selector step 2700 current loss 1.008825, current_train_items 74496.
I1012 19:05:39.836256 124643143087616 run.py:769] (val) algo activity_selector step 2700: {'selected': 0.9520295202952029, 'score': 0.9520295202952029, 'examples_seen': 74496, 'step': 2700, 'algorithm': 'activity_selector'}
I1012 19:05:39.836517 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.950, current avg val score is 0.952, val scores are: activity_selector: 0.952
I1012 19:05:40.993743 124643143087616 run.py:734] Algo activity_selector step 2750 current loss 1.318866, current_train_items 75856.
I1012 19:05:41.127150 124643143087616 run.py:769] (val) algo activity_selector step 2750: {'selected': 0.890625, 'score': 0.890625, 'examples_seen': 75856, 'step': 2750, 'algorithm': 'activity_selector'}
I1012 19:05:41.127372 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.952, current avg val score is 0.891, val scores are: activity_selector: 0.891
I1012 19:05:42.170990 124643143087616 run.py:734] Algo activity_selector step 2800 current loss 0.887324, current_train_items 77264.
I1012 19:05:42.321437 124643143087616 run.py:769] (val) algo activity_selector step 2800: {'selected': 0.9364161849710984, 'score': 0.9364161849710984, 'examples_seen': 77264, 'step': 2800, 'algorithm': 'activity_selector'}
I1012 19:05:42.321687 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.952, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1012 19:05:43.391120 124643143087616 run.py:734] Algo activity_selector step 2850 current loss 1.039980, current_train_items 78624.
I1012 19:05:43.526408 124643143087616 run.py:769] (val) algo activity_selector step 2850: {'selected': 0.9359223300970874, 'score': 0.9359223300970874, 'examples_seen': 78624, 'step': 2850, 'algorithm': 'activity_selector'}
I1012 19:05:43.526638 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.952, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1012 19:05:44.585038 124643143087616 run.py:734] Algo activity_selector step 2900 current loss 1.173689, current_train_items 80000.
I1012 19:05:44.719552 124643143087616 run.py:769] (val) algo activity_selector step 2900: {'selected': 0.9020408163265307, 'score': 0.9020408163265307, 'examples_seen': 80000, 'step': 2900, 'algorithm': 'activity_selector'}
I1012 19:05:44.719791 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.952, current avg val score is 0.902, val scores are: activity_selector: 0.902
I1012 19:05:45.766448 124643143087616 run.py:734] Algo activity_selector step 2950 current loss 1.112313, current_train_items 81392.
I1012 19:05:45.915530 124643143087616 run.py:769] (val) algo activity_selector step 2950: {'selected': 0.9359223300970874, 'score': 0.9359223300970874, 'examples_seen': 81392, 'step': 2950, 'algorithm': 'activity_selector'}
I1012 19:05:45.915809 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.952, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1012 19:05:46.969675 124643143087616 run.py:734] Algo activity_selector step 3000 current loss 1.384008, current_train_items 82752.
I1012 19:05:47.116387 124643143087616 run.py:769] (val) algo activity_selector step 3000: {'selected': 0.8958333333333334, 'score': 0.8958333333333334, 'examples_seen': 82752, 'step': 3000, 'algorithm': 'activity_selector'}
I1012 19:05:47.116639 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.952, current avg val score is 0.896, val scores are: activity_selector: 0.896
I1012 19:05:48.177101 124643143087616 run.py:734] Algo activity_selector step 3050 current loss 0.926299, current_train_items 84144.
I1012 19:05:48.311872 124643143087616 run.py:769] (val) algo activity_selector step 3050: {'selected': 0.91796875, 'score': 0.91796875, 'examples_seen': 84144, 'step': 3050, 'algorithm': 'activity_selector'}
I1012 19:05:48.312096 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.952, current avg val score is 0.918, val scores are: activity_selector: 0.918
I1012 19:05:49.369237 124643143087616 run.py:734] Algo activity_selector step 3100 current loss 1.292504, current_train_items 85520.
I1012 19:05:49.504192 124643143087616 run.py:769] (val) algo activity_selector step 3100: {'selected': 0.9590643274853802, 'score': 0.9590643274853802, 'examples_seen': 85520, 'step': 3100, 'algorithm': 'activity_selector'}
I1012 19:05:49.504417 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.952, current avg val score is 0.959, val scores are: activity_selector: 0.959
I1012 19:05:50.611811 124643143087616 run.py:734] Algo activity_selector step 3150 current loss 0.805513, current_train_items 86896.
I1012 19:05:50.757239 124643143087616 run.py:769] (val) algo activity_selector step 3150: {'selected': 0.9405204460966542, 'score': 0.9405204460966542, 'examples_seen': 86896, 'step': 3150, 'algorithm': 'activity_selector'}
I1012 19:05:50.757462 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.959, current avg val score is 0.941, val scores are: activity_selector: 0.941
I1012 19:05:51.814971 124643143087616 run.py:734] Algo activity_selector step 3200 current loss 0.770342, current_train_items 88272.
I1012 19:05:51.946822 124643143087616 run.py:769] (val) algo activity_selector step 3200: {'selected': 0.9239999999999999, 'score': 0.9239999999999999, 'examples_seen': 88272, 'step': 3200, 'algorithm': 'activity_selector'}
I1012 19:05:51.947057 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.959, current avg val score is 0.924, val scores are: activity_selector: 0.924
I1012 19:05:53.008777 124643143087616 run.py:734] Algo activity_selector step 3250 current loss 1.300112, current_train_items 89664.
I1012 19:05:53.144254 124643143087616 run.py:769] (val) algo activity_selector step 3250: {'selected': 0.9563567362428843, 'score': 0.9563567362428843, 'examples_seen': 89664, 'step': 3250, 'algorithm': 'activity_selector'}
I1012 19:05:53.144505 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.959, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1012 19:05:54.212152 124643143087616 run.py:734] Algo activity_selector step 3300 current loss 0.923310, current_train_items 91040.
I1012 19:05:54.343424 124643143087616 run.py:769] (val) algo activity_selector step 3300: {'selected': 0.9271255060728745, 'score': 0.9271255060728745, 'examples_seen': 91040, 'step': 3300, 'algorithm': 'activity_selector'}
I1012 19:05:54.343647 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.959, current avg val score is 0.927, val scores are: activity_selector: 0.927
I1012 19:05:55.386951 124643143087616 run.py:734] Algo activity_selector step 3350 current loss 1.150525, current_train_items 92400.
I1012 19:05:55.536494 124643143087616 run.py:769] (val) algo activity_selector step 3350: {'selected': 0.9439071566731142, 'score': 0.9439071566731142, 'examples_seen': 92400, 'step': 3350, 'algorithm': 'activity_selector'}
I1012 19:05:55.536775 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.959, current avg val score is 0.944, val scores are: activity_selector: 0.944
I1012 19:05:56.598620 124643143087616 run.py:734] Algo activity_selector step 3400 current loss 0.931763, current_train_items 93792.
I1012 19:05:56.730855 124643143087616 run.py:769] (val) algo activity_selector step 3400: {'selected': 0.9674952198852772, 'score': 0.9674952198852772, 'examples_seen': 93792, 'step': 3400, 'algorithm': 'activity_selector'}
I1012 19:05:56.731078 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.959, current avg val score is 0.967, val scores are: activity_selector: 0.967
I1012 19:05:57.841194 124643143087616 run.py:734] Algo activity_selector step 3450 current loss 0.993064, current_train_items 95168.
I1012 19:05:57.989021 124643143087616 run.py:769] (val) algo activity_selector step 3450: {'selected': 0.937984496124031, 'score': 0.937984496124031, 'examples_seen': 95168, 'step': 3450, 'algorithm': 'activity_selector'}
I1012 19:05:57.989242 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.938, val scores are: activity_selector: 0.938
I1012 19:05:59.033910 124643143087616 run.py:734] Algo activity_selector step 3500 current loss 1.019313, current_train_items 96544.
I1012 19:05:59.183113 124643143087616 run.py:769] (val) algo activity_selector step 3500: {'selected': 0.903954802259887, 'score': 0.903954802259887, 'examples_seen': 96544, 'step': 3500, 'algorithm': 'activity_selector'}
I1012 19:05:59.183335 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.904, val scores are: activity_selector: 0.904
I1012 19:06:00.227435 124643143087616 run.py:734] Algo activity_selector step 3550 current loss 0.912485, current_train_items 97936.
I1012 19:06:00.374072 124643143087616 run.py:769] (val) algo activity_selector step 3550: {'selected': 0.9486166007905138, 'score': 0.9486166007905138, 'examples_seen': 97936, 'step': 3550, 'algorithm': 'activity_selector'}
I1012 19:06:00.374296 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.949, val scores are: activity_selector: 0.949
I1012 19:06:01.427561 124643143087616 run.py:734] Algo activity_selector step 3600 current loss 1.159552, current_train_items 99312.
I1012 19:06:01.574517 124643143087616 run.py:769] (val) algo activity_selector step 3600: {'selected': 0.9659318637274549, 'score': 0.9659318637274549, 'examples_seen': 99312, 'step': 3600, 'algorithm': 'activity_selector'}
I1012 19:06:01.574752 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.966, val scores are: activity_selector: 0.966
I1012 19:06:02.621836 124643143087616 run.py:734] Algo activity_selector step 3650 current loss 1.118075, current_train_items 100688.
I1012 19:06:02.770704 124643143087616 run.py:769] (val) algo activity_selector step 3650: {'selected': 0.9194991055456172, 'score': 0.9194991055456172, 'examples_seen': 100688, 'step': 3650, 'algorithm': 'activity_selector'}
I1012 19:06:02.770887 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.919, val scores are: activity_selector: 0.919
I1012 19:06:03.831451 124643143087616 run.py:734] Algo activity_selector step 3700 current loss 0.940932, current_train_items 102064.
I1012 19:06:03.965534 124643143087616 run.py:769] (val) algo activity_selector step 3700: {'selected': 0.9554655870445344, 'score': 0.9554655870445344, 'examples_seen': 102064, 'step': 3700, 'algorithm': 'activity_selector'}
I1012 19:06:03.965799 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.955, val scores are: activity_selector: 0.955
I1012 19:06:05.032765 124643143087616 run.py:734] Algo activity_selector step 3750 current loss 1.081349, current_train_items 103440.
I1012 19:06:05.167947 124643143087616 run.py:769] (val) algo activity_selector step 3750: {'selected': 0.9432485322896281, 'score': 0.9432485322896281, 'examples_seen': 103440, 'step': 3750, 'algorithm': 'activity_selector'}
I1012 19:06:05.168194 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1012 19:06:06.224221 124643143087616 run.py:734] Algo activity_selector step 3800 current loss 0.987195, current_train_items 104816.
I1012 19:06:06.361224 124643143087616 run.py:769] (val) algo activity_selector step 3800: {'selected': 0.9372549019607842, 'score': 0.9372549019607842, 'examples_seen': 104816, 'step': 3800, 'algorithm': 'activity_selector'}
I1012 19:06:06.361457 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.937, val scores are: activity_selector: 0.937
I1012 19:06:07.419797 124643143087616 run.py:734] Algo activity_selector step 3850 current loss 1.132561, current_train_items 106208.
I1012 19:06:07.551518 124643143087616 run.py:769] (val) algo activity_selector step 3850: {'selected': 0.9165120593692022, 'score': 0.9165120593692022, 'examples_seen': 106208, 'step': 3850, 'algorithm': 'activity_selector'}
I1012 19:06:07.551759 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.917, val scores are: activity_selector: 0.917
I1012 19:06:08.609361 124643143087616 run.py:734] Algo activity_selector step 3900 current loss 1.053746, current_train_items 107584.
I1012 19:06:08.755630 124643143087616 run.py:769] (val) algo activity_selector step 3900: {'selected': 0.9387755102040817, 'score': 0.9387755102040817, 'examples_seen': 107584, 'step': 3900, 'algorithm': 'activity_selector'}
I1012 19:06:08.755895 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.939, val scores are: activity_selector: 0.939
I1012 19:06:09.804662 124643143087616 run.py:734] Algo activity_selector step 3950 current loss 0.715953, current_train_items 108960.
I1012 19:06:09.950173 124643143087616 run.py:769] (val) algo activity_selector step 3950: {'selected': 0.9449715370018976, 'score': 0.9449715370018976, 'examples_seen': 108960, 'step': 3950, 'algorithm': 'activity_selector'}
I1012 19:06:09.950396 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.945, val scores are: activity_selector: 0.945
I1012 19:06:11.011684 124643143087616 run.py:734] Algo activity_selector step 4000 current loss 0.985319, current_train_items 110336.
I1012 19:06:11.145452 124643143087616 run.py:769] (val) algo activity_selector step 4000: {'selected': 0.8677839851024208, 'score': 0.8677839851024208, 'examples_seen': 110336, 'step': 4000, 'algorithm': 'activity_selector'}
I1012 19:06:11.145677 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.868, val scores are: activity_selector: 0.868
I1012 19:06:12.212917 124643143087616 run.py:734] Algo activity_selector step 4050 current loss 0.889115, current_train_items 111712.
I1012 19:06:12.345412 124643143087616 run.py:769] (val) algo activity_selector step 4050: {'selected': 0.948, 'score': 0.948, 'examples_seen': 111712, 'step': 4050, 'algorithm': 'activity_selector'}
I1012 19:06:12.345646 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1012 19:06:13.393386 124643143087616 run.py:734] Algo activity_selector step 4100 current loss 0.763309, current_train_items 113088.
I1012 19:06:13.541460 124643143087616 run.py:769] (val) algo activity_selector step 4100: {'selected': 0.9499072356215214, 'score': 0.9499072356215214, 'examples_seen': 113088, 'step': 4100, 'algorithm': 'activity_selector'}
I1012 19:06:13.541703 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1012 19:06:14.602117 124643143087616 run.py:734] Algo activity_selector step 4150 current loss 0.710776, current_train_items 114480.
I1012 19:06:14.735552 124643143087616 run.py:769] (val) algo activity_selector step 4150: {'selected': 0.9461538461538462, 'score': 0.9461538461538462, 'examples_seen': 114480, 'step': 4150, 'algorithm': 'activity_selector'}
I1012 19:06:14.735792 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.946, val scores are: activity_selector: 0.946
I1012 19:06:15.804566 124643143087616 run.py:734] Algo activity_selector step 4200 current loss 1.297626, current_train_items 115856.
I1012 19:06:15.936414 124643143087616 run.py:769] (val) algo activity_selector step 4200: {'selected': 0.9218750000000001, 'score': 0.9218750000000001, 'examples_seen': 115856, 'step': 4200, 'algorithm': 'activity_selector'}
I1012 19:06:15.936639 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.922, val scores are: activity_selector: 0.922
I1012 19:06:16.981113 124643143087616 run.py:734] Algo activity_selector step 4250 current loss 0.887301, current_train_items 117216.
I1012 19:06:17.125261 124643143087616 run.py:769] (val) algo activity_selector step 4250: {'selected': 0.9479768786127166, 'score': 0.9479768786127166, 'examples_seen': 117216, 'step': 4250, 'algorithm': 'activity_selector'}
I1012 19:06:17.125485 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1012 19:06:18.171389 124643143087616 run.py:734] Algo activity_selector step 4300 current loss 0.987916, current_train_items 118624.
I1012 19:06:18.318746 124643143087616 run.py:769] (val) algo activity_selector step 4300: {'selected': 0.9653916211293261, 'score': 0.9653916211293261, 'examples_seen': 118624, 'step': 4300, 'algorithm': 'activity_selector'}
I1012 19:06:18.318984 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.965, val scores are: activity_selector: 0.965
I1012 19:06:19.380361 124643143087616 run.py:734] Algo activity_selector step 4350 current loss 0.693781, current_train_items 119984.
I1012 19:06:19.528023 124643143087616 run.py:769] (val) algo activity_selector step 4350: {'selected': 0.9606299212598426, 'score': 0.9606299212598426, 'examples_seen': 119984, 'step': 4350, 'algorithm': 'activity_selector'}
I1012 19:06:19.528249 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.961, val scores are: activity_selector: 0.961
I1012 19:06:20.586539 124643143087616 run.py:734] Algo activity_selector step 4400 current loss 0.696345, current_train_items 121360.
I1012 19:06:20.719765 124643143087616 run.py:769] (val) algo activity_selector step 4400: {'selected': 0.9402697495183046, 'score': 0.9402697495183046, 'examples_seen': 121360, 'step': 4400, 'algorithm': 'activity_selector'}
I1012 19:06:20.719992 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.940, val scores are: activity_selector: 0.940
I1012 19:06:21.764247 124643143087616 run.py:734] Algo activity_selector step 4450 current loss 1.109803, current_train_items 122752.
I1012 19:06:21.912213 124643143087616 run.py:769] (val) algo activity_selector step 4450: {'selected': 0.9551656920077973, 'score': 0.9551656920077973, 'examples_seen': 122752, 'step': 4450, 'algorithm': 'activity_selector'}
I1012 19:06:21.912441 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.955, val scores are: activity_selector: 0.955
I1012 19:06:22.981849 124643143087616 run.py:734] Algo activity_selector step 4500 current loss 0.730640, current_train_items 124128.
I1012 19:06:23.117082 124643143087616 run.py:769] (val) algo activity_selector step 4500: {'selected': 0.9604743083003954, 'score': 0.9604743083003954, 'examples_seen': 124128, 'step': 4500, 'algorithm': 'activity_selector'}
I1012 19:06:23.117308 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.960, val scores are: activity_selector: 0.960
I1012 19:06:24.186521 124643143087616 run.py:734] Algo activity_selector step 4550 current loss 0.751837, current_train_items 125504.
I1012 19:06:24.314342 124643143087616 run.py:769] (val) algo activity_selector step 4550: {'selected': 0.8976377952755905, 'score': 0.8976377952755905, 'examples_seen': 125504, 'step': 4550, 'algorithm': 'activity_selector'}
I1012 19:06:24.314491 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.898, val scores are: activity_selector: 0.898
I1012 19:06:25.347355 124643143087616 run.py:734] Algo activity_selector step 4600 current loss 1.016706, current_train_items 126880.
I1012 19:06:25.493504 124643143087616 run.py:769] (val) algo activity_selector step 4600: {'selected': 0.9571984435797667, 'score': 0.9571984435797667, 'examples_seen': 126880, 'step': 4600, 'algorithm': 'activity_selector'}
I1012 19:06:25.493654 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.957, val scores are: activity_selector: 0.957
I1012 19:06:26.549011 124643143087616 run.py:734] Algo activity_selector step 4650 current loss 0.918886, current_train_items 128272.
I1012 19:06:26.678807 124643143087616 run.py:769] (val) algo activity_selector step 4650: {'selected': 0.9500000000000001, 'score': 0.9500000000000001, 'examples_seen': 128272, 'step': 4650, 'algorithm': 'activity_selector'}
I1012 19:06:26.679000 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1012 19:06:27.730325 124643143087616 run.py:734] Algo activity_selector step 4700 current loss 0.956242, current_train_items 129632.
I1012 19:06:27.861363 124643143087616 run.py:769] (val) algo activity_selector step 4700: {'selected': 0.9111969111969113, 'score': 0.9111969111969113, 'examples_seen': 129632, 'step': 4700, 'algorithm': 'activity_selector'}
I1012 19:06:27.861511 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.911, val scores are: activity_selector: 0.911
I1012 19:06:28.901288 124643143087616 run.py:734] Algo activity_selector step 4750 current loss 1.284664, current_train_items 131024.
I1012 19:06:29.052694 124643143087616 run.py:769] (val) algo activity_selector step 4750: {'selected': 0.9057971014492754, 'score': 0.9057971014492754, 'examples_seen': 131024, 'step': 4750, 'algorithm': 'activity_selector'}
I1012 19:06:29.052930 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.906, val scores are: activity_selector: 0.906
I1012 19:06:30.123364 124643143087616 run.py:734] Algo activity_selector step 4800 current loss 1.089043, current_train_items 132400.
I1012 19:06:30.255596 124643143087616 run.py:769] (val) algo activity_selector step 4800: {'selected': 0.9273743016759777, 'score': 0.9273743016759777, 'examples_seen': 132400, 'step': 4800, 'algorithm': 'activity_selector'}
I1012 19:06:30.255755 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.927, val scores are: activity_selector: 0.927
I1012 19:06:31.309400 124643143087616 run.py:734] Algo activity_selector step 4850 current loss 0.763247, current_train_items 133760.
I1012 19:06:31.441326 124643143087616 run.py:769] (val) algo activity_selector step 4850: {'selected': 0.929889298892989, 'score': 0.929889298892989, 'examples_seen': 133760, 'step': 4850, 'algorithm': 'activity_selector'}
I1012 19:06:31.441525 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.930, val scores are: activity_selector: 0.930
I1012 19:06:32.477563 124643143087616 run.py:734] Algo activity_selector step 4900 current loss 0.801223, current_train_items 135168.
I1012 19:06:32.621699 124643143087616 run.py:769] (val) algo activity_selector step 4900: {'selected': 0.9459962756052143, 'score': 0.9459962756052143, 'examples_seen': 135168, 'step': 4900, 'algorithm': 'activity_selector'}
I1012 19:06:32.621938 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.946, val scores are: activity_selector: 0.946
I1012 19:06:33.678628 124643143087616 run.py:734] Algo activity_selector step 4950 current loss 0.671852, current_train_items 136528.
I1012 19:06:33.809121 124643143087616 run.py:769] (val) algo activity_selector step 4950: {'selected': 0.9190207156308852, 'score': 0.9190207156308852, 'examples_seen': 136528, 'step': 4950, 'algorithm': 'activity_selector'}
I1012 19:06:33.809355 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.919, val scores are: activity_selector: 0.919
I1012 19:06:34.862987 124643143087616 run.py:734] Algo activity_selector step 5000 current loss 0.744141, current_train_items 137920.
I1012 19:06:34.994908 124643143087616 run.py:769] (val) algo activity_selector step 5000: {'selected': 0.927643784786642, 'score': 0.927643784786642, 'examples_seen': 137920, 'step': 5000, 'algorithm': 'activity_selector'}
I1012 19:06:34.995108 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.928, val scores are: activity_selector: 0.928
I1012 19:06:36.045696 124643143087616 run.py:734] Algo activity_selector step 5050 current loss 1.007183, current_train_items 139296.
I1012 19:06:36.178086 124643143087616 run.py:769] (val) algo activity_selector step 5050: {'selected': 0.925, 'score': 0.925, 'examples_seen': 139296, 'step': 5050, 'algorithm': 'activity_selector'}
I1012 19:06:36.178309 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.925, val scores are: activity_selector: 0.925
I1012 19:06:37.234280 124643143087616 run.py:734] Algo activity_selector step 5100 current loss 1.116717, current_train_items 140656.
I1012 19:06:37.381271 124643143087616 run.py:769] (val) algo activity_selector step 5100: {'selected': 0.9225352112676056, 'score': 0.9225352112676056, 'examples_seen': 140656, 'step': 5100, 'algorithm': 'activity_selector'}
I1012 19:06:37.381497 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.923, val scores are: activity_selector: 0.923
I1012 19:06:38.441473 124643143087616 run.py:734] Algo activity_selector step 5150 current loss 1.143136, current_train_items 142048.
I1012 19:06:38.573378 124643143087616 run.py:769] (val) algo activity_selector step 5150: {'selected': 0.9120654396728016, 'score': 0.9120654396728016, 'examples_seen': 142048, 'step': 5150, 'algorithm': 'activity_selector'}
I1012 19:06:38.573604 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.967, current avg val score is 0.912, val scores are: activity_selector: 0.912
I1012 19:06:39.638063 124643143087616 run.py:734] Algo activity_selector step 5200 current loss 0.706791, current_train_items 143424.
I1012 19:06:39.767374 124643143087616 run.py:769] (val) algo activity_selector step 5200: {'selected': 0.970873786407767, 'score': 0.970873786407767, 'examples_seen': 143424, 'step': 5200, 'algorithm': 'activity_selector'}
I1012 19:06:39.767524 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.967, current avg val score is 0.971, val scores are: activity_selector: 0.971
I1012 19:06:40.887950 124643143087616 run.py:734] Algo activity_selector step 5250 current loss 0.738212, current_train_items 144816.
I1012 19:06:41.020773 124643143087616 run.py:769] (val) algo activity_selector step 5250: {'selected': 0.9355432780847145, 'score': 0.9355432780847145, 'examples_seen': 144816, 'step': 5250, 'algorithm': 'activity_selector'}
I1012 19:06:41.020997 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.971, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1012 19:06:42.089798 124643143087616 run.py:734] Algo activity_selector step 5300 current loss 0.850499, current_train_items 146176.
I1012 19:06:42.215147 124643143087616 run.py:769] (val) algo activity_selector step 5300: {'selected': 0.9736842105263158, 'score': 0.9736842105263158, 'examples_seen': 146176, 'step': 5300, 'algorithm': 'activity_selector'}
I1012 19:06:42.215371 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.971, current avg val score is 0.974, val scores are: activity_selector: 0.974
I1012 19:06:43.330597 124643143087616 run.py:734] Algo activity_selector step 5350 current loss 0.743626, current_train_items 147584.
I1012 19:06:43.465620 124643143087616 run.py:769] (val) algo activity_selector step 5350: {'selected': 0.9197860962566845, 'score': 0.9197860962566845, 'examples_seen': 147584, 'step': 5350, 'algorithm': 'activity_selector'}
I1012 19:06:43.465858 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.920, val scores are: activity_selector: 0.920
I1012 19:06:44.542002 124643143087616 run.py:734] Algo activity_selector step 5400 current loss 0.840593, current_train_items 148944.
I1012 19:06:44.675755 124643143087616 run.py:769] (val) algo activity_selector step 5400: {'selected': 0.8995983935742972, 'score': 0.8995983935742972, 'examples_seen': 148944, 'step': 5400, 'algorithm': 'activity_selector'}
I1012 19:06:44.675981 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.900, val scores are: activity_selector: 0.900
I1012 19:06:45.737167 124643143087616 run.py:734] Algo activity_selector step 5450 current loss 0.801358, current_train_items 150304.
I1012 19:06:45.865958 124643143087616 run.py:769] (val) algo activity_selector step 5450: {'selected': 0.9420560747663551, 'score': 0.9420560747663551, 'examples_seen': 150304, 'step': 5450, 'algorithm': 'activity_selector'}
I1012 19:06:45.866111 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1012 19:06:46.913801 124643143087616 run.py:734] Algo activity_selector step 5500 current loss 1.294163, current_train_items 151712.
I1012 19:06:47.046180 124643143087616 run.py:769] (val) algo activity_selector step 5500: {'selected': 0.8583162217659138, 'score': 0.8583162217659138, 'examples_seen': 151712, 'step': 5500, 'algorithm': 'activity_selector'}
I1012 19:06:47.046327 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.858, val scores are: activity_selector: 0.858
I1012 19:06:48.085757 124643143087616 run.py:734] Algo activity_selector step 5550 current loss 1.005137, current_train_items 153072.
I1012 19:06:48.233478 124643143087616 run.py:769] (val) algo activity_selector step 5550: {'selected': 0.9573283858998145, 'score': 0.9573283858998145, 'examples_seen': 153072, 'step': 5550, 'algorithm': 'activity_selector'}
I1012 19:06:48.233701 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.957, val scores are: activity_selector: 0.957
I1012 19:06:49.300005 124643143087616 run.py:734] Algo activity_selector step 5600 current loss 0.669292, current_train_items 154464.
I1012 19:06:49.427017 124643143087616 run.py:769] (val) algo activity_selector step 5600: {'selected': 0.9509594882729212, 'score': 0.9509594882729212, 'examples_seen': 154464, 'step': 5600, 'algorithm': 'activity_selector'}
I1012 19:06:49.427245 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.951, val scores are: activity_selector: 0.951
I1012 19:06:50.489370 124643143087616 run.py:734] Algo activity_selector step 5650 current loss 0.587131, current_train_items 155840.
I1012 19:06:50.623899 124643143087616 run.py:769] (val) algo activity_selector step 5650: {'selected': 0.9499072356215212, 'score': 0.9499072356215212, 'examples_seen': 155840, 'step': 5650, 'algorithm': 'activity_selector'}
I1012 19:06:50.624123 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1012 19:06:51.678331 124643143087616 run.py:734] Algo activity_selector step 5700 current loss 1.148929, current_train_items 157216.
I1012 19:06:51.827030 124643143087616 run.py:769] (val) algo activity_selector step 5700: {'selected': 0.9113924050632911, 'score': 0.9113924050632911, 'examples_seen': 157216, 'step': 5700, 'algorithm': 'activity_selector'}
I1012 19:06:51.827254 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.911, val scores are: activity_selector: 0.911
I1012 19:06:52.888978 124643143087616 run.py:734] Algo activity_selector step 5750 current loss 1.131178, current_train_items 158592.
I1012 19:06:53.024250 124643143087616 run.py:769] (val) algo activity_selector step 5750: {'selected': 0.952191235059761, 'score': 0.952191235059761, 'examples_seen': 158592, 'step': 5750, 'algorithm': 'activity_selector'}
I1012 19:06:53.024501 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.952, val scores are: activity_selector: 0.952
I1012 19:06:54.083915 124643143087616 run.py:734] Algo activity_selector step 5800 current loss 0.773821, current_train_items 159968.
I1012 19:06:54.215966 124643143087616 run.py:769] (val) algo activity_selector step 5800: {'selected': 0.9265536723163842, 'score': 0.9265536723163842, 'examples_seen': 159968, 'step': 5800, 'algorithm': 'activity_selector'}
I1012 19:06:54.216188 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.927, val scores are: activity_selector: 0.927
I1012 19:06:55.289533 124643143087616 run.py:734] Algo activity_selector step 5850 current loss 0.878268, current_train_items 161360.
I1012 19:06:55.424388 124643143087616 run.py:769] (val) algo activity_selector step 5850: {'selected': 0.9070208728652752, 'score': 0.9070208728652752, 'examples_seen': 161360, 'step': 5850, 'algorithm': 'activity_selector'}
I1012 19:06:55.424612 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.907, val scores are: activity_selector: 0.907
I1012 19:06:56.469052 124643143087616 run.py:734] Algo activity_selector step 5900 current loss 0.813379, current_train_items 162720.
I1012 19:06:56.617193 124643143087616 run.py:769] (val) algo activity_selector step 5900: {'selected': 0.9343065693430657, 'score': 0.9343065693430657, 'examples_seen': 162720, 'step': 5900, 'algorithm': 'activity_selector'}
I1012 19:06:56.617418 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.934, val scores are: activity_selector: 0.934
I1012 19:06:57.675259 124643143087616 run.py:734] Algo activity_selector step 5950 current loss 0.596550, current_train_items 164112.
I1012 19:06:57.809130 124643143087616 run.py:769] (val) algo activity_selector step 5950: {'selected': 0.9553398058252428, 'score': 0.9553398058252428, 'examples_seen': 164112, 'step': 5950, 'algorithm': 'activity_selector'}
I1012 19:06:57.809359 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.974, current avg val score is 0.955, val scores are: activity_selector: 0.955
I1012 19:06:58.877700 124643143087616 run.py:734] Algo activity_selector step 6000 current loss 0.710862, current_train_items 165488.
I1012 19:06:59.011807 124643143087616 run.py:769] (val) algo activity_selector step 6000: {'selected': 0.9766606822262119, 'score': 0.9766606822262119, 'examples_seen': 165488, 'step': 6000, 'algorithm': 'activity_selector'}
I1012 19:06:59.012048 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.974, current avg val score is 0.977, val scores are: activity_selector: 0.977
I1012 19:07:00.129590 124643143087616 run.py:734] Algo activity_selector step 6050 current loss 0.688841, current_train_items 166864.
I1012 19:07:00.266193 124643143087616 run.py:769] (val) algo activity_selector step 6050: {'selected': 0.9166666666666667, 'score': 0.9166666666666667, 'examples_seen': 166864, 'step': 6050, 'algorithm': 'activity_selector'}
I1012 19:07:00.266429 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.917, val scores are: activity_selector: 0.917
I1012 19:07:01.326657 124643143087616 run.py:734] Algo activity_selector step 6100 current loss 0.887294, current_train_items 168256.
I1012 19:07:01.461910 124643143087616 run.py:769] (val) algo activity_selector step 6100: {'selected': 0.9068322981366461, 'score': 0.9068322981366461, 'examples_seen': 168256, 'step': 6100, 'algorithm': 'activity_selector'}
I1012 19:07:01.462135 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.907, val scores are: activity_selector: 0.907
I1012 19:07:02.530736 124643143087616 run.py:734] Algo activity_selector step 6150 current loss 1.025351, current_train_items 169616.
I1012 19:07:02.664716 124643143087616 run.py:769] (val) algo activity_selector step 6150: {'selected': 0.9535864978902954, 'score': 0.9535864978902954, 'examples_seen': 169616, 'step': 6150, 'algorithm': 'activity_selector'}
I1012 19:07:02.664953 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.954, val scores are: activity_selector: 0.954
I1012 19:07:03.708174 124643143087616 run.py:734] Algo activity_selector step 6200 current loss 0.816524, current_train_items 171008.
I1012 19:07:03.855342 124643143087616 run.py:769] (val) algo activity_selector step 6200: {'selected': 0.9355509355509356, 'score': 0.9355509355509356, 'examples_seen': 171008, 'step': 6200, 'algorithm': 'activity_selector'}
I1012 19:07:03.855568 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1012 19:07:04.914288 124643143087616 run.py:734] Algo activity_selector step 6250 current loss 0.999222, current_train_items 172384.
I1012 19:07:05.045415 124643143087616 run.py:769] (val) algo activity_selector step 6250: {'selected': 0.9671179883945842, 'score': 0.9671179883945842, 'examples_seen': 172384, 'step': 6250, 'algorithm': 'activity_selector'}
I1012 19:07:05.045637 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.967, val scores are: activity_selector: 0.967
I1012 19:07:06.103591 124643143087616 run.py:734] Algo activity_selector step 6300 current loss 0.639272, current_train_items 173760.
I1012 19:07:06.236393 124643143087616 run.py:769] (val) algo activity_selector step 6300: {'selected': 0.9447619047619047, 'score': 0.9447619047619047, 'examples_seen': 173760, 'step': 6300, 'algorithm': 'activity_selector'}
I1012 19:07:06.236614 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.945, val scores are: activity_selector: 0.945
I1012 19:07:07.294643 124643143087616 run.py:734] Algo activity_selector step 6350 current loss 0.741498, current_train_items 175136.
I1012 19:07:07.429121 124643143087616 run.py:769] (val) algo activity_selector step 6350: {'selected': 0.931237721021611, 'score': 0.931237721021611, 'examples_seen': 175136, 'step': 6350, 'algorithm': 'activity_selector'}
I1012 19:07:07.429349 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1012 19:07:08.486464 124643143087616 run.py:734] Algo activity_selector step 6400 current loss 0.882609, current_train_items 176528.
I1012 19:07:08.621571 124643143087616 run.py:769] (val) algo activity_selector step 6400: {'selected': 0.9400000000000001, 'score': 0.9400000000000001, 'examples_seen': 176528, 'step': 6400, 'algorithm': 'activity_selector'}
I1012 19:07:08.621809 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.940, val scores are: activity_selector: 0.940
I1012 19:07:09.691025 124643143087616 run.py:734] Algo activity_selector step 6450 current loss 0.664288, current_train_items 177904.
I1012 19:07:09.826107 124643143087616 run.py:769] (val) algo activity_selector step 6450: {'selected': 0.9379562043795621, 'score': 0.9379562043795621, 'examples_seen': 177904, 'step': 6450, 'algorithm': 'activity_selector'}
I1012 19:07:09.826342 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.938, val scores are: activity_selector: 0.938
I1012 19:07:10.889351 124643143087616 run.py:734] Algo activity_selector step 6500 current loss 0.546535, current_train_items 179264.
I1012 19:07:11.022938 124643143087616 run.py:769] (val) algo activity_selector step 6500: {'selected': 0.9420035149384886, 'score': 0.9420035149384886, 'examples_seen': 179264, 'step': 6500, 'algorithm': 'activity_selector'}
I1012 19:07:11.023165 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1012 19:07:12.080954 124643143087616 run.py:734] Algo activity_selector step 6550 current loss 0.654472, current_train_items 180656.
I1012 19:07:12.215762 124643143087616 run.py:769] (val) algo activity_selector step 6550: {'selected': 0.9459962756052142, 'score': 0.9459962756052142, 'examples_seen': 180656, 'step': 6550, 'algorithm': 'activity_selector'}
I1012 19:07:12.215992 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.946, val scores are: activity_selector: 0.946
I1012 19:07:13.288896 124643143087616 run.py:734] Algo activity_selector step 6600 current loss 0.975378, current_train_items 182032.
I1012 19:07:13.416470 124643143087616 run.py:769] (val) algo activity_selector step 6600: {'selected': 0.9416195856873824, 'score': 0.9416195856873824, 'examples_seen': 182032, 'step': 6600, 'algorithm': 'activity_selector'}
I1012 19:07:13.416617 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1012 19:07:14.463457 124643143087616 run.py:734] Algo activity_selector step 6650 current loss 0.985154, current_train_items 183408.
I1012 19:07:14.594988 124643143087616 run.py:769] (val) algo activity_selector step 6650: {'selected': 0.8923076923076922, 'score': 0.8923076923076922, 'examples_seen': 183408, 'step': 6650, 'algorithm': 'activity_selector'}
I1012 19:07:14.595139 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.892, val scores are: activity_selector: 0.892
I1012 19:07:15.645068 124643143087616 run.py:734] Algo activity_selector step 6700 current loss 0.781195, current_train_items 184800.
I1012 19:07:15.776955 124643143087616 run.py:769] (val) algo activity_selector step 6700: {'selected': 0.9333333333333332, 'score': 0.9333333333333332, 'examples_seen': 184800, 'step': 6700, 'algorithm': 'activity_selector'}
I1012 19:07:15.777183 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.933, val scores are: activity_selector: 0.933
I1012 19:07:16.839376 124643143087616 run.py:734] Algo activity_selector step 6750 current loss 0.718016, current_train_items 186176.
I1012 19:07:16.970883 124643143087616 run.py:769] (val) algo activity_selector step 6750: {'selected': 0.9195876288659794, 'score': 0.9195876288659794, 'examples_seen': 186176, 'step': 6750, 'algorithm': 'activity_selector'}
I1012 19:07:16.971125 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.920, val scores are: activity_selector: 0.920
I1012 19:07:18.020164 124643143087616 run.py:734] Algo activity_selector step 6800 current loss 0.637232, current_train_items 187536.
I1012 19:07:18.165908 124643143087616 run.py:769] (val) algo activity_selector step 6800: {'selected': 0.9050279329608939, 'score': 0.9050279329608939, 'examples_seen': 187536, 'step': 6800, 'algorithm': 'activity_selector'}
I1012 19:07:18.166084 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.905, val scores are: activity_selector: 0.905
I1012 19:07:19.212575 124643143087616 run.py:734] Algo activity_selector step 6850 current loss 1.002056, current_train_items 188928.
I1012 19:07:19.344281 124643143087616 run.py:769] (val) algo activity_selector step 6850: {'selected': 0.92057761732852, 'score': 0.92057761732852, 'examples_seen': 188928, 'step': 6850, 'algorithm': 'activity_selector'}
I1012 19:07:19.344505 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.921, val scores are: activity_selector: 0.921
I1012 19:07:20.399116 124643143087616 run.py:734] Algo activity_selector step 6900 current loss 0.616476, current_train_items 190304.
I1012 19:07:20.534763 124643143087616 run.py:769] (val) algo activity_selector step 6900: {'selected': 0.9402390438247012, 'score': 0.9402390438247012, 'examples_seen': 190304, 'step': 6900, 'algorithm': 'activity_selector'}
I1012 19:07:20.535013 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.940, val scores are: activity_selector: 0.940
I1012 19:07:21.598449 124643143087616 run.py:734] Algo activity_selector step 6950 current loss 0.730872, current_train_items 191680.
I1012 19:07:21.731817 124643143087616 run.py:769] (val) algo activity_selector step 6950: {'selected': 0.968, 'score': 0.968, 'examples_seen': 191680, 'step': 6950, 'algorithm': 'activity_selector'}
I1012 19:07:21.732042 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.968, val scores are: activity_selector: 0.968
I1012 19:07:22.790109 124643143087616 run.py:734] Algo activity_selector step 7000 current loss 0.904003, current_train_items 193072.
I1012 19:07:22.921221 124643143087616 run.py:769] (val) algo activity_selector step 7000: {'selected': 0.9603174603174603, 'score': 0.9603174603174603, 'examples_seen': 193072, 'step': 7000, 'algorithm': 'activity_selector'}
I1012 19:07:22.921382 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.960, val scores are: activity_selector: 0.960
I1012 19:07:23.974545 124643143087616 run.py:734] Algo activity_selector step 7050 current loss 0.724240, current_train_items 194448.
I1012 19:07:24.105980 124643143087616 run.py:769] (val) algo activity_selector step 7050: {'selected': 0.8893203883495144, 'score': 0.8893203883495144, 'examples_seen': 194448, 'step': 7050, 'algorithm': 'activity_selector'}
I1012 19:07:24.106203 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.889, val scores are: activity_selector: 0.889
I1012 19:07:25.156413 124643143087616 run.py:734] Algo activity_selector step 7100 current loss 0.637018, current_train_items 195824.
I1012 19:07:25.287902 124643143087616 run.py:769] (val) algo activity_selector step 7100: {'selected': 0.9380863039399626, 'score': 0.9380863039399626, 'examples_seen': 195824, 'step': 7100, 'algorithm': 'activity_selector'}
I1012 19:07:25.288077 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.938, val scores are: activity_selector: 0.938
I1012 19:07:26.346702 124643143087616 run.py:734] Algo activity_selector step 7150 current loss 0.833536, current_train_items 197200.
I1012 19:07:26.477542 124643143087616 run.py:769] (val) algo activity_selector step 7150: {'selected': 0.9398496240601504, 'score': 0.9398496240601504, 'examples_seen': 197200, 'step': 7150, 'algorithm': 'activity_selector'}
I1012 19:07:26.477699 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.940, val scores are: activity_selector: 0.940
I1012 19:07:27.532748 124643143087616 run.py:734] Algo activity_selector step 7200 current loss 0.615115, current_train_items 198576.
I1012 19:07:27.665013 124643143087616 run.py:769] (val) algo activity_selector step 7200: {'selected': 0.9659318637274549, 'score': 0.9659318637274549, 'examples_seen': 198576, 'step': 7200, 'algorithm': 'activity_selector'}
I1012 19:07:27.665243 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.966, val scores are: activity_selector: 0.966
I1012 19:07:28.725890 124643143087616 run.py:734] Algo activity_selector step 7250 current loss 0.832632, current_train_items 199952.
I1012 19:07:28.861138 124643143087616 run.py:769] (val) algo activity_selector step 7250: {'selected': 0.9679999999999999, 'score': 0.9679999999999999, 'examples_seen': 199952, 'step': 7250, 'algorithm': 'activity_selector'}
I1012 19:07:28.861364 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.968, val scores are: activity_selector: 0.968
I1012 19:07:29.927180 124643143087616 run.py:734] Algo activity_selector step 7300 current loss 0.715228, current_train_items 201344.
I1012 19:07:30.053618 124643143087616 run.py:769] (val) algo activity_selector step 7300: {'selected': 0.9280303030303031, 'score': 0.9280303030303031, 'examples_seen': 201344, 'step': 7300, 'algorithm': 'activity_selector'}
I1012 19:07:30.053856 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.928, val scores are: activity_selector: 0.928
I1012 19:07:31.112021 124643143087616 run.py:734] Algo activity_selector step 7350 current loss 0.841720, current_train_items 202720.
I1012 19:07:31.258187 124643143087616 run.py:769] (val) algo activity_selector step 7350: {'selected': 0.9336099585062241, 'score': 0.9336099585062241, 'examples_seen': 202720, 'step': 7350, 'algorithm': 'activity_selector'}
I1012 19:07:31.258407 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.934, val scores are: activity_selector: 0.934
I1012 19:07:32.303714 124643143087616 run.py:734] Algo activity_selector step 7400 current loss 0.759609, current_train_items 204080.
I1012 19:07:32.450807 124643143087616 run.py:769] (val) algo activity_selector step 7400: {'selected': 0.9496124031007752, 'score': 0.9496124031007752, 'examples_seen': 204080, 'step': 7400, 'algorithm': 'activity_selector'}
I1012 19:07:32.451028 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1012 19:07:33.509268 124643143087616 run.py:734] Algo activity_selector step 7450 current loss 0.825341, current_train_items 205488.
I1012 19:07:33.640857 124643143087616 run.py:769] (val) algo activity_selector step 7450: {'selected': 0.9481481481481482, 'score': 0.9481481481481482, 'examples_seen': 205488, 'step': 7450, 'algorithm': 'activity_selector'}
I1012 19:07:33.641080 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1012 19:07:34.708657 124643143087616 run.py:734] Algo activity_selector step 7500 current loss 0.719139, current_train_items 206848.
I1012 19:07:34.840671 124643143087616 run.py:769] (val) algo activity_selector step 7500: {'selected': 0.9588014981273407, 'score': 0.9588014981273407, 'examples_seen': 206848, 'step': 7500, 'algorithm': 'activity_selector'}
I1012 19:07:34.840908 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.959, val scores are: activity_selector: 0.959
I1012 19:07:35.900079 124643143087616 run.py:734] Algo activity_selector step 7550 current loss 0.702195, current_train_items 208224.
I1012 19:07:36.032631 124643143087616 run.py:769] (val) algo activity_selector step 7550: {'selected': 0.8995983935742973, 'score': 0.8995983935742973, 'examples_seen': 208224, 'step': 7550, 'algorithm': 'activity_selector'}
I1012 19:07:36.032914 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.900, val scores are: activity_selector: 0.900
I1012 19:07:37.096078 124643143087616 run.py:734] Algo activity_selector step 7600 current loss 0.924276, current_train_items 209616.
I1012 19:07:37.228369 124643143087616 run.py:769] (val) algo activity_selector step 7600: {'selected': 0.9661654135338347, 'score': 0.9661654135338347, 'examples_seen': 209616, 'step': 7600, 'algorithm': 'activity_selector'}
I1012 19:07:37.228593 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.966, val scores are: activity_selector: 0.966
I1012 19:07:38.295888 124643143087616 run.py:734] Algo activity_selector step 7650 current loss 1.065657, current_train_items 210976.
I1012 19:07:38.429010 124643143087616 run.py:769] (val) algo activity_selector step 7650: {'selected': 0.9303201506591338, 'score': 0.9303201506591338, 'examples_seen': 210976, 'step': 7650, 'algorithm': 'activity_selector'}
I1012 19:07:38.429237 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.930, val scores are: activity_selector: 0.930
I1012 19:07:39.486069 124643143087616 run.py:734] Algo activity_selector step 7700 current loss 0.772596, current_train_items 212368.
I1012 19:07:39.619711 124643143087616 run.py:769] (val) algo activity_selector step 7700: {'selected': 0.9397590361445783, 'score': 0.9397590361445783, 'examples_seen': 212368, 'step': 7700, 'algorithm': 'activity_selector'}
I1012 19:07:39.619945 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.940, val scores are: activity_selector: 0.940
I1012 19:07:40.676895 124643143087616 run.py:734] Algo activity_selector step 7750 current loss 0.828175, current_train_items 213744.
I1012 19:07:40.811715 124643143087616 run.py:769] (val) algo activity_selector step 7750: {'selected': 0.9651162790697675, 'score': 0.9651162790697675, 'examples_seen': 213744, 'step': 7750, 'algorithm': 'activity_selector'}
I1012 19:07:40.811958 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.965, val scores are: activity_selector: 0.965
I1012 19:07:41.882610 124643143087616 run.py:734] Algo activity_selector step 7800 current loss 0.790655, current_train_items 215136.
I1012 19:07:42.017787 124643143087616 run.py:769] (val) algo activity_selector step 7800: {'selected': 0.911487758945386, 'score': 0.911487758945386, 'examples_seen': 215136, 'step': 7800, 'algorithm': 'activity_selector'}
I1012 19:07:42.018016 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.911, val scores are: activity_selector: 0.911
I1012 19:07:43.088475 124643143087616 run.py:734] Algo activity_selector step 7850 current loss 0.581303, current_train_items 216496.
I1012 19:07:43.212884 124643143087616 run.py:769] (val) algo activity_selector step 7850: {'selected': 0.9444444444444445, 'score': 0.9444444444444445, 'examples_seen': 216496, 'step': 7850, 'algorithm': 'activity_selector'}
I1012 19:07:43.213109 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.944, val scores are: activity_selector: 0.944
I1012 19:07:44.269603 124643143087616 run.py:734] Algo activity_selector step 7900 current loss 0.563460, current_train_items 217888.
I1012 19:07:44.404281 124643143087616 run.py:769] (val) algo activity_selector step 7900: {'selected': 0.9541284403669725, 'score': 0.9541284403669725, 'examples_seen': 217888, 'step': 7900, 'algorithm': 'activity_selector'}
I1012 19:07:44.404524 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.954, val scores are: activity_selector: 0.954
I1012 19:07:45.458024 124643143087616 run.py:734] Algo activity_selector step 7950 current loss 0.647642, current_train_items 219264.
I1012 19:07:45.607213 124643143087616 run.py:769] (val) algo activity_selector step 7950: {'selected': 0.9083969465648857, 'score': 0.9083969465648857, 'examples_seen': 219264, 'step': 7950, 'algorithm': 'activity_selector'}
I1012 19:07:45.607454 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.908, val scores are: activity_selector: 0.908
I1012 19:07:46.653695 124643143087616 run.py:734] Algo activity_selector step 8000 current loss 0.590015, current_train_items 220624.
I1012 19:07:46.802145 124643143087616 run.py:769] (val) algo activity_selector step 8000: {'selected': 0.9563492063492063, 'score': 0.9563492063492063, 'examples_seen': 220624, 'step': 8000, 'algorithm': 'activity_selector'}
I1012 19:07:46.802369 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.977, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1012 19:07:47.902053 124643143087616 run.py:734] Algo activity_selector step 8050 current loss 0.713418, current_train_items 222032.
I1012 19:07:48.041028 124643143087616 run.py:769] (val) algo activity_selector step 8050: {'selected': 0.92578125, 'score': 0.92578125, 'examples_seen': 222032, 'step': 8050, 'algorithm': 'activity_selector'}
I1012 19:07:48.041254 124643143087616 run.py:790] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.926, val scores are: activity_selector: 0.926
I1012 19:07:49.161596 124643143087616 run.py:734] Algo activity_selector step 8100 current loss 0.818313, current_train_items 223392.
I1012 19:07:49.295249 124643143087616 run.py:769] (val) algo activity_selector step 8100: {'selected': 0.9461538461538462, 'score': 0.9461538461538462, 'examples_seen': 223392, 'step': 8100, 'algorithm': 'activity_selector'}
I1012 19:07:49.295475 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.926, current avg val score is 0.946, val scores are: activity_selector: 0.946
I1012 19:07:50.406639 124643143087616 run.py:734] Algo activity_selector step 8150 current loss 0.737759, current_train_items 224784.
I1012 19:07:50.541478 124643143087616 run.py:769] (val) algo activity_selector step 8150: {'selected': 0.9457364341085271, 'score': 0.9457364341085271, 'examples_seen': 224784, 'step': 8150, 'algorithm': 'activity_selector'}
I1012 19:07:50.541726 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.946, current avg val score is 0.946, val scores are: activity_selector: 0.946
I1012 19:07:51.607564 124643143087616 run.py:734] Algo activity_selector step 8200 current loss 0.715354, current_train_items 226160.
I1012 19:07:51.736600 124643143087616 run.py:769] (val) algo activity_selector step 8200: {'selected': 0.9584905660377357, 'score': 0.9584905660377357, 'examples_seen': 226160, 'step': 8200, 'algorithm': 'activity_selector'}
I1012 19:07:51.736893 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.946, current avg val score is 0.958, val scores are: activity_selector: 0.958
I1012 19:07:52.845342 124643143087616 run.py:734] Algo activity_selector step 8250 current loss 0.791976, current_train_items 227520.
I1012 19:07:52.993554 124643143087616 run.py:769] (val) algo activity_selector step 8250: {'selected': 0.9506903353057198, 'score': 0.9506903353057198, 'examples_seen': 227520, 'step': 8250, 'algorithm': 'activity_selector'}
I1012 19:07:52.993793 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.958, current avg val score is 0.951, val scores are: activity_selector: 0.951
I1012 19:07:54.051435 124643143087616 run.py:734] Algo activity_selector step 8300 current loss 0.894564, current_train_items 228912.
I1012 19:07:54.185227 124643143087616 run.py:769] (val) algo activity_selector step 8300: {'selected': 0.9296875, 'score': 0.9296875, 'examples_seen': 228912, 'step': 8300, 'algorithm': 'activity_selector'}
I1012 19:07:54.185450 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.958, current avg val score is 0.930, val scores are: activity_selector: 0.930
I1012 19:07:55.228471 124643143087616 run.py:734] Algo activity_selector step 8350 current loss 0.578926, current_train_items 230288.
I1012 19:07:55.375236 124643143087616 run.py:769] (val) algo activity_selector step 8350: {'selected': 0.9640831758034027, 'score': 0.9640831758034027, 'examples_seen': 230288, 'step': 8350, 'algorithm': 'activity_selector'}
I1012 19:07:55.375483 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.958, current avg val score is 0.964, val scores are: activity_selector: 0.964
I1012 19:07:56.497441 124643143087616 run.py:734] Algo activity_selector step 8400 current loss 0.635629, current_train_items 231680.
I1012 19:07:56.630707 124643143087616 run.py:769] (val) algo activity_selector step 8400: {'selected': 0.9395711500974658, 'score': 0.9395711500974658, 'examples_seen': 231680, 'step': 8400, 'algorithm': 'activity_selector'}
I1012 19:07:56.630986 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.964, current avg val score is 0.940, val scores are: activity_selector: 0.940
I1012 19:07:57.694272 124643143087616 run.py:734] Algo activity_selector step 8450 current loss 0.675347, current_train_items 233040.
I1012 19:07:57.828599 124643143087616 run.py:769] (val) algo activity_selector step 8450: {'selected': 0.9124767225325884, 'score': 0.9124767225325884, 'examples_seen': 233040, 'step': 8450, 'algorithm': 'activity_selector'}
I1012 19:07:57.828842 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.964, current avg val score is 0.912, val scores are: activity_selector: 0.912
I1012 19:07:58.886136 124643143087616 run.py:734] Algo activity_selector step 8500 current loss 0.753806, current_train_items 234432.
I1012 19:07:59.020600 124643143087616 run.py:769] (val) algo activity_selector step 8500: {'selected': 0.9444444444444444, 'score': 0.9444444444444444, 'examples_seen': 234432, 'step': 8500, 'algorithm': 'activity_selector'}
I1012 19:07:59.020838 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.964, current avg val score is 0.944, val scores are: activity_selector: 0.944
I1012 19:08:00.089902 124643143087616 run.py:734] Algo activity_selector step 8550 current loss 0.926367, current_train_items 235808.
I1012 19:08:00.224415 124643143087616 run.py:769] (val) algo activity_selector step 8550: {'selected': 0.9561904761904763, 'score': 0.9561904761904763, 'examples_seen': 235808, 'step': 8550, 'algorithm': 'activity_selector'}
I1012 19:08:00.224639 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.964, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1012 19:08:01.283781 124643143087616 run.py:734] Algo activity_selector step 8600 current loss 0.637733, current_train_items 237168.
I1012 19:08:01.415615 124643143087616 run.py:769] (val) algo activity_selector step 8600: {'selected': 0.9609375, 'score': 0.9609375, 'examples_seen': 237168, 'step': 8600, 'algorithm': 'activity_selector'}
I1012 19:08:01.415856 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.964, current avg val score is 0.961, val scores are: activity_selector: 0.961
I1012 19:08:02.477093 124643143087616 run.py:734] Algo activity_selector step 8650 current loss 0.610627, current_train_items 238576.
I1012 19:08:02.611683 124643143087616 run.py:769] (val) algo activity_selector step 8650: {'selected': 0.9390962671905698, 'score': 0.9390962671905698, 'examples_seen': 238576, 'step': 8650, 'algorithm': 'activity_selector'}
I1012 19:08:02.611929 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.964, current avg val score is 0.939, val scores are: activity_selector: 0.939
I1012 19:08:03.678941 124643143087616 run.py:734] Algo activity_selector step 8700 current loss 0.758713, current_train_items 239936.
I1012 19:08:03.813455 124643143087616 run.py:769] (val) algo activity_selector step 8700: {'selected': 0.9548872180451128, 'score': 0.9548872180451128, 'examples_seen': 239936, 'step': 8700, 'algorithm': 'activity_selector'}
I1012 19:08:03.813677 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.964, current avg val score is 0.955, val scores are: activity_selector: 0.955
I1012 19:08:04.858065 124643143087616 run.py:734] Algo activity_selector step 8750 current loss 0.922989, current_train_items 241328.
I1012 19:08:05.005135 124643143087616 run.py:769] (val) algo activity_selector step 8750: {'selected': 0.9487179487179486, 'score': 0.9487179487179486, 'examples_seen': 241328, 'step': 8750, 'algorithm': 'activity_selector'}
I1012 19:08:05.005293 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.964, current avg val score is 0.949, val scores are: activity_selector: 0.949
I1012 19:08:06.052699 124643143087616 run.py:734] Algo activity_selector step 8800 current loss 0.694752, current_train_items 242704.
I1012 19:08:06.187080 124643143087616 run.py:769] (val) algo activity_selector step 8800: {'selected': 0.906764168190128, 'score': 0.906764168190128, 'examples_seen': 242704, 'step': 8800, 'algorithm': 'activity_selector'}
I1012 19:08:06.187302 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.964, current avg val score is 0.907, val scores are: activity_selector: 0.907
I1012 19:08:07.245943 124643143087616 run.py:734] Algo activity_selector step 8850 current loss 0.648347, current_train_items 244080.
I1012 19:08:07.394537 124643143087616 run.py:769] (val) algo activity_selector step 8850: {'selected': 0.928, 'score': 0.928, 'examples_seen': 244080, 'step': 8850, 'algorithm': 'activity_selector'}
I1012 19:08:07.394779 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.964, current avg val score is 0.928, val scores are: activity_selector: 0.928
I1012 19:08:08.460705 124643143087616 run.py:734] Algo activity_selector step 8900 current loss 0.656551, current_train_items 245456.
I1012 19:08:08.592801 124643143087616 run.py:769] (val) algo activity_selector step 8900: {'selected': 0.9525691699604742, 'score': 0.9525691699604742, 'examples_seen': 245456, 'step': 8900, 'algorithm': 'activity_selector'}
I1012 19:08:08.593024 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.964, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1012 19:08:09.651363 124643143087616 run.py:734] Algo activity_selector step 8950 current loss 0.723911, current_train_items 246832.
I1012 19:08:09.785486 124643143087616 run.py:769] (val) algo activity_selector step 8950: {'selected': 0.9242424242424242, 'score': 0.9242424242424242, 'examples_seen': 246832, 'step': 8950, 'algorithm': 'activity_selector'}
I1012 19:08:09.785707 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.964, current avg val score is 0.924, val scores are: activity_selector: 0.924
I1012 19:08:10.854228 124643143087616 run.py:734] Algo activity_selector step 9000 current loss 0.715345, current_train_items 248224.
I1012 19:08:10.988919 124643143087616 run.py:769] (val) algo activity_selector step 9000: {'selected': 0.9010989010989011, 'score': 0.9010989010989011, 'examples_seen': 248224, 'step': 9000, 'algorithm': 'activity_selector'}
I1012 19:08:10.989170 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.964, current avg val score is 0.901, val scores are: activity_selector: 0.901
I1012 19:08:12.034907 124643143087616 run.py:734] Algo activity_selector step 9050 current loss 0.826910, current_train_items 249584.
I1012 19:08:12.182044 124643143087616 run.py:769] (val) algo activity_selector step 9050: {'selected': 0.9655172413793104, 'score': 0.9655172413793104, 'examples_seen': 249584, 'step': 9050, 'algorithm': 'activity_selector'}
I1012 19:08:12.182343 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.964, current avg val score is 0.966, val scores are: activity_selector: 0.966
I1012 19:08:13.292335 124643143087616 run.py:734] Algo activity_selector step 9100 current loss 0.858544, current_train_items 250976.
I1012 19:08:13.424483 124643143087616 run.py:769] (val) algo activity_selector step 9100: {'selected': 0.9730769230769232, 'score': 0.9730769230769232, 'examples_seen': 250976, 'step': 9100, 'algorithm': 'activity_selector'}
I1012 19:08:13.424659 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.966, current avg val score is 0.973, val scores are: activity_selector: 0.973
I1012 19:08:14.542777 124643143087616 run.py:734] Algo activity_selector step 9150 current loss 0.641238, current_train_items 252352.
I1012 19:08:14.674512 124643143087616 run.py:769] (val) algo activity_selector step 9150: {'selected': 0.9527410207939507, 'score': 0.9527410207939507, 'examples_seen': 252352, 'step': 9150, 'algorithm': 'activity_selector'}
I1012 19:08:14.674662 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1012 19:08:15.723552 124643143087616 run.py:734] Algo activity_selector step 9200 current loss 0.791426, current_train_items 253728.
I1012 19:08:15.852705 124643143087616 run.py:769] (val) algo activity_selector step 9200: {'selected': 0.9642184557438794, 'score': 0.9642184557438794, 'examples_seen': 253728, 'step': 9200, 'algorithm': 'activity_selector'}
I1012 19:08:15.852859 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.964, val scores are: activity_selector: 0.964
I1012 19:08:16.907672 124643143087616 run.py:734] Algo activity_selector step 9250 current loss 0.709509, current_train_items 255120.
I1012 19:08:17.041838 124643143087616 run.py:769] (val) algo activity_selector step 9250: {'selected': 0.9431818181818182, 'score': 0.9431818181818182, 'examples_seen': 255120, 'step': 9250, 'algorithm': 'activity_selector'}
I1012 19:08:17.042063 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1012 19:08:18.099796 124643143087616 run.py:734] Algo activity_selector step 9300 current loss 0.657080, current_train_items 256480.
I1012 19:08:18.248178 124643143087616 run.py:769] (val) algo activity_selector step 9300: {'selected': 0.937269372693727, 'score': 0.937269372693727, 'examples_seen': 256480, 'step': 9300, 'algorithm': 'activity_selector'}
I1012 19:08:18.248400 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.937, val scores are: activity_selector: 0.937
I1012 19:08:19.307906 124643143087616 run.py:734] Algo activity_selector step 9350 current loss 0.743045, current_train_items 257856.
I1012 19:08:19.438879 124643143087616 run.py:769] (val) algo activity_selector step 9350: {'selected': 0.9666666666666668, 'score': 0.9666666666666668, 'examples_seen': 257856, 'step': 9350, 'algorithm': 'activity_selector'}
I1012 19:08:19.439100 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.967, val scores are: activity_selector: 0.967
I1012 19:08:20.482578 124643143087616 run.py:734] Algo activity_selector step 9400 current loss 0.672617, current_train_items 259248.
I1012 19:08:20.633774 124643143087616 run.py:769] (val) algo activity_selector step 9400: {'selected': 0.9190207156308852, 'score': 0.9190207156308852, 'examples_seen': 259248, 'step': 9400, 'algorithm': 'activity_selector'}
I1012 19:08:20.634000 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.919, val scores are: activity_selector: 0.919
I1012 19:08:21.702188 124643143087616 run.py:734] Algo activity_selector step 9450 current loss 0.595362, current_train_items 260624.
I1012 19:08:21.835951 124643143087616 run.py:769] (val) algo activity_selector step 9450: {'selected': 0.9518072289156628, 'score': 0.9518072289156628, 'examples_seen': 260624, 'step': 9450, 'algorithm': 'activity_selector'}
I1012 19:08:21.836180 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.952, val scores are: activity_selector: 0.952
I1012 19:08:22.894785 124643143087616 run.py:734] Algo activity_selector step 9500 current loss 0.812550, current_train_items 262000.
I1012 19:08:23.030774 124643143087616 run.py:769] (val) algo activity_selector step 9500: {'selected': 0.9315589353612167, 'score': 0.9315589353612167, 'examples_seen': 262000, 'step': 9500, 'algorithm': 'activity_selector'}
I1012 19:08:23.030998 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.932, val scores are: activity_selector: 0.932
I1012 19:08:24.089187 124643143087616 run.py:734] Algo activity_selector step 9550 current loss 0.468649, current_train_items 263392.
I1012 19:08:24.224695 124643143087616 run.py:769] (val) algo activity_selector step 9550: {'selected': 0.9423459244532804, 'score': 0.9423459244532804, 'examples_seen': 263392, 'step': 9550, 'algorithm': 'activity_selector'}
I1012 19:08:24.224932 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1012 19:08:25.279561 124643143087616 run.py:734] Algo activity_selector step 9600 current loss 0.958887, current_train_items 264768.
I1012 19:08:25.424162 124643143087616 run.py:769] (val) algo activity_selector step 9600: {'selected': 0.9502982107355865, 'score': 0.9502982107355865, 'examples_seen': 264768, 'step': 9600, 'algorithm': 'activity_selector'}
I1012 19:08:25.424310 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1012 19:08:26.475132 124643143087616 run.py:734] Algo activity_selector step 9650 current loss 0.753888, current_train_items 266128.
I1012 19:08:26.602489 124643143087616 run.py:769] (val) algo activity_selector step 9650: {'selected': 0.9305816135084428, 'score': 0.9305816135084428, 'examples_seen': 266128, 'step': 9650, 'algorithm': 'activity_selector'}
I1012 19:08:26.602638 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1012 19:08:27.635173 124643143087616 run.py:734] Algo activity_selector step 9700 current loss 0.616758, current_train_items 267520.
I1012 19:08:27.781901 124643143087616 run.py:769] (val) algo activity_selector step 9700: {'selected': 0.9581749049429659, 'score': 0.9581749049429659, 'examples_seen': 267520, 'step': 9700, 'algorithm': 'activity_selector'}
I1012 19:08:27.782126 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.958, val scores are: activity_selector: 0.958
I1012 19:08:28.843452 124643143087616 run.py:734] Algo activity_selector step 9750 current loss 0.706471, current_train_items 268896.
I1012 19:08:28.974840 124643143087616 run.py:769] (val) algo activity_selector step 9750: {'selected': 0.9549902152641878, 'score': 0.9549902152641878, 'examples_seen': 268896, 'step': 9750, 'algorithm': 'activity_selector'}
I1012 19:08:28.975065 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.955, val scores are: activity_selector: 0.955
I1012 19:08:30.033613 124643143087616 run.py:734] Algo activity_selector step 9800 current loss 0.744991, current_train_items 270272.
I1012 19:08:30.166409 124643143087616 run.py:769] (val) algo activity_selector step 9800: {'selected': 0.9529411764705883, 'score': 0.9529411764705883, 'examples_seen': 270272, 'step': 9800, 'algorithm': 'activity_selector'}
I1012 19:08:30.166674 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1012 19:08:31.224753 124643143087616 run.py:734] Algo activity_selector step 9850 current loss 0.770870, current_train_items 271664.
I1012 19:08:31.358398 124643143087616 run.py:769] (val) algo activity_selector step 9850: {'selected': 0.96309963099631, 'score': 0.96309963099631, 'examples_seen': 271664, 'step': 9850, 'algorithm': 'activity_selector'}
I1012 19:08:31.358641 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.973, current avg val score is 0.963, val scores are: activity_selector: 0.963
I1012 19:08:32.427106 124643143087616 run.py:734] Algo activity_selector step 9900 current loss 0.792298, current_train_items 273040.
I1012 19:08:32.559423 124643143087616 run.py:769] (val) algo activity_selector step 9900: {'selected': 0.984, 'score': 0.984, 'examples_seen': 273040, 'step': 9900, 'algorithm': 'activity_selector'}
I1012 19:08:32.559598 124643143087616 run.py:790] Checkpointing best model, best avg val score was 0.973, current avg val score is 0.984, val scores are: activity_selector: 0.984
I1012 19:08:33.665358 124643143087616 run.py:734] Algo activity_selector step 9950 current loss 0.501355, current_train_items 274400.
I1012 19:08:33.811722 124643143087616 run.py:769] (val) algo activity_selector step 9950: {'selected': 0.9729729729729729, 'score': 0.9729729729729729, 'examples_seen': 274400, 'step': 9950, 'algorithm': 'activity_selector'}
I1012 19:08:33.811961 124643143087616 run.py:793] Not saving new best model, best avg val score was 0.984, current avg val score is 0.973, val scores are: activity_selector: 0.973
I1012 19:08:34.838376 124643143087616 run.py:799] Restoring best model from checkpoint...
I1012 19:08:46.108507 124643143087616 run.py:814] (test) algo activity_selector : {'selected': 0.9057301293900185, 'score': 0.9057301293900185, 'examples_seen': 275760, 'step': 10000, 'algorithm': 'activity_selector'}
I1012 19:08:46.108656 124643143087616 run.py:816] Done!
