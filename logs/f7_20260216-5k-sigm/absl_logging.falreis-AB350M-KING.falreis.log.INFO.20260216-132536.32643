I0216 13:25:38.942135 124543013864960 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0216 13:25:38.942866 124543013864960 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0216 13:25:39.186949 124543013864960 run.py:443] Model: f7 ['find_maximum_subarray_kadane']
I0216 13:25:39.187062 124543013864960 run.py:445] algorithms ['find_maximum_subarray_kadane']
I0216 13:25:39.187234 124543013864960 run.py:446] train_lengths ['4', '7', '11', '13', '16']
I0216 13:25:39.187271 124543013864960 run.py:447] train_batch_size 16
I0216 13:25:39.187365 124543013864960 run.py:448] val_batch_size 16
I0216 13:25:39.187397 124543013864960 run.py:449] test_batch_size 16
I0216 13:25:39.187426 124543013864960 run.py:450] chunked_training True
I0216 13:25:39.187544 124543013864960 run.py:451] chunk_length 16
I0216 13:25:39.187575 124543013864960 run.py:452] train_steps 5001
I0216 13:25:39.187604 124543013864960 run.py:453] eval_every 50
I0216 13:25:39.187632 124543013864960 run.py:454] test_every 500
I0216 13:25:39.187663 124543013864960 run.py:455] hidden_size 256
I0216 13:25:39.187692 124543013864960 run.py:456] nb_msg_passing_steps 1
I0216 13:25:39.187720 124543013864960 run.py:457] learning_rate 0.001
I0216 13:25:39.187805 124543013864960 run.py:458] grad_clip_max_norm 1.0
I0216 13:25:39.187837 124543013864960 run.py:459] dropout_prob 0.0
I0216 13:25:39.187867 124543013864960 run.py:460] hint_teacher_forcing 0.0
I0216 13:25:39.187900 124543013864960 run.py:461] hint_mode encoded_decoded
I0216 13:25:39.188013 124543013864960 run.py:462] hint_repred_mode soft
I0216 13:25:39.188044 124543013864960 run.py:463] use_ln True
I0216 13:25:39.188073 124543013864960 run.py:464] use_lstm True
I0216 13:25:39.188100 124543013864960 run.py:465] nb_triplet_fts 16
I0216 13:25:39.188128 124543013864960 run.py:466] encoder_init xavier_on_scalars
I0216 13:25:39.188156 124543013864960 run.py:467] processor_type f7
I0216 13:25:39.188185 124543013864960 run.py:468] checkpoint_path CLRS30
I0216 13:25:39.188216 124543013864960 run.py:469] dataset_path CLRS30
I0216 13:25:39.188246 124543013864960 run.py:470] freeze_processor False
I0216 13:25:39.188274 124543013864960 run.py:471] reduction min
I0216 13:25:39.188302 124543013864960 run.py:472] activation elu
I0216 13:25:39.188329 124543013864960 run.py:473] restore_model 
I0216 13:25:39.188356 124543013864960 run.py:474] gated True
I0216 13:25:39.188386 124543013864960 run.py:475] gated_activation sigmoid
I0216 13:25:39.188414 124543013864960 run.py:476] memory_type None
I0216 13:25:39.188499 124543013864960 run.py:477] memory_size None
I0216 13:25:39.191179 124543013864960 run.py:503] Creating samplers for algo find_maximum_subarray_kadane
W0216 13:25:39.191355 124543013864960 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.MaxSubarraySampler'>
W0216 13:25:39.191612 124543013864960 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0216 13:25:39.479209 124543013864960 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.MaxSubarraySampler'>
W0216 13:25:39.814451 124543013864960 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.MaxSubarraySampler'>
W0216 13:25:40.220838 124543013864960 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.MaxSubarraySampler'>
W0216 13:25:40.671494 124543013864960 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.MaxSubarraySampler'>
W0216 13:25:41.176334 124543013864960 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.MaxSubarraySampler'>
I0216 13:25:41.176596 124543013864960 samplers.py:124] Creating a dataset with 2048 samples.
I0216 13:25:41.688472 124543013864960 samplers.py:144] 1000 samples created
I0216 13:25:42.200994 124543013864960 samplers.py:144] 2000 samples created
I0216 13:25:42.289728 124543013864960 run.py:287] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0216 13:25:42.290512 124543013864960 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/find_maximum_subarray_kadane_test/1.0.0
I0216 13:25:42.294332 124543013864960 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/find_maximum_subarray_kadane_test/1.0.0
I0216 13:25:42.297572 124543013864960 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/find_maximum_subarray_kadane_test/1.0.0.
I0216 13:25:42.350653 124543013864960 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/find_maximum_subarray_kadane_test/1.0.0
W0216 13:25:42.371861 124543013864960 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x7144e98be020> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0216 13:26:18.017535 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 0 current loss 17.092537, current_train_items 32.
I0216 13:26:28.791402 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 0: {'start': 0.10302734375, 'end': 0.13037109375, 'score': 0.11669921875, 'examples_seen': 32, 'step': 0, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:26:28.791664 124543013864960 run.py:785] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.117, val scores are: find_maximum_subarray_kadane: 0.117
I0216 13:27:27.903512 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 50 current loss 6.904307, current_train_items 1632.
I0216 13:27:28.886067 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 50: {'start': 0.5751953125, 'end': 0.48974609375, 'score': 0.532470703125, 'examples_seen': 1632, 'step': 50, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:27:28.886324 124543013864960 run.py:785] Checkpointing best model, best avg val score was 0.117, current avg val score is 0.532, val scores are: find_maximum_subarray_kadane: 0.532
I0216 13:27:30.203666 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 100 current loss 5.476379, current_train_items 3216.
I0216 13:27:31.179097 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 100: {'start': 0.67724609375, 'end': 0.482421875, 'score': 0.579833984375, 'examples_seen': 3216, 'step': 100, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:27:31.179337 124543013864960 run.py:785] Checkpointing best model, best avg val score was 0.532, current avg val score is 0.580, val scores are: find_maximum_subarray_kadane: 0.580
I0216 13:27:32.518434 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 150 current loss 7.581354, current_train_items 4832.
I0216 13:27:33.503090 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 150: {'start': 0.79296875, 'end': 0.59912109375, 'score': 0.696044921875, 'examples_seen': 4832, 'step': 150, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:27:33.503332 124543013864960 run.py:785] Checkpointing best model, best avg val score was 0.580, current avg val score is 0.696, val scores are: find_maximum_subarray_kadane: 0.696
I0216 13:27:34.821765 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 200 current loss 5.884520, current_train_items 6416.
I0216 13:27:35.798031 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 200: {'start': 0.771484375, 'end': 0.646484375, 'score': 0.708984375, 'examples_seen': 6416, 'step': 200, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:27:35.798215 124543013864960 run.py:785] Checkpointing best model, best avg val score was 0.696, current avg val score is 0.709, val scores are: find_maximum_subarray_kadane: 0.709
I0216 13:27:37.131055 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 250 current loss 5.318950, current_train_items 8000.
I0216 13:27:38.112982 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 250: {'start': 0.80517578125, 'end': 0.6259765625, 'score': 0.715576171875, 'examples_seen': 8000, 'step': 250, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:27:38.113231 124543013864960 run.py:785] Checkpointing best model, best avg val score was 0.709, current avg val score is 0.716, val scores are: find_maximum_subarray_kadane: 0.716
I0216 13:27:39.423695 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 300 current loss 5.238921, current_train_items 9600.
I0216 13:27:40.399147 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 300: {'start': 0.7783203125, 'end': 0.7001953125, 'score': 0.7392578125, 'examples_seen': 9600, 'step': 300, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:27:40.399383 124543013864960 run.py:785] Checkpointing best model, best avg val score was 0.716, current avg val score is 0.739, val scores are: find_maximum_subarray_kadane: 0.739
I0216 13:27:41.725927 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 350 current loss 4.948451, current_train_items 11200.
I0216 13:27:42.724721 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 350: {'start': 0.81201171875, 'end': 0.703125, 'score': 0.757568359375, 'examples_seen': 11200, 'step': 350, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:27:42.724957 124543013864960 run.py:785] Checkpointing best model, best avg val score was 0.739, current avg val score is 0.758, val scores are: find_maximum_subarray_kadane: 0.758
I0216 13:27:44.042147 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 400 current loss 4.042416, current_train_items 12784.
I0216 13:27:45.017734 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 400: {'start': 0.853515625, 'end': 0.75634765625, 'score': 0.804931640625, 'examples_seen': 12784, 'step': 400, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:27:45.017994 124543013864960 run.py:785] Checkpointing best model, best avg val score was 0.758, current avg val score is 0.805, val scores are: find_maximum_subarray_kadane: 0.805
I0216 13:27:46.348543 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 450 current loss 4.256822, current_train_items 14400.
I0216 13:27:47.324620 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 450: {'start': 0.7978515625, 'end': 0.6650390625, 'score': 0.7314453125, 'examples_seen': 14400, 'step': 450, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:27:47.324852 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.805, current avg val score is 0.731, val scores are: find_maximum_subarray_kadane: 0.731
I0216 13:27:48.600542 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 500 current loss 5.365720, current_train_items 15984.
I0216 13:27:49.576482 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 500: {'start': 0.8193359375, 'end': 0.73388671875, 'score': 0.776611328125, 'examples_seen': 15984, 'step': 500, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:27:49.576747 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.805, current avg val score is 0.777, val scores are: find_maximum_subarray_kadane: 0.777
I0216 13:27:50.837008 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 550 current loss 5.281558, current_train_items 17584.
I0216 13:27:51.816686 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 550: {'start': 0.84912109375, 'end': 0.71240234375, 'score': 0.78076171875, 'examples_seen': 17584, 'step': 550, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:27:51.816945 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.805, current avg val score is 0.781, val scores are: find_maximum_subarray_kadane: 0.781
I0216 13:27:53.088439 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 600 current loss 6.243404, current_train_items 19168.
I0216 13:27:54.075712 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 600: {'start': 0.83251953125, 'end': 0.70458984375, 'score': 0.7685546875, 'examples_seen': 19168, 'step': 600, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:27:54.075948 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.805, current avg val score is 0.769, val scores are: find_maximum_subarray_kadane: 0.769
I0216 13:27:55.370621 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 650 current loss 4.420926, current_train_items 20768.
I0216 13:27:56.352235 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 650: {'start': 0.8359375, 'end': 0.7822265625, 'score': 0.80908203125, 'examples_seen': 20768, 'step': 650, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:27:56.352468 124543013864960 run.py:785] Checkpointing best model, best avg val score was 0.805, current avg val score is 0.809, val scores are: find_maximum_subarray_kadane: 0.809
I0216 13:27:57.674104 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 700 current loss 3.735312, current_train_items 22368.
I0216 13:27:58.663091 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 700: {'start': 0.80078125, 'end': 0.74072265625, 'score': 0.770751953125, 'examples_seen': 22368, 'step': 700, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:27:58.663328 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.809, current avg val score is 0.771, val scores are: find_maximum_subarray_kadane: 0.771
I0216 13:27:59.922299 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 750 current loss 3.172073, current_train_items 23952.
I0216 13:28:00.902196 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 750: {'start': 0.88671875, 'end': 0.81005859375, 'score': 0.848388671875, 'examples_seen': 23952, 'step': 750, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:00.902365 124543013864960 run.py:785] Checkpointing best model, best avg val score was 0.809, current avg val score is 0.848, val scores are: find_maximum_subarray_kadane: 0.848
I0216 13:28:02.223646 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 800 current loss 2.715639, current_train_items 25568.
I0216 13:28:03.201962 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 800: {'start': 0.88916015625, 'end': 0.82958984375, 'score': 0.859375, 'examples_seen': 25568, 'step': 800, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:03.202221 124543013864960 run.py:785] Checkpointing best model, best avg val score was 0.848, current avg val score is 0.859, val scores are: find_maximum_subarray_kadane: 0.859
I0216 13:28:04.521463 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 850 current loss 4.844545, current_train_items 27152.
I0216 13:28:05.500357 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 850: {'start': 0.86865234375, 'end': 0.76708984375, 'score': 0.81787109375, 'examples_seen': 27152, 'step': 850, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:05.500598 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.859, current avg val score is 0.818, val scores are: find_maximum_subarray_kadane: 0.818
I0216 13:28:06.768709 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 900 current loss 4.800513, current_train_items 28752.
I0216 13:28:07.760014 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 900: {'start': 0.81787109375, 'end': 0.72802734375, 'score': 0.77294921875, 'examples_seen': 28752, 'step': 900, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:07.760266 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.859, current avg val score is 0.773, val scores are: find_maximum_subarray_kadane: 0.773
I0216 13:28:09.028880 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 950 current loss 4.632885, current_train_items 30336.
I0216 13:28:09.998813 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 950: {'start': 0.8134765625, 'end': 0.80712890625, 'score': 0.810302734375, 'examples_seen': 30336, 'step': 950, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:09.998984 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.859, current avg val score is 0.810, val scores are: find_maximum_subarray_kadane: 0.810
I0216 13:28:11.248255 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1000 current loss 5.202714, current_train_items 31936.
I0216 13:28:12.229851 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1000: {'start': 0.845703125, 'end': 0.8515625, 'score': 0.8486328125, 'examples_seen': 31936, 'step': 1000, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:12.230020 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.859, current avg val score is 0.849, val scores are: find_maximum_subarray_kadane: 0.849
I0216 13:28:13.483396 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1050 current loss 3.465627, current_train_items 33520.
I0216 13:28:14.460335 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1050: {'start': 0.90185546875, 'end': 0.86279296875, 'score': 0.88232421875, 'examples_seen': 33520, 'step': 1050, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:14.460499 124543013864960 run.py:785] Checkpointing best model, best avg val score was 0.859, current avg val score is 0.882, val scores are: find_maximum_subarray_kadane: 0.882
I0216 13:28:15.770202 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1100 current loss 3.374435, current_train_items 35136.
I0216 13:28:16.755921 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1100: {'start': 0.83154296875, 'end': 0.81005859375, 'score': 0.82080078125, 'examples_seen': 35136, 'step': 1100, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:16.756170 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.882, current avg val score is 0.821, val scores are: find_maximum_subarray_kadane: 0.821
I0216 13:28:18.028374 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1150 current loss 2.320612, current_train_items 36736.
I0216 13:28:19.004928 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1150: {'start': 0.84619140625, 'end': 0.8359375, 'score': 0.841064453125, 'examples_seen': 36736, 'step': 1150, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:19.005176 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.882, current avg val score is 0.841, val scores are: find_maximum_subarray_kadane: 0.841
I0216 13:28:20.277142 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1200 current loss 4.495460, current_train_items 38320.
I0216 13:28:21.252971 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1200: {'start': 0.845703125, 'end': 0.83935546875, 'score': 0.842529296875, 'examples_seen': 38320, 'step': 1200, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:21.253220 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.882, current avg val score is 0.843, val scores are: find_maximum_subarray_kadane: 0.843
I0216 13:28:22.515577 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1250 current loss 4.387320, current_train_items 39920.
I0216 13:28:23.506704 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1250: {'start': 0.8955078125, 'end': 0.80419921875, 'score': 0.849853515625, 'examples_seen': 39920, 'step': 1250, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:23.506990 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.882, current avg val score is 0.850, val scores are: find_maximum_subarray_kadane: 0.850
I0216 13:28:24.772406 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1300 current loss 3.897689, current_train_items 41504.
I0216 13:28:25.968396 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1300: {'start': 0.8974609375, 'end': 0.86572265625, 'score': 0.881591796875, 'examples_seen': 41504, 'step': 1300, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:25.968634 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.882, current avg val score is 0.882, val scores are: find_maximum_subarray_kadane: 0.882
I0216 13:28:27.232233 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1350 current loss 3.910820, current_train_items 43104.
I0216 13:28:28.225255 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1350: {'start': 0.90185546875, 'end': 0.876953125, 'score': 0.889404296875, 'examples_seen': 43104, 'step': 1350, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:28.225496 124543013864960 run.py:785] Checkpointing best model, best avg val score was 0.882, current avg val score is 0.889, val scores are: find_maximum_subarray_kadane: 0.889
I0216 13:28:29.536210 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1400 current loss 3.653213, current_train_items 44688.
I0216 13:28:30.517025 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1400: {'start': 0.87451171875, 'end': 0.86474609375, 'score': 0.86962890625, 'examples_seen': 44688, 'step': 1400, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:30.517189 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.889, current avg val score is 0.870, val scores are: find_maximum_subarray_kadane: 0.870
I0216 13:28:31.768883 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1450 current loss 3.134840, current_train_items 46304.
I0216 13:28:32.751802 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1450: {'start': 0.83544921875, 'end': 0.84716796875, 'score': 0.84130859375, 'examples_seen': 46304, 'step': 1450, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:32.751966 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.889, current avg val score is 0.841, val scores are: find_maximum_subarray_kadane: 0.841
I0216 13:28:34.002911 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1500 current loss 1.896584, current_train_items 47888.
I0216 13:28:34.975599 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1500: {'start': 0.884765625, 'end': 0.85205078125, 'score': 0.868408203125, 'examples_seen': 47888, 'step': 1500, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:34.975762 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.889, current avg val score is 0.868, val scores are: find_maximum_subarray_kadane: 0.868
I0216 13:28:36.225734 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1550 current loss 4.398136, current_train_items 49488.
I0216 13:28:37.195664 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1550: {'start': 0.900390625, 'end': 0.85791015625, 'score': 0.879150390625, 'examples_seen': 49488, 'step': 1550, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:37.195826 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.889, current avg val score is 0.879, val scores are: find_maximum_subarray_kadane: 0.879
I0216 13:28:38.440972 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1600 current loss 4.656476, current_train_items 51088.
I0216 13:28:39.415447 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1600: {'start': 0.83203125, 'end': 0.76953125, 'score': 0.80078125, 'examples_seen': 51088, 'step': 1600, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:39.415734 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.889, current avg val score is 0.801, val scores are: find_maximum_subarray_kadane: 0.801
I0216 13:28:40.675196 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1650 current loss 3.525359, current_train_items 52672.
I0216 13:28:41.665279 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1650: {'start': 0.876953125, 'end': 0.87890625, 'score': 0.8779296875, 'examples_seen': 52672, 'step': 1650, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:41.665513 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.889, current avg val score is 0.878, val scores are: find_maximum_subarray_kadane: 0.878
I0216 13:28:42.912347 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1700 current loss 3.950355, current_train_items 54272.
I0216 13:28:43.898341 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1700: {'start': 0.87255859375, 'end': 0.8271484375, 'score': 0.849853515625, 'examples_seen': 54272, 'step': 1700, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:43.898575 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.889, current avg val score is 0.850, val scores are: find_maximum_subarray_kadane: 0.850
I0216 13:28:45.155940 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1750 current loss 3.121781, current_train_items 55872.
I0216 13:28:46.139009 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1750: {'start': 0.9150390625, 'end': 0.86181640625, 'score': 0.888427734375, 'examples_seen': 55872, 'step': 1750, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:46.139254 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.889, current avg val score is 0.888, val scores are: find_maximum_subarray_kadane: 0.888
I0216 13:28:47.402073 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1800 current loss 3.315987, current_train_items 57472.
I0216 13:28:48.406293 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1800: {'start': 0.86474609375, 'end': 0.8505859375, 'score': 0.857666015625, 'examples_seen': 57472, 'step': 1800, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:48.406579 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.889, current avg val score is 0.858, val scores are: find_maximum_subarray_kadane: 0.858
I0216 13:28:49.652729 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1850 current loss 1.834563, current_train_items 59056.
I0216 13:28:50.635807 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1850: {'start': 0.9013671875, 'end': 0.87939453125, 'score': 0.890380859375, 'examples_seen': 59056, 'step': 1850, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:50.636058 124543013864960 run.py:785] Checkpointing best model, best avg val score was 0.889, current avg val score is 0.890, val scores are: find_maximum_subarray_kadane: 0.890
I0216 13:28:51.949515 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1900 current loss 4.224771, current_train_items 60656.
I0216 13:28:52.923582 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1900: {'start': 0.87060546875, 'end': 0.8466796875, 'score': 0.858642578125, 'examples_seen': 60656, 'step': 1900, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:52.923819 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.890, current avg val score is 0.859, val scores are: find_maximum_subarray_kadane: 0.859
I0216 13:28:54.171430 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 1950 current loss 4.526288, current_train_items 62256.
I0216 13:28:55.151120 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 1950: {'start': 0.8974609375, 'end': 0.9013671875, 'score': 0.8994140625, 'examples_seen': 62256, 'step': 1950, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:55.151406 124543013864960 run.py:785] Checkpointing best model, best avg val score was 0.890, current avg val score is 0.899, val scores are: find_maximum_subarray_kadane: 0.899
I0216 13:28:56.472381 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2000 current loss 4.005222, current_train_items 63840.
I0216 13:28:57.460511 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2000: {'start': 0.87548828125, 'end': 0.82080078125, 'score': 0.84814453125, 'examples_seen': 63840, 'step': 2000, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:57.460747 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.899, current avg val score is 0.848, val scores are: find_maximum_subarray_kadane: 0.848
I0216 13:28:58.723318 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2050 current loss 3.246863, current_train_items 65424.
I0216 13:28:59.716153 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2050: {'start': 0.8662109375, 'end': 0.87158203125, 'score': 0.868896484375, 'examples_seen': 65424, 'step': 2050, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:28:59.716389 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.899, current avg val score is 0.869, val scores are: find_maximum_subarray_kadane: 0.869
I0216 13:29:00.988662 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2100 current loss 2.748215, current_train_items 67040.
I0216 13:29:01.965732 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2100: {'start': 0.873046875, 'end': 0.85986328125, 'score': 0.866455078125, 'examples_seen': 67040, 'step': 2100, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:01.965898 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.899, current avg val score is 0.866, val scores are: find_maximum_subarray_kadane: 0.866
I0216 13:29:03.216501 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2150 current loss 2.786759, current_train_items 68624.
I0216 13:29:04.201391 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2150: {'start': 0.8935546875, 'end': 0.83935546875, 'score': 0.866455078125, 'examples_seen': 68624, 'step': 2150, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:04.201559 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.899, current avg val score is 0.866, val scores are: find_maximum_subarray_kadane: 0.866
I0216 13:29:05.453635 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2200 current loss 1.895986, current_train_items 70224.
I0216 13:29:06.431064 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2200: {'start': 0.87353515625, 'end': 0.83447265625, 'score': 0.85400390625, 'examples_seen': 70224, 'step': 2200, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:06.431226 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.899, current avg val score is 0.854, val scores are: find_maximum_subarray_kadane: 0.854
I0216 13:29:07.680504 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2250 current loss 4.166031, current_train_items 71840.
I0216 13:29:08.655506 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2250: {'start': 0.8818359375, 'end': 0.80078125, 'score': 0.84130859375, 'examples_seen': 71840, 'step': 2250, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:08.655751 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.899, current avg val score is 0.841, val scores are: find_maximum_subarray_kadane: 0.841
I0216 13:29:09.920975 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2300 current loss 4.840586, current_train_items 73424.
I0216 13:29:10.916939 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2300: {'start': 0.89013671875, 'end': 0.853515625, 'score': 0.871826171875, 'examples_seen': 73424, 'step': 2300, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:10.917229 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.899, current avg val score is 0.872, val scores are: find_maximum_subarray_kadane: 0.872
I0216 13:29:12.176654 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2350 current loss 3.936056, current_train_items 75008.
I0216 13:29:13.160025 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2350: {'start': 0.8828125, 'end': 0.8447265625, 'score': 0.86376953125, 'examples_seen': 75008, 'step': 2350, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:13.160289 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.899, current avg val score is 0.864, val scores are: find_maximum_subarray_kadane: 0.864
I0216 13:29:14.410769 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2400 current loss 3.398506, current_train_items 76608.
I0216 13:29:15.392632 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2400: {'start': 0.91796875, 'end': 0.87744140625, 'score': 0.897705078125, 'examples_seen': 76608, 'step': 2400, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:15.392794 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.899, current avg val score is 0.898, val scores are: find_maximum_subarray_kadane: 0.898
I0216 13:29:16.657713 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2450 current loss 2.848522, current_train_items 78208.
I0216 13:29:17.654185 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2450: {'start': 0.89013671875, 'end': 0.8740234375, 'score': 0.882080078125, 'examples_seen': 78208, 'step': 2450, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:17.654418 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.899, current avg val score is 0.882, val scores are: find_maximum_subarray_kadane: 0.882
I0216 13:29:18.912079 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2500 current loss 2.747017, current_train_items 79792.
I0216 13:29:19.903764 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2500: {'start': 0.90185546875, 'end': 0.8798828125, 'score': 0.890869140625, 'examples_seen': 79792, 'step': 2500, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:19.904054 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.899, current avg val score is 0.891, val scores are: find_maximum_subarray_kadane: 0.891
I0216 13:29:21.164317 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2550 current loss 1.642451, current_train_items 81392.
I0216 13:29:22.145506 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2550: {'start': 0.91357421875, 'end': 0.8251953125, 'score': 0.869384765625, 'examples_seen': 81392, 'step': 2550, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:22.145692 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.899, current avg val score is 0.869, val scores are: find_maximum_subarray_kadane: 0.869
I0216 13:29:23.394110 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2600 current loss 4.236747, current_train_items 82992.
I0216 13:29:24.366755 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2600: {'start': 0.8857421875, 'end': 0.89453125, 'score': 0.89013671875, 'examples_seen': 82992, 'step': 2600, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:24.366990 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.899, current avg val score is 0.890, val scores are: find_maximum_subarray_kadane: 0.890
I0216 13:29:25.643796 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2650 current loss 4.010337, current_train_items 84592.
I0216 13:29:26.629025 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2650: {'start': 0.8935546875, 'end': 0.87158203125, 'score': 0.882568359375, 'examples_seen': 84592, 'step': 2650, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:26.629278 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.899, current avg val score is 0.883, val scores are: find_maximum_subarray_kadane: 0.883
I0216 13:29:27.883028 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2700 current loss 3.558537, current_train_items 86160.
I0216 13:29:28.865132 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2700: {'start': 0.89111328125, 'end': 0.8623046875, 'score': 0.876708984375, 'examples_seen': 86160, 'step': 2700, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:28.865366 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.899, current avg val score is 0.877, val scores are: find_maximum_subarray_kadane: 0.877
I0216 13:29:30.146464 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2750 current loss 3.063427, current_train_items 87776.
I0216 13:29:31.131213 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2750: {'start': 0.88671875, 'end': 0.87890625, 'score': 0.8828125, 'examples_seen': 87776, 'step': 2750, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:31.131455 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.899, current avg val score is 0.883, val scores are: find_maximum_subarray_kadane: 0.883
I0216 13:29:32.384793 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2800 current loss 2.933789, current_train_items 89376.
I0216 13:29:33.365520 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2800: {'start': 0.8916015625, 'end': 0.900390625, 'score': 0.89599609375, 'examples_seen': 89376, 'step': 2800, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:33.365755 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.899, current avg val score is 0.896, val scores are: find_maximum_subarray_kadane: 0.896
I0216 13:29:34.641686 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2850 current loss 2.794325, current_train_items 90960.
I0216 13:29:35.629503 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2850: {'start': 0.90283203125, 'end': 0.880859375, 'score': 0.891845703125, 'examples_seen': 90960, 'step': 2850, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:35.629740 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.899, current avg val score is 0.892, val scores are: find_maximum_subarray_kadane: 0.892
I0216 13:29:36.902196 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2900 current loss 1.833290, current_train_items 92576.
I0216 13:29:37.884367 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2900: {'start': 0.9140625, 'end': 0.89599609375, 'score': 0.905029296875, 'examples_seen': 92576, 'step': 2900, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:37.884605 124543013864960 run.py:785] Checkpointing best model, best avg val score was 0.899, current avg val score is 0.905, val scores are: find_maximum_subarray_kadane: 0.905
I0216 13:29:39.201561 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 2950 current loss 5.464809, current_train_items 94160.
I0216 13:29:40.181667 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 2950: {'start': 0.86962890625, 'end': 0.77197265625, 'score': 0.82080078125, 'examples_seen': 94160, 'step': 2950, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:40.181902 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.905, current avg val score is 0.821, val scores are: find_maximum_subarray_kadane: 0.821
I0216 13:29:41.441104 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3000 current loss 4.821928, current_train_items 95760.
I0216 13:29:42.432099 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3000: {'start': 0.85693359375, 'end': 0.87744140625, 'score': 0.8671875, 'examples_seen': 95760, 'step': 3000, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:42.432352 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.905, current avg val score is 0.867, val scores are: find_maximum_subarray_kadane: 0.867
I0216 13:29:43.702075 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3050 current loss 3.170315, current_train_items 97344.
I0216 13:29:44.695678 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3050: {'start': 0.89306640625, 'end': 0.8994140625, 'score': 0.896240234375, 'examples_seen': 97344, 'step': 3050, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:44.695842 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.905, current avg val score is 0.896, val scores are: find_maximum_subarray_kadane: 0.896
I0216 13:29:45.968228 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3100 current loss 3.661060, current_train_items 98944.
I0216 13:29:46.958906 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3100: {'start': 0.89794921875, 'end': 0.912109375, 'score': 0.905029296875, 'examples_seen': 98944, 'step': 3100, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:46.959157 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.905, current avg val score is 0.905, val scores are: find_maximum_subarray_kadane: 0.905
I0216 13:29:48.214855 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3150 current loss 2.444744, current_train_items 100528.
I0216 13:29:49.196322 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3150: {'start': 0.91357421875, 'end': 0.8525390625, 'score': 0.883056640625, 'examples_seen': 100528, 'step': 3150, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:49.196561 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.905, current avg val score is 0.883, val scores are: find_maximum_subarray_kadane: 0.883
I0216 13:29:50.461851 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3200 current loss 2.802694, current_train_items 102128.
I0216 13:29:51.444338 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3200: {'start': 0.7978515625, 'end': 0.87841796875, 'score': 0.838134765625, 'examples_seen': 102128, 'step': 3200, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:51.444578 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.905, current avg val score is 0.838, val scores are: find_maximum_subarray_kadane: 0.838
I0216 13:29:52.701004 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3250 current loss 1.382793, current_train_items 103728.
I0216 13:29:53.674402 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3250: {'start': 0.91748046875, 'end': 0.87255859375, 'score': 0.89501953125, 'examples_seen': 103728, 'step': 3250, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:53.674639 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.905, current avg val score is 0.895, val scores are: find_maximum_subarray_kadane: 0.895
I0216 13:29:54.931824 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3300 current loss 4.364762, current_train_items 105328.
I0216 13:29:55.906106 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3300: {'start': 0.84716796875, 'end': 0.89990234375, 'score': 0.87353515625, 'examples_seen': 105328, 'step': 3300, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:55.906344 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.905, current avg val score is 0.874, val scores are: find_maximum_subarray_kadane: 0.874
I0216 13:29:57.144046 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3350 current loss 4.085989, current_train_items 106928.
I0216 13:29:58.138640 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3350: {'start': 0.89306640625, 'end': 0.912109375, 'score': 0.902587890625, 'examples_seen': 106928, 'step': 3350, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:29:58.138896 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.905, current avg val score is 0.903, val scores are: find_maximum_subarray_kadane: 0.903
I0216 13:29:59.405621 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3400 current loss 3.329156, current_train_items 108512.
I0216 13:30:00.380668 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3400: {'start': 0.86181640625, 'end': 0.8642578125, 'score': 0.863037109375, 'examples_seen': 108512, 'step': 3400, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:00.380908 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.905, current avg val score is 0.863, val scores are: find_maximum_subarray_kadane: 0.863
I0216 13:30:01.644475 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3450 current loss 2.940677, current_train_items 110112.
I0216 13:30:02.640488 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3450: {'start': 0.9365234375, 'end': 0.91845703125, 'score': 0.927490234375, 'examples_seen': 110112, 'step': 3450, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:02.640726 124543013864960 run.py:785] Checkpointing best model, best avg val score was 0.905, current avg val score is 0.927, val scores are: find_maximum_subarray_kadane: 0.927
I0216 13:30:03.937620 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3500 current loss 2.631291, current_train_items 111696.
I0216 13:30:04.921912 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3500: {'start': 0.89453125, 'end': 0.85693359375, 'score': 0.875732421875, 'examples_seen': 111696, 'step': 3500, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:04.922163 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.927, current avg val score is 0.876, val scores are: find_maximum_subarray_kadane: 0.876
I0216 13:30:06.202290 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3550 current loss 3.308193, current_train_items 113312.
I0216 13:30:07.188865 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3550: {'start': 0.89453125, 'end': 0.89306640625, 'score': 0.893798828125, 'examples_seen': 113312, 'step': 3550, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:07.189116 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.927, current avg val score is 0.894, val scores are: find_maximum_subarray_kadane: 0.894
I0216 13:30:08.438005 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3600 current loss 2.097396, current_train_items 114896.
I0216 13:30:09.417031 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3600: {'start': 0.85498046875, 'end': 0.83642578125, 'score': 0.845703125, 'examples_seen': 114896, 'step': 3600, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:09.417264 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.927, current avg val score is 0.846, val scores are: find_maximum_subarray_kadane: 0.846
I0216 13:30:10.696677 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3650 current loss 3.847441, current_train_items 116496.
I0216 13:30:11.683013 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3650: {'start': 0.92333984375, 'end': 0.9228515625, 'score': 0.923095703125, 'examples_seen': 116496, 'step': 3650, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:11.683250 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.927, current avg val score is 0.923, val scores are: find_maximum_subarray_kadane: 0.923
I0216 13:30:12.934610 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3700 current loss 3.568053, current_train_items 118096.
I0216 13:30:13.983963 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3700: {'start': 0.90234375, 'end': 0.87060546875, 'score': 0.886474609375, 'examples_seen': 118096, 'step': 3700, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:13.984225 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.927, current avg val score is 0.886, val scores are: find_maximum_subarray_kadane: 0.886
I0216 13:30:15.280897 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3750 current loss 3.848944, current_train_items 119680.
I0216 13:30:16.262589 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3750: {'start': 0.83349609375, 'end': 0.75244140625, 'score': 0.79296875, 'examples_seen': 119680, 'step': 3750, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:16.262834 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.927, current avg val score is 0.793, val scores are: find_maximum_subarray_kadane: 0.793
I0216 13:30:17.518982 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3800 current loss 2.882762, current_train_items 121264.
I0216 13:30:18.516296 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3800: {'start': 0.912109375, 'end': 0.91552734375, 'score': 0.913818359375, 'examples_seen': 121264, 'step': 3800, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:18.516482 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.927, current avg val score is 0.914, val scores are: find_maximum_subarray_kadane: 0.914
I0216 13:30:19.886188 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3850 current loss 2.904069, current_train_items 122864.
I0216 13:30:20.918193 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3850: {'start': 0.9208984375, 'end': 0.90185546875, 'score': 0.911376953125, 'examples_seen': 122864, 'step': 3850, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:20.918440 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.927, current avg val score is 0.911, val scores are: find_maximum_subarray_kadane: 0.911
I0216 13:30:22.280566 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3900 current loss 2.624522, current_train_items 124480.
I0216 13:30:23.337090 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3900: {'start': 0.8857421875, 'end': 0.89013671875, 'score': 0.887939453125, 'examples_seen': 124480, 'step': 3900, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:23.337329 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.927, current avg val score is 0.888, val scores are: find_maximum_subarray_kadane: 0.888
I0216 13:30:24.670082 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 3950 current loss 1.808598, current_train_items 126064.
I0216 13:30:25.735156 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 3950: {'start': 0.9140625, 'end': 0.8427734375, 'score': 0.87841796875, 'examples_seen': 126064, 'step': 3950, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:25.735337 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.927, current avg val score is 0.878, val scores are: find_maximum_subarray_kadane: 0.878
I0216 13:30:27.089635 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4000 current loss 4.337499, current_train_items 127664.
I0216 13:30:28.067612 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4000: {'start': 0.89599609375, 'end': 0.88916015625, 'score': 0.892578125, 'examples_seen': 127664, 'step': 4000, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:28.067788 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.927, current avg val score is 0.893, val scores are: find_maximum_subarray_kadane: 0.893
I0216 13:30:29.363436 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4050 current loss 3.885971, current_train_items 129264.
I0216 13:30:30.347161 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4050: {'start': 0.912109375, 'end': 0.90283203125, 'score': 0.907470703125, 'examples_seen': 129264, 'step': 4050, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:30.347404 124543013864960 run.py:785] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.907, val scores are: find_maximum_subarray_kadane: 0.907
I0216 13:30:31.691183 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4100 current loss 3.201056, current_train_items 130848.
I0216 13:30:32.673051 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4100: {'start': 0.9111328125, 'end': 0.875, 'score': 0.89306640625, 'examples_seen': 130848, 'step': 4100, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:32.673294 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.907, current avg val score is 0.893, val scores are: find_maximum_subarray_kadane: 0.893
I0216 13:30:33.954518 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4150 current loss 3.106980, current_train_items 132432.
I0216 13:30:34.942965 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4150: {'start': 0.92236328125, 'end': 0.9228515625, 'score': 0.922607421875, 'examples_seen': 132432, 'step': 4150, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:34.943215 124543013864960 run.py:785] Checkpointing best model, best avg val score was 0.907, current avg val score is 0.923, val scores are: find_maximum_subarray_kadane: 0.923
I0216 13:30:36.282826 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4200 current loss 2.479701, current_train_items 134048.
I0216 13:30:37.263236 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4200: {'start': 0.9052734375, 'end': 0.9091796875, 'score': 0.9072265625, 'examples_seen': 134048, 'step': 4200, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:37.263471 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.923, current avg val score is 0.907, val scores are: find_maximum_subarray_kadane: 0.907
I0216 13:30:38.531702 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4250 current loss 2.708533, current_train_items 135632.
I0216 13:30:39.520825 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4250: {'start': 0.88134765625, 'end': 0.9013671875, 'score': 0.891357421875, 'examples_seen': 135632, 'step': 4250, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:39.521096 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.923, current avg val score is 0.891, val scores are: find_maximum_subarray_kadane: 0.891
I0216 13:30:40.790208 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4300 current loss 1.315839, current_train_items 137232.
I0216 13:30:41.766903 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4300: {'start': 0.91796875, 'end': 0.91748046875, 'score': 0.917724609375, 'examples_seen': 137232, 'step': 4300, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:41.767089 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.923, current avg val score is 0.918, val scores are: find_maximum_subarray_kadane: 0.918
I0216 13:30:43.019015 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4350 current loss 3.950168, current_train_items 138832.
I0216 13:30:44.001805 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4350: {'start': 0.93017578125, 'end': 0.91015625, 'score': 0.920166015625, 'examples_seen': 138832, 'step': 4350, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:44.002052 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.923, current avg val score is 0.920, val scores are: find_maximum_subarray_kadane: 0.920
I0216 13:30:45.285268 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4400 current loss 3.788302, current_train_items 140432.
I0216 13:30:46.273676 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4400: {'start': 0.908203125, 'end': 0.90234375, 'score': 0.9052734375, 'examples_seen': 140432, 'step': 4400, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:46.273921 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.923, current avg val score is 0.905, val scores are: find_maximum_subarray_kadane: 0.905
I0216 13:30:47.518653 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4450 current loss 3.180669, current_train_items 142016.
I0216 13:30:48.514027 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4450: {'start': 0.8798828125, 'end': 0.88427734375, 'score': 0.882080078125, 'examples_seen': 142016, 'step': 4450, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:48.514262 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.923, current avg val score is 0.882, val scores are: find_maximum_subarray_kadane: 0.882
I0216 13:30:49.792462 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4500 current loss 2.998004, current_train_items 143600.
I0216 13:30:50.781417 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4500: {'start': 0.91552734375, 'end': 0.8955078125, 'score': 0.905517578125, 'examples_seen': 143600, 'step': 4500, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:50.781594 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.923, current avg val score is 0.906, val scores are: find_maximum_subarray_kadane: 0.906
I0216 13:30:52.056980 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4550 current loss 2.148862, current_train_items 145216.
I0216 13:30:53.037063 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4550: {'start': 0.8984375, 'end': 0.908203125, 'score': 0.9033203125, 'examples_seen': 145216, 'step': 4550, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:53.037303 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.923, current avg val score is 0.903, val scores are: find_maximum_subarray_kadane: 0.903
I0216 13:30:54.307027 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4600 current loss 3.034261, current_train_items 146800.
I0216 13:30:55.301396 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4600: {'start': 0.91064453125, 'end': 0.8896484375, 'score': 0.900146484375, 'examples_seen': 146800, 'step': 4600, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:55.301635 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.923, current avg val score is 0.900, val scores are: find_maximum_subarray_kadane: 0.900
I0216 13:30:56.581648 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4650 current loss 1.457110, current_train_items 148400.
I0216 13:30:57.560590 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4650: {'start': 0.87890625, 'end': 0.89990234375, 'score': 0.889404296875, 'examples_seen': 148400, 'step': 4650, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:57.560828 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.923, current avg val score is 0.889, val scores are: find_maximum_subarray_kadane: 0.889
I0216 13:30:58.842825 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4700 current loss 3.704587, current_train_items 150000.
I0216 13:30:59.821784 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4700: {'start': 0.87548828125, 'end': 0.91943359375, 'score': 0.8974609375, 'examples_seen': 150000, 'step': 4700, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:30:59.822042 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.923, current avg val score is 0.897, val scores are: find_maximum_subarray_kadane: 0.897
I0216 13:31:01.104504 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4750 current loss 3.848219, current_train_items 151600.
I0216 13:31:02.086989 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4750: {'start': 0.92529296875, 'end': 0.91748046875, 'score': 0.92138671875, 'examples_seen': 151600, 'step': 4750, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:31:02.087171 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.923, current avg val score is 0.921, val scores are: find_maximum_subarray_kadane: 0.921
I0216 13:31:03.343695 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4800 current loss 3.092890, current_train_items 153168.
I0216 13:31:04.330934 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4800: {'start': 0.93505859375, 'end': 0.9267578125, 'score': 0.930908203125, 'examples_seen': 153168, 'step': 4800, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:31:04.331102 124543013864960 run.py:785] Checkpointing best model, best avg val score was 0.923, current avg val score is 0.931, val scores are: find_maximum_subarray_kadane: 0.931
I0216 13:31:05.671245 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4850 current loss 2.700376, current_train_items 154784.
I0216 13:31:06.658218 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4850: {'start': 0.9013671875, 'end': 0.9189453125, 'score': 0.91015625, 'examples_seen': 154784, 'step': 4850, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:31:06.658457 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.931, current avg val score is 0.910, val scores are: find_maximum_subarray_kadane: 0.910
I0216 13:31:07.913560 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4900 current loss 2.423752, current_train_items 156368.
I0216 13:31:08.902613 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4900: {'start': 0.927734375, 'end': 0.9072265625, 'score': 0.91748046875, 'examples_seen': 156368, 'step': 4900, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:31:08.902850 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.931, current avg val score is 0.917, val scores are: find_maximum_subarray_kadane: 0.917
I0216 13:31:10.178226 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 4950 current loss 3.072876, current_train_items 157968.
I0216 13:31:11.168496 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 4950: {'start': 0.9208984375, 'end': 0.92236328125, 'score': 0.921630859375, 'examples_seen': 157968, 'step': 4950, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:31:11.168735 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.931, current avg val score is 0.922, val scores are: find_maximum_subarray_kadane: 0.922
I0216 13:31:12.433632 124543013864960 run.py:729] Algo find_maximum_subarray_kadane step 5000 current loss 1.200484, current_train_items 159584.
I0216 13:31:13.422933 124543013864960 run.py:764] (val) algo find_maximum_subarray_kadane step 5000: {'start': 0.93115234375, 'end': 0.91259765625, 'score': 0.921875, 'examples_seen': 159584, 'step': 5000, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:31:13.423189 124543013864960 run.py:788] Not saving new best model, best avg val score was 0.931, current avg val score is 0.922, val scores are: find_maximum_subarray_kadane: 0.922
I0216 13:31:13.423285 124543013864960 run.py:794] Restoring best model from checkpoint...
I0216 13:31:41.328706 124543013864960 run.py:809] (test) algo find_maximum_subarray_kadane : {'end': 0.4140625, 'start': 0.6044921875, 'score': 0.50927734375, 'examples_seen': 159584, 'step': 5001, 'algorithm': 'find_maximum_subarray_kadane'}
I0216 13:31:41.328888 124543013864960 run.py:811] Done!
