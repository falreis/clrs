I1006 21:54:40.991431 129051738551808 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I1006 21:54:40.993864 129051738551808 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I1006 21:54:41.318862 129051738551808 run.py:453] Model: f7 ['activity_selector']
I1006 21:54:41.318965 129051738551808 run.py:455] algorithms ['activity_selector']
I1006 21:54:41.319163 129051738551808 run.py:456] train_lengths ['4', '7', '11', '13', '16']
I1006 21:54:41.319201 129051738551808 run.py:457] train_batch_size 16
I1006 21:54:41.319288 129051738551808 run.py:458] val_batch_size 8
I1006 21:54:41.319322 129051738551808 run.py:459] test_batch_size 8
I1006 21:54:41.319352 129051738551808 run.py:460] chunked_training True
I1006 21:54:41.319478 129051738551808 run.py:461] chunk_length 16
I1006 21:54:41.319508 129051738551808 run.py:462] train_steps 10000
I1006 21:54:41.319538 129051738551808 run.py:463] eval_every 50
I1006 21:54:41.319567 129051738551808 run.py:464] test_every 500
I1006 21:54:41.319598 129051738551808 run.py:465] hidden_size 64
I1006 21:54:41.319626 129051738551808 run.py:466] nb_msg_passing_steps 1
I1006 21:54:41.319654 129051738551808 run.py:467] learning_rate 0.001
I1006 21:54:41.319752 129051738551808 run.py:468] grad_clip_max_norm 1.0
I1006 21:54:41.319785 129051738551808 run.py:469] dropout_prob 0.1
I1006 21:54:41.319815 129051738551808 run.py:470] hint_teacher_forcing 0.0
I1006 21:54:41.319843 129051738551808 run.py:471] hint_mode encoded_decoded
I1006 21:54:41.319942 129051738551808 run.py:472] hint_repred_mode soft
I1006 21:54:41.319973 129051738551808 run.py:473] use_ln True
I1006 21:54:41.320002 129051738551808 run.py:474] use_lstm True
I1006 21:54:41.320030 129051738551808 run.py:475] nb_triplet_fts 8
I1006 21:54:41.320058 129051738551808 run.py:476] encoder_init xavier_on_scalars
I1006 21:54:41.320086 129051738551808 run.py:477] processor_type f7
I1006 21:54:41.320120 129051738551808 run.py:478] checkpoint_path CLRS30
I1006 21:54:41.320148 129051738551808 run.py:479] dataset_path CLRS30
I1006 21:54:41.320179 129051738551808 run.py:480] freeze_processor False
I1006 21:54:41.320208 129051738551808 run.py:481] reduction min
I1006 21:54:41.320236 129051738551808 run.py:482] activation elu
I1006 21:54:41.320263 129051738551808 run.py:483] restore_model 
I1006 21:54:41.320290 129051738551808 run.py:484] gated True
I1006 21:54:41.320318 129051738551808 run.py:485] gated_activation tanh
I1006 21:54:41.323027 129051738551808 run.py:511] Creating samplers for algo activity_selector
W1006 21:54:41.323226 129051738551808 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1006 21:54:41.323482 129051738551808 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W1006 21:54:41.534596 129051738551808 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1006 21:54:41.781327 129051738551808 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1006 21:54:42.087158 129051738551808 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1006 21:54:42.425723 129051738551808 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1006 21:54:42.815365 129051738551808 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I1006 21:54:42.815661 129051738551808 samplers.py:124] Creating a dataset with 64 samples.
I1006 21:54:42.841913 129051738551808 run.py:297] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I1006 21:54:42.842618 129051738551808 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I1006 21:54:42.846360 129051738551808 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I1006 21:54:42.849600 129051738551808 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I1006 21:54:42.904142 129051738551808 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W1006 21:54:42.924924 129051738551808 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x755eae7b09a0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I1006 21:55:10.765975 129051738551808 run.py:734] Algo activity_selector step 0 current loss 5.423452, current_train_items 32.
I1006 21:55:14.847185 129051738551808 run.py:769] (val) algo activity_selector step 0: {'selected': 0.4157814871016692, 'score': 0.4157814871016692, 'examples_seen': 32, 'step': 0, 'algorithm': 'activity_selector'}
I1006 21:55:14.847351 129051738551808 run.py:790] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.416, val scores are: activity_selector: 0.416
I1006 21:55:46.909010 129051738551808 run.py:734] Algo activity_selector step 50 current loss 4.158654, current_train_items 1408.
I1006 21:55:46.933647 129051738551808 run.py:769] (val) algo activity_selector step 50: {'selected': 0.7232704402515724, 'score': 0.7232704402515724, 'examples_seen': 1408, 'step': 50, 'algorithm': 'activity_selector'}
I1006 21:55:46.933813 129051738551808 run.py:790] Checkpointing best model, best avg val score was 0.416, current avg val score is 0.723, val scores are: activity_selector: 0.723
I1006 21:55:47.826766 129051738551808 run.py:734] Algo activity_selector step 100 current loss 3.694749, current_train_items 2800.
I1006 21:55:47.851125 129051738551808 run.py:769] (val) algo activity_selector step 100: {'selected': 0.7441860465116279, 'score': 0.7441860465116279, 'examples_seen': 2800, 'step': 100, 'algorithm': 'activity_selector'}
I1006 21:55:47.851273 129051738551808 run.py:790] Checkpointing best model, best avg val score was 0.723, current avg val score is 0.744, val scores are: activity_selector: 0.744
I1006 21:55:48.769068 129051738551808 run.py:734] Algo activity_selector step 150 current loss 3.461706, current_train_items 4176.
I1006 21:55:48.793801 129051738551808 run.py:769] (val) algo activity_selector step 150: {'selected': 0.7200000000000001, 'score': 0.7200000000000001, 'examples_seen': 4176, 'step': 150, 'algorithm': 'activity_selector'}
I1006 21:55:48.793955 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.744, current avg val score is 0.720, val scores are: activity_selector: 0.720
I1006 21:55:49.677701 129051738551808 run.py:734] Algo activity_selector step 200 current loss 3.270882, current_train_items 5536.
I1006 21:55:49.704515 129051738551808 run.py:769] (val) algo activity_selector step 200: {'selected': 0.7104722792607804, 'score': 0.7104722792607804, 'examples_seen': 5536, 'step': 200, 'algorithm': 'activity_selector'}
I1006 21:55:49.704667 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.744, current avg val score is 0.710, val scores are: activity_selector: 0.710
I1006 21:55:50.593884 129051738551808 run.py:734] Algo activity_selector step 250 current loss 3.685335, current_train_items 6944.
I1006 21:55:50.618449 129051738551808 run.py:769] (val) algo activity_selector step 250: {'selected': 0.6160520607375272, 'score': 0.6160520607375272, 'examples_seen': 6944, 'step': 250, 'algorithm': 'activity_selector'}
I1006 21:55:50.618596 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.744, current avg val score is 0.616, val scores are: activity_selector: 0.616
I1006 21:55:51.516019 129051738551808 run.py:734] Algo activity_selector step 300 current loss 3.050831, current_train_items 8304.
I1006 21:55:51.540081 129051738551808 run.py:769] (val) algo activity_selector step 300: {'selected': 0.6816479400749064, 'score': 0.6816479400749064, 'examples_seen': 8304, 'step': 300, 'algorithm': 'activity_selector'}
I1006 21:55:51.540229 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.744, current avg val score is 0.682, val scores are: activity_selector: 0.682
I1006 21:55:52.428073 129051738551808 run.py:734] Algo activity_selector step 350 current loss 2.785482, current_train_items 9680.
I1006 21:55:52.452373 129051738551808 run.py:769] (val) algo activity_selector step 350: {'selected': 0.7338709677419355, 'score': 0.7338709677419355, 'examples_seen': 9680, 'step': 350, 'algorithm': 'activity_selector'}
I1006 21:55:52.452526 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.744, current avg val score is 0.734, val scores are: activity_selector: 0.734
I1006 21:55:53.344835 129051738551808 run.py:734] Algo activity_selector step 400 current loss 2.586207, current_train_items 11072.
I1006 21:55:53.368817 129051738551808 run.py:769] (val) algo activity_selector step 400: {'selected': 0.6984126984126984, 'score': 0.6984126984126984, 'examples_seen': 11072, 'step': 400, 'algorithm': 'activity_selector'}
I1006 21:55:53.368966 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.744, current avg val score is 0.698, val scores are: activity_selector: 0.698
I1006 21:55:54.255329 129051738551808 run.py:734] Algo activity_selector step 450 current loss 2.462030, current_train_items 12448.
I1006 21:55:54.282363 129051738551808 run.py:769] (val) algo activity_selector step 450: {'selected': 0.7508650519031141, 'score': 0.7508650519031141, 'examples_seen': 12448, 'step': 450, 'algorithm': 'activity_selector'}
I1006 21:55:54.282510 129051738551808 run.py:790] Checkpointing best model, best avg val score was 0.744, current avg val score is 0.751, val scores are: activity_selector: 0.751
I1006 21:55:55.186105 129051738551808 run.py:734] Algo activity_selector step 500 current loss 2.695735, current_train_items 13824.
I1006 21:55:55.209871 129051738551808 run.py:769] (val) algo activity_selector step 500: {'selected': 0.7193675889328062, 'score': 0.7193675889328062, 'examples_seen': 13824, 'step': 500, 'algorithm': 'activity_selector'}
I1006 21:55:55.210022 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.751, current avg val score is 0.719, val scores are: activity_selector: 0.719
I1006 21:55:56.091339 129051738551808 run.py:734] Algo activity_selector step 550 current loss 2.419059, current_train_items 15200.
I1006 21:55:56.115485 129051738551808 run.py:769] (val) algo activity_selector step 550: {'selected': 0.7543252595155711, 'score': 0.7543252595155711, 'examples_seen': 15200, 'step': 550, 'algorithm': 'activity_selector'}
I1006 21:55:56.115635 129051738551808 run.py:790] Checkpointing best model, best avg val score was 0.751, current avg val score is 0.754, val scores are: activity_selector: 0.754
I1006 21:55:57.019417 129051738551808 run.py:734] Algo activity_selector step 600 current loss 2.394728, current_train_items 16576.
I1006 21:55:57.044990 129051738551808 run.py:769] (val) algo activity_selector step 600: {'selected': 0.7505070993914807, 'score': 0.7505070993914807, 'examples_seen': 16576, 'step': 600, 'algorithm': 'activity_selector'}
I1006 21:55:57.045145 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.754, current avg val score is 0.751, val scores are: activity_selector: 0.751
I1006 21:55:57.944800 129051738551808 run.py:734] Algo activity_selector step 650 current loss 2.709738, current_train_items 17952.
I1006 21:55:57.968728 129051738551808 run.py:769] (val) algo activity_selector step 650: {'selected': 0.721774193548387, 'score': 0.721774193548387, 'examples_seen': 17952, 'step': 650, 'algorithm': 'activity_selector'}
I1006 21:55:57.968892 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.754, current avg val score is 0.722, val scores are: activity_selector: 0.722
I1006 21:55:58.855819 129051738551808 run.py:734] Algo activity_selector step 700 current loss 2.638517, current_train_items 19344.
I1006 21:55:58.881189 129051738551808 run.py:769] (val) algo activity_selector step 700: {'selected': 0.8046421663442941, 'score': 0.8046421663442941, 'examples_seen': 19344, 'step': 700, 'algorithm': 'activity_selector'}
I1006 21:55:58.881339 129051738551808 run.py:790] Checkpointing best model, best avg val score was 0.754, current avg val score is 0.805, val scores are: activity_selector: 0.805
I1006 21:55:59.787015 129051738551808 run.py:734] Algo activity_selector step 750 current loss 2.196539, current_train_items 20720.
I1006 21:55:59.811588 129051738551808 run.py:769] (val) algo activity_selector step 750: {'selected': 0.7792706333973128, 'score': 0.7792706333973128, 'examples_seen': 20720, 'step': 750, 'algorithm': 'activity_selector'}
I1006 21:55:59.811746 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.805, current avg val score is 0.779, val scores are: activity_selector: 0.779
I1006 21:56:00.686808 129051738551808 run.py:734] Algo activity_selector step 800 current loss 2.146335, current_train_items 22096.
I1006 21:56:00.711111 129051738551808 run.py:769] (val) algo activity_selector step 800: {'selected': 0.8451730418943535, 'score': 0.8451730418943535, 'examples_seen': 22096, 'step': 800, 'algorithm': 'activity_selector'}
I1006 21:56:00.711260 129051738551808 run.py:790] Checkpointing best model, best avg val score was 0.805, current avg val score is 0.845, val scores are: activity_selector: 0.845
I1006 21:56:01.596814 129051738551808 run.py:734] Algo activity_selector step 850 current loss 2.108887, current_train_items 23472.
I1006 21:56:01.620354 129051738551808 run.py:769] (val) algo activity_selector step 850: {'selected': 0.8062015503875969, 'score': 0.8062015503875969, 'examples_seen': 23472, 'step': 850, 'algorithm': 'activity_selector'}
I1006 21:56:01.620501 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.845, current avg val score is 0.806, val scores are: activity_selector: 0.806
I1006 21:56:02.508206 129051738551808 run.py:734] Algo activity_selector step 900 current loss 2.311587, current_train_items 24848.
I1006 21:56:02.532063 129051738551808 run.py:769] (val) algo activity_selector step 900: {'selected': 0.7891682785299806, 'score': 0.7891682785299806, 'examples_seen': 24848, 'step': 900, 'algorithm': 'activity_selector'}
I1006 21:56:02.532214 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.845, current avg val score is 0.789, val scores are: activity_selector: 0.789
I1006 21:56:03.412451 129051738551808 run.py:734] Algo activity_selector step 950 current loss 2.066527, current_train_items 26224.
I1006 21:56:03.436984 129051738551808 run.py:769] (val) algo activity_selector step 950: {'selected': 0.7977099236641222, 'score': 0.7977099236641222, 'examples_seen': 26224, 'step': 950, 'algorithm': 'activity_selector'}
I1006 21:56:03.437143 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.845, current avg val score is 0.798, val scores are: activity_selector: 0.798
I1006 21:56:04.325691 129051738551808 run.py:734] Algo activity_selector step 1000 current loss 1.974571, current_train_items 27616.
I1006 21:56:04.350121 129051738551808 run.py:769] (val) algo activity_selector step 1000: {'selected': 0.7352941176470589, 'score': 0.7352941176470589, 'examples_seen': 27616, 'step': 1000, 'algorithm': 'activity_selector'}
I1006 21:56:04.350277 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.845, current avg val score is 0.735, val scores are: activity_selector: 0.735
I1006 21:56:05.236823 129051738551808 run.py:734] Algo activity_selector step 1050 current loss 2.296761, current_train_items 28992.
I1006 21:56:05.261234 129051738551808 run.py:769] (val) algo activity_selector step 1050: {'selected': 0.8063872255489021, 'score': 0.8063872255489021, 'examples_seen': 28992, 'step': 1050, 'algorithm': 'activity_selector'}
I1006 21:56:05.261379 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.845, current avg val score is 0.806, val scores are: activity_selector: 0.806
I1006 21:56:06.135868 129051738551808 run.py:734] Algo activity_selector step 1100 current loss 2.022213, current_train_items 30368.
I1006 21:56:06.159797 129051738551808 run.py:769] (val) algo activity_selector step 1100: {'selected': 0.7815631262525049, 'score': 0.7815631262525049, 'examples_seen': 30368, 'step': 1100, 'algorithm': 'activity_selector'}
I1006 21:56:06.159947 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.845, current avg val score is 0.782, val scores are: activity_selector: 0.782
I1006 21:56:07.040320 129051738551808 run.py:734] Algo activity_selector step 1150 current loss 2.040837, current_train_items 31760.
I1006 21:56:07.064461 129051738551808 run.py:769] (val) algo activity_selector step 1150: {'selected': 0.8468809073724008, 'score': 0.8468809073724008, 'examples_seen': 31760, 'step': 1150, 'algorithm': 'activity_selector'}
I1006 21:56:07.064609 129051738551808 run.py:790] Checkpointing best model, best avg val score was 0.845, current avg val score is 0.847, val scores are: activity_selector: 0.847
I1006 21:56:07.961233 129051738551808 run.py:734] Algo activity_selector step 1200 current loss 1.646408, current_train_items 33120.
I1006 21:56:07.985603 129051738551808 run.py:769] (val) algo activity_selector step 1200: {'selected': 0.8529411764705883, 'score': 0.8529411764705883, 'examples_seen': 33120, 'step': 1200, 'algorithm': 'activity_selector'}
I1006 21:56:07.985759 129051738551808 run.py:790] Checkpointing best model, best avg val score was 0.847, current avg val score is 0.853, val scores are: activity_selector: 0.853
I1006 21:56:08.879647 129051738551808 run.py:734] Algo activity_selector step 1250 current loss 1.939736, current_train_items 34496.
I1006 21:56:08.903840 129051738551808 run.py:769] (val) algo activity_selector step 1250: {'selected': 0.8948374760994264, 'score': 0.8948374760994264, 'examples_seen': 34496, 'step': 1250, 'algorithm': 'activity_selector'}
I1006 21:56:08.903991 129051738551808 run.py:790] Checkpointing best model, best avg val score was 0.853, current avg val score is 0.895, val scores are: activity_selector: 0.895
I1006 21:56:09.798035 129051738551808 run.py:734] Algo activity_selector step 1300 current loss 1.879664, current_train_items 35888.
I1006 21:56:09.825490 129051738551808 run.py:769] (val) algo activity_selector step 1300: {'selected': 0.8049792531120331, 'score': 0.8049792531120331, 'examples_seen': 35888, 'step': 1300, 'algorithm': 'activity_selector'}
I1006 21:56:09.825641 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.895, current avg val score is 0.805, val scores are: activity_selector: 0.805
I1006 21:56:10.715620 129051738551808 run.py:734] Algo activity_selector step 1350 current loss 1.832449, current_train_items 37264.
I1006 21:56:10.739925 129051738551808 run.py:769] (val) algo activity_selector step 1350: {'selected': 0.7999999999999999, 'score': 0.7999999999999999, 'examples_seen': 37264, 'step': 1350, 'algorithm': 'activity_selector'}
I1006 21:56:10.740074 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.895, current avg val score is 0.800, val scores are: activity_selector: 0.800
I1006 21:56:11.622493 129051738551808 run.py:734] Algo activity_selector step 1400 current loss 1.827391, current_train_items 38640.
I1006 21:56:11.650214 129051738551808 run.py:769] (val) algo activity_selector step 1400: {'selected': 0.8375733855185911, 'score': 0.8375733855185911, 'examples_seen': 38640, 'step': 1400, 'algorithm': 'activity_selector'}
I1006 21:56:11.650362 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.895, current avg val score is 0.838, val scores are: activity_selector: 0.838
I1006 21:56:12.523001 129051738551808 run.py:734] Algo activity_selector step 1450 current loss 1.816866, current_train_items 40016.
I1006 21:56:12.546913 129051738551808 run.py:769] (val) algo activity_selector step 1450: {'selected': 0.8932038834951456, 'score': 0.8932038834951456, 'examples_seen': 40016, 'step': 1450, 'algorithm': 'activity_selector'}
I1006 21:56:12.547063 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.895, current avg val score is 0.893, val scores are: activity_selector: 0.893
I1006 21:56:13.438060 129051738551808 run.py:734] Algo activity_selector step 1500 current loss 1.814746, current_train_items 41408.
I1006 21:56:13.462171 129051738551808 run.py:769] (val) algo activity_selector step 1500: {'selected': 0.8940269749518305, 'score': 0.8940269749518305, 'examples_seen': 41408, 'step': 1500, 'algorithm': 'activity_selector'}
I1006 21:56:13.462322 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.895, current avg val score is 0.894, val scores are: activity_selector: 0.894
I1006 21:56:14.340679 129051738551808 run.py:734] Algo activity_selector step 1550 current loss 1.825852, current_train_items 42768.
I1006 21:56:14.365396 129051738551808 run.py:769] (val) algo activity_selector step 1550: {'selected': 0.89945155393053, 'score': 0.89945155393053, 'examples_seen': 42768, 'step': 1550, 'algorithm': 'activity_selector'}
I1006 21:56:14.365543 129051738551808 run.py:790] Checkpointing best model, best avg val score was 0.895, current avg val score is 0.899, val scores are: activity_selector: 0.899
I1006 21:56:15.262216 129051738551808 run.py:734] Algo activity_selector step 1600 current loss 1.637915, current_train_items 44160.
I1006 21:56:15.286526 129051738551808 run.py:769] (val) algo activity_selector step 1600: {'selected': 0.8960302457466919, 'score': 0.8960302457466919, 'examples_seen': 44160, 'step': 1600, 'algorithm': 'activity_selector'}
I1006 21:56:15.286673 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.899, current avg val score is 0.896, val scores are: activity_selector: 0.896
I1006 21:56:16.168647 129051738551808 run.py:734] Algo activity_selector step 1650 current loss 1.700370, current_train_items 45536.
I1006 21:56:16.193516 129051738551808 run.py:769] (val) algo activity_selector step 1650: {'selected': 0.848030018761726, 'score': 0.848030018761726, 'examples_seen': 45536, 'step': 1650, 'algorithm': 'activity_selector'}
I1006 21:56:16.193664 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.899, current avg val score is 0.848, val scores are: activity_selector: 0.848
I1006 21:56:17.063678 129051738551808 run.py:734] Algo activity_selector step 1700 current loss 1.788511, current_train_items 46896.
I1006 21:56:17.088035 129051738551808 run.py:769] (val) algo activity_selector step 1700: {'selected': 0.8918918918918919, 'score': 0.8918918918918919, 'examples_seen': 46896, 'step': 1700, 'algorithm': 'activity_selector'}
I1006 21:56:17.088180 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.899, current avg val score is 0.892, val scores are: activity_selector: 0.892
I1006 21:56:17.983633 129051738551808 run.py:734] Algo activity_selector step 1750 current loss 1.860140, current_train_items 48304.
I1006 21:56:18.007794 129051738551808 run.py:769] (val) algo activity_selector step 1750: {'selected': 0.8653846153846154, 'score': 0.8653846153846154, 'examples_seen': 48304, 'step': 1750, 'algorithm': 'activity_selector'}
I1006 21:56:18.007941 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.899, current avg val score is 0.865, val scores are: activity_selector: 0.865
I1006 21:56:18.885267 129051738551808 run.py:734] Algo activity_selector step 1800 current loss 1.596313, current_train_items 49664.
I1006 21:56:18.910108 129051738551808 run.py:769] (val) algo activity_selector step 1800: {'selected': 0.8546099290780141, 'score': 0.8546099290780141, 'examples_seen': 49664, 'step': 1800, 'algorithm': 'activity_selector'}
I1006 21:56:18.910268 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.899, current avg val score is 0.855, val scores are: activity_selector: 0.855
I1006 21:56:19.796719 129051738551808 run.py:734] Algo activity_selector step 1850 current loss 1.592657, current_train_items 51056.
I1006 21:56:19.821778 129051738551808 run.py:769] (val) algo activity_selector step 1850: {'selected': 0.8722316865417378, 'score': 0.8722316865417378, 'examples_seen': 51056, 'step': 1850, 'algorithm': 'activity_selector'}
I1006 21:56:19.821933 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.899, current avg val score is 0.872, val scores are: activity_selector: 0.872
I1006 21:56:20.705535 129051738551808 run.py:734] Algo activity_selector step 1900 current loss 1.331102, current_train_items 52432.
I1006 21:56:20.729328 129051738551808 run.py:769] (val) algo activity_selector step 1900: {'selected': 0.8863198458574181, 'score': 0.8863198458574181, 'examples_seen': 52432, 'step': 1900, 'algorithm': 'activity_selector'}
I1006 21:56:20.729476 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.899, current avg val score is 0.886, val scores are: activity_selector: 0.886
I1006 21:56:21.613212 129051738551808 run.py:734] Algo activity_selector step 1950 current loss 1.775392, current_train_items 53808.
I1006 21:56:21.637578 129051738551808 run.py:769] (val) algo activity_selector step 1950: {'selected': 0.8964218455743879, 'score': 0.8964218455743879, 'examples_seen': 53808, 'step': 1950, 'algorithm': 'activity_selector'}
I1006 21:56:21.637735 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.899, current avg val score is 0.896, val scores are: activity_selector: 0.896
I1006 21:56:22.530807 129051738551808 run.py:734] Algo activity_selector step 2000 current loss 1.617615, current_train_items 55184.
I1006 21:56:22.555029 129051738551808 run.py:769] (val) algo activity_selector step 2000: {'selected': 0.8642447418738051, 'score': 0.8642447418738051, 'examples_seen': 55184, 'step': 2000, 'algorithm': 'activity_selector'}
I1006 21:56:22.555180 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.899, current avg val score is 0.864, val scores are: activity_selector: 0.864
I1006 21:56:23.432814 129051738551808 run.py:734] Algo activity_selector step 2050 current loss 1.509806, current_train_items 56560.
I1006 21:56:23.458435 129051738551808 run.py:769] (val) algo activity_selector step 2050: {'selected': 0.8970588235294118, 'score': 0.8970588235294118, 'examples_seen': 56560, 'step': 2050, 'algorithm': 'activity_selector'}
I1006 21:56:23.458587 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.899, current avg val score is 0.897, val scores are: activity_selector: 0.897
I1006 21:56:24.350798 129051738551808 run.py:734] Algo activity_selector step 2100 current loss 1.599344, current_train_items 57952.
I1006 21:56:24.374890 129051738551808 run.py:769] (val) algo activity_selector step 2100: {'selected': 0.8938547486033519, 'score': 0.8938547486033519, 'examples_seen': 57952, 'step': 2100, 'algorithm': 'activity_selector'}
I1006 21:56:24.375037 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.899, current avg val score is 0.894, val scores are: activity_selector: 0.894
I1006 21:56:25.246623 129051738551808 run.py:734] Algo activity_selector step 2150 current loss 1.874117, current_train_items 59312.
I1006 21:56:25.270451 129051738551808 run.py:769] (val) algo activity_selector step 2150: {'selected': 0.9140625000000001, 'score': 0.9140625000000001, 'examples_seen': 59312, 'step': 2150, 'algorithm': 'activity_selector'}
I1006 21:56:25.270604 129051738551808 run.py:790] Checkpointing best model, best avg val score was 0.899, current avg val score is 0.914, val scores are: activity_selector: 0.914
I1006 21:56:26.163095 129051738551808 run.py:734] Algo activity_selector step 2200 current loss 1.767273, current_train_items 60720.
I1006 21:56:26.187007 129051738551808 run.py:769] (val) algo activity_selector step 2200: {'selected': 0.8834586466165414, 'score': 0.8834586466165414, 'examples_seen': 60720, 'step': 2200, 'algorithm': 'activity_selector'}
I1006 21:56:26.187152 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.914, current avg val score is 0.883, val scores are: activity_selector: 0.883
I1006 21:56:27.067045 129051738551808 run.py:734] Algo activity_selector step 2250 current loss 1.450391, current_train_items 62080.
I1006 21:56:27.092556 129051738551808 run.py:769] (val) algo activity_selector step 2250: {'selected': 0.8803088803088803, 'score': 0.8803088803088803, 'examples_seen': 62080, 'step': 2250, 'algorithm': 'activity_selector'}
I1006 21:56:27.092714 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.914, current avg val score is 0.880, val scores are: activity_selector: 0.880
I1006 21:56:27.970386 129051738551808 run.py:734] Algo activity_selector step 2300 current loss 1.525868, current_train_items 63440.
I1006 21:56:27.994942 129051738551808 run.py:769] (val) algo activity_selector step 2300: {'selected': 0.8901098901098901, 'score': 0.8901098901098901, 'examples_seen': 63440, 'step': 2300, 'algorithm': 'activity_selector'}
I1006 21:56:27.995089 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.914, current avg val score is 0.890, val scores are: activity_selector: 0.890
I1006 21:56:28.893126 129051738551808 run.py:734] Algo activity_selector step 2350 current loss 1.367974, current_train_items 64848.
I1006 21:56:28.917007 129051738551808 run.py:769] (val) algo activity_selector step 2350: {'selected': 0.9603024574669187, 'score': 0.9603024574669187, 'examples_seen': 64848, 'step': 2350, 'algorithm': 'activity_selector'}
I1006 21:56:28.917152 129051738551808 run.py:790] Checkpointing best model, best avg val score was 0.914, current avg val score is 0.960, val scores are: activity_selector: 0.960
I1006 21:56:29.819318 129051738551808 run.py:734] Algo activity_selector step 2400 current loss 1.417551, current_train_items 66208.
I1006 21:56:29.844116 129051738551808 run.py:769] (val) algo activity_selector step 2400: {'selected': 0.8984375, 'score': 0.8984375, 'examples_seen': 66208, 'step': 2400, 'algorithm': 'activity_selector'}
I1006 21:56:29.844273 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.898, val scores are: activity_selector: 0.898
I1006 21:56:30.743850 129051738551808 run.py:734] Algo activity_selector step 2450 current loss 1.701906, current_train_items 67600.
I1006 21:56:30.768162 129051738551808 run.py:769] (val) algo activity_selector step 2450: {'selected': 0.9177330895795247, 'score': 0.9177330895795247, 'examples_seen': 67600, 'step': 2450, 'algorithm': 'activity_selector'}
I1006 21:56:30.768312 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.918, val scores are: activity_selector: 0.918
I1006 21:56:31.648386 129051738551808 run.py:734] Algo activity_selector step 2500 current loss 1.398792, current_train_items 68976.
I1006 21:56:31.672095 129051738551808 run.py:769] (val) algo activity_selector step 2500: {'selected': 0.9070631970260224, 'score': 0.9070631970260224, 'examples_seen': 68976, 'step': 2500, 'algorithm': 'activity_selector'}
I1006 21:56:31.672240 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.907, val scores are: activity_selector: 0.907
I1006 21:56:32.556437 129051738551808 run.py:734] Algo activity_selector step 2550 current loss 1.466353, current_train_items 70352.
I1006 21:56:32.581752 129051738551808 run.py:769] (val) algo activity_selector step 2550: {'selected': 0.8526522593320236, 'score': 0.8526522593320236, 'examples_seen': 70352, 'step': 2550, 'algorithm': 'activity_selector'}
I1006 21:56:32.581901 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.853, val scores are: activity_selector: 0.853
I1006 21:56:33.476338 129051738551808 run.py:734] Algo activity_selector step 2600 current loss 1.511882, current_train_items 71728.
I1006 21:56:33.500788 129051738551808 run.py:769] (val) algo activity_selector step 2600: {'selected': 0.9066666666666667, 'score': 0.9066666666666667, 'examples_seen': 71728, 'step': 2600, 'algorithm': 'activity_selector'}
I1006 21:56:33.500937 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.907, val scores are: activity_selector: 0.907
I1006 21:56:34.372133 129051738551808 run.py:734] Algo activity_selector step 2650 current loss 1.135587, current_train_items 73104.
I1006 21:56:34.397561 129051738551808 run.py:769] (val) algo activity_selector step 2650: {'selected': 0.9262759924385633, 'score': 0.9262759924385633, 'examples_seen': 73104, 'step': 2650, 'algorithm': 'activity_selector'}
I1006 21:56:34.397715 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.926, val scores are: activity_selector: 0.926
I1006 21:56:35.311384 129051738551808 run.py:734] Algo activity_selector step 2700 current loss 1.495954, current_train_items 74496.
I1006 21:56:35.335842 129051738551808 run.py:769] (val) algo activity_selector step 2700: {'selected': 0.9528985507246377, 'score': 0.9528985507246377, 'examples_seen': 74496, 'step': 2700, 'algorithm': 'activity_selector'}
I1006 21:56:35.335997 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1006 21:56:36.227445 129051738551808 run.py:734] Algo activity_selector step 2750 current loss 1.354339, current_train_items 75856.
I1006 21:56:36.251354 129051738551808 run.py:769] (val) algo activity_selector step 2750: {'selected': 0.8990476190476189, 'score': 0.8990476190476189, 'examples_seen': 75856, 'step': 2750, 'algorithm': 'activity_selector'}
I1006 21:56:36.251507 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.899, val scores are: activity_selector: 0.899
I1006 21:56:37.139727 129051738551808 run.py:734] Algo activity_selector step 2800 current loss 1.453505, current_train_items 77264.
I1006 21:56:37.164392 129051738551808 run.py:769] (val) algo activity_selector step 2800: {'selected': 0.8884462151394422, 'score': 0.8884462151394422, 'examples_seen': 77264, 'step': 2800, 'algorithm': 'activity_selector'}
I1006 21:56:37.164542 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.888, val scores are: activity_selector: 0.888
I1006 21:56:38.060877 129051738551808 run.py:734] Algo activity_selector step 2850 current loss 1.387012, current_train_items 78624.
I1006 21:56:38.085205 129051738551808 run.py:769] (val) algo activity_selector step 2850: {'selected': 0.9555125725338491, 'score': 0.9555125725338491, 'examples_seen': 78624, 'step': 2850, 'algorithm': 'activity_selector'}
I1006 21:56:38.085353 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1006 21:56:38.964747 129051738551808 run.py:734] Algo activity_selector step 2900 current loss 1.456455, current_train_items 80000.
I1006 21:56:38.989156 129051738551808 run.py:769] (val) algo activity_selector step 2900: {'selected': 0.8992248062015504, 'score': 0.8992248062015504, 'examples_seen': 80000, 'step': 2900, 'algorithm': 'activity_selector'}
I1006 21:56:38.989303 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.899, val scores are: activity_selector: 0.899
I1006 21:56:39.888507 129051738551808 run.py:734] Algo activity_selector step 2950 current loss 1.345900, current_train_items 81392.
I1006 21:56:39.915701 129051738551808 run.py:769] (val) algo activity_selector step 2950: {'selected': 0.9366602687140115, 'score': 0.9366602687140115, 'examples_seen': 81392, 'step': 2950, 'algorithm': 'activity_selector'}
I1006 21:56:39.915862 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.937, val scores are: activity_selector: 0.937
I1006 21:56:40.800182 129051738551808 run.py:734] Algo activity_selector step 3000 current loss 1.766289, current_train_items 82752.
I1006 21:56:40.824194 129051738551808 run.py:769] (val) algo activity_selector step 3000: {'selected': 0.877959927140255, 'score': 0.877959927140255, 'examples_seen': 82752, 'step': 3000, 'algorithm': 'activity_selector'}
I1006 21:56:40.824346 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.878, val scores are: activity_selector: 0.878
I1006 21:56:41.722843 129051738551808 run.py:734] Algo activity_selector step 3050 current loss 1.403993, current_train_items 84144.
I1006 21:56:41.748407 129051738551808 run.py:769] (val) algo activity_selector step 3050: {'selected': 0.8788426763110309, 'score': 0.8788426763110309, 'examples_seen': 84144, 'step': 3050, 'algorithm': 'activity_selector'}
I1006 21:56:41.748563 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.879, val scores are: activity_selector: 0.879
I1006 21:56:42.630114 129051738551808 run.py:734] Algo activity_selector step 3100 current loss 1.156693, current_train_items 85520.
I1006 21:56:42.655194 129051738551808 run.py:769] (val) algo activity_selector step 3100: {'selected': 0.8961538461538463, 'score': 0.8961538461538463, 'examples_seen': 85520, 'step': 3100, 'algorithm': 'activity_selector'}
I1006 21:56:42.655346 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.896, val scores are: activity_selector: 0.896
I1006 21:56:43.549193 129051738551808 run.py:734] Algo activity_selector step 3150 current loss 1.109474, current_train_items 86896.
I1006 21:56:43.573857 129051738551808 run.py:769] (val) algo activity_selector step 3150: {'selected': 0.9165120593692021, 'score': 0.9165120593692021, 'examples_seen': 86896, 'step': 3150, 'algorithm': 'activity_selector'}
I1006 21:56:43.574006 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.917, val scores are: activity_selector: 0.917
I1006 21:56:44.466719 129051738551808 run.py:734] Algo activity_selector step 3200 current loss 1.281940, current_train_items 88272.
I1006 21:56:44.491781 129051738551808 run.py:769] (val) algo activity_selector step 3200: {'selected': 0.9070631970260223, 'score': 0.9070631970260223, 'examples_seen': 88272, 'step': 3200, 'algorithm': 'activity_selector'}
I1006 21:56:44.491933 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.907, val scores are: activity_selector: 0.907
I1006 21:56:45.374201 129051738551808 run.py:734] Algo activity_selector step 3250 current loss 1.425632, current_train_items 89664.
I1006 21:56:45.398906 129051738551808 run.py:769] (val) algo activity_selector step 3250: {'selected': 0.9090909090909091, 'score': 0.9090909090909091, 'examples_seen': 89664, 'step': 3250, 'algorithm': 'activity_selector'}
I1006 21:56:45.399057 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.909, val scores are: activity_selector: 0.909
I1006 21:56:46.305589 129051738551808 run.py:734] Algo activity_selector step 3300 current loss 1.317335, current_train_items 91040.
I1006 21:56:46.330949 129051738551808 run.py:769] (val) algo activity_selector step 3300: {'selected': 0.9069767441860465, 'score': 0.9069767441860465, 'examples_seen': 91040, 'step': 3300, 'algorithm': 'activity_selector'}
I1006 21:56:46.331099 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.907, val scores are: activity_selector: 0.907
I1006 21:56:47.213254 129051738551808 run.py:734] Algo activity_selector step 3350 current loss 1.298808, current_train_items 92400.
I1006 21:56:47.237505 129051738551808 run.py:769] (val) algo activity_selector step 3350: {'selected': 0.9244935543278086, 'score': 0.9244935543278086, 'examples_seen': 92400, 'step': 3350, 'algorithm': 'activity_selector'}
I1006 21:56:47.237659 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.924, val scores are: activity_selector: 0.924
I1006 21:56:48.123691 129051738551808 run.py:734] Algo activity_selector step 3400 current loss 1.416871, current_train_items 93792.
I1006 21:56:48.147791 129051738551808 run.py:769] (val) algo activity_selector step 3400: {'selected': 0.9187145557655955, 'score': 0.9187145557655955, 'examples_seen': 93792, 'step': 3400, 'algorithm': 'activity_selector'}
I1006 21:56:48.147941 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.919, val scores are: activity_selector: 0.919
I1006 21:56:49.048908 129051738551808 run.py:734] Algo activity_selector step 3450 current loss 1.079213, current_train_items 95168.
I1006 21:56:49.073618 129051738551808 run.py:769] (val) algo activity_selector step 3450: {'selected': 0.9428007889546351, 'score': 0.9428007889546351, 'examples_seen': 95168, 'step': 3450, 'algorithm': 'activity_selector'}
I1006 21:56:49.073778 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1006 21:56:49.962377 129051738551808 run.py:734] Algo activity_selector step 3500 current loss 1.377672, current_train_items 96544.
I1006 21:56:49.987173 129051738551808 run.py:769] (val) algo activity_selector step 3500: {'selected': 0.9021113243761996, 'score': 0.9021113243761996, 'examples_seen': 96544, 'step': 3500, 'algorithm': 'activity_selector'}
I1006 21:56:49.987323 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.902, val scores are: activity_selector: 0.902
I1006 21:56:50.881418 129051738551808 run.py:734] Algo activity_selector step 3550 current loss 1.095296, current_train_items 97936.
I1006 21:56:50.906466 129051738551808 run.py:769] (val) algo activity_selector step 3550: {'selected': 0.9130434782608695, 'score': 0.9130434782608695, 'examples_seen': 97936, 'step': 3550, 'algorithm': 'activity_selector'}
I1006 21:56:50.906618 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.913, val scores are: activity_selector: 0.913
I1006 21:56:51.815225 129051738551808 run.py:734] Algo activity_selector step 3600 current loss 1.622110, current_train_items 99312.
I1006 21:56:51.845487 129051738551808 run.py:769] (val) algo activity_selector step 3600: {'selected': 0.911340206185567, 'score': 0.911340206185567, 'examples_seen': 99312, 'step': 3600, 'algorithm': 'activity_selector'}
I1006 21:56:51.845739 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.911, val scores are: activity_selector: 0.911
I1006 21:56:52.783278 129051738551808 run.py:734] Algo activity_selector step 3650 current loss 1.318189, current_train_items 100688.
I1006 21:56:52.808342 129051738551808 run.py:769] (val) algo activity_selector step 3650: {'selected': 0.9247706422018349, 'score': 0.9247706422018349, 'examples_seen': 100688, 'step': 3650, 'algorithm': 'activity_selector'}
I1006 21:56:52.808502 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.925, val scores are: activity_selector: 0.925
I1006 21:56:53.727024 129051738551808 run.py:734] Algo activity_selector step 3700 current loss 1.438398, current_train_items 102064.
I1006 21:56:53.752350 129051738551808 run.py:769] (val) algo activity_selector step 3700: {'selected': 0.9203187250996016, 'score': 0.9203187250996016, 'examples_seen': 102064, 'step': 3700, 'algorithm': 'activity_selector'}
I1006 21:56:53.752526 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.920, val scores are: activity_selector: 0.920
I1006 21:56:54.700473 129051738551808 run.py:734] Algo activity_selector step 3750 current loss 1.389245, current_train_items 103440.
I1006 21:56:54.728433 129051738551808 run.py:769] (val) algo activity_selector step 3750: {'selected': 0.9199255121042831, 'score': 0.9199255121042831, 'examples_seen': 103440, 'step': 3750, 'algorithm': 'activity_selector'}
I1006 21:56:54.728595 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.920, val scores are: activity_selector: 0.920
I1006 21:56:55.690367 129051738551808 run.py:734] Algo activity_selector step 3800 current loss 1.093297, current_train_items 104816.
I1006 21:56:55.716104 129051738551808 run.py:769] (val) algo activity_selector step 3800: {'selected': 0.9561904761904763, 'score': 0.9561904761904763, 'examples_seen': 104816, 'step': 3800, 'algorithm': 'activity_selector'}
I1006 21:56:55.716264 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1006 21:56:56.631015 129051738551808 run.py:734] Algo activity_selector step 3850 current loss 1.293003, current_train_items 106208.
I1006 21:56:56.655177 129051738551808 run.py:769] (val) algo activity_selector step 3850: {'selected': 0.8294434470377021, 'score': 0.8294434470377021, 'examples_seen': 106208, 'step': 3850, 'algorithm': 'activity_selector'}
I1006 21:56:56.655325 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.829, val scores are: activity_selector: 0.829
I1006 21:56:57.566707 129051738551808 run.py:734] Algo activity_selector step 3900 current loss 1.269647, current_train_items 107584.
I1006 21:56:57.591883 129051738551808 run.py:769] (val) algo activity_selector step 3900: {'selected': 0.9304029304029305, 'score': 0.9304029304029305, 'examples_seen': 107584, 'step': 3900, 'algorithm': 'activity_selector'}
I1006 21:56:57.592044 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.930, val scores are: activity_selector: 0.930
I1006 21:56:58.472858 129051738551808 run.py:734] Algo activity_selector step 3950 current loss 1.053908, current_train_items 108960.
I1006 21:56:58.496917 129051738551808 run.py:769] (val) algo activity_selector step 3950: {'selected': 0.9103690685413007, 'score': 0.9103690685413007, 'examples_seen': 108960, 'step': 3950, 'algorithm': 'activity_selector'}
I1006 21:56:58.497062 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.910, val scores are: activity_selector: 0.910
I1006 21:56:59.376364 129051738551808 run.py:734] Algo activity_selector step 4000 current loss 1.091929, current_train_items 110336.
I1006 21:56:59.401037 129051738551808 run.py:769] (val) algo activity_selector step 4000: {'selected': 0.8834586466165415, 'score': 0.8834586466165415, 'examples_seen': 110336, 'step': 4000, 'algorithm': 'activity_selector'}
I1006 21:56:59.401187 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.883, val scores are: activity_selector: 0.883
I1006 21:57:00.291597 129051738551808 run.py:734] Algo activity_selector step 4050 current loss 1.180900, current_train_items 111712.
I1006 21:57:00.315661 129051738551808 run.py:769] (val) algo activity_selector step 4050: {'selected': 0.909433962264151, 'score': 0.909433962264151, 'examples_seen': 111712, 'step': 4050, 'algorithm': 'activity_selector'}
I1006 21:57:00.315817 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.909, val scores are: activity_selector: 0.909
I1006 21:57:01.191631 129051738551808 run.py:734] Algo activity_selector step 4100 current loss 1.044948, current_train_items 113088.
I1006 21:57:01.215869 129051738551808 run.py:769] (val) algo activity_selector step 4100: {'selected': 0.9236234458259326, 'score': 0.9236234458259326, 'examples_seen': 113088, 'step': 4100, 'algorithm': 'activity_selector'}
I1006 21:57:01.216016 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.924, val scores are: activity_selector: 0.924
I1006 21:57:02.118488 129051738551808 run.py:734] Algo activity_selector step 4150 current loss 1.077291, current_train_items 114480.
I1006 21:57:02.143077 129051738551808 run.py:769] (val) algo activity_selector step 4150: {'selected': 0.9568345323741008, 'score': 0.9568345323741008, 'examples_seen': 114480, 'step': 4150, 'algorithm': 'activity_selector'}
I1006 21:57:02.143226 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.957, val scores are: activity_selector: 0.957
I1006 21:57:03.039934 129051738551808 run.py:734] Algo activity_selector step 4200 current loss 1.373742, current_train_items 115856.
I1006 21:57:03.064780 129051738551808 run.py:769] (val) algo activity_selector step 4200: {'selected': 0.9311740890688259, 'score': 0.9311740890688259, 'examples_seen': 115856, 'step': 4200, 'algorithm': 'activity_selector'}
I1006 21:57:03.064930 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1006 21:57:03.936567 129051738551808 run.py:734] Algo activity_selector step 4250 current loss 1.564170, current_train_items 117216.
I1006 21:57:03.961410 129051738551808 run.py:769] (val) algo activity_selector step 4250: {'selected': 0.931098696461825, 'score': 0.931098696461825, 'examples_seen': 117216, 'step': 4250, 'algorithm': 'activity_selector'}
I1006 21:57:03.961560 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1006 21:57:04.855525 129051738551808 run.py:734] Algo activity_selector step 4300 current loss 1.059029, current_train_items 118624.
I1006 21:57:04.879765 129051738551808 run.py:769] (val) algo activity_selector step 4300: {'selected': 0.9466192170818506, 'score': 0.9466192170818506, 'examples_seen': 118624, 'step': 4300, 'algorithm': 'activity_selector'}
I1006 21:57:04.879917 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.947, val scores are: activity_selector: 0.947
I1006 21:57:05.771597 129051738551808 run.py:734] Algo activity_selector step 4350 current loss 1.089959, current_train_items 119984.
I1006 21:57:05.795904 129051738551808 run.py:769] (val) algo activity_selector step 4350: {'selected': 0.9124767225325885, 'score': 0.9124767225325885, 'examples_seen': 119984, 'step': 4350, 'algorithm': 'activity_selector'}
I1006 21:57:05.796055 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.912, val scores are: activity_selector: 0.912
I1006 21:57:06.691488 129051738551808 run.py:734] Algo activity_selector step 4400 current loss 1.074826, current_train_items 121360.
I1006 21:57:06.715830 129051738551808 run.py:769] (val) algo activity_selector step 4400: {'selected': 0.935361216730038, 'score': 0.935361216730038, 'examples_seen': 121360, 'step': 4400, 'algorithm': 'activity_selector'}
I1006 21:57:06.715981 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.935, val scores are: activity_selector: 0.935
I1006 21:57:07.603074 129051738551808 run.py:734] Algo activity_selector step 4450 current loss 1.346173, current_train_items 122752.
I1006 21:57:07.630158 129051738551808 run.py:769] (val) algo activity_selector step 4450: {'selected': 0.9112426035502958, 'score': 0.9112426035502958, 'examples_seen': 122752, 'step': 4450, 'algorithm': 'activity_selector'}
I1006 21:57:07.630313 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.911, val scores are: activity_selector: 0.911
I1006 21:57:08.530076 129051738551808 run.py:734] Algo activity_selector step 4500 current loss 1.121072, current_train_items 124128.
I1006 21:57:08.554388 129051738551808 run.py:769] (val) algo activity_selector step 4500: {'selected': 0.9488188976377954, 'score': 0.9488188976377954, 'examples_seen': 124128, 'step': 4500, 'algorithm': 'activity_selector'}
I1006 21:57:08.554538 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.949, val scores are: activity_selector: 0.949
I1006 21:57:09.449186 129051738551808 run.py:734] Algo activity_selector step 4550 current loss 0.985410, current_train_items 125504.
I1006 21:57:09.473284 129051738551808 run.py:769] (val) algo activity_selector step 4550: {'selected': 0.903225806451613, 'score': 0.903225806451613, 'examples_seen': 125504, 'step': 4550, 'algorithm': 'activity_selector'}
I1006 21:57:09.473433 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.903, val scores are: activity_selector: 0.903
I1006 21:57:10.357334 129051738551808 run.py:734] Algo activity_selector step 4600 current loss 1.321931, current_train_items 126880.
I1006 21:57:10.381065 129051738551808 run.py:769] (val) algo activity_selector step 4600: {'selected': 0.9283018867924527, 'score': 0.9283018867924527, 'examples_seen': 126880, 'step': 4600, 'algorithm': 'activity_selector'}
I1006 21:57:10.381217 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.928, val scores are: activity_selector: 0.928
I1006 21:57:11.285730 129051738551808 run.py:734] Algo activity_selector step 4650 current loss 0.997542, current_train_items 128272.
I1006 21:57:11.309875 129051738551808 run.py:769] (val) algo activity_selector step 4650: {'selected': 0.9345454545454546, 'score': 0.9345454545454546, 'examples_seen': 128272, 'step': 4650, 'algorithm': 'activity_selector'}
I1006 21:57:11.310024 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.935, val scores are: activity_selector: 0.935
I1006 21:57:12.196147 129051738551808 run.py:734] Algo activity_selector step 4700 current loss 1.258251, current_train_items 129632.
I1006 21:57:12.221051 129051738551808 run.py:769] (val) algo activity_selector step 4700: {'selected': 0.948339483394834, 'score': 0.948339483394834, 'examples_seen': 129632, 'step': 4700, 'algorithm': 'activity_selector'}
I1006 21:57:12.221199 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1006 21:57:13.114885 129051738551808 run.py:734] Algo activity_selector step 4750 current loss 1.330029, current_train_items 131024.
I1006 21:57:13.139759 129051738551808 run.py:769] (val) algo activity_selector step 4750: {'selected': 0.9279112754158965, 'score': 0.9279112754158965, 'examples_seen': 131024, 'step': 4750, 'algorithm': 'activity_selector'}
I1006 21:57:13.139904 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.928, val scores are: activity_selector: 0.928
I1006 21:57:14.025994 129051738551808 run.py:734] Algo activity_selector step 4800 current loss 1.217117, current_train_items 132400.
I1006 21:57:14.052805 129051738551808 run.py:769] (val) algo activity_selector step 4800: {'selected': 0.9305816135084428, 'score': 0.9305816135084428, 'examples_seen': 132400, 'step': 4800, 'algorithm': 'activity_selector'}
I1006 21:57:14.052953 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1006 21:57:14.939864 129051738551808 run.py:734] Algo activity_selector step 4850 current loss 1.142779, current_train_items 133760.
I1006 21:57:14.964820 129051738551808 run.py:769] (val) algo activity_selector step 4850: {'selected': 0.8762541806020068, 'score': 0.8762541806020068, 'examples_seen': 133760, 'step': 4850, 'algorithm': 'activity_selector'}
I1006 21:57:14.964991 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.876, val scores are: activity_selector: 0.876
I1006 21:57:15.872553 129051738551808 run.py:734] Algo activity_selector step 4900 current loss 1.147100, current_train_items 135168.
I1006 21:57:15.897568 129051738551808 run.py:769] (val) algo activity_selector step 4900: {'selected': 0.9046793760831889, 'score': 0.9046793760831889, 'examples_seen': 135168, 'step': 4900, 'algorithm': 'activity_selector'}
I1006 21:57:15.897731 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.905, val scores are: activity_selector: 0.905
I1006 21:57:16.788334 129051738551808 run.py:734] Algo activity_selector step 4950 current loss 1.313743, current_train_items 136528.
I1006 21:57:16.812550 129051738551808 run.py:769] (val) algo activity_selector step 4950: {'selected': 0.9471698113207547, 'score': 0.9471698113207547, 'examples_seen': 136528, 'step': 4950, 'algorithm': 'activity_selector'}
I1006 21:57:16.812707 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.947, val scores are: activity_selector: 0.947
I1006 21:57:17.709789 129051738551808 run.py:734] Algo activity_selector step 5000 current loss 1.023348, current_train_items 137920.
I1006 21:57:17.733930 129051738551808 run.py:769] (val) algo activity_selector step 5000: {'selected': 0.8483816013628619, 'score': 0.8483816013628619, 'examples_seen': 137920, 'step': 5000, 'algorithm': 'activity_selector'}
I1006 21:57:17.734078 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.848, val scores are: activity_selector: 0.848
I1006 21:57:18.624011 129051738551808 run.py:734] Algo activity_selector step 5050 current loss 1.119861, current_train_items 139296.
I1006 21:57:18.648101 129051738551808 run.py:769] (val) algo activity_selector step 5050: {'selected': 0.9120654396728015, 'score': 0.9120654396728015, 'examples_seen': 139296, 'step': 5050, 'algorithm': 'activity_selector'}
I1006 21:57:18.648248 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.912, val scores are: activity_selector: 0.912
I1006 21:57:19.539365 129051738551808 run.py:734] Algo activity_selector step 5100 current loss 1.435268, current_train_items 140656.
I1006 21:57:19.563555 129051738551808 run.py:769] (val) algo activity_selector step 5100: {'selected': 0.8970331588132634, 'score': 0.8970331588132634, 'examples_seen': 140656, 'step': 5100, 'algorithm': 'activity_selector'}
I1006 21:57:19.563711 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.897, val scores are: activity_selector: 0.897
I1006 21:57:20.465459 129051738551808 run.py:734] Algo activity_selector step 5150 current loss 1.395540, current_train_items 142048.
I1006 21:57:20.490270 129051738551808 run.py:769] (val) algo activity_selector step 5150: {'selected': 0.8612244897959185, 'score': 0.8612244897959185, 'examples_seen': 142048, 'step': 5150, 'algorithm': 'activity_selector'}
I1006 21:57:20.490417 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.861, val scores are: activity_selector: 0.861
I1006 21:57:21.369963 129051738551808 run.py:734] Algo activity_selector step 5200 current loss 0.927818, current_train_items 143424.
I1006 21:57:21.394110 129051738551808 run.py:769] (val) algo activity_selector step 5200: {'selected': 0.9753320683111953, 'score': 0.9753320683111953, 'examples_seen': 143424, 'step': 5200, 'algorithm': 'activity_selector'}
I1006 21:57:21.394260 129051738551808 run.py:790] Checkpointing best model, best avg val score was 0.960, current avg val score is 0.975, val scores are: activity_selector: 0.975
I1006 21:57:22.302385 129051738551808 run.py:734] Algo activity_selector step 5250 current loss 1.173862, current_train_items 144816.
I1006 21:57:22.329087 129051738551808 run.py:769] (val) algo activity_selector step 5250: {'selected': 0.8950276243093922, 'score': 0.8950276243093922, 'examples_seen': 144816, 'step': 5250, 'algorithm': 'activity_selector'}
I1006 21:57:22.329236 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.895, val scores are: activity_selector: 0.895
I1006 21:57:23.204605 129051738551808 run.py:734] Algo activity_selector step 5300 current loss 1.548879, current_train_items 146176.
I1006 21:57:23.228826 129051738551808 run.py:769] (val) algo activity_selector step 5300: {'selected': 0.9117647058823529, 'score': 0.9117647058823529, 'examples_seen': 146176, 'step': 5300, 'algorithm': 'activity_selector'}
I1006 21:57:23.228973 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.912, val scores are: activity_selector: 0.912
I1006 21:57:24.106945 129051738551808 run.py:734] Algo activity_selector step 5350 current loss 1.318916, current_train_items 147584.
I1006 21:57:24.131640 129051738551808 run.py:769] (val) algo activity_selector step 5350: {'selected': 0.9046728971962616, 'score': 0.9046728971962616, 'examples_seen': 147584, 'step': 5350, 'algorithm': 'activity_selector'}
I1006 21:57:24.131804 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.905, val scores are: activity_selector: 0.905
I1006 21:57:25.028632 129051738551808 run.py:734] Algo activity_selector step 5400 current loss 1.067689, current_train_items 148944.
I1006 21:57:25.055432 129051738551808 run.py:769] (val) algo activity_selector step 5400: {'selected': 0.9425742574257426, 'score': 0.9425742574257426, 'examples_seen': 148944, 'step': 5400, 'algorithm': 'activity_selector'}
I1006 21:57:25.055581 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1006 21:57:25.938982 129051738551808 run.py:734] Algo activity_selector step 5450 current loss 1.121333, current_train_items 150304.
I1006 21:57:25.963787 129051738551808 run.py:769] (val) algo activity_selector step 5450: {'selected': 0.8726003490401396, 'score': 0.8726003490401396, 'examples_seen': 150304, 'step': 5450, 'algorithm': 'activity_selector'}
I1006 21:57:25.963936 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.873, val scores are: activity_selector: 0.873
I1006 21:57:26.870856 129051738551808 run.py:734] Algo activity_selector step 5500 current loss 1.065374, current_train_items 151712.
I1006 21:57:26.895974 129051738551808 run.py:769] (val) algo activity_selector step 5500: {'selected': 0.8928571428571428, 'score': 0.8928571428571428, 'examples_seen': 151712, 'step': 5500, 'algorithm': 'activity_selector'}
I1006 21:57:26.896122 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.893, val scores are: activity_selector: 0.893
I1006 21:57:27.792144 129051738551808 run.py:734] Algo activity_selector step 5550 current loss 1.403947, current_train_items 153072.
I1006 21:57:27.817214 129051738551808 run.py:769] (val) algo activity_selector step 5550: {'selected': 0.9471698113207546, 'score': 0.9471698113207546, 'examples_seen': 153072, 'step': 5550, 'algorithm': 'activity_selector'}
I1006 21:57:27.817375 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.947, val scores are: activity_selector: 0.947
I1006 21:57:28.738768 129051738551808 run.py:734] Algo activity_selector step 5600 current loss 0.969285, current_train_items 154464.
I1006 21:57:28.762835 129051738551808 run.py:769] (val) algo activity_selector step 5600: {'selected': 0.953125, 'score': 0.953125, 'examples_seen': 154464, 'step': 5600, 'algorithm': 'activity_selector'}
I1006 21:57:28.762995 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1006 21:57:29.662399 129051738551808 run.py:734] Algo activity_selector step 5650 current loss 0.865915, current_train_items 155840.
I1006 21:57:29.686760 129051738551808 run.py:769] (val) algo activity_selector step 5650: {'selected': 0.9198473282442747, 'score': 0.9198473282442747, 'examples_seen': 155840, 'step': 5650, 'algorithm': 'activity_selector'}
I1006 21:57:29.686913 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.920, val scores are: activity_selector: 0.920
I1006 21:57:30.578955 129051738551808 run.py:734] Algo activity_selector step 5700 current loss 0.947433, current_train_items 157216.
I1006 21:57:30.603091 129051738551808 run.py:769] (val) algo activity_selector step 5700: {'selected': 0.9577464788732394, 'score': 0.9577464788732394, 'examples_seen': 157216, 'step': 5700, 'algorithm': 'activity_selector'}
I1006 21:57:30.603245 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.958, val scores are: activity_selector: 0.958
I1006 21:57:31.524463 129051738551808 run.py:734] Algo activity_selector step 5750 current loss 1.116645, current_train_items 158592.
I1006 21:57:31.549477 129051738551808 run.py:769] (val) algo activity_selector step 5750: {'selected': 0.953781512605042, 'score': 0.953781512605042, 'examples_seen': 158592, 'step': 5750, 'algorithm': 'activity_selector'}
I1006 21:57:31.549629 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.954, val scores are: activity_selector: 0.954
I1006 21:57:32.428896 129051738551808 run.py:734] Algo activity_selector step 5800 current loss 0.964469, current_train_items 159968.
I1006 21:57:32.453837 129051738551808 run.py:769] (val) algo activity_selector step 5800: {'selected': 0.9306569343065693, 'score': 0.9306569343065693, 'examples_seen': 159968, 'step': 5800, 'algorithm': 'activity_selector'}
I1006 21:57:32.453989 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1006 21:57:33.356890 129051738551808 run.py:734] Algo activity_selector step 5850 current loss 1.073726, current_train_items 161360.
I1006 21:57:33.381344 129051738551808 run.py:769] (val) algo activity_selector step 5850: {'selected': 0.9456740442655936, 'score': 0.9456740442655936, 'examples_seen': 161360, 'step': 5850, 'algorithm': 'activity_selector'}
I1006 21:57:33.381497 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.946, val scores are: activity_selector: 0.946
I1006 21:57:34.266186 129051738551808 run.py:734] Algo activity_selector step 5900 current loss 1.191505, current_train_items 162720.
I1006 21:57:34.290762 129051738551808 run.py:769] (val) algo activity_selector step 5900: {'selected': 0.9254901960784313, 'score': 0.9254901960784313, 'examples_seen': 162720, 'step': 5900, 'algorithm': 'activity_selector'}
I1006 21:57:34.290915 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.925, val scores are: activity_selector: 0.925
I1006 21:57:35.176729 129051738551808 run.py:734] Algo activity_selector step 5950 current loss 0.902884, current_train_items 164112.
I1006 21:57:35.200870 129051738551808 run.py:769] (val) algo activity_selector step 5950: {'selected': 0.9355432780847147, 'score': 0.9355432780847147, 'examples_seen': 164112, 'step': 5950, 'algorithm': 'activity_selector'}
I1006 21:57:35.201021 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1006 21:57:36.101175 129051738551808 run.py:734] Algo activity_selector step 6000 current loss 1.055366, current_train_items 165488.
I1006 21:57:36.125305 129051738551808 run.py:769] (val) algo activity_selector step 6000: {'selected': 0.9285714285714286, 'score': 0.9285714285714286, 'examples_seen': 165488, 'step': 6000, 'algorithm': 'activity_selector'}
I1006 21:57:36.125456 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.929, val scores are: activity_selector: 0.929
I1006 21:57:37.008947 129051738551808 run.py:734] Algo activity_selector step 6050 current loss 1.320213, current_train_items 166864.
I1006 21:57:37.033158 129051738551808 run.py:769] (val) algo activity_selector step 6050: {'selected': 0.9388560157790926, 'score': 0.9388560157790926, 'examples_seen': 166864, 'step': 6050, 'algorithm': 'activity_selector'}
I1006 21:57:37.033312 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.939, val scores are: activity_selector: 0.939
I1006 21:57:37.934185 129051738551808 run.py:734] Algo activity_selector step 6100 current loss 1.050830, current_train_items 168256.
I1006 21:57:37.959116 129051738551808 run.py:769] (val) algo activity_selector step 6100: {'selected': 0.9496981891348089, 'score': 0.9496981891348089, 'examples_seen': 168256, 'step': 6100, 'algorithm': 'activity_selector'}
I1006 21:57:37.959276 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1006 21:57:38.848837 129051738551808 run.py:734] Algo activity_selector step 6150 current loss 1.591131, current_train_items 169616.
I1006 21:57:38.873316 129051738551808 run.py:769] (val) algo activity_selector step 6150: {'selected': 0.9482401656314698, 'score': 0.9482401656314698, 'examples_seen': 169616, 'step': 6150, 'algorithm': 'activity_selector'}
I1006 21:57:38.873463 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1006 21:57:39.759344 129051738551808 run.py:734] Algo activity_selector step 6200 current loss 1.271853, current_train_items 171008.
I1006 21:57:39.784485 129051738551808 run.py:769] (val) algo activity_selector step 6200: {'selected': 0.9404255319148935, 'score': 0.9404255319148935, 'examples_seen': 171008, 'step': 6200, 'algorithm': 'activity_selector'}
I1006 21:57:39.784638 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.940, val scores are: activity_selector: 0.940
I1006 21:57:40.679391 129051738551808 run.py:734] Algo activity_selector step 6250 current loss 1.239150, current_train_items 172384.
I1006 21:57:40.703992 129051738551808 run.py:769] (val) algo activity_selector step 6250: {'selected': 0.9427480916030535, 'score': 0.9427480916030535, 'examples_seen': 172384, 'step': 6250, 'algorithm': 'activity_selector'}
I1006 21:57:40.704142 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1006 21:57:41.604382 129051738551808 run.py:734] Algo activity_selector step 6300 current loss 0.883552, current_train_items 173760.
I1006 21:57:41.629195 129051738551808 run.py:769] (val) algo activity_selector step 6300: {'selected': 0.8822495606326889, 'score': 0.8822495606326889, 'examples_seen': 173760, 'step': 6300, 'algorithm': 'activity_selector'}
I1006 21:57:41.629356 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.882, val scores are: activity_selector: 0.882
I1006 21:57:42.534225 129051738551808 run.py:734] Algo activity_selector step 6350 current loss 0.948679, current_train_items 175136.
I1006 21:57:42.558436 129051738551808 run.py:769] (val) algo activity_selector step 6350: {'selected': 0.9094412331406552, 'score': 0.9094412331406552, 'examples_seen': 175136, 'step': 6350, 'algorithm': 'activity_selector'}
I1006 21:57:42.558584 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.909, val scores are: activity_selector: 0.909
I1006 21:57:43.439842 129051738551808 run.py:734] Algo activity_selector step 6400 current loss 1.271381, current_train_items 176528.
I1006 21:57:43.464428 129051738551808 run.py:769] (val) algo activity_selector step 6400: {'selected': 0.9328063241106719, 'score': 0.9328063241106719, 'examples_seen': 176528, 'step': 6400, 'algorithm': 'activity_selector'}
I1006 21:57:43.464575 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.933, val scores are: activity_selector: 0.933
I1006 21:57:44.368115 129051738551808 run.py:734] Algo activity_selector step 6450 current loss 0.916656, current_train_items 177904.
I1006 21:57:44.392390 129051738551808 run.py:769] (val) algo activity_selector step 6450: {'selected': 0.8896551724137931, 'score': 0.8896551724137931, 'examples_seen': 177904, 'step': 6450, 'algorithm': 'activity_selector'}
I1006 21:57:44.392540 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.890, val scores are: activity_selector: 0.890
I1006 21:57:45.274639 129051738551808 run.py:734] Algo activity_selector step 6500 current loss 0.972479, current_train_items 179264.
I1006 21:57:45.299871 129051738551808 run.py:769] (val) algo activity_selector step 6500: {'selected': 0.9211908931698775, 'score': 0.9211908931698775, 'examples_seen': 179264, 'step': 6500, 'algorithm': 'activity_selector'}
I1006 21:57:45.300021 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.921, val scores are: activity_selector: 0.921
I1006 21:57:46.194011 129051738551808 run.py:734] Algo activity_selector step 6550 current loss 1.057437, current_train_items 180656.
I1006 21:57:46.218595 129051738551808 run.py:769] (val) algo activity_selector step 6550: {'selected': 0.9228070175438596, 'score': 0.9228070175438596, 'examples_seen': 180656, 'step': 6550, 'algorithm': 'activity_selector'}
I1006 21:57:46.218752 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.923, val scores are: activity_selector: 0.923
I1006 21:57:47.124048 129051738551808 run.py:734] Algo activity_selector step 6600 current loss 1.347417, current_train_items 182032.
I1006 21:57:47.148587 129051738551808 run.py:769] (val) algo activity_selector step 6600: {'selected': 0.8912655971479501, 'score': 0.8912655971479501, 'examples_seen': 182032, 'step': 6600, 'algorithm': 'activity_selector'}
I1006 21:57:47.148746 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.891, val scores are: activity_selector: 0.891
I1006 21:57:48.036278 129051738551808 run.py:734] Algo activity_selector step 6650 current loss 1.329090, current_train_items 183408.
I1006 21:57:48.060724 129051738551808 run.py:769] (val) algo activity_selector step 6650: {'selected': 0.8471454880294659, 'score': 0.8471454880294659, 'examples_seen': 183408, 'step': 6650, 'algorithm': 'activity_selector'}
I1006 21:57:48.060877 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.847, val scores are: activity_selector: 0.847
I1006 21:57:48.951588 129051738551808 run.py:734] Algo activity_selector step 6700 current loss 1.035120, current_train_items 184800.
I1006 21:57:48.975955 129051738551808 run.py:769] (val) algo activity_selector step 6700: {'selected': 0.9407114624505929, 'score': 0.9407114624505929, 'examples_seen': 184800, 'step': 6700, 'algorithm': 'activity_selector'}
I1006 21:57:48.976103 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.941, val scores are: activity_selector: 0.941
I1006 21:57:49.862397 129051738551808 run.py:734] Algo activity_selector step 6750 current loss 0.966048, current_train_items 186176.
I1006 21:57:49.887064 129051738551808 run.py:769] (val) algo activity_selector step 6750: {'selected': 0.9617706237424546, 'score': 0.9617706237424546, 'examples_seen': 186176, 'step': 6750, 'algorithm': 'activity_selector'}
I1006 21:57:49.887224 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.962, val scores are: activity_selector: 0.962
I1006 21:57:50.770375 129051738551808 run.py:734] Algo activity_selector step 6800 current loss 0.902607, current_train_items 187536.
I1006 21:57:50.794842 129051738551808 run.py:769] (val) algo activity_selector step 6800: {'selected': 0.9148148148148149, 'score': 0.9148148148148149, 'examples_seen': 187536, 'step': 6800, 'algorithm': 'activity_selector'}
I1006 21:57:50.794988 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.915, val scores are: activity_selector: 0.915
I1006 21:57:51.687668 129051738551808 run.py:734] Algo activity_selector step 6850 current loss 1.006492, current_train_items 188928.
I1006 21:57:51.712030 129051738551808 run.py:769] (val) algo activity_selector step 6850: {'selected': 0.9473684210526315, 'score': 0.9473684210526315, 'examples_seen': 188928, 'step': 6850, 'algorithm': 'activity_selector'}
I1006 21:57:51.712176 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.947, val scores are: activity_selector: 0.947
I1006 21:57:52.601153 129051738551808 run.py:734] Algo activity_selector step 6900 current loss 0.958246, current_train_items 190304.
I1006 21:57:52.627015 129051738551808 run.py:769] (val) algo activity_selector step 6900: {'selected': 0.9538461538461538, 'score': 0.9538461538461538, 'examples_seen': 190304, 'step': 6900, 'algorithm': 'activity_selector'}
I1006 21:57:52.627173 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.954, val scores are: activity_selector: 0.954
I1006 21:57:53.524474 129051738551808 run.py:734] Algo activity_selector step 6950 current loss 0.846257, current_train_items 191680.
I1006 21:57:53.549404 129051738551808 run.py:769] (val) algo activity_selector step 6950: {'selected': 0.9486166007905139, 'score': 0.9486166007905139, 'examples_seen': 191680, 'step': 6950, 'algorithm': 'activity_selector'}
I1006 21:57:53.549556 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.949, val scores are: activity_selector: 0.949
I1006 21:57:54.443821 129051738551808 run.py:734] Algo activity_selector step 7000 current loss 1.269760, current_train_items 193072.
I1006 21:57:54.468662 129051738551808 run.py:769] (val) algo activity_selector step 7000: {'selected': 0.8312159709618875, 'score': 0.8312159709618875, 'examples_seen': 193072, 'step': 7000, 'algorithm': 'activity_selector'}
I1006 21:57:54.468821 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.831, val scores are: activity_selector: 0.831
I1006 21:57:55.360073 129051738551808 run.py:734] Algo activity_selector step 7050 current loss 0.838592, current_train_items 194448.
I1006 21:57:55.384203 129051738551808 run.py:769] (val) algo activity_selector step 7050: {'selected': 0.9617486338797814, 'score': 0.9617486338797814, 'examples_seen': 194448, 'step': 7050, 'algorithm': 'activity_selector'}
I1006 21:57:55.384356 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.962, val scores are: activity_selector: 0.962
I1006 21:57:56.283273 129051738551808 run.py:734] Algo activity_selector step 7100 current loss 0.964428, current_train_items 195824.
I1006 21:57:56.307175 129051738551808 run.py:769] (val) algo activity_selector step 7100: {'selected': 0.9534450651769087, 'score': 0.9534450651769087, 'examples_seen': 195824, 'step': 7100, 'algorithm': 'activity_selector'}
I1006 21:57:56.307326 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1006 21:57:57.200746 129051738551808 run.py:734] Algo activity_selector step 7150 current loss 0.964426, current_train_items 197200.
I1006 21:57:57.225068 129051738551808 run.py:769] (val) algo activity_selector step 7150: {'selected': 0.9387755102040817, 'score': 0.9387755102040817, 'examples_seen': 197200, 'step': 7150, 'algorithm': 'activity_selector'}
I1006 21:57:57.225221 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.939, val scores are: activity_selector: 0.939
I1006 21:57:58.136528 129051738551808 run.py:734] Algo activity_selector step 7200 current loss 0.937757, current_train_items 198576.
I1006 21:57:58.160670 129051738551808 run.py:769] (val) algo activity_selector step 7200: {'selected': 0.9592233009708737, 'score': 0.9592233009708737, 'examples_seen': 198576, 'step': 7200, 'algorithm': 'activity_selector'}
I1006 21:57:58.160829 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.959, val scores are: activity_selector: 0.959
I1006 21:57:59.056203 129051738551808 run.py:734] Algo activity_selector step 7250 current loss 1.027168, current_train_items 199952.
I1006 21:57:59.080329 129051738551808 run.py:769] (val) algo activity_selector step 7250: {'selected': 0.964, 'score': 0.964, 'examples_seen': 199952, 'step': 7250, 'algorithm': 'activity_selector'}
I1006 21:57:59.080482 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.975, current avg val score is 0.964, val scores are: activity_selector: 0.964
I1006 21:57:59.984564 129051738551808 run.py:734] Algo activity_selector step 7300 current loss 1.067233, current_train_items 201344.
I1006 21:58:00.010879 129051738551808 run.py:769] (val) algo activity_selector step 7300: {'selected': 0.978640776699029, 'score': 0.978640776699029, 'examples_seen': 201344, 'step': 7300, 'algorithm': 'activity_selector'}
I1006 21:58:00.011041 129051738551808 run.py:790] Checkpointing best model, best avg val score was 0.975, current avg val score is 0.979, val scores are: activity_selector: 0.979
I1006 21:58:00.931378 129051738551808 run.py:734] Algo activity_selector step 7350 current loss 1.159860, current_train_items 202720.
I1006 21:58:00.955538 129051738551808 run.py:769] (val) algo activity_selector step 7350: {'selected': 0.9508840864440078, 'score': 0.9508840864440078, 'examples_seen': 202720, 'step': 7350, 'algorithm': 'activity_selector'}
I1006 21:58:00.955695 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.951, val scores are: activity_selector: 0.951
I1006 21:58:01.840474 129051738551808 run.py:734] Algo activity_selector step 7400 current loss 1.137805, current_train_items 204080.
I1006 21:58:01.864319 129051738551808 run.py:769] (val) algo activity_selector step 7400: {'selected': 0.9469696969696969, 'score': 0.9469696969696969, 'examples_seen': 204080, 'step': 7400, 'algorithm': 'activity_selector'}
I1006 21:58:01.864467 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.947, val scores are: activity_selector: 0.947
I1006 21:58:02.763700 129051738551808 run.py:734] Algo activity_selector step 7450 current loss 1.157012, current_train_items 205488.
I1006 21:58:02.788067 129051738551808 run.py:769] (val) algo activity_selector step 7450: {'selected': 0.9437386569872959, 'score': 0.9437386569872959, 'examples_seen': 205488, 'step': 7450, 'algorithm': 'activity_selector'}
I1006 21:58:02.788217 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.944, val scores are: activity_selector: 0.944
I1006 21:58:03.688486 129051738551808 run.py:734] Algo activity_selector step 7500 current loss 0.938176, current_train_items 206848.
I1006 21:58:03.713393 129051738551808 run.py:769] (val) algo activity_selector step 7500: {'selected': 0.9674952198852772, 'score': 0.9674952198852772, 'examples_seen': 206848, 'step': 7500, 'algorithm': 'activity_selector'}
I1006 21:58:03.713555 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.967, val scores are: activity_selector: 0.967
I1006 21:58:04.615303 129051738551808 run.py:734] Algo activity_selector step 7550 current loss 0.958306, current_train_items 208224.
I1006 21:58:04.639178 129051738551808 run.py:769] (val) algo activity_selector step 7550: {'selected': 0.9534883720930233, 'score': 0.9534883720930233, 'examples_seen': 208224, 'step': 7550, 'algorithm': 'activity_selector'}
I1006 21:58:04.639334 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1006 21:58:05.534972 129051738551808 run.py:734] Algo activity_selector step 7600 current loss 0.862702, current_train_items 209616.
I1006 21:58:05.560219 129051738551808 run.py:769] (val) algo activity_selector step 7600: {'selected': 0.9507575757575758, 'score': 0.9507575757575758, 'examples_seen': 209616, 'step': 7600, 'algorithm': 'activity_selector'}
I1006 21:58:05.560370 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.951, val scores are: activity_selector: 0.951
I1006 21:58:06.456392 129051738551808 run.py:734] Algo activity_selector step 7650 current loss 1.136486, current_train_items 210976.
I1006 21:58:06.481091 129051738551808 run.py:769] (val) algo activity_selector step 7650: {'selected': 0.9031078610603291, 'score': 0.9031078610603291, 'examples_seen': 210976, 'step': 7650, 'algorithm': 'activity_selector'}
I1006 21:58:06.481241 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.903, val scores are: activity_selector: 0.903
I1006 21:58:07.390482 129051738551808 run.py:734] Algo activity_selector step 7700 current loss 1.096350, current_train_items 212368.
I1006 21:58:07.414798 129051738551808 run.py:769] (val) algo activity_selector step 7700: {'selected': 0.9222011385199241, 'score': 0.9222011385199241, 'examples_seen': 212368, 'step': 7700, 'algorithm': 'activity_selector'}
I1006 21:58:07.414949 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.922, val scores are: activity_selector: 0.922
I1006 21:58:08.316984 129051738551808 run.py:734] Algo activity_selector step 7750 current loss 1.017007, current_train_items 213744.
I1006 21:58:08.341471 129051738551808 run.py:769] (val) algo activity_selector step 7750: {'selected': 0.9547169811320755, 'score': 0.9547169811320755, 'examples_seen': 213744, 'step': 7750, 'algorithm': 'activity_selector'}
I1006 21:58:08.341622 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.955, val scores are: activity_selector: 0.955
I1006 21:58:09.244357 129051738551808 run.py:734] Algo activity_selector step 7800 current loss 0.931580, current_train_items 215136.
I1006 21:58:09.268895 129051738551808 run.py:769] (val) algo activity_selector step 7800: {'selected': 0.9389312977099237, 'score': 0.9389312977099237, 'examples_seen': 215136, 'step': 7800, 'algorithm': 'activity_selector'}
I1006 21:58:09.269044 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.939, val scores are: activity_selector: 0.939
I1006 21:58:10.161338 129051738551808 run.py:734] Algo activity_selector step 7850 current loss 0.987229, current_train_items 216496.
I1006 21:58:10.189780 129051738551808 run.py:769] (val) algo activity_selector step 7850: {'selected': 0.961089494163424, 'score': 0.961089494163424, 'examples_seen': 216496, 'step': 7850, 'algorithm': 'activity_selector'}
I1006 21:58:10.189934 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.961, val scores are: activity_selector: 0.961
I1006 21:58:11.079311 129051738551808 run.py:734] Algo activity_selector step 7900 current loss 0.785356, current_train_items 217888.
I1006 21:58:11.103802 129051738551808 run.py:769] (val) algo activity_selector step 7900: {'selected': 0.9316081330868763, 'score': 0.9316081330868763, 'examples_seen': 217888, 'step': 7900, 'algorithm': 'activity_selector'}
I1006 21:58:11.103964 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.932, val scores are: activity_selector: 0.932
I1006 21:58:12.015506 129051738551808 run.py:734] Algo activity_selector step 7950 current loss 0.888934, current_train_items 219264.
I1006 21:58:12.040220 129051738551808 run.py:769] (val) algo activity_selector step 7950: {'selected': 0.9473684210526315, 'score': 0.9473684210526315, 'examples_seen': 219264, 'step': 7950, 'algorithm': 'activity_selector'}
I1006 21:58:12.040387 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.947, val scores are: activity_selector: 0.947
I1006 21:58:12.936654 129051738551808 run.py:734] Algo activity_selector step 8000 current loss 0.948127, current_train_items 220624.
I1006 21:58:12.960825 129051738551808 run.py:769] (val) algo activity_selector step 8000: {'selected': 0.9716446124763706, 'score': 0.9716446124763706, 'examples_seen': 220624, 'step': 8000, 'algorithm': 'activity_selector'}
I1006 21:58:12.960990 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.972, val scores are: activity_selector: 0.972
I1006 21:58:13.893946 129051738551808 run.py:734] Algo activity_selector step 8050 current loss 1.032331, current_train_items 222032.
I1006 21:58:13.918925 129051738551808 run.py:769] (val) algo activity_selector step 8050: {'selected': 0.9302325581395349, 'score': 0.9302325581395349, 'examples_seen': 222032, 'step': 8050, 'algorithm': 'activity_selector'}
I1006 21:58:13.919073 129051738551808 run.py:790] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.930, val scores are: activity_selector: 0.930
I1006 21:58:14.827932 129051738551808 run.py:734] Algo activity_selector step 8100 current loss 0.954601, current_train_items 223392.
I1006 21:58:14.852603 129051738551808 run.py:769] (val) algo activity_selector step 8100: {'selected': 0.9153846153846155, 'score': 0.9153846153846155, 'examples_seen': 223392, 'step': 8100, 'algorithm': 'activity_selector'}
I1006 21:58:14.852759 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.930, current avg val score is 0.915, val scores are: activity_selector: 0.915
I1006 21:58:15.740910 129051738551808 run.py:734] Algo activity_selector step 8150 current loss 1.157034, current_train_items 224784.
I1006 21:58:15.764694 129051738551808 run.py:769] (val) algo activity_selector step 8150: {'selected': 0.931237721021611, 'score': 0.931237721021611, 'examples_seen': 224784, 'step': 8150, 'algorithm': 'activity_selector'}
I1006 21:58:15.764842 129051738551808 run.py:790] Checkpointing best model, best avg val score was 0.930, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1006 21:58:16.662661 129051738551808 run.py:734] Algo activity_selector step 8200 current loss 0.939080, current_train_items 226160.
I1006 21:58:16.687347 129051738551808 run.py:769] (val) algo activity_selector step 8200: {'selected': 0.9555555555555556, 'score': 0.9555555555555556, 'examples_seen': 226160, 'step': 8200, 'algorithm': 'activity_selector'}
I1006 21:58:16.687498 129051738551808 run.py:790] Checkpointing best model, best avg val score was 0.931, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1006 21:58:17.571959 129051738551808 run.py:734] Algo activity_selector step 8250 current loss 0.911575, current_train_items 227520.
I1006 21:58:17.596720 129051738551808 run.py:769] (val) algo activity_selector step 8250: {'selected': 0.920152091254753, 'score': 0.920152091254753, 'examples_seen': 227520, 'step': 8250, 'algorithm': 'activity_selector'}
I1006 21:58:17.596870 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.920, val scores are: activity_selector: 0.920
I1006 21:58:18.499432 129051738551808 run.py:734] Algo activity_selector step 8300 current loss 1.077661, current_train_items 228912.
I1006 21:58:18.524383 129051738551808 run.py:769] (val) algo activity_selector step 8300: {'selected': 0.9407265774378585, 'score': 0.9407265774378585, 'examples_seen': 228912, 'step': 8300, 'algorithm': 'activity_selector'}
I1006 21:58:18.524530 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.941, val scores are: activity_selector: 0.941
I1006 21:58:19.403517 129051738551808 run.py:734] Algo activity_selector step 8350 current loss 0.773825, current_train_items 230288.
I1006 21:58:19.428091 129051738551808 run.py:769] (val) algo activity_selector step 8350: {'selected': 0.949640287769784, 'score': 0.949640287769784, 'examples_seen': 230288, 'step': 8350, 'algorithm': 'activity_selector'}
I1006 21:58:19.428240 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1006 21:58:20.331065 129051738551808 run.py:734] Algo activity_selector step 8400 current loss 0.828592, current_train_items 231680.
I1006 21:58:20.354957 129051738551808 run.py:769] (val) algo activity_selector step 8400: {'selected': 0.9477756286266925, 'score': 0.9477756286266925, 'examples_seen': 231680, 'step': 8400, 'algorithm': 'activity_selector'}
I1006 21:58:20.355106 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1006 21:58:21.247262 129051738551808 run.py:734] Algo activity_selector step 8450 current loss 1.020599, current_train_items 233040.
I1006 21:58:21.273877 129051738551808 run.py:769] (val) algo activity_selector step 8450: {'selected': 0.9090909090909092, 'score': 0.9090909090909092, 'examples_seen': 233040, 'step': 8450, 'algorithm': 'activity_selector'}
I1006 21:58:21.274028 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.909, val scores are: activity_selector: 0.909
I1006 21:58:22.155018 129051738551808 run.py:734] Algo activity_selector step 8500 current loss 1.131996, current_train_items 234432.
I1006 21:58:22.179918 129051738551808 run.py:769] (val) algo activity_selector step 8500: {'selected': 0.9439071566731141, 'score': 0.9439071566731141, 'examples_seen': 234432, 'step': 8500, 'algorithm': 'activity_selector'}
I1006 21:58:22.180068 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.944, val scores are: activity_selector: 0.944
I1006 21:58:23.082824 129051738551808 run.py:734] Algo activity_selector step 8550 current loss 0.755766, current_train_items 235808.
I1006 21:58:23.107553 129051738551808 run.py:769] (val) algo activity_selector step 8550: {'selected': 0.9176029962546817, 'score': 0.9176029962546817, 'examples_seen': 235808, 'step': 8550, 'algorithm': 'activity_selector'}
I1006 21:58:23.107708 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.918, val scores are: activity_selector: 0.918
I1006 21:58:23.988088 129051738551808 run.py:734] Algo activity_selector step 8600 current loss 0.695851, current_train_items 237168.
I1006 21:58:24.015296 129051738551808 run.py:769] (val) algo activity_selector step 8600: {'selected': 0.9215686274509804, 'score': 0.9215686274509804, 'examples_seen': 237168, 'step': 8600, 'algorithm': 'activity_selector'}
I1006 21:58:24.015445 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.922, val scores are: activity_selector: 0.922
I1006 21:58:24.912860 129051738551808 run.py:734] Algo activity_selector step 8650 current loss 0.954420, current_train_items 238576.
I1006 21:58:24.937375 129051738551808 run.py:769] (val) algo activity_selector step 8650: {'selected': 0.9027237354085603, 'score': 0.9027237354085603, 'examples_seen': 238576, 'step': 8650, 'algorithm': 'activity_selector'}
I1006 21:58:24.937539 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.903, val scores are: activity_selector: 0.903
I1006 21:58:25.823223 129051738551808 run.py:734] Algo activity_selector step 8700 current loss 1.135302, current_train_items 239936.
I1006 21:58:25.848182 129051738551808 run.py:769] (val) algo activity_selector step 8700: {'selected': 0.9530685920577617, 'score': 0.9530685920577617, 'examples_seen': 239936, 'step': 8700, 'algorithm': 'activity_selector'}
I1006 21:58:25.848329 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1006 21:58:26.743465 129051738551808 run.py:734] Algo activity_selector step 8750 current loss 1.062830, current_train_items 241328.
I1006 21:58:26.768469 129051738551808 run.py:769] (val) algo activity_selector step 8750: {'selected': 0.943609022556391, 'score': 0.943609022556391, 'examples_seen': 241328, 'step': 8750, 'algorithm': 'activity_selector'}
I1006 21:58:26.768616 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.944, val scores are: activity_selector: 0.944
I1006 21:58:27.659434 129051738551808 run.py:734] Algo activity_selector step 8800 current loss 0.764319, current_train_items 242704.
I1006 21:58:27.683812 129051738551808 run.py:769] (val) algo activity_selector step 8800: {'selected': 0.8897058823529412, 'score': 0.8897058823529412, 'examples_seen': 242704, 'step': 8800, 'algorithm': 'activity_selector'}
I1006 21:58:27.683962 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.890, val scores are: activity_selector: 0.890
I1006 21:58:28.570190 129051738551808 run.py:734] Algo activity_selector step 8850 current loss 1.060583, current_train_items 244080.
I1006 21:58:28.594438 129051738551808 run.py:769] (val) algo activity_selector step 8850: {'selected': 0.9233576642335767, 'score': 0.9233576642335767, 'examples_seen': 244080, 'step': 8850, 'algorithm': 'activity_selector'}
I1006 21:58:28.594586 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.923, val scores are: activity_selector: 0.923
I1006 21:58:29.492542 129051738551808 run.py:734] Algo activity_selector step 8900 current loss 0.993577, current_train_items 245456.
I1006 21:58:29.517694 129051738551808 run.py:769] (val) algo activity_selector step 8900: {'selected': 0.8795411089866156, 'score': 0.8795411089866156, 'examples_seen': 245456, 'step': 8900, 'algorithm': 'activity_selector'}
I1006 21:58:29.517853 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.880, val scores are: activity_selector: 0.880
I1006 21:58:30.405166 129051738551808 run.py:734] Algo activity_selector step 8950 current loss 0.932974, current_train_items 246832.
I1006 21:58:30.430891 129051738551808 run.py:769] (val) algo activity_selector step 8950: {'selected': 0.9067641681901281, 'score': 0.9067641681901281, 'examples_seen': 246832, 'step': 8950, 'algorithm': 'activity_selector'}
I1006 21:58:30.431040 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.907, val scores are: activity_selector: 0.907
I1006 21:58:31.333244 129051738551808 run.py:734] Algo activity_selector step 9000 current loss 1.006335, current_train_items 248224.
I1006 21:58:31.358543 129051738551808 run.py:769] (val) algo activity_selector step 9000: {'selected': 0.9398496240601503, 'score': 0.9398496240601503, 'examples_seen': 248224, 'step': 9000, 'algorithm': 'activity_selector'}
I1006 21:58:31.358703 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.940, val scores are: activity_selector: 0.940
I1006 21:58:32.241056 129051738551808 run.py:734] Algo activity_selector step 9050 current loss 0.964634, current_train_items 249584.
I1006 21:58:32.264986 129051738551808 run.py:769] (val) algo activity_selector step 9050: {'selected': 0.9027522935779817, 'score': 0.9027522935779817, 'examples_seen': 249584, 'step': 9050, 'algorithm': 'activity_selector'}
I1006 21:58:32.265141 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.903, val scores are: activity_selector: 0.903
I1006 21:58:33.156211 129051738551808 run.py:734] Algo activity_selector step 9100 current loss 1.192289, current_train_items 250976.
I1006 21:58:33.180031 129051738551808 run.py:769] (val) algo activity_selector step 9100: {'selected': 0.8987108655616943, 'score': 0.8987108655616943, 'examples_seen': 250976, 'step': 9100, 'algorithm': 'activity_selector'}
I1006 21:58:33.180180 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.899, val scores are: activity_selector: 0.899
I1006 21:58:34.077772 129051738551808 run.py:734] Algo activity_selector step 9150 current loss 0.863890, current_train_items 252352.
I1006 21:58:34.101675 129051738551808 run.py:769] (val) algo activity_selector step 9150: {'selected': 0.9485714285714286, 'score': 0.9485714285714286, 'examples_seen': 252352, 'step': 9150, 'algorithm': 'activity_selector'}
I1006 21:58:34.101830 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.949, val scores are: activity_selector: 0.949
I1006 21:58:34.984794 129051738551808 run.py:734] Algo activity_selector step 9200 current loss 0.875894, current_train_items 253728.
I1006 21:58:35.009445 129051738551808 run.py:769] (val) algo activity_selector step 9200: {'selected': 0.949343339587242, 'score': 0.949343339587242, 'examples_seen': 253728, 'step': 9200, 'algorithm': 'activity_selector'}
I1006 21:58:35.009596 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.949, val scores are: activity_selector: 0.949
I1006 21:58:35.907846 129051738551808 run.py:734] Algo activity_selector step 9250 current loss 0.849515, current_train_items 255120.
I1006 21:58:35.931875 129051738551808 run.py:769] (val) algo activity_selector step 9250: {'selected': 0.9378531073446328, 'score': 0.9378531073446328, 'examples_seen': 255120, 'step': 9250, 'algorithm': 'activity_selector'}
I1006 21:58:35.932027 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.938, val scores are: activity_selector: 0.938
I1006 21:58:36.820705 129051738551808 run.py:734] Algo activity_selector step 9300 current loss 0.871682, current_train_items 256480.
I1006 21:58:36.844859 129051738551808 run.py:769] (val) algo activity_selector step 9300: {'selected': 0.9318996415770608, 'score': 0.9318996415770608, 'examples_seen': 256480, 'step': 9300, 'algorithm': 'activity_selector'}
I1006 21:58:36.845012 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.932, val scores are: activity_selector: 0.932
I1006 21:58:37.733311 129051738551808 run.py:734] Algo activity_selector step 9350 current loss 1.060819, current_train_items 257856.
I1006 21:58:37.757598 129051738551808 run.py:769] (val) algo activity_selector step 9350: {'selected': 0.955223880597015, 'score': 0.955223880597015, 'examples_seen': 257856, 'step': 9350, 'algorithm': 'activity_selector'}
I1006 21:58:37.757756 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.955, val scores are: activity_selector: 0.955
I1006 21:58:38.654749 129051738551808 run.py:734] Algo activity_selector step 9400 current loss 0.798238, current_train_items 259248.
I1006 21:58:38.679542 129051738551808 run.py:769] (val) algo activity_selector step 9400: {'selected': 0.9260563380281691, 'score': 0.9260563380281691, 'examples_seen': 259248, 'step': 9400, 'algorithm': 'activity_selector'}
I1006 21:58:38.679701 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.926, val scores are: activity_selector: 0.926
I1006 21:58:39.573076 129051738551808 run.py:734] Algo activity_selector step 9450 current loss 0.847938, current_train_items 260624.
I1006 21:58:39.597284 129051738551808 run.py:769] (val) algo activity_selector step 9450: {'selected': 0.951167728237792, 'score': 0.951167728237792, 'examples_seen': 260624, 'step': 9450, 'algorithm': 'activity_selector'}
I1006 21:58:39.597433 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.951, val scores are: activity_selector: 0.951
I1006 21:58:40.493574 129051738551808 run.py:734] Algo activity_selector step 9500 current loss 0.853588, current_train_items 262000.
I1006 21:58:40.517973 129051738551808 run.py:769] (val) algo activity_selector step 9500: {'selected': 0.8981818181818182, 'score': 0.8981818181818182, 'examples_seen': 262000, 'step': 9500, 'algorithm': 'activity_selector'}
I1006 21:58:40.518135 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.898, val scores are: activity_selector: 0.898
I1006 21:58:41.404194 129051738551808 run.py:734] Algo activity_selector step 9550 current loss 0.683482, current_train_items 263392.
I1006 21:58:41.427915 129051738551808 run.py:769] (val) algo activity_selector step 9550: {'selected': 0.936, 'score': 0.936, 'examples_seen': 263392, 'step': 9550, 'algorithm': 'activity_selector'}
I1006 21:58:41.428063 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1006 21:58:42.325632 129051738551808 run.py:734] Algo activity_selector step 9600 current loss 1.091156, current_train_items 264768.
I1006 21:58:42.349582 129051738551808 run.py:769] (val) algo activity_selector step 9600: {'selected': 0.9295774647887325, 'score': 0.9295774647887325, 'examples_seen': 264768, 'step': 9600, 'algorithm': 'activity_selector'}
I1006 21:58:42.349747 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.930, val scores are: activity_selector: 0.930
I1006 21:58:43.244207 129051738551808 run.py:734] Algo activity_selector step 9650 current loss 1.031739, current_train_items 266128.
I1006 21:58:43.268408 129051738551808 run.py:769] (val) algo activity_selector step 9650: {'selected': 0.9368029739776953, 'score': 0.9368029739776953, 'examples_seen': 266128, 'step': 9650, 'algorithm': 'activity_selector'}
I1006 21:58:43.268563 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.956, current avg val score is 0.937, val scores are: activity_selector: 0.937
I1006 21:58:44.157649 129051738551808 run.py:734] Algo activity_selector step 9700 current loss 0.763000, current_train_items 267520.
I1006 21:58:44.182147 129051738551808 run.py:769] (val) algo activity_selector step 9700: {'selected': 0.9603024574669187, 'score': 0.9603024574669187, 'examples_seen': 267520, 'step': 9700, 'algorithm': 'activity_selector'}
I1006 21:58:44.182296 129051738551808 run.py:790] Checkpointing best model, best avg val score was 0.956, current avg val score is 0.960, val scores are: activity_selector: 0.960
I1006 21:58:45.097825 129051738551808 run.py:734] Algo activity_selector step 9750 current loss 1.148298, current_train_items 268896.
I1006 21:58:45.122938 129051738551808 run.py:769] (val) algo activity_selector step 9750: {'selected': 0.9421487603305786, 'score': 0.9421487603305786, 'examples_seen': 268896, 'step': 9750, 'algorithm': 'activity_selector'}
I1006 21:58:45.123089 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1006 21:58:46.032662 129051738551808 run.py:734] Algo activity_selector step 9800 current loss 0.925304, current_train_items 270272.
I1006 21:58:46.056690 129051738551808 run.py:769] (val) algo activity_selector step 9800: {'selected': 0.9453860640301317, 'score': 0.9453860640301317, 'examples_seen': 270272, 'step': 9800, 'algorithm': 'activity_selector'}
I1006 21:58:46.056853 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.945, val scores are: activity_selector: 0.945
I1006 21:58:46.949792 129051738551808 run.py:734] Algo activity_selector step 9850 current loss 0.844828, current_train_items 271664.
I1006 21:58:46.973780 129051738551808 run.py:769] (val) algo activity_selector step 9850: {'selected': 0.9402985074626866, 'score': 0.9402985074626866, 'examples_seen': 271664, 'step': 9850, 'algorithm': 'activity_selector'}
I1006 21:58:46.973935 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.940, val scores are: activity_selector: 0.940
I1006 21:58:47.862209 129051738551808 run.py:734] Algo activity_selector step 9900 current loss 0.764901, current_train_items 273040.
I1006 21:58:47.886787 129051738551808 run.py:769] (val) algo activity_selector step 9900: {'selected': 0.9064220183486238, 'score': 0.9064220183486238, 'examples_seen': 273040, 'step': 9900, 'algorithm': 'activity_selector'}
I1006 21:58:47.886938 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.906, val scores are: activity_selector: 0.906
I1006 21:58:48.778456 129051738551808 run.py:734] Algo activity_selector step 9950 current loss 0.767742, current_train_items 274400.
I1006 21:58:48.803019 129051738551808 run.py:769] (val) algo activity_selector step 9950: {'selected': 0.9439071566731141, 'score': 0.9439071566731141, 'examples_seen': 274400, 'step': 9950, 'algorithm': 'activity_selector'}
I1006 21:58:48.803170 129051738551808 run.py:793] Not saving new best model, best avg val score was 0.960, current avg val score is 0.944, val scores are: activity_selector: 0.944
I1006 21:58:49.683226 129051738551808 run.py:799] Restoring best model from checkpoint...
I1006 21:58:54.084500 129051738551808 run.py:814] (test) algo activity_selector : {'selected': 0.8128342245989305, 'score': 0.8128342245989305, 'examples_seen': 275760, 'step': 10000, 'algorithm': 'activity_selector'}
I1006 21:58:54.084628 129051738551808 run.py:816] Done!
