I0828 20:15:51.846146 129822405686784 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0828 20:15:51.846776 129822405686784 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0828 20:15:52.067137 129822405686784 run.py:412] Model: f4 ['activity_selector']
I0828 20:15:52.067238 129822405686784 run.py:414] algorithms ['activity_selector']
I0828 20:15:52.067409 129822405686784 run.py:415] train_lengths ['4', '7', '11', '13', '16']
I0828 20:15:52.067445 129822405686784 run.py:416] train_batch_size 16
I0828 20:15:52.067542 129822405686784 run.py:417] val_batch_size 16
I0828 20:15:52.067574 129822405686784 run.py:418] test_batch_size 16
I0828 20:15:52.067603 129822405686784 run.py:419] chunked_training True
I0828 20:15:52.067720 129822405686784 run.py:420] chunk_length 8
I0828 20:15:52.067751 129822405686784 run.py:421] train_steps 10000
I0828 20:15:52.067781 129822405686784 run.py:422] eval_every 50
I0828 20:15:52.067810 129822405686784 run.py:423] test_every 500
I0828 20:15:52.067841 129822405686784 run.py:424] hidden_size 128
I0828 20:15:52.067869 129822405686784 run.py:425] nb_msg_passing_steps 1
I0828 20:15:52.067897 129822405686784 run.py:426] learning_rate 0.001
I0828 20:15:52.067985 129822405686784 run.py:427] grad_clip_max_norm 1.0
I0828 20:15:52.068017 129822405686784 run.py:428] dropout_prob 0.0
I0828 20:15:52.068053 129822405686784 run.py:429] hint_teacher_forcing 0.0
I0828 20:15:52.068083 129822405686784 run.py:430] hint_mode encoded_decoded
I0828 20:15:52.068187 129822405686784 run.py:431] hint_repred_mode soft
I0828 20:15:52.068218 129822405686784 run.py:432] use_ln False
I0828 20:15:52.068247 129822405686784 run.py:433] use_lstm True
I0828 20:15:52.068274 129822405686784 run.py:434] nb_triplet_fts 8
I0828 20:15:52.068301 129822405686784 run.py:435] encoder_init xavier_on_scalars
I0828 20:15:52.068328 129822405686784 run.py:436] processor_type f4
I0828 20:15:52.068357 129822405686784 run.py:437] checkpoint_path CLRS30
I0828 20:15:52.068387 129822405686784 run.py:438] dataset_path CLRS30
I0828 20:15:52.068416 129822405686784 run.py:439] freeze_processor False
I0828 20:15:52.068444 129822405686784 run.py:440] reduction min
I0828 20:15:52.068472 129822405686784 run.py:441] activation elu
I0828 20:15:52.068500 129822405686784 run.py:442] restore_model 
I0828 20:15:52.068527 129822405686784 run.py:443] gated False
I0828 20:15:52.068557 129822405686784 run.py:444] gated_activation sigmoid
I0828 20:15:52.071203 129822405686784 run.py:470] Creating samplers for algo activity_selector
W0828 20:15:52.071387 129822405686784 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0828 20:15:52.071638 129822405686784 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0828 20:15:52.289475 129822405686784 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0828 20:15:52.538043 129822405686784 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0828 20:15:52.839017 129822405686784 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0828 20:15:53.188207 129822405686784 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0828 20:15:53.569752 129822405686784 samplers.py:299] Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0828 20:15:53.570079 129822405686784 samplers.py:124] Creating a dataset with 64 samples.
I0828 20:15:53.596173 129822405686784 run.py:256] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0828 20:15:53.597003 129822405686784 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0828 20:15:53.599952 129822405686784 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0828 20:15:53.603900 129822405686784 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0828 20:15:53.655294 129822405686784 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W0828 20:15:53.676055 129822405686784 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x76121dd6b920> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0828 20:16:16.684238 129822405686784 run.py:693] Algo activity_selector step 0 current loss 5.270394, current_train_items 16.
I0828 20:16:19.240496 129822405686784 run.py:728] (val) algo activity_selector step 0: {'selected': 0.0, 'score': 0.0, 'examples_seen': 16, 'step': 0, 'algorithm': 'activity_selector'}
I0828 20:16:19.240699 129822405686784 run.py:749] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.000, val scores are: activity_selector: 0.000
I0828 20:16:50.945519 129822405686784 run.py:693] Algo activity_selector step 50 current loss 3.829941, current_train_items 720.
I0828 20:16:50.961174 129822405686784 run.py:728] (val) algo activity_selector step 50: {'selected': 0.65149359886202, 'score': 0.65149359886202, 'examples_seen': 720, 'step': 50, 'algorithm': 'activity_selector'}
I0828 20:16:50.961330 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.000, current avg val score is 0.651, val scores are: activity_selector: 0.651
I0828 20:16:51.477238 129822405686784 run.py:693] Algo activity_selector step 100 current loss 3.802608, current_train_items 1408.
I0828 20:16:51.492675 129822405686784 run.py:728] (val) algo activity_selector step 100: {'selected': 0.6862745098039215, 'score': 0.6862745098039215, 'examples_seen': 1408, 'step': 100, 'algorithm': 'activity_selector'}
I0828 20:16:51.492830 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.651, current avg val score is 0.686, val scores are: activity_selector: 0.686
I0828 20:16:52.028854 129822405686784 run.py:693] Algo activity_selector step 150 current loss 3.445013, current_train_items 2080.
I0828 20:16:52.046250 129822405686784 run.py:728] (val) algo activity_selector step 150: {'selected': 0.5613207547169811, 'score': 0.5613207547169811, 'examples_seen': 2080, 'step': 150, 'algorithm': 'activity_selector'}
I0828 20:16:52.046397 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.686, current avg val score is 0.561, val scores are: activity_selector: 0.561
I0828 20:16:52.589647 129822405686784 run.py:693] Algo activity_selector step 200 current loss 3.343461, current_train_items 2784.
I0828 20:16:52.604708 129822405686784 run.py:728] (val) algo activity_selector step 200: {'selected': 0.7070707070707071, 'score': 0.7070707070707071, 'examples_seen': 2784, 'step': 200, 'algorithm': 'activity_selector'}
I0828 20:16:52.604852 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.686, current avg val score is 0.707, val scores are: activity_selector: 0.707
I0828 20:16:53.122907 129822405686784 run.py:693] Algo activity_selector step 250 current loss 3.054151, current_train_items 3488.
I0828 20:16:53.137762 129822405686784 run.py:728] (val) algo activity_selector step 250: {'selected': 0.7332053742802304, 'score': 0.7332053742802304, 'examples_seen': 3488, 'step': 250, 'algorithm': 'activity_selector'}
I0828 20:16:53.137909 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.707, current avg val score is 0.733, val scores are: activity_selector: 0.733
I0828 20:16:53.666702 129822405686784 run.py:693] Algo activity_selector step 300 current loss 2.986005, current_train_items 4144.
I0828 20:16:53.681236 129822405686784 run.py:728] (val) algo activity_selector step 300: {'selected': 0.6847599164926931, 'score': 0.6847599164926931, 'examples_seen': 4144, 'step': 300, 'algorithm': 'activity_selector'}
I0828 20:16:53.681381 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.733, current avg val score is 0.685, val scores are: activity_selector: 0.685
I0828 20:16:54.205577 129822405686784 run.py:693] Algo activity_selector step 350 current loss 2.400920, current_train_items 4848.
I0828 20:16:54.220888 129822405686784 run.py:728] (val) algo activity_selector step 350: {'selected': 0.692967409948542, 'score': 0.692967409948542, 'examples_seen': 4848, 'step': 350, 'algorithm': 'activity_selector'}
I0828 20:16:54.221042 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.733, current avg val score is 0.693, val scores are: activity_selector: 0.693
I0828 20:16:54.747809 129822405686784 run.py:693] Algo activity_selector step 400 current loss 2.826825, current_train_items 5552.
I0828 20:16:54.763193 129822405686784 run.py:728] (val) algo activity_selector step 400: {'selected': 0.7358834244080146, 'score': 0.7358834244080146, 'examples_seen': 5552, 'step': 400, 'algorithm': 'activity_selector'}
I0828 20:16:54.763339 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.733, current avg val score is 0.736, val scores are: activity_selector: 0.736
I0828 20:16:55.287472 129822405686784 run.py:693] Algo activity_selector step 450 current loss 1.872969, current_train_items 6224.
I0828 20:16:55.303019 129822405686784 run.py:728] (val) algo activity_selector step 450: {'selected': 0.6990654205607477, 'score': 0.6990654205607477, 'examples_seen': 6224, 'step': 450, 'algorithm': 'activity_selector'}
I0828 20:16:55.303174 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.736, current avg val score is 0.699, val scores are: activity_selector: 0.699
I0828 20:16:55.835224 129822405686784 run.py:693] Algo activity_selector step 500 current loss 2.212220, current_train_items 6912.
I0828 20:16:55.850336 129822405686784 run.py:728] (val) algo activity_selector step 500: {'selected': 0.7576923076923077, 'score': 0.7576923076923077, 'examples_seen': 6912, 'step': 500, 'algorithm': 'activity_selector'}
I0828 20:16:55.850484 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.736, current avg val score is 0.758, val scores are: activity_selector: 0.758
I0828 20:16:56.385150 129822405686784 run.py:693] Algo activity_selector step 550 current loss 1.875448, current_train_items 7616.
I0828 20:16:56.400148 129822405686784 run.py:728] (val) algo activity_selector step 550: {'selected': 0.732824427480916, 'score': 0.732824427480916, 'examples_seen': 7616, 'step': 550, 'algorithm': 'activity_selector'}
I0828 20:16:56.400296 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.758, current avg val score is 0.733, val scores are: activity_selector: 0.733
I0828 20:16:56.917381 129822405686784 run.py:693] Algo activity_selector step 600 current loss 1.903850, current_train_items 8288.
I0828 20:16:56.932440 129822405686784 run.py:728] (val) algo activity_selector step 600: {'selected': 0.7582417582417582, 'score': 0.7582417582417582, 'examples_seen': 8288, 'step': 600, 'algorithm': 'activity_selector'}
I0828 20:16:56.932599 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.758, current avg val score is 0.758, val scores are: activity_selector: 0.758
I0828 20:16:57.467118 129822405686784 run.py:693] Algo activity_selector step 650 current loss 2.095898, current_train_items 8976.
I0828 20:16:57.481622 129822405686784 run.py:728] (val) algo activity_selector step 650: {'selected': 0.7228915662650602, 'score': 0.7228915662650602, 'examples_seen': 8976, 'step': 650, 'algorithm': 'activity_selector'}
I0828 20:16:57.481779 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.758, current avg val score is 0.723, val scores are: activity_selector: 0.723
I0828 20:16:57.999728 129822405686784 run.py:693] Algo activity_selector step 700 current loss 1.715466, current_train_items 9680.
I0828 20:16:58.014876 129822405686784 run.py:728] (val) algo activity_selector step 700: {'selected': 0.7392055267702935, 'score': 0.7392055267702935, 'examples_seen': 9680, 'step': 700, 'algorithm': 'activity_selector'}
I0828 20:16:58.015021 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.758, current avg val score is 0.739, val scores are: activity_selector: 0.739
I0828 20:16:58.540620 129822405686784 run.py:693] Algo activity_selector step 750 current loss 1.736942, current_train_items 10368.
I0828 20:16:58.555481 129822405686784 run.py:728] (val) algo activity_selector step 750: {'selected': 0.7213740458015268, 'score': 0.7213740458015268, 'examples_seen': 10368, 'step': 750, 'algorithm': 'activity_selector'}
I0828 20:16:58.555627 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.758, current avg val score is 0.721, val scores are: activity_selector: 0.721
I0828 20:16:59.063737 129822405686784 run.py:693] Algo activity_selector step 800 current loss 1.686640, current_train_items 11056.
I0828 20:16:59.078339 129822405686784 run.py:728] (val) algo activity_selector step 800: {'selected': 0.697495183044316, 'score': 0.697495183044316, 'examples_seen': 11056, 'step': 800, 'algorithm': 'activity_selector'}
I0828 20:16:59.078485 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.758, current avg val score is 0.697, val scores are: activity_selector: 0.697
I0828 20:16:59.606730 129822405686784 run.py:693] Algo activity_selector step 850 current loss 1.661504, current_train_items 11744.
I0828 20:16:59.622212 129822405686784 run.py:728] (val) algo activity_selector step 850: {'selected': 0.7430441898527005, 'score': 0.7430441898527005, 'examples_seen': 11744, 'step': 850, 'algorithm': 'activity_selector'}
I0828 20:16:59.622363 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.758, current avg val score is 0.743, val scores are: activity_selector: 0.743
I0828 20:17:00.186484 129822405686784 run.py:693] Algo activity_selector step 900 current loss 1.513359, current_train_items 12432.
I0828 20:17:00.201720 129822405686784 run.py:728] (val) algo activity_selector step 900: {'selected': 0.7208588957055215, 'score': 0.7208588957055215, 'examples_seen': 12432, 'step': 900, 'algorithm': 'activity_selector'}
I0828 20:17:00.201867 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.758, current avg val score is 0.721, val scores are: activity_selector: 0.721
I0828 20:17:00.734388 129822405686784 run.py:693] Algo activity_selector step 950 current loss 1.552758, current_train_items 13120.
I0828 20:17:00.749245 129822405686784 run.py:728] (val) algo activity_selector step 950: {'selected': 0.8008213552361396, 'score': 0.8008213552361396, 'examples_seen': 13120, 'step': 950, 'algorithm': 'activity_selector'}
I0828 20:17:00.749389 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.758, current avg val score is 0.801, val scores are: activity_selector: 0.801
I0828 20:17:01.288256 129822405686784 run.py:693] Algo activity_selector step 1000 current loss 1.388511, current_train_items 13808.
I0828 20:17:01.303166 129822405686784 run.py:728] (val) algo activity_selector step 1000: {'selected': 0.7522281639928698, 'score': 0.7522281639928698, 'examples_seen': 13808, 'step': 1000, 'algorithm': 'activity_selector'}
I0828 20:17:01.303312 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.801, current avg val score is 0.752, val scores are: activity_selector: 0.752
I0828 20:17:01.842412 129822405686784 run.py:693] Algo activity_selector step 1050 current loss 1.601233, current_train_items 14496.
I0828 20:17:01.857408 129822405686784 run.py:728] (val) algo activity_selector step 1050: {'selected': 0.7871939736346517, 'score': 0.7871939736346517, 'examples_seen': 14496, 'step': 1050, 'algorithm': 'activity_selector'}
I0828 20:17:01.857554 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.801, current avg val score is 0.787, val scores are: activity_selector: 0.787
I0828 20:17:02.395519 129822405686784 run.py:693] Algo activity_selector step 1100 current loss 1.508483, current_train_items 15200.
I0828 20:17:02.410495 129822405686784 run.py:728] (val) algo activity_selector step 1100: {'selected': 0.76, 'score': 0.76, 'examples_seen': 15200, 'step': 1100, 'algorithm': 'activity_selector'}
I0828 20:17:02.410650 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.801, current avg val score is 0.760, val scores are: activity_selector: 0.760
I0828 20:17:02.945373 129822405686784 run.py:693] Algo activity_selector step 1150 current loss 1.716726, current_train_items 15888.
I0828 20:17:02.960371 129822405686784 run.py:728] (val) algo activity_selector step 1150: {'selected': 0.7725752508361204, 'score': 0.7725752508361204, 'examples_seen': 15888, 'step': 1150, 'algorithm': 'activity_selector'}
I0828 20:17:02.960517 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.801, current avg val score is 0.773, val scores are: activity_selector: 0.773
I0828 20:17:03.509441 129822405686784 run.py:693] Algo activity_selector step 1200 current loss 1.774843, current_train_items 16560.
I0828 20:17:03.524449 129822405686784 run.py:728] (val) algo activity_selector step 1200: {'selected': 0.7603960396039604, 'score': 0.7603960396039604, 'examples_seen': 16560, 'step': 1200, 'algorithm': 'activity_selector'}
I0828 20:17:03.524596 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.801, current avg val score is 0.760, val scores are: activity_selector: 0.760
I0828 20:17:04.068660 129822405686784 run.py:693] Algo activity_selector step 1250 current loss 1.669532, current_train_items 17264.
I0828 20:17:04.083703 129822405686784 run.py:728] (val) algo activity_selector step 1250: {'selected': 0.7568493150684932, 'score': 0.7568493150684932, 'examples_seen': 17264, 'step': 1250, 'algorithm': 'activity_selector'}
I0828 20:17:04.083848 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.801, current avg val score is 0.757, val scores are: activity_selector: 0.757
I0828 20:17:04.609074 129822405686784 run.py:693] Algo activity_selector step 1300 current loss 1.277948, current_train_items 17952.
I0828 20:17:04.623931 129822405686784 run.py:728] (val) algo activity_selector step 1300: {'selected': 0.736842105263158, 'score': 0.736842105263158, 'examples_seen': 17952, 'step': 1300, 'algorithm': 'activity_selector'}
I0828 20:17:04.624088 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.801, current avg val score is 0.737, val scores are: activity_selector: 0.737
I0828 20:17:05.163233 129822405686784 run.py:693] Algo activity_selector step 1350 current loss 1.567435, current_train_items 18624.
I0828 20:17:05.178178 129822405686784 run.py:728] (val) algo activity_selector step 1350: {'selected': 0.8006993006993006, 'score': 0.8006993006993006, 'examples_seen': 18624, 'step': 1350, 'algorithm': 'activity_selector'}
I0828 20:17:05.178326 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.801, current avg val score is 0.801, val scores are: activity_selector: 0.801
I0828 20:17:05.712493 129822405686784 run.py:693] Algo activity_selector step 1400 current loss 0.918441, current_train_items 19328.
I0828 20:17:05.727400 129822405686784 run.py:728] (val) algo activity_selector step 1400: {'selected': 0.7883211678832117, 'score': 0.7883211678832117, 'examples_seen': 19328, 'step': 1400, 'algorithm': 'activity_selector'}
I0828 20:17:05.727548 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.801, current avg val score is 0.788, val scores are: activity_selector: 0.788
I0828 20:17:06.248105 129822405686784 run.py:693] Algo activity_selector step 1450 current loss 0.959730, current_train_items 20016.
I0828 20:17:06.263067 129822405686784 run.py:728] (val) algo activity_selector step 1450: {'selected': 0.7812499999999999, 'score': 0.7812499999999999, 'examples_seen': 20016, 'step': 1450, 'algorithm': 'activity_selector'}
I0828 20:17:06.263215 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.801, current avg val score is 0.781, val scores are: activity_selector: 0.781
I0828 20:17:06.794538 129822405686784 run.py:693] Algo activity_selector step 1500 current loss 1.063767, current_train_items 20704.
I0828 20:17:06.809379 129822405686784 run.py:728] (val) algo activity_selector step 1500: {'selected': 0.8351254480286738, 'score': 0.8351254480286738, 'examples_seen': 20704, 'step': 1500, 'algorithm': 'activity_selector'}
I0828 20:17:06.809525 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.801, current avg val score is 0.835, val scores are: activity_selector: 0.835
I0828 20:17:07.356761 129822405686784 run.py:693] Algo activity_selector step 1550 current loss 1.606401, current_train_items 21392.
I0828 20:17:07.371901 129822405686784 run.py:728] (val) algo activity_selector step 1550: {'selected': 0.8068833652007649, 'score': 0.8068833652007649, 'examples_seen': 21392, 'step': 1550, 'algorithm': 'activity_selector'}
I0828 20:17:07.372057 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.835, current avg val score is 0.807, val scores are: activity_selector: 0.807
I0828 20:17:07.917075 129822405686784 run.py:693] Algo activity_selector step 1600 current loss 1.168737, current_train_items 22096.
I0828 20:17:07.932775 129822405686784 run.py:728] (val) algo activity_selector step 1600: {'selected': 0.8072727272727273, 'score': 0.8072727272727273, 'examples_seen': 22096, 'step': 1600, 'algorithm': 'activity_selector'}
I0828 20:17:07.932923 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.835, current avg val score is 0.807, val scores are: activity_selector: 0.807
I0828 20:17:08.452751 129822405686784 run.py:693] Algo activity_selector step 1650 current loss 1.337976, current_train_items 22768.
I0828 20:17:08.468463 129822405686784 run.py:728] (val) algo activity_selector step 1650: {'selected': 0.8199643493761141, 'score': 0.8199643493761141, 'examples_seen': 22768, 'step': 1650, 'algorithm': 'activity_selector'}
I0828 20:17:08.468611 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.835, current avg val score is 0.820, val scores are: activity_selector: 0.820
I0828 20:17:08.995225 129822405686784 run.py:693] Algo activity_selector step 1700 current loss 1.035233, current_train_items 23456.
I0828 20:17:09.012590 129822405686784 run.py:728] (val) algo activity_selector step 1700: {'selected': 0.7876712328767124, 'score': 0.7876712328767124, 'examples_seen': 23456, 'step': 1700, 'algorithm': 'activity_selector'}
I0828 20:17:09.012737 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.835, current avg val score is 0.788, val scores are: activity_selector: 0.788
I0828 20:17:09.550199 129822405686784 run.py:693] Algo activity_selector step 1750 current loss 1.053126, current_train_items 24160.
I0828 20:17:09.565042 129822405686784 run.py:728] (val) algo activity_selector step 1750: {'selected': 0.7908745247148289, 'score': 0.7908745247148289, 'examples_seen': 24160, 'step': 1750, 'algorithm': 'activity_selector'}
I0828 20:17:09.565189 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.835, current avg val score is 0.791, val scores are: activity_selector: 0.791
I0828 20:17:10.094146 129822405686784 run.py:693] Algo activity_selector step 1800 current loss 1.014751, current_train_items 24832.
I0828 20:17:10.108824 129822405686784 run.py:728] (val) algo activity_selector step 1800: {'selected': 0.8074074074074074, 'score': 0.8074074074074074, 'examples_seen': 24832, 'step': 1800, 'algorithm': 'activity_selector'}
I0828 20:17:10.108983 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.835, current avg val score is 0.807, val scores are: activity_selector: 0.807
I0828 20:17:10.647086 129822405686784 run.py:693] Algo activity_selector step 1850 current loss 0.857195, current_train_items 25536.
I0828 20:17:10.662585 129822405686784 run.py:728] (val) algo activity_selector step 1850: {'selected': 0.7960199004975125, 'score': 0.7960199004975125, 'examples_seen': 25536, 'step': 1850, 'algorithm': 'activity_selector'}
I0828 20:17:10.662740 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.835, current avg val score is 0.796, val scores are: activity_selector: 0.796
I0828 20:17:11.197794 129822405686784 run.py:693] Algo activity_selector step 1900 current loss 1.188268, current_train_items 26224.
I0828 20:17:11.213072 129822405686784 run.py:728] (val) algo activity_selector step 1900: {'selected': 0.7875647668393781, 'score': 0.7875647668393781, 'examples_seen': 26224, 'step': 1900, 'algorithm': 'activity_selector'}
I0828 20:17:11.213218 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.835, current avg val score is 0.788, val scores are: activity_selector: 0.788
I0828 20:17:11.742714 129822405686784 run.py:693] Algo activity_selector step 1950 current loss 0.999028, current_train_items 26912.
I0828 20:17:11.757688 129822405686784 run.py:728] (val) algo activity_selector step 1950: {'selected': 0.8249566724436742, 'score': 0.8249566724436742, 'examples_seen': 26912, 'step': 1950, 'algorithm': 'activity_selector'}
I0828 20:17:11.757837 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.835, current avg val score is 0.825, val scores are: activity_selector: 0.825
I0828 20:17:12.293302 129822405686784 run.py:693] Algo activity_selector step 2000 current loss 1.033717, current_train_items 27600.
I0828 20:17:12.308729 129822405686784 run.py:728] (val) algo activity_selector step 2000: {'selected': 0.8221070811744386, 'score': 0.8221070811744386, 'examples_seen': 27600, 'step': 2000, 'algorithm': 'activity_selector'}
I0828 20:17:12.308877 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.835, current avg val score is 0.822, val scores are: activity_selector: 0.822
I0828 20:17:12.838909 129822405686784 run.py:693] Algo activity_selector step 2050 current loss 1.083339, current_train_items 28288.
I0828 20:17:12.854422 129822405686784 run.py:728] (val) algo activity_selector step 2050: {'selected': 0.7723880597014926, 'score': 0.7723880597014926, 'examples_seen': 28288, 'step': 2050, 'algorithm': 'activity_selector'}
I0828 20:17:12.854571 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.835, current avg val score is 0.772, val scores are: activity_selector: 0.772
I0828 20:17:13.401546 129822405686784 run.py:693] Algo activity_selector step 2100 current loss 1.339655, current_train_items 28976.
I0828 20:17:13.416900 129822405686784 run.py:728] (val) algo activity_selector step 2100: {'selected': 0.8327526132404182, 'score': 0.8327526132404182, 'examples_seen': 28976, 'step': 2100, 'algorithm': 'activity_selector'}
I0828 20:17:13.417069 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.835, current avg val score is 0.833, val scores are: activity_selector: 0.833
I0828 20:17:13.951732 129822405686784 run.py:693] Algo activity_selector step 2150 current loss 1.263033, current_train_items 29664.
I0828 20:17:13.966891 129822405686784 run.py:728] (val) algo activity_selector step 2150: {'selected': 0.8377358490566038, 'score': 0.8377358490566038, 'examples_seen': 29664, 'step': 2150, 'algorithm': 'activity_selector'}
I0828 20:17:13.967049 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.835, current avg val score is 0.838, val scores are: activity_selector: 0.838
I0828 20:17:14.504342 129822405686784 run.py:693] Algo activity_selector step 2200 current loss 1.526453, current_train_items 30368.
I0828 20:17:14.522045 129822405686784 run.py:728] (val) algo activity_selector step 2200: {'selected': 0.7986230636833047, 'score': 0.7986230636833047, 'examples_seen': 30368, 'step': 2200, 'algorithm': 'activity_selector'}
I0828 20:17:14.522195 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.838, current avg val score is 0.799, val scores are: activity_selector: 0.799
I0828 20:17:15.055199 129822405686784 run.py:693] Algo activity_selector step 2250 current loss 1.077429, current_train_items 31040.
I0828 20:17:15.069735 129822405686784 run.py:728] (val) algo activity_selector step 2250: {'selected': 0.8083623693379791, 'score': 0.8083623693379791, 'examples_seen': 31040, 'step': 2250, 'algorithm': 'activity_selector'}
I0828 20:17:15.069882 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.838, current avg val score is 0.808, val scores are: activity_selector: 0.808
I0828 20:17:15.614676 129822405686784 run.py:693] Algo activity_selector step 2300 current loss 1.036417, current_train_items 31728.
I0828 20:17:15.629386 129822405686784 run.py:728] (val) algo activity_selector step 2300: {'selected': 0.843065693430657, 'score': 0.843065693430657, 'examples_seen': 31728, 'step': 2300, 'algorithm': 'activity_selector'}
I0828 20:17:15.629531 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.838, current avg val score is 0.843, val scores are: activity_selector: 0.843
I0828 20:17:16.177750 129822405686784 run.py:693] Algo activity_selector step 2350 current loss 0.843104, current_train_items 32432.
I0828 20:17:16.193252 129822405686784 run.py:728] (val) algo activity_selector step 2350: {'selected': 0.8457350272232305, 'score': 0.8457350272232305, 'examples_seen': 32432, 'step': 2350, 'algorithm': 'activity_selector'}
I0828 20:17:16.193399 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.843, current avg val score is 0.846, val scores are: activity_selector: 0.846
I0828 20:17:16.731778 129822405686784 run.py:693] Algo activity_selector step 2400 current loss 1.414702, current_train_items 33104.
I0828 20:17:16.747023 129822405686784 run.py:728] (val) algo activity_selector step 2400: {'selected': 0.7755834829443448, 'score': 0.7755834829443448, 'examples_seen': 33104, 'step': 2400, 'algorithm': 'activity_selector'}
I0828 20:17:16.747180 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.846, current avg val score is 0.776, val scores are: activity_selector: 0.776
I0828 20:17:17.283931 129822405686784 run.py:693] Algo activity_selector step 2450 current loss 1.206395, current_train_items 33808.
I0828 20:17:17.298477 129822405686784 run.py:728] (val) algo activity_selector step 2450: {'selected': 0.8292682926829268, 'score': 0.8292682926829268, 'examples_seen': 33808, 'step': 2450, 'algorithm': 'activity_selector'}
I0828 20:17:17.298624 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.846, current avg val score is 0.829, val scores are: activity_selector: 0.829
I0828 20:17:17.816255 129822405686784 run.py:693] Algo activity_selector step 2500 current loss 1.634082, current_train_items 34496.
I0828 20:17:17.830943 129822405686784 run.py:728] (val) algo activity_selector step 2500: {'selected': 0.8379446640316205, 'score': 0.8379446640316205, 'examples_seen': 34496, 'step': 2500, 'algorithm': 'activity_selector'}
I0828 20:17:17.831096 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.846, current avg val score is 0.838, val scores are: activity_selector: 0.838
I0828 20:17:18.354698 129822405686784 run.py:693] Algo activity_selector step 2550 current loss 0.607857, current_train_items 35184.
I0828 20:17:18.369472 129822405686784 run.py:728] (val) algo activity_selector step 2550: {'selected': 0.8447653429602888, 'score': 0.8447653429602888, 'examples_seen': 35184, 'step': 2550, 'algorithm': 'activity_selector'}
I0828 20:17:18.369619 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.846, current avg val score is 0.845, val scores are: activity_selector: 0.845
I0828 20:17:18.903193 129822405686784 run.py:693] Algo activity_selector step 2600 current loss 2.057723, current_train_items 35872.
I0828 20:17:18.918008 129822405686784 run.py:728] (val) algo activity_selector step 2600: {'selected': 0.8312611012433394, 'score': 0.8312611012433394, 'examples_seen': 35872, 'step': 2600, 'algorithm': 'activity_selector'}
I0828 20:17:18.918163 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.846, current avg val score is 0.831, val scores are: activity_selector: 0.831
I0828 20:17:19.441399 129822405686784 run.py:693] Algo activity_selector step 2650 current loss 0.777320, current_train_items 36560.
I0828 20:17:19.456308 129822405686784 run.py:728] (val) algo activity_selector step 2650: {'selected': 0.8385964912280702, 'score': 0.8385964912280702, 'examples_seen': 36560, 'step': 2650, 'algorithm': 'activity_selector'}
I0828 20:17:19.456454 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.846, current avg val score is 0.839, val scores are: activity_selector: 0.839
I0828 20:17:19.987752 129822405686784 run.py:693] Algo activity_selector step 2700 current loss 1.238506, current_train_items 37248.
I0828 20:17:20.002733 129822405686784 run.py:728] (val) algo activity_selector step 2700: {'selected': 0.8640000000000001, 'score': 0.8640000000000001, 'examples_seen': 37248, 'step': 2700, 'algorithm': 'activity_selector'}
I0828 20:17:20.002881 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.846, current avg val score is 0.864, val scores are: activity_selector: 0.864
I0828 20:17:20.538596 129822405686784 run.py:693] Algo activity_selector step 2750 current loss 1.077481, current_train_items 37936.
I0828 20:17:20.553271 129822405686784 run.py:728] (val) algo activity_selector step 2750: {'selected': 0.8811700182815357, 'score': 0.8811700182815357, 'examples_seen': 37936, 'step': 2750, 'algorithm': 'activity_selector'}
I0828 20:17:20.553418 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.864, current avg val score is 0.881, val scores are: activity_selector: 0.881
I0828 20:17:21.081782 129822405686784 run.py:693] Algo activity_selector step 2800 current loss 1.070989, current_train_items 38640.
I0828 20:17:21.096707 129822405686784 run.py:728] (val) algo activity_selector step 2800: {'selected': 0.8487084870848708, 'score': 0.8487084870848708, 'examples_seen': 38640, 'step': 2800, 'algorithm': 'activity_selector'}
I0828 20:17:21.096853 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.881, current avg val score is 0.849, val scores are: activity_selector: 0.849
I0828 20:17:21.627799 129822405686784 run.py:693] Algo activity_selector step 2850 current loss 0.693582, current_train_items 39312.
I0828 20:17:21.642326 129822405686784 run.py:728] (val) algo activity_selector step 2850: {'selected': 0.8385964912280701, 'score': 0.8385964912280701, 'examples_seen': 39312, 'step': 2850, 'algorithm': 'activity_selector'}
I0828 20:17:21.642475 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.881, current avg val score is 0.839, val scores are: activity_selector: 0.839
I0828 20:17:22.165366 129822405686784 run.py:693] Algo activity_selector step 2900 current loss 1.305076, current_train_items 40016.
I0828 20:17:22.181848 129822405686784 run.py:728] (val) algo activity_selector step 2900: {'selected': 0.8458646616541353, 'score': 0.8458646616541353, 'examples_seen': 40016, 'step': 2900, 'algorithm': 'activity_selector'}
I0828 20:17:22.181996 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.881, current avg val score is 0.846, val scores are: activity_selector: 0.846
I0828 20:17:22.726052 129822405686784 run.py:693] Algo activity_selector step 2950 current loss 0.694756, current_train_items 40704.
I0828 20:17:22.740663 129822405686784 run.py:728] (val) algo activity_selector step 2950: {'selected': 0.8360000000000001, 'score': 0.8360000000000001, 'examples_seen': 40704, 'step': 2950, 'algorithm': 'activity_selector'}
I0828 20:17:22.740836 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.881, current avg val score is 0.836, val scores are: activity_selector: 0.836
I0828 20:17:23.262777 129822405686784 run.py:693] Algo activity_selector step 3000 current loss 1.409335, current_train_items 41376.
I0828 20:17:23.277462 129822405686784 run.py:728] (val) algo activity_selector step 3000: {'selected': 0.8217317487266553, 'score': 0.8217317487266553, 'examples_seen': 41376, 'step': 3000, 'algorithm': 'activity_selector'}
I0828 20:17:23.277610 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.881, current avg val score is 0.822, val scores are: activity_selector: 0.822
I0828 20:17:23.814341 129822405686784 run.py:693] Algo activity_selector step 3050 current loss 1.272984, current_train_items 42080.
I0828 20:17:23.829332 129822405686784 run.py:728] (val) algo activity_selector step 3050: {'selected': 0.8371212121212122, 'score': 0.8371212121212122, 'examples_seen': 42080, 'step': 3050, 'algorithm': 'activity_selector'}
I0828 20:17:23.829483 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.881, current avg val score is 0.837, val scores are: activity_selector: 0.837
I0828 20:17:24.359102 129822405686784 run.py:693] Algo activity_selector step 3100 current loss 0.620739, current_train_items 42768.
I0828 20:17:24.374452 129822405686784 run.py:728] (val) algo activity_selector step 3100: {'selected': 0.8605108055009824, 'score': 0.8605108055009824, 'examples_seen': 42768, 'step': 3100, 'algorithm': 'activity_selector'}
I0828 20:17:24.374600 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.881, current avg val score is 0.861, val scores are: activity_selector: 0.861
I0828 20:17:24.895533 129822405686784 run.py:693] Algo activity_selector step 3150 current loss 1.004174, current_train_items 43440.
I0828 20:17:24.910888 129822405686784 run.py:728] (val) algo activity_selector step 3150: {'selected': 0.8336448598130841, 'score': 0.8336448598130841, 'examples_seen': 43440, 'step': 3150, 'algorithm': 'activity_selector'}
I0828 20:17:24.911048 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.881, current avg val score is 0.834, val scores are: activity_selector: 0.834
I0828 20:17:25.447138 129822405686784 run.py:693] Algo activity_selector step 3200 current loss 0.611159, current_train_items 44144.
I0828 20:17:25.461835 129822405686784 run.py:728] (val) algo activity_selector step 3200: {'selected': 0.8301075268817204, 'score': 0.8301075268817204, 'examples_seen': 44144, 'step': 3200, 'algorithm': 'activity_selector'}
I0828 20:17:25.461987 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.881, current avg val score is 0.830, val scores are: activity_selector: 0.830
I0828 20:17:25.980009 129822405686784 run.py:693] Algo activity_selector step 3250 current loss 0.780195, current_train_items 44848.
I0828 20:17:25.995328 129822405686784 run.py:728] (val) algo activity_selector step 3250: {'selected': 0.8671586715867159, 'score': 0.8671586715867159, 'examples_seen': 44848, 'step': 3250, 'algorithm': 'activity_selector'}
I0828 20:17:25.995477 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.881, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0828 20:17:26.526839 129822405686784 run.py:693] Algo activity_selector step 3300 current loss 0.744440, current_train_items 45520.
I0828 20:17:26.542160 129822405686784 run.py:728] (val) algo activity_selector step 3300: {'selected': 0.8855534709193246, 'score': 0.8855534709193246, 'examples_seen': 45520, 'step': 3300, 'algorithm': 'activity_selector'}
I0828 20:17:26.542307 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.881, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0828 20:17:27.080623 129822405686784 run.py:693] Algo activity_selector step 3350 current loss 0.788319, current_train_items 46208.
I0828 20:17:27.095557 129822405686784 run.py:728] (val) algo activity_selector step 3350: {'selected': 0.8448275862068965, 'score': 0.8448275862068965, 'examples_seen': 46208, 'step': 3350, 'algorithm': 'activity_selector'}
I0828 20:17:27.095706 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.886, current avg val score is 0.845, val scores are: activity_selector: 0.845
I0828 20:17:27.620073 129822405686784 run.py:693] Algo activity_selector step 3400 current loss 0.608442, current_train_items 46912.
I0828 20:17:27.636224 129822405686784 run.py:728] (val) algo activity_selector step 3400: {'selected': 0.8804780876494024, 'score': 0.8804780876494024, 'examples_seen': 46912, 'step': 3400, 'algorithm': 'activity_selector'}
I0828 20:17:27.636371 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.886, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0828 20:17:28.164303 129822405686784 run.py:693] Algo activity_selector step 3450 current loss 0.869910, current_train_items 47584.
I0828 20:17:28.179269 129822405686784 run.py:728] (val) algo activity_selector step 3450: {'selected': 0.8847583643122676, 'score': 0.8847583643122676, 'examples_seen': 47584, 'step': 3450, 'algorithm': 'activity_selector'}
I0828 20:17:28.179414 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.886, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0828 20:17:28.700459 129822405686784 run.py:693] Algo activity_selector step 3500 current loss 0.547191, current_train_items 48272.
I0828 20:17:28.715551 129822405686784 run.py:728] (val) algo activity_selector step 3500: {'selected': 0.8140900195694717, 'score': 0.8140900195694717, 'examples_seen': 48272, 'step': 3500, 'algorithm': 'activity_selector'}
I0828 20:17:28.715697 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.886, current avg val score is 0.814, val scores are: activity_selector: 0.814
I0828 20:17:29.248425 129822405686784 run.py:693] Algo activity_selector step 3550 current loss 0.796861, current_train_items 48976.
I0828 20:17:29.263890 129822405686784 run.py:728] (val) algo activity_selector step 3550: {'selected': 0.9045801526717557, 'score': 0.9045801526717557, 'examples_seen': 48976, 'step': 3550, 'algorithm': 'activity_selector'}
I0828 20:17:29.264045 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.886, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0828 20:17:29.806120 129822405686784 run.py:693] Algo activity_selector step 3600 current loss 0.933437, current_train_items 49664.
I0828 20:17:29.821162 129822405686784 run.py:728] (val) algo activity_selector step 3600: {'selected': 0.8858267716535433, 'score': 0.8858267716535433, 'examples_seen': 49664, 'step': 3600, 'algorithm': 'activity_selector'}
I0828 20:17:29.821305 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.905, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0828 20:17:30.347424 129822405686784 run.py:693] Algo activity_selector step 3650 current loss 1.000762, current_train_items 50352.
I0828 20:17:30.362585 129822405686784 run.py:728] (val) algo activity_selector step 3650: {'selected': 0.8704663212435232, 'score': 0.8704663212435232, 'examples_seen': 50352, 'step': 3650, 'algorithm': 'activity_selector'}
I0828 20:17:30.362730 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.905, current avg val score is 0.870, val scores are: activity_selector: 0.870
I0828 20:17:30.890978 129822405686784 run.py:693] Algo activity_selector step 3700 current loss 0.708996, current_train_items 51040.
I0828 20:17:30.905683 129822405686784 run.py:728] (val) algo activity_selector step 3700: {'selected': 0.8761904761904762, 'score': 0.8761904761904762, 'examples_seen': 51040, 'step': 3700, 'algorithm': 'activity_selector'}
I0828 20:17:30.905847 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.905, current avg val score is 0.876, val scores are: activity_selector: 0.876
I0828 20:17:31.434204 129822405686784 run.py:693] Algo activity_selector step 3750 current loss 0.940304, current_train_items 51728.
I0828 20:17:31.449621 129822405686784 run.py:728] (val) algo activity_selector step 3750: {'selected': 0.8825757575757575, 'score': 0.8825757575757575, 'examples_seen': 51728, 'step': 3750, 'algorithm': 'activity_selector'}
I0828 20:17:31.449765 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.905, current avg val score is 0.883, val scores are: activity_selector: 0.883
I0828 20:17:31.977313 129822405686784 run.py:693] Algo activity_selector step 3800 current loss 0.733277, current_train_items 52416.
I0828 20:17:31.992325 129822405686784 run.py:728] (val) algo activity_selector step 3800: {'selected': 0.8433333333333334, 'score': 0.8433333333333334, 'examples_seen': 52416, 'step': 3800, 'algorithm': 'activity_selector'}
I0828 20:17:31.992484 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.905, current avg val score is 0.843, val scores are: activity_selector: 0.843
I0828 20:17:32.513202 129822405686784 run.py:693] Algo activity_selector step 3850 current loss 0.900615, current_train_items 53104.
I0828 20:17:32.528596 129822405686784 run.py:728] (val) algo activity_selector step 3850: {'selected': 0.9046728971962616, 'score': 0.9046728971962616, 'examples_seen': 53104, 'step': 3850, 'algorithm': 'activity_selector'}
I0828 20:17:32.528743 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.905, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0828 20:17:33.074618 129822405686784 run.py:693] Algo activity_selector step 3900 current loss 1.094285, current_train_items 53792.
I0828 20:17:33.089249 129822405686784 run.py:728] (val) algo activity_selector step 3900: {'selected': 0.9047619047619048, 'score': 0.9047619047619048, 'examples_seen': 53792, 'step': 3900, 'algorithm': 'activity_selector'}
I0828 20:17:33.089397 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.905, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0828 20:17:33.625754 129822405686784 run.py:693] Algo activity_selector step 3950 current loss 0.545561, current_train_items 54496.
I0828 20:17:33.640371 129822405686784 run.py:728] (val) algo activity_selector step 3950: {'selected': 0.893542757417103, 'score': 0.893542757417103, 'examples_seen': 54496, 'step': 3950, 'algorithm': 'activity_selector'}
I0828 20:17:33.640518 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.905, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0828 20:17:34.154731 129822405686784 run.py:693] Algo activity_selector step 4000 current loss 1.521575, current_train_items 55168.
I0828 20:17:34.172465 129822405686784 run.py:728] (val) algo activity_selector step 4000: {'selected': 0.8547579298831386, 'score': 0.8547579298831386, 'examples_seen': 55168, 'step': 4000, 'algorithm': 'activity_selector'}
I0828 20:17:34.172610 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.905, current avg val score is 0.855, val scores are: activity_selector: 0.855
I0828 20:17:34.703607 129822405686784 run.py:693] Algo activity_selector step 4050 current loss 1.134002, current_train_items 55856.
I0828 20:17:34.718331 129822405686784 run.py:728] (val) algo activity_selector step 4050: {'selected': 0.9010989010989011, 'score': 0.9010989010989011, 'examples_seen': 55856, 'step': 4050, 'algorithm': 'activity_selector'}
I0828 20:17:34.718478 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.905, current avg val score is 0.901, val scores are: activity_selector: 0.901
I0828 20:17:35.251143 129822405686784 run.py:693] Algo activity_selector step 4100 current loss 1.281345, current_train_items 56560.
I0828 20:17:35.266592 129822405686784 run.py:728] (val) algo activity_selector step 4100: {'selected': 0.8319467554076538, 'score': 0.8319467554076538, 'examples_seen': 56560, 'step': 4100, 'algorithm': 'activity_selector'}
I0828 20:17:35.266747 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.905, current avg val score is 0.832, val scores are: activity_selector: 0.832
I0828 20:17:35.789166 129822405686784 run.py:693] Algo activity_selector step 4150 current loss 0.781213, current_train_items 57248.
I0828 20:17:35.804093 129822405686784 run.py:728] (val) algo activity_selector step 4150: {'selected': 0.886029411764706, 'score': 0.886029411764706, 'examples_seen': 57248, 'step': 4150, 'algorithm': 'activity_selector'}
I0828 20:17:35.804236 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.905, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0828 20:17:36.325544 129822405686784 run.py:693] Algo activity_selector step 4200 current loss 0.817940, current_train_items 57920.
I0828 20:17:36.340413 129822405686784 run.py:728] (val) algo activity_selector step 4200: {'selected': 0.8333333333333335, 'score': 0.8333333333333335, 'examples_seen': 57920, 'step': 4200, 'algorithm': 'activity_selector'}
I0828 20:17:36.340562 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.905, current avg val score is 0.833, val scores are: activity_selector: 0.833
I0828 20:17:36.891201 129822405686784 run.py:693] Algo activity_selector step 4250 current loss 0.907986, current_train_items 58624.
I0828 20:17:36.906112 129822405686784 run.py:728] (val) algo activity_selector step 4250: {'selected': 0.8602540834845736, 'score': 0.8602540834845736, 'examples_seen': 58624, 'step': 4250, 'algorithm': 'activity_selector'}
I0828 20:17:36.906258 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.905, current avg val score is 0.860, val scores are: activity_selector: 0.860
I0828 20:17:37.426259 129822405686784 run.py:693] Algo activity_selector step 4300 current loss 0.854815, current_train_items 59328.
I0828 20:17:37.441320 129822405686784 run.py:728] (val) algo activity_selector step 4300: {'selected': 0.9108159392789373, 'score': 0.9108159392789373, 'examples_seen': 59328, 'step': 4300, 'algorithm': 'activity_selector'}
I0828 20:17:37.441464 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.905, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0828 20:17:37.975541 129822405686784 run.py:693] Algo activity_selector step 4350 current loss 1.418430, current_train_items 59984.
I0828 20:17:37.990811 129822405686784 run.py:728] (val) algo activity_selector step 4350: {'selected': 0.8622540250447228, 'score': 0.8622540250447228, 'examples_seen': 59984, 'step': 4350, 'algorithm': 'activity_selector'}
I0828 20:17:37.990960 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.862, val scores are: activity_selector: 0.862
I0828 20:17:38.527205 129822405686784 run.py:693] Algo activity_selector step 4400 current loss 0.773707, current_train_items 60688.
I0828 20:17:38.542712 129822405686784 run.py:728] (val) algo activity_selector step 4400: {'selected': 0.8698884758364311, 'score': 0.8698884758364311, 'examples_seen': 60688, 'step': 4400, 'algorithm': 'activity_selector'}
I0828 20:17:38.542854 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.870, val scores are: activity_selector: 0.870
I0828 20:17:39.071092 129822405686784 run.py:693] Algo activity_selector step 4450 current loss 0.835414, current_train_items 61392.
I0828 20:17:39.085782 129822405686784 run.py:728] (val) algo activity_selector step 4450: {'selected': 0.8936936936936938, 'score': 0.8936936936936938, 'examples_seen': 61392, 'step': 4450, 'algorithm': 'activity_selector'}
I0828 20:17:39.085928 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0828 20:17:39.605458 129822405686784 run.py:693] Algo activity_selector step 4500 current loss 0.556257, current_train_items 62064.
I0828 20:17:39.620402 129822405686784 run.py:728] (val) algo activity_selector step 4500: {'selected': 0.8566308243727598, 'score': 0.8566308243727598, 'examples_seen': 62064, 'step': 4500, 'algorithm': 'activity_selector'}
I0828 20:17:39.620549 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.857, val scores are: activity_selector: 0.857
I0828 20:17:40.150318 129822405686784 run.py:693] Algo activity_selector step 4550 current loss 0.791013, current_train_items 62752.
I0828 20:17:40.164914 129822405686784 run.py:728] (val) algo activity_selector step 4550: {'selected': 0.8913857677902621, 'score': 0.8913857677902621, 'examples_seen': 62752, 'step': 4550, 'algorithm': 'activity_selector'}
I0828 20:17:40.165066 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0828 20:17:40.689221 129822405686784 run.py:693] Algo activity_selector step 4600 current loss 0.591430, current_train_items 63456.
I0828 20:17:40.704056 129822405686784 run.py:728] (val) algo activity_selector step 4600: {'selected': 0.8333333333333334, 'score': 0.8333333333333334, 'examples_seen': 63456, 'step': 4600, 'algorithm': 'activity_selector'}
I0828 20:17:40.704203 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.833, val scores are: activity_selector: 0.833
I0828 20:17:41.228464 129822405686784 run.py:693] Algo activity_selector step 4650 current loss 0.551885, current_train_items 64144.
I0828 20:17:41.243166 129822405686784 run.py:728] (val) algo activity_selector step 4650: {'selected': 0.8973384030418251, 'score': 0.8973384030418251, 'examples_seen': 64144, 'step': 4650, 'algorithm': 'activity_selector'}
I0828 20:17:41.243313 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0828 20:17:41.765594 129822405686784 run.py:693] Algo activity_selector step 4700 current loss 0.727830, current_train_items 64816.
I0828 20:17:41.780781 129822405686784 run.py:728] (val) algo activity_selector step 4700: {'selected': 0.8864468864468864, 'score': 0.8864468864468864, 'examples_seen': 64816, 'step': 4700, 'algorithm': 'activity_selector'}
I0828 20:17:41.780934 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0828 20:17:42.317363 129822405686784 run.py:693] Algo activity_selector step 4750 current loss 0.571722, current_train_items 65520.
I0828 20:17:42.332891 129822405686784 run.py:728] (val) algo activity_selector step 4750: {'selected': 0.8527397260273972, 'score': 0.8527397260273972, 'examples_seen': 65520, 'step': 4750, 'algorithm': 'activity_selector'}
I0828 20:17:42.333050 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.853, val scores are: activity_selector: 0.853
I0828 20:17:42.876480 129822405686784 run.py:693] Algo activity_selector step 4800 current loss 0.614972, current_train_items 66208.
I0828 20:17:42.891069 129822405686784 run.py:728] (val) algo activity_selector step 4800: {'selected': 0.8868613138686131, 'score': 0.8868613138686131, 'examples_seen': 66208, 'step': 4800, 'algorithm': 'activity_selector'}
I0828 20:17:42.891215 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.887, val scores are: activity_selector: 0.887
I0828 20:17:43.408262 129822405686784 run.py:693] Algo activity_selector step 4850 current loss 0.976105, current_train_items 66880.
I0828 20:17:43.422895 129822405686784 run.py:728] (val) algo activity_selector step 4850: {'selected': 0.8545119705340699, 'score': 0.8545119705340699, 'examples_seen': 66880, 'step': 4850, 'algorithm': 'activity_selector'}
I0828 20:17:43.423068 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.855, val scores are: activity_selector: 0.855
I0828 20:17:43.958756 129822405686784 run.py:693] Algo activity_selector step 4900 current loss 0.692559, current_train_items 67584.
I0828 20:17:43.973271 129822405686784 run.py:728] (val) algo activity_selector step 4900: {'selected': 0.8623188405797102, 'score': 0.8623188405797102, 'examples_seen': 67584, 'step': 4900, 'algorithm': 'activity_selector'}
I0828 20:17:43.973419 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.862, val scores are: activity_selector: 0.862
I0828 20:17:44.510755 129822405686784 run.py:693] Algo activity_selector step 4950 current loss 0.454608, current_train_items 68272.
I0828 20:17:44.525744 129822405686784 run.py:728] (val) algo activity_selector step 4950: {'selected': 0.884990253411306, 'score': 0.884990253411306, 'examples_seen': 68272, 'step': 4950, 'algorithm': 'activity_selector'}
I0828 20:17:44.525888 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0828 20:17:45.054630 129822405686784 run.py:693] Algo activity_selector step 5000 current loss 0.752939, current_train_items 68976.
I0828 20:17:45.069555 129822405686784 run.py:728] (val) algo activity_selector step 5000: {'selected': 0.8756756756756756, 'score': 0.8756756756756756, 'examples_seen': 68976, 'step': 5000, 'algorithm': 'activity_selector'}
I0828 20:17:45.069703 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.876, val scores are: activity_selector: 0.876
I0828 20:17:45.591975 129822405686784 run.py:693] Algo activity_selector step 5050 current loss 0.905885, current_train_items 69648.
I0828 20:17:45.607465 129822405686784 run.py:728] (val) algo activity_selector step 5050: {'selected': 0.8876190476190478, 'score': 0.8876190476190478, 'examples_seen': 69648, 'step': 5050, 'algorithm': 'activity_selector'}
I0828 20:17:45.607612 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.888, val scores are: activity_selector: 0.888
I0828 20:17:46.149639 129822405686784 run.py:693] Algo activity_selector step 5100 current loss 0.673397, current_train_items 70336.
I0828 20:17:46.164790 129822405686784 run.py:728] (val) algo activity_selector step 5100: {'selected': 0.8848920863309353, 'score': 0.8848920863309353, 'examples_seen': 70336, 'step': 5100, 'algorithm': 'activity_selector'}
I0828 20:17:46.164937 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0828 20:17:46.701571 129822405686784 run.py:693] Algo activity_selector step 5150 current loss 0.402610, current_train_items 71040.
I0828 20:17:46.716336 129822405686784 run.py:728] (val) algo activity_selector step 5150: {'selected': 0.877310924369748, 'score': 0.877310924369748, 'examples_seen': 71040, 'step': 5150, 'algorithm': 'activity_selector'}
I0828 20:17:46.716482 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.877, val scores are: activity_selector: 0.877
I0828 20:17:47.231985 129822405686784 run.py:693] Algo activity_selector step 5200 current loss 1.056503, current_train_items 71712.
I0828 20:17:47.246782 129822405686784 run.py:728] (val) algo activity_selector step 5200: {'selected': 0.8897196261682243, 'score': 0.8897196261682243, 'examples_seen': 71712, 'step': 5200, 'algorithm': 'activity_selector'}
I0828 20:17:47.246926 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.890, val scores are: activity_selector: 0.890
I0828 20:17:47.781627 129822405686784 run.py:693] Algo activity_selector step 5250 current loss 0.666982, current_train_items 72400.
I0828 20:17:47.796865 129822405686784 run.py:728] (val) algo activity_selector step 5250: {'selected': 0.8651685393258427, 'score': 0.8651685393258427, 'examples_seen': 72400, 'step': 5250, 'algorithm': 'activity_selector'}
I0828 20:17:47.797023 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.865, val scores are: activity_selector: 0.865
I0828 20:17:48.342345 129822405686784 run.py:693] Algo activity_selector step 5300 current loss 0.657313, current_train_items 73104.
I0828 20:17:48.357088 129822405686784 run.py:728] (val) algo activity_selector step 5300: {'selected': 0.8711433756805806, 'score': 0.8711433756805806, 'examples_seen': 73104, 'step': 5300, 'algorithm': 'activity_selector'}
I0828 20:17:48.357232 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.871, val scores are: activity_selector: 0.871
I0828 20:17:48.872836 129822405686784 run.py:693] Algo activity_selector step 5350 current loss 0.923258, current_train_items 73808.
I0828 20:17:48.887652 129822405686784 run.py:728] (val) algo activity_selector step 5350: {'selected': 0.8782435129740518, 'score': 0.8782435129740518, 'examples_seen': 73808, 'step': 5350, 'algorithm': 'activity_selector'}
I0828 20:17:48.887796 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.878, val scores are: activity_selector: 0.878
I0828 20:17:49.430370 129822405686784 run.py:693] Algo activity_selector step 5400 current loss 0.800947, current_train_items 74464.
I0828 20:17:49.446433 129822405686784 run.py:728] (val) algo activity_selector step 5400: {'selected': 0.8571428571428572, 'score': 0.8571428571428572, 'examples_seen': 74464, 'step': 5400, 'algorithm': 'activity_selector'}
I0828 20:17:49.446578 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.857, val scores are: activity_selector: 0.857
I0828 20:17:49.985024 129822405686784 run.py:693] Algo activity_selector step 5450 current loss 0.755696, current_train_items 75168.
I0828 20:17:50.000042 129822405686784 run.py:728] (val) algo activity_selector step 5450: {'selected': 0.86, 'score': 0.86, 'examples_seen': 75168, 'step': 5450, 'algorithm': 'activity_selector'}
I0828 20:17:50.000192 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.860, val scores are: activity_selector: 0.860
I0828 20:17:50.527332 129822405686784 run.py:693] Algo activity_selector step 5500 current loss 0.533491, current_train_items 75872.
I0828 20:17:50.545050 129822405686784 run.py:728] (val) algo activity_selector step 5500: {'selected': 0.893854748603352, 'score': 0.893854748603352, 'examples_seen': 75872, 'step': 5500, 'algorithm': 'activity_selector'}
I0828 20:17:50.545196 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0828 20:17:51.071347 129822405686784 run.py:693] Algo activity_selector step 5550 current loss 0.550703, current_train_items 76528.
I0828 20:17:51.087023 129822405686784 run.py:728] (val) algo activity_selector step 5550: {'selected': 0.8785046728971962, 'score': 0.8785046728971962, 'examples_seen': 76528, 'step': 5550, 'algorithm': 'activity_selector'}
I0828 20:17:51.087177 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0828 20:17:51.621084 129822405686784 run.py:693] Algo activity_selector step 5600 current loss 0.682175, current_train_items 77232.
I0828 20:17:51.635911 129822405686784 run.py:728] (val) algo activity_selector step 5600: {'selected': 0.9051094890510949, 'score': 0.9051094890510949, 'examples_seen': 77232, 'step': 5600, 'algorithm': 'activity_selector'}
I0828 20:17:51.636065 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0828 20:17:52.160032 129822405686784 run.py:693] Algo activity_selector step 5650 current loss 0.618364, current_train_items 77936.
I0828 20:17:52.175668 129822405686784 run.py:728] (val) algo activity_selector step 5650: {'selected': 0.8759689922480621, 'score': 0.8759689922480621, 'examples_seen': 77936, 'step': 5650, 'algorithm': 'activity_selector'}
I0828 20:17:52.175815 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.876, val scores are: activity_selector: 0.876
I0828 20:17:52.691992 129822405686784 run.py:693] Algo activity_selector step 5700 current loss 0.665486, current_train_items 78608.
I0828 20:17:52.707486 129822405686784 run.py:728] (val) algo activity_selector step 5700: {'selected': 0.928709055876686, 'score': 0.928709055876686, 'examples_seen': 78608, 'step': 5700, 'algorithm': 'activity_selector'}
I0828 20:17:52.707632 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.911, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0828 20:17:53.252629 129822405686784 run.py:693] Algo activity_selector step 5750 current loss 0.752945, current_train_items 79296.
I0828 20:17:53.267345 129822405686784 run.py:728] (val) algo activity_selector step 5750: {'selected': 0.8851913477537438, 'score': 0.8851913477537438, 'examples_seen': 79296, 'step': 5750, 'algorithm': 'activity_selector'}
I0828 20:17:53.267492 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0828 20:17:53.794121 129822405686784 run.py:693] Algo activity_selector step 5800 current loss 1.023883, current_train_items 80000.
I0828 20:17:53.809260 129822405686784 run.py:728] (val) algo activity_selector step 5800: {'selected': 0.897163120567376, 'score': 0.897163120567376, 'examples_seen': 80000, 'step': 5800, 'algorithm': 'activity_selector'}
I0828 20:17:53.809406 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0828 20:17:54.342973 129822405686784 run.py:693] Algo activity_selector step 5850 current loss 0.362197, current_train_items 80688.
I0828 20:17:54.357854 129822405686784 run.py:728] (val) algo activity_selector step 5850: {'selected': 0.8754448398576512, 'score': 0.8754448398576512, 'examples_seen': 80688, 'step': 5850, 'algorithm': 'activity_selector'}
I0828 20:17:54.358003 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.875, val scores are: activity_selector: 0.875
I0828 20:17:54.876785 129822405686784 run.py:693] Algo activity_selector step 5900 current loss 0.416481, current_train_items 81360.
I0828 20:17:54.892579 129822405686784 run.py:728] (val) algo activity_selector step 5900: {'selected': 0.8998178506375227, 'score': 0.8998178506375227, 'examples_seen': 81360, 'step': 5900, 'algorithm': 'activity_selector'}
I0828 20:17:54.892731 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.900, val scores are: activity_selector: 0.900
I0828 20:17:55.416848 129822405686784 run.py:693] Algo activity_selector step 5950 current loss 0.798947, current_train_items 82064.
I0828 20:17:55.431585 129822405686784 run.py:728] (val) algo activity_selector step 5950: {'selected': 0.8904847396768402, 'score': 0.8904847396768402, 'examples_seen': 82064, 'step': 5950, 'algorithm': 'activity_selector'}
I0828 20:17:55.431731 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.890, val scores are: activity_selector: 0.890
I0828 20:17:55.967910 129822405686784 run.py:693] Algo activity_selector step 6000 current loss 0.676241, current_train_items 82752.
I0828 20:17:55.982677 129822405686784 run.py:728] (val) algo activity_selector step 6000: {'selected': 0.8549019607843139, 'score': 0.8549019607843139, 'examples_seen': 82752, 'step': 6000, 'algorithm': 'activity_selector'}
I0828 20:17:55.982839 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.855, val scores are: activity_selector: 0.855
I0828 20:17:56.502255 129822405686784 run.py:693] Algo activity_selector step 6050 current loss 0.698352, current_train_items 83440.
I0828 20:17:56.517310 129822405686784 run.py:728] (val) algo activity_selector step 6050: {'selected': 0.8561020036429873, 'score': 0.8561020036429873, 'examples_seen': 83440, 'step': 6050, 'algorithm': 'activity_selector'}
I0828 20:17:56.517458 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.856, val scores are: activity_selector: 0.856
I0828 20:17:57.042833 129822405686784 run.py:693] Algo activity_selector step 6100 current loss 0.727737, current_train_items 84128.
I0828 20:17:57.057954 129822405686784 run.py:728] (val) algo activity_selector step 6100: {'selected': 0.8545454545454546, 'score': 0.8545454545454546, 'examples_seen': 84128, 'step': 6100, 'algorithm': 'activity_selector'}
I0828 20:17:57.058107 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.855, val scores are: activity_selector: 0.855
I0828 20:17:57.609321 129822405686784 run.py:693] Algo activity_selector step 6150 current loss 0.723651, current_train_items 84816.
I0828 20:17:57.623819 129822405686784 run.py:728] (val) algo activity_selector step 6150: {'selected': 0.88468809073724, 'score': 0.88468809073724, 'examples_seen': 84816, 'step': 6150, 'algorithm': 'activity_selector'}
I0828 20:17:57.623968 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0828 20:17:58.149842 129822405686784 run.py:693] Algo activity_selector step 6200 current loss 0.651645, current_train_items 85520.
I0828 20:17:58.164529 129822405686784 run.py:728] (val) algo activity_selector step 6200: {'selected': 0.8941605839416059, 'score': 0.8941605839416059, 'examples_seen': 85520, 'step': 6200, 'algorithm': 'activity_selector'}
I0828 20:17:58.164676 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0828 20:17:58.685400 129822405686784 run.py:693] Algo activity_selector step 6250 current loss 0.661798, current_train_items 86192.
I0828 20:17:58.700428 129822405686784 run.py:728] (val) algo activity_selector step 6250: {'selected': 0.8884826325411335, 'score': 0.8884826325411335, 'examples_seen': 86192, 'step': 6250, 'algorithm': 'activity_selector'}
I0828 20:17:58.700573 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.888, val scores are: activity_selector: 0.888
I0828 20:17:59.236645 129822405686784 run.py:693] Algo activity_selector step 6300 current loss 0.924371, current_train_items 86880.
I0828 20:17:59.251814 129822405686784 run.py:728] (val) algo activity_selector step 6300: {'selected': 0.8621908127208481, 'score': 0.8621908127208481, 'examples_seen': 86880, 'step': 6300, 'algorithm': 'activity_selector'}
I0828 20:17:59.251962 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.862, val scores are: activity_selector: 0.862
I0828 20:17:59.788095 129822405686784 run.py:693] Algo activity_selector step 6350 current loss 0.595717, current_train_items 87584.
I0828 20:17:59.802898 129822405686784 run.py:728] (val) algo activity_selector step 6350: {'selected': 0.911304347826087, 'score': 0.911304347826087, 'examples_seen': 87584, 'step': 6350, 'algorithm': 'activity_selector'}
I0828 20:17:59.803050 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0828 20:18:00.313339 129822405686784 run.py:693] Algo activity_selector step 6400 current loss 0.309374, current_train_items 88272.
I0828 20:18:00.329257 129822405686784 run.py:728] (val) algo activity_selector step 6400: {'selected': 0.9077490774907749, 'score': 0.9077490774907749, 'examples_seen': 88272, 'step': 6400, 'algorithm': 'activity_selector'}
I0828 20:18:00.329403 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0828 20:18:00.861472 129822405686784 run.py:693] Algo activity_selector step 6450 current loss 0.734197, current_train_items 88944.
I0828 20:18:00.876492 129822405686784 run.py:728] (val) algo activity_selector step 6450: {'selected': 0.8688845401174168, 'score': 0.8688845401174168, 'examples_seen': 88944, 'step': 6450, 'algorithm': 'activity_selector'}
I0828 20:18:00.876641 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.869, val scores are: activity_selector: 0.869
I0828 20:18:01.409560 129822405686784 run.py:693] Algo activity_selector step 6500 current loss 0.687810, current_train_items 89648.
I0828 20:18:01.425202 129822405686784 run.py:728] (val) algo activity_selector step 6500: {'selected': 0.8670120898100173, 'score': 0.8670120898100173, 'examples_seen': 89648, 'step': 6500, 'algorithm': 'activity_selector'}
I0828 20:18:01.425347 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0828 20:18:01.944868 129822405686784 run.py:693] Algo activity_selector step 6550 current loss 0.731001, current_train_items 90336.
I0828 20:18:01.962070 129822405686784 run.py:728] (val) algo activity_selector step 6550: {'selected': 0.8935361216730039, 'score': 0.8935361216730039, 'examples_seen': 90336, 'step': 6550, 'algorithm': 'activity_selector'}
I0828 20:18:01.962218 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0828 20:18:02.513071 129822405686784 run.py:693] Algo activity_selector step 6600 current loss 0.634453, current_train_items 91008.
I0828 20:18:02.527693 129822405686784 run.py:728] (val) algo activity_selector step 6600: {'selected': 0.8913443830570902, 'score': 0.8913443830570902, 'examples_seen': 91008, 'step': 6600, 'algorithm': 'activity_selector'}
I0828 20:18:02.527843 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0828 20:18:03.058369 129822405686784 run.py:693] Algo activity_selector step 6650 current loss 0.507095, current_train_items 91712.
I0828 20:18:03.073752 129822405686784 run.py:728] (val) algo activity_selector step 6650: {'selected': 0.8823529411764707, 'score': 0.8823529411764707, 'examples_seen': 91712, 'step': 6650, 'algorithm': 'activity_selector'}
I0828 20:18:03.073896 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.882, val scores are: activity_selector: 0.882
I0828 20:18:03.596946 129822405686784 run.py:693] Algo activity_selector step 6700 current loss 0.506065, current_train_items 92416.
I0828 20:18:03.611650 129822405686784 run.py:728] (val) algo activity_selector step 6700: {'selected': 0.89198606271777, 'score': 0.89198606271777, 'examples_seen': 92416, 'step': 6700, 'algorithm': 'activity_selector'}
I0828 20:18:03.611799 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.892, val scores are: activity_selector: 0.892
I0828 20:18:04.125941 129822405686784 run.py:693] Algo activity_selector step 6750 current loss 0.423883, current_train_items 93088.
I0828 20:18:04.140486 129822405686784 run.py:728] (val) algo activity_selector step 6750: {'selected': 0.8913857677902621, 'score': 0.8913857677902621, 'examples_seen': 93088, 'step': 6750, 'algorithm': 'activity_selector'}
I0828 20:18:04.140634 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0828 20:18:04.668373 129822405686784 run.py:693] Algo activity_selector step 6800 current loss 1.114015, current_train_items 93776.
I0828 20:18:04.683063 129822405686784 run.py:728] (val) algo activity_selector step 6800: {'selected': 0.8897485493230175, 'score': 0.8897485493230175, 'examples_seen': 93776, 'step': 6800, 'algorithm': 'activity_selector'}
I0828 20:18:04.683206 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.890, val scores are: activity_selector: 0.890
I0828 20:18:05.208326 129822405686784 run.py:693] Algo activity_selector step 6850 current loss 0.551472, current_train_items 94480.
I0828 20:18:05.223243 129822405686784 run.py:728] (val) algo activity_selector step 6850: {'selected': 0.9108159392789373, 'score': 0.9108159392789373, 'examples_seen': 94480, 'step': 6850, 'algorithm': 'activity_selector'}
I0828 20:18:05.223389 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0828 20:18:05.741077 129822405686784 run.py:693] Algo activity_selector step 6900 current loss 0.603778, current_train_items 95152.
I0828 20:18:05.757791 129822405686784 run.py:728] (val) algo activity_selector step 6900: {'selected': 0.8631578947368421, 'score': 0.8631578947368421, 'examples_seen': 95152, 'step': 6900, 'algorithm': 'activity_selector'}
I0828 20:18:05.757940 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.863, val scores are: activity_selector: 0.863
I0828 20:18:06.286946 129822405686784 run.py:693] Algo activity_selector step 6950 current loss 0.669617, current_train_items 95840.
I0828 20:18:06.304100 129822405686784 run.py:728] (val) algo activity_selector step 6950: {'selected': 0.8827292110874201, 'score': 0.8827292110874201, 'examples_seen': 95840, 'step': 6950, 'algorithm': 'activity_selector'}
I0828 20:18:06.304248 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.883, val scores are: activity_selector: 0.883
I0828 20:18:06.827684 129822405686784 run.py:693] Algo activity_selector step 7000 current loss 0.597589, current_train_items 96544.
I0828 20:18:06.843004 129822405686784 run.py:728] (val) algo activity_selector step 7000: {'selected': 0.8775894538606402, 'score': 0.8775894538606402, 'examples_seen': 96544, 'step': 7000, 'algorithm': 'activity_selector'}
I0828 20:18:06.843164 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.878, val scores are: activity_selector: 0.878
I0828 20:18:07.379301 129822405686784 run.py:693] Algo activity_selector step 7050 current loss 0.748780, current_train_items 97232.
I0828 20:18:07.394388 129822405686784 run.py:728] (val) algo activity_selector step 7050: {'selected': 0.9123505976095618, 'score': 0.9123505976095618, 'examples_seen': 97232, 'step': 7050, 'algorithm': 'activity_selector'}
I0828 20:18:07.394535 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0828 20:18:07.923499 129822405686784 run.py:693] Algo activity_selector step 7100 current loss 0.672253, current_train_items 97920.
I0828 20:18:07.938673 129822405686784 run.py:728] (val) algo activity_selector step 7100: {'selected': 0.8727272727272726, 'score': 0.8727272727272726, 'examples_seen': 97920, 'step': 7100, 'algorithm': 'activity_selector'}
I0828 20:18:07.938819 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.873, val scores are: activity_selector: 0.873
I0828 20:18:08.466249 129822405686784 run.py:693] Algo activity_selector step 7150 current loss 0.748237, current_train_items 98608.
I0828 20:18:08.481094 129822405686784 run.py:728] (val) algo activity_selector step 7150: {'selected': 0.8768115942028986, 'score': 0.8768115942028986, 'examples_seen': 98608, 'step': 7150, 'algorithm': 'activity_selector'}
I0828 20:18:08.481252 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.877, val scores are: activity_selector: 0.877
I0828 20:18:09.019077 129822405686784 run.py:693] Algo activity_selector step 7200 current loss 0.553475, current_train_items 99296.
I0828 20:18:09.034053 129822405686784 run.py:728] (val) algo activity_selector step 7200: {'selected': 0.9052224371373307, 'score': 0.9052224371373307, 'examples_seen': 99296, 'step': 7200, 'algorithm': 'activity_selector'}
I0828 20:18:09.034202 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0828 20:18:09.559032 129822405686784 run.py:693] Algo activity_selector step 7250 current loss 0.695475, current_train_items 99984.
I0828 20:18:09.573975 129822405686784 run.py:728] (val) algo activity_selector step 7250: {'selected': 0.900398406374502, 'score': 0.900398406374502, 'examples_seen': 99984, 'step': 7250, 'algorithm': 'activity_selector'}
I0828 20:18:09.574130 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.900, val scores are: activity_selector: 0.900
I0828 20:18:10.098310 129822405686784 run.py:693] Algo activity_selector step 7300 current loss 0.585876, current_train_items 100672.
I0828 20:18:10.112971 129822405686784 run.py:728] (val) algo activity_selector step 7300: {'selected': 0.9046793760831888, 'score': 0.9046793760831888, 'examples_seen': 100672, 'step': 7300, 'algorithm': 'activity_selector'}
I0828 20:18:10.113126 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0828 20:18:10.645265 129822405686784 run.py:693] Algo activity_selector step 7350 current loss 1.151154, current_train_items 101360.
I0828 20:18:10.659986 129822405686784 run.py:728] (val) algo activity_selector step 7350: {'selected': 0.888015717092338, 'score': 0.888015717092338, 'examples_seen': 101360, 'step': 7350, 'algorithm': 'activity_selector'}
I0828 20:18:10.660140 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.888, val scores are: activity_selector: 0.888
I0828 20:18:11.183463 129822405686784 run.py:693] Algo activity_selector step 7400 current loss 1.180009, current_train_items 102048.
I0828 20:18:11.198865 129822405686784 run.py:728] (val) algo activity_selector step 7400: {'selected': 0.8808664259927798, 'score': 0.8808664259927798, 'examples_seen': 102048, 'step': 7400, 'algorithm': 'activity_selector'}
I0828 20:18:11.199010 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.881, val scores are: activity_selector: 0.881
I0828 20:18:11.720900 129822405686784 run.py:693] Algo activity_selector step 7450 current loss 0.860099, current_train_items 102752.
I0828 20:18:11.735740 129822405686784 run.py:728] (val) algo activity_selector step 7450: {'selected': 0.8324697754749568, 'score': 0.8324697754749568, 'examples_seen': 102752, 'step': 7450, 'algorithm': 'activity_selector'}
I0828 20:18:11.735884 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.832, val scores are: activity_selector: 0.832
I0828 20:18:12.274373 129822405686784 run.py:693] Algo activity_selector step 7500 current loss 0.405905, current_train_items 103424.
I0828 20:18:12.289140 129822405686784 run.py:728] (val) algo activity_selector step 7500: {'selected': 0.821917808219178, 'score': 0.821917808219178, 'examples_seen': 103424, 'step': 7500, 'algorithm': 'activity_selector'}
I0828 20:18:12.289287 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.822, val scores are: activity_selector: 0.822
I0828 20:18:12.827414 129822405686784 run.py:693] Algo activity_selector step 7550 current loss 0.857588, current_train_items 104128.
I0828 20:18:12.842514 129822405686784 run.py:728] (val) algo activity_selector step 7550: {'selected': 0.8940269749518306, 'score': 0.8940269749518306, 'examples_seen': 104128, 'step': 7550, 'algorithm': 'activity_selector'}
I0828 20:18:12.842660 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0828 20:18:13.359761 129822405686784 run.py:693] Algo activity_selector step 7600 current loss 0.461413, current_train_items 104816.
I0828 20:18:13.374354 129822405686784 run.py:728] (val) algo activity_selector step 7600: {'selected': 0.8419182948490231, 'score': 0.8419182948490231, 'examples_seen': 104816, 'step': 7600, 'algorithm': 'activity_selector'}
I0828 20:18:13.374500 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.842, val scores are: activity_selector: 0.842
I0828 20:18:13.898309 129822405686784 run.py:693] Algo activity_selector step 7650 current loss 0.675182, current_train_items 105488.
I0828 20:18:13.912925 129822405686784 run.py:728] (val) algo activity_selector step 7650: {'selected': 0.8418972332015809, 'score': 0.8418972332015809, 'examples_seen': 105488, 'step': 7650, 'algorithm': 'activity_selector'}
I0828 20:18:13.913094 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.842, val scores are: activity_selector: 0.842
I0828 20:18:14.450755 129822405686784 run.py:693] Algo activity_selector step 7700 current loss 0.593519, current_train_items 106192.
I0828 20:18:14.465408 129822405686784 run.py:728] (val) algo activity_selector step 7700: {'selected': 0.915129151291513, 'score': 0.915129151291513, 'examples_seen': 106192, 'step': 7700, 'algorithm': 'activity_selector'}
I0828 20:18:14.465551 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0828 20:18:14.982533 129822405686784 run.py:693] Algo activity_selector step 7750 current loss 0.469469, current_train_items 106880.
I0828 20:18:14.997532 129822405686784 run.py:728] (val) algo activity_selector step 7750: {'selected': 0.8623853211009175, 'score': 0.8623853211009175, 'examples_seen': 106880, 'step': 7750, 'algorithm': 'activity_selector'}
I0828 20:18:14.997677 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.862, val scores are: activity_selector: 0.862
I0828 20:18:15.524144 129822405686784 run.py:693] Algo activity_selector step 7800 current loss 0.573526, current_train_items 107568.
I0828 20:18:15.539136 129822405686784 run.py:728] (val) algo activity_selector step 7800: {'selected': 0.9056603773584906, 'score': 0.9056603773584906, 'examples_seen': 107568, 'step': 7800, 'algorithm': 'activity_selector'}
I0828 20:18:15.539283 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0828 20:18:16.073182 129822405686784 run.py:693] Algo activity_selector step 7850 current loss 0.742021, current_train_items 108256.
I0828 20:18:16.088633 129822405686784 run.py:728] (val) algo activity_selector step 7850: {'selected': 0.8749999999999999, 'score': 0.8749999999999999, 'examples_seen': 108256, 'step': 7850, 'algorithm': 'activity_selector'}
I0828 20:18:16.088793 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.875, val scores are: activity_selector: 0.875
I0828 20:18:16.628350 129822405686784 run.py:693] Algo activity_selector step 7900 current loss 0.518581, current_train_items 108960.
I0828 20:18:16.644771 129822405686784 run.py:728] (val) algo activity_selector step 7900: {'selected': 0.8665377176015473, 'score': 0.8665377176015473, 'examples_seen': 108960, 'step': 7900, 'algorithm': 'activity_selector'}
I0828 20:18:16.644930 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0828 20:18:17.181661 129822405686784 run.py:693] Algo activity_selector step 7950 current loss 0.946680, current_train_items 109632.
I0828 20:18:17.196264 129822405686784 run.py:728] (val) algo activity_selector step 7950: {'selected': 0.7861060329067643, 'score': 0.7861060329067643, 'examples_seen': 109632, 'step': 7950, 'algorithm': 'activity_selector'}
I0828 20:18:17.196417 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.786, val scores are: activity_selector: 0.786
I0828 20:18:17.722453 129822405686784 run.py:693] Algo activity_selector step 8000 current loss 0.393236, current_train_items 110320.
I0828 20:18:17.737729 129822405686784 run.py:728] (val) algo activity_selector step 8000: {'selected': 0.8587786259541985, 'score': 0.8587786259541985, 'examples_seen': 110320, 'step': 8000, 'algorithm': 'activity_selector'}
I0828 20:18:17.737878 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.929, current avg val score is 0.859, val scores are: activity_selector: 0.859
I0828 20:18:18.267233 129822405686784 run.py:693] Algo activity_selector step 8050 current loss 0.632735, current_train_items 111024.
I0828 20:18:18.283758 129822405686784 run.py:728] (val) algo activity_selector step 8050: {'selected': 0.8622754491017963, 'score': 0.8622754491017963, 'examples_seen': 111024, 'step': 8050, 'algorithm': 'activity_selector'}
I0828 20:18:18.283904 129822405686784 run.py:749] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.862, val scores are: activity_selector: 0.862
I0828 20:18:18.828715 129822405686784 run.py:693] Algo activity_selector step 8100 current loss 0.514939, current_train_items 111696.
I0828 20:18:18.843902 129822405686784 run.py:728] (val) algo activity_selector step 8100: {'selected': 0.8604206500956023, 'score': 0.8604206500956023, 'examples_seen': 111696, 'step': 8100, 'algorithm': 'activity_selector'}
I0828 20:18:18.844057 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.862, current avg val score is 0.860, val scores are: activity_selector: 0.860
I0828 20:18:19.373287 129822405686784 run.py:693] Algo activity_selector step 8150 current loss 0.741853, current_train_items 112400.
I0828 20:18:19.388594 129822405686784 run.py:728] (val) algo activity_selector step 8150: {'selected': 0.8270944741532976, 'score': 0.8270944741532976, 'examples_seen': 112400, 'step': 8150, 'algorithm': 'activity_selector'}
I0828 20:18:19.388741 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.862, current avg val score is 0.827, val scores are: activity_selector: 0.827
I0828 20:18:19.918117 129822405686784 run.py:693] Algo activity_selector step 8200 current loss 0.415748, current_train_items 113088.
I0828 20:18:19.933374 129822405686784 run.py:728] (val) algo activity_selector step 8200: {'selected': 0.9111969111969112, 'score': 0.9111969111969112, 'examples_seen': 113088, 'step': 8200, 'algorithm': 'activity_selector'}
I0828 20:18:19.933519 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.862, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0828 20:18:20.469942 129822405686784 run.py:693] Algo activity_selector step 8250 current loss 0.398330, current_train_items 113760.
I0828 20:18:20.484891 129822405686784 run.py:728] (val) algo activity_selector step 8250: {'selected': 0.8599221789883269, 'score': 0.8599221789883269, 'examples_seen': 113760, 'step': 8250, 'algorithm': 'activity_selector'}
I0828 20:18:20.485045 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.860, val scores are: activity_selector: 0.860
I0828 20:18:21.025984 129822405686784 run.py:693] Algo activity_selector step 8300 current loss 0.857124, current_train_items 114464.
I0828 20:18:21.040722 129822405686784 run.py:728] (val) algo activity_selector step 8300: {'selected': 0.8774422735346358, 'score': 0.8774422735346358, 'examples_seen': 114464, 'step': 8300, 'algorithm': 'activity_selector'}
I0828 20:18:21.040868 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.877, val scores are: activity_selector: 0.877
I0828 20:18:21.557528 129822405686784 run.py:693] Algo activity_selector step 8350 current loss 0.733733, current_train_items 115152.
I0828 20:18:21.572292 129822405686784 run.py:728] (val) algo activity_selector step 8350: {'selected': 0.8926553672316384, 'score': 0.8926553672316384, 'examples_seen': 115152, 'step': 8350, 'algorithm': 'activity_selector'}
I0828 20:18:21.572438 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0828 20:18:22.104103 129822405686784 run.py:693] Algo activity_selector step 8400 current loss 0.355914, current_train_items 115840.
I0828 20:18:22.118718 129822405686784 run.py:728] (val) algo activity_selector step 8400: {'selected': 0.8866396761133603, 'score': 0.8866396761133603, 'examples_seen': 115840, 'step': 8400, 'algorithm': 'activity_selector'}
I0828 20:18:22.118865 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.887, val scores are: activity_selector: 0.887
I0828 20:18:22.643632 129822405686784 run.py:693] Algo activity_selector step 8450 current loss 0.569975, current_train_items 116528.
I0828 20:18:22.658513 129822405686784 run.py:728] (val) algo activity_selector step 8450: {'selected': 0.899047619047619, 'score': 0.899047619047619, 'examples_seen': 116528, 'step': 8450, 'algorithm': 'activity_selector'}
I0828 20:18:22.658661 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0828 20:18:23.175374 129822405686784 run.py:693] Algo activity_selector step 8500 current loss 0.609667, current_train_items 117232.
I0828 20:18:23.189855 129822405686784 run.py:728] (val) algo activity_selector step 8500: {'selected': 0.8730158730158731, 'score': 0.8730158730158731, 'examples_seen': 117232, 'step': 8500, 'algorithm': 'activity_selector'}
I0828 20:18:23.190001 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.911, current avg val score is 0.873, val scores are: activity_selector: 0.873
I0828 20:18:23.721762 129822405686784 run.py:693] Algo activity_selector step 8550 current loss 0.556979, current_train_items 117904.
I0828 20:18:23.736893 129822405686784 run.py:728] (val) algo activity_selector step 8550: {'selected': 0.9245647969052224, 'score': 0.9245647969052224, 'examples_seen': 117904, 'step': 8550, 'algorithm': 'activity_selector'}
I0828 20:18:23.737048 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.911, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0828 20:18:24.274280 129822405686784 run.py:693] Algo activity_selector step 8600 current loss 0.373746, current_train_items 118592.
I0828 20:18:24.289772 129822405686784 run.py:728] (val) algo activity_selector step 8600: {'selected': 0.899628252788104, 'score': 0.899628252788104, 'examples_seen': 118592, 'step': 8600, 'algorithm': 'activity_selector'}
I0828 20:18:24.289918 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.925, current avg val score is 0.900, val scores are: activity_selector: 0.900
I0828 20:18:24.818132 129822405686784 run.py:693] Algo activity_selector step 8650 current loss 0.971170, current_train_items 119296.
I0828 20:18:24.833458 129822405686784 run.py:728] (val) algo activity_selector step 8650: {'selected': 0.9272030651340997, 'score': 0.9272030651340997, 'examples_seen': 119296, 'step': 8650, 'algorithm': 'activity_selector'}
I0828 20:18:24.833615 129822405686784 run.py:749] Checkpointing best model, best avg val score was 0.925, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0828 20:18:25.389615 129822405686784 run.py:693] Algo activity_selector step 8700 current loss 0.446777, current_train_items 119968.
I0828 20:18:25.404759 129822405686784 run.py:728] (val) algo activity_selector step 8700: {'selected': 0.8668941979522184, 'score': 0.8668941979522184, 'examples_seen': 119968, 'step': 8700, 'algorithm': 'activity_selector'}
I0828 20:18:25.404908 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0828 20:18:25.930676 129822405686784 run.py:693] Algo activity_selector step 8750 current loss 0.350483, current_train_items 120672.
I0828 20:18:25.947407 129822405686784 run.py:728] (val) algo activity_selector step 8750: {'selected': 0.8805460750853242, 'score': 0.8805460750853242, 'examples_seen': 120672, 'step': 8750, 'algorithm': 'activity_selector'}
I0828 20:18:25.947556 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.881, val scores are: activity_selector: 0.881
I0828 20:18:26.474272 129822405686784 run.py:693] Algo activity_selector step 8800 current loss 0.603012, current_train_items 121360.
I0828 20:18:26.491960 129822405686784 run.py:728] (val) algo activity_selector step 8800: {'selected': 0.8695652173913043, 'score': 0.8695652173913043, 'examples_seen': 121360, 'step': 8800, 'algorithm': 'activity_selector'}
I0828 20:18:26.492113 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.870, val scores are: activity_selector: 0.870
I0828 20:18:27.020808 129822405686784 run.py:693] Algo activity_selector step 8850 current loss 0.397344, current_train_items 122048.
I0828 20:18:27.035983 129822405686784 run.py:728] (val) algo activity_selector step 8850: {'selected': 0.8943661971830985, 'score': 0.8943661971830985, 'examples_seen': 122048, 'step': 8850, 'algorithm': 'activity_selector'}
I0828 20:18:27.036135 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0828 20:18:27.571408 129822405686784 run.py:693] Algo activity_selector step 8900 current loss 0.725148, current_train_items 122736.
I0828 20:18:27.586250 129822405686784 run.py:728] (val) algo activity_selector step 8900: {'selected': 0.873394495412844, 'score': 0.873394495412844, 'examples_seen': 122736, 'step': 8900, 'algorithm': 'activity_selector'}
I0828 20:18:27.586395 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.873, val scores are: activity_selector: 0.873
I0828 20:18:28.102829 129822405686784 run.py:693] Algo activity_selector step 8950 current loss 0.761031, current_train_items 123424.
I0828 20:18:28.117309 129822405686784 run.py:728] (val) algo activity_selector step 8950: {'selected': 0.8759124087591241, 'score': 0.8759124087591241, 'examples_seen': 123424, 'step': 8950, 'algorithm': 'activity_selector'}
I0828 20:18:28.117457 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.876, val scores are: activity_selector: 0.876
I0828 20:18:28.645473 129822405686784 run.py:693] Algo activity_selector step 9000 current loss 0.627164, current_train_items 124112.
I0828 20:18:28.660068 129822405686784 run.py:728] (val) algo activity_selector step 9000: {'selected': 0.8893360160965794, 'score': 0.8893360160965794, 'examples_seen': 124112, 'step': 9000, 'algorithm': 'activity_selector'}
I0828 20:18:28.660212 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.889, val scores are: activity_selector: 0.889
I0828 20:18:29.184974 129822405686784 run.py:693] Algo activity_selector step 9050 current loss 0.408104, current_train_items 124800.
I0828 20:18:29.202291 129822405686784 run.py:728] (val) algo activity_selector step 9050: {'selected': 0.8801498127340823, 'score': 0.8801498127340823, 'examples_seen': 124800, 'step': 9050, 'algorithm': 'activity_selector'}
I0828 20:18:29.202447 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0828 20:18:29.721330 129822405686784 run.py:693] Algo activity_selector step 9100 current loss 0.772227, current_train_items 125488.
I0828 20:18:29.736825 129822405686784 run.py:728] (val) algo activity_selector step 9100: {'selected': 0.922794117647059, 'score': 0.922794117647059, 'examples_seen': 125488, 'step': 9100, 'algorithm': 'activity_selector'}
I0828 20:18:29.736972 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.923, val scores are: activity_selector: 0.923
I0828 20:18:30.272711 129822405686784 run.py:693] Algo activity_selector step 9150 current loss 1.005989, current_train_items 126176.
I0828 20:18:30.287739 129822405686784 run.py:728] (val) algo activity_selector step 9150: {'selected': 0.9139784946236559, 'score': 0.9139784946236559, 'examples_seen': 126176, 'step': 9150, 'algorithm': 'activity_selector'}
I0828 20:18:30.287886 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0828 20:18:30.811848 129822405686784 run.py:693] Algo activity_selector step 9200 current loss 0.790501, current_train_items 126880.
I0828 20:18:30.826667 129822405686784 run.py:728] (val) algo activity_selector step 9200: {'selected': 0.8617594254937163, 'score': 0.8617594254937163, 'examples_seen': 126880, 'step': 9200, 'algorithm': 'activity_selector'}
I0828 20:18:30.826811 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.862, val scores are: activity_selector: 0.862
I0828 20:18:31.355525 129822405686784 run.py:693] Algo activity_selector step 9250 current loss 0.532577, current_train_items 127568.
I0828 20:18:31.370750 129822405686784 run.py:728] (val) algo activity_selector step 9250: {'selected': 0.8636363636363636, 'score': 0.8636363636363636, 'examples_seen': 127568, 'step': 9250, 'algorithm': 'activity_selector'}
I0828 20:18:31.370908 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.864, val scores are: activity_selector: 0.864
I0828 20:18:31.892897 129822405686784 run.py:693] Algo activity_selector step 9300 current loss 0.538432, current_train_items 128240.
I0828 20:18:31.908408 129822405686784 run.py:728] (val) algo activity_selector step 9300: {'selected': 0.886986301369863, 'score': 0.886986301369863, 'examples_seen': 128240, 'step': 9300, 'algorithm': 'activity_selector'}
I0828 20:18:31.908553 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.887, val scores are: activity_selector: 0.887
I0828 20:18:32.442387 129822405686784 run.py:693] Algo activity_selector step 9350 current loss 0.608986, current_train_items 128944.
I0828 20:18:32.457007 129822405686784 run.py:728] (val) algo activity_selector step 9350: {'selected': 0.9132743362831859, 'score': 0.9132743362831859, 'examples_seen': 128944, 'step': 9350, 'algorithm': 'activity_selector'}
I0828 20:18:32.457165 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0828 20:18:32.974137 129822405686784 run.py:693] Algo activity_selector step 9400 current loss 0.465533, current_train_items 129632.
I0828 20:18:32.989173 129822405686784 run.py:728] (val) algo activity_selector step 9400: {'selected': 0.9014084507042254, 'score': 0.9014084507042254, 'examples_seen': 129632, 'step': 9400, 'algorithm': 'activity_selector'}
I0828 20:18:32.989320 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.901, val scores are: activity_selector: 0.901
I0828 20:18:33.508729 129822405686784 run.py:693] Algo activity_selector step 9450 current loss 0.640541, current_train_items 130304.
I0828 20:18:33.523685 129822405686784 run.py:728] (val) algo activity_selector step 9450: {'selected': 0.8938547486033519, 'score': 0.8938547486033519, 'examples_seen': 130304, 'step': 9450, 'algorithm': 'activity_selector'}
I0828 20:18:33.523831 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.894, val scores are: activity_selector: 0.894
I0828 20:18:34.072987 129822405686784 run.py:693] Algo activity_selector step 9500 current loss 0.655913, current_train_items 131008.
I0828 20:18:34.088466 129822405686784 run.py:728] (val) algo activity_selector step 9500: {'selected': 0.8961538461538462, 'score': 0.8961538461538462, 'examples_seen': 131008, 'step': 9500, 'algorithm': 'activity_selector'}
I0828 20:18:34.088617 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0828 20:18:34.604174 129822405686784 run.py:693] Algo activity_selector step 9550 current loss 0.357557, current_train_items 131712.
I0828 20:18:34.618816 129822405686784 run.py:728] (val) algo activity_selector step 9550: {'selected': 0.8905660377358491, 'score': 0.8905660377358491, 'examples_seen': 131712, 'step': 9550, 'algorithm': 'activity_selector'}
I0828 20:18:34.618961 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0828 20:18:35.139790 129822405686784 run.py:693] Algo activity_selector step 9600 current loss 0.714000, current_train_items 132384.
I0828 20:18:35.154948 129822405686784 run.py:728] (val) algo activity_selector step 9600: {'selected': 0.8520499108734402, 'score': 0.8520499108734402, 'examples_seen': 132384, 'step': 9600, 'algorithm': 'activity_selector'}
I0828 20:18:35.155101 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.852, val scores are: activity_selector: 0.852
I0828 20:18:35.691398 129822405686784 run.py:693] Algo activity_selector step 9650 current loss 0.604018, current_train_items 133072.
I0828 20:18:35.707262 129822405686784 run.py:728] (val) algo activity_selector step 9650: {'selected': 0.87890625, 'score': 0.87890625, 'examples_seen': 133072, 'step': 9650, 'algorithm': 'activity_selector'}
I0828 20:18:35.707408 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0828 20:18:36.227982 129822405686784 run.py:693] Algo activity_selector step 9700 current loss 0.631719, current_train_items 133776.
I0828 20:18:36.243290 129822405686784 run.py:728] (val) algo activity_selector step 9700: {'selected': 0.8857644991212654, 'score': 0.8857644991212654, 'examples_seen': 133776, 'step': 9700, 'algorithm': 'activity_selector'}
I0828 20:18:36.243448 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0828 20:18:36.767163 129822405686784 run.py:693] Algo activity_selector step 9750 current loss 1.031216, current_train_items 134448.
I0828 20:18:36.781625 129822405686784 run.py:728] (val) algo activity_selector step 9750: {'selected': 0.9123434704830053, 'score': 0.9123434704830053, 'examples_seen': 134448, 'step': 9750, 'algorithm': 'activity_selector'}
I0828 20:18:36.781774 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0828 20:18:37.300941 129822405686784 run.py:693] Algo activity_selector step 9800 current loss 0.485661, current_train_items 135136.
I0828 20:18:37.316249 129822405686784 run.py:728] (val) algo activity_selector step 9800: {'selected': 0.9246031746031745, 'score': 0.9246031746031745, 'examples_seen': 135136, 'step': 9800, 'algorithm': 'activity_selector'}
I0828 20:18:37.316396 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0828 20:18:37.845516 129822405686784 run.py:693] Algo activity_selector step 9850 current loss 0.834527, current_train_items 135840.
I0828 20:18:37.862668 129822405686784 run.py:728] (val) algo activity_selector step 9850: {'selected': 0.8821292775665399, 'score': 0.8821292775665399, 'examples_seen': 135840, 'step': 9850, 'algorithm': 'activity_selector'}
I0828 20:18:37.862816 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.882, val scores are: activity_selector: 0.882
I0828 20:18:38.403563 129822405686784 run.py:693] Algo activity_selector step 9900 current loss 0.747390, current_train_items 136528.
I0828 20:18:38.419627 129822405686784 run.py:728] (val) algo activity_selector step 9900: {'selected': 0.8757396449704142, 'score': 0.8757396449704142, 'examples_seen': 136528, 'step': 9900, 'algorithm': 'activity_selector'}
I0828 20:18:38.419782 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.876, val scores are: activity_selector: 0.876
I0828 20:18:38.943226 129822405686784 run.py:693] Algo activity_selector step 9950 current loss 0.396897, current_train_items 137200.
I0828 20:18:38.958531 129822405686784 run.py:728] (val) algo activity_selector step 9950: {'selected': 0.8925925925925926, 'score': 0.8925925925925926, 'examples_seen': 137200, 'step': 9950, 'algorithm': 'activity_selector'}
I0828 20:18:38.958686 129822405686784 run.py:752] Not saving new best model, best avg val score was 0.927, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0828 20:18:39.481268 129822405686784 run.py:758] Restoring best model from checkpoint...
I0828 20:18:42.295342 129822405686784 run.py:773] (test) algo activity_selector : {'selected': 0.7333333333333333, 'score': 0.7333333333333333, 'examples_seen': 137888, 'step': 10000, 'algorithm': 'activity_selector'}
I0828 20:18:42.295459 129822405686784 run.py:775] Done!
