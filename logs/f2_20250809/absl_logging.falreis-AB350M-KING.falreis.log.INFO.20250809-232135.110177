I0809 23:21:37.882523 126285554812416 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0809 23:21:37.883115 126285554812416 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0809 23:21:38.108174 126285554812416 run.py:410] Model: f2 ['activity_selector']
I0809 23:21:38.108275 126285554812416 run.py:412] algorithms ['activity_selector']
I0809 23:21:38.108458 126285554812416 run.py:413] train_lengths [-1]
I0809 23:21:38.108495 126285554812416 run.py:414] train_batch_size 16
I0809 23:21:38.108591 126285554812416 run.py:415] val_batch_size 8
I0809 23:21:38.108623 126285554812416 run.py:416] test_batch_size 8
I0809 23:21:38.108653 126285554812416 run.py:417] chunked_training True
I0809 23:21:38.108775 126285554812416 run.py:418] chunk_length 16
I0809 23:21:38.108806 126285554812416 run.py:419] train_steps 10000
I0809 23:21:38.108836 126285554812416 run.py:420] eval_every 50
I0809 23:21:38.108864 126285554812416 run.py:421] test_every 500
I0809 23:21:38.108893 126285554812416 run.py:422] learning_rate 0.001
I0809 23:21:38.108988 126285554812416 run.py:423] grad_clip_max_norm 1.0
I0809 23:21:38.109018 126285554812416 run.py:424] dropout_prob 0.1
I0809 23:21:38.109048 126285554812416 run.py:425] hint_teacher_forcing 0.0
I0809 23:21:38.109076 126285554812416 run.py:426] hint_mode encoded_decoded
I0809 23:21:38.109187 126285554812416 run.py:427] hint_repred_mode hard_on_eval
I0809 23:21:38.109216 126285554812416 run.py:428] use_ln False
I0809 23:21:38.109244 126285554812416 run.py:429] use_lstm True
I0809 23:21:38.109272 126285554812416 run.py:430] nb_triplet_fts 8
I0809 23:21:38.109299 126285554812416 run.py:431] encoder_init xavier_on_scalars
I0809 23:21:38.109327 126285554812416 run.py:432] processor_type f2
I0809 23:21:38.109354 126285554812416 run.py:433] checkpoint_path CLRS30
I0809 23:21:38.109385 126285554812416 run.py:434] dataset_path CLRS30
I0809 23:21:38.109414 126285554812416 run.py:435] freeze_processor False
I0809 23:21:38.109442 126285554812416 run.py:436] reduction min
I0809 23:21:38.109470 126285554812416 run.py:437] activation elu
I0809 23:21:38.109498 126285554812416 run.py:438] restore_model 
I0809 23:21:38.109525 126285554812416 run.py:439] gated True
I0809 23:21:38.109553 126285554812416 run.py:440] gated_activation sigmoid
I0809 23:21:38.112189 126285554812416 run.py:466] Creating samplers for algo activity_selector
I0809 23:21:38.112310 126285554812416 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0809 23:21:38.112973 126285554812416 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_train/1.0.0
I0809 23:21:38.115637 126285554812416 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_train/1.0.0
I0809 23:21:38.118798 126285554812416 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_train/1.0.0.
I0809 23:21:38.170225 126285554812416 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split train, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_train/1.0.0
W0809 23:21:38.191128 126285554812416 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x72daa118ae80> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0809 23:21:38.267459 126285554812416 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0809 23:21:38.268082 126285554812416 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_val/1.0.0
I0809 23:21:38.270361 126285554812416 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_val/1.0.0
I0809 23:21:38.272213 126285554812416 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_val/1.0.0.
I0809 23:21:38.306023 126285554812416 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split val, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_val/1.0.0
I0809 23:21:38.383398 126285554812416 run.py:254] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0809 23:21:38.383962 126285554812416 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0809 23:21:38.385988 126285554812416 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0809 23:21:38.387873 126285554812416 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0809 23:21:38.421341 126285554812416 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0809 23:21:59.445037 126285554812416 run.py:689] Algo activity_selector step 0 current loss 7.041360, current_train_items 16.
I0809 23:22:04.819670 126285554812416 run.py:724] (val) algo activity_selector step 0: {'selected': 0.2909090909090909, 'score': 0.2909090909090909, 'examples_seen': 16, 'step': 0, 'algorithm': 'activity_selector'}
I0809 23:22:04.819837 126285554812416 run.py:745] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.291, val scores are: activity_selector: 0.291
I0809 23:22:05.537009 126285554812416 run.py:689] Algo activity_selector step 50 current loss 5.188640, current_train_items 768.
I0809 23:22:05.633086 126285554812416 run.py:724] (val) algo activity_selector step 50: {'selected': 0.56957928802589, 'score': 0.56957928802589, 'examples_seen': 768, 'step': 50, 'algorithm': 'activity_selector'}
I0809 23:22:05.633338 126285554812416 run.py:745] Checkpointing best model, best avg val score was 0.291, current avg val score is 0.570, val scores are: activity_selector: 0.570
I0809 23:22:06.348369 126285554812416 run.py:689] Algo activity_selector step 100 current loss 4.179227, current_train_items 1520.
I0809 23:22:06.461087 126285554812416 run.py:724] (val) algo activity_selector step 100: {'selected': 0.45685279187817257, 'score': 0.45685279187817257, 'examples_seen': 1520, 'step': 100, 'algorithm': 'activity_selector'}
I0809 23:22:06.461327 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.570, current avg val score is 0.457, val scores are: activity_selector: 0.457
I0809 23:22:07.170772 126285554812416 run.py:689] Algo activity_selector step 150 current loss 5.192113, current_train_items 2288.
I0809 23:22:07.267309 126285554812416 run.py:724] (val) algo activity_selector step 150: {'selected': 0.6636771300448431, 'score': 0.6636771300448431, 'examples_seen': 2288, 'step': 150, 'algorithm': 'activity_selector'}
I0809 23:22:07.267530 126285554812416 run.py:745] Checkpointing best model, best avg val score was 0.570, current avg val score is 0.664, val scores are: activity_selector: 0.664
I0809 23:22:07.994241 126285554812416 run.py:689] Algo activity_selector step 200 current loss 5.634077, current_train_items 3040.
I0809 23:22:08.091674 126285554812416 run.py:724] (val) algo activity_selector step 200: {'selected': 0.683982683982684, 'score': 0.683982683982684, 'examples_seen': 3040, 'step': 200, 'algorithm': 'activity_selector'}
I0809 23:22:08.091899 126285554812416 run.py:745] Checkpointing best model, best avg val score was 0.664, current avg val score is 0.684, val scores are: activity_selector: 0.684
I0809 23:22:08.813299 126285554812416 run.py:689] Algo activity_selector step 250 current loss 4.971612, current_train_items 3792.
I0809 23:22:08.910112 126285554812416 run.py:724] (val) algo activity_selector step 250: {'selected': 0.6901960784313725, 'score': 0.6901960784313725, 'examples_seen': 3792, 'step': 250, 'algorithm': 'activity_selector'}
I0809 23:22:08.910366 126285554812416 run.py:745] Checkpointing best model, best avg val score was 0.684, current avg val score is 0.690, val scores are: activity_selector: 0.690
I0809 23:22:09.634704 126285554812416 run.py:689] Algo activity_selector step 300 current loss 4.464202, current_train_items 4544.
I0809 23:22:09.731177 126285554812416 run.py:724] (val) algo activity_selector step 300: {'selected': 0.708171206225681, 'score': 0.708171206225681, 'examples_seen': 4544, 'step': 300, 'algorithm': 'activity_selector'}
I0809 23:22:09.731404 126285554812416 run.py:745] Checkpointing best model, best avg val score was 0.690, current avg val score is 0.708, val scores are: activity_selector: 0.708
I0809 23:22:10.455896 126285554812416 run.py:689] Algo activity_selector step 350 current loss 3.842089, current_train_items 5296.
I0809 23:22:10.552480 126285554812416 run.py:724] (val) algo activity_selector step 350: {'selected': 0.751054852320675, 'score': 0.751054852320675, 'examples_seen': 5296, 'step': 350, 'algorithm': 'activity_selector'}
I0809 23:22:10.552707 126285554812416 run.py:745] Checkpointing best model, best avg val score was 0.708, current avg val score is 0.751, val scores are: activity_selector: 0.751
I0809 23:22:11.273023 126285554812416 run.py:689] Algo activity_selector step 400 current loss 3.713072, current_train_items 6048.
I0809 23:22:11.369916 126285554812416 run.py:724] (val) algo activity_selector step 400: {'selected': 0.6333333333333333, 'score': 0.6333333333333333, 'examples_seen': 6048, 'step': 400, 'algorithm': 'activity_selector'}
I0809 23:22:11.370155 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.751, current avg val score is 0.633, val scores are: activity_selector: 0.633
I0809 23:22:12.075000 126285554812416 run.py:689] Algo activity_selector step 450 current loss 3.641178, current_train_items 6800.
I0809 23:22:12.172205 126285554812416 run.py:724] (val) algo activity_selector step 450: {'selected': 0.658008658008658, 'score': 0.658008658008658, 'examples_seen': 6800, 'step': 450, 'algorithm': 'activity_selector'}
I0809 23:22:12.172428 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.751, current avg val score is 0.658, val scores are: activity_selector: 0.658
I0809 23:22:12.871518 126285554812416 run.py:689] Algo activity_selector step 500 current loss 3.508813, current_train_items 7552.
I0809 23:22:12.974301 126285554812416 run.py:724] (val) algo activity_selector step 500: {'selected': 0.7441860465116279, 'score': 0.7441860465116279, 'examples_seen': 7552, 'step': 500, 'algorithm': 'activity_selector'}
I0809 23:22:12.974532 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.751, current avg val score is 0.744, val scores are: activity_selector: 0.744
I0809 23:22:13.666429 126285554812416 run.py:689] Algo activity_selector step 550 current loss 3.420912, current_train_items 8304.
I0809 23:22:13.776233 126285554812416 run.py:724] (val) algo activity_selector step 550: {'selected': 0.7912087912087913, 'score': 0.7912087912087913, 'examples_seen': 8304, 'step': 550, 'algorithm': 'activity_selector'}
I0809 23:22:13.776491 126285554812416 run.py:745] Checkpointing best model, best avg val score was 0.751, current avg val score is 0.791, val scores are: activity_selector: 0.791
I0809 23:22:14.502114 126285554812416 run.py:689] Algo activity_selector step 600 current loss 3.002809, current_train_items 9056.
I0809 23:22:14.598358 126285554812416 run.py:724] (val) algo activity_selector step 600: {'selected': 0.7786259541984732, 'score': 0.7786259541984732, 'examples_seen': 9056, 'step': 600, 'algorithm': 'activity_selector'}
I0809 23:22:14.598583 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.791, current avg val score is 0.779, val scores are: activity_selector: 0.779
I0809 23:22:15.303319 126285554812416 run.py:689] Algo activity_selector step 650 current loss 3.405824, current_train_items 9808.
I0809 23:22:15.399833 126285554812416 run.py:724] (val) algo activity_selector step 650: {'selected': 0.726530612244898, 'score': 0.726530612244898, 'examples_seen': 9808, 'step': 650, 'algorithm': 'activity_selector'}
I0809 23:22:15.400059 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.791, current avg val score is 0.727, val scores are: activity_selector: 0.727
I0809 23:22:16.104997 126285554812416 run.py:689] Algo activity_selector step 700 current loss 3.234145, current_train_items 10560.
I0809 23:22:16.201370 126285554812416 run.py:724] (val) algo activity_selector step 700: {'selected': 0.7870036101083032, 'score': 0.7870036101083032, 'examples_seen': 10560, 'step': 700, 'algorithm': 'activity_selector'}
I0809 23:22:16.201597 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.791, current avg val score is 0.787, val scores are: activity_selector: 0.787
I0809 23:22:16.906353 126285554812416 run.py:689] Algo activity_selector step 750 current loss 3.227951, current_train_items 11312.
I0809 23:22:16.999246 126285554812416 run.py:724] (val) algo activity_selector step 750: {'selected': 0.832116788321168, 'score': 0.832116788321168, 'examples_seen': 11312, 'step': 750, 'algorithm': 'activity_selector'}
I0809 23:22:16.999407 126285554812416 run.py:745] Checkpointing best model, best avg val score was 0.791, current avg val score is 0.832, val scores are: activity_selector: 0.832
I0809 23:22:17.729803 126285554812416 run.py:689] Algo activity_selector step 800 current loss 2.514847, current_train_items 12064.
I0809 23:22:17.827263 126285554812416 run.py:724] (val) algo activity_selector step 800: {'selected': 0.7908745247148289, 'score': 0.7908745247148289, 'examples_seen': 12064, 'step': 800, 'algorithm': 'activity_selector'}
I0809 23:22:17.827488 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.832, current avg val score is 0.791, val scores are: activity_selector: 0.791
I0809 23:22:18.528360 126285554812416 run.py:689] Algo activity_selector step 850 current loss 2.791741, current_train_items 12816.
I0809 23:22:18.630579 126285554812416 run.py:724] (val) algo activity_selector step 850: {'selected': 0.8296296296296297, 'score': 0.8296296296296297, 'examples_seen': 12816, 'step': 850, 'algorithm': 'activity_selector'}
I0809 23:22:18.630807 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.832, current avg val score is 0.830, val scores are: activity_selector: 0.830
I0809 23:22:19.336786 126285554812416 run.py:689] Algo activity_selector step 900 current loss 2.419375, current_train_items 13568.
I0809 23:22:19.432623 126285554812416 run.py:724] (val) algo activity_selector step 900: {'selected': 0.8217054263565892, 'score': 0.8217054263565892, 'examples_seen': 13568, 'step': 900, 'algorithm': 'activity_selector'}
I0809 23:22:19.432848 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.832, current avg val score is 0.822, val scores are: activity_selector: 0.822
I0809 23:22:20.138504 126285554812416 run.py:689] Algo activity_selector step 950 current loss 1.826732, current_train_items 14320.
I0809 23:22:20.234645 126285554812416 run.py:724] (val) algo activity_selector step 950: {'selected': 0.7836734693877551, 'score': 0.7836734693877551, 'examples_seen': 14320, 'step': 950, 'algorithm': 'activity_selector'}
I0809 23:22:20.234867 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.832, current avg val score is 0.784, val scores are: activity_selector: 0.784
I0809 23:22:20.940858 126285554812416 run.py:689] Algo activity_selector step 1000 current loss 4.676696, current_train_items 15088.
I0809 23:22:21.036802 126285554812416 run.py:724] (val) algo activity_selector step 1000: {'selected': 0.7968749999999999, 'score': 0.7968749999999999, 'examples_seen': 15088, 'step': 1000, 'algorithm': 'activity_selector'}
I0809 23:22:21.037031 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.832, current avg val score is 0.797, val scores are: activity_selector: 0.797
I0809 23:22:21.738403 126285554812416 run.py:689] Algo activity_selector step 1050 current loss 4.386219, current_train_items 15840.
I0809 23:22:21.836625 126285554812416 run.py:724] (val) algo activity_selector step 1050: {'selected': 0.8846153846153846, 'score': 0.8846153846153846, 'examples_seen': 15840, 'step': 1050, 'algorithm': 'activity_selector'}
I0809 23:22:21.836847 126285554812416 run.py:745] Checkpointing best model, best avg val score was 0.832, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0809 23:22:22.561375 126285554812416 run.py:689] Algo activity_selector step 1100 current loss 4.121232, current_train_items 16592.
I0809 23:22:22.659382 126285554812416 run.py:724] (val) algo activity_selector step 1100: {'selected': 0.8537549407114625, 'score': 0.8537549407114625, 'examples_seen': 16592, 'step': 1100, 'algorithm': 'activity_selector'}
I0809 23:22:22.659603 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.885, current avg val score is 0.854, val scores are: activity_selector: 0.854
I0809 23:22:23.357235 126285554812416 run.py:689] Algo activity_selector step 1150 current loss 3.745413, current_train_items 17344.
I0809 23:22:23.460468 126285554812416 run.py:724] (val) algo activity_selector step 1150: {'selected': 0.8239999999999998, 'score': 0.8239999999999998, 'examples_seen': 17344, 'step': 1150, 'algorithm': 'activity_selector'}
I0809 23:22:23.460694 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.885, current avg val score is 0.824, val scores are: activity_selector: 0.824
I0809 23:22:24.165731 126285554812416 run.py:689] Algo activity_selector step 1200 current loss 3.365667, current_train_items 18096.
I0809 23:22:24.261497 126285554812416 run.py:724] (val) algo activity_selector step 1200: {'selected': 0.8527131782945736, 'score': 0.8527131782945736, 'examples_seen': 18096, 'step': 1200, 'algorithm': 'activity_selector'}
I0809 23:22:24.261721 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.885, current avg val score is 0.853, val scores are: activity_selector: 0.853
I0809 23:22:24.966576 126285554812416 run.py:689] Algo activity_selector step 1250 current loss 2.856260, current_train_items 18848.
I0809 23:22:25.065037 126285554812416 run.py:724] (val) algo activity_selector step 1250: {'selected': 0.8256227758007119, 'score': 0.8256227758007119, 'examples_seen': 18848, 'step': 1250, 'algorithm': 'activity_selector'}
I0809 23:22:25.065272 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.885, current avg val score is 0.826, val scores are: activity_selector: 0.826
I0809 23:22:25.770379 126285554812416 run.py:689] Algo activity_selector step 1300 current loss 2.994997, current_train_items 19600.
I0809 23:22:25.866434 126285554812416 run.py:724] (val) algo activity_selector step 1300: {'selected': 0.8085106382978723, 'score': 0.8085106382978723, 'examples_seen': 19600, 'step': 1300, 'algorithm': 'activity_selector'}
I0809 23:22:25.866659 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.885, current avg val score is 0.809, val scores are: activity_selector: 0.809
I0809 23:22:26.571892 126285554812416 run.py:689] Algo activity_selector step 1350 current loss 2.678840, current_train_items 20352.
I0809 23:22:26.670179 126285554812416 run.py:724] (val) algo activity_selector step 1350: {'selected': 0.8449612403100775, 'score': 0.8449612403100775, 'examples_seen': 20352, 'step': 1350, 'algorithm': 'activity_selector'}
I0809 23:22:26.670408 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.885, current avg val score is 0.845, val scores are: activity_selector: 0.845
I0809 23:22:27.375989 126285554812416 run.py:689] Algo activity_selector step 1400 current loss 2.421201, current_train_items 21104.
I0809 23:22:27.472777 126285554812416 run.py:724] (val) algo activity_selector step 1400: {'selected': 0.8539325842696629, 'score': 0.8539325842696629, 'examples_seen': 21104, 'step': 1400, 'algorithm': 'activity_selector'}
I0809 23:22:27.473016 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.885, current avg val score is 0.854, val scores are: activity_selector: 0.854
I0809 23:22:28.180492 126285554812416 run.py:689] Algo activity_selector step 1450 current loss 2.366554, current_train_items 21856.
I0809 23:22:28.275288 126285554812416 run.py:724] (val) algo activity_selector step 1450: {'selected': 0.803030303030303, 'score': 0.803030303030303, 'examples_seen': 21856, 'step': 1450, 'algorithm': 'activity_selector'}
I0809 23:22:28.275510 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.885, current avg val score is 0.803, val scores are: activity_selector: 0.803
I0809 23:22:28.974132 126285554812416 run.py:689] Algo activity_selector step 1500 current loss 2.480675, current_train_items 22608.
I0809 23:22:29.078842 126285554812416 run.py:724] (val) algo activity_selector step 1500: {'selected': 0.8840579710144928, 'score': 0.8840579710144928, 'examples_seen': 22608, 'step': 1500, 'algorithm': 'activity_selector'}
I0809 23:22:29.079070 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.885, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0809 23:22:29.768416 126285554812416 run.py:689] Algo activity_selector step 1550 current loss 1.985171, current_train_items 23360.
I0809 23:22:29.881811 126285554812416 run.py:724] (val) algo activity_selector step 1550: {'selected': 0.899628252788104, 'score': 0.899628252788104, 'examples_seen': 23360, 'step': 1550, 'algorithm': 'activity_selector'}
I0809 23:22:29.882037 126285554812416 run.py:745] Checkpointing best model, best avg val score was 0.885, current avg val score is 0.900, val scores are: activity_selector: 0.900
I0809 23:22:30.593745 126285554812416 run.py:689] Algo activity_selector step 1600 current loss 2.047229, current_train_items 24112.
I0809 23:22:30.703260 126285554812416 run.py:724] (val) algo activity_selector step 1600: {'selected': 0.8671875, 'score': 0.8671875, 'examples_seen': 24112, 'step': 1600, 'algorithm': 'activity_selector'}
I0809 23:22:30.703485 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.900, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0809 23:22:31.409402 126285554812416 run.py:689] Algo activity_selector step 1650 current loss 1.611990, current_train_items 24864.
I0809 23:22:31.505542 126285554812416 run.py:724] (val) algo activity_selector step 1650: {'selected': 0.8519855595667871, 'score': 0.8519855595667871, 'examples_seen': 24864, 'step': 1650, 'algorithm': 'activity_selector'}
I0809 23:22:31.505773 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.900, current avg val score is 0.852, val scores are: activity_selector: 0.852
I0809 23:22:32.211738 126285554812416 run.py:689] Algo activity_selector step 1700 current loss 1.744412, current_train_items 25616.
I0809 23:22:32.309268 126285554812416 run.py:724] (val) algo activity_selector step 1700: {'selected': 0.8130081300813008, 'score': 0.8130081300813008, 'examples_seen': 25616, 'step': 1700, 'algorithm': 'activity_selector'}
I0809 23:22:32.309495 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.900, current avg val score is 0.813, val scores are: activity_selector: 0.813
I0809 23:22:33.014508 126285554812416 run.py:689] Algo activity_selector step 1750 current loss 1.788468, current_train_items 26368.
I0809 23:22:33.110784 126285554812416 run.py:724] (val) algo activity_selector step 1750: {'selected': 0.9019607843137256, 'score': 0.9019607843137256, 'examples_seen': 26368, 'step': 1750, 'algorithm': 'activity_selector'}
I0809 23:22:33.111010 126285554812416 run.py:745] Checkpointing best model, best avg val score was 0.900, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0809 23:22:33.837787 126285554812416 run.py:689] Algo activity_selector step 1800 current loss 1.141227, current_train_items 27120.
I0809 23:22:33.934435 126285554812416 run.py:724] (val) algo activity_selector step 1800: {'selected': 0.8725868725868725, 'score': 0.8725868725868725, 'examples_seen': 27120, 'step': 1800, 'algorithm': 'activity_selector'}
I0809 23:22:33.934659 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.902, current avg val score is 0.873, val scores are: activity_selector: 0.873
I0809 23:22:34.641036 126285554812416 run.py:689] Algo activity_selector step 1850 current loss 4.590458, current_train_items 27888.
I0809 23:22:34.738134 126285554812416 run.py:724] (val) algo activity_selector step 1850: {'selected': 0.9581749049429658, 'score': 0.9581749049429658, 'examples_seen': 27888, 'step': 1850, 'algorithm': 'activity_selector'}
I0809 23:22:34.738381 126285554812416 run.py:745] Checkpointing best model, best avg val score was 0.902, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0809 23:22:35.457898 126285554812416 run.py:689] Algo activity_selector step 1900 current loss 4.651651, current_train_items 28640.
I0809 23:22:35.554934 126285554812416 run.py:724] (val) algo activity_selector step 1900: {'selected': 0.8759124087591241, 'score': 0.8759124087591241, 'examples_seen': 28640, 'step': 1900, 'algorithm': 'activity_selector'}
I0809 23:22:35.555190 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.876, val scores are: activity_selector: 0.876
I0809 23:22:36.255559 126285554812416 run.py:689] Algo activity_selector step 1950 current loss 3.769130, current_train_items 29392.
I0809 23:22:36.478991 126285554812416 run.py:724] (val) algo activity_selector step 1950: {'selected': 0.862453531598513, 'score': 0.862453531598513, 'examples_seen': 29392, 'step': 1950, 'algorithm': 'activity_selector'}
I0809 23:22:36.479148 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.862, val scores are: activity_selector: 0.862
I0809 23:22:37.164316 126285554812416 run.py:689] Algo activity_selector step 2000 current loss 3.206566, current_train_items 30144.
I0809 23:22:37.273272 126285554812416 run.py:724] (val) algo activity_selector step 2000: {'selected': 0.8695652173913043, 'score': 0.8695652173913043, 'examples_seen': 30144, 'step': 2000, 'algorithm': 'activity_selector'}
I0809 23:22:37.273499 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.870, val scores are: activity_selector: 0.870
I0809 23:22:37.963406 126285554812416 run.py:689] Algo activity_selector step 2050 current loss 3.061971, current_train_items 30896.
I0809 23:22:38.075857 126285554812416 run.py:724] (val) algo activity_selector step 2050: {'selected': 0.8832116788321167, 'score': 0.8832116788321167, 'examples_seen': 30896, 'step': 2050, 'algorithm': 'activity_selector'}
I0809 23:22:38.076085 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.883, val scores are: activity_selector: 0.883
I0809 23:22:38.767390 126285554812416 run.py:689] Algo activity_selector step 2100 current loss 2.635249, current_train_items 31648.
I0809 23:22:38.879487 126285554812416 run.py:724] (val) algo activity_selector step 2100: {'selected': 0.8754716981132076, 'score': 0.8754716981132076, 'examples_seen': 31648, 'step': 2100, 'algorithm': 'activity_selector'}
I0809 23:22:38.879715 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.875, val scores are: activity_selector: 0.875
I0809 23:22:39.586528 126285554812416 run.py:689] Algo activity_selector step 2150 current loss 2.520668, current_train_items 32400.
I0809 23:22:39.681620 126285554812416 run.py:724] (val) algo activity_selector step 2150: {'selected': 0.8955223880597014, 'score': 0.8955223880597014, 'examples_seen': 32400, 'step': 2150, 'algorithm': 'activity_selector'}
I0809 23:22:39.681845 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0809 23:22:40.389468 126285554812416 run.py:689] Algo activity_selector step 2200 current loss 2.511927, current_train_items 33152.
I0809 23:22:40.485708 126285554812416 run.py:724] (val) algo activity_selector step 2200: {'selected': 0.9328358208955224, 'score': 0.9328358208955224, 'examples_seen': 33152, 'step': 2200, 'algorithm': 'activity_selector'}
I0809 23:22:40.485933 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0809 23:22:41.193196 126285554812416 run.py:689] Algo activity_selector step 2250 current loss 2.102711, current_train_items 33904.
I0809 23:22:41.289587 126285554812416 run.py:724] (val) algo activity_selector step 2250: {'selected': 0.9090909090909091, 'score': 0.9090909090909091, 'examples_seen': 33904, 'step': 2250, 'algorithm': 'activity_selector'}
I0809 23:22:41.289818 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0809 23:22:41.996442 126285554812416 run.py:689] Algo activity_selector step 2300 current loss 2.382999, current_train_items 34656.
I0809 23:22:42.094456 126285554812416 run.py:724] (val) algo activity_selector step 2300: {'selected': 0.8458781362007168, 'score': 0.8458781362007168, 'examples_seen': 34656, 'step': 2300, 'algorithm': 'activity_selector'}
I0809 23:22:42.094678 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.846, val scores are: activity_selector: 0.846
I0809 23:22:42.801849 126285554812416 run.py:689] Algo activity_selector step 2350 current loss 2.086679, current_train_items 35408.
I0809 23:22:42.900058 126285554812416 run.py:724] (val) algo activity_selector step 2350: {'selected': 0.8913857677902622, 'score': 0.8913857677902622, 'examples_seen': 35408, 'step': 2350, 'algorithm': 'activity_selector'}
I0809 23:22:42.900295 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0809 23:22:43.593092 126285554812416 run.py:689] Algo activity_selector step 2400 current loss 2.113916, current_train_items 36160.
I0809 23:22:43.704820 126285554812416 run.py:724] (val) algo activity_selector step 2400: {'selected': 0.8970588235294118, 'score': 0.8970588235294118, 'examples_seen': 36160, 'step': 2400, 'algorithm': 'activity_selector'}
I0809 23:22:43.705048 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0809 23:22:44.412184 126285554812416 run.py:689] Algo activity_selector step 2450 current loss 1.553192, current_train_items 36912.
I0809 23:22:44.509689 126285554812416 run.py:724] (val) algo activity_selector step 2450: {'selected': 0.9138576779026217, 'score': 0.9138576779026217, 'examples_seen': 36912, 'step': 2450, 'algorithm': 'activity_selector'}
I0809 23:22:44.509917 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0809 23:22:45.202489 126285554812416 run.py:689] Algo activity_selector step 2500 current loss 1.625808, current_train_items 37664.
I0809 23:22:45.314012 126285554812416 run.py:724] (val) algo activity_selector step 2500: {'selected': 0.900369003690037, 'score': 0.900369003690037, 'examples_seen': 37664, 'step': 2500, 'algorithm': 'activity_selector'}
I0809 23:22:45.314249 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.900, val scores are: activity_selector: 0.900
I0809 23:22:46.036610 126285554812416 run.py:689] Algo activity_selector step 2550 current loss 1.359200, current_train_items 38416.
I0809 23:22:46.117707 126285554812416 run.py:724] (val) algo activity_selector step 2550: {'selected': 0.9056603773584906, 'score': 0.9056603773584906, 'examples_seen': 38416, 'step': 2550, 'algorithm': 'activity_selector'}
I0809 23:22:46.117958 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0809 23:22:46.826213 126285554812416 run.py:689] Algo activity_selector step 2600 current loss 1.308452, current_train_items 39168.
I0809 23:22:46.923692 126285554812416 run.py:724] (val) algo activity_selector step 2600: {'selected': 0.8847583643122677, 'score': 0.8847583643122677, 'examples_seen': 39168, 'step': 2600, 'algorithm': 'activity_selector'}
I0809 23:22:46.923920 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0809 23:22:47.615913 126285554812416 run.py:689] Algo activity_selector step 2650 current loss 0.343943, current_train_items 39920.
I0809 23:22:47.728735 126285554812416 run.py:724] (val) algo activity_selector step 2650: {'selected': 0.9457364341085271, 'score': 0.9457364341085271, 'examples_seen': 39920, 'step': 2650, 'algorithm': 'activity_selector'}
I0809 23:22:47.728960 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0809 23:22:48.437644 126285554812416 run.py:689] Algo activity_selector step 2700 current loss 4.734783, current_train_items 40688.
I0809 23:22:48.536657 126285554812416 run.py:724] (val) algo activity_selector step 2700: {'selected': 0.9302325581395349, 'score': 0.9302325581395349, 'examples_seen': 40688, 'step': 2700, 'algorithm': 'activity_selector'}
I0809 23:22:48.536894 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0809 23:22:49.239908 126285554812416 run.py:689] Algo activity_selector step 2750 current loss 4.647703, current_train_items 41440.
I0809 23:22:49.337756 126285554812416 run.py:724] (val) algo activity_selector step 2750: {'selected': 0.9277566539923955, 'score': 0.9277566539923955, 'examples_seen': 41440, 'step': 2750, 'algorithm': 'activity_selector'}
I0809 23:22:49.337984 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0809 23:22:50.039245 126285554812416 run.py:689] Algo activity_selector step 2800 current loss 3.570274, current_train_items 42192.
I0809 23:22:50.136737 126285554812416 run.py:724] (val) algo activity_selector step 2800: {'selected': 0.911111111111111, 'score': 0.911111111111111, 'examples_seen': 42192, 'step': 2800, 'algorithm': 'activity_selector'}
I0809 23:22:50.136983 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0809 23:22:50.844283 126285554812416 run.py:689] Algo activity_selector step 2850 current loss 3.176457, current_train_items 42944.
I0809 23:22:50.939804 126285554812416 run.py:724] (val) algo activity_selector step 2850: {'selected': 0.8613138686131386, 'score': 0.8613138686131386, 'examples_seen': 42944, 'step': 2850, 'algorithm': 'activity_selector'}
I0809 23:22:50.940089 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.861, val scores are: activity_selector: 0.861
I0809 23:22:51.657310 126285554812416 run.py:689] Algo activity_selector step 2900 current loss 2.660494, current_train_items 43696.
I0809 23:22:51.744226 126285554812416 run.py:724] (val) algo activity_selector step 2900: {'selected': 0.8847583643122677, 'score': 0.8847583643122677, 'examples_seen': 43696, 'step': 2900, 'algorithm': 'activity_selector'}
I0809 23:22:51.744457 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0809 23:22:52.439700 126285554812416 run.py:689] Algo activity_selector step 2950 current loss 2.457164, current_train_items 44448.
I0809 23:22:52.547323 126285554812416 run.py:724] (val) algo activity_selector step 2950: {'selected': 0.900763358778626, 'score': 0.900763358778626, 'examples_seen': 44448, 'step': 2950, 'algorithm': 'activity_selector'}
I0809 23:22:52.547549 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.901, val scores are: activity_selector: 0.901
I0809 23:22:53.254344 126285554812416 run.py:689] Algo activity_selector step 3000 current loss 2.543097, current_train_items 45200.
I0809 23:22:53.351682 126285554812416 run.py:724] (val) algo activity_selector step 3000: {'selected': 0.9185185185185185, 'score': 0.9185185185185185, 'examples_seen': 45200, 'step': 3000, 'algorithm': 'activity_selector'}
I0809 23:22:53.351908 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0809 23:22:54.059328 126285554812416 run.py:689] Algo activity_selector step 3050 current loss 2.235211, current_train_items 45952.
I0809 23:22:54.157539 126285554812416 run.py:724] (val) algo activity_selector step 3050: {'selected': 0.9429657794676807, 'score': 0.9429657794676807, 'examples_seen': 45952, 'step': 3050, 'algorithm': 'activity_selector'}
I0809 23:22:54.157763 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0809 23:22:54.865062 126285554812416 run.py:689] Algo activity_selector step 3100 current loss 2.139601, current_train_items 46704.
I0809 23:22:54.962322 126285554812416 run.py:724] (val) algo activity_selector step 3100: {'selected': 0.9015151515151514, 'score': 0.9015151515151514, 'examples_seen': 46704, 'step': 3100, 'algorithm': 'activity_selector'}
I0809 23:22:54.962546 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0809 23:22:55.654437 126285554812416 run.py:689] Algo activity_selector step 3150 current loss 2.357419, current_train_items 47456.
I0809 23:22:55.765870 126285554812416 run.py:724] (val) algo activity_selector step 3150: {'selected': 0.9070631970260222, 'score': 0.9070631970260222, 'examples_seen': 47456, 'step': 3150, 'algorithm': 'activity_selector'}
I0809 23:22:55.766095 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0809 23:22:56.458430 126285554812416 run.py:689] Algo activity_selector step 3200 current loss 1.996424, current_train_items 48208.
I0809 23:22:56.570348 126285554812416 run.py:724] (val) algo activity_selector step 3200: {'selected': 0.9323308270676691, 'score': 0.9323308270676691, 'examples_seen': 48208, 'step': 3200, 'algorithm': 'activity_selector'}
I0809 23:22:56.570578 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0809 23:22:57.262343 126285554812416 run.py:689] Algo activity_selector step 3250 current loss 1.699785, current_train_items 48960.
I0809 23:22:57.375349 126285554812416 run.py:724] (val) algo activity_selector step 3250: {'selected': 0.9029850746268656, 'score': 0.9029850746268656, 'examples_seen': 48960, 'step': 3250, 'algorithm': 'activity_selector'}
I0809 23:22:57.375576 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.903, val scores are: activity_selector: 0.903
I0809 23:22:58.083089 126285554812416 run.py:689] Algo activity_selector step 3300 current loss 1.564345, current_train_items 49712.
I0809 23:22:58.178875 126285554812416 run.py:724] (val) algo activity_selector step 3300: {'selected': 0.8814814814814814, 'score': 0.8814814814814814, 'examples_seen': 49712, 'step': 3300, 'algorithm': 'activity_selector'}
I0809 23:22:58.179119 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.881, val scores are: activity_selector: 0.881
I0809 23:22:58.886412 126285554812416 run.py:689] Algo activity_selector step 3350 current loss 1.705390, current_train_items 50464.
I0809 23:22:58.985551 126285554812416 run.py:724] (val) algo activity_selector step 3350: {'selected': 0.8960000000000001, 'score': 0.8960000000000001, 'examples_seen': 50464, 'step': 3350, 'algorithm': 'activity_selector'}
I0809 23:22:58.985794 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0809 23:22:59.678387 126285554812416 run.py:689] Algo activity_selector step 3400 current loss 1.398220, current_train_items 51216.
I0809 23:22:59.790841 126285554812416 run.py:724] (val) algo activity_selector step 3400: {'selected': 0.9172932330827067, 'score': 0.9172932330827067, 'examples_seen': 51216, 'step': 3400, 'algorithm': 'activity_selector'}
I0809 23:22:59.791065 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0809 23:23:00.498950 126285554812416 run.py:689] Algo activity_selector step 3450 current loss 1.920045, current_train_items 51968.
I0809 23:23:00.595071 126285554812416 run.py:724] (val) algo activity_selector step 3450: {'selected': 0.9266409266409267, 'score': 0.9266409266409267, 'examples_seen': 51968, 'step': 3450, 'algorithm': 'activity_selector'}
I0809 23:23:00.595310 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0809 23:23:01.302668 126285554812416 run.py:689] Algo activity_selector step 3500 current loss 0.972949, current_train_items 52720.
I0809 23:23:01.401035 126285554812416 run.py:724] (val) algo activity_selector step 3500: {'selected': 0.9063670411985019, 'score': 0.9063670411985019, 'examples_seen': 52720, 'step': 3500, 'algorithm': 'activity_selector'}
I0809 23:23:01.401273 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0809 23:23:02.109941 126285554812416 run.py:689] Algo activity_selector step 3550 current loss 4.306195, current_train_items 53488.
I0809 23:23:02.207646 126285554812416 run.py:724] (val) algo activity_selector step 3550: {'selected': 0.920152091254753, 'score': 0.920152091254753, 'examples_seen': 53488, 'step': 3550, 'algorithm': 'activity_selector'}
I0809 23:23:02.207871 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0809 23:23:02.896575 126285554812416 run.py:689] Algo activity_selector step 3600 current loss 4.701966, current_train_items 54240.
I0809 23:23:03.007930 126285554812416 run.py:724] (val) algo activity_selector step 3600: {'selected': 0.8847583643122677, 'score': 0.8847583643122677, 'examples_seen': 54240, 'step': 3600, 'algorithm': 'activity_selector'}
I0809 23:23:03.008167 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0809 23:23:03.694075 126285554812416 run.py:689] Algo activity_selector step 3650 current loss 3.728535, current_train_items 54992.
I0809 23:23:03.805265 126285554812416 run.py:724] (val) algo activity_selector step 3650: {'selected': 0.9429657794676807, 'score': 0.9429657794676807, 'examples_seen': 54992, 'step': 3650, 'algorithm': 'activity_selector'}
I0809 23:23:03.805488 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0809 23:23:04.511901 126285554812416 run.py:689] Algo activity_selector step 3700 current loss 3.063179, current_train_items 55744.
I0809 23:23:04.609778 126285554812416 run.py:724] (val) algo activity_selector step 3700: {'selected': 0.920754716981132, 'score': 0.920754716981132, 'examples_seen': 55744, 'step': 3700, 'algorithm': 'activity_selector'}
I0809 23:23:04.610020 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0809 23:23:05.302175 126285554812416 run.py:689] Algo activity_selector step 3750 current loss 2.829157, current_train_items 56496.
I0809 23:23:05.411452 126285554812416 run.py:724] (val) algo activity_selector step 3750: {'selected': 0.9328358208955224, 'score': 0.9328358208955224, 'examples_seen': 56496, 'step': 3750, 'algorithm': 'activity_selector'}
I0809 23:23:05.411678 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0809 23:23:06.118151 126285554812416 run.py:689] Algo activity_selector step 3800 current loss 2.671927, current_train_items 57248.
I0809 23:23:06.214663 126285554812416 run.py:724] (val) algo activity_selector step 3800: {'selected': 0.9318181818181818, 'score': 0.9318181818181818, 'examples_seen': 57248, 'step': 3800, 'algorithm': 'activity_selector'}
I0809 23:23:06.214892 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0809 23:23:06.921922 126285554812416 run.py:689] Algo activity_selector step 3850 current loss 2.372210, current_train_items 58000.
I0809 23:23:07.019003 126285554812416 run.py:724] (val) algo activity_selector step 3850: {'selected': 0.9070631970260222, 'score': 0.9070631970260222, 'examples_seen': 58000, 'step': 3850, 'algorithm': 'activity_selector'}
I0809 23:23:07.019246 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0809 23:23:07.710469 126285554812416 run.py:689] Algo activity_selector step 3900 current loss 2.398378, current_train_items 58752.
I0809 23:23:07.820328 126285554812416 run.py:724] (val) algo activity_selector step 3900: {'selected': 0.8921933085501859, 'score': 0.8921933085501859, 'examples_seen': 58752, 'step': 3900, 'algorithm': 'activity_selector'}
I0809 23:23:07.820494 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.892, val scores are: activity_selector: 0.892
I0809 23:23:08.511301 126285554812416 run.py:689] Algo activity_selector step 3950 current loss 2.096406, current_train_items 59504.
I0809 23:23:08.622908 126285554812416 run.py:724] (val) algo activity_selector step 3950: {'selected': 0.9584905660377359, 'score': 0.9584905660377359, 'examples_seen': 59504, 'step': 3950, 'algorithm': 'activity_selector'}
I0809 23:23:08.623135 126285554812416 run.py:745] Checkpointing best model, best avg val score was 0.958, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0809 23:23:09.341727 126285554812416 run.py:689] Algo activity_selector step 4000 current loss 2.145580, current_train_items 60256.
I0809 23:23:09.435937 126285554812416 run.py:724] (val) algo activity_selector step 4000: {'selected': 0.8654545454545454, 'score': 0.8654545454545454, 'examples_seen': 60256, 'step': 4000, 'algorithm': 'activity_selector'}
I0809 23:23:09.436086 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.865, val scores are: activity_selector: 0.865
I0809 23:23:10.138632 126285554812416 run.py:689] Algo activity_selector step 4050 current loss 1.955379, current_train_items 61008.
I0809 23:23:10.232373 126285554812416 run.py:724] (val) algo activity_selector step 4050: {'selected': 0.8863636363636365, 'score': 0.8863636363636365, 'examples_seen': 61008, 'step': 4050, 'algorithm': 'activity_selector'}
I0809 23:23:10.232522 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0809 23:23:10.926727 126285554812416 run.py:689] Algo activity_selector step 4100 current loss 1.866741, current_train_items 61760.
I0809 23:23:11.033851 126285554812416 run.py:724] (val) algo activity_selector step 4100: {'selected': 0.8970588235294118, 'score': 0.8970588235294118, 'examples_seen': 61760, 'step': 4100, 'algorithm': 'activity_selector'}
I0809 23:23:11.034026 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0809 23:23:11.737409 126285554812416 run.py:689] Algo activity_selector step 4150 current loss 1.889336, current_train_items 62512.
I0809 23:23:11.832295 126285554812416 run.py:724] (val) algo activity_selector step 4150: {'selected': 0.9132075471698113, 'score': 0.9132075471698113, 'examples_seen': 62512, 'step': 4150, 'algorithm': 'activity_selector'}
I0809 23:23:11.832471 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0809 23:23:12.541101 126285554812416 run.py:689] Algo activity_selector step 4200 current loss 1.430157, current_train_items 63264.
I0809 23:23:12.634026 126285554812416 run.py:724] (val) algo activity_selector step 4200: {'selected': 0.9097744360902256, 'score': 0.9097744360902256, 'examples_seen': 63264, 'step': 4200, 'algorithm': 'activity_selector'}
I0809 23:23:12.634208 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0809 23:23:13.335899 126285554812416 run.py:689] Algo activity_selector step 4250 current loss 1.198394, current_train_items 64016.
I0809 23:23:13.430637 126285554812416 run.py:724] (val) algo activity_selector step 4250: {'selected': 0.9133858267716536, 'score': 0.9133858267716536, 'examples_seen': 64016, 'step': 4250, 'algorithm': 'activity_selector'}
I0809 23:23:13.430833 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0809 23:23:14.134610 126285554812416 run.py:689] Algo activity_selector step 4300 current loss 1.460415, current_train_items 64768.
I0809 23:23:14.229527 126285554812416 run.py:724] (val) algo activity_selector step 4300: {'selected': 0.9133858267716536, 'score': 0.9133858267716536, 'examples_seen': 64768, 'step': 4300, 'algorithm': 'activity_selector'}
I0809 23:23:14.229677 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0809 23:23:14.931412 126285554812416 run.py:689] Algo activity_selector step 4350 current loss 1.243574, current_train_items 65520.
I0809 23:23:15.025904 126285554812416 run.py:724] (val) algo activity_selector step 4350: {'selected': 0.9505703422053231, 'score': 0.9505703422053231, 'examples_seen': 65520, 'step': 4350, 'algorithm': 'activity_selector'}
I0809 23:23:15.026061 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0809 23:23:15.732331 126285554812416 run.py:689] Algo activity_selector step 4400 current loss 4.257773, current_train_items 66288.
I0809 23:23:15.826502 126285554812416 run.py:724] (val) algo activity_selector step 4400: {'selected': 0.8913857677902622, 'score': 0.8913857677902622, 'examples_seen': 66288, 'step': 4400, 'algorithm': 'activity_selector'}
I0809 23:23:15.826656 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0809 23:23:16.525891 126285554812416 run.py:689] Algo activity_selector step 4450 current loss 4.312848, current_train_items 67040.
I0809 23:23:16.618393 126285554812416 run.py:724] (val) algo activity_selector step 4450: {'selected': 0.9584905660377359, 'score': 0.9584905660377359, 'examples_seen': 67040, 'step': 4450, 'algorithm': 'activity_selector'}
I0809 23:23:16.618556 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0809 23:23:17.316930 126285554812416 run.py:689] Algo activity_selector step 4500 current loss 3.506566, current_train_items 67792.
I0809 23:23:17.415764 126285554812416 run.py:724] (val) algo activity_selector step 4500: {'selected': 0.9498069498069497, 'score': 0.9498069498069497, 'examples_seen': 67792, 'step': 4500, 'algorithm': 'activity_selector'}
I0809 23:23:17.415987 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0809 23:23:18.122752 126285554812416 run.py:689] Algo activity_selector step 4550 current loss 2.957482, current_train_items 68544.
I0809 23:23:18.218663 126285554812416 run.py:724] (val) algo activity_selector step 4550: {'selected': 0.9389312977099236, 'score': 0.9389312977099236, 'examples_seen': 68544, 'step': 4550, 'algorithm': 'activity_selector'}
I0809 23:23:18.218888 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0809 23:23:18.925849 126285554812416 run.py:689] Algo activity_selector step 4600 current loss 2.928859, current_train_items 69296.
I0809 23:23:19.017644 126285554812416 run.py:724] (val) algo activity_selector step 4600: {'selected': 0.9348659003831418, 'score': 0.9348659003831418, 'examples_seen': 69296, 'step': 4600, 'algorithm': 'activity_selector'}
I0809 23:23:19.017871 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0809 23:23:19.725439 126285554812416 run.py:689] Algo activity_selector step 4650 current loss 2.458636, current_train_items 70048.
I0809 23:23:19.823079 126285554812416 run.py:724] (val) algo activity_selector step 4650: {'selected': 0.9438202247191011, 'score': 0.9438202247191011, 'examples_seen': 70048, 'step': 4650, 'algorithm': 'activity_selector'}
I0809 23:23:19.823315 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0809 23:23:20.530400 126285554812416 run.py:689] Algo activity_selector step 4700 current loss 2.483715, current_train_items 70800.
I0809 23:23:20.630312 126285554812416 run.py:724] (val) algo activity_selector step 4700: {'selected': 0.8981132075471698, 'score': 0.8981132075471698, 'examples_seen': 70800, 'step': 4700, 'algorithm': 'activity_selector'}
I0809 23:23:20.630540 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0809 23:23:21.337902 126285554812416 run.py:689] Algo activity_selector step 4750 current loss 2.337260, current_train_items 71552.
I0809 23:23:21.435449 126285554812416 run.py:724] (val) algo activity_selector step 4750: {'selected': 0.9465648854961831, 'score': 0.9465648854961831, 'examples_seen': 71552, 'step': 4750, 'algorithm': 'activity_selector'}
I0809 23:23:21.435674 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0809 23:23:22.143326 126285554812416 run.py:689] Algo activity_selector step 4800 current loss 2.069190, current_train_items 72304.
I0809 23:23:22.235220 126285554812416 run.py:724] (val) algo activity_selector step 4800: {'selected': 0.9541984732824428, 'score': 0.9541984732824428, 'examples_seen': 72304, 'step': 4800, 'algorithm': 'activity_selector'}
I0809 23:23:22.235426 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0809 23:23:22.937617 126285554812416 run.py:689] Algo activity_selector step 4850 current loss 2.136418, current_train_items 73056.
I0809 23:23:23.035553 126285554812416 run.py:724] (val) algo activity_selector step 4850: {'selected': 0.9283018867924527, 'score': 0.9283018867924527, 'examples_seen': 73056, 'step': 4850, 'algorithm': 'activity_selector'}
I0809 23:23:23.035778 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0809 23:23:23.742981 126285554812416 run.py:689] Algo activity_selector step 4900 current loss 1.970421, current_train_items 73808.
I0809 23:23:23.840042 126285554812416 run.py:724] (val) algo activity_selector step 4900: {'selected': 0.8988764044943821, 'score': 0.8988764044943821, 'examples_seen': 73808, 'step': 4900, 'algorithm': 'activity_selector'}
I0809 23:23:23.840279 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.958, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0809 23:23:24.548271 126285554812416 run.py:689] Algo activity_selector step 4950 current loss 1.715571, current_train_items 74560.
I0809 23:23:24.645406 126285554812416 run.py:724] (val) algo activity_selector step 4950: {'selected': 0.9615384615384616, 'score': 0.9615384615384616, 'examples_seen': 74560, 'step': 4950, 'algorithm': 'activity_selector'}
I0809 23:23:24.645629 126285554812416 run.py:745] Checkpointing best model, best avg val score was 0.958, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0809 23:23:25.393920 126285554812416 run.py:689] Algo activity_selector step 5000 current loss 1.614739, current_train_items 75312.
I0809 23:23:25.475267 126285554812416 run.py:724] (val) algo activity_selector step 5000: {'selected': 0.9044117647058824, 'score': 0.9044117647058824, 'examples_seen': 75312, 'step': 5000, 'algorithm': 'activity_selector'}
I0809 23:23:25.475491 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.962, current avg val score is 0.904, val scores are: activity_selector: 0.904
I0809 23:23:26.183233 126285554812416 run.py:689] Algo activity_selector step 5050 current loss 1.262760, current_train_items 76064.
I0809 23:23:26.276201 126285554812416 run.py:724] (val) algo activity_selector step 5050: {'selected': 0.8955223880597014, 'score': 0.8955223880597014, 'examples_seen': 76064, 'step': 5050, 'algorithm': 'activity_selector'}
I0809 23:23:26.276379 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.962, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0809 23:23:26.978806 126285554812416 run.py:689] Algo activity_selector step 5100 current loss 1.267558, current_train_items 76816.
I0809 23:23:27.073878 126285554812416 run.py:724] (val) algo activity_selector step 5100: {'selected': 0.8796992481203008, 'score': 0.8796992481203008, 'examples_seen': 76816, 'step': 5100, 'algorithm': 'activity_selector'}
I0809 23:23:27.074036 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.962, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0809 23:23:27.776965 126285554812416 run.py:689] Algo activity_selector step 5150 current loss 1.321054, current_train_items 77568.
I0809 23:23:27.874286 126285554812416 run.py:724] (val) algo activity_selector step 5150: {'selected': 0.9655172413793103, 'score': 0.9655172413793103, 'examples_seen': 77568, 'step': 5150, 'algorithm': 'activity_selector'}
I0809 23:23:27.874512 126285554812416 run.py:745] Checkpointing best model, best avg val score was 0.962, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0809 23:23:28.600922 126285554812416 run.py:689] Algo activity_selector step 5200 current loss 0.255977, current_train_items 78320.
I0809 23:23:28.692514 126285554812416 run.py:724] (val) algo activity_selector step 5200: {'selected': 0.911111111111111, 'score': 0.911111111111111, 'examples_seen': 78320, 'step': 5200, 'algorithm': 'activity_selector'}
I0809 23:23:28.692709 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0809 23:23:29.400922 126285554812416 run.py:689] Algo activity_selector step 5250 current loss 5.721770, current_train_items 79088.
I0809 23:23:29.497797 126285554812416 run.py:724] (val) algo activity_selector step 5250: {'selected': 0.9254901960784314, 'score': 0.9254901960784314, 'examples_seen': 79088, 'step': 5250, 'algorithm': 'activity_selector'}
I0809 23:23:29.498021 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0809 23:23:30.201104 126285554812416 run.py:689] Algo activity_selector step 5300 current loss 3.591724, current_train_items 79840.
I0809 23:23:30.294855 126285554812416 run.py:724] (val) algo activity_selector step 5300: {'selected': 0.935361216730038, 'score': 0.935361216730038, 'examples_seen': 79840, 'step': 5300, 'algorithm': 'activity_selector'}
I0809 23:23:30.295080 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0809 23:23:30.996021 126285554812416 run.py:689] Algo activity_selector step 5350 current loss 3.387689, current_train_items 80592.
I0809 23:23:31.094083 126285554812416 run.py:724] (val) algo activity_selector step 5350: {'selected': 0.9358490566037735, 'score': 0.9358490566037735, 'examples_seen': 80592, 'step': 5350, 'algorithm': 'activity_selector'}
I0809 23:23:31.094324 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0809 23:23:31.801297 126285554812416 run.py:689] Algo activity_selector step 5400 current loss 2.819454, current_train_items 81344.
I0809 23:23:31.898849 126285554812416 run.py:724] (val) algo activity_selector step 5400: {'selected': 0.8988764044943821, 'score': 0.8988764044943821, 'examples_seen': 81344, 'step': 5400, 'algorithm': 'activity_selector'}
I0809 23:23:31.899075 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0809 23:23:32.605908 126285554812416 run.py:689] Algo activity_selector step 5450 current loss 2.673544, current_train_items 82096.
I0809 23:23:32.702194 126285554812416 run.py:724] (val) algo activity_selector step 5450: {'selected': 0.9457364341085271, 'score': 0.9457364341085271, 'examples_seen': 82096, 'step': 5450, 'algorithm': 'activity_selector'}
I0809 23:23:32.702418 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0809 23:23:33.409154 126285554812416 run.py:689] Algo activity_selector step 5500 current loss 2.550275, current_train_items 82848.
I0809 23:23:33.505828 126285554812416 run.py:724] (val) algo activity_selector step 5500: {'selected': 0.9144981412639406, 'score': 0.9144981412639406, 'examples_seen': 82848, 'step': 5500, 'algorithm': 'activity_selector'}
I0809 23:23:33.506048 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0809 23:23:34.213254 126285554812416 run.py:689] Algo activity_selector step 5550 current loss 2.422881, current_train_items 83600.
I0809 23:23:34.310463 126285554812416 run.py:724] (val) algo activity_selector step 5550: {'selected': 0.8970588235294118, 'score': 0.8970588235294118, 'examples_seen': 83600, 'step': 5550, 'algorithm': 'activity_selector'}
I0809 23:23:34.310686 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0809 23:23:35.033946 126285554812416 run.py:689] Algo activity_selector step 5600 current loss 2.350565, current_train_items 84352.
I0809 23:23:35.112035 126285554812416 run.py:724] (val) algo activity_selector step 5600: {'selected': 0.935361216730038, 'score': 0.935361216730038, 'examples_seen': 84352, 'step': 5600, 'algorithm': 'activity_selector'}
I0809 23:23:35.112293 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0809 23:23:35.819432 126285554812416 run.py:689] Algo activity_selector step 5650 current loss 2.179138, current_train_items 85104.
I0809 23:23:35.917400 126285554812416 run.py:724] (val) algo activity_selector step 5650: {'selected': 0.8856088560885609, 'score': 0.8856088560885609, 'examples_seen': 85104, 'step': 5650, 'algorithm': 'activity_selector'}
I0809 23:23:35.917624 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.886, val scores are: activity_selector: 0.886
I0809 23:23:36.618674 126285554812416 run.py:689] Algo activity_selector step 5700 current loss 1.832416, current_train_items 85856.
I0809 23:23:36.721474 126285554812416 run.py:724] (val) algo activity_selector step 5700: {'selected': 0.9545454545454547, 'score': 0.9545454545454547, 'examples_seen': 85856, 'step': 5700, 'algorithm': 'activity_selector'}
I0809 23:23:36.721698 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0809 23:23:37.429569 126285554812416 run.py:689] Algo activity_selector step 5750 current loss 2.005946, current_train_items 86608.
I0809 23:23:37.525593 126285554812416 run.py:724] (val) algo activity_selector step 5750: {'selected': 0.9312977099236641, 'score': 0.9312977099236641, 'examples_seen': 86608, 'step': 5750, 'algorithm': 'activity_selector'}
I0809 23:23:37.525819 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0809 23:23:38.219918 126285554812416 run.py:689] Algo activity_selector step 5800 current loss 1.838411, current_train_items 87360.
I0809 23:23:38.329822 126285554812416 run.py:724] (val) algo activity_selector step 5800: {'selected': 0.8962962962962964, 'score': 0.8962962962962964, 'examples_seen': 87360, 'step': 5800, 'algorithm': 'activity_selector'}
I0809 23:23:38.330049 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0809 23:23:39.045103 126285554812416 run.py:689] Algo activity_selector step 5850 current loss 1.489414, current_train_items 88112.
I0809 23:23:39.133916 126285554812416 run.py:724] (val) algo activity_selector step 5850: {'selected': 0.9486166007905139, 'score': 0.9486166007905139, 'examples_seen': 88112, 'step': 5850, 'algorithm': 'activity_selector'}
I0809 23:23:39.134137 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0809 23:23:39.826476 126285554812416 run.py:689] Algo activity_selector step 5900 current loss 1.170524, current_train_items 88864.
I0809 23:23:39.935687 126285554812416 run.py:724] (val) algo activity_selector step 5900: {'selected': 0.9612403100775193, 'score': 0.9612403100775193, 'examples_seen': 88864, 'step': 5900, 'algorithm': 'activity_selector'}
I0809 23:23:39.935914 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0809 23:23:40.627916 126285554812416 run.py:689] Algo activity_selector step 5950 current loss 1.478710, current_train_items 89616.
I0809 23:23:40.740302 126285554812416 run.py:724] (val) algo activity_selector step 5950: {'selected': 0.9652509652509652, 'score': 0.9652509652509652, 'examples_seen': 89616, 'step': 5950, 'algorithm': 'activity_selector'}
I0809 23:23:40.740575 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0809 23:23:41.449201 126285554812416 run.py:689] Algo activity_selector step 6000 current loss 1.259797, current_train_items 90368.
I0809 23:23:41.545594 126285554812416 run.py:724] (val) algo activity_selector step 6000: {'selected': 0.935361216730038, 'score': 0.935361216730038, 'examples_seen': 90368, 'step': 6000, 'algorithm': 'activity_selector'}
I0809 23:23:41.545847 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0809 23:23:42.253918 126285554812416 run.py:689] Algo activity_selector step 6050 current loss 0.316999, current_train_items 91120.
I0809 23:23:42.346911 126285554812416 run.py:724] (val) algo activity_selector step 6050: {'selected': 0.9312977099236641, 'score': 0.9312977099236641, 'examples_seen': 91120, 'step': 6050, 'algorithm': 'activity_selector'}
I0809 23:23:42.347141 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0809 23:23:43.044657 126285554812416 run.py:689] Algo activity_selector step 6100 current loss 5.727868, current_train_items 91888.
I0809 23:23:43.152667 126285554812416 run.py:724] (val) algo activity_selector step 6100: {'selected': 0.9534883720930233, 'score': 0.9534883720930233, 'examples_seen': 91888, 'step': 6100, 'algorithm': 'activity_selector'}
I0809 23:23:43.152895 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0809 23:23:43.856123 126285554812416 run.py:689] Algo activity_selector step 6150 current loss 4.334046, current_train_items 92640.
I0809 23:23:43.953406 126285554812416 run.py:724] (val) algo activity_selector step 6150: {'selected': 0.9534883720930233, 'score': 0.9534883720930233, 'examples_seen': 92640, 'step': 6150, 'algorithm': 'activity_selector'}
I0809 23:23:43.953636 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0809 23:23:44.654598 126285554812416 run.py:689] Algo activity_selector step 6200 current loss 3.242709, current_train_items 93392.
I0809 23:23:44.751112 126285554812416 run.py:724] (val) algo activity_selector step 6200: {'selected': 0.8973384030418251, 'score': 0.8973384030418251, 'examples_seen': 93392, 'step': 6200, 'algorithm': 'activity_selector'}
I0809 23:23:44.751346 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0809 23:23:45.457908 126285554812416 run.py:689] Algo activity_selector step 6250 current loss 2.819797, current_train_items 94144.
I0809 23:23:45.554335 126285554812416 run.py:724] (val) algo activity_selector step 6250: {'selected': 0.9393939393939394, 'score': 0.9393939393939394, 'examples_seen': 94144, 'step': 6250, 'algorithm': 'activity_selector'}
I0809 23:23:45.554566 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0809 23:23:46.246090 126285554812416 run.py:689] Algo activity_selector step 6300 current loss 2.761757, current_train_items 94896.
I0809 23:23:46.357618 126285554812416 run.py:724] (val) algo activity_selector step 6300: {'selected': 0.8949416342412451, 'score': 0.8949416342412451, 'examples_seen': 94896, 'step': 6300, 'algorithm': 'activity_selector'}
I0809 23:23:46.357858 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.895, val scores are: activity_selector: 0.895
I0809 23:23:47.064634 126285554812416 run.py:689] Algo activity_selector step 6350 current loss 2.318957, current_train_items 95648.
I0809 23:23:47.161973 126285554812416 run.py:724] (val) algo activity_selector step 6350: {'selected': 0.9090909090909091, 'score': 0.9090909090909091, 'examples_seen': 95648, 'step': 6350, 'algorithm': 'activity_selector'}
I0809 23:23:47.162244 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0809 23:23:47.869295 126285554812416 run.py:689] Algo activity_selector step 6400 current loss 2.463799, current_train_items 96400.
I0809 23:23:47.966456 126285554812416 run.py:724] (val) algo activity_selector step 6400: {'selected': 0.8796992481203008, 'score': 0.8796992481203008, 'examples_seen': 96400, 'step': 6400, 'algorithm': 'activity_selector'}
I0809 23:23:47.966706 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0809 23:23:48.689908 126285554812416 run.py:689] Algo activity_selector step 6450 current loss 2.182666, current_train_items 97152.
I0809 23:23:48.766717 126285554812416 run.py:724] (val) algo activity_selector step 6450: {'selected': 0.8717948717948718, 'score': 0.8717948717948718, 'examples_seen': 97152, 'step': 6450, 'algorithm': 'activity_selector'}
I0809 23:23:48.766950 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.872, val scores are: activity_selector: 0.872
I0809 23:23:49.474162 126285554812416 run.py:689] Algo activity_selector step 6500 current loss 2.146232, current_train_items 97904.
I0809 23:23:49.569267 126285554812416 run.py:724] (val) algo activity_selector step 6500: {'selected': 0.8689138576779026, 'score': 0.8689138576779026, 'examples_seen': 97904, 'step': 6500, 'algorithm': 'activity_selector'}
I0809 23:23:49.569513 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.869, val scores are: activity_selector: 0.869
I0809 23:23:50.276790 126285554812416 run.py:689] Algo activity_selector step 6550 current loss 1.983310, current_train_items 98656.
I0809 23:23:50.373866 126285554812416 run.py:724] (val) algo activity_selector step 6550: {'selected': 0.9494163424124514, 'score': 0.9494163424124514, 'examples_seen': 98656, 'step': 6550, 'algorithm': 'activity_selector'}
I0809 23:23:50.374091 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0809 23:23:51.081648 126285554812416 run.py:689] Algo activity_selector step 6600 current loss 1.762467, current_train_items 99408.
I0809 23:23:51.178589 126285554812416 run.py:724] (val) algo activity_selector step 6600: {'selected': 0.9538461538461539, 'score': 0.9538461538461539, 'examples_seen': 99408, 'step': 6600, 'algorithm': 'activity_selector'}
I0809 23:23:51.178813 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0809 23:23:51.901188 126285554812416 run.py:689] Algo activity_selector step 6650 current loss 1.600950, current_train_items 100160.
I0809 23:23:51.983693 126285554812416 run.py:724] (val) algo activity_selector step 6650: {'selected': 0.920754716981132, 'score': 0.920754716981132, 'examples_seen': 100160, 'step': 6650, 'algorithm': 'activity_selector'}
I0809 23:23:51.983915 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0809 23:23:52.691542 126285554812416 run.py:689] Algo activity_selector step 6700 current loss 1.486543, current_train_items 100912.
I0809 23:23:52.790403 126285554812416 run.py:724] (val) algo activity_selector step 6700: {'selected': 0.8830188679245283, 'score': 0.8830188679245283, 'examples_seen': 100912, 'step': 6700, 'algorithm': 'activity_selector'}
I0809 23:23:52.790628 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.883, val scores are: activity_selector: 0.883
I0809 23:23:53.498451 126285554812416 run.py:689] Algo activity_selector step 6750 current loss 1.401446, current_train_items 101664.
I0809 23:23:53.596232 126285554812416 run.py:724] (val) algo activity_selector step 6750: {'selected': 0.9389312977099236, 'score': 0.9389312977099236, 'examples_seen': 101664, 'step': 6750, 'algorithm': 'activity_selector'}
I0809 23:23:53.596493 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.966, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0809 23:23:54.305353 126285554812416 run.py:689] Algo activity_selector step 6800 current loss 1.069091, current_train_items 102416.
I0809 23:23:54.400524 126285554812416 run.py:724] (val) algo activity_selector step 6800: {'selected': 0.9731800766283524, 'score': 0.9731800766283524, 'examples_seen': 102416, 'step': 6800, 'algorithm': 'activity_selector'}
I0809 23:23:54.400745 126285554812416 run.py:745] Checkpointing best model, best avg val score was 0.966, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0809 23:23:55.127292 126285554812416 run.py:689] Algo activity_selector step 6850 current loss 1.081274, current_train_items 103168.
I0809 23:23:55.225205 126285554812416 run.py:724] (val) algo activity_selector step 6850: {'selected': 0.9318181818181818, 'score': 0.9318181818181818, 'examples_seen': 103168, 'step': 6850, 'algorithm': 'activity_selector'}
I0809 23:23:55.225432 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0809 23:23:55.933673 126285554812416 run.py:689] Algo activity_selector step 6900 current loss 0.546558, current_train_items 103920.
I0809 23:23:56.030815 126285554812416 run.py:724] (val) algo activity_selector step 6900: {'selected': 0.9236641221374045, 'score': 0.9236641221374045, 'examples_seen': 103920, 'step': 6900, 'algorithm': 'activity_selector'}
I0809 23:23:56.031042 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0809 23:23:56.738375 126285554812416 run.py:689] Algo activity_selector step 6950 current loss 5.356335, current_train_items 104688.
I0809 23:23:56.836324 126285554812416 run.py:724] (val) algo activity_selector step 6950: {'selected': 0.9429657794676807, 'score': 0.9429657794676807, 'examples_seen': 104688, 'step': 6950, 'algorithm': 'activity_selector'}
I0809 23:23:56.836551 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0809 23:23:57.548719 126285554812416 run.py:689] Algo activity_selector step 7000 current loss 4.251956, current_train_items 105440.
I0809 23:23:57.665935 126285554812416 run.py:724] (val) algo activity_selector step 7000: {'selected': 0.9285714285714285, 'score': 0.9285714285714285, 'examples_seen': 105440, 'step': 7000, 'algorithm': 'activity_selector'}
I0809 23:23:57.666192 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0809 23:23:58.404497 126285554812416 run.py:689] Algo activity_selector step 7050 current loss 3.249301, current_train_items 106192.
I0809 23:23:58.516379 126285554812416 run.py:724] (val) algo activity_selector step 7050: {'selected': 0.9358490566037735, 'score': 0.9358490566037735, 'examples_seen': 106192, 'step': 7050, 'algorithm': 'activity_selector'}
I0809 23:23:58.516609 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0809 23:23:59.224251 126285554812416 run.py:689] Algo activity_selector step 7100 current loss 2.994483, current_train_items 106944.
I0809 23:23:59.332509 126285554812416 run.py:724] (val) algo activity_selector step 7100: {'selected': 0.875, 'score': 0.875, 'examples_seen': 106944, 'step': 7100, 'algorithm': 'activity_selector'}
I0809 23:23:59.332705 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.875, val scores are: activity_selector: 0.875
I0809 23:24:00.044327 126285554812416 run.py:689] Algo activity_selector step 7150 current loss 2.637805, current_train_items 107696.
I0809 23:24:00.162928 126285554812416 run.py:724] (val) algo activity_selector step 7150: {'selected': 0.9022556390977443, 'score': 0.9022556390977443, 'examples_seen': 107696, 'step': 7150, 'algorithm': 'activity_selector'}
I0809 23:24:00.163080 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.902, val scores are: activity_selector: 0.902
I0809 23:24:00.924832 126285554812416 run.py:689] Algo activity_selector step 7200 current loss 2.480989, current_train_items 108448.
I0809 23:24:01.022201 126285554812416 run.py:724] (val) algo activity_selector step 7200: {'selected': 0.8995983935742972, 'score': 0.8995983935742972, 'examples_seen': 108448, 'step': 7200, 'algorithm': 'activity_selector'}
I0809 23:24:01.022432 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.900, val scores are: activity_selector: 0.900
I0809 23:24:01.750299 126285554812416 run.py:689] Algo activity_selector step 7250 current loss 2.580760, current_train_items 109200.
I0809 23:24:01.871908 126285554812416 run.py:724] (val) algo activity_selector step 7250: {'selected': 0.8791208791208791, 'score': 0.8791208791208791, 'examples_seen': 109200, 'step': 7250, 'algorithm': 'activity_selector'}
I0809 23:24:01.872136 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0809 23:24:02.607209 126285554812416 run.py:689] Algo activity_selector step 7300 current loss 2.074820, current_train_items 109952.
I0809 23:24:02.718273 126285554812416 run.py:724] (val) algo activity_selector step 7300: {'selected': 0.9612403100775193, 'score': 0.9612403100775193, 'examples_seen': 109952, 'step': 7300, 'algorithm': 'activity_selector'}
I0809 23:24:02.718527 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0809 23:24:03.429543 126285554812416 run.py:689] Algo activity_selector step 7350 current loss 1.958608, current_train_items 110704.
I0809 23:24:03.540933 126285554812416 run.py:724] (val) algo activity_selector step 7350: {'selected': 0.9461538461538461, 'score': 0.9461538461538461, 'examples_seen': 110704, 'step': 7350, 'algorithm': 'activity_selector'}
I0809 23:24:03.541131 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0809 23:24:04.233856 126285554812416 run.py:689] Algo activity_selector step 7400 current loss 1.792086, current_train_items 111456.
I0809 23:24:04.345812 126285554812416 run.py:724] (val) algo activity_selector step 7400: {'selected': 0.9236641221374045, 'score': 0.9236641221374045, 'examples_seen': 111456, 'step': 7400, 'algorithm': 'activity_selector'}
I0809 23:24:04.346034 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0809 23:24:05.048376 126285554812416 run.py:689] Algo activity_selector step 7450 current loss 1.784296, current_train_items 112208.
I0809 23:24:05.151564 126285554812416 run.py:724] (val) algo activity_selector step 7450: {'selected': 0.9242424242424243, 'score': 0.9242424242424243, 'examples_seen': 112208, 'step': 7450, 'algorithm': 'activity_selector'}
I0809 23:24:05.151810 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0809 23:24:05.861120 126285554812416 run.py:689] Algo activity_selector step 7500 current loss 1.683997, current_train_items 112960.
I0809 23:24:05.959157 126285554812416 run.py:724] (val) algo activity_selector step 7500: {'selected': 0.9490196078431372, 'score': 0.9490196078431372, 'examples_seen': 112960, 'step': 7500, 'algorithm': 'activity_selector'}
I0809 23:24:05.959399 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0809 23:24:06.667612 126285554812416 run.py:689] Algo activity_selector step 7550 current loss 1.511256, current_train_items 113712.
I0809 23:24:06.764934 126285554812416 run.py:724] (val) algo activity_selector step 7550: {'selected': 0.9328063241106719, 'score': 0.9328063241106719, 'examples_seen': 113712, 'step': 7550, 'algorithm': 'activity_selector'}
I0809 23:24:06.765170 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0809 23:24:07.474269 126285554812416 run.py:689] Algo activity_selector step 7600 current loss 1.391384, current_train_items 114464.
I0809 23:24:07.570381 126285554812416 run.py:724] (val) algo activity_selector step 7600: {'selected': 0.9070631970260222, 'score': 0.9070631970260222, 'examples_seen': 114464, 'step': 7600, 'algorithm': 'activity_selector'}
I0809 23:24:07.570608 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0809 23:24:08.279660 126285554812416 run.py:689] Algo activity_selector step 7650 current loss 1.195167, current_train_items 115216.
I0809 23:24:08.378464 126285554812416 run.py:724] (val) algo activity_selector step 7650: {'selected': 0.9425287356321839, 'score': 0.9425287356321839, 'examples_seen': 115216, 'step': 7650, 'algorithm': 'activity_selector'}
I0809 23:24:08.378706 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0809 23:24:09.072327 126285554812416 run.py:689] Algo activity_selector step 7700 current loss 1.286369, current_train_items 115968.
I0809 23:24:09.185026 126285554812416 run.py:724] (val) algo activity_selector step 7700: {'selected': 0.96875, 'score': 0.96875, 'examples_seen': 115968, 'step': 7700, 'algorithm': 'activity_selector'}
I0809 23:24:09.185259 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0809 23:24:09.878532 126285554812416 run.py:689] Algo activity_selector step 7750 current loss 0.231684, current_train_items 116720.
I0809 23:24:09.990967 126285554812416 run.py:724] (val) algo activity_selector step 7750: {'selected': 0.9042145593869731, 'score': 0.9042145593869731, 'examples_seen': 116720, 'step': 7750, 'algorithm': 'activity_selector'}
I0809 23:24:09.991204 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.904, val scores are: activity_selector: 0.904
I0809 23:24:10.700090 126285554812416 run.py:689] Algo activity_selector step 7800 current loss 4.763090, current_train_items 117488.
I0809 23:24:10.798480 126285554812416 run.py:724] (val) algo activity_selector step 7800: {'selected': 0.935361216730038, 'score': 0.935361216730038, 'examples_seen': 117488, 'step': 7800, 'algorithm': 'activity_selector'}
I0809 23:24:10.798706 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0809 23:24:11.503215 126285554812416 run.py:689] Algo activity_selector step 7850 current loss 3.898293, current_train_items 118240.
I0809 23:24:11.601211 126285554812416 run.py:724] (val) algo activity_selector step 7850: {'selected': 0.887218045112782, 'score': 0.887218045112782, 'examples_seen': 118240, 'step': 7850, 'algorithm': 'activity_selector'}
I0809 23:24:11.601438 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.887, val scores are: activity_selector: 0.887
I0809 23:24:12.290227 126285554812416 run.py:689] Algo activity_selector step 7900 current loss 3.317876, current_train_items 118992.
I0809 23:24:12.403934 126285554812416 run.py:724] (val) algo activity_selector step 7900: {'selected': 0.9348659003831418, 'score': 0.9348659003831418, 'examples_seen': 118992, 'step': 7900, 'algorithm': 'activity_selector'}
I0809 23:24:12.404174 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0809 23:24:13.105404 126285554812416 run.py:689] Algo activity_selector step 7950 current loss 3.053457, current_train_items 119744.
I0809 23:24:13.208683 126285554812416 run.py:724] (val) algo activity_selector step 7950: {'selected': 0.9132075471698113, 'score': 0.9132075471698113, 'examples_seen': 119744, 'step': 7950, 'algorithm': 'activity_selector'}
I0809 23:24:13.208913 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0809 23:24:13.904093 126285554812416 run.py:689] Algo activity_selector step 8000 current loss 2.595851, current_train_items 120496.
I0809 23:24:14.014808 126285554812416 run.py:724] (val) algo activity_selector step 8000: {'selected': 0.9541984732824428, 'score': 0.9541984732824428, 'examples_seen': 120496, 'step': 8000, 'algorithm': 'activity_selector'}
I0809 23:24:14.015034 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.973, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0809 23:24:14.743361 126285554812416 run.py:689] Algo activity_selector step 8050 current loss 2.501431, current_train_items 121248.
I0809 23:24:14.844024 126285554812416 run.py:724] (val) algo activity_selector step 8050: {'selected': 0.9318181818181818, 'score': 0.9318181818181818, 'examples_seen': 121248, 'step': 8050, 'algorithm': 'activity_selector'}
I0809 23:24:14.844216 126285554812416 run.py:745] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0809 23:24:15.584889 126285554812416 run.py:689] Algo activity_selector step 8100 current loss 2.252801, current_train_items 122000.
I0809 23:24:15.688677 126285554812416 run.py:724] (val) algo activity_selector step 8100: {'selected': 0.9132075471698113, 'score': 0.9132075471698113, 'examples_seen': 122000, 'step': 8100, 'algorithm': 'activity_selector'}
I0809 23:24:15.688925 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.932, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0809 23:24:16.383951 126285554812416 run.py:689] Algo activity_selector step 8150 current loss 2.135705, current_train_items 122752.
I0809 23:24:16.496393 126285554812416 run.py:724] (val) algo activity_selector step 8150: {'selected': 0.9498069498069497, 'score': 0.9498069498069497, 'examples_seen': 122752, 'step': 8150, 'algorithm': 'activity_selector'}
I0809 23:24:16.496620 126285554812416 run.py:745] Checkpointing best model, best avg val score was 0.932, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0809 23:24:17.222694 126285554812416 run.py:689] Algo activity_selector step 8200 current loss 2.118902, current_train_items 123504.
I0809 23:24:17.320967 126285554812416 run.py:724] (val) algo activity_selector step 8200: {'selected': 0.887218045112782, 'score': 0.887218045112782, 'examples_seen': 123504, 'step': 8200, 'algorithm': 'activity_selector'}
I0809 23:24:17.321211 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.950, current avg val score is 0.887, val scores are: activity_selector: 0.887
I0809 23:24:18.044983 126285554812416 run.py:689] Algo activity_selector step 8250 current loss 2.232568, current_train_items 124256.
I0809 23:24:18.127456 126285554812416 run.py:724] (val) algo activity_selector step 8250: {'selected': 0.8509090909090908, 'score': 0.8509090909090908, 'examples_seen': 124256, 'step': 8250, 'algorithm': 'activity_selector'}
I0809 23:24:18.127705 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.950, current avg val score is 0.851, val scores are: activity_selector: 0.851
I0809 23:24:18.836682 126285554812416 run.py:689] Algo activity_selector step 8300 current loss 1.774224, current_train_items 125008.
I0809 23:24:18.933257 126285554812416 run.py:724] (val) algo activity_selector step 8300: {'selected': 0.9104477611940298, 'score': 0.9104477611940298, 'examples_seen': 125008, 'step': 8300, 'algorithm': 'activity_selector'}
I0809 23:24:18.933495 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.950, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0809 23:24:19.642706 126285554812416 run.py:689] Algo activity_selector step 8350 current loss 1.619061, current_train_items 125760.
I0809 23:24:19.735783 126285554812416 run.py:724] (val) algo activity_selector step 8350: {'selected': 0.9438202247191011, 'score': 0.9438202247191011, 'examples_seen': 125760, 'step': 8350, 'algorithm': 'activity_selector'}
I0809 23:24:19.736008 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.950, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0809 23:24:20.430092 126285554812416 run.py:689] Algo activity_selector step 8400 current loss 1.787253, current_train_items 126512.
I0809 23:24:20.544895 126285554812416 run.py:724] (val) algo activity_selector step 8400: {'selected': 0.9189189189189189, 'score': 0.9189189189189189, 'examples_seen': 126512, 'step': 8400, 'algorithm': 'activity_selector'}
I0809 23:24:20.545132 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.950, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0809 23:24:21.253757 126285554812416 run.py:689] Algo activity_selector step 8450 current loss 1.083064, current_train_items 127264.
I0809 23:24:21.349935 126285554812416 run.py:724] (val) algo activity_selector step 8450: {'selected': 0.9652509652509652, 'score': 0.9652509652509652, 'examples_seen': 127264, 'step': 8450, 'algorithm': 'activity_selector'}
I0809 23:24:21.350203 126285554812416 run.py:745] Checkpointing best model, best avg val score was 0.950, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0809 23:24:22.080684 126285554812416 run.py:689] Algo activity_selector step 8500 current loss 1.037057, current_train_items 128016.
I0809 23:24:22.179012 126285554812416 run.py:724] (val) algo activity_selector step 8500: {'selected': 0.9429657794676807, 'score': 0.9429657794676807, 'examples_seen': 128016, 'step': 8500, 'algorithm': 'activity_selector'}
I0809 23:24:22.179251 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0809 23:24:22.888505 126285554812416 run.py:689] Algo activity_selector step 8550 current loss 1.160646, current_train_items 128768.
I0809 23:24:22.983826 126285554812416 run.py:724] (val) algo activity_selector step 8550: {'selected': 0.9037037037037037, 'score': 0.9037037037037037, 'examples_seen': 128768, 'step': 8550, 'algorithm': 'activity_selector'}
I0809 23:24:22.984054 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.904, val scores are: activity_selector: 0.904
I0809 23:24:23.692924 126285554812416 run.py:689] Algo activity_selector step 8600 current loss 0.263544, current_train_items 129520.
I0809 23:24:23.788999 126285554812416 run.py:724] (val) algo activity_selector step 8600: {'selected': 0.9429657794676807, 'score': 0.9429657794676807, 'examples_seen': 129520, 'step': 8600, 'algorithm': 'activity_selector'}
I0809 23:24:23.789238 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0809 23:24:24.498353 126285554812416 run.py:689] Algo activity_selector step 8650 current loss 4.944493, current_train_items 130288.
I0809 23:24:24.590335 126285554812416 run.py:724] (val) algo activity_selector step 8650: {'selected': 0.937984496124031, 'score': 0.937984496124031, 'examples_seen': 130288, 'step': 8650, 'algorithm': 'activity_selector'}
I0809 23:24:24.590507 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0809 23:24:25.277111 126285554812416 run.py:689] Algo activity_selector step 8700 current loss 3.881868, current_train_items 131040.
I0809 23:24:25.388882 126285554812416 run.py:724] (val) algo activity_selector step 8700: {'selected': 0.9011857707509882, 'score': 0.9011857707509882, 'examples_seen': 131040, 'step': 8700, 'algorithm': 'activity_selector'}
I0809 23:24:25.389108 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.901, val scores are: activity_selector: 0.901
I0809 23:24:26.084574 126285554812416 run.py:689] Algo activity_selector step 8750 current loss 3.279463, current_train_items 131792.
I0809 23:24:26.185382 126285554812416 run.py:724] (val) algo activity_selector step 8750: {'selected': 0.9453125000000001, 'score': 0.9453125000000001, 'examples_seen': 131792, 'step': 8750, 'algorithm': 'activity_selector'}
I0809 23:24:26.185575 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0809 23:24:26.874406 126285554812416 run.py:689] Algo activity_selector step 8800 current loss 2.951279, current_train_items 132544.
I0809 23:24:26.985264 126285554812416 run.py:724] (val) algo activity_selector step 8800: {'selected': 0.9312977099236641, 'score': 0.9312977099236641, 'examples_seen': 132544, 'step': 8800, 'algorithm': 'activity_selector'}
I0809 23:24:26.985488 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0809 23:24:27.693586 126285554812416 run.py:689] Algo activity_selector step 8850 current loss 2.607139, current_train_items 133296.
I0809 23:24:27.785710 126285554812416 run.py:724] (val) algo activity_selector step 8850: {'selected': 0.9505703422053231, 'score': 0.9505703422053231, 'examples_seen': 133296, 'step': 8850, 'algorithm': 'activity_selector'}
I0809 23:24:27.785857 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0809 23:24:28.475107 126285554812416 run.py:689] Algo activity_selector step 8900 current loss 2.457706, current_train_items 134048.
I0809 23:24:28.580411 126285554812416 run.py:724] (val) algo activity_selector step 8900: {'selected': 0.9501915708812262, 'score': 0.9501915708812262, 'examples_seen': 134048, 'step': 8900, 'algorithm': 'activity_selector'}
I0809 23:24:28.580560 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0809 23:24:29.272604 126285554812416 run.py:689] Algo activity_selector step 8950 current loss 2.257751, current_train_items 134800.
I0809 23:24:29.378545 126285554812416 run.py:724] (val) algo activity_selector step 8950: {'selected': 0.9457364341085271, 'score': 0.9457364341085271, 'examples_seen': 134800, 'step': 8950, 'algorithm': 'activity_selector'}
I0809 23:24:29.378696 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0809 23:24:30.081442 126285554812416 run.py:689] Algo activity_selector step 9000 current loss 2.191655, current_train_items 135552.
I0809 23:24:30.174710 126285554812416 run.py:724] (val) algo activity_selector step 9000: {'selected': 0.9195402298850576, 'score': 0.9195402298850576, 'examples_seen': 135552, 'step': 9000, 'algorithm': 'activity_selector'}
I0809 23:24:30.174856 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0809 23:24:30.877496 126285554812416 run.py:689] Algo activity_selector step 9050 current loss 1.800539, current_train_items 136304.
I0809 23:24:30.973869 126285554812416 run.py:724] (val) algo activity_selector step 9050: {'selected': 0.9242424242424243, 'score': 0.9242424242424243, 'examples_seen': 136304, 'step': 9050, 'algorithm': 'activity_selector'}
I0809 23:24:30.974091 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0809 23:24:31.682442 126285554812416 run.py:689] Algo activity_selector step 9100 current loss 1.866504, current_train_items 137056.
I0809 23:24:31.773171 126285554812416 run.py:724] (val) algo activity_selector step 9100: {'selected': 0.9070631970260222, 'score': 0.9070631970260222, 'examples_seen': 137056, 'step': 9100, 'algorithm': 'activity_selector'}
I0809 23:24:31.773337 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0809 23:24:32.476268 126285554812416 run.py:689] Algo activity_selector step 9150 current loss 1.913453, current_train_items 137808.
I0809 23:24:32.573285 126285554812416 run.py:724] (val) algo activity_selector step 9150: {'selected': 0.8634686346863468, 'score': 0.8634686346863468, 'examples_seen': 137808, 'step': 9150, 'algorithm': 'activity_selector'}
I0809 23:24:32.573509 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.863, val scores are: activity_selector: 0.863
I0809 23:24:33.266268 126285554812416 run.py:689] Algo activity_selector step 9200 current loss 1.610446, current_train_items 138560.
I0809 23:24:33.375906 126285554812416 run.py:724] (val) algo activity_selector step 9200: {'selected': 0.9272030651340997, 'score': 0.9272030651340997, 'examples_seen': 138560, 'step': 9200, 'algorithm': 'activity_selector'}
I0809 23:24:33.376089 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0809 23:24:34.079945 126285554812416 run.py:689] Algo activity_selector step 9250 current loss 1.472125, current_train_items 139312.
I0809 23:24:34.178370 126285554812416 run.py:724] (val) algo activity_selector step 9250: {'selected': 0.9429657794676807, 'score': 0.9429657794676807, 'examples_seen': 139312, 'step': 9250, 'algorithm': 'activity_selector'}
I0809 23:24:34.178597 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0809 23:24:34.887033 126285554812416 run.py:689] Algo activity_selector step 9300 current loss 1.122298, current_train_items 140064.
I0809 23:24:34.983769 126285554812416 run.py:724] (val) algo activity_selector step 9300: {'selected': 0.9461538461538461, 'score': 0.9461538461538461, 'examples_seen': 140064, 'step': 9300, 'algorithm': 'activity_selector'}
I0809 23:24:34.983997 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0809 23:24:35.692964 126285554812416 run.py:689] Algo activity_selector step 9350 current loss 0.955092, current_train_items 140816.
I0809 23:24:35.789572 126285554812416 run.py:724] (val) algo activity_selector step 9350: {'selected': 0.9195402298850576, 'score': 0.9195402298850576, 'examples_seen': 140816, 'step': 9350, 'algorithm': 'activity_selector'}
I0809 23:24:35.789798 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0809 23:24:36.498664 126285554812416 run.py:689] Algo activity_selector step 9400 current loss 1.415697, current_train_items 141568.
I0809 23:24:36.596892 126285554812416 run.py:724] (val) algo activity_selector step 9400: {'selected': 0.9213483146067415, 'score': 0.9213483146067415, 'examples_seen': 141568, 'step': 9400, 'algorithm': 'activity_selector'}
I0809 23:24:36.597137 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0809 23:24:37.306251 126285554812416 run.py:689] Algo activity_selector step 9450 current loss 0.308491, current_train_items 142320.
I0809 23:24:37.405507 126285554812416 run.py:724] (val) algo activity_selector step 9450: {'selected': 0.9578544061302683, 'score': 0.9578544061302683, 'examples_seen': 142320, 'step': 9450, 'algorithm': 'activity_selector'}
I0809 23:24:37.405732 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0809 23:24:38.099445 126285554812416 run.py:689] Algo activity_selector step 9500 current loss 4.941681, current_train_items 143088.
I0809 23:24:38.209330 126285554812416 run.py:724] (val) algo activity_selector step 9500: {'selected': 0.9649805447470817, 'score': 0.9649805447470817, 'examples_seen': 143088, 'step': 9500, 'algorithm': 'activity_selector'}
I0809 23:24:38.209572 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0809 23:24:38.913936 126285554812416 run.py:689] Algo activity_selector step 9550 current loss 3.886801, current_train_items 143840.
I0809 23:24:39.012850 126285554812416 run.py:724] (val) algo activity_selector step 9550: {'selected': 0.9498069498069497, 'score': 0.9498069498069497, 'examples_seen': 143840, 'step': 9550, 'algorithm': 'activity_selector'}
I0809 23:24:39.013074 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0809 23:24:39.700184 126285554812416 run.py:689] Algo activity_selector step 9600 current loss 3.394174, current_train_items 144592.
I0809 23:24:39.811117 126285554812416 run.py:724] (val) algo activity_selector step 9600: {'selected': 0.9575289575289576, 'score': 0.9575289575289576, 'examples_seen': 144592, 'step': 9600, 'algorithm': 'activity_selector'}
I0809 23:24:39.811362 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0809 23:24:40.519306 126285554812416 run.py:689] Algo activity_selector step 9650 current loss 2.816552, current_train_items 145344.
I0809 23:24:40.617021 126285554812416 run.py:724] (val) algo activity_selector step 9650: {'selected': 0.9236641221374045, 'score': 0.9236641221374045, 'examples_seen': 145344, 'step': 9650, 'algorithm': 'activity_selector'}
I0809 23:24:40.617263 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0809 23:24:41.324897 126285554812416 run.py:689] Algo activity_selector step 9700 current loss 2.479573, current_train_items 146096.
I0809 23:24:41.422530 126285554812416 run.py:724] (val) algo activity_selector step 9700: {'selected': 0.9307692307692308, 'score': 0.9307692307692308, 'examples_seen': 146096, 'step': 9700, 'algorithm': 'activity_selector'}
I0809 23:24:41.422757 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0809 23:24:42.125480 126285554812416 run.py:689] Algo activity_selector step 9750 current loss 2.339720, current_train_items 146848.
I0809 23:24:42.230190 126285554812416 run.py:724] (val) algo activity_selector step 9750: {'selected': 0.920152091254753, 'score': 0.920152091254753, 'examples_seen': 146848, 'step': 9750, 'algorithm': 'activity_selector'}
I0809 23:24:42.230416 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0809 23:24:42.940298 126285554812416 run.py:689] Algo activity_selector step 9800 current loss 2.263604, current_train_items 147600.
I0809 23:24:43.036621 126285554812416 run.py:724] (val) algo activity_selector step 9800: {'selected': 0.8838951310861423, 'score': 0.8838951310861423, 'examples_seen': 147600, 'step': 9800, 'algorithm': 'activity_selector'}
I0809 23:24:43.036866 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0809 23:24:43.751427 126285554812416 run.py:689] Algo activity_selector step 9850 current loss 2.090513, current_train_items 148352.
I0809 23:24:43.842719 126285554812416 run.py:724] (val) algo activity_selector step 9850: {'selected': 0.8913857677902622, 'score': 0.8913857677902622, 'examples_seen': 148352, 'step': 9850, 'algorithm': 'activity_selector'}
I0809 23:24:43.842943 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0809 23:24:44.540525 126285554812416 run.py:689] Algo activity_selector step 9900 current loss 1.958431, current_train_items 149104.
I0809 23:24:44.649603 126285554812416 run.py:724] (val) algo activity_selector step 9900: {'selected': 0.8981132075471698, 'score': 0.8981132075471698, 'examples_seen': 149104, 'step': 9900, 'algorithm': 'activity_selector'}
I0809 23:24:44.649829 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.898, val scores are: activity_selector: 0.898
I0809 23:24:45.359907 126285554812416 run.py:689] Algo activity_selector step 9950 current loss 1.844220, current_train_items 149856.
I0809 23:24:45.456626 126285554812416 run.py:724] (val) algo activity_selector step 9950: {'selected': 0.9242424242424243, 'score': 0.9242424242424243, 'examples_seen': 149856, 'step': 9950, 'algorithm': 'activity_selector'}
I0809 23:24:45.456848 126285554812416 run.py:748] Not saving new best model, best avg val score was 0.965, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0809 23:24:46.151161 126285554812416 run.py:754] Restoring best model from checkpoint...
I0809 23:24:52.002780 126285554812416 run.py:769] (test) algo activity_selector : {'selected': 0.9137614678899082, 'score': 0.9137614678899082, 'examples_seen': 150592, 'step': 10000, 'algorithm': 'activity_selector'}
I0809 23:24:52.002922 126285554812416 run.py:771] Done!
