I0703 11:29:59.443260 133161429332608 xla_bridge.py:924] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0703 11:29:59.470364 133161429332608 xla_bridge.py:924] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0703 11:30:00.575651 133161429332608 run.py:402] Model: falreis ['activity_selector']
I0703 11:30:00.575863 133161429332608 run.py:404] algorithms ['activity_selector']
I0703 11:30:00.576201 133161429332608 run.py:405] train_lengths ['2', '3', '5', '7', '11', '13', '17', '19', '23', '29', '31', '37', '39', '41']
I0703 11:30:00.576261 133161429332608 run.py:406] train_batch_size 32
I0703 11:30:00.576411 133161429332608 run.py:407] val_batch_size 16
I0703 11:30:00.576454 133161429332608 run.py:408] test_batch_size 16
I0703 11:30:00.576504 133161429332608 run.py:409] chunked_training True
I0703 11:30:00.576899 133161429332608 run.py:410] chunk_length 16
I0703 11:30:00.576940 133161429332608 run.py:411] train_steps 10000
I0703 11:30:00.576972 133161429332608 run.py:412] eval_every 50
I0703 11:30:00.577002 133161429332608 run.py:413] test_every 500
I0703 11:30:00.577029 133161429332608 run.py:414] learning_rate 0.001
I0703 11:30:00.577178 133161429332608 run.py:415] grad_clip_max_norm 1.0
I0703 11:30:00.577208 133161429332608 run.py:416] dropout_prob 0.1
I0703 11:30:00.577235 133161429332608 run.py:417] hint_teacher_forcing 0.0
I0703 11:30:00.577262 133161429332608 run.py:418] hint_mode encoded_decoded
I0703 11:30:00.577377 133161429332608 run.py:419] hint_repred_mode hard_on_eval
I0703 11:30:00.577405 133161429332608 run.py:420] use_ln False
I0703 11:30:00.577432 133161429332608 run.py:421] use_lstm True
I0703 11:30:00.577460 133161429332608 run.py:422] nb_triplet_fts 8
I0703 11:30:00.577486 133161429332608 run.py:423] encoder_init xavier_on_scalars
I0703 11:30:00.577512 133161429332608 run.py:424] processor_type falreis
I0703 11:30:00.577537 133161429332608 run.py:425] checkpoint_path CLRS30
I0703 11:30:00.577562 133161429332608 run.py:426] dataset_path CLRS30
I0703 11:30:00.577587 133161429332608 run.py:427] freeze_processor False
I0703 11:30:00.577613 133161429332608 run.py:428] reduction min
I0703 11:30:00.577639 133161429332608 run.py:429] activation elu
I0703 11:30:00.577666 133161429332608 run.py:430] algorithm_models ['F1', 'F2']
I0703 11:30:00.577694 133161429332608 run.py:431] restore_model 
I0703 11:30:00.577728 133161429332608 run.py:432] gated True
I0703 11:30:00.577755 133161429332608 run.py:433] gated_activation sigmoid
I0703 11:30:00.588330 133161429332608 run.py:459] Creating samplers for algo activity_selector
W0703 11:30:00.588557 133161429332608 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0703 11:30:00.588907 133161429332608 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0703 11:30:00.790594 133161429332608 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0703 11:30:00.997394 133161429332608 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0703 11:30:01.247317 133161429332608 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0703 11:30:01.534645 133161429332608 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0703 11:30:01.899779 133161429332608 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0703 11:30:02.296499 133161429332608 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0703 11:30:02.750573 133161429332608 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0703 11:30:03.237430 133161429332608 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0703 11:30:03.869337 133161429332608 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0703 11:30:04.607526 133161429332608 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0703 11:30:05.502572 133161429332608 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0703 11:30:06.517102 133161429332608 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0703 11:30:08.011731 133161429332608 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0703 11:30:09.821523 133161429332608 samplers.py:299] Ignoring kwargs {'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0703 11:30:09.821915 133161429332608 samplers.py:124] Creating a dataset with 64 samples.
I0703 11:30:09.897603 133161429332608 run.py:248] Dataset not found in CLRS30/CLRS30_v1.0.0. Downloading...
I0703 11:30:37.241893 133161429332608 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0703 11:30:37.245176 133161429332608 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0703 11:30:37.255850 133161429332608 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0703 11:30:37.356740 133161429332608 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0703 11:31:48.479281 133161429332608 run.py:674] Algo activity_selector step 0 current loss 3.771763, current_train_items 128.
I0703 11:31:50.692577 133161429332608 run.py:709] (val) algo activity_selector step 0: {'selected': 0.03894080996884735, 'score': 0.03894080996884735, 'examples_seen': 128, 'step': 0, 'algorithm': 'activity_selector'}
I0703 11:31:50.692792 133161429332608 run.py:730] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.039, val scores are: activity_selector: 0.039
I0703 11:33:52.666153 133161429332608 run.py:674] Algo activity_selector step 50 current loss 6.167295, current_train_items 2496.
I0703 11:33:53.088529 133161429332608 run.py:709] (val) algo activity_selector step 50: {'selected': 0.5965770171149145, 'score': 0.5965770171149145, 'examples_seen': 2496, 'step': 50, 'algorithm': 'activity_selector'}
I0703 11:33:53.088775 133161429332608 run.py:730] Checkpointing best model, best avg val score was 0.039, current avg val score is 0.597, val scores are: activity_selector: 0.597
I0703 11:33:56.947935 133161429332608 run.py:674] Algo activity_selector step 100 current loss 4.059486, current_train_items 5120.
I0703 11:33:57.199676 133161429332608 run.py:709] (val) algo activity_selector step 100: {'selected': 0.6511627906976745, 'score': 0.6511627906976745, 'examples_seen': 5120, 'step': 100, 'algorithm': 'activity_selector'}
I0703 11:33:57.199945 133161429332608 run.py:730] Checkpointing best model, best avg val score was 0.597, current avg val score is 0.651, val scores are: activity_selector: 0.651
I0703 11:34:00.851948 133161429332608 run.py:674] Algo activity_selector step 150 current loss 6.411395, current_train_items 7328.
I0703 11:34:01.424988 133161429332608 run.py:709] (val) algo activity_selector step 150: {'selected': 0.5735694822888284, 'score': 0.5735694822888284, 'examples_seen': 7328, 'step': 150, 'algorithm': 'activity_selector'}
I0703 11:34:01.425188 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.651, current avg val score is 0.574, val scores are: activity_selector: 0.574
I0703 11:34:05.041045 133161429332608 run.py:674] Algo activity_selector step 200 current loss 4.337154, current_train_items 9888.
I0703 11:34:05.308295 133161429332608 run.py:709] (val) algo activity_selector step 200: {'selected': 0.5834633385335414, 'score': 0.5834633385335414, 'examples_seen': 9888, 'step': 200, 'algorithm': 'activity_selector'}
I0703 11:34:05.308494 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.651, current avg val score is 0.583, val scores are: activity_selector: 0.583
I0703 11:34:08.934555 133161429332608 run.py:674] Algo activity_selector step 250 current loss 7.141277, current_train_items 12000.
I0703 11:34:09.626397 133161429332608 run.py:709] (val) algo activity_selector step 250: {'selected': 0.6318407960199005, 'score': 0.6318407960199005, 'examples_seen': 12000, 'step': 250, 'algorithm': 'activity_selector'}
I0703 11:34:09.626635 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.651, current avg val score is 0.632, val scores are: activity_selector: 0.632
I0703 11:34:13.311278 133161429332608 run.py:674] Algo activity_selector step 300 current loss 4.772161, current_train_items 14592.
I0703 11:34:13.603403 133161429332608 run.py:709] (val) algo activity_selector step 300: {'selected': 0.7355450236966825, 'score': 0.7355450236966825, 'examples_seen': 14592, 'step': 300, 'algorithm': 'activity_selector'}
I0703 11:34:13.603580 133161429332608 run.py:730] Checkpointing best model, best avg val score was 0.651, current avg val score is 0.736, val scores are: activity_selector: 0.736
I0703 11:34:17.439203 133161429332608 run.py:674] Algo activity_selector step 350 current loss 2.093970, current_train_items 16992.
I0703 11:34:17.823523 133161429332608 run.py:709] (val) algo activity_selector step 350: {'selected': 0.6379114642451759, 'score': 0.6379114642451759, 'examples_seen': 16992, 'step': 350, 'algorithm': 'activity_selector'}
I0703 11:34:17.823770 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.736, current avg val score is 0.638, val scores are: activity_selector: 0.638
I0703 11:34:21.160204 133161429332608 run.py:674] Algo activity_selector step 400 current loss 4.967990, current_train_items 19456.
I0703 11:34:21.587712 133161429332608 run.py:709] (val) algo activity_selector step 400: {'selected': 0.7076923076923077, 'score': 0.7076923076923077, 'examples_seen': 19456, 'step': 400, 'algorithm': 'activity_selector'}
I0703 11:34:21.587967 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.736, current avg val score is 0.708, val scores are: activity_selector: 0.708
I0703 11:34:25.591585 133161429332608 run.py:674] Algo activity_selector step 450 current loss 3.312851, current_train_items 21888.
I0703 11:34:25.854371 133161429332608 run.py:709] (val) algo activity_selector step 450: {'selected': 0.7063414634146341, 'score': 0.7063414634146341, 'examples_seen': 21888, 'step': 450, 'algorithm': 'activity_selector'}
I0703 11:34:25.854646 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.736, current avg val score is 0.706, val scores are: activity_selector: 0.706
I0703 11:34:29.232057 133161429332608 run.py:674] Algo activity_selector step 500 current loss 5.405866, current_train_items 24064.
I0703 11:34:29.792043 133161429332608 run.py:709] (val) algo activity_selector step 500: {'selected': 0.6854838709677419, 'score': 0.6854838709677419, 'examples_seen': 24064, 'step': 500, 'algorithm': 'activity_selector'}
I0703 11:34:29.792233 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.736, current avg val score is 0.685, val scores are: activity_selector: 0.685
I0703 11:34:33.378641 133161429332608 run.py:674] Algo activity_selector step 550 current loss 3.977583, current_train_items 26688.
I0703 11:34:33.646983 133161429332608 run.py:709] (val) algo activity_selector step 550: {'selected': 0.7410281280310378, 'score': 0.7410281280310378, 'examples_seen': 26688, 'step': 550, 'algorithm': 'activity_selector'}
I0703 11:34:33.647207 133161429332608 run.py:730] Checkpointing best model, best avg val score was 0.736, current avg val score is 0.741, val scores are: activity_selector: 0.741
I0703 11:34:37.478724 133161429332608 run.py:674] Algo activity_selector step 600 current loss 5.456116, current_train_items 28864.
I0703 11:34:38.146325 133161429332608 run.py:709] (val) algo activity_selector step 600: {'selected': 0.6519944979367264, 'score': 0.6519944979367264, 'examples_seen': 28864, 'step': 600, 'algorithm': 'activity_selector'}
I0703 11:34:38.146514 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.741, current avg val score is 0.652, val scores are: activity_selector: 0.652
I0703 11:34:41.501451 133161429332608 run.py:674] Algo activity_selector step 650 current loss 4.224578, current_train_items 31456.
I0703 11:34:41.792401 133161429332608 run.py:709] (val) algo activity_selector step 650: {'selected': 0.7142857142857143, 'score': 0.7142857142857143, 'examples_seen': 31456, 'step': 650, 'algorithm': 'activity_selector'}
I0703 11:34:41.792585 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.741, current avg val score is 0.714, val scores are: activity_selector: 0.714
I0703 11:34:45.561541 133161429332608 run.py:674] Algo activity_selector step 700 current loss 1.220739, current_train_items 33920.
I0703 11:34:45.936670 133161429332608 run.py:709] (val) algo activity_selector step 700: {'selected': 0.7395264116575592, 'score': 0.7395264116575592, 'examples_seen': 33920, 'step': 700, 'algorithm': 'activity_selector'}
I0703 11:34:45.936930 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.741, current avg val score is 0.740, val scores are: activity_selector: 0.740
I0703 11:34:49.479499 133161429332608 run.py:674] Algo activity_selector step 750 current loss 4.508673, current_train_items 36192.
I0703 11:34:49.859709 133161429332608 run.py:709] (val) algo activity_selector step 750: {'selected': 0.6809210526315789, 'score': 0.6809210526315789, 'examples_seen': 36192, 'step': 750, 'algorithm': 'activity_selector'}
I0703 11:34:49.859946 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.741, current avg val score is 0.681, val scores are: activity_selector: 0.681
I0703 11:34:53.608533 133161429332608 run.py:674] Algo activity_selector step 800 current loss 1.632489, current_train_items 38752.
I0703 11:34:53.855232 133161429332608 run.py:709] (val) algo activity_selector step 800: {'selected': 0.7850834151128556, 'score': 0.7850834151128556, 'examples_seen': 38752, 'step': 800, 'algorithm': 'activity_selector'}
I0703 11:34:53.855441 133161429332608 run.py:730] Checkpointing best model, best avg val score was 0.741, current avg val score is 0.785, val scores are: activity_selector: 0.785
I0703 11:34:57.212063 133161429332608 run.py:674] Algo activity_selector step 850 current loss 4.904475, current_train_items 40992.
I0703 11:34:57.768376 133161429332608 run.py:709] (val) algo activity_selector step 850: {'selected': 0.8130252100840336, 'score': 0.8130252100840336, 'examples_seen': 40992, 'step': 850, 'algorithm': 'activity_selector'}
I0703 11:34:57.768567 133161429332608 run.py:730] Checkpointing best model, best avg val score was 0.785, current avg val score is 0.813, val scores are: activity_selector: 0.813
I0703 11:35:01.470811 133161429332608 run.py:674] Algo activity_selector step 900 current loss 3.225677, current_train_items 43584.
I0703 11:35:01.730072 133161429332608 run.py:709] (val) algo activity_selector step 900: {'selected': 0.7887029288702929, 'score': 0.7887029288702929, 'examples_seen': 43584, 'step': 900, 'algorithm': 'activity_selector'}
I0703 11:35:01.730256 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.813, current avg val score is 0.789, val scores are: activity_selector: 0.789
I0703 11:35:05.271531 133161429332608 run.py:674] Algo activity_selector step 950 current loss 4.518816, current_train_items 45760.
I0703 11:35:05.943675 133161429332608 run.py:709] (val) algo activity_selector step 950: {'selected': 0.8362369337979093, 'score': 0.8362369337979093, 'examples_seen': 45760, 'step': 950, 'algorithm': 'activity_selector'}
I0703 11:35:05.943961 133161429332608 run.py:730] Checkpointing best model, best avg val score was 0.813, current avg val score is 0.836, val scores are: activity_selector: 0.836
I0703 11:35:09.400215 133161429332608 run.py:674] Algo activity_selector step 1000 current loss 3.646408, current_train_items 48320.
I0703 11:35:09.694155 133161429332608 run.py:709] (val) algo activity_selector step 1000: {'selected': 0.8242548818088387, 'score': 0.8242548818088387, 'examples_seen': 48320, 'step': 1000, 'algorithm': 'activity_selector'}
I0703 11:35:09.694449 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.836, current avg val score is 0.824, val scores are: activity_selector: 0.824
I0703 11:35:13.695625 133161429332608 run.py:674] Algo activity_selector step 1050 current loss 0.989359, current_train_items 50688.
I0703 11:35:14.095288 133161429332608 run.py:709] (val) algo activity_selector step 1050: {'selected': 0.7517361111111112, 'score': 0.7517361111111112, 'examples_seen': 50688, 'step': 1050, 'algorithm': 'activity_selector'}
I0703 11:35:14.095477 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.836, current avg val score is 0.752, val scores are: activity_selector: 0.752
I0703 11:35:17.465395 133161429332608 run.py:674] Algo activity_selector step 1100 current loss 6.476015, current_train_items 53088.
I0703 11:35:17.887722 133161429332608 run.py:709] (val) algo activity_selector step 1100: {'selected': 0.7743362831858407, 'score': 0.7743362831858407, 'examples_seen': 53088, 'step': 1100, 'algorithm': 'activity_selector'}
I0703 11:35:17.887961 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.836, current avg val score is 0.774, val scores are: activity_selector: 0.774
I0703 11:35:21.655592 133161429332608 run.py:674] Algo activity_selector step 1150 current loss 0.877959, current_train_items 55584.
I0703 11:35:21.907368 133161429332608 run.py:709] (val) algo activity_selector step 1150: {'selected': 0.8665207877461708, 'score': 0.8665207877461708, 'examples_seen': 55584, 'step': 1150, 'algorithm': 'activity_selector'}
I0703 11:35:21.907550 133161429332608 run.py:730] Checkpointing best model, best avg val score was 0.836, current avg val score is 0.867, val scores are: activity_selector: 0.867
I0703 11:35:25.541264 133161429332608 run.py:674] Algo activity_selector step 1200 current loss 7.404100, current_train_items 57856.
I0703 11:35:26.108533 133161429332608 run.py:709] (val) algo activity_selector step 1200: {'selected': 0.8590021691973969, 'score': 0.8590021691973969, 'examples_seen': 57856, 'step': 1200, 'algorithm': 'activity_selector'}
I0703 11:35:26.108763 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.867, current avg val score is 0.859, val scores are: activity_selector: 0.859
I0703 11:35:29.677878 133161429332608 run.py:674] Algo activity_selector step 1250 current loss 2.330525, current_train_items 60480.
I0703 11:35:29.941753 133161429332608 run.py:709] (val) algo activity_selector step 1250: {'selected': 0.8431137724550899, 'score': 0.8431137724550899, 'examples_seen': 60480, 'step': 1250, 'algorithm': 'activity_selector'}
I0703 11:35:29.942006 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.867, current avg val score is 0.843, val scores are: activity_selector: 0.843
I0703 11:35:33.542351 133161429332608 run.py:674] Algo activity_selector step 1300 current loss 5.438554, current_train_items 62560.
I0703 11:35:34.224292 133161429332608 run.py:709] (val) algo activity_selector step 1300: {'selected': 0.8454106280193238, 'score': 0.8454106280193238, 'examples_seen': 62560, 'step': 1300, 'algorithm': 'activity_selector'}
I0703 11:35:34.224502 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.867, current avg val score is 0.845, val scores are: activity_selector: 0.845
I0703 11:35:37.941881 133161429332608 run.py:674] Algo activity_selector step 1350 current loss 3.785153, current_train_items 65120.
I0703 11:35:38.240219 133161429332608 run.py:709] (val) algo activity_selector step 1350: {'selected': 0.805668016194332, 'score': 0.805668016194332, 'examples_seen': 65120, 'step': 1350, 'algorithm': 'activity_selector'}
I0703 11:35:38.240427 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.867, current avg val score is 0.806, val scores are: activity_selector: 0.806
I0703 11:35:42.043560 133161429332608 run.py:674] Algo activity_selector step 1400 current loss 0.700799, current_train_items 67552.
I0703 11:35:42.425513 133161429332608 run.py:709] (val) algo activity_selector step 1400: {'selected': 0.8364717542120911, 'score': 0.8364717542120911, 'examples_seen': 67552, 'step': 1400, 'algorithm': 'activity_selector'}
I0703 11:35:42.425773 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.867, current avg val score is 0.836, val scores are: activity_selector: 0.836
I0703 11:35:45.755091 133161429332608 run.py:674] Algo activity_selector step 1450 current loss 4.889217, current_train_items 70016.
I0703 11:35:46.178081 133161429332608 run.py:709] (val) algo activity_selector step 1450: {'selected': 0.8322981366459626, 'score': 0.8322981366459626, 'examples_seen': 70016, 'step': 1450, 'algorithm': 'activity_selector'}
I0703 11:35:46.178288 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.867, current avg val score is 0.832, val scores are: activity_selector: 0.832
I0703 11:35:50.218625 133161429332608 run.py:674] Algo activity_selector step 1500 current loss 0.911936, current_train_items 72512.
I0703 11:35:50.468121 133161429332608 run.py:709] (val) algo activity_selector step 1500: {'selected': 0.8926673751328374, 'score': 0.8926673751328374, 'examples_seen': 72512, 'step': 1500, 'algorithm': 'activity_selector'}
I0703 11:35:50.468325 133161429332608 run.py:730] Checkpointing best model, best avg val score was 0.867, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0703 11:35:53.852151 133161429332608 run.py:674] Algo activity_selector step 1550 current loss 4.052480, current_train_items 74688.
I0703 11:35:54.414424 133161429332608 run.py:709] (val) algo activity_selector step 1550: {'selected': 0.8307692307692308, 'score': 0.8307692307692308, 'examples_seen': 74688, 'step': 1550, 'algorithm': 'activity_selector'}
I0703 11:35:54.414672 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.893, current avg val score is 0.831, val scores are: activity_selector: 0.831
I0703 11:35:57.959835 133161429332608 run.py:674] Algo activity_selector step 1600 current loss 2.643330, current_train_items 77248.
I0703 11:35:58.222172 133161429332608 run.py:709] (val) algo activity_selector step 1600: {'selected': 0.8316633266533066, 'score': 0.8316633266533066, 'examples_seen': 77248, 'step': 1600, 'algorithm': 'activity_selector'}
I0703 11:35:58.222353 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.893, current avg val score is 0.832, val scores are: activity_selector: 0.832
I0703 11:36:01.934295 133161429332608 run.py:674] Algo activity_selector step 1650 current loss 2.276791, current_train_items 79424.
I0703 11:36:02.607145 133161429332608 run.py:709] (val) algo activity_selector step 1650: {'selected': 0.9101382488479263, 'score': 0.9101382488479263, 'examples_seen': 79424, 'step': 1650, 'algorithm': 'activity_selector'}
I0703 11:36:02.607333 133161429332608 run.py:730] Checkpointing best model, best avg val score was 0.893, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0703 11:36:06.024559 133161429332608 run.py:674] Algo activity_selector step 1700 current loss 2.570464, current_train_items 82080.
I0703 11:36:06.316579 133161429332608 run.py:709] (val) algo activity_selector step 1700: {'selected': 0.9122807017543859, 'score': 0.9122807017543859, 'examples_seen': 82080, 'step': 1700, 'algorithm': 'activity_selector'}
I0703 11:36:06.316763 133161429332608 run.py:730] Checkpointing best model, best avg val score was 0.910, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0703 11:36:10.102305 133161429332608 run.py:674] Algo activity_selector step 1750 current loss 0.414537, current_train_items 84544.
I0703 11:36:10.479642 133161429332608 run.py:709] (val) algo activity_selector step 1750: {'selected': 0.8838643371017472, 'score': 0.8838643371017472, 'examples_seen': 84544, 'step': 1750, 'algorithm': 'activity_selector'}
I0703 11:36:10.479931 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.912, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0703 11:36:14.056807 133161429332608 run.py:674] Algo activity_selector step 1800 current loss 3.052289, current_train_items 86784.
I0703 11:36:14.463776 133161429332608 run.py:709] (val) algo activity_selector step 1800: {'selected': 0.9065520945220192, 'score': 0.9065520945220192, 'examples_seen': 86784, 'step': 1800, 'algorithm': 'activity_selector'}
I0703 11:36:14.464034 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.912, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0703 11:36:18.245718 133161429332608 run.py:674] Algo activity_selector step 1850 current loss 0.582018, current_train_items 89312.
I0703 11:36:18.494453 133161429332608 run.py:709] (val) algo activity_selector step 1850: {'selected': 0.9317919075144507, 'score': 0.9317919075144507, 'examples_seen': 89312, 'step': 1850, 'algorithm': 'activity_selector'}
I0703 11:36:18.494673 133161429332608 run.py:730] Checkpointing best model, best avg val score was 0.912, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0703 11:36:21.852244 133161429332608 run.py:674] Algo activity_selector step 1900 current loss 6.320506, current_train_items 91488.
I0703 11:36:22.412016 133161429332608 run.py:709] (val) algo activity_selector step 1900: {'selected': 0.9275028768699655, 'score': 0.9275028768699655, 'examples_seen': 91488, 'step': 1900, 'algorithm': 'activity_selector'}
I0703 11:36:22.412277 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.932, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0703 11:36:26.168621 133161429332608 run.py:674] Algo activity_selector step 1950 current loss 0.689263, current_train_items 94176.
I0703 11:36:26.427878 133161429332608 run.py:709] (val) algo activity_selector step 1950: {'selected': 0.8675995694294941, 'score': 0.8675995694294941, 'examples_seen': 94176, 'step': 1950, 'algorithm': 'activity_selector'}
I0703 11:36:26.428074 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.932, current avg val score is 0.868, val scores are: activity_selector: 0.868
I0703 11:36:29.957354 133161429332608 run.py:674] Algo activity_selector step 2000 current loss 5.585073, current_train_items 96320.
I0703 11:36:30.629140 133161429332608 run.py:709] (val) algo activity_selector step 2000: {'selected': 0.8404133180252583, 'score': 0.8404133180252583, 'examples_seen': 96320, 'step': 2000, 'algorithm': 'activity_selector'}
I0703 11:36:30.629350 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.932, current avg val score is 0.840, val scores are: activity_selector: 0.840
I0703 11:36:34.060830 133161429332608 run.py:674] Algo activity_selector step 2050 current loss 2.572969, current_train_items 98880.
I0703 11:36:34.352784 133161429332608 run.py:709] (val) algo activity_selector step 2050: {'selected': 0.9170403587443946, 'score': 0.9170403587443946, 'examples_seen': 98880, 'step': 2050, 'algorithm': 'activity_selector'}
I0703 11:36:34.353018 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.932, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0703 11:36:38.232849 133161429332608 run.py:674] Algo activity_selector step 2100 current loss 0.409624, current_train_items 101248.
I0703 11:36:38.617985 133161429332608 run.py:709] (val) algo activity_selector step 2100: {'selected': 0.9142212189616253, 'score': 0.9142212189616253, 'examples_seen': 101248, 'step': 2100, 'algorithm': 'activity_selector'}
I0703 11:36:38.618193 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.932, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0703 11:36:41.942730 133161429332608 run.py:674] Algo activity_selector step 2150 current loss 5.909793, current_train_items 103616.
I0703 11:36:42.363635 133161429332608 run.py:709] (val) algo activity_selector step 2150: {'selected': 0.9199134199134199, 'score': 0.9199134199134199, 'examples_seen': 103616, 'step': 2150, 'algorithm': 'activity_selector'}
I0703 11:36:42.363920 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.932, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0703 11:36:46.164199 133161429332608 run.py:674] Algo activity_selector step 2200 current loss 0.978403, current_train_items 106208.
I0703 11:36:46.414717 133161429332608 run.py:709] (val) algo activity_selector step 2200: {'selected': 0.9027149321266967, 'score': 0.9027149321266967, 'examples_seen': 106208, 'step': 2200, 'algorithm': 'activity_selector'}
I0703 11:36:46.414972 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.932, current avg val score is 0.903, val scores are: activity_selector: 0.903
I0703 11:36:50.040242 133161429332608 run.py:674] Algo activity_selector step 2250 current loss 3.772544, current_train_items 108480.
I0703 11:36:50.600742 133161429332608 run.py:709] (val) algo activity_selector step 2250: {'selected': 0.920297555791711, 'score': 0.920297555791711, 'examples_seen': 108480, 'step': 2250, 'algorithm': 'activity_selector'}
I0703 11:36:50.601009 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.932, current avg val score is 0.920, val scores are: activity_selector: 0.920
I0703 11:36:54.164857 133161429332608 run.py:674] Algo activity_selector step 2300 current loss 2.136516, current_train_items 110976.
I0703 11:36:54.429063 133161429332608 run.py:709] (val) algo activity_selector step 2300: {'selected': 0.9427312775330396, 'score': 0.9427312775330396, 'examples_seen': 110976, 'step': 2300, 'algorithm': 'activity_selector'}
I0703 11:36:54.429441 133161429332608 run.py:730] Checkpointing best model, best avg val score was 0.932, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0703 11:36:58.082207 133161429332608 run.py:674] Algo activity_selector step 2350 current loss 0.807601, current_train_items 113152.
I0703 11:36:58.757886 133161429332608 run.py:709] (val) algo activity_selector step 2350: {'selected': 0.9401330376940132, 'score': 0.9401330376940132, 'examples_seen': 113152, 'step': 2350, 'algorithm': 'activity_selector'}
I0703 11:36:58.758109 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.943, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0703 11:37:02.662678 133161429332608 run.py:674] Algo activity_selector step 2400 current loss 2.814036, current_train_items 115680.
I0703 11:37:02.953472 133161429332608 run.py:709] (val) algo activity_selector step 2400: {'selected': 0.937286202964652, 'score': 0.937286202964652, 'examples_seen': 115680, 'step': 2400, 'algorithm': 'activity_selector'}
I0703 11:37:02.953675 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.943, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0703 11:37:06.800732 133161429332608 run.py:674] Algo activity_selector step 2450 current loss 0.362197, current_train_items 118176.
I0703 11:37:07.183377 133161429332608 run.py:709] (val) algo activity_selector step 2450: {'selected': 0.9272918861959958, 'score': 0.9272918861959958, 'examples_seen': 118176, 'step': 2450, 'algorithm': 'activity_selector'}
I0703 11:37:07.183578 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.943, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0703 11:37:10.518618 133161429332608 run.py:674] Algo activity_selector step 2500 current loss 4.392599, current_train_items 120576.
I0703 11:37:10.940062 133161429332608 run.py:709] (val) algo activity_selector step 2500: {'selected': 0.9368932038834952, 'score': 0.9368932038834952, 'examples_seen': 120576, 'step': 2500, 'algorithm': 'activity_selector'}
I0703 11:37:10.940270 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.943, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0703 11:37:14.964196 133161429332608 run.py:674] Algo activity_selector step 2550 current loss 0.503766, current_train_items 123040.
I0703 11:37:15.214007 133161429332608 run.py:709] (val) algo activity_selector step 2550: {'selected': 0.9609810479375697, 'score': 0.9609810479375697, 'examples_seen': 123040, 'step': 2550, 'algorithm': 'activity_selector'}
I0703 11:37:15.214212 133161429332608 run.py:730] Checkpointing best model, best avg val score was 0.943, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0703 11:37:18.605807 133161429332608 run.py:674] Algo activity_selector step 2600 current loss 5.585195, current_train_items 125184.
I0703 11:37:19.163164 133161429332608 run.py:709] (val) algo activity_selector step 2600: {'selected': 0.9755555555555555, 'score': 0.9755555555555555, 'examples_seen': 125184, 'step': 2600, 'algorithm': 'activity_selector'}
I0703 11:37:19.163366 133161429332608 run.py:730] Checkpointing best model, best avg val score was 0.961, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0703 11:37:22.734935 133161429332608 run.py:674] Algo activity_selector step 2650 current loss 3.526243, current_train_items 127840.
I0703 11:37:22.996387 133161429332608 run.py:709] (val) algo activity_selector step 2650: {'selected': 0.9170403587443946, 'score': 0.9170403587443946, 'examples_seen': 127840, 'step': 2650, 'algorithm': 'activity_selector'}
I0703 11:37:22.996580 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0703 11:37:26.820148 133161429332608 run.py:674] Algo activity_selector step 2700 current loss 4.798493, current_train_items 129952.
I0703 11:37:27.486963 133161429332608 run.py:709] (val) algo activity_selector step 2700: {'selected': 0.8618654073199529, 'score': 0.8618654073199529, 'examples_seen': 129952, 'step': 2700, 'algorithm': 'activity_selector'}
I0703 11:37:27.487219 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.862, val scores are: activity_selector: 0.862
I0703 11:37:30.877068 133161429332608 run.py:674] Algo activity_selector step 2750 current loss 2.875478, current_train_items 132640.
I0703 11:37:31.184473 133161429332608 run.py:709] (val) algo activity_selector step 2750: {'selected': 0.8640192539109507, 'score': 0.8640192539109507, 'examples_seen': 132640, 'step': 2750, 'algorithm': 'activity_selector'}
I0703 11:37:31.184650 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.864, val scores are: activity_selector: 0.864
I0703 11:37:34.945901 133161429332608 run.py:674] Algo activity_selector step 2800 current loss 0.211290, current_train_items 135008.
I0703 11:37:35.318004 133161429332608 run.py:709] (val) algo activity_selector step 2800: {'selected': 0.9701834862385321, 'score': 0.9701834862385321, 'examples_seen': 135008, 'step': 2800, 'algorithm': 'activity_selector'}
I0703 11:37:35.318183 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0703 11:37:38.803036 133161429332608 run.py:674] Algo activity_selector step 2850 current loss 3.051615, current_train_items 137344.
I0703 11:37:39.216119 133161429332608 run.py:709] (val) algo activity_selector step 2850: {'selected': 0.8838219326818675, 'score': 0.8838219326818675, 'examples_seen': 137344, 'step': 2850, 'algorithm': 'activity_selector'}
I0703 11:37:39.216308 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0703 11:37:42.971159 133161429332608 run.py:674] Algo activity_selector step 2900 current loss 0.462311, current_train_items 139840.
I0703 11:37:43.221629 133161429332608 run.py:709] (val) algo activity_selector step 2900: {'selected': 0.9634551495016611, 'score': 0.9634551495016611, 'examples_seen': 139840, 'step': 2900, 'algorithm': 'activity_selector'}
I0703 11:37:43.221934 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0703 11:37:46.640378 133161429332608 run.py:674] Algo activity_selector step 2950 current loss 3.137500, current_train_items 142112.
I0703 11:37:47.191412 133161429332608 run.py:709] (val) algo activity_selector step 2950: {'selected': 0.9670588235294117, 'score': 0.9670588235294117, 'examples_seen': 142112, 'step': 2950, 'algorithm': 'activity_selector'}
I0703 11:37:47.191605 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0703 11:37:50.932862 133161429332608 run.py:674] Algo activity_selector step 3000 current loss 1.823829, current_train_items 144704.
I0703 11:37:51.196434 133161429332608 run.py:709] (val) algo activity_selector step 3000: {'selected': 0.9295478443743428, 'score': 0.9295478443743428, 'examples_seen': 144704, 'step': 3000, 'algorithm': 'activity_selector'}
I0703 11:37:51.196671 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0703 11:37:54.742856 133161429332608 run.py:674] Algo activity_selector step 3050 current loss 9.886778, current_train_items 146880.
I0703 11:37:55.409937 133161429332608 run.py:709] (val) algo activity_selector step 3050: {'selected': 0.9584816132858837, 'score': 0.9584816132858837, 'examples_seen': 146880, 'step': 3050, 'algorithm': 'activity_selector'}
I0703 11:37:55.410148 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0703 11:37:58.834726 133161429332608 run.py:674] Algo activity_selector step 3100 current loss 2.681235, current_train_items 149440.
I0703 11:37:59.127236 133161429332608 run.py:709] (val) algo activity_selector step 3100: {'selected': 0.941446613088404, 'score': 0.941446613088404, 'examples_seen': 149440, 'step': 3100, 'algorithm': 'activity_selector'}
I0703 11:37:59.127454 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0703 11:38:03.106987 133161429332608 run.py:674] Algo activity_selector step 3150 current loss 0.200994, current_train_items 151840.
I0703 11:38:03.479570 133161429332608 run.py:709] (val) algo activity_selector step 3150: {'selected': 0.9315068493150684, 'score': 0.9315068493150684, 'examples_seen': 151840, 'step': 3150, 'algorithm': 'activity_selector'}
I0703 11:38:03.479750 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0703 11:38:06.814454 133161429332608 run.py:674] Algo activity_selector step 3200 current loss 6.880152, current_train_items 154176.
I0703 11:38:07.236186 133161429332608 run.py:709] (val) algo activity_selector step 3200: {'selected': 0.9703872437357631, 'score': 0.9703872437357631, 'examples_seen': 154176, 'step': 3200, 'algorithm': 'activity_selector'}
I0703 11:38:07.236473 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0703 11:38:11.001815 133161429332608 run.py:674] Algo activity_selector step 3250 current loss 0.679659, current_train_items 156768.
I0703 11:38:11.251410 133161429332608 run.py:709] (val) algo activity_selector step 3250: {'selected': 0.8932461873638344, 'score': 0.8932461873638344, 'examples_seen': 156768, 'step': 3250, 'algorithm': 'activity_selector'}
I0703 11:38:11.251616 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0703 11:38:14.848964 133161429332608 run.py:674] Algo activity_selector step 3300 current loss 5.020118, current_train_items 158944.
I0703 11:38:15.407120 133161429332608 run.py:709] (val) algo activity_selector step 3300: {'selected': 0.9484777517564402, 'score': 0.9484777517564402, 'examples_seen': 158944, 'step': 3300, 'algorithm': 'activity_selector'}
I0703 11:38:15.407298 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0703 11:38:19.012729 133161429332608 run.py:674] Algo activity_selector step 3350 current loss 2.452153, current_train_items 161600.
I0703 11:38:19.274303 133161429332608 run.py:709] (val) algo activity_selector step 3350: {'selected': 0.951501154734411, 'score': 0.951501154734411, 'examples_seen': 161600, 'step': 3350, 'algorithm': 'activity_selector'}
I0703 11:38:19.274542 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0703 11:38:22.839329 133161429332608 run.py:674] Algo activity_selector step 3400 current loss 4.896747, current_train_items 163648.
I0703 11:38:23.511985 133161429332608 run.py:709] (val) algo activity_selector step 3400: {'selected': 0.9694915254237287, 'score': 0.9694915254237287, 'examples_seen': 163648, 'step': 3400, 'algorithm': 'activity_selector'}
I0703 11:38:23.512202 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0703 11:38:27.188069 133161429332608 run.py:674] Algo activity_selector step 3450 current loss 2.336243, current_train_items 166272.
I0703 11:38:27.480137 133161429332608 run.py:709] (val) algo activity_selector step 3450: {'selected': 0.9662398137369034, 'score': 0.9662398137369034, 'examples_seen': 166272, 'step': 3450, 'algorithm': 'activity_selector'}
I0703 11:38:27.480336 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0703 11:38:31.259023 133161429332608 run.py:674] Algo activity_selector step 3500 current loss 0.438491, current_train_items 168672.
I0703 11:38:31.643293 133161429332608 run.py:709] (val) algo activity_selector step 3500: {'selected': 0.9382448537378115, 'score': 0.9382448537378115, 'examples_seen': 168672, 'step': 3500, 'algorithm': 'activity_selector'}
I0703 11:38:31.643493 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0703 11:38:34.977782 133161429332608 run.py:674] Algo activity_selector step 3550 current loss 4.257075, current_train_items 171104.
I0703 11:38:35.404358 133161429332608 run.py:709] (val) algo activity_selector step 3550: {'selected': 0.9706916764361078, 'score': 0.9706916764361078, 'examples_seen': 171104, 'step': 3550, 'algorithm': 'activity_selector'}
I0703 11:38:35.404584 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0703 11:38:39.521381 133161429332608 run.py:674] Algo activity_selector step 3600 current loss 0.409090, current_train_items 173600.
I0703 11:38:39.768869 133161429332608 run.py:709] (val) algo activity_selector step 3600: {'selected': 0.9330306469920546, 'score': 0.9330306469920546, 'examples_seen': 173600, 'step': 3600, 'algorithm': 'activity_selector'}
I0703 11:38:39.769073 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0703 11:38:43.147354 133161429332608 run.py:674] Algo activity_selector step 3650 current loss 2.449939, current_train_items 175776.
I0703 11:38:43.707697 133161429332608 run.py:709] (val) algo activity_selector step 3650: {'selected': 0.9737742303306728, 'score': 0.9737742303306728, 'examples_seen': 175776, 'step': 3650, 'algorithm': 'activity_selector'}
I0703 11:38:43.707972 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0703 11:38:47.291177 133161429332608 run.py:674] Algo activity_selector step 3700 current loss 1.321951, current_train_items 178368.
I0703 11:38:47.553691 133161429332608 run.py:709] (val) algo activity_selector step 3700: {'selected': 0.9506726457399103, 'score': 0.9506726457399103, 'examples_seen': 178368, 'step': 3700, 'algorithm': 'activity_selector'}
I0703 11:38:47.553954 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0703 11:38:51.293141 133161429332608 run.py:674] Algo activity_selector step 3750 current loss 9.095751, current_train_items 180544.
I0703 11:38:51.972183 133161429332608 run.py:709] (val) algo activity_selector step 3750: {'selected': 0.9133489461358313, 'score': 0.9133489461358313, 'examples_seen': 180544, 'step': 3750, 'algorithm': 'activity_selector'}
I0703 11:38:51.972369 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0703 11:38:55.362998 133161429332608 run.py:674] Algo activity_selector step 3800 current loss 2.519339, current_train_items 183200.
I0703 11:38:55.646610 133161429332608 run.py:709] (val) algo activity_selector step 3800: {'selected': 0.9276974416017797, 'score': 0.9276974416017797, 'examples_seen': 183200, 'step': 3800, 'algorithm': 'activity_selector'}
I0703 11:38:55.646823 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.928, val scores are: activity_selector: 0.928
I0703 11:38:59.466286 133161429332608 run.py:674] Algo activity_selector step 3850 current loss 0.208158, current_train_items 185632.
I0703 11:38:59.840732 133161429332608 run.py:709] (val) algo activity_selector step 3850: {'selected': 0.870264064293915, 'score': 0.870264064293915, 'examples_seen': 185632, 'step': 3850, 'algorithm': 'activity_selector'}
I0703 11:38:59.841016 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.870, val scores are: activity_selector: 0.870
I0703 11:39:03.479430 133161429332608 run.py:674] Algo activity_selector step 3900 current loss 2.894385, current_train_items 187904.
I0703 11:39:03.888305 133161429332608 run.py:709] (val) algo activity_selector step 3900: {'selected': 0.9396551724137931, 'score': 0.9396551724137931, 'examples_seen': 187904, 'step': 3900, 'algorithm': 'activity_selector'}
I0703 11:39:03.888505 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0703 11:39:07.646044 133161429332608 run.py:674] Algo activity_selector step 3950 current loss 0.377427, current_train_items 190400.
I0703 11:39:07.896957 133161429332608 run.py:709] (val) algo activity_selector step 3950: {'selected': 0.9497607655502394, 'score': 0.9497607655502394, 'examples_seen': 190400, 'step': 3950, 'algorithm': 'activity_selector'}
I0703 11:39:07.897133 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0703 11:39:11.267645 133161429332608 run.py:674] Algo activity_selector step 4000 current loss 4.928075, current_train_items 192640.
I0703 11:39:11.828574 133161429332608 run.py:709] (val) algo activity_selector step 4000: {'selected': 0.9263392857142857, 'score': 0.9263392857142857, 'examples_seen': 192640, 'step': 4000, 'algorithm': 'activity_selector'}
I0703 11:39:11.828852 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0703 11:39:15.598483 133161429332608 run.py:674] Algo activity_selector step 4050 current loss 2.258702, current_train_items 195296.
I0703 11:39:15.860266 133161429332608 run.py:709] (val) algo activity_selector step 4050: {'selected': 0.8512585812356979, 'score': 0.8512585812356979, 'examples_seen': 195296, 'step': 4050, 'algorithm': 'activity_selector'}
I0703 11:39:15.860471 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.851, val scores are: activity_selector: 0.851
I0703 11:39:19.473960 133161429332608 run.py:674] Algo activity_selector step 4100 current loss 4.548212, current_train_items 197472.
I0703 11:39:20.144328 133161429332608 run.py:709] (val) algo activity_selector step 4100: {'selected': 0.9294512877939529, 'score': 0.9294512877939529, 'examples_seen': 197472, 'step': 4100, 'algorithm': 'activity_selector'}
I0703 11:39:20.144613 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0703 11:39:23.575179 133161429332608 run.py:674] Algo activity_selector step 4150 current loss 2.336927, current_train_items 200000.
I0703 11:39:23.866217 133161429332608 run.py:709] (val) algo activity_selector step 4150: {'selected': 0.953125, 'score': 0.953125, 'examples_seen': 200000, 'step': 4150, 'algorithm': 'activity_selector'}
I0703 11:39:23.866429 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0703 11:39:27.811011 133161429332608 run.py:674] Algo activity_selector step 4200 current loss 0.325891, current_train_items 202368.
I0703 11:39:28.192282 133161429332608 run.py:709] (val) algo activity_selector step 4200: {'selected': 0.9687861271676301, 'score': 0.9687861271676301, 'examples_seen': 202368, 'step': 4200, 'algorithm': 'activity_selector'}
I0703 11:39:28.192487 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0703 11:39:31.576818 133161429332608 run.py:674] Algo activity_selector step 4250 current loss 6.132875, current_train_items 204768.
I0703 11:39:31.996275 133161429332608 run.py:709] (val) algo activity_selector step 4250: {'selected': 0.9692671394799054, 'score': 0.9692671394799054, 'examples_seen': 204768, 'step': 4250, 'algorithm': 'activity_selector'}
I0703 11:39:31.996551 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0703 11:39:35.776391 133161429332608 run.py:674] Algo activity_selector step 4300 current loss 0.370859, current_train_items 207328.
I0703 11:39:36.028698 133161429332608 run.py:709] (val) algo activity_selector step 4300: {'selected': 0.9545957918050941, 'score': 0.9545957918050941, 'examples_seen': 207328, 'step': 4300, 'algorithm': 'activity_selector'}
I0703 11:39:36.028945 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.976, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0703 11:39:39.649428 133161429332608 run.py:674] Algo activity_selector step 4350 current loss 1.888569, current_train_items 209568.
I0703 11:39:40.210247 133161429332608 run.py:709] (val) algo activity_selector step 4350: {'selected': 0.9818594104308389, 'score': 0.9818594104308389, 'examples_seen': 209568, 'step': 4350, 'algorithm': 'activity_selector'}
I0703 11:39:40.210463 133161429332608 run.py:730] Checkpointing best model, best avg val score was 0.976, current avg val score is 0.982, val scores are: activity_selector: 0.982
I0703 11:39:43.802263 133161429332608 run.py:674] Algo activity_selector step 4400 current loss 0.615881, current_train_items 212160.
I0703 11:39:44.064358 133161429332608 run.py:709] (val) algo activity_selector step 4400: {'selected': 0.9290322580645162, 'score': 0.9290322580645162, 'examples_seen': 212160, 'step': 4400, 'algorithm': 'activity_selector'}
I0703 11:39:44.064645 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0703 11:39:47.636963 133161429332608 run.py:674] Algo activity_selector step 4450 current loss 7.769806, current_train_items 214240.
I0703 11:39:48.310286 133161429332608 run.py:709] (val) algo activity_selector step 4450: {'selected': 0.9754385964912281, 'score': 0.9754385964912281, 'examples_seen': 214240, 'step': 4450, 'algorithm': 'activity_selector'}
I0703 11:39:48.310518 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0703 11:39:52.028663 133161429332608 run.py:674] Algo activity_selector step 4500 current loss 2.753774, current_train_items 216832.
I0703 11:39:52.319898 133161429332608 run.py:709] (val) algo activity_selector step 4500: {'selected': 0.9562289562289563, 'score': 0.9562289562289563, 'examples_seen': 216832, 'step': 4500, 'algorithm': 'activity_selector'}
I0703 11:39:52.320130 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0703 11:39:56.153361 133161429332608 run.py:674] Algo activity_selector step 4550 current loss 0.317664, current_train_items 219264.
I0703 11:39:56.531906 133161429332608 run.py:709] (val) algo activity_selector step 4550: {'selected': 0.9613259668508287, 'score': 0.9613259668508287, 'examples_seen': 219264, 'step': 4550, 'algorithm': 'activity_selector'}
I0703 11:39:56.532142 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0703 11:39:59.873170 133161429332608 run.py:674] Algo activity_selector step 4600 current loss 4.246181, current_train_items 221696.
I0703 11:40:00.296698 133161429332608 run.py:709] (val) algo activity_selector step 4600: {'selected': 0.9602649006622516, 'score': 0.9602649006622516, 'examples_seen': 221696, 'step': 4600, 'algorithm': 'activity_selector'}
I0703 11:40:00.296954 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0703 11:40:04.207036 133161429332608 run.py:674] Algo activity_selector step 4650 current loss 0.414345, current_train_items 224160.
I0703 11:40:04.455492 133161429332608 run.py:709] (val) algo activity_selector step 4650: {'selected': 0.9299221357063404, 'score': 0.9299221357063404, 'examples_seen': 224160, 'step': 4650, 'algorithm': 'activity_selector'}
I0703 11:40:04.455742 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0703 11:40:07.840350 133161429332608 run.py:674] Algo activity_selector step 4700 current loss 4.803628, current_train_items 226336.
I0703 11:40:08.399151 133161429332608 run.py:709] (val) algo activity_selector step 4700: {'selected': 0.9496855345911951, 'score': 0.9496855345911951, 'examples_seen': 226336, 'step': 4700, 'algorithm': 'activity_selector'}
I0703 11:40:08.399382 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0703 11:40:11.939349 133161429332608 run.py:674] Algo activity_selector step 4750 current loss 1.896483, current_train_items 228960.
I0703 11:40:12.205113 133161429332608 run.py:709] (val) algo activity_selector step 4750: {'selected': 0.9252013808975834, 'score': 0.9252013808975834, 'examples_seen': 228960, 'step': 4750, 'algorithm': 'activity_selector'}
I0703 11:40:12.205338 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0703 11:40:15.962042 133161429332608 run.py:674] Algo activity_selector step 4800 current loss 4.703803, current_train_items 231104.
I0703 11:40:16.625536 133161429332608 run.py:709] (val) algo activity_selector step 4800: {'selected': 0.9459459459459458, 'score': 0.9459459459459458, 'examples_seen': 231104, 'step': 4800, 'algorithm': 'activity_selector'}
I0703 11:40:16.625766 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0703 11:40:19.993540 133161429332608 run.py:674] Algo activity_selector step 4850 current loss 2.364140, current_train_items 233760.
I0703 11:40:20.282307 133161429332608 run.py:709] (val) algo activity_selector step 4850: {'selected': 0.9649717514124293, 'score': 0.9649717514124293, 'examples_seen': 233760, 'step': 4850, 'algorithm': 'activity_selector'}
I0703 11:40:20.282536 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0703 11:40:24.088362 133161429332608 run.py:674] Algo activity_selector step 4900 current loss 0.151535, current_train_items 236160.
I0703 11:40:24.473411 133161429332608 run.py:709] (val) algo activity_selector step 4900: {'selected': 0.975501113585746, 'score': 0.975501113585746, 'examples_seen': 236160, 'step': 4900, 'algorithm': 'activity_selector'}
I0703 11:40:24.473652 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0703 11:40:28.075326 133161429332608 run.py:674] Algo activity_selector step 4950 current loss 2.651532, current_train_items 238464.
I0703 11:40:28.475563 133161429332608 run.py:709] (val) algo activity_selector step 4950: {'selected': 0.9637426900584796, 'score': 0.9637426900584796, 'examples_seen': 238464, 'step': 4950, 'algorithm': 'activity_selector'}
I0703 11:40:28.475751 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0703 11:40:32.249456 133161429332608 run.py:674] Algo activity_selector step 5000 current loss 0.263662, current_train_items 240992.
I0703 11:40:32.498298 133161429332608 run.py:709] (val) algo activity_selector step 5000: {'selected': 0.9209932279909707, 'score': 0.9209932279909707, 'examples_seen': 240992, 'step': 5000, 'algorithm': 'activity_selector'}
I0703 11:40:32.498494 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0703 11:40:35.927928 133161429332608 run.py:674] Algo activity_selector step 5050 current loss 0.954565, current_train_items 243200.
I0703 11:40:36.485432 133161429332608 run.py:709] (val) algo activity_selector step 5050: {'selected': 0.9621993127147767, 'score': 0.9621993127147767, 'examples_seen': 243200, 'step': 5050, 'algorithm': 'activity_selector'}
I0703 11:40:36.485668 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0703 11:40:40.261798 133161429332608 run.py:674] Algo activity_selector step 5100 current loss 3.153213, current_train_items 245856.
I0703 11:40:40.524106 133161429332608 run.py:709] (val) algo activity_selector step 5100: {'selected': 0.966740576496674, 'score': 0.966740576496674, 'examples_seen': 245856, 'step': 5100, 'algorithm': 'activity_selector'}
I0703 11:40:40.524324 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0703 11:40:44.080845 133161429332608 run.py:674] Algo activity_selector step 5150 current loss 6.870516, current_train_items 248000.
I0703 11:40:44.750275 133161429332608 run.py:709] (val) algo activity_selector step 5150: {'selected': 0.8906077348066298, 'score': 0.8906077348066298, 'examples_seen': 248000, 'step': 5150, 'algorithm': 'activity_selector'}
I0703 11:40:44.750514 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.891, val scores are: activity_selector: 0.891
I0703 11:40:48.251005 133161429332608 run.py:674] Algo activity_selector step 5200 current loss 2.320523, current_train_items 250560.
I0703 11:40:48.542072 133161429332608 run.py:709] (val) algo activity_selector step 5200: {'selected': 0.9413092550790069, 'score': 0.9413092550790069, 'examples_seen': 250560, 'step': 5200, 'algorithm': 'activity_selector'}
I0703 11:40:48.542262 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0703 11:40:52.542849 133161429332608 run.py:674] Algo activity_selector step 5250 current loss 0.168258, current_train_items 252960.
I0703 11:40:52.925429 133161429332608 run.py:709] (val) algo activity_selector step 5250: {'selected': 0.9308755760368663, 'score': 0.9308755760368663, 'examples_seen': 252960, 'step': 5250, 'algorithm': 'activity_selector'}
I0703 11:40:52.925694 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0703 11:40:56.403684 133161429332608 run.py:674] Algo activity_selector step 5300 current loss 5.204127, current_train_items 255296.
I0703 11:40:56.825361 133161429332608 run.py:709] (val) algo activity_selector step 5300: {'selected': 0.9312977099236641, 'score': 0.9312977099236641, 'examples_seen': 255296, 'step': 5300, 'algorithm': 'activity_selector'}
I0703 11:40:56.825547 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0703 11:41:00.617412 133161429332608 run.py:674] Algo activity_selector step 5350 current loss 0.262128, current_train_items 257856.
I0703 11:41:00.872014 133161429332608 run.py:709] (val) algo activity_selector step 5350: {'selected': 0.9740698985343856, 'score': 0.9740698985343856, 'examples_seen': 257856, 'step': 5350, 'algorithm': 'activity_selector'}
I0703 11:41:00.872225 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0703 11:41:04.435754 133161429332608 run.py:674] Algo activity_selector step 5400 current loss 4.785265, current_train_items 260128.
I0703 11:41:04.992259 133161429332608 run.py:709] (val) algo activity_selector step 5400: {'selected': 0.9495412844036697, 'score': 0.9495412844036697, 'examples_seen': 260128, 'step': 5400, 'algorithm': 'activity_selector'}
I0703 11:41:04.992456 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0703 11:41:08.568108 133161429332608 run.py:674] Algo activity_selector step 5450 current loss 1.705006, current_train_items 262688.
I0703 11:41:08.830520 133161429332608 run.py:709] (val) algo activity_selector step 5450: {'selected': 0.9479392624728851, 'score': 0.9479392624728851, 'examples_seen': 262688, 'step': 5450, 'algorithm': 'activity_selector'}
I0703 11:41:08.830732 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0703 11:41:12.380858 133161429332608 run.py:674] Algo activity_selector step 5500 current loss 4.620319, current_train_items 264832.
I0703 11:41:13.049959 133161429332608 run.py:709] (val) algo activity_selector step 5500: {'selected': 0.9372937293729373, 'score': 0.9372937293729373, 'examples_seen': 264832, 'step': 5500, 'algorithm': 'activity_selector'}
I0703 11:41:13.050171 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0703 11:41:16.619244 133161429332608 run.py:674] Algo activity_selector step 5550 current loss 2.488775, current_train_items 267360.
I0703 11:41:16.911627 133161429332608 run.py:709] (val) algo activity_selector step 5550: {'selected': 0.9365962180200224, 'score': 0.9365962180200224, 'examples_seen': 267360, 'step': 5550, 'algorithm': 'activity_selector'}
I0703 11:41:16.911847 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0703 11:41:20.699783 133161429332608 run.py:674] Algo activity_selector step 5600 current loss 0.300905, current_train_items 269792.
I0703 11:41:21.080915 133161429332608 run.py:709] (val) algo activity_selector step 5600: {'selected': 0.9758241758241758, 'score': 0.9758241758241758, 'examples_seen': 269792, 'step': 5600, 'algorithm': 'activity_selector'}
I0703 11:41:21.081101 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0703 11:41:24.402122 133161429332608 run.py:674] Algo activity_selector step 5650 current loss 4.205070, current_train_items 272256.
I0703 11:41:24.822742 133161429332608 run.py:709] (val) algo activity_selector step 5650: {'selected': 0.9771167048054921, 'score': 0.9771167048054921, 'examples_seen': 272256, 'step': 5650, 'algorithm': 'activity_selector'}
I0703 11:41:24.823016 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0703 11:41:28.899983 133161429332608 run.py:674] Algo activity_selector step 5700 current loss 0.450052, current_train_items 274720.
I0703 11:41:29.149768 133161429332608 run.py:709] (val) algo activity_selector step 5700: {'selected': 0.9392523364485982, 'score': 0.9392523364485982, 'examples_seen': 274720, 'step': 5700, 'algorithm': 'activity_selector'}
I0703 11:41:29.150018 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0703 11:41:32.502286 133161429332608 run.py:674] Algo activity_selector step 5750 current loss 8.196752, current_train_items 276896.
I0703 11:41:33.063369 133161429332608 run.py:709] (val) algo activity_selector step 5750: {'selected': 0.9316628701594533, 'score': 0.9316628701594533, 'examples_seen': 276896, 'step': 5750, 'algorithm': 'activity_selector'}
I0703 11:41:33.063582 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0703 11:41:36.591902 133161429332608 run.py:674] Algo activity_selector step 5800 current loss 2.458919, current_train_items 279488.
I0703 11:41:36.853943 133161429332608 run.py:709] (val) algo activity_selector step 5800: {'selected': 0.9571263035921205, 'score': 0.9571263035921205, 'examples_seen': 279488, 'step': 5800, 'algorithm': 'activity_selector'}
I0703 11:41:36.854163 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0703 11:41:40.693852 133161429332608 run.py:674] Algo activity_selector step 5850 current loss 6.656636, current_train_items 281632.
I0703 11:41:41.378840 133161429332608 run.py:709] (val) algo activity_selector step 5850: {'selected': 0.9740566037735848, 'score': 0.9740566037735848, 'examples_seen': 281632, 'step': 5850, 'algorithm': 'activity_selector'}
I0703 11:41:41.379040 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0703 11:41:44.767282 133161429332608 run.py:674] Algo activity_selector step 5900 current loss 2.797891, current_train_items 284320.
I0703 11:41:45.076009 133161429332608 run.py:709] (val) algo activity_selector step 5900: {'selected': 0.914826498422713, 'score': 0.914826498422713, 'examples_seen': 284320, 'step': 5900, 'algorithm': 'activity_selector'}
I0703 11:41:45.076223 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0703 11:41:48.844635 133161429332608 run.py:674] Algo activity_selector step 5950 current loss 0.275404, current_train_items 286720.
I0703 11:41:49.223208 133161429332608 run.py:709] (val) algo activity_selector step 5950: {'selected': 0.8613138686131386, 'score': 0.8613138686131386, 'examples_seen': 286720, 'step': 5950, 'algorithm': 'activity_selector'}
I0703 11:41:49.223415 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.861, val scores are: activity_selector: 0.861
I0703 11:41:52.752606 133161429332608 run.py:674] Algo activity_selector step 6000 current loss 2.808069, current_train_items 289024.
I0703 11:41:53.159234 133161429332608 run.py:709] (val) algo activity_selector step 6000: {'selected': 0.9139072847682119, 'score': 0.9139072847682119, 'examples_seen': 289024, 'step': 6000, 'algorithm': 'activity_selector'}
I0703 11:41:53.159425 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0703 11:41:56.885534 133161429332608 run.py:674] Algo activity_selector step 6050 current loss 0.283940, current_train_items 291488.
I0703 11:41:57.137227 133161429332608 run.py:709] (val) algo activity_selector step 6050: {'selected': 0.9605411499436303, 'score': 0.9605411499436303, 'examples_seen': 291488, 'step': 6050, 'algorithm': 'activity_selector'}
I0703 11:41:57.137415 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0703 11:42:00.501096 133161429332608 run.py:674] Algo activity_selector step 6100 current loss 4.422223, current_train_items 293792.
I0703 11:42:01.058708 133161429332608 run.py:709] (val) algo activity_selector step 6100: {'selected': 0.9783845278725826, 'score': 0.9783845278725826, 'examples_seen': 293792, 'step': 6100, 'algorithm': 'activity_selector'}
I0703 11:42:01.058948 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.978, val scores are: activity_selector: 0.978
I0703 11:42:04.796070 133161429332608 run.py:674] Algo activity_selector step 6150 current loss 1.683341, current_train_items 296448.
I0703 11:42:05.057569 133161429332608 run.py:709] (val) algo activity_selector step 6150: {'selected': 0.8628272251308902, 'score': 0.8628272251308902, 'examples_seen': 296448, 'step': 6150, 'algorithm': 'activity_selector'}
I0703 11:42:05.057750 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.863, val scores are: activity_selector: 0.863
I0703 11:42:08.627490 133161429332608 run.py:674] Algo activity_selector step 6200 current loss 4.738951, current_train_items 298560.
I0703 11:42:09.316393 133161429332608 run.py:709] (val) algo activity_selector step 6200: {'selected': 0.9811320754716982, 'score': 0.9811320754716982, 'examples_seen': 298560, 'step': 6200, 'algorithm': 'activity_selector'}
I0703 11:42:09.316588 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0703 11:42:12.753928 133161429332608 run.py:674] Algo activity_selector step 6250 current loss 2.233858, current_train_items 301152.
I0703 11:42:13.043546 133161429332608 run.py:709] (val) algo activity_selector step 6250: {'selected': 0.9652076318742985, 'score': 0.9652076318742985, 'examples_seen': 301152, 'step': 6250, 'algorithm': 'activity_selector'}
I0703 11:42:13.043752 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0703 11:42:17.031345 133161429332608 run.py:674] Algo activity_selector step 6300 current loss 0.126320, current_train_items 303456.
I0703 11:42:17.405865 133161429332608 run.py:709] (val) algo activity_selector step 6300: {'selected': 0.9523809523809524, 'score': 0.9523809523809524, 'examples_seen': 303456, 'step': 6300, 'algorithm': 'activity_selector'}
I0703 11:42:17.406054 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0703 11:42:20.746331 133161429332608 run.py:674] Algo activity_selector step 6350 current loss 6.754319, current_train_items 305888.
I0703 11:42:21.167699 133161429332608 run.py:709] (val) algo activity_selector step 6350: {'selected': 0.955631399317406, 'score': 0.955631399317406, 'examples_seen': 305888, 'step': 6350, 'algorithm': 'activity_selector'}
I0703 11:42:21.167954 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0703 11:42:24.937411 133161429332608 run.py:674] Algo activity_selector step 6400 current loss 0.423161, current_train_items 308448.
I0703 11:42:25.187992 133161429332608 run.py:709] (val) algo activity_selector step 6400: {'selected': 0.9089026915113871, 'score': 0.9089026915113871, 'examples_seen': 308448, 'step': 6400, 'algorithm': 'activity_selector'}
I0703 11:42:25.188218 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0703 11:42:28.704113 133161429332608 run.py:674] Algo activity_selector step 6450 current loss 6.741252, current_train_items 310688.
I0703 11:42:29.263618 133161429332608 run.py:709] (val) algo activity_selector step 6450: {'selected': 0.9322617680826636, 'score': 0.9322617680826636, 'examples_seen': 310688, 'step': 6450, 'algorithm': 'activity_selector'}
I0703 11:42:29.263841 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0703 11:42:32.805421 133161429332608 run.py:674] Algo activity_selector step 6500 current loss 1.927024, current_train_items 313248.
I0703 11:42:33.066164 133161429332608 run.py:709] (val) algo activity_selector step 6500: {'selected': 0.9306029579067122, 'score': 0.9306029579067122, 'examples_seen': 313248, 'step': 6500, 'algorithm': 'activity_selector'}
I0703 11:42:33.066365 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0703 11:42:36.643358 133161429332608 run.py:674] Algo activity_selector step 6550 current loss 5.725995, current_train_items 315360.
I0703 11:42:37.316009 133161429332608 run.py:709] (val) algo activity_selector step 6550: {'selected': 0.9732739420935412, 'score': 0.9732739420935412, 'examples_seen': 315360, 'step': 6550, 'algorithm': 'activity_selector'}
I0703 11:42:37.316210 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0703 11:42:40.942425 133161429332608 run.py:674] Algo activity_selector step 6600 current loss 2.461136, current_train_items 317920.
I0703 11:42:41.231377 133161429332608 run.py:709] (val) algo activity_selector step 6600: {'selected': 0.9569160997732427, 'score': 0.9569160997732427, 'examples_seen': 317920, 'step': 6600, 'algorithm': 'activity_selector'}
I0703 11:42:41.231574 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0703 11:42:44.981922 133161429332608 run.py:674] Algo activity_selector step 6650 current loss 0.173115, current_train_items 320416.
I0703 11:42:45.361897 133161429332608 run.py:709] (val) algo activity_selector step 6650: {'selected': 0.9555302166476625, 'score': 0.9555302166476625, 'examples_seen': 320416, 'step': 6650, 'algorithm': 'activity_selector'}
I0703 11:42:45.362077 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0703 11:42:48.731935 133161429332608 run.py:674] Algo activity_selector step 6700 current loss 4.475368, current_train_items 322784.
I0703 11:42:49.150231 133161429332608 run.py:709] (val) algo activity_selector step 6700: {'selected': 0.9667049368541907, 'score': 0.9667049368541907, 'examples_seen': 322784, 'step': 6700, 'algorithm': 'activity_selector'}
I0703 11:42:49.150426 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0703 11:42:53.121756 133161429332608 run.py:674] Algo activity_selector step 6750 current loss 0.257919, current_train_items 325312.
I0703 11:42:53.372519 133161429332608 run.py:709] (val) algo activity_selector step 6750: {'selected': 0.9356321839080459, 'score': 0.9356321839080459, 'examples_seen': 325312, 'step': 6750, 'algorithm': 'activity_selector'}
I0703 11:42:53.372753 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.982, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0703 11:42:56.732308 133161429332608 run.py:674] Algo activity_selector step 6800 current loss 4.435302, current_train_items 327456.
I0703 11:42:57.294789 133161429332608 run.py:709] (val) algo activity_selector step 6800: {'selected': 0.9860465116279069, 'score': 0.9860465116279069, 'examples_seen': 327456, 'step': 6800, 'algorithm': 'activity_selector'}
I0703 11:42:57.295065 133161429332608 run.py:730] Checkpointing best model, best avg val score was 0.982, current avg val score is 0.986, val scores are: activity_selector: 0.986
I0703 11:43:00.864587 133161429332608 run.py:674] Algo activity_selector step 6850 current loss 0.470945, current_train_items 330080.
I0703 11:43:01.125734 133161429332608 run.py:709] (val) algo activity_selector step 6850: {'selected': 0.9733487833140209, 'score': 0.9733487833140209, 'examples_seen': 330080, 'step': 6850, 'algorithm': 'activity_selector'}
I0703 11:43:01.125990 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0703 11:43:04.898640 133161429332608 run.py:674] Algo activity_selector step 6900 current loss 3.477497, current_train_items 332256.
I0703 11:43:05.573453 133161429332608 run.py:709] (val) algo activity_selector step 6900: {'selected': 0.9720044792833147, 'score': 0.9720044792833147, 'examples_seen': 332256, 'step': 6900, 'algorithm': 'activity_selector'}
I0703 11:43:05.573664 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0703 11:43:08.952918 133161429332608 run.py:674] Algo activity_selector step 6950 current loss 2.319508, current_train_items 334880.
I0703 11:43:09.244375 133161429332608 run.py:709] (val) algo activity_selector step 6950: {'selected': 0.9776286353467561, 'score': 0.9776286353467561, 'examples_seen': 334880, 'step': 6950, 'algorithm': 'activity_selector'}
I0703 11:43:09.244593 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.978, val scores are: activity_selector: 0.978
I0703 11:43:12.997581 133161429332608 run.py:674] Algo activity_selector step 7000 current loss 0.197529, current_train_items 337248.
I0703 11:43:13.372164 133161429332608 run.py:709] (val) algo activity_selector step 7000: {'selected': 0.9451575262543758, 'score': 0.9451575262543758, 'examples_seen': 337248, 'step': 7000, 'algorithm': 'activity_selector'}
I0703 11:43:13.372361 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0703 11:43:16.978605 133161429332608 run.py:674] Algo activity_selector step 7050 current loss 2.416014, current_train_items 339616.
I0703 11:43:17.389601 133161429332608 run.py:709] (val) algo activity_selector step 7050: {'selected': 0.9742990654205608, 'score': 0.9742990654205608, 'examples_seen': 339616, 'step': 7050, 'algorithm': 'activity_selector'}
I0703 11:43:17.389796 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0703 11:43:21.161339 133161429332608 run.py:674] Algo activity_selector step 7100 current loss 0.186022, current_train_items 342080.
I0703 11:43:21.410783 133161429332608 run.py:709] (val) algo activity_selector step 7100: {'selected': 0.9638273045507585, 'score': 0.9638273045507585, 'examples_seen': 342080, 'step': 7100, 'algorithm': 'activity_selector'}
I0703 11:43:21.411088 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0703 11:43:24.792459 133161429332608 run.py:674] Algo activity_selector step 7150 current loss 6.247417, current_train_items 344352.
I0703 11:43:25.353140 133161429332608 run.py:709] (val) algo activity_selector step 7150: {'selected': 0.9467592592592593, 'score': 0.9467592592592593, 'examples_seen': 344352, 'step': 7150, 'algorithm': 'activity_selector'}
I0703 11:43:25.353338 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0703 11:43:29.124572 133161429332608 run.py:674] Algo activity_selector step 7200 current loss 1.589504, current_train_items 346944.
I0703 11:43:29.386129 133161429332608 run.py:709] (val) algo activity_selector step 7200: {'selected': 0.9830890642615558, 'score': 0.9830890642615558, 'examples_seen': 346944, 'step': 7200, 'algorithm': 'activity_selector'}
I0703 11:43:29.386327 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.983, val scores are: activity_selector: 0.983
I0703 11:43:32.954332 133161429332608 run.py:674] Algo activity_selector step 7250 current loss 5.692430, current_train_items 349120.
I0703 11:43:33.621953 133161429332608 run.py:709] (val) algo activity_selector step 7250: {'selected': 0.9657615112160566, 'score': 0.9657615112160566, 'examples_seen': 349120, 'step': 7250, 'algorithm': 'activity_selector'}
I0703 11:43:33.622148 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0703 11:43:37.024258 133161429332608 run.py:674] Algo activity_selector step 7300 current loss 2.462385, current_train_items 351648.
I0703 11:43:37.317270 133161429332608 run.py:709] (val) algo activity_selector step 7300: {'selected': 0.9841628959276019, 'score': 0.9841628959276019, 'examples_seen': 351648, 'step': 7300, 'algorithm': 'activity_selector'}
I0703 11:43:37.317538 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.984, val scores are: activity_selector: 0.984
I0703 11:43:41.325611 133161429332608 run.py:674] Algo activity_selector step 7350 current loss 0.217699, current_train_items 354080.
I0703 11:43:41.723588 133161429332608 run.py:709] (val) algo activity_selector step 7350: {'selected': 0.9647577092511013, 'score': 0.9647577092511013, 'examples_seen': 354080, 'step': 7350, 'algorithm': 'activity_selector'}
I0703 11:43:41.723779 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0703 11:43:45.030225 133161429332608 run.py:674] Algo activity_selector step 7400 current loss 5.323527, current_train_items 356416.
I0703 11:43:45.449678 133161429332608 run.py:709] (val) algo activity_selector step 7400: {'selected': 0.9516129032258065, 'score': 0.9516129032258065, 'examples_seen': 356416, 'step': 7400, 'algorithm': 'activity_selector'}
I0703 11:43:45.449901 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0703 11:43:49.202889 133161429332608 run.py:674] Algo activity_selector step 7450 current loss 0.298535, current_train_items 359008.
I0703 11:43:49.450408 133161429332608 run.py:709] (val) algo activity_selector step 7450: {'selected': 0.9452380952380952, 'score': 0.9452380952380952, 'examples_seen': 359008, 'step': 7450, 'algorithm': 'activity_selector'}
I0703 11:43:49.450605 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0703 11:43:52.957707 133161429332608 run.py:674] Algo activity_selector step 7500 current loss 3.893593, current_train_items 361248.
I0703 11:43:53.516755 133161429332608 run.py:709] (val) algo activity_selector step 7500: {'selected': 0.9747126436781609, 'score': 0.9747126436781609, 'examples_seen': 361248, 'step': 7500, 'algorithm': 'activity_selector'}
I0703 11:43:53.517008 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0703 11:43:57.127268 133161429332608 run.py:674] Algo activity_selector step 7550 current loss 3.176204, current_train_items 363840.
I0703 11:43:57.386602 133161429332608 run.py:709] (val) algo activity_selector step 7550: {'selected': 0.9641255605381166, 'score': 0.9641255605381166, 'examples_seen': 363840, 'step': 7550, 'algorithm': 'activity_selector'}
I0703 11:43:57.386781 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0703 11:44:00.934117 133161429332608 run.py:674] Algo activity_selector step 7600 current loss 2.801297, current_train_items 365952.
I0703 11:44:01.603305 133161429332608 run.py:709] (val) algo activity_selector step 7600: {'selected': 0.9602803738317757, 'score': 0.9602803738317757, 'examples_seen': 365952, 'step': 7600, 'algorithm': 'activity_selector'}
I0703 11:44:01.603606 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0703 11:44:05.272717 133161429332608 run.py:674] Algo activity_selector step 7650 current loss 2.649732, current_train_items 368512.
I0703 11:44:05.569855 133161429332608 run.py:709] (val) algo activity_selector step 7650: {'selected': 0.9766355140186914, 'score': 0.9766355140186914, 'examples_seen': 368512, 'step': 7650, 'algorithm': 'activity_selector'}
I0703 11:44:05.570078 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0703 11:44:09.358259 133161429332608 run.py:674] Algo activity_selector step 7700 current loss 0.181514, current_train_items 370912.
I0703 11:44:09.734586 133161429332608 run.py:709] (val) algo activity_selector step 7700: {'selected': 0.9706916764361079, 'score': 0.9706916764361079, 'examples_seen': 370912, 'step': 7700, 'algorithm': 'activity_selector'}
I0703 11:44:09.734773 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0703 11:44:13.025404 133161429332608 run.py:674] Algo activity_selector step 7750 current loss 4.178999, current_train_items 373408.
I0703 11:44:13.447946 133161429332608 run.py:709] (val) algo activity_selector step 7750: {'selected': 0.9776286353467561, 'score': 0.9776286353467561, 'examples_seen': 373408, 'step': 7750, 'algorithm': 'activity_selector'}
I0703 11:44:13.448223 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.978, val scores are: activity_selector: 0.978
I0703 11:44:17.394212 133161429332608 run.py:674] Algo activity_selector step 7800 current loss 0.334265, current_train_items 375840.
I0703 11:44:17.642591 133161429332608 run.py:709] (val) algo activity_selector step 7800: {'selected': 0.9704545454545453, 'score': 0.9704545454545453, 'examples_seen': 375840, 'step': 7800, 'algorithm': 'activity_selector'}
I0703 11:44:17.642839 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0703 11:44:21.001898 133161429332608 run.py:674] Algo activity_selector step 7850 current loss 5.884091, current_train_items 378016.
I0703 11:44:21.564791 133161429332608 run.py:709] (val) algo activity_selector step 7850: {'selected': 0.9490790899241603, 'score': 0.9490790899241603, 'examples_seen': 378016, 'step': 7850, 'algorithm': 'activity_selector'}
I0703 11:44:21.565029 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0703 11:44:25.125125 133161429332608 run.py:674] Algo activity_selector step 7900 current loss 1.574878, current_train_items 380608.
I0703 11:44:25.386167 133161429332608 run.py:709] (val) algo activity_selector step 7900: {'selected': 0.9524913093858632, 'score': 0.9524913093858632, 'examples_seen': 380608, 'step': 7900, 'algorithm': 'activity_selector'}
I0703 11:44:25.386361 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0703 11:44:29.035664 133161429332608 run.py:674] Algo activity_selector step 7950 current loss 5.360312, current_train_items 382752.
I0703 11:44:29.702929 133161429332608 run.py:709] (val) algo activity_selector step 7950: {'selected': 0.9584816132858839, 'score': 0.9584816132858839, 'examples_seen': 382752, 'step': 7950, 'algorithm': 'activity_selector'}
I0703 11:44:29.703138 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0703 11:44:33.046699 133161429332608 run.py:674] Algo activity_selector step 8000 current loss 2.342362, current_train_items 385408.
I0703 11:44:33.338958 133161429332608 run.py:709] (val) algo activity_selector step 8000: {'selected': 0.9710312862108923, 'score': 0.9710312862108923, 'examples_seen': 385408, 'step': 8000, 'algorithm': 'activity_selector'}
I0703 11:44:33.339405 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0703 11:44:37.101141 133161429332608 run.py:674] Algo activity_selector step 8050 current loss 0.107737, current_train_items 387872.
I0703 11:44:37.475001 133161429332608 run.py:709] (val) algo activity_selector step 8050: {'selected': 0.9531615925058546, 'score': 0.9531615925058546, 'examples_seen': 387872, 'step': 8050, 'algorithm': 'activity_selector'}
I0703 11:44:37.475242 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0703 11:44:41.073316 133161429332608 run.py:674] Algo activity_selector step 8100 current loss 2.411511, current_train_items 390112.
I0703 11:44:41.489269 133161429332608 run.py:709] (val) algo activity_selector step 8100: {'selected': 0.9738339021615472, 'score': 0.9738339021615472, 'examples_seen': 390112, 'step': 8100, 'algorithm': 'activity_selector'}
I0703 11:44:41.489468 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0703 11:44:45.233560 133161429332608 run.py:674] Algo activity_selector step 8150 current loss 0.199539, current_train_items 392672.
I0703 11:44:45.483708 133161429332608 run.py:709] (val) algo activity_selector step 8150: {'selected': 0.9607182940516273, 'score': 0.9607182940516273, 'examples_seen': 392672, 'step': 8150, 'algorithm': 'activity_selector'}
I0703 11:44:45.483949 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0703 11:44:48.838268 133161429332608 run.py:674] Algo activity_selector step 8200 current loss 3.623386, current_train_items 394880.
I0703 11:44:49.384143 133161429332608 run.py:709] (val) algo activity_selector step 8200: {'selected': 0.9507119386637459, 'score': 0.9507119386637459, 'examples_seen': 394880, 'step': 8200, 'algorithm': 'activity_selector'}
I0703 11:44:49.384404 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0703 11:44:53.362360 133161429332608 run.py:674] Algo activity_selector step 8250 current loss 2.393408, current_train_items 397536.
I0703 11:44:53.622887 133161429332608 run.py:709] (val) algo activity_selector step 8250: {'selected': 0.9502369668246446, 'score': 0.9502369668246446, 'examples_seen': 397536, 'step': 8250, 'algorithm': 'activity_selector'}
I0703 11:44:53.623081 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0703 11:44:57.158468 133161429332608 run.py:674] Algo activity_selector step 8300 current loss 2.791902, current_train_items 399712.
I0703 11:44:57.824528 133161429332608 run.py:709] (val) algo activity_selector step 8300: {'selected': 0.9672131147540984, 'score': 0.9672131147540984, 'examples_seen': 399712, 'step': 8300, 'algorithm': 'activity_selector'}
I0703 11:44:57.824730 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0703 11:45:01.217422 133161429332608 run.py:674] Algo activity_selector step 8350 current loss 2.470735, current_train_items 402240.
I0703 11:45:01.510196 133161429332608 run.py:709] (val) algo activity_selector step 8350: {'selected': 0.9814814814814814, 'score': 0.9814814814814814, 'examples_seen': 402240, 'step': 8350, 'algorithm': 'activity_selector'}
I0703 11:45:01.510408 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0703 11:45:05.425583 133161429332608 run.py:674] Algo activity_selector step 8400 current loss 0.199690, current_train_items 404608.
I0703 11:45:05.802859 133161429332608 run.py:709] (val) algo activity_selector step 8400: {'selected': 0.971764705882353, 'score': 0.971764705882353, 'examples_seen': 404608, 'step': 8400, 'algorithm': 'activity_selector'}
I0703 11:45:05.803050 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0703 11:45:09.123935 133161429332608 run.py:674] Algo activity_selector step 8450 current loss 5.812701, current_train_items 407008.
I0703 11:45:09.548352 133161429332608 run.py:709] (val) algo activity_selector step 8450: {'selected': 0.9603624009060022, 'score': 0.9603624009060022, 'examples_seen': 407008, 'step': 8450, 'algorithm': 'activity_selector'}
I0703 11:45:09.548611 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0703 11:45:13.331090 133161429332608 run.py:674] Algo activity_selector step 8500 current loss 0.187527, current_train_items 409568.
I0703 11:45:13.581650 133161429332608 run.py:709] (val) algo activity_selector step 8500: {'selected': 0.9130434782608696, 'score': 0.9130434782608696, 'examples_seen': 409568, 'step': 8500, 'algorithm': 'activity_selector'}
I0703 11:45:13.581901 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.913, val scores are: activity_selector: 0.913
I0703 11:45:17.156683 133161429332608 run.py:674] Algo activity_selector step 8550 current loss 5.493672, current_train_items 411808.
I0703 11:45:17.714576 133161429332608 run.py:709] (val) algo activity_selector step 8550: {'selected': 0.9649532710280374, 'score': 0.9649532710280374, 'examples_seen': 411808, 'step': 8550, 'algorithm': 'activity_selector'}
I0703 11:45:17.714780 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0703 11:45:21.266458 133161429332608 run.py:674] Algo activity_selector step 8600 current loss 1.345487, current_train_items 414368.
I0703 11:45:21.530598 133161429332608 run.py:709] (val) algo activity_selector step 8600: {'selected': 0.9605568445475637, 'score': 0.9605568445475637, 'examples_seen': 414368, 'step': 8600, 'algorithm': 'activity_selector'}
I0703 11:45:21.530874 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0703 11:45:25.091170 133161429332608 run.py:674] Algo activity_selector step 8650 current loss 4.873155, current_train_items 416480.
I0703 11:45:25.766251 133161429332608 run.py:709] (val) algo activity_selector step 8650: {'selected': 0.9515011547344111, 'score': 0.9515011547344111, 'examples_seen': 416480, 'step': 8650, 'algorithm': 'activity_selector'}
I0703 11:45:25.766464 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0703 11:45:29.356621 133161429332608 run.py:674] Algo activity_selector step 8700 current loss 2.271476, current_train_items 419040.
I0703 11:45:29.646320 133161429332608 run.py:709] (val) algo activity_selector step 8700: {'selected': 0.9724137931034482, 'score': 0.9724137931034482, 'examples_seen': 419040, 'step': 8700, 'algorithm': 'activity_selector'}
I0703 11:45:29.646520 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0703 11:45:33.474256 133161429332608 run.py:674] Algo activity_selector step 8750 current loss 0.093443, current_train_items 421504.
I0703 11:45:33.864275 133161429332608 run.py:709] (val) algo activity_selector step 8750: {'selected': 0.9695550351288057, 'score': 0.9695550351288057, 'examples_seen': 421504, 'step': 8750, 'algorithm': 'activity_selector'}
I0703 11:45:33.864488 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0703 11:45:37.163414 133161429332608 run.py:674] Algo activity_selector step 8800 current loss 4.238493, current_train_items 423936.
I0703 11:45:37.582253 133161429332608 run.py:709] (val) algo activity_selector step 8800: {'selected': 0.9303867403314917, 'score': 0.9303867403314917, 'examples_seen': 423936, 'step': 8800, 'algorithm': 'activity_selector'}
I0703 11:45:37.582459 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0703 11:45:41.508189 133161429332608 run.py:674] Algo activity_selector step 8850 current loss 0.274316, current_train_items 426400.
I0703 11:45:41.755993 133161429332608 run.py:709] (val) algo activity_selector step 8850: {'selected': 0.9467723669309173, 'score': 0.9467723669309173, 'examples_seen': 426400, 'step': 8850, 'algorithm': 'activity_selector'}
I0703 11:45:41.756180 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0703 11:45:45.131549 133161429332608 run.py:674] Algo activity_selector step 8900 current loss 3.154702, current_train_items 428608.
I0703 11:45:45.690084 133161429332608 run.py:709] (val) algo activity_selector step 8900: {'selected': 0.9790518191841234, 'score': 0.9790518191841234, 'examples_seen': 428608, 'step': 8900, 'algorithm': 'activity_selector'}
I0703 11:45:45.690353 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.979, val scores are: activity_selector: 0.979
I0703 11:45:49.244705 133161429332608 run.py:674] Algo activity_selector step 8950 current loss 2.093041, current_train_items 431168.
I0703 11:45:49.506269 133161429332608 run.py:709] (val) algo activity_selector step 8950: {'selected': 0.9472502805836138, 'score': 0.9472502805836138, 'examples_seen': 431168, 'step': 8950, 'algorithm': 'activity_selector'}
I0703 11:45:49.506470 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0703 11:45:53.206719 133161429332608 run.py:674] Algo activity_selector step 9000 current loss 1.581137, current_train_items 433376.
I0703 11:45:53.877861 133161429332608 run.py:709] (val) algo activity_selector step 9000: {'selected': 0.9390919158361019, 'score': 0.9390919158361019, 'examples_seen': 433376, 'step': 9000, 'algorithm': 'activity_selector'}
I0703 11:45:53.878058 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0703 11:45:57.238089 133161429332608 run.py:674] Algo activity_selector step 9050 current loss 2.599355, current_train_items 436000.
I0703 11:45:57.550022 133161429332608 run.py:709] (val) algo activity_selector step 9050: {'selected': 0.9424307036247336, 'score': 0.9424307036247336, 'examples_seen': 436000, 'step': 9050, 'algorithm': 'activity_selector'}
I0703 11:45:57.550273 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0703 11:46:01.355414 133161429332608 run.py:674] Algo activity_selector step 9100 current loss 0.133801, current_train_items 438432.
I0703 11:46:01.733633 133161429332608 run.py:709] (val) algo activity_selector step 9100: {'selected': 0.9593301435406698, 'score': 0.9593301435406698, 'examples_seen': 438432, 'step': 9100, 'algorithm': 'activity_selector'}
I0703 11:46:01.733904 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0703 11:46:05.273330 133161429332608 run.py:674] Algo activity_selector step 9150 current loss 2.716699, current_train_items 440736.
I0703 11:46:05.684289 133161429332608 run.py:709] (val) algo activity_selector step 9150: {'selected': 0.9796380090497738, 'score': 0.9796380090497738, 'examples_seen': 440736, 'step': 9150, 'algorithm': 'activity_selector'}
I0703 11:46:05.684490 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.980, val scores are: activity_selector: 0.980
I0703 11:46:09.422119 133161429332608 run.py:674] Algo activity_selector step 9200 current loss 0.208580, current_train_items 443232.
I0703 11:46:09.674257 133161429332608 run.py:709] (val) algo activity_selector step 9200: {'selected': 0.9774078478002378, 'score': 0.9774078478002378, 'examples_seen': 443232, 'step': 9200, 'algorithm': 'activity_selector'}
I0703 11:46:09.674508 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.986, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0703 11:46:13.044287 133161429332608 run.py:674] Algo activity_selector step 9250 current loss 5.023771, current_train_items 445440.
I0703 11:46:13.602415 133161429332608 run.py:709] (val) algo activity_selector step 9250: {'selected': 0.9882629107981221, 'score': 0.9882629107981221, 'examples_seen': 445440, 'step': 9250, 'algorithm': 'activity_selector'}
I0703 11:46:13.602661 133161429332608 run.py:730] Checkpointing best model, best avg val score was 0.986, current avg val score is 0.988, val scores are: activity_selector: 0.988
I0703 11:46:17.409893 133161429332608 run.py:674] Algo activity_selector step 9300 current loss 0.531445, current_train_items 448128.
I0703 11:46:17.674102 133161429332608 run.py:709] (val) algo activity_selector step 9300: {'selected': 0.9519650655021833, 'score': 0.9519650655021833, 'examples_seen': 448128, 'step': 9300, 'algorithm': 'activity_selector'}
I0703 11:46:17.674294 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.988, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0703 11:46:21.240139 133161429332608 run.py:674] Algo activity_selector step 9350 current loss 4.743753, current_train_items 450208.
I0703 11:46:21.910019 133161429332608 run.py:709] (val) algo activity_selector step 9350: {'selected': 0.9614935822637106, 'score': 0.9614935822637106, 'examples_seen': 450208, 'step': 9350, 'algorithm': 'activity_selector'}
I0703 11:46:21.910217 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.988, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0703 11:46:25.349503 133161429332608 run.py:674] Algo activity_selector step 9400 current loss 2.443821, current_train_items 452832.
I0703 11:46:25.634700 133161429332608 run.py:709] (val) algo activity_selector step 9400: {'selected': 0.9939975990396158, 'score': 0.9939975990396158, 'examples_seen': 452832, 'step': 9400, 'algorithm': 'activity_selector'}
I0703 11:46:25.634967 133161429332608 run.py:730] Checkpointing best model, best avg val score was 0.988, current avg val score is 0.994, val scores are: activity_selector: 0.994
I0703 11:46:29.621994 133161429332608 run.py:674] Algo activity_selector step 9450 current loss 0.341687, current_train_items 455168.
I0703 11:46:29.994956 133161429332608 run.py:709] (val) algo activity_selector step 9450: {'selected': 0.8692660550458716, 'score': 0.8692660550458716, 'examples_seen': 455168, 'step': 9450, 'algorithm': 'activity_selector'}
I0703 11:46:29.995166 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.994, current avg val score is 0.869, val scores are: activity_selector: 0.869
I0703 11:46:33.335396 133161429332608 run.py:674] Algo activity_selector step 9500 current loss 5.938984, current_train_items 457536.
I0703 11:46:33.756317 133161429332608 run.py:709] (val) algo activity_selector step 9500: {'selected': 0.964244521337947, 'score': 0.964244521337947, 'examples_seen': 457536, 'step': 9500, 'algorithm': 'activity_selector'}
I0703 11:46:33.756515 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.994, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0703 11:46:37.493591 133161429332608 run.py:674] Algo activity_selector step 9550 current loss 0.319994, current_train_items 460128.
I0703 11:46:37.743052 133161429332608 run.py:709] (val) algo activity_selector step 9550: {'selected': 0.9617117117117117, 'score': 0.9617117117117117, 'examples_seen': 460128, 'step': 9550, 'algorithm': 'activity_selector'}
I0703 11:46:37.743262 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.994, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0703 11:46:41.334955 133161429332608 run.py:674] Algo activity_selector step 9600 current loss 2.994016, current_train_items 462368.
I0703 11:46:41.895013 133161429332608 run.py:709] (val) algo activity_selector step 9600: {'selected': 0.9486887115165337, 'score': 0.9486887115165337, 'examples_seen': 462368, 'step': 9600, 'algorithm': 'activity_selector'}
I0703 11:46:41.895207 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.994, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0703 11:46:45.459477 133161429332608 run.py:674] Algo activity_selector step 9650 current loss 1.774179, current_train_items 464928.
I0703 11:46:45.721458 133161429332608 run.py:709] (val) algo activity_selector step 9650: {'selected': 0.9654377880184332, 'score': 0.9654377880184332, 'examples_seen': 464928, 'step': 9650, 'algorithm': 'activity_selector'}
I0703 11:46:45.721712 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.994, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0703 11:46:49.324241 133161429332608 run.py:674] Algo activity_selector step 9700 current loss 0.578030, current_train_items 467072.
I0703 11:46:49.991657 133161429332608 run.py:709] (val) algo activity_selector step 9700: {'selected': 0.9698375870069605, 'score': 0.9698375870069605, 'examples_seen': 467072, 'step': 9700, 'algorithm': 'activity_selector'}
I0703 11:46:49.991935 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.994, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0703 11:46:53.600471 133161429332608 run.py:674] Algo activity_selector step 9750 current loss 2.292390, current_train_items 469600.
I0703 11:46:53.893044 133161429332608 run.py:709] (val) algo activity_selector step 9750: {'selected': 0.9778761061946902, 'score': 0.9778761061946902, 'examples_seen': 469600, 'step': 9750, 'algorithm': 'activity_selector'}
I0703 11:46:53.893242 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.994, current avg val score is 0.978, val scores are: activity_selector: 0.978
I0703 11:46:57.676749 133161429332608 run.py:674] Algo activity_selector step 9800 current loss 0.160642, current_train_items 472096.
I0703 11:46:58.054553 133161429332608 run.py:709] (val) algo activity_selector step 9800: {'selected': 0.9686800894854586, 'score': 0.9686800894854586, 'examples_seen': 472096, 'step': 9800, 'algorithm': 'activity_selector'}
I0703 11:46:58.054751 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.994, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0703 11:47:01.349900 133161429332608 run.py:674] Algo activity_selector step 9850 current loss 3.971673, current_train_items 474496.
I0703 11:47:01.770188 133161429332608 run.py:709] (val) algo activity_selector step 9850: {'selected': 0.9735327963176064, 'score': 0.9735327963176064, 'examples_seen': 474496, 'step': 9850, 'algorithm': 'activity_selector'}
I0703 11:47:01.770477 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.994, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0703 11:47:05.757327 133161429332608 run.py:674] Algo activity_selector step 9900 current loss 0.242006, current_train_items 476992.
I0703 11:47:06.010682 133161429332608 run.py:709] (val) algo activity_selector step 9900: {'selected': 0.9792626728110599, 'score': 0.9792626728110599, 'examples_seen': 476992, 'step': 9900, 'algorithm': 'activity_selector'}
I0703 11:47:06.010926 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.994, current avg val score is 0.979, val scores are: activity_selector: 0.979
I0703 11:47:09.396036 133161429332608 run.py:674] Algo activity_selector step 9950 current loss 4.782495, current_train_items 479104.
I0703 11:47:09.956857 133161429332608 run.py:709] (val) algo activity_selector step 9950: {'selected': 0.9858490566037735, 'score': 0.9858490566037735, 'examples_seen': 479104, 'step': 9950, 'algorithm': 'activity_selector'}
I0703 11:47:09.957072 133161429332608 run.py:733] Not saving new best model, best avg val score was 0.994, current avg val score is 0.986, val scores are: activity_selector: 0.986
I0703 11:47:13.487355 133161429332608 run.py:739] Restoring best model from checkpoint...
I0703 11:47:15.568181 133161429332608 run.py:754] (test) algo activity_selector : {'selected': 0.933572710951526, 'score': 0.933572710951526, 'examples_seen': 481728, 'step': 10000, 'algorithm': 'activity_selector'}
I0703 11:47:15.568364 133161429332608 run.py:756] Done!
