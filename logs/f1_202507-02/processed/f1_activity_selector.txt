I0715 07:25:53.630456 125536568714752 run.py:688] Algo activity_selector step 0 current loss 3.757482, current_train_items 64.
I0715 07:25:58.811959 125536568714752 run.py:723] (val) algo activity_selector step 0: {'selected': 0.42130365659777425, 'score': 0.42130365659777425, 'examples_seen': 64, 'step': 0, 'algorithm': 'activity_selector'}
I0715 07:25:58.812122 125536568714752 run.py:744] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.421, val scores are: activity_selector: 0.421
I0715 07:27:05.183278 125536568714752 run.py:688] Algo activity_selector step 50 current loss 3.588275, current_train_items 2080.
I0715 07:27:05.207354 125536568714752 run.py:723] (val) algo activity_selector step 50: {'selected': 0.6742301458670988, 'score': 0.6742301458670988, 'examples_seen': 2080, 'step': 50, 'algorithm': 'activity_selector'}
I0715 07:27:05.207521 125536568714752 run.py:744] Checkpointing best model, best avg val score was 0.421, current avg val score is 0.674, val scores are: activity_selector: 0.674
I0715 07:27:06.219726 125536568714752 run.py:688] Algo activity_selector step 100 current loss 3.501404, current_train_items 4064.
I0715 07:27:06.244491 125536568714752 run.py:723] (val) algo activity_selector step 100: {'selected': 0.6602316602316602, 'score': 0.6602316602316602, 'examples_seen': 4064, 'step': 100, 'algorithm': 'activity_selector'}
I0715 07:27:06.244640 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.674, current avg val score is 0.660, val scores are: activity_selector: 0.660
I0715 07:27:07.236040 125536568714752 run.py:688] Algo activity_selector step 150 current loss 4.137877, current_train_items 6016.
I0715 07:27:07.264452 125536568714752 run.py:723] (val) algo activity_selector step 150: {'selected': 0.7504244482173175, 'score': 0.7504244482173175, 'examples_seen': 6016, 'step': 150, 'algorithm': 'activity_selector'}
I0715 07:27:07.264614 125536568714752 run.py:744] Checkpointing best model, best avg val score was 0.674, current avg val score is 0.750, val scores are: activity_selector: 0.750
I0715 07:27:08.282126 125536568714752 run.py:688] Algo activity_selector step 200 current loss 3.861809, current_train_items 8016.
I0715 07:27:08.311611 125536568714752 run.py:723] (val) algo activity_selector step 200: {'selected': 0.7387387387387387, 'score': 0.7387387387387387, 'examples_seen': 8016, 'step': 200, 'algorithm': 'activity_selector'}
I0715 07:27:08.311760 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.750, current avg val score is 0.739, val scores are: activity_selector: 0.739
I0715 07:27:09.310508 125536568714752 run.py:688] Algo activity_selector step 250 current loss 4.169052, current_train_items 9952.
I0715 07:27:09.345469 125536568714752 run.py:723] (val) algo activity_selector step 250: {'selected': 0.7615062761506275, 'score': 0.7615062761506275, 'examples_seen': 9952, 'step': 250, 'algorithm': 'activity_selector'}
I0715 07:27:09.345637 125536568714752 run.py:744] Checkpointing best model, best avg val score was 0.750, current avg val score is 0.762, val scores are: activity_selector: 0.762
I0715 07:27:10.381355 125536568714752 run.py:688] Algo activity_selector step 300 current loss 1.491188, current_train_items 12000.
I0715 07:27:10.403805 125536568714752 run.py:723] (val) algo activity_selector step 300: {'selected': 0.7985074626865671, 'score': 0.7985074626865671, 'examples_seen': 12000, 'step': 300, 'algorithm': 'activity_selector'}
I0715 07:27:10.403955 125536568714752 run.py:744] Checkpointing best model, best avg val score was 0.762, current avg val score is 0.799, val scores are: activity_selector: 0.799
I0715 07:27:11.416023 125536568714752 run.py:688] Algo activity_selector step 350 current loss 1.675923, current_train_items 14032.
I0715 07:27:11.438977 125536568714752 run.py:723] (val) algo activity_selector step 350: {'selected': 0.6109785202863962, 'score': 0.6109785202863962, 'examples_seen': 14032, 'step': 350, 'algorithm': 'activity_selector'}
I0715 07:27:11.439126 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.799, current avg val score is 0.611, val scores are: activity_selector: 0.611
I0715 07:27:12.454687 125536568714752 run.py:688] Algo activity_selector step 400 current loss 1.912627, current_train_items 16000.
I0715 07:27:12.478751 125536568714752 run.py:723] (val) algo activity_selector step 400: {'selected': 0.7918367346938776, 'score': 0.7918367346938776, 'examples_seen': 16000, 'step': 400, 'algorithm': 'activity_selector'}
I0715 07:27:12.478910 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.799, current avg val score is 0.792, val scores are: activity_selector: 0.792
I0715 07:27:13.476559 125536568714752 run.py:688] Algo activity_selector step 450 current loss 1.599907, current_train_items 18000.
I0715 07:27:13.501794 125536568714752 run.py:723] (val) algo activity_selector step 450: {'selected': 0.8461538461538461, 'score': 0.8461538461538461, 'examples_seen': 18000, 'step': 450, 'algorithm': 'activity_selector'}
I0715 07:27:13.501942 125536568714752 run.py:744] Checkpointing best model, best avg val score was 0.799, current avg val score is 0.846, val scores are: activity_selector: 0.846
I0715 07:27:14.499070 125536568714752 run.py:688] Algo activity_selector step 500 current loss 2.692428, current_train_items 19952.
I0715 07:27:14.527002 125536568714752 run.py:723] (val) algo activity_selector step 500: {'selected': 0.8405253283302064, 'score': 0.8405253283302064, 'examples_seen': 19952, 'step': 500, 'algorithm': 'activity_selector'}
I0715 07:27:14.527158 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.846, current avg val score is 0.841, val scores are: activity_selector: 0.841
I0715 07:27:15.513050 125536568714752 run.py:688] Algo activity_selector step 550 current loss 3.180312, current_train_items 21920.
I0715 07:27:15.542553 125536568714752 run.py:723] (val) algo activity_selector step 550: {'selected': 0.8481481481481482, 'score': 0.8481481481481482, 'examples_seen': 21920, 'step': 550, 'algorithm': 'activity_selector'}
I0715 07:27:15.542701 125536568714752 run.py:744] Checkpointing best model, best avg val score was 0.846, current avg val score is 0.848, val scores are: activity_selector: 0.848
I0715 07:27:16.531461 125536568714752 run.py:688] Algo activity_selector step 600 current loss 3.389071, current_train_items 23904.
I0715 07:27:16.564438 125536568714752 run.py:723] (val) algo activity_selector step 600: {'selected': 0.8713235294117647, 'score': 0.8713235294117647, 'examples_seen': 23904, 'step': 600, 'algorithm': 'activity_selector'}
I0715 07:27:16.564589 125536568714752 run.py:744] Checkpointing best model, best avg val score was 0.848, current avg val score is 0.871, val scores are: activity_selector: 0.871
I0715 07:27:17.594653 125536568714752 run.py:688] Algo activity_selector step 650 current loss 1.126247, current_train_items 25920.
I0715 07:27:17.616983 125536568714752 run.py:723] (val) algo activity_selector step 650: {'selected': 0.8356164383561644, 'score': 0.8356164383561644, 'examples_seen': 25920, 'step': 650, 'algorithm': 'activity_selector'}
I0715 07:27:17.617169 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.871, current avg val score is 0.836, val scores are: activity_selector: 0.836
I0715 07:27:18.631262 125536568714752 run.py:688] Algo activity_selector step 700 current loss 0.487056, current_train_items 27952.
I0715 07:27:18.653752 125536568714752 run.py:723] (val) algo activity_selector step 700: {'selected': 0.8376068376068377, 'score': 0.8376068376068377, 'examples_seen': 27952, 'step': 700, 'algorithm': 'activity_selector'}
I0715 07:27:18.653900 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.871, current avg val score is 0.838, val scores are: activity_selector: 0.838
I0715 07:27:19.651622 125536568714752 run.py:688] Algo activity_selector step 750 current loss 0.823022, current_train_items 29936.
I0715 07:27:19.674985 125536568714752 run.py:723] (val) algo activity_selector step 750: {'selected': 0.8479427549194991, 'score': 0.8479427549194991, 'examples_seen': 29936, 'step': 750, 'algorithm': 'activity_selector'}
I0715 07:27:19.675130 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.871, current avg val score is 0.848, val scores are: activity_selector: 0.848
I0715 07:27:20.686676 125536568714752 run.py:688] Algo activity_selector step 800 current loss 0.808518, current_train_items 31920.
I0715 07:27:20.711816 125536568714752 run.py:723] (val) algo activity_selector step 800: {'selected': 0.8229166666666667, 'score': 0.8229166666666667, 'examples_seen': 31920, 'step': 800, 'algorithm': 'activity_selector'}
I0715 07:27:20.711964 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.871, current avg val score is 0.823, val scores are: activity_selector: 0.823
I0715 07:27:21.690201 125536568714752 run.py:688] Algo activity_selector step 850 current loss 2.443961, current_train_items 33904.
I0715 07:27:21.718050 125536568714752 run.py:723] (val) algo activity_selector step 850: {'selected': 0.9236641221374046, 'score': 0.9236641221374046, 'examples_seen': 33904, 'step': 850, 'algorithm': 'activity_selector'}
I0715 07:27:21.718195 125536568714752 run.py:744] Checkpointing best model, best avg val score was 0.871, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0715 07:27:22.743078 125536568714752 run.py:688] Algo activity_selector step 900 current loss 2.552294, current_train_items 35856.
I0715 07:27:22.773885 125536568714752 run.py:723] (val) algo activity_selector step 900: {'selected': 0.8615384615384616, 'score': 0.8615384615384616, 'examples_seen': 35856, 'step': 900, 'algorithm': 'activity_selector'}
I0715 07:27:22.774031 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.924, current avg val score is 0.862, val scores are: activity_selector: 0.862
I0715 07:27:23.759817 125536568714752 run.py:688] Algo activity_selector step 950 current loss 1.497741, current_train_items 37808.
I0715 07:27:23.792729 125536568714752 run.py:723] (val) algo activity_selector step 950: {'selected': 0.9144981412639405, 'score': 0.9144981412639405, 'examples_seen': 37808, 'step': 950, 'algorithm': 'activity_selector'}
I0715 07:27:23.792876 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.924, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0715 07:27:24.801173 125536568714752 run.py:688] Algo activity_selector step 1000 current loss 0.311915, current_train_items 39872.
I0715 07:27:24.823074 125536568714752 run.py:723] (val) algo activity_selector step 1000: {'selected': 0.8422939068100358, 'score': 0.8422939068100358, 'examples_seen': 39872, 'step': 1000, 'algorithm': 'activity_selector'}
I0715 07:27:24.823222 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.924, current avg val score is 0.842, val scores are: activity_selector: 0.842
I0715 07:27:25.835183 125536568714752 run.py:688] Algo activity_selector step 1050 current loss 0.688682, current_train_items 41872.
I0715 07:27:25.857802 125536568714752 run.py:723] (val) algo activity_selector step 1050: {'selected': 0.8628884826325411, 'score': 0.8628884826325411, 'examples_seen': 41872, 'step': 1050, 'algorithm': 'activity_selector'}
I0715 07:27:25.857952 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.924, current avg val score is 0.863, val scores are: activity_selector: 0.863
I0715 07:27:26.843817 125536568714752 run.py:688] Algo activity_selector step 1100 current loss 1.493623, current_train_items 43872.
I0715 07:27:26.867670 125536568714752 run.py:723] (val) algo activity_selector step 1100: {'selected': 0.9251439539347408, 'score': 0.9251439539347408, 'examples_seen': 43872, 'step': 1100, 'algorithm': 'activity_selector'}
I0715 07:27:26.867823 125536568714752 run.py:744] Checkpointing best model, best avg val score was 0.924, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0715 07:27:27.886391 125536568714752 run.py:688] Algo activity_selector step 1150 current loss 1.712134, current_train_items 45856.
I0715 07:27:27.911510 125536568714752 run.py:723] (val) algo activity_selector step 1150: {'selected': 0.8994708994708996, 'score': 0.8994708994708996, 'examples_seen': 45856, 'step': 1150, 'algorithm': 'activity_selector'}
I0715 07:27:27.911658 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.925, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0715 07:27:28.906853 125536568714752 run.py:688] Algo activity_selector step 1200 current loss 2.423546, current_train_items 47808.
I0715 07:27:28.934350 125536568714752 run.py:723] (val) algo activity_selector step 1200: {'selected': 0.9139579349904398, 'score': 0.9139579349904398, 'examples_seen': 47808, 'step': 1200, 'algorithm': 'activity_selector'}
I0715 07:27:28.934502 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.925, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0715 07:27:29.928562 125536568714752 run.py:688] Algo activity_selector step 1250 current loss 2.243112, current_train_items 49808.
I0715 07:27:29.960539 125536568714752 run.py:723] (val) algo activity_selector step 1250: {'selected': 0.9119373776908024, 'score': 0.9119373776908024, 'examples_seen': 49808, 'step': 1250, 'algorithm': 'activity_selector'}
I0715 07:27:29.960685 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.925, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0715 07:27:30.954907 125536568714752 run.py:688] Algo activity_selector step 1300 current loss 4.833045, current_train_items 51760.
I0715 07:27:30.994438 125536568714752 run.py:723] (val) algo activity_selector step 1300: {'selected': 0.9416195856873822, 'score': 0.9416195856873822, 'examples_seen': 51760, 'step': 1300, 'algorithm': 'activity_selector'}
I0715 07:27:30.994596 125536568714752 run.py:744] Checkpointing best model, best avg val score was 0.925, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0715 07:27:32.022009 125536568714752 run.py:688] Algo activity_selector step 1350 current loss 0.478987, current_train_items 53792.
I0715 07:27:32.045062 125536568714752 run.py:723] (val) algo activity_selector step 1350: {'selected': 0.9326047358834243, 'score': 0.9326047358834243, 'examples_seen': 53792, 'step': 1350, 'algorithm': 'activity_selector'}
I0715 07:27:32.045209 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.942, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0715 07:27:33.046853 125536568714752 run.py:688] Algo activity_selector step 1400 current loss 0.617082, current_train_items 55824.
I0715 07:27:33.069422 125536568714752 run.py:723] (val) algo activity_selector step 1400: {'selected': 0.9032258064516128, 'score': 0.9032258064516128, 'examples_seen': 55824, 'step': 1400, 'algorithm': 'activity_selector'}
I0715 07:27:33.069588 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.942, current avg val score is 0.903, val scores are: activity_selector: 0.903
I0715 07:27:34.069525 125536568714752 run.py:688] Algo activity_selector step 1450 current loss 1.218678, current_train_items 57792.
I0715 07:27:34.093607 125536568714752 run.py:723] (val) algo activity_selector step 1450: {'selected': 0.9248554913294796, 'score': 0.9248554913294796, 'examples_seen': 57792, 'step': 1450, 'algorithm': 'activity_selector'}
I0715 07:27:34.093754 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.942, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0715 07:27:35.079510 125536568714752 run.py:688] Algo activity_selector step 1500 current loss 0.363936, current_train_items 59792.
I0715 07:27:35.104630 125536568714752 run.py:723] (val) algo activity_selector step 1500: {'selected': 0.9222423146473779, 'score': 0.9222423146473779, 'examples_seen': 59792, 'step': 1500, 'algorithm': 'activity_selector'}
I0715 07:27:35.104776 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.942, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0715 07:27:36.091095 125536568714752 run.py:688] Algo activity_selector step 1550 current loss 0.679335, current_train_items 61744.
I0715 07:27:36.119076 125536568714752 run.py:723] (val) algo activity_selector step 1550: {'selected': 0.9087221095334685, 'score': 0.9087221095334685, 'examples_seen': 61744, 'step': 1550, 'algorithm': 'activity_selector'}
I0715 07:27:36.119225 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.942, current avg val score is 0.909, val scores are: activity_selector: 0.909
I0715 07:27:37.113767 125536568714752 run.py:688] Algo activity_selector step 1600 current loss 1.758141, current_train_items 63712.
I0715 07:27:37.144497 125536568714752 run.py:723] (val) algo activity_selector step 1600: {'selected': 0.9422718808193667, 'score': 0.9422718808193667, 'examples_seen': 63712, 'step': 1600, 'algorithm': 'activity_selector'}
I0715 07:27:37.144642 125536568714752 run.py:744] Checkpointing best model, best avg val score was 0.942, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0715 07:27:38.147315 125536568714752 run.py:688] Algo activity_selector step 1650 current loss 3.872382, current_train_items 65712.
I0715 07:27:38.180515 125536568714752 run.py:723] (val) algo activity_selector step 1650: {'selected': 0.9647495361781075, 'score': 0.9647495361781075, 'examples_seen': 65712, 'step': 1650, 'algorithm': 'activity_selector'}
I0715 07:27:38.180663 125536568714752 run.py:744] Checkpointing best model, best avg val score was 0.942, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0715 07:27:39.209263 125536568714752 run.py:688] Algo activity_selector step 1700 current loss 0.406790, current_train_items 67712.
I0715 07:27:39.231730 125536568714752 run.py:723] (val) algo activity_selector step 1700: {'selected': 0.8695652173913043, 'score': 0.8695652173913043, 'examples_seen': 67712, 'step': 1700, 'algorithm': 'activity_selector'}
I0715 07:27:39.231880 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.965, current avg val score is 0.870, val scores are: activity_selector: 0.870
I0715 07:27:40.248106 125536568714752 run.py:688] Algo activity_selector step 1750 current loss 0.509494, current_train_items 69744.
I0715 07:27:40.271254 125536568714752 run.py:723] (val) algo activity_selector step 1750: {'selected': 0.9042145593869733, 'score': 0.9042145593869733, 'examples_seen': 69744, 'step': 1750, 'algorithm': 'activity_selector'}
I0715 07:27:40.271399 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.965, current avg val score is 0.904, val scores are: activity_selector: 0.904
I0715 07:27:41.264517 125536568714752 run.py:688] Algo activity_selector step 1800 current loss 0.435056, current_train_items 71728.
I0715 07:27:41.288267 125536568714752 run.py:723] (val) algo activity_selector step 1800: {'selected': 0.8679927667269439, 'score': 0.8679927667269439, 'examples_seen': 71728, 'step': 1800, 'algorithm': 'activity_selector'}
I0715 07:27:41.288416 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.965, current avg val score is 0.868, val scores are: activity_selector: 0.868
I0715 07:27:42.294616 125536568714752 run.py:688] Algo activity_selector step 1850 current loss 0.441017, current_train_items 73712.
I0715 07:27:42.319832 125536568714752 run.py:723] (val) algo activity_selector step 1850: {'selected': 0.9009345794392524, 'score': 0.9009345794392524, 'examples_seen': 73712, 'step': 1850, 'algorithm': 'activity_selector'}
I0715 07:27:42.319977 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.965, current avg val score is 0.901, val scores are: activity_selector: 0.901
I0715 07:27:43.300978 125536568714752 run.py:688] Algo activity_selector step 1900 current loss 1.757350, current_train_items 75712.
I0715 07:27:43.329206 125536568714752 run.py:723] (val) algo activity_selector step 1900: {'selected': 0.9380863039399624, 'score': 0.9380863039399624, 'examples_seen': 75712, 'step': 1900, 'algorithm': 'activity_selector'}
I0715 07:27:43.329351 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.965, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0715 07:27:44.342739 125536568714752 run.py:688] Algo activity_selector step 1950 current loss 1.817771, current_train_items 77664.
I0715 07:27:44.372576 125536568714752 run.py:723] (val) algo activity_selector step 1950: {'selected': 0.9239332096474955, 'score': 0.9239332096474955, 'examples_seen': 77664, 'step': 1950, 'algorithm': 'activity_selector'}
I0715 07:27:44.372721 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.965, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0715 07:27:45.380160 125536568714752 run.py:688] Algo activity_selector step 2000 current loss 4.205172, current_train_items 79632.
I0715 07:27:45.415472 125536568714752 run.py:723] (val) algo activity_selector step 2000: {'selected': 0.9585798816568047, 'score': 0.9585798816568047, 'examples_seen': 79632, 'step': 2000, 'algorithm': 'activity_selector'}
I0715 07:27:45.415627 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.965, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0715 07:27:46.425073 125536568714752 run.py:688] Algo activity_selector step 2050 current loss 0.221850, current_train_items 81680.
I0715 07:27:46.450055 125536568714752 run.py:723] (val) algo activity_selector step 2050: {'selected': 0.8957952468007312, 'score': 0.8957952468007312, 'examples_seen': 81680, 'step': 2050, 'algorithm': 'activity_selector'}
I0715 07:27:46.450204 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.965, current avg val score is 0.896, val scores are: activity_selector: 0.896
I0715 07:27:47.470886 125536568714752 run.py:688] Algo activity_selector step 2100 current loss 0.139994, current_train_items 83680.
I0715 07:27:47.493465 125536568714752 run.py:723] (val) algo activity_selector step 2100: {'selected': 0.9518072289156627, 'score': 0.9518072289156627, 'examples_seen': 83680, 'step': 2100, 'algorithm': 'activity_selector'}
I0715 07:27:47.493626 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.965, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0715 07:27:48.489747 125536568714752 run.py:688] Algo activity_selector step 2150 current loss 1.329198, current_train_items 85680.
I0715 07:27:48.514626 125536568714752 run.py:723] (val) algo activity_selector step 2150: {'selected': 0.9420849420849421, 'score': 0.9420849420849421, 'examples_seen': 85680, 'step': 2150, 'algorithm': 'activity_selector'}
I0715 07:27:48.514786 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.965, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0715 07:27:49.548184 125536568714752 run.py:688] Algo activity_selector step 2200 current loss 0.484083, current_train_items 87664.
I0715 07:27:49.573676 125536568714752 run.py:723] (val) algo activity_selector step 2200: {'selected': 0.9364161849710982, 'score': 0.9364161849710982, 'examples_seen': 87664, 'step': 2200, 'algorithm': 'activity_selector'}
I0715 07:27:49.573826 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.965, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0715 07:27:50.578120 125536568714752 run.py:688] Algo activity_selector step 2250 current loss 2.067412, current_train_items 89632.
I0715 07:27:50.606094 125536568714752 run.py:723] (val) algo activity_selector step 2250: {'selected': 0.9751434034416826, 'score': 0.9751434034416826, 'examples_seen': 89632, 'step': 2250, 'algorithm': 'activity_selector'}
I0715 07:27:50.606241 125536568714752 run.py:744] Checkpointing best model, best avg val score was 0.965, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0715 07:27:51.609252 125536568714752 run.py:688] Algo activity_selector step 2300 current loss 0.870285, current_train_items 91616.
I0715 07:27:51.638807 125536568714752 run.py:723] (val) algo activity_selector step 2300: {'selected': 0.9187145557655955, 'score': 0.9187145557655955, 'examples_seen': 91616, 'step': 2300, 'algorithm': 'activity_selector'}
I0715 07:27:51.638952 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0715 07:27:52.643132 125536568714752 run.py:688] Algo activity_selector step 2350 current loss 3.437687, current_train_items 93568.
I0715 07:27:52.676153 125536568714752 run.py:723] (val) algo activity_selector step 2350: {'selected': 0.9265734265734266, 'score': 0.9265734265734266, 'examples_seen': 93568, 'step': 2350, 'algorithm': 'activity_selector'}
I0715 07:27:52.676298 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0715 07:27:53.681908 125536568714752 run.py:688] Algo activity_selector step 2400 current loss 0.488316, current_train_items 95600.
I0715 07:27:53.704208 125536568714752 run.py:723] (val) algo activity_selector step 2400: {'selected': 0.9361702127659575, 'score': 0.9361702127659575, 'examples_seen': 95600, 'step': 2400, 'algorithm': 'activity_selector'}
I0715 07:27:53.704365 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0715 07:27:54.718575 125536568714752 run.py:688] Algo activity_selector step 2450 current loss 0.204363, current_train_items 97632.
I0715 07:27:54.741014 125536568714752 run.py:723] (val) algo activity_selector step 2450: {'selected': 0.9440993788819876, 'score': 0.9440993788819876, 'examples_seen': 97632, 'step': 2450, 'algorithm': 'activity_selector'}
I0715 07:27:54.741159 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0715 07:27:55.734765 125536568714752 run.py:688] Algo activity_selector step 2500 current loss 1.171907, current_train_items 99600.
I0715 07:27:55.758565 125536568714752 run.py:723] (val) algo activity_selector step 2500: {'selected': 0.9409368635437882, 'score': 0.9409368635437882, 'examples_seen': 99600, 'step': 2500, 'algorithm': 'activity_selector'}
I0715 07:27:55.758712 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0715 07:27:56.750946 125536568714752 run.py:688] Algo activity_selector step 2550 current loss 0.401622, current_train_items 101600.
I0715 07:27:56.776216 125536568714752 run.py:723] (val) algo activity_selector step 2550: {'selected': 0.9138576779026217, 'score': 0.9138576779026217, 'examples_seen': 101600, 'step': 2550, 'algorithm': 'activity_selector'}
I0715 07:27:56.776376 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0715 07:27:57.782552 125536568714752 run.py:688] Algo activity_selector step 2600 current loss 0.441403, current_train_items 103568.
I0715 07:27:57.810915 125536568714752 run.py:723] (val) algo activity_selector step 2600: {'selected': 0.9479768786127167, 'score': 0.9479768786127167, 'examples_seen': 103568, 'step': 2600, 'algorithm': 'activity_selector'}
I0715 07:27:57.811061 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0715 07:27:58.793027 125536568714752 run.py:688] Algo activity_selector step 2650 current loss 4.511974, current_train_items 105520.
I0715 07:27:58.822329 125536568714752 run.py:723] (val) algo activity_selector step 2650: {'selected': 0.9686924493554327, 'score': 0.9686924493554327, 'examples_seen': 105520, 'step': 2650, 'algorithm': 'activity_selector'}
I0715 07:27:58.822486 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0715 07:27:59.819648 125536568714752 run.py:688] Algo activity_selector step 2700 current loss 3.236081, current_train_items 107520.
I0715 07:27:59.853439 125536568714752 run.py:723] (val) algo activity_selector step 2700: {'selected': 0.9188118811881189, 'score': 0.9188118811881189, 'examples_seen': 107520, 'step': 2700, 'algorithm': 'activity_selector'}
I0715 07:27:59.853597 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0715 07:28:00.866086 125536568714752 run.py:688] Algo activity_selector step 2750 current loss 0.469226, current_train_items 109520.
I0715 07:28:00.888147 125536568714752 run.py:723] (val) algo activity_selector step 2750: {'selected': 0.9545454545454546, 'score': 0.9545454545454546, 'examples_seen': 109520, 'step': 2750, 'algorithm': 'activity_selector'}
I0715 07:28:00.888293 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0715 07:28:01.900140 125536568714752 run.py:688] Algo activity_selector step 2800 current loss 0.201049, current_train_items 111552.
I0715 07:28:01.924752 125536568714752 run.py:723] (val) algo activity_selector step 2800: {'selected': 0.9323308270676691, 'score': 0.9323308270676691, 'examples_seen': 111552, 'step': 2800, 'algorithm': 'activity_selector'}
I0715 07:28:01.924905 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0715 07:28:02.916241 125536568714752 run.py:688] Algo activity_selector step 2850 current loss 0.268602, current_train_items 113552.
I0715 07:28:02.939645 125536568714752 run.py:723] (val) algo activity_selector step 2850: {'selected': 0.9416195856873824, 'score': 0.9416195856873824, 'examples_seen': 113552, 'step': 2850, 'algorithm': 'activity_selector'}
I0715 07:28:02.939792 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0715 07:28:03.942224 125536568714752 run.py:688] Algo activity_selector step 2900 current loss 0.366754, current_train_items 115520.
I0715 07:28:03.967439 125536568714752 run.py:723] (val) algo activity_selector step 2900: {'selected': 0.8920353982300885, 'score': 0.8920353982300885, 'examples_seen': 115520, 'step': 2900, 'algorithm': 'activity_selector'}
I0715 07:28:03.967593 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.892, val scores are: activity_selector: 0.892
I0715 07:28:04.961938 125536568714752 run.py:688] Algo activity_selector step 2950 current loss 2.052125, current_train_items 117520.
I0715 07:28:04.989350 125536568714752 run.py:723] (val) algo activity_selector step 2950: {'selected': 0.9320754716981132, 'score': 0.9320754716981132, 'examples_seen': 117520, 'step': 2950, 'algorithm': 'activity_selector'}
I0715 07:28:04.989506 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0715 07:28:05.978592 125536568714752 run.py:688] Algo activity_selector step 3000 current loss 2.465712, current_train_items 119456.
I0715 07:28:06.008086 125536568714752 run.py:723] (val) algo activity_selector step 3000: {'selected': 0.8987108655616943, 'score': 0.8987108655616943, 'examples_seen': 119456, 'step': 3000, 'algorithm': 'activity_selector'}
I0715 07:28:06.008239 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0715 07:28:07.010338 125536568714752 run.py:688] Algo activity_selector step 3050 current loss 2.917606, current_train_items 121424.
I0715 07:28:07.043456 125536568714752 run.py:723] (val) algo activity_selector step 3050: {'selected': 0.953125, 'score': 0.953125, 'examples_seen': 121424, 'step': 3050, 'algorithm': 'activity_selector'}
I0715 07:28:07.043612 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0715 07:28:08.042896 125536568714752 run.py:688] Algo activity_selector step 3100 current loss 0.197818, current_train_items 123472.
I0715 07:28:08.065193 125536568714752 run.py:723] (val) algo activity_selector step 3100: {'selected': 0.9604743083003953, 'score': 0.9604743083003953, 'examples_seen': 123472, 'step': 3100, 'algorithm': 'activity_selector'}
I0715 07:28:08.065343 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0715 07:28:09.073681 125536568714752 run.py:688] Algo activity_selector step 3150 current loss 0.227467, current_train_items 125472.
I0715 07:28:09.096329 125536568714752 run.py:723] (val) algo activity_selector step 3150: {'selected': 0.9224952741020794, 'score': 0.9224952741020794, 'examples_seen': 125472, 'step': 3150, 'algorithm': 'activity_selector'}
I0715 07:28:09.096476 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0715 07:28:10.096891 125536568714752 run.py:688] Algo activity_selector step 3200 current loss 1.177502, current_train_items 127488.
I0715 07:28:10.120695 125536568714752 run.py:723] (val) algo activity_selector step 3200: {'selected': 0.9574861367837338, 'score': 0.9574861367837338, 'examples_seen': 127488, 'step': 3200, 'algorithm': 'activity_selector'}
I0715 07:28:10.120857 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0715 07:28:11.109185 125536568714752 run.py:688] Algo activity_selector step 3250 current loss 0.348470, current_train_items 129456.
I0715 07:28:11.134411 125536568714752 run.py:723] (val) algo activity_selector step 3250: {'selected': 0.877959927140255, 'score': 0.877959927140255, 'examples_seen': 129456, 'step': 3250, 'algorithm': 'activity_selector'}
I0715 07:28:11.134570 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.975, current avg val score is 0.878, val scores are: activity_selector: 0.878
I0715 07:28:12.134963 125536568714752 run.py:688] Algo activity_selector step 3300 current loss 1.826462, current_train_items 131424.
I0715 07:28:12.162883 125536568714752 run.py:723] (val) algo activity_selector step 3300: {'selected': 0.9825918762088974, 'score': 0.9825918762088974, 'examples_seen': 131424, 'step': 3300, 'algorithm': 'activity_selector'}
I0715 07:28:12.163041 125536568714752 run.py:744] Checkpointing best model, best avg val score was 0.975, current avg val score is 0.983, val scores are: activity_selector: 0.983
I0715 07:28:13.149596 125536568714752 run.py:688] Algo activity_selector step 3350 current loss 2.022686, current_train_items 133408.
I0715 07:28:13.179474 125536568714752 run.py:723] (val) algo activity_selector step 3350: {'selected': 0.9657794676806084, 'score': 0.9657794676806084, 'examples_seen': 133408, 'step': 3350, 'algorithm': 'activity_selector'}
I0715 07:28:13.179629 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0715 07:28:14.180697 125536568714752 run.py:688] Algo activity_selector step 3400 current loss 2.275136, current_train_items 135360.
I0715 07:28:14.213502 125536568714752 run.py:723] (val) algo activity_selector step 3400: {'selected': 0.9669902912621359, 'score': 0.9669902912621359, 'examples_seen': 135360, 'step': 3400, 'algorithm': 'activity_selector'}
I0715 07:28:14.213646 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0715 07:28:15.232580 125536568714752 run.py:688] Algo activity_selector step 3450 current loss 0.560445, current_train_items 137392.
I0715 07:28:15.254488 125536568714752 run.py:723] (val) algo activity_selector step 3450: {'selected': 0.9448529411764707, 'score': 0.9448529411764707, 'examples_seen': 137392, 'step': 3450, 'algorithm': 'activity_selector'}
I0715 07:28:15.254637 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0715 07:28:16.264538 125536568714752 run.py:688] Algo activity_selector step 3500 current loss 0.080991, current_train_items 139424.
I0715 07:28:16.286918 125536568714752 run.py:723] (val) algo activity_selector step 3500: {'selected': 0.9635627530364373, 'score': 0.9635627530364373, 'examples_seen': 139424, 'step': 3500, 'algorithm': 'activity_selector'}
I0715 07:28:16.287067 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0715 07:28:17.297470 125536568714752 run.py:688] Algo activity_selector step 3550 current loss 1.071327, current_train_items 141408.
I0715 07:28:17.321592 125536568714752 run.py:723] (val) algo activity_selector step 3550: {'selected': 0.9628180039138943, 'score': 0.9628180039138943, 'examples_seen': 141408, 'step': 3550, 'algorithm': 'activity_selector'}
I0715 07:28:17.321742 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0715 07:28:18.304944 125536568714752 run.py:688] Algo activity_selector step 3600 current loss 0.356956, current_train_items 143392.
I0715 07:28:18.329847 125536568714752 run.py:723] (val) algo activity_selector step 3600: {'selected': 0.9351669941060905, 'score': 0.9351669941060905, 'examples_seen': 143392, 'step': 3600, 'algorithm': 'activity_selector'}
I0715 07:28:18.329992 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0715 07:28:19.327155 125536568714752 run.py:688] Algo activity_selector step 3650 current loss 0.595840, current_train_items 145360.
I0715 07:28:19.355063 125536568714752 run.py:723] (val) algo activity_selector step 3650: {'selected': 0.9398496240601504, 'score': 0.9398496240601504, 'examples_seen': 145360, 'step': 3650, 'algorithm': 'activity_selector'}
I0715 07:28:19.355210 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0715 07:28:20.337135 125536568714752 run.py:688] Algo activity_selector step 3700 current loss 2.413927, current_train_items 147312.
I0715 07:28:20.367915 125536568714752 run.py:723] (val) algo activity_selector step 3700: {'selected': 0.9325842696629214, 'score': 0.9325842696629214, 'examples_seen': 147312, 'step': 3700, 'algorithm': 'activity_selector'}
I0715 07:28:20.368061 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0715 07:28:21.353550 125536568714752 run.py:688] Algo activity_selector step 3750 current loss 2.149816, current_train_items 149312.
I0715 07:28:21.386033 125536568714752 run.py:723] (val) algo activity_selector step 3750: {'selected': 0.942528735632184, 'score': 0.942528735632184, 'examples_seen': 149312, 'step': 3750, 'algorithm': 'activity_selector'}
I0715 07:28:21.386182 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0715 07:28:22.393604 125536568714752 run.py:688] Algo activity_selector step 3800 current loss 0.367375, current_train_items 151328.
I0715 07:28:22.416064 125536568714752 run.py:723] (val) algo activity_selector step 3800: {'selected': 0.8917910447761195, 'score': 0.8917910447761195, 'examples_seen': 151328, 'step': 3800, 'algorithm': 'activity_selector'}
I0715 07:28:22.416213 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.892, val scores are: activity_selector: 0.892
I0715 07:28:23.419626 125536568714752 run.py:688] Algo activity_selector step 3850 current loss 0.180131, current_train_items 153344.
I0715 07:28:23.442591 125536568714752 run.py:723] (val) algo activity_selector step 3850: {'selected': 0.957169459962756, 'score': 0.957169459962756, 'examples_seen': 153344, 'step': 3850, 'algorithm': 'activity_selector'}
I0715 07:28:23.442736 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0715 07:28:24.440299 125536568714752 run.py:688] Algo activity_selector step 3900 current loss 0.401029, current_train_items 155344.
I0715 07:28:24.464098 125536568714752 run.py:723] (val) algo activity_selector step 3900: {'selected': 0.9516441005802707, 'score': 0.9516441005802707, 'examples_seen': 155344, 'step': 3900, 'algorithm': 'activity_selector'}
I0715 07:28:24.464245 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0715 07:28:25.457617 125536568714752 run.py:688] Algo activity_selector step 3950 current loss 0.722188, current_train_items 157312.
I0715 07:28:25.483072 125536568714752 run.py:723] (val) algo activity_selector step 3950: {'selected': 0.9100917431192661, 'score': 0.9100917431192661, 'examples_seen': 157312, 'step': 3950, 'algorithm': 'activity_selector'}
I0715 07:28:25.483219 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.910, val scores are: activity_selector: 0.910
I0715 07:28:26.473227 125536568714752 run.py:688] Algo activity_selector step 4000 current loss 1.383371, current_train_items 159312.
I0715 07:28:26.500677 125536568714752 run.py:723] (val) algo activity_selector step 4000: {'selected': 0.9610894941634242, 'score': 0.9610894941634242, 'examples_seen': 159312, 'step': 4000, 'algorithm': 'activity_selector'}
I0715 07:28:26.500825 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0715 07:28:27.487930 125536568714752 run.py:688] Algo activity_selector step 4050 current loss 1.620370, current_train_items 161248.
I0715 07:28:27.518416 125536568714752 run.py:723] (val) algo activity_selector step 4050: {'selected': 0.9558232931726908, 'score': 0.9558232931726908, 'examples_seen': 161248, 'step': 4050, 'algorithm': 'activity_selector'}
I0715 07:28:27.518575 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0715 07:28:28.516519 125536568714752 run.py:688] Algo activity_selector step 4100 current loss 2.168137, current_train_items 163216.
I0715 07:28:28.549649 125536568714752 run.py:723] (val) algo activity_selector step 4100: {'selected': 0.9578544061302682, 'score': 0.9578544061302682, 'examples_seen': 163216, 'step': 4100, 'algorithm': 'activity_selector'}
I0715 07:28:28.549794 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0715 07:28:29.556673 125536568714752 run.py:688] Algo activity_selector step 4150 current loss 0.158770, current_train_items 165280.
I0715 07:28:29.578707 125536568714752 run.py:723] (val) algo activity_selector step 4150: {'selected': 0.9338677354709418, 'score': 0.9338677354709418, 'examples_seen': 165280, 'step': 4150, 'algorithm': 'activity_selector'}
I0715 07:28:29.578853 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0715 07:28:30.583180 125536568714752 run.py:688] Algo activity_selector step 4200 current loss 0.086484, current_train_items 167264.
I0715 07:28:30.606288 125536568714752 run.py:723] (val) algo activity_selector step 4200: {'selected': 0.9676190476190475, 'score': 0.9676190476190475, 'examples_seen': 167264, 'step': 4200, 'algorithm': 'activity_selector'}
I0715 07:28:30.606437 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0715 07:28:31.608606 125536568714752 run.py:688] Algo activity_selector step 4250 current loss 1.029706, current_train_items 169280.
I0715 07:28:31.632181 125536568714752 run.py:723] (val) algo activity_selector step 4250: {'selected': 0.9581749049429658, 'score': 0.9581749049429658, 'examples_seen': 169280, 'step': 4250, 'algorithm': 'activity_selector'}
I0715 07:28:31.632329 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0715 07:28:32.619788 125536568714752 run.py:688] Algo activity_selector step 4300 current loss 0.347481, current_train_items 171248.
I0715 07:28:32.644876 125536568714752 run.py:723] (val) algo activity_selector step 4300: {'selected': 0.9662921348314607, 'score': 0.9662921348314607, 'examples_seen': 171248, 'step': 4300, 'algorithm': 'activity_selector'}
I0715 07:28:32.645027 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0715 07:28:33.643348 125536568714752 run.py:688] Algo activity_selector step 4350 current loss 2.323583, current_train_items 173216.
I0715 07:28:33.670864 125536568714752 run.py:723] (val) algo activity_selector step 4350: {'selected': 0.9598393574297188, 'score': 0.9598393574297188, 'examples_seen': 173216, 'step': 4350, 'algorithm': 'activity_selector'}
I0715 07:28:33.671017 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0715 07:28:34.646507 125536568714752 run.py:688] Algo activity_selector step 4400 current loss 1.371078, current_train_items 175232.
I0715 07:28:34.676198 125536568714752 run.py:723] (val) algo activity_selector step 4400: {'selected': 0.9435483870967742, 'score': 0.9435483870967742, 'examples_seen': 175232, 'step': 4400, 'algorithm': 'activity_selector'}
I0715 07:28:34.676345 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0715 07:28:35.678866 125536568714752 run.py:688] Algo activity_selector step 4450 current loss 1.870872, current_train_items 177168.
I0715 07:28:35.712529 125536568714752 run.py:723] (val) algo activity_selector step 4450: {'selected': 0.962962962962963, 'score': 0.962962962962963, 'examples_seen': 177168, 'step': 4450, 'algorithm': 'activity_selector'}
I0715 07:28:35.712690 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0715 07:28:36.724911 125536568714752 run.py:688] Algo activity_selector step 4500 current loss 0.478593, current_train_items 179216.
I0715 07:28:36.747188 125536568714752 run.py:723] (val) algo activity_selector step 4500: {'selected': 0.976190476190476, 'score': 0.976190476190476, 'examples_seen': 179216, 'step': 4500, 'algorithm': 'activity_selector'}
I0715 07:28:36.747334 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0715 07:28:37.739516 125536568714752 run.py:688] Algo activity_selector step 4550 current loss 0.273881, current_train_items 181232.
I0715 07:28:37.762659 125536568714752 run.py:723] (val) algo activity_selector step 4550: {'selected': 0.9752380952380952, 'score': 0.9752380952380952, 'examples_seen': 181232, 'step': 4550, 'algorithm': 'activity_selector'}
I0715 07:28:37.762808 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0715 07:28:38.772900 125536568714752 run.py:688] Algo activity_selector step 4600 current loss 1.277720, current_train_items 183216.
I0715 07:28:38.796787 125536568714752 run.py:723] (val) algo activity_selector step 4600: {'selected': 0.9471624266144814, 'score': 0.9471624266144814, 'examples_seen': 183216, 'step': 4600, 'algorithm': 'activity_selector'}
I0715 07:28:38.796932 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0715 07:28:39.773314 125536568714752 run.py:688] Algo activity_selector step 4650 current loss 0.275772, current_train_items 185200.
I0715 07:28:39.798586 125536568714752 run.py:723] (val) algo activity_selector step 4650: {'selected': 0.9483747609942638, 'score': 0.9483747609942638, 'examples_seen': 185200, 'step': 4650, 'algorithm': 'activity_selector'}
I0715 07:28:39.798733 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0715 07:28:40.803387 125536568714752 run.py:688] Algo activity_selector step 4700 current loss 0.364305, current_train_items 187168.
I0715 07:28:40.831401 125536568714752 run.py:723] (val) algo activity_selector step 4700: {'selected': 0.9421157684630739, 'score': 0.9421157684630739, 'examples_seen': 187168, 'step': 4700, 'algorithm': 'activity_selector'}
I0715 07:28:40.831559 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0715 07:28:41.832122 125536568714752 run.py:688] Algo activity_selector step 4750 current loss 0.446400, current_train_items 189136.
I0715 07:28:41.863605 125536568714752 run.py:723] (val) algo activity_selector step 4750: {'selected': 0.9375, 'score': 0.9375, 'examples_seen': 189136, 'step': 4750, 'algorithm': 'activity_selector'}
I0715 07:28:41.863753 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0715 07:28:42.842879 125536568714752 run.py:688] Algo activity_selector step 4800 current loss 1.892337, current_train_items 191120.
I0715 07:28:42.876377 125536568714752 run.py:723] (val) algo activity_selector step 4800: {'selected': 0.96, 'score': 0.96, 'examples_seen': 191120, 'step': 4800, 'algorithm': 'activity_selector'}
I0715 07:28:42.876536 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.983, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0715 07:28:43.894102 125536568714752 run.py:688] Algo activity_selector step 4850 current loss 0.317798, current_train_items 193136.
I0715 07:28:43.916276 125536568714752 run.py:723] (val) algo activity_selector step 4850: {'selected': 0.9870609981515711, 'score': 0.9870609981515711, 'examples_seen': 193136, 'step': 4850, 'algorithm': 'activity_selector'}
I0715 07:28:43.916421 125536568714752 run.py:744] Checkpointing best model, best avg val score was 0.983, current avg val score is 0.987, val scores are: activity_selector: 0.987
I0715 07:28:44.925562 125536568714752 run.py:688] Algo activity_selector step 4900 current loss 0.183688, current_train_items 195152.
I0715 07:28:44.949422 125536568714752 run.py:723] (val) algo activity_selector step 4900: {'selected': 0.9786407766990292, 'score': 0.9786407766990292, 'examples_seen': 195152, 'step': 4900, 'algorithm': 'activity_selector'}
I0715 07:28:44.949579 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.979, val scores are: activity_selector: 0.979
I0715 07:28:45.947528 125536568714752 run.py:688] Algo activity_selector step 4950 current loss 0.670581, current_train_items 197152.
I0715 07:28:45.971810 125536568714752 run.py:723] (val) algo activity_selector step 4950: {'selected': 0.9151873767258383, 'score': 0.9151873767258383, 'examples_seen': 197152, 'step': 4950, 'algorithm': 'activity_selector'}
I0715 07:28:45.971955 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.915, val scores are: activity_selector: 0.915
I0715 07:28:46.967040 125536568714752 run.py:688] Algo activity_selector step 5000 current loss 0.299059, current_train_items 199120.
I0715 07:28:46.991991 125536568714752 run.py:723] (val) algo activity_selector step 5000: {'selected': 0.9587426326129665, 'score': 0.9587426326129665, 'examples_seen': 199120, 'step': 5000, 'algorithm': 'activity_selector'}
I0715 07:28:46.992137 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0715 07:28:47.980818 125536568714752 run.py:688] Algo activity_selector step 5050 current loss 1.315425, current_train_items 201120.
I0715 07:28:48.011558 125536568714752 run.py:723] (val) algo activity_selector step 5050: {'selected': 0.9593810444874274, 'score': 0.9593810444874274, 'examples_seen': 201120, 'step': 5050, 'algorithm': 'activity_selector'}
I0715 07:28:48.011706 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0715 07:28:49.016899 125536568714752 run.py:688] Algo activity_selector step 5100 current loss 2.764893, current_train_items 203072.
I0715 07:28:49.046303 125536568714752 run.py:723] (val) algo activity_selector step 5100: {'selected': 0.9529190207156308, 'score': 0.9529190207156308, 'examples_seen': 203072, 'step': 5100, 'algorithm': 'activity_selector'}
I0715 07:28:49.046450 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0715 07:28:50.030766 125536568714752 run.py:688] Algo activity_selector step 5150 current loss 1.944916, current_train_items 205024.
I0715 07:28:50.063573 125536568714752 run.py:723] (val) algo activity_selector step 5150: {'selected': 0.959016393442623, 'score': 0.959016393442623, 'examples_seen': 205024, 'step': 5150, 'algorithm': 'activity_selector'}
I0715 07:28:50.063719 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0715 07:28:51.073090 125536568714752 run.py:688] Algo activity_selector step 5200 current loss 0.205556, current_train_items 207088.
I0715 07:28:51.095613 125536568714752 run.py:723] (val) algo activity_selector step 5200: {'selected': 0.9623762376237623, 'score': 0.9623762376237623, 'examples_seen': 207088, 'step': 5200, 'algorithm': 'activity_selector'}
I0715 07:28:51.095782 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0715 07:28:52.102285 125536568714752 run.py:688] Algo activity_selector step 5250 current loss 0.357204, current_train_items 209072.
I0715 07:28:52.126474 125536568714752 run.py:723] (val) algo activity_selector step 5250: {'selected': 0.939622641509434, 'score': 0.939622641509434, 'examples_seen': 209072, 'step': 5250, 'algorithm': 'activity_selector'}
I0715 07:28:52.126626 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0715 07:28:53.120136 125536568714752 run.py:688] Algo activity_selector step 5300 current loss 1.027572, current_train_items 211088.
I0715 07:28:53.144505 125536568714752 run.py:723] (val) algo activity_selector step 5300: {'selected': 0.9503816793893128, 'score': 0.9503816793893128, 'examples_seen': 211088, 'step': 5300, 'algorithm': 'activity_selector'}
I0715 07:28:53.144653 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0715 07:28:54.136782 125536568714752 run.py:688] Algo activity_selector step 5350 current loss 0.219737, current_train_items 213072.
I0715 07:28:54.161528 125536568714752 run.py:723] (val) algo activity_selector step 5350: {'selected': 0.9601518026565464, 'score': 0.9601518026565464, 'examples_seen': 213072, 'step': 5350, 'algorithm': 'activity_selector'}
I0715 07:28:54.161674 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0715 07:28:55.161193 125536568714752 run.py:688] Algo activity_selector step 5400 current loss 2.014821, current_train_items 215024.
I0715 07:28:55.189442 125536568714752 run.py:723] (val) algo activity_selector step 5400: {'selected': 0.9633911368015414, 'score': 0.9633911368015414, 'examples_seen': 215024, 'step': 5400, 'algorithm': 'activity_selector'}
I0715 07:28:55.189597 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0715 07:28:56.179833 125536568714752 run.py:688] Algo activity_selector step 5450 current loss 2.277768, current_train_items 217024.
I0715 07:28:56.209506 125536568714752 run.py:723] (val) algo activity_selector step 5450: {'selected': 0.9604743083003953, 'score': 0.9604743083003953, 'examples_seen': 217024, 'step': 5450, 'algorithm': 'activity_selector'}
I0715 07:28:56.209652 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0715 07:28:57.207431 125536568714752 run.py:688] Algo activity_selector step 5500 current loss 1.688207, current_train_items 218960.
I0715 07:28:57.240508 125536568714752 run.py:723] (val) algo activity_selector step 5500: {'selected': 0.9155722326454033, 'score': 0.9155722326454033, 'examples_seen': 218960, 'step': 5500, 'algorithm': 'activity_selector'}
I0715 07:28:57.240656 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.916, val scores are: activity_selector: 0.916
I0715 07:28:58.257591 125536568714752 run.py:688] Algo activity_selector step 5550 current loss 0.370665, current_train_items 221008.
I0715 07:28:58.280181 125536568714752 run.py:723] (val) algo activity_selector step 5550: {'selected': 0.9416342412451363, 'score': 0.9416342412451363, 'examples_seen': 221008, 'step': 5550, 'algorithm': 'activity_selector'}
I0715 07:28:58.280332 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0715 07:28:59.278734 125536568714752 run.py:688] Algo activity_selector step 5600 current loss 0.161777, current_train_items 223024.
I0715 07:28:59.301645 125536568714752 run.py:723] (val) algo activity_selector step 5600: {'selected': 0.937984496124031, 'score': 0.937984496124031, 'examples_seen': 223024, 'step': 5600, 'algorithm': 'activity_selector'}
I0715 07:28:59.301805 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0715 07:29:00.317322 125536568714752 run.py:688] Algo activity_selector step 5650 current loss 1.209369, current_train_items 225008.
I0715 07:29:00.341113 125536568714752 run.py:723] (val) algo activity_selector step 5650: {'selected': 0.9724409448818898, 'score': 0.9724409448818898, 'examples_seen': 225008, 'step': 5650, 'algorithm': 'activity_selector'}
I0715 07:29:00.341259 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0715 07:29:01.335063 125536568714752 run.py:688] Algo activity_selector step 5700 current loss 0.433356, current_train_items 227008.
I0715 07:29:01.361510 125536568714752 run.py:723] (val) algo activity_selector step 5700: {'selected': 0.9418386491557224, 'score': 0.9418386491557224, 'examples_seen': 227008, 'step': 5700, 'algorithm': 'activity_selector'}
I0715 07:29:01.361655 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0715 07:29:02.358298 125536568714752 run.py:688] Algo activity_selector step 5750 current loss 0.324456, current_train_items 228960.
I0715 07:29:02.386392 125536568714752 run.py:723] (val) algo activity_selector step 5750: {'selected': 0.9672447013487475, 'score': 0.9672447013487475, 'examples_seen': 228960, 'step': 5750, 'algorithm': 'activity_selector'}
I0715 07:29:02.386546 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0715 07:29:03.385949 125536568714752 run.py:688] Algo activity_selector step 5800 current loss 2.228402, current_train_items 230928.
I0715 07:29:03.415164 125536568714752 run.py:723] (val) algo activity_selector step 5800: {'selected': 0.9676190476190475, 'score': 0.9676190476190475, 'examples_seen': 230928, 'step': 5800, 'algorithm': 'activity_selector'}
I0715 07:29:03.415312 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0715 07:29:04.397382 125536568714752 run.py:688] Algo activity_selector step 5850 current loss 2.060677, current_train_items 232912.
I0715 07:29:04.430245 125536568714752 run.py:723] (val) algo activity_selector step 5850: {'selected': 0.963531669865643, 'score': 0.963531669865643, 'examples_seen': 232912, 'step': 5850, 'algorithm': 'activity_selector'}
I0715 07:29:04.430391 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0715 07:29:05.452668 125536568714752 run.py:688] Algo activity_selector step 5900 current loss 0.331432, current_train_items 234928.
I0715 07:29:05.475290 125536568714752 run.py:723] (val) algo activity_selector step 5900: {'selected': 0.9492187500000001, 'score': 0.9492187500000001, 'examples_seen': 234928, 'step': 5900, 'algorithm': 'activity_selector'}
I0715 07:29:05.475441 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0715 07:29:06.470312 125536568714752 run.py:688] Algo activity_selector step 5950 current loss 0.098606, current_train_items 236944.
I0715 07:29:06.493262 125536568714752 run.py:723] (val) algo activity_selector step 5950: {'selected': 0.9364161849710982, 'score': 0.9364161849710982, 'examples_seen': 236944, 'step': 5950, 'algorithm': 'activity_selector'}
I0715 07:29:06.493433 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0715 07:29:07.512368 125536568714752 run.py:688] Algo activity_selector step 6000 current loss 0.146924, current_train_items 238944.
I0715 07:29:07.535716 125536568714752 run.py:723] (val) algo activity_selector step 6000: {'selected': 0.9328214971209214, 'score': 0.9328214971209214, 'examples_seen': 238944, 'step': 6000, 'algorithm': 'activity_selector'}
I0715 07:29:07.535865 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0715 07:29:08.541349 125536568714752 run.py:688] Algo activity_selector step 6050 current loss 0.261537, current_train_items 240928.
I0715 07:29:08.567395 125536568714752 run.py:723] (val) algo activity_selector step 6050: {'selected': 0.9660678642714571, 'score': 0.9660678642714571, 'examples_seen': 240928, 'step': 6050, 'algorithm': 'activity_selector'}
I0715 07:29:08.567555 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0715 07:29:09.549268 125536568714752 run.py:688] Algo activity_selector step 6100 current loss 1.445272, current_train_items 242912.
I0715 07:29:09.577538 125536568714752 run.py:723] (val) algo activity_selector step 6100: {'selected': 0.977859778597786, 'score': 0.977859778597786, 'examples_seen': 242912, 'step': 6100, 'algorithm': 'activity_selector'}
I0715 07:29:09.577685 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.978, val scores are: activity_selector: 0.978
I0715 07:29:10.580276 125536568714752 run.py:688] Algo activity_selector step 6150 current loss 1.805787, current_train_items 244864.
I0715 07:29:10.610237 125536568714752 run.py:723] (val) algo activity_selector step 6150: {'selected': 0.9601518026565464, 'score': 0.9601518026565464, 'examples_seen': 244864, 'step': 6150, 'algorithm': 'activity_selector'}
I0715 07:29:10.610383 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0715 07:29:11.585367 125536568714752 run.py:688] Algo activity_selector step 6200 current loss 1.202644, current_train_items 246816.
I0715 07:29:11.618471 125536568714752 run.py:723] (val) algo activity_selector step 6200: {'selected': 0.9717514124293786, 'score': 0.9717514124293786, 'examples_seen': 246816, 'step': 6200, 'algorithm': 'activity_selector'}
I0715 07:29:11.618626 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0715 07:29:12.632530 125536568714752 run.py:688] Algo activity_selector step 6250 current loss 0.049561, current_train_items 248880.
I0715 07:29:12.655054 125536568714752 run.py:723] (val) algo activity_selector step 6250: {'selected': 0.9775280898876405, 'score': 0.9775280898876405, 'examples_seen': 248880, 'step': 6250, 'algorithm': 'activity_selector'}
I0715 07:29:12.655201 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.978, val scores are: activity_selector: 0.978
I0715 07:29:13.649832 125536568714752 run.py:688] Algo activity_selector step 6300 current loss 0.173415, current_train_items 250880.
I0715 07:29:13.672289 125536568714752 run.py:723] (val) algo activity_selector step 6300: {'selected': 0.946058091286307, 'score': 0.946058091286307, 'examples_seen': 250880, 'step': 6300, 'algorithm': 'activity_selector'}
I0715 07:29:13.672440 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0715 07:29:14.662711 125536568714752 run.py:688] Algo activity_selector step 6350 current loss 1.028406, current_train_items 252880.
I0715 07:29:14.686516 125536568714752 run.py:723] (val) algo activity_selector step 6350: {'selected': 0.9809885931558935, 'score': 0.9809885931558935, 'examples_seen': 252880, 'step': 6350, 'algorithm': 'activity_selector'}
I0715 07:29:14.686675 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0715 07:29:15.679059 125536568714752 run.py:688] Algo activity_selector step 6400 current loss 0.201028, current_train_items 254864.
I0715 07:29:15.704431 125536568714752 run.py:723] (val) algo activity_selector step 6400: {'selected': 0.9622266401590457, 'score': 0.9622266401590457, 'examples_seen': 254864, 'step': 6400, 'algorithm': 'activity_selector'}
I0715 07:29:15.704582 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0715 07:29:16.688060 125536568714752 run.py:688] Algo activity_selector step 6450 current loss 2.291195, current_train_items 256816.
I0715 07:29:16.716001 125536568714752 run.py:723] (val) algo activity_selector step 6450: {'selected': 0.9418386491557222, 'score': 0.9418386491557222, 'examples_seen': 256816, 'step': 6450, 'algorithm': 'activity_selector'}
I0715 07:29:16.716151 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0715 07:29:17.711237 125536568714752 run.py:688] Algo activity_selector step 6500 current loss 1.714777, current_train_items 258816.
I0715 07:29:17.740876 125536568714752 run.py:723] (val) algo activity_selector step 6500: {'selected': 0.9784735812133072, 'score': 0.9784735812133072, 'examples_seen': 258816, 'step': 6500, 'algorithm': 'activity_selector'}
I0715 07:29:17.741023 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.978, val scores are: activity_selector: 0.978
I0715 07:29:18.729090 125536568714752 run.py:688] Algo activity_selector step 6550 current loss 1.391453, current_train_items 260752.
I0715 07:29:18.761884 125536568714752 run.py:723] (val) algo activity_selector step 6550: {'selected': 0.9689213893967094, 'score': 0.9689213893967094, 'examples_seen': 260752, 'step': 6550, 'algorithm': 'activity_selector'}
I0715 07:29:18.762030 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0715 07:29:19.769276 125536568714752 run.py:688] Algo activity_selector step 6600 current loss 0.411265, current_train_items 262800.
I0715 07:29:19.791574 125536568714752 run.py:723] (val) algo activity_selector step 6600: {'selected': 0.9439421338155515, 'score': 0.9439421338155515, 'examples_seen': 262800, 'step': 6600, 'algorithm': 'activity_selector'}
I0715 07:29:19.791721 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0715 07:29:20.799334 125536568714752 run.py:688] Algo activity_selector step 6650 current loss 0.072286, current_train_items 264832.
I0715 07:29:20.822628 125536568714752 run.py:723] (val) algo activity_selector step 6650: {'selected': 0.9803149606299214, 'score': 0.9803149606299214, 'examples_seen': 264832, 'step': 6650, 'algorithm': 'activity_selector'}
I0715 07:29:20.822777 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.980, val scores are: activity_selector: 0.980
I0715 07:29:21.819076 125536568714752 run.py:688] Algo activity_selector step 6700 current loss 1.031833, current_train_items 266800.
I0715 07:29:21.842656 125536568714752 run.py:723] (val) algo activity_selector step 6700: {'selected': 0.9549902152641878, 'score': 0.9549902152641878, 'examples_seen': 266800, 'step': 6700, 'algorithm': 'activity_selector'}
I0715 07:29:21.842802 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0715 07:29:22.839621 125536568714752 run.py:688] Algo activity_selector step 6750 current loss 0.185183, current_train_items 268800.
I0715 07:29:22.864799 125536568714752 run.py:723] (val) algo activity_selector step 6750: {'selected': 0.9572953736654805, 'score': 0.9572953736654805, 'examples_seen': 268800, 'step': 6750, 'algorithm': 'activity_selector'}
I0715 07:29:22.864947 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0715 07:29:23.852929 125536568714752 run.py:688] Algo activity_selector step 6800 current loss 0.416192, current_train_items 270752.
I0715 07:29:23.881691 125536568714752 run.py:723] (val) algo activity_selector step 6800: {'selected': 0.963531669865643, 'score': 0.963531669865643, 'examples_seen': 270752, 'step': 6800, 'algorithm': 'activity_selector'}
I0715 07:29:23.881838 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0715 07:29:24.875111 125536568714752 run.py:688] Algo activity_selector step 6850 current loss 1.589828, current_train_items 272736.
I0715 07:29:24.904923 125536568714752 run.py:723] (val) algo activity_selector step 6850: {'selected': 0.9607843137254902, 'score': 0.9607843137254902, 'examples_seen': 272736, 'step': 6850, 'algorithm': 'activity_selector'}
I0715 07:29:24.905071 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0715 07:29:25.882462 125536568714752 run.py:688] Algo activity_selector step 6900 current loss 0.349085, current_train_items 274720.
I0715 07:29:25.915826 125536568714752 run.py:723] (val) algo activity_selector step 6900: {'selected': 0.946360153256705, 'score': 0.946360153256705, 'examples_seen': 274720, 'step': 6900, 'algorithm': 'activity_selector'}
I0715 07:29:25.915973 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0715 07:29:26.932582 125536568714752 run.py:688] Algo activity_selector step 6950 current loss 0.315462, current_train_items 276736.
I0715 07:29:26.955321 125536568714752 run.py:723] (val) algo activity_selector step 6950: {'selected': 0.9672447013487475, 'score': 0.9672447013487475, 'examples_seen': 276736, 'step': 6950, 'algorithm': 'activity_selector'}
I0715 07:29:26.955467 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0715 07:29:27.982093 125536568714752 run.py:688] Algo activity_selector step 7000 current loss 0.276420, current_train_items 278768.
I0715 07:29:28.004845 125536568714752 run.py:723] (val) algo activity_selector step 7000: {'selected': 0.9848484848484849, 'score': 0.9848484848484849, 'examples_seen': 278768, 'step': 7000, 'algorithm': 'activity_selector'}
I0715 07:29:28.004992 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.985, val scores are: activity_selector: 0.985
I0715 07:29:28.989356 125536568714752 run.py:688] Algo activity_selector step 7050 current loss 0.165807, current_train_items 280752.
I0715 07:29:29.014243 125536568714752 run.py:723] (val) algo activity_selector step 7050: {'selected': 0.9695740365111561, 'score': 0.9695740365111561, 'examples_seen': 280752, 'step': 7050, 'algorithm': 'activity_selector'}
I0715 07:29:29.014395 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0715 07:29:30.015396 125536568714752 run.py:688] Algo activity_selector step 7100 current loss 0.227668, current_train_items 282736.
I0715 07:29:30.040120 125536568714752 run.py:723] (val) algo activity_selector step 7100: {'selected': 0.9612403100775193, 'score': 0.9612403100775193, 'examples_seen': 282736, 'step': 7100, 'algorithm': 'activity_selector'}
I0715 07:29:30.040268 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0715 07:29:31.016043 125536568714752 run.py:688] Algo activity_selector step 7150 current loss 1.461060, current_train_items 284720.
I0715 07:29:31.045521 125536568714752 run.py:723] (val) algo activity_selector step 7150: {'selected': 0.9551656920077973, 'score': 0.9551656920077973, 'examples_seen': 284720, 'step': 7150, 'algorithm': 'activity_selector'}
I0715 07:29:31.045669 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0715 07:29:32.051083 125536568714752 run.py:688] Algo activity_selector step 7200 current loss 0.226403, current_train_items 286672.
I0715 07:29:32.081333 125536568714752 run.py:723] (val) algo activity_selector step 7200: {'selected': 0.9498069498069499, 'score': 0.9498069498069499, 'examples_seen': 286672, 'step': 7200, 'algorithm': 'activity_selector'}
I0715 07:29:32.081486 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0715 07:29:33.078022 125536568714752 run.py:688] Algo activity_selector step 7250 current loss 4.161322, current_train_items 288640.
I0715 07:29:33.118203 125536568714752 run.py:723] (val) algo activity_selector step 7250: {'selected': 0.9622641509433963, 'score': 0.9622641509433963, 'examples_seen': 288640, 'step': 7250, 'algorithm': 'activity_selector'}
I0715 07:29:33.118352 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0715 07:29:34.124209 125536568714752 run.py:688] Algo activity_selector step 7300 current loss 0.592240, current_train_items 290688.
I0715 07:29:34.146617 125536568714752 run.py:723] (val) algo activity_selector step 7300: {'selected': 0.946788990825688, 'score': 0.946788990825688, 'examples_seen': 290688, 'step': 7300, 'algorithm': 'activity_selector'}
I0715 07:29:34.146766 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0715 07:29:35.153959 125536568714752 run.py:688] Algo activity_selector step 7350 current loss 0.160706, current_train_items 292688.
I0715 07:29:35.176687 125536568714752 run.py:723] (val) algo activity_selector step 7350: {'selected': 0.9548133595284872, 'score': 0.9548133595284872, 'examples_seen': 292688, 'step': 7350, 'algorithm': 'activity_selector'}
I0715 07:29:35.176835 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0715 07:29:36.160606 125536568714752 run.py:688] Algo activity_selector step 7400 current loss 0.874026, current_train_items 294688.
I0715 07:29:36.184328 125536568714752 run.py:723] (val) algo activity_selector step 7400: {'selected': 0.9616161616161616, 'score': 0.9616161616161616, 'examples_seen': 294688, 'step': 7400, 'algorithm': 'activity_selector'}
I0715 07:29:36.184476 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0715 07:29:37.180997 125536568714752 run.py:688] Algo activity_selector step 7450 current loss 0.165921, current_train_items 296672.
I0715 07:29:37.206091 125536568714752 run.py:723] (val) algo activity_selector step 7450: {'selected': 0.9764705882352941, 'score': 0.9764705882352941, 'examples_seen': 296672, 'step': 7450, 'algorithm': 'activity_selector'}
I0715 07:29:37.206235 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0715 07:29:38.209466 125536568714752 run.py:688] Algo activity_selector step 7500 current loss 2.015741, current_train_items 298624.
I0715 07:29:38.237435 125536568714752 run.py:723] (val) algo activity_selector step 7500: {'selected': 0.9688715953307393, 'score': 0.9688715953307393, 'examples_seen': 298624, 'step': 7500, 'algorithm': 'activity_selector'}
I0715 07:29:38.237602 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.987, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0715 07:29:39.222356 125536568714752 run.py:688] Algo activity_selector step 7550 current loss 5.315780, current_train_items 300624.
I0715 07:29:39.252002 125536568714752 run.py:723] (val) algo activity_selector step 7550: {'selected': 0.9878542510121457, 'score': 0.9878542510121457, 'examples_seen': 300624, 'step': 7550, 'algorithm': 'activity_selector'}
I0715 07:29:39.252151 125536568714752 run.py:744] Checkpointing best model, best avg val score was 0.987, current avg val score is 0.988, val scores are: activity_selector: 0.988
I0715 07:29:40.263743 125536568714752 run.py:688] Algo activity_selector step 7600 current loss 3.756141, current_train_items 302576.
I0715 07:29:40.296892 125536568714752 run.py:723] (val) algo activity_selector step 7600: {'selected': 0.9788053949903661, 'score': 0.9788053949903661, 'examples_seen': 302576, 'step': 7600, 'algorithm': 'activity_selector'}
I0715 07:29:40.297038 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.988, current avg val score is 0.979, val scores are: activity_selector: 0.979
I0715 07:29:41.293504 125536568714752 run.py:688] Algo activity_selector step 7650 current loss 0.424120, current_train_items 304608.
I0715 07:29:41.315881 125536568714752 run.py:723] (val) algo activity_selector step 7650: {'selected': 0.9591836734693877, 'score': 0.9591836734693877, 'examples_seen': 304608, 'step': 7650, 'algorithm': 'activity_selector'}
I0715 07:29:41.316030 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.988, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0715 07:29:42.320117 125536568714752 run.py:688] Algo activity_selector step 7700 current loss 0.232427, current_train_items 306640.
I0715 07:29:42.342800 125536568714752 run.py:723] (val) algo activity_selector step 7700: {'selected': 0.9490835030549899, 'score': 0.9490835030549899, 'examples_seen': 306640, 'step': 7700, 'algorithm': 'activity_selector'}
I0715 07:29:42.342947 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.988, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0715 07:29:43.341499 125536568714752 run.py:688] Algo activity_selector step 7750 current loss 0.808756, current_train_items 308608.
I0715 07:29:43.367663 125536568714752 run.py:723] (val) algo activity_selector step 7750: {'selected': 0.9294755877034359, 'score': 0.9294755877034359, 'examples_seen': 308608, 'step': 7750, 'algorithm': 'activity_selector'}
I0715 07:29:43.367810 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.988, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0715 07:29:44.351462 125536568714752 run.py:688] Algo activity_selector step 7800 current loss 0.140325, current_train_items 310608.
I0715 07:29:44.376754 125536568714752 run.py:723] (val) algo activity_selector step 7800: {'selected': 0.9079754601226994, 'score': 0.9079754601226994, 'examples_seen': 310608, 'step': 7800, 'algorithm': 'activity_selector'}
I0715 07:29:44.376903 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.988, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0715 07:29:45.360868 125536568714752 run.py:688] Algo activity_selector step 7850 current loss 0.408048, current_train_items 312576.
I0715 07:29:45.388969 125536568714752 run.py:723] (val) algo activity_selector step 7850: {'selected': 0.9886363636363636, 'score': 0.9886363636363636, 'examples_seen': 312576, 'step': 7850, 'algorithm': 'activity_selector'}
I0715 07:29:45.389114 125536568714752 run.py:744] Checkpointing best model, best avg val score was 0.988, current avg val score is 0.989, val scores are: activity_selector: 0.989
I0715 07:29:46.392364 125536568714752 run.py:688] Algo activity_selector step 7900 current loss 2.296389, current_train_items 314528.
I0715 07:29:46.422052 125536568714752 run.py:723] (val) algo activity_selector step 7900: {'selected': 0.9669902912621359, 'score': 0.9669902912621359, 'examples_seen': 314528, 'step': 7900, 'algorithm': 'activity_selector'}
I0715 07:29:46.422197 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0715 07:29:47.407970 125536568714752 run.py:688] Algo activity_selector step 7950 current loss 3.113862, current_train_items 316528.
I0715 07:29:47.441116 125536568714752 run.py:723] (val) algo activity_selector step 7950: {'selected': 0.962432915921288, 'score': 0.962432915921288, 'examples_seen': 316528, 'step': 7950, 'algorithm': 'activity_selector'}
I0715 07:29:47.441262 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0715 07:29:48.451604 125536568714752 run.py:688] Algo activity_selector step 8000 current loss 0.535430, current_train_items 318528.
I0715 07:29:48.474806 125536568714752 run.py:723] (val) algo activity_selector step 8000: {'selected': 0.9601518026565464, 'score': 0.9601518026565464, 'examples_seen': 318528, 'step': 8000, 'algorithm': 'activity_selector'}
I0715 07:29:48.474952 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0715 07:29:49.475138 125536568714752 run.py:688] Algo activity_selector step 8050 current loss 0.152798, current_train_items 320560.
I0715 07:29:49.497709 125536568714752 run.py:723] (val) algo activity_selector step 8050: {'selected': 0.9769230769230769, 'score': 0.9769230769230769, 'examples_seen': 320560, 'step': 8050, 'algorithm': 'activity_selector'}
I0715 07:29:49.497857 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0715 07:29:50.483101 125536568714752 run.py:688] Algo activity_selector step 8100 current loss 0.273789, current_train_items 322544.
I0715 07:29:50.506848 125536568714752 run.py:723] (val) algo activity_selector step 8100: {'selected': 0.9752380952380953, 'score': 0.9752380952380953, 'examples_seen': 322544, 'step': 8100, 'algorithm': 'activity_selector'}
I0715 07:29:50.506996 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0715 07:29:51.511119 125536568714752 run.py:688] Algo activity_selector step 8150 current loss 0.124585, current_train_items 324528.
I0715 07:29:51.536298 125536568714752 run.py:723] (val) algo activity_selector step 8150: {'selected': 0.969811320754717, 'score': 0.969811320754717, 'examples_seen': 324528, 'step': 8150, 'algorithm': 'activity_selector'}
I0715 07:29:51.536447 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0715 07:29:52.521424 125536568714752 run.py:688] Algo activity_selector step 8200 current loss 1.517947, current_train_items 326528.
I0715 07:29:52.550323 125536568714752 run.py:723] (val) algo activity_selector step 8200: {'selected': 0.9540918163672655, 'score': 0.9540918163672655, 'examples_seen': 326528, 'step': 8200, 'algorithm': 'activity_selector'}
I0715 07:29:52.550469 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.954, val scores are: activity_selector: 0.954
I0715 07:29:53.546130 125536568714752 run.py:688] Algo activity_selector step 8250 current loss 2.001277, current_train_items 328464.
I0715 07:29:53.575681 125536568714752 run.py:723] (val) algo activity_selector step 8250: {'selected': 0.967984934086629, 'score': 0.967984934086629, 'examples_seen': 328464, 'step': 8250, 'algorithm': 'activity_selector'}
I0715 07:29:53.575841 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0715 07:29:54.568668 125536568714752 run.py:688] Algo activity_selector step 8300 current loss 2.894063, current_train_items 330432.
I0715 07:29:54.603758 125536568714752 run.py:723] (val) algo activity_selector step 8300: {'selected': 0.937142857142857, 'score': 0.937142857142857, 'examples_seen': 330432, 'step': 8300, 'algorithm': 'activity_selector'}
I0715 07:29:54.603909 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0715 07:29:55.598886 125536568714752 run.py:688] Algo activity_selector step 8350 current loss 0.095344, current_train_items 332480.
I0715 07:29:55.623934 125536568714752 run.py:723] (val) algo activity_selector step 8350: {'selected': 0.951830443159923, 'score': 0.951830443159923, 'examples_seen': 332480, 'step': 8350, 'algorithm': 'activity_selector'}
I0715 07:29:55.624081 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0715 07:29:56.633004 125536568714752 run.py:688] Algo activity_selector step 8400 current loss 0.066625, current_train_items 334480.
I0715 07:29:56.655545 125536568714752 run.py:723] (val) algo activity_selector step 8400: {'selected': 0.9500000000000001, 'score': 0.9500000000000001, 'examples_seen': 334480, 'step': 8400, 'algorithm': 'activity_selector'}
I0715 07:29:56.655712 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0715 07:29:57.633245 125536568714752 run.py:688] Algo activity_selector step 8450 current loss 1.144022, current_train_items 336480.
I0715 07:29:57.656917 125536568714752 run.py:723] (val) algo activity_selector step 8450: {'selected': 0.978131212723658, 'score': 0.978131212723658, 'examples_seen': 336480, 'step': 8450, 'algorithm': 'activity_selector'}
I0715 07:29:57.657063 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.978, val scores are: activity_selector: 0.978
I0715 07:29:58.657984 125536568714752 run.py:688] Algo activity_selector step 8500 current loss 0.156989, current_train_items 338464.
I0715 07:29:58.683678 125536568714752 run.py:723] (val) algo activity_selector step 8500: {'selected': 0.9656488549618321, 'score': 0.9656488549618321, 'examples_seen': 338464, 'step': 8500, 'algorithm': 'activity_selector'}
I0715 07:29:58.683827 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0715 07:29:59.679631 125536568714752 run.py:688] Algo activity_selector step 8550 current loss 2.023740, current_train_items 340432.
I0715 07:29:59.707106 125536568714752 run.py:723] (val) algo activity_selector step 8550: {'selected': 0.9658886894075404, 'score': 0.9658886894075404, 'examples_seen': 340432, 'step': 8550, 'algorithm': 'activity_selector'}
I0715 07:29:59.707254 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.966, val scores are: activity_selector: 0.966
I0715 07:30:00.679726 125536568714752 run.py:688] Algo activity_selector step 8600 current loss 1.820526, current_train_items 342416.
I0715 07:30:00.709332 125536568714752 run.py:723] (val) algo activity_selector step 8600: {'selected': 0.9739776951672863, 'score': 0.9739776951672863, 'examples_seen': 342416, 'step': 8600, 'algorithm': 'activity_selector'}
I0715 07:30:00.709488 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0715 07:30:01.728086 125536568714752 run.py:688] Algo activity_selector step 8650 current loss 2.788672, current_train_items 344368.
I0715 07:30:01.761139 125536568714752 run.py:723] (val) algo activity_selector step 8650: {'selected': 0.9645669291338582, 'score': 0.9645669291338582, 'examples_seen': 344368, 'step': 8650, 'algorithm': 'activity_selector'}
I0715 07:30:01.761287 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0715 07:30:02.809116 125536568714752 run.py:688] Algo activity_selector step 8700 current loss 0.327853, current_train_items 346400.
I0715 07:30:02.834766 125536568714752 run.py:723] (val) algo activity_selector step 8700: {'selected': 0.9343339587242027, 'score': 0.9343339587242027, 'examples_seen': 346400, 'step': 8700, 'algorithm': 'activity_selector'}
I0715 07:30:02.834919 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0715 07:30:03.877633 125536568714752 run.py:688] Algo activity_selector step 8750 current loss 0.030832, current_train_items 348432.
I0715 07:30:03.900521 125536568714752 run.py:723] (val) algo activity_selector step 8750: {'selected': 0.9573643410852712, 'score': 0.9573643410852712, 'examples_seen': 348432, 'step': 8750, 'algorithm': 'activity_selector'}
I0715 07:30:03.900667 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0715 07:30:04.968494 125536568714752 run.py:688] Algo activity_selector step 8800 current loss 0.783792, current_train_items 350416.
I0715 07:30:04.994087 125536568714752 run.py:723] (val) algo activity_selector step 8800: {'selected': 0.9676113360323887, 'score': 0.9676113360323887, 'examples_seen': 350416, 'step': 8800, 'algorithm': 'activity_selector'}
I0715 07:30:04.994244 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0715 07:30:06.047688 125536568714752 run.py:688] Algo activity_selector step 8850 current loss 0.252122, current_train_items 352400.
I0715 07:30:06.075881 125536568714752 run.py:723] (val) algo activity_selector step 8850: {'selected': 0.9750479846449136, 'score': 0.9750479846449136, 'examples_seen': 352400, 'step': 8850, 'algorithm': 'activity_selector'}
I0715 07:30:06.076032 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0715 07:30:07.125640 125536568714752 run.py:688] Algo activity_selector step 8900 current loss 0.418524, current_train_items 354368.
I0715 07:30:07.154793 125536568714752 run.py:723] (val) algo activity_selector step 8900: {'selected': 0.9289827255278311, 'score': 0.9289827255278311, 'examples_seen': 354368, 'step': 8900, 'algorithm': 'activity_selector'}
I0715 07:30:07.154943 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0715 07:30:08.156077 125536568714752 run.py:688] Algo activity_selector step 8950 current loss 1.418241, current_train_items 356320.
I0715 07:30:08.185882 125536568714752 run.py:723] (val) algo activity_selector step 8950: {'selected': 0.951830443159923, 'score': 0.951830443159923, 'examples_seen': 356320, 'step': 8950, 'algorithm': 'activity_selector'}
I0715 07:30:08.186030 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.989, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0715 07:30:09.207875 125536568714752 run.py:688] Algo activity_selector step 9000 current loss 2.320122, current_train_items 358320.
I0715 07:30:09.240937 125536568714752 run.py:723] (val) algo activity_selector step 9000: {'selected': 0.99609375, 'score': 0.99609375, 'examples_seen': 358320, 'step': 9000, 'algorithm': 'activity_selector'}
I0715 07:30:09.241091 125536568714752 run.py:744] Checkpointing best model, best avg val score was 0.989, current avg val score is 0.996, val scores are: activity_selector: 0.996
I0715 07:30:10.269338 125536568714752 run.py:688] Algo activity_selector step 9050 current loss 0.296693, current_train_items 360320.
I0715 07:30:10.291790 125536568714752 run.py:723] (val) algo activity_selector step 9050: {'selected': 0.9773584905660377, 'score': 0.9773584905660377, 'examples_seen': 360320, 'step': 9050, 'algorithm': 'activity_selector'}
I0715 07:30:10.291934 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.996, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0715 07:30:11.323532 125536568714752 run.py:688] Algo activity_selector step 9100 current loss 0.174170, current_train_items 362352.
I0715 07:30:11.345743 125536568714752 run.py:723] (val) algo activity_selector step 9100: {'selected': 0.944558521560575, 'score': 0.944558521560575, 'examples_seen': 362352, 'step': 9100, 'algorithm': 'activity_selector'}
I0715 07:30:11.345889 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.996, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0715 07:30:12.357998 125536568714752 run.py:688] Algo activity_selector step 9150 current loss 0.225640, current_train_items 364352.
I0715 07:30:12.381466 125536568714752 run.py:723] (val) algo activity_selector step 9150: {'selected': 0.9710982658959537, 'score': 0.9710982658959537, 'examples_seen': 364352, 'step': 9150, 'algorithm': 'activity_selector'}
I0715 07:30:12.381622 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.996, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0715 07:30:13.370337 125536568714752 run.py:688] Algo activity_selector step 9200 current loss 0.086167, current_train_items 366320.
I0715 07:30:13.395001 125536568714752 run.py:723] (val) algo activity_selector step 9200: {'selected': 0.974559686888454, 'score': 0.974559686888454, 'examples_seen': 366320, 'step': 9200, 'algorithm': 'activity_selector'}
I0715 07:30:13.395144 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.996, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0715 07:30:14.415584 125536568714752 run.py:688] Algo activity_selector step 9250 current loss 1.208476, current_train_items 368320.
I0715 07:30:14.443110 125536568714752 run.py:723] (val) algo activity_selector step 9250: {'selected': 0.9738430583501007, 'score': 0.9738430583501007, 'examples_seen': 368320, 'step': 9250, 'algorithm': 'activity_selector'}
I0715 07:30:14.443261 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.996, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0715 07:30:15.442639 125536568714752 run.py:688] Algo activity_selector step 9300 current loss 1.275192, current_train_items 370272.
I0715 07:30:15.471881 125536568714752 run.py:723] (val) algo activity_selector step 9300: {'selected': 0.9788867562380039, 'score': 0.9788867562380039, 'examples_seen': 370272, 'step': 9300, 'algorithm': 'activity_selector'}
I0715 07:30:15.472031 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.996, current avg val score is 0.979, val scores are: activity_selector: 0.979
I0715 07:30:16.476445 125536568714752 run.py:688] Algo activity_selector step 9350 current loss 2.536772, current_train_items 372240.
I0715 07:30:16.509712 125536568714752 run.py:723] (val) algo activity_selector step 9350: {'selected': 0.973384030418251, 'score': 0.973384030418251, 'examples_seen': 372240, 'step': 9350, 'algorithm': 'activity_selector'}
I0715 07:30:16.509863 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.996, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0715 07:30:17.515167 125536568714752 run.py:688] Algo activity_selector step 9400 current loss 0.413029, current_train_items 374288.
I0715 07:30:17.537066 125536568714752 run.py:723] (val) algo activity_selector step 9400: {'selected': 0.926441351888668, 'score': 0.926441351888668, 'examples_seen': 374288, 'step': 9400, 'algorithm': 'activity_selector'}
I0715 07:30:17.537226 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.996, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0715 07:30:18.560931 125536568714752 run.py:688] Algo activity_selector step 9450 current loss 0.076928, current_train_items 376288.
I0715 07:30:18.583794 125536568714752 run.py:723] (val) algo activity_selector step 9450: {'selected': 0.9414062500000001, 'score': 0.9414062500000001, 'examples_seen': 376288, 'step': 9450, 'algorithm': 'activity_selector'}
I0715 07:30:18.583941 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.996, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0715 07:30:19.606691 125536568714752 run.py:688] Algo activity_selector step 9500 current loss 0.760093, current_train_items 378304.
I0715 07:30:19.630017 125536568714752 run.py:723] (val) algo activity_selector step 9500: {'selected': 0.9808429118773946, 'score': 0.9808429118773946, 'examples_seen': 378304, 'step': 9500, 'algorithm': 'activity_selector'}
I0715 07:30:19.630170 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.996, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0715 07:30:20.621389 125536568714752 run.py:688] Algo activity_selector step 9550 current loss 0.128928, current_train_items 380272.
I0715 07:30:20.645706 125536568714752 run.py:723] (val) algo activity_selector step 9550: {'selected': 0.9622641509433963, 'score': 0.9622641509433963, 'examples_seen': 380272, 'step': 9550, 'algorithm': 'activity_selector'}
I0715 07:30:20.645851 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.996, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0715 07:30:21.650763 125536568714752 run.py:688] Algo activity_selector step 9600 current loss 1.961836, current_train_items 382240.
I0715 07:30:21.678910 125536568714752 run.py:723] (val) algo activity_selector step 9600: {'selected': 0.9638095238095238, 'score': 0.9638095238095238, 'examples_seen': 382240, 'step': 9600, 'algorithm': 'activity_selector'}
I0715 07:30:21.679064 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.996, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0715 07:30:22.661638 125536568714752 run.py:688] Algo activity_selector step 9650 current loss 0.343779, current_train_items 384224.
I0715 07:30:22.691338 125536568714752 run.py:723] (val) algo activity_selector step 9650: {'selected': 0.9848484848484849, 'score': 0.9848484848484849, 'examples_seen': 384224, 'step': 9650, 'algorithm': 'activity_selector'}
I0715 07:30:22.691493 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.996, current avg val score is 0.985, val scores are: activity_selector: 0.985
I0715 07:30:23.695922 125536568714752 run.py:688] Algo activity_selector step 9700 current loss 1.961149, current_train_items 386176.
I0715 07:30:23.728834 125536568714752 run.py:723] (val) algo activity_selector step 9700: {'selected': 0.9739478957915831, 'score': 0.9739478957915831, 'examples_seen': 386176, 'step': 9700, 'algorithm': 'activity_selector'}
I0715 07:30:23.728982 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.996, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0715 07:30:24.733414 125536568714752 run.py:688] Algo activity_selector step 9750 current loss 0.315870, current_train_items 388224.
I0715 07:30:24.755951 125536568714752 run.py:723] (val) algo activity_selector step 9750: {'selected': 0.9700374531835206, 'score': 0.9700374531835206, 'examples_seen': 388224, 'step': 9750, 'algorithm': 'activity_selector'}
I0715 07:30:24.756101 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.996, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0715 07:30:25.758149 125536568714752 run.py:688] Algo activity_selector step 9800 current loss 0.123473, current_train_items 390240.
I0715 07:30:25.782630 125536568714752 run.py:723] (val) algo activity_selector step 9800: {'selected': 0.9591078066914499, 'score': 0.9591078066914499, 'examples_seen': 390240, 'step': 9800, 'algorithm': 'activity_selector'}
I0715 07:30:25.782779 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.996, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0715 07:30:26.791672 125536568714752 run.py:688] Algo activity_selector step 9850 current loss 0.674128, current_train_items 392224.
I0715 07:30:26.815090 125536568714752 run.py:723] (val) algo activity_selector step 9850: {'selected': 0.9625246548323472, 'score': 0.9625246548323472, 'examples_seen': 392224, 'step': 9850, 'algorithm': 'activity_selector'}
I0715 07:30:26.815240 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.996, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0715 07:30:27.804990 125536568714752 run.py:688] Algo activity_selector step 9900 current loss 0.180821, current_train_items 394208.
I0715 07:30:27.830623 125536568714752 run.py:723] (val) algo activity_selector step 9900: {'selected': 0.9769230769230769, 'score': 0.9769230769230769, 'examples_seen': 394208, 'step': 9900, 'algorithm': 'activity_selector'}
I0715 07:30:27.830771 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.996, current avg val score is 0.977, val scores are: activity_selector: 0.977
I0715 07:30:28.839978 125536568714752 run.py:688] Algo activity_selector step 9950 current loss 0.226411, current_train_items 396176.
I0715 07:30:28.867773 125536568714752 run.py:723] (val) algo activity_selector step 9950: {'selected': 0.9603174603174602, 'score': 0.9603174603174602, 'examples_seen': 396176, 'step': 9950, 'algorithm': 'activity_selector'}
I0715 07:30:28.867924 125536568714752 run.py:747] Not saving new best model, best avg val score was 0.996, current avg val score is 0.960, val scores are: activity_selector: 0.960
I0715 07:30:29.845015 125536568714752 run.py:753] Restoring best model from checkpoint...
I0715 07:30:35.610447 125536568714752 run.py:768] (test) algo activity_selector : {'selected': 0.9430604982206406, 'score': 0.9430604982206406, 'examples_seen': 398112, 'step': 10000, 'algorithm': 'activity_selector'}
I0715 07:30:35.610612 125536568714752 run.py:770] Done!
