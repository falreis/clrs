I0119 22:35:34.286723 127225725752832 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0119 22:35:34.287366 127225725752832 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0119 22:35:34.524737 127225725752832 run.py:462] Model: f8 ['activity_selector']
I0119 22:35:34.524838 127225725752832 run.py:464] algorithms ['activity_selector']
I0119 22:35:34.525013 127225725752832 run.py:465] train_lengths ['4', '7', '11', '13', '16']
I0119 22:35:34.525050 127225725752832 run.py:466] train_batch_size 16
I0119 22:35:34.525144 127225725752832 run.py:467] val_batch_size 16
I0119 22:35:34.525177 127225725752832 run.py:468] test_batch_size 16
I0119 22:35:34.525207 127225725752832 run.py:469] chunked_training True
I0119 22:35:34.525329 127225725752832 run.py:470] chunk_length 16
I0119 22:35:34.525361 127225725752832 run.py:471] train_steps 10000
I0119 22:35:34.525393 127225725752832 run.py:472] eval_every 50
I0119 22:35:34.525425 127225725752832 run.py:473] test_every 500
I0119 22:35:34.525456 127225725752832 run.py:474] hidden_size 128
I0119 22:35:34.525485 127225725752832 run.py:475] nb_msg_passing_steps 1
I0119 22:35:34.525514 127225725752832 run.py:476] learning_rate 0.001
I0119 22:35:34.525613 127225725752832 run.py:477] grad_clip_max_norm 1.0
I0119 22:35:34.525646 127225725752832 run.py:478] dropout_prob 0.0
I0119 22:35:34.525676 127225725752832 run.py:479] hint_teacher_forcing 0.0
I0119 22:35:34.525706 127225725752832 run.py:480] hint_mode encoded_decoded
I0119 22:35:34.525811 127225725752832 run.py:481] hint_repred_mode soft
I0119 22:35:34.525841 127225725752832 run.py:482] use_ln True
I0119 22:35:34.525871 127225725752832 run.py:483] use_lstm True
I0119 22:35:34.525899 127225725752832 run.py:484] nb_triplet_fts 16
I0119 22:35:34.525928 127225725752832 run.py:485] encoder_init xavier_on_scalars
I0119 22:35:34.525955 127225725752832 run.py:486] processor_type f8
I0119 22:35:34.525987 127225725752832 run.py:487] checkpoint_path CLRS30
I0119 22:35:34.526017 127225725752832 run.py:488] dataset_path CLRS30
I0119 22:35:34.526046 127225725752832 run.py:489] freeze_processor False
I0119 22:35:34.526074 127225725752832 run.py:490] reduction min
I0119 22:35:34.526103 127225725752832 run.py:491] activation elu
I0119 22:35:34.526131 127225725752832 run.py:492] restore_model 
I0119 22:35:34.526159 127225725752832 run.py:493] gated True
I0119 22:35:34.526190 127225725752832 run.py:494] gated_activation tanh
I0119 22:35:34.526219 127225725752832 run.py:495] memory_type mha
I0119 22:35:34.526248 127225725752832 run.py:496] memory_size 16
I0119 22:35:34.528813 127225725752832 run.py:522] Creating samplers for algo activity_selector
W0119 22:35:34.528986 127225725752832 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0119 22:35:34.529242 127225725752832 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W0119 22:35:34.741388 127225725752832 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0119 22:35:34.989325 127225725752832 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0119 22:35:35.298588 127225725752832 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0119 22:35:35.638792 127225725752832 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W0119 22:35:36.033079 127225725752832 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I0119 22:35:36.033350 127225725752832 samplers.py:124] Creating a dataset with 64 samples.
I0119 22:35:36.060113 127225725752832 run.py:306] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I0119 22:35:36.060891 127225725752832 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0119 22:35:36.063740 127225725752832 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I0119 22:35:36.067442 127225725752832 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I0119 22:35:36.118873 127225725752832 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W0119 22:35:36.139829 127225725752832 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x73b587a95440> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0119 22:36:18.034086 127225725752832 run.py:748] Algo activity_selector step 0 current loss 5.496377, current_train_items 32.
I0119 22:36:24.826883 127225725752832 run.py:783] (val) algo activity_selector step 0: {'selected': 0.3551401869158879, 'score': 0.3551401869158879, 'examples_seen': 32, 'step': 0, 'algorithm': 'activity_selector'}
I0119 22:36:24.827053 127225725752832 run.py:804] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.355, val scores are: activity_selector: 0.355
I0119 22:37:31.374046 127225725752832 run.py:748] Algo activity_selector step 50 current loss 3.783984, current_train_items 1408.
I0119 22:37:31.414615 127225725752832 run.py:783] (val) algo activity_selector step 50: {'selected': 0.7229357798165137, 'score': 0.7229357798165137, 'examples_seen': 1408, 'step': 50, 'algorithm': 'activity_selector'}
I0119 22:37:31.414775 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.355, current avg val score is 0.723, val scores are: activity_selector: 0.723
I0119 22:37:32.393471 127225725752832 run.py:748] Algo activity_selector step 100 current loss 3.437998, current_train_items 2800.
I0119 22:37:32.433286 127225725752832 run.py:783] (val) algo activity_selector step 100: {'selected': 0.662309368191721, 'score': 0.662309368191721, 'examples_seen': 2800, 'step': 100, 'algorithm': 'activity_selector'}
I0119 22:37:32.433453 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.723, current avg val score is 0.662, val scores are: activity_selector: 0.662
I0119 22:37:33.386969 127225725752832 run.py:748] Algo activity_selector step 150 current loss 3.024422, current_train_items 4176.
I0119 22:37:33.426964 127225725752832 run.py:783] (val) algo activity_selector step 150: {'selected': 0.7538461538461538, 'score': 0.7538461538461538, 'examples_seen': 4176, 'step': 150, 'algorithm': 'activity_selector'}
I0119 22:37:33.427113 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.723, current avg val score is 0.754, val scores are: activity_selector: 0.754
I0119 22:37:34.391249 127225725752832 run.py:748] Algo activity_selector step 200 current loss 3.027423, current_train_items 5536.
I0119 22:37:34.430732 127225725752832 run.py:783] (val) algo activity_selector step 200: {'selected': 0.7596899224806201, 'score': 0.7596899224806201, 'examples_seen': 5536, 'step': 200, 'algorithm': 'activity_selector'}
I0119 22:37:34.430884 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.754, current avg val score is 0.760, val scores are: activity_selector: 0.760
I0119 22:37:35.397979 127225725752832 run.py:748] Algo activity_selector step 250 current loss 3.880700, current_train_items 6944.
I0119 22:37:35.440467 127225725752832 run.py:783] (val) algo activity_selector step 250: {'selected': 0.6537634408602151, 'score': 0.6537634408602151, 'examples_seen': 6944, 'step': 250, 'algorithm': 'activity_selector'}
I0119 22:37:35.440642 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.760, current avg val score is 0.654, val scores are: activity_selector: 0.654
I0119 22:37:36.376287 127225725752832 run.py:748] Algo activity_selector step 300 current loss 2.414077, current_train_items 8304.
I0119 22:37:36.416536 127225725752832 run.py:783] (val) algo activity_selector step 300: {'selected': 0.7549019607843137, 'score': 0.7549019607843137, 'examples_seen': 8304, 'step': 300, 'algorithm': 'activity_selector'}
I0119 22:37:36.416696 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.760, current avg val score is 0.755, val scores are: activity_selector: 0.755
I0119 22:37:37.343919 127225725752832 run.py:748] Algo activity_selector step 350 current loss 2.188856, current_train_items 9680.
I0119 22:37:37.384003 127225725752832 run.py:783] (val) algo activity_selector step 350: {'selected': 0.7842401500938087, 'score': 0.7842401500938087, 'examples_seen': 9680, 'step': 350, 'algorithm': 'activity_selector'}
I0119 22:37:37.384154 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.760, current avg val score is 0.784, val scores are: activity_selector: 0.784
I0119 22:37:38.355236 127225725752832 run.py:748] Algo activity_selector step 400 current loss 2.012810, current_train_items 11072.
I0119 22:37:38.395697 127225725752832 run.py:783] (val) algo activity_selector step 400: {'selected': 0.7961165048543689, 'score': 0.7961165048543689, 'examples_seen': 11072, 'step': 400, 'algorithm': 'activity_selector'}
I0119 22:37:38.395861 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.784, current avg val score is 0.796, val scores are: activity_selector: 0.796
I0119 22:37:39.364803 127225725752832 run.py:748] Algo activity_selector step 450 current loss 2.295663, current_train_items 12448.
I0119 22:37:39.405253 127225725752832 run.py:783] (val) algo activity_selector step 450: {'selected': 0.7983014861995754, 'score': 0.7983014861995754, 'examples_seen': 12448, 'step': 450, 'algorithm': 'activity_selector'}
I0119 22:37:39.405416 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.796, current avg val score is 0.798, val scores are: activity_selector: 0.798
I0119 22:37:40.385635 127225725752832 run.py:748] Algo activity_selector step 500 current loss 2.753971, current_train_items 13824.
I0119 22:37:40.425729 127225725752832 run.py:783] (val) algo activity_selector step 500: {'selected': 0.8045112781954888, 'score': 0.8045112781954888, 'examples_seen': 13824, 'step': 500, 'algorithm': 'activity_selector'}
I0119 22:37:40.425879 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.798, current avg val score is 0.805, val scores are: activity_selector: 0.805
I0119 22:37:41.384467 127225725752832 run.py:748] Algo activity_selector step 550 current loss 2.221094, current_train_items 15200.
I0119 22:37:41.424993 127225725752832 run.py:783] (val) algo activity_selector step 550: {'selected': 0.7328918322295805, 'score': 0.7328918322295805, 'examples_seen': 15200, 'step': 550, 'algorithm': 'activity_selector'}
I0119 22:37:41.425155 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.805, current avg val score is 0.733, val scores are: activity_selector: 0.733
I0119 22:37:42.364194 127225725752832 run.py:748] Algo activity_selector step 600 current loss 1.806814, current_train_items 16576.
I0119 22:37:42.403895 127225725752832 run.py:783] (val) algo activity_selector step 600: {'selected': 0.7807308970099667, 'score': 0.7807308970099667, 'examples_seen': 16576, 'step': 600, 'algorithm': 'activity_selector'}
I0119 22:37:42.404045 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.805, current avg val score is 0.781, val scores are: activity_selector: 0.781
I0119 22:37:43.338832 127225725752832 run.py:748] Algo activity_selector step 650 current loss 1.786311, current_train_items 17952.
I0119 22:37:43.383575 127225725752832 run.py:783] (val) algo activity_selector step 650: {'selected': 0.8872180451127819, 'score': 0.8872180451127819, 'examples_seen': 17952, 'step': 650, 'algorithm': 'activity_selector'}
I0119 22:37:43.383723 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.805, current avg val score is 0.887, val scores are: activity_selector: 0.887
I0119 22:37:44.347005 127225725752832 run.py:748] Algo activity_selector step 700 current loss 2.125957, current_train_items 19344.
I0119 22:37:44.386934 127225725752832 run.py:783] (val) algo activity_selector step 700: {'selected': 0.8490566037735849, 'score': 0.8490566037735849, 'examples_seen': 19344, 'step': 700, 'algorithm': 'activity_selector'}
I0119 22:37:44.387084 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.887, current avg val score is 0.849, val scores are: activity_selector: 0.849
I0119 22:37:45.339303 127225725752832 run.py:748] Algo activity_selector step 750 current loss 1.729187, current_train_items 20720.
I0119 22:37:45.380035 127225725752832 run.py:783] (val) algo activity_selector step 750: {'selected': 0.8619957537154989, 'score': 0.8619957537154989, 'examples_seen': 20720, 'step': 750, 'algorithm': 'activity_selector'}
I0119 22:37:45.380184 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.887, current avg val score is 0.862, val scores are: activity_selector: 0.862
I0119 22:37:46.303436 127225725752832 run.py:748] Algo activity_selector step 800 current loss 2.019686, current_train_items 22096.
I0119 22:37:46.344297 127225725752832 run.py:783] (val) algo activity_selector step 800: {'selected': 0.9111969111969113, 'score': 0.9111969111969113, 'examples_seen': 22096, 'step': 800, 'algorithm': 'activity_selector'}
I0119 22:37:46.344446 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.887, current avg val score is 0.911, val scores are: activity_selector: 0.911
I0119 22:37:47.328012 127225725752832 run.py:748] Algo activity_selector step 850 current loss 2.306483, current_train_items 23472.
I0119 22:37:47.374184 127225725752832 run.py:783] (val) algo activity_selector step 850: {'selected': 0.8103448275862069, 'score': 0.8103448275862069, 'examples_seen': 23472, 'step': 850, 'algorithm': 'activity_selector'}
I0119 22:37:47.374339 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.911, current avg val score is 0.810, val scores are: activity_selector: 0.810
I0119 22:37:48.355651 127225725752832 run.py:748] Algo activity_selector step 900 current loss 1.812393, current_train_items 24848.
I0119 22:37:48.401436 127225725752832 run.py:783] (val) algo activity_selector step 900: {'selected': 0.8617886178861788, 'score': 0.8617886178861788, 'examples_seen': 24848, 'step': 900, 'algorithm': 'activity_selector'}
I0119 22:37:48.401663 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.911, current avg val score is 0.862, val scores are: activity_selector: 0.862
I0119 22:37:49.401516 127225725752832 run.py:748] Algo activity_selector step 950 current loss 1.592286, current_train_items 26224.
I0119 22:37:49.444313 127225725752832 run.py:783] (val) algo activity_selector step 950: {'selected': 0.8288973384030418, 'score': 0.8288973384030418, 'examples_seen': 26224, 'step': 950, 'algorithm': 'activity_selector'}
I0119 22:37:49.444468 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.911, current avg val score is 0.829, val scores are: activity_selector: 0.829
I0119 22:37:50.386908 127225725752832 run.py:748] Algo activity_selector step 1000 current loss 1.707750, current_train_items 27616.
I0119 22:37:50.427305 127225725752832 run.py:783] (val) algo activity_selector step 1000: {'selected': 0.8786764705882353, 'score': 0.8786764705882353, 'examples_seen': 27616, 'step': 1000, 'algorithm': 'activity_selector'}
I0119 22:37:50.427462 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.911, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0119 22:37:51.369948 127225725752832 run.py:748] Algo activity_selector step 1050 current loss 1.712297, current_train_items 28992.
I0119 22:37:51.410728 127225725752832 run.py:783] (val) algo activity_selector step 1050: {'selected': 0.8796992481203009, 'score': 0.8796992481203009, 'examples_seen': 28992, 'step': 1050, 'algorithm': 'activity_selector'}
I0119 22:37:51.410880 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.911, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0119 22:37:52.336656 127225725752832 run.py:748] Algo activity_selector step 1100 current loss 1.580241, current_train_items 30368.
I0119 22:37:52.379299 127225725752832 run.py:783] (val) algo activity_selector step 1100: {'selected': 0.854368932038835, 'score': 0.854368932038835, 'examples_seen': 30368, 'step': 1100, 'algorithm': 'activity_selector'}
I0119 22:37:52.379447 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.911, current avg val score is 0.854, val scores are: activity_selector: 0.854
I0119 22:37:53.316030 127225725752832 run.py:748] Algo activity_selector step 1150 current loss 1.376421, current_train_items 31760.
I0119 22:37:53.355418 127225725752832 run.py:783] (val) algo activity_selector step 1150: {'selected': 0.8924162257495589, 'score': 0.8924162257495589, 'examples_seen': 31760, 'step': 1150, 'algorithm': 'activity_selector'}
I0119 22:37:53.355579 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.911, current avg val score is 0.892, val scores are: activity_selector: 0.892
I0119 22:37:54.285454 127225725752832 run.py:748] Algo activity_selector step 1200 current loss 1.359008, current_train_items 33120.
I0119 22:37:54.324924 127225725752832 run.py:783] (val) algo activity_selector step 1200: {'selected': 0.8821428571428571, 'score': 0.8821428571428571, 'examples_seen': 33120, 'step': 1200, 'algorithm': 'activity_selector'}
I0119 22:37:54.325070 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.911, current avg val score is 0.882, val scores are: activity_selector: 0.882
I0119 22:37:55.258815 127225725752832 run.py:748] Algo activity_selector step 1250 current loss 1.501188, current_train_items 34496.
I0119 22:37:55.299057 127225725752832 run.py:783] (val) algo activity_selector step 1250: {'selected': 0.925925925925926, 'score': 0.925925925925926, 'examples_seen': 34496, 'step': 1250, 'algorithm': 'activity_selector'}
I0119 22:37:55.299205 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.911, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0119 22:37:56.268651 127225725752832 run.py:748] Algo activity_selector step 1300 current loss 1.343762, current_train_items 35888.
I0119 22:37:56.307757 127225725752832 run.py:783] (val) algo activity_selector step 1300: {'selected': 0.8934579439252337, 'score': 0.8934579439252337, 'examples_seen': 35888, 'step': 1300, 'algorithm': 'activity_selector'}
I0119 22:37:56.307910 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.926, current avg val score is 0.893, val scores are: activity_selector: 0.893
I0119 22:37:57.243406 127225725752832 run.py:748] Algo activity_selector step 1350 current loss 1.495509, current_train_items 37264.
I0119 22:37:57.283165 127225725752832 run.py:783] (val) algo activity_selector step 1350: {'selected': 0.8778761061946903, 'score': 0.8778761061946903, 'examples_seen': 37264, 'step': 1350, 'algorithm': 'activity_selector'}
I0119 22:37:57.283312 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.926, current avg val score is 0.878, val scores are: activity_selector: 0.878
I0119 22:37:58.213575 127225725752832 run.py:748] Algo activity_selector step 1400 current loss 1.182701, current_train_items 38640.
I0119 22:37:58.255414 127225725752832 run.py:783] (val) algo activity_selector step 1400: {'selected': 0.9049429657794676, 'score': 0.9049429657794676, 'examples_seen': 38640, 'step': 1400, 'algorithm': 'activity_selector'}
I0119 22:37:58.255582 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.926, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0119 22:37:59.174563 127225725752832 run.py:748] Algo activity_selector step 1450 current loss 1.158629, current_train_items 40016.
I0119 22:37:59.214864 127225725752832 run.py:783] (val) algo activity_selector step 1450: {'selected': 0.9118198874296435, 'score': 0.9118198874296435, 'examples_seen': 40016, 'step': 1450, 'algorithm': 'activity_selector'}
I0119 22:37:59.215015 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.926, current avg val score is 0.912, val scores are: activity_selector: 0.912
I0119 22:38:00.154671 127225725752832 run.py:748] Algo activity_selector step 1500 current loss 1.316292, current_train_items 41408.
I0119 22:38:00.193997 127225725752832 run.py:783] (val) algo activity_selector step 1500: {'selected': 0.8836291913214989, 'score': 0.8836291913214989, 'examples_seen': 41408, 'step': 1500, 'algorithm': 'activity_selector'}
I0119 22:38:00.194148 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.926, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0119 22:38:01.122211 127225725752832 run.py:748] Algo activity_selector step 1550 current loss 1.430247, current_train_items 42768.
I0119 22:38:01.162647 127225725752832 run.py:783] (val) algo activity_selector step 1550: {'selected': 0.8790786948176582, 'score': 0.8790786948176582, 'examples_seen': 42768, 'step': 1550, 'algorithm': 'activity_selector'}
I0119 22:38:01.162796 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.926, current avg val score is 0.879, val scores are: activity_selector: 0.879
I0119 22:38:02.098736 127225725752832 run.py:748] Algo activity_selector step 1600 current loss 1.147399, current_train_items 44160.
I0119 22:38:02.138086 127225725752832 run.py:783] (val) algo activity_selector step 1600: {'selected': 0.9242718446601942, 'score': 0.9242718446601942, 'examples_seen': 44160, 'step': 1600, 'algorithm': 'activity_selector'}
I0119 22:38:02.138237 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.926, current avg val score is 0.924, val scores are: activity_selector: 0.924
I0119 22:38:03.071856 127225725752832 run.py:748] Algo activity_selector step 1650 current loss 1.309204, current_train_items 45536.
I0119 22:38:03.113184 127225725752832 run.py:783] (val) algo activity_selector step 1650: {'selected': 0.8843813387423934, 'score': 0.8843813387423934, 'examples_seen': 45536, 'step': 1650, 'algorithm': 'activity_selector'}
I0119 22:38:03.113333 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.926, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0119 22:38:04.029349 127225725752832 run.py:748] Algo activity_selector step 1700 current loss 1.022607, current_train_items 46896.
I0119 22:38:04.069377 127225725752832 run.py:783] (val) algo activity_selector step 1700: {'selected': 0.9428007889546351, 'score': 0.9428007889546351, 'examples_seen': 46896, 'step': 1700, 'algorithm': 'activity_selector'}
I0119 22:38:04.069525 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.926, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0119 22:38:05.045782 127225725752832 run.py:748] Algo activity_selector step 1750 current loss 1.190779, current_train_items 48304.
I0119 22:38:05.085523 127225725752832 run.py:783] (val) algo activity_selector step 1750: {'selected': 0.9066666666666667, 'score': 0.9066666666666667, 'examples_seen': 48304, 'step': 1750, 'algorithm': 'activity_selector'}
I0119 22:38:05.085684 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.943, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0119 22:38:06.008492 127225725752832 run.py:748] Algo activity_selector step 1800 current loss 1.184467, current_train_items 49664.
I0119 22:38:06.048248 127225725752832 run.py:783] (val) algo activity_selector step 1800: {'selected': 0.9224952741020793, 'score': 0.9224952741020793, 'examples_seen': 49664, 'step': 1800, 'algorithm': 'activity_selector'}
I0119 22:38:06.048399 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.943, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0119 22:38:06.979891 127225725752832 run.py:748] Algo activity_selector step 1850 current loss 1.104802, current_train_items 51056.
I0119 22:38:07.020491 127225725752832 run.py:783] (val) algo activity_selector step 1850: {'selected': 0.8838821490467937, 'score': 0.8838821490467937, 'examples_seen': 51056, 'step': 1850, 'algorithm': 'activity_selector'}
I0119 22:38:07.020648 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.943, current avg val score is 0.884, val scores are: activity_selector: 0.884
I0119 22:38:07.947675 127225725752832 run.py:748] Algo activity_selector step 1900 current loss 1.061119, current_train_items 52432.
I0119 22:38:07.988780 127225725752832 run.py:783] (val) algo activity_selector step 1900: {'selected': 0.8816029143897997, 'score': 0.8816029143897997, 'examples_seen': 52432, 'step': 1900, 'algorithm': 'activity_selector'}
I0119 22:38:07.988930 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.943, current avg val score is 0.882, val scores are: activity_selector: 0.882
I0119 22:38:08.912135 127225725752832 run.py:748] Algo activity_selector step 1950 current loss 1.541229, current_train_items 53808.
I0119 22:38:08.958371 127225725752832 run.py:783] (val) algo activity_selector step 1950: {'selected': 0.8724137931034484, 'score': 0.8724137931034484, 'examples_seen': 53808, 'step': 1950, 'algorithm': 'activity_selector'}
I0119 22:38:08.958520 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.943, current avg val score is 0.872, val scores are: activity_selector: 0.872
I0119 22:38:09.892486 127225725752832 run.py:748] Algo activity_selector step 2000 current loss 1.126093, current_train_items 55184.
I0119 22:38:09.932501 127225725752832 run.py:783] (val) algo activity_selector step 2000: {'selected': 0.9035714285714286, 'score': 0.9035714285714286, 'examples_seen': 55184, 'step': 2000, 'algorithm': 'activity_selector'}
I0119 22:38:09.932664 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.943, current avg val score is 0.904, val scores are: activity_selector: 0.904
I0119 22:38:10.849166 127225725752832 run.py:748] Algo activity_selector step 2050 current loss 0.943849, current_train_items 56560.
I0119 22:38:10.889409 127225725752832 run.py:783] (val) algo activity_selector step 2050: {'selected': 0.9140624999999999, 'score': 0.9140624999999999, 'examples_seen': 56560, 'step': 2050, 'algorithm': 'activity_selector'}
I0119 22:38:10.889568 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.943, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0119 22:38:11.832490 127225725752832 run.py:748] Algo activity_selector step 2100 current loss 1.402442, current_train_items 57952.
I0119 22:38:11.872625 127225725752832 run.py:783] (val) algo activity_selector step 2100: {'selected': 0.9069767441860466, 'score': 0.9069767441860466, 'examples_seen': 57952, 'step': 2100, 'algorithm': 'activity_selector'}
I0119 22:38:11.872775 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.943, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0119 22:38:12.791515 127225725752832 run.py:748] Algo activity_selector step 2150 current loss 1.510539, current_train_items 59312.
I0119 22:38:12.832350 127225725752832 run.py:783] (val) algo activity_selector step 2150: {'selected': 0.9172932330827068, 'score': 0.9172932330827068, 'examples_seen': 59312, 'step': 2150, 'algorithm': 'activity_selector'}
I0119 22:38:12.832501 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.943, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0119 22:38:13.761829 127225725752832 run.py:748] Algo activity_selector step 2200 current loss 1.125403, current_train_items 60720.
I0119 22:38:13.801737 127225725752832 run.py:783] (val) algo activity_selector step 2200: {'selected': 0.921259842519685, 'score': 0.921259842519685, 'examples_seen': 60720, 'step': 2200, 'algorithm': 'activity_selector'}
I0119 22:38:13.801888 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.943, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0119 22:38:14.737176 127225725752832 run.py:748] Algo activity_selector step 2250 current loss 1.029443, current_train_items 62080.
I0119 22:38:14.777783 127225725752832 run.py:783] (val) algo activity_selector step 2250: {'selected': 0.9340866290018832, 'score': 0.9340866290018832, 'examples_seen': 62080, 'step': 2250, 'algorithm': 'activity_selector'}
I0119 22:38:14.777933 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.943, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0119 22:38:15.701301 127225725752832 run.py:748] Algo activity_selector step 2300 current loss 0.969313, current_train_items 63440.
I0119 22:38:15.741436 127225725752832 run.py:783] (val) algo activity_selector step 2300: {'selected': 0.9447619047619048, 'score': 0.9447619047619048, 'examples_seen': 63440, 'step': 2300, 'algorithm': 'activity_selector'}
I0119 22:38:15.741596 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.943, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0119 22:38:16.718301 127225725752832 run.py:748] Algo activity_selector step 2350 current loss 0.984065, current_train_items 64848.
I0119 22:38:16.758601 127225725752832 run.py:783] (val) algo activity_selector step 2350: {'selected': 0.8999999999999999, 'score': 0.8999999999999999, 'examples_seen': 64848, 'step': 2350, 'algorithm': 'activity_selector'}
I0119 22:38:16.758754 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.945, current avg val score is 0.900, val scores are: activity_selector: 0.900
I0119 22:38:17.696825 127225725752832 run.py:748] Algo activity_selector step 2400 current loss 1.011312, current_train_items 66208.
I0119 22:38:17.738212 127225725752832 run.py:783] (val) algo activity_selector step 2400: {'selected': 0.8734402852049911, 'score': 0.8734402852049911, 'examples_seen': 66208, 'step': 2400, 'algorithm': 'activity_selector'}
I0119 22:38:17.738364 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.945, current avg val score is 0.873, val scores are: activity_selector: 0.873
I0119 22:38:18.679525 127225725752832 run.py:748] Algo activity_selector step 2450 current loss 1.022128, current_train_items 67600.
I0119 22:38:18.719408 127225725752832 run.py:783] (val) algo activity_selector step 2450: {'selected': 0.9479553903345724, 'score': 0.9479553903345724, 'examples_seen': 67600, 'step': 2450, 'algorithm': 'activity_selector'}
I0119 22:38:18.719569 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.945, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0119 22:38:19.677511 127225725752832 run.py:748] Algo activity_selector step 2500 current loss 0.960473, current_train_items 68976.
I0119 22:38:19.717225 127225725752832 run.py:783] (val) algo activity_selector step 2500: {'selected': 0.9369024856596558, 'score': 0.9369024856596558, 'examples_seen': 68976, 'step': 2500, 'algorithm': 'activity_selector'}
I0119 22:38:19.717376 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.948, current avg val score is 0.937, val scores are: activity_selector: 0.937
I0119 22:38:20.649104 127225725752832 run.py:748] Algo activity_selector step 2550 current loss 0.969998, current_train_items 70352.
I0119 22:38:20.688294 127225725752832 run.py:783] (val) algo activity_selector step 2550: {'selected': 0.9609375, 'score': 0.9609375, 'examples_seen': 70352, 'step': 2550, 'algorithm': 'activity_selector'}
I0119 22:38:20.688457 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.948, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0119 22:38:21.666799 127225725752832 run.py:748] Algo activity_selector step 2600 current loss 0.928852, current_train_items 71728.
I0119 22:38:21.707890 127225725752832 run.py:783] (val) algo activity_selector step 2600: {'selected': 0.9377431906614787, 'score': 0.9377431906614787, 'examples_seen': 71728, 'step': 2600, 'algorithm': 'activity_selector'}
I0119 22:38:21.708040 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.961, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0119 22:38:22.629427 127225725752832 run.py:748] Algo activity_selector step 2650 current loss 0.846381, current_train_items 73104.
I0119 22:38:22.669269 127225725752832 run.py:783] (val) algo activity_selector step 2650: {'selected': 0.9274809160305344, 'score': 0.9274809160305344, 'examples_seen': 73104, 'step': 2650, 'algorithm': 'activity_selector'}
I0119 22:38:22.669419 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.961, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0119 22:38:23.617984 127225725752832 run.py:748] Algo activity_selector step 2700 current loss 0.957789, current_train_items 74496.
I0119 22:38:23.657686 127225725752832 run.py:783] (val) algo activity_selector step 2700: {'selected': 0.966542750929368, 'score': 0.966542750929368, 'examples_seen': 74496, 'step': 2700, 'algorithm': 'activity_selector'}
I0119 22:38:23.657835 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.961, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0119 22:38:24.620858 127225725752832 run.py:748] Algo activity_selector step 2750 current loss 1.307179, current_train_items 75856.
I0119 22:38:24.660525 127225725752832 run.py:783] (val) algo activity_selector step 2750: {'selected': 0.907473309608541, 'score': 0.907473309608541, 'examples_seen': 75856, 'step': 2750, 'algorithm': 'activity_selector'}
I0119 22:38:24.660685 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.907, val scores are: activity_selector: 0.907
I0119 22:38:25.592920 127225725752832 run.py:748] Algo activity_selector step 2800 current loss 0.895719, current_train_items 77264.
I0119 22:38:25.634923 127225725752832 run.py:783] (val) algo activity_selector step 2800: {'selected': 0.9050279329608938, 'score': 0.9050279329608938, 'examples_seen': 77264, 'step': 2800, 'algorithm': 'activity_selector'}
I0119 22:38:25.635079 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.905, val scores are: activity_selector: 0.905
I0119 22:38:26.576210 127225725752832 run.py:748] Algo activity_selector step 2850 current loss 1.012199, current_train_items 78624.
I0119 22:38:26.615523 127225725752832 run.py:783] (val) algo activity_selector step 2850: {'selected': 0.9669902912621358, 'score': 0.9669902912621358, 'examples_seen': 78624, 'step': 2850, 'algorithm': 'activity_selector'}
I0119 22:38:26.615682 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.967, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0119 22:38:27.573248 127225725752832 run.py:748] Algo activity_selector step 2900 current loss 1.126969, current_train_items 80000.
I0119 22:38:27.612971 127225725752832 run.py:783] (val) algo activity_selector step 2900: {'selected': 0.9032258064516128, 'score': 0.9032258064516128, 'examples_seen': 80000, 'step': 2900, 'algorithm': 'activity_selector'}
I0119 22:38:27.613121 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.903, val scores are: activity_selector: 0.903
I0119 22:38:28.556200 127225725752832 run.py:748] Algo activity_selector step 2950 current loss 0.947310, current_train_items 81392.
I0119 22:38:28.595812 127225725752832 run.py:783] (val) algo activity_selector step 2950: {'selected': 0.9009345794392524, 'score': 0.9009345794392524, 'examples_seen': 81392, 'step': 2950, 'algorithm': 'activity_selector'}
I0119 22:38:28.595963 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.901, val scores are: activity_selector: 0.901
I0119 22:38:29.535821 127225725752832 run.py:748] Algo activity_selector step 3000 current loss 0.973025, current_train_items 82752.
I0119 22:38:29.579305 127225725752832 run.py:783] (val) algo activity_selector step 3000: {'selected': 0.9192982456140351, 'score': 0.9192982456140351, 'examples_seen': 82752, 'step': 3000, 'algorithm': 'activity_selector'}
I0119 22:38:29.579453 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0119 22:38:30.530764 127225725752832 run.py:748] Algo activity_selector step 3050 current loss 0.944092, current_train_items 84144.
I0119 22:38:30.570329 127225725752832 run.py:783] (val) algo activity_selector step 3050: {'selected': 0.9330628803245437, 'score': 0.9330628803245437, 'examples_seen': 84144, 'step': 3050, 'algorithm': 'activity_selector'}
I0119 22:38:30.570482 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0119 22:38:31.502475 127225725752832 run.py:748] Algo activity_selector step 3100 current loss 0.806925, current_train_items 85520.
I0119 22:38:31.542682 127225725752832 run.py:783] (val) algo activity_selector step 3100: {'selected': 0.9249011857707511, 'score': 0.9249011857707511, 'examples_seen': 85520, 'step': 3100, 'algorithm': 'activity_selector'}
I0119 22:38:31.542831 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.925, val scores are: activity_selector: 0.925
I0119 22:38:32.482982 127225725752832 run.py:748] Algo activity_selector step 3150 current loss 0.759663, current_train_items 86896.
I0119 22:38:32.523933 127225725752832 run.py:783] (val) algo activity_selector step 3150: {'selected': 0.9584905660377357, 'score': 0.9584905660377357, 'examples_seen': 86896, 'step': 3150, 'algorithm': 'activity_selector'}
I0119 22:38:32.524163 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0119 22:38:33.459056 127225725752832 run.py:748] Algo activity_selector step 3200 current loss 0.812321, current_train_items 88272.
I0119 22:38:33.499159 127225725752832 run.py:783] (val) algo activity_selector step 3200: {'selected': 0.9338521400778209, 'score': 0.9338521400778209, 'examples_seen': 88272, 'step': 3200, 'algorithm': 'activity_selector'}
I0119 22:38:33.499311 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0119 22:38:34.418097 127225725752832 run.py:748] Algo activity_selector step 3250 current loss 1.103188, current_train_items 89664.
I0119 22:38:34.459888 127225725752832 run.py:783] (val) algo activity_selector step 3250: {'selected': 0.9431818181818182, 'score': 0.9431818181818182, 'examples_seen': 89664, 'step': 3250, 'algorithm': 'activity_selector'}
I0119 22:38:34.460036 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0119 22:38:35.401583 127225725752832 run.py:748] Algo activity_selector step 3300 current loss 0.889059, current_train_items 91040.
I0119 22:38:35.442122 127225725752832 run.py:783] (val) algo activity_selector step 3300: {'selected': 0.8994515539305302, 'score': 0.8994515539305302, 'examples_seen': 91040, 'step': 3300, 'algorithm': 'activity_selector'}
I0119 22:38:35.442283 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.899, val scores are: activity_selector: 0.899
I0119 22:38:36.364374 127225725752832 run.py:748] Algo activity_selector step 3350 current loss 0.978270, current_train_items 92400.
I0119 22:38:36.403879 127225725752832 run.py:783] (val) algo activity_selector step 3350: {'selected': 0.9420849420849421, 'score': 0.9420849420849421, 'examples_seen': 92400, 'step': 3350, 'algorithm': 'activity_selector'}
I0119 22:38:36.404031 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0119 22:38:37.322431 127225725752832 run.py:748] Algo activity_selector step 3400 current loss 1.145535, current_train_items 93792.
I0119 22:38:37.362298 127225725752832 run.py:783] (val) algo activity_selector step 3400: {'selected': 0.9615384615384615, 'score': 0.9615384615384615, 'examples_seen': 93792, 'step': 3400, 'algorithm': 'activity_selector'}
I0119 22:38:37.362448 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0119 22:38:38.297705 127225725752832 run.py:748] Algo activity_selector step 3450 current loss 1.233461, current_train_items 95168.
I0119 22:38:38.337587 127225725752832 run.py:783] (val) algo activity_selector step 3450: {'selected': 0.9484126984126984, 'score': 0.9484126984126984, 'examples_seen': 95168, 'step': 3450, 'algorithm': 'activity_selector'}
I0119 22:38:38.337738 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0119 22:38:39.266793 127225725752832 run.py:748] Algo activity_selector step 3500 current loss 0.929272, current_train_items 96544.
I0119 22:38:39.306314 127225725752832 run.py:783] (val) algo activity_selector step 3500: {'selected': 0.8996282527881041, 'score': 0.8996282527881041, 'examples_seen': 96544, 'step': 3500, 'algorithm': 'activity_selector'}
I0119 22:38:39.306468 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.900, val scores are: activity_selector: 0.900
I0119 22:38:40.245391 127225725752832 run.py:748] Algo activity_selector step 3550 current loss 0.800216, current_train_items 97936.
I0119 22:38:40.285485 127225725752832 run.py:783] (val) algo activity_selector step 3550: {'selected': 0.9593810444874274, 'score': 0.9593810444874274, 'examples_seen': 97936, 'step': 3550, 'algorithm': 'activity_selector'}
I0119 22:38:40.285644 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0119 22:38:41.212494 127225725752832 run.py:748] Algo activity_selector step 3600 current loss 1.043978, current_train_items 99312.
I0119 22:38:41.252572 127225725752832 run.py:783] (val) algo activity_selector step 3600: {'selected': 0.9512670565302146, 'score': 0.9512670565302146, 'examples_seen': 99312, 'step': 3600, 'algorithm': 'activity_selector'}
I0119 22:38:41.252724 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0119 22:38:42.190726 127225725752832 run.py:748] Algo activity_selector step 3650 current loss 0.983582, current_train_items 100688.
I0119 22:38:42.232795 127225725752832 run.py:783] (val) algo activity_selector step 3650: {'selected': 0.942857142857143, 'score': 0.942857142857143, 'examples_seen': 100688, 'step': 3650, 'algorithm': 'activity_selector'}
I0119 22:38:42.232945 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0119 22:38:43.167457 127225725752832 run.py:748] Algo activity_selector step 3700 current loss 0.768967, current_train_items 102064.
I0119 22:38:43.207449 127225725752832 run.py:783] (val) algo activity_selector step 3700: {'selected': 0.9261477045908184, 'score': 0.9261477045908184, 'examples_seen': 102064, 'step': 3700, 'algorithm': 'activity_selector'}
I0119 22:38:43.207628 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0119 22:38:44.141026 127225725752832 run.py:748] Algo activity_selector step 3750 current loss 0.834145, current_train_items 103440.
I0119 22:38:44.180717 127225725752832 run.py:783] (val) algo activity_selector step 3750: {'selected': 0.9441233140655106, 'score': 0.9441233140655106, 'examples_seen': 103440, 'step': 3750, 'algorithm': 'activity_selector'}
I0119 22:38:44.180870 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0119 22:38:45.115559 127225725752832 run.py:748] Algo activity_selector step 3800 current loss 0.644032, current_train_items 104816.
I0119 22:38:45.155203 127225725752832 run.py:783] (val) algo activity_selector step 3800: {'selected': 0.9420849420849421, 'score': 0.9420849420849421, 'examples_seen': 104816, 'step': 3800, 'algorithm': 'activity_selector'}
I0119 22:38:45.155354 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0119 22:38:46.086674 127225725752832 run.py:748] Algo activity_selector step 3850 current loss 0.774170, current_train_items 106208.
I0119 22:38:46.126804 127225725752832 run.py:783] (val) algo activity_selector step 3850: {'selected': 0.9416342412451362, 'score': 0.9416342412451362, 'examples_seen': 106208, 'step': 3850, 'algorithm': 'activity_selector'}
I0119 22:38:46.126953 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.967, current avg val score is 0.942, val scores are: activity_selector: 0.942
I0119 22:38:47.068720 127225725752832 run.py:748] Algo activity_selector step 3900 current loss 0.770792, current_train_items 107584.
I0119 22:38:47.111591 127225725752832 run.py:783] (val) algo activity_selector step 3900: {'selected': 0.9695817490494296, 'score': 0.9695817490494296, 'examples_seen': 107584, 'step': 3900, 'algorithm': 'activity_selector'}
I0119 22:38:47.111750 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.967, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0119 22:38:48.071966 127225725752832 run.py:748] Algo activity_selector step 3950 current loss 0.582848, current_train_items 108960.
I0119 22:38:48.111590 127225725752832 run.py:783] (val) algo activity_selector step 3950: {'selected': 0.961038961038961, 'score': 0.961038961038961, 'examples_seen': 108960, 'step': 3950, 'algorithm': 'activity_selector'}
I0119 22:38:48.111741 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0119 22:38:49.046897 127225725752832 run.py:748] Algo activity_selector step 4000 current loss 0.820187, current_train_items 110336.
I0119 22:38:49.085898 127225725752832 run.py:783] (val) algo activity_selector step 4000: {'selected': 0.8970873786407767, 'score': 0.8970873786407767, 'examples_seen': 110336, 'step': 4000, 'algorithm': 'activity_selector'}
I0119 22:38:49.086050 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.897, val scores are: activity_selector: 0.897
I0119 22:38:50.053034 127225725752832 run.py:748] Algo activity_selector step 4050 current loss 1.047101, current_train_items 111712.
I0119 22:38:50.092225 127225725752832 run.py:783] (val) algo activity_selector step 4050: {'selected': 0.9481765834932822, 'score': 0.9481765834932822, 'examples_seen': 111712, 'step': 4050, 'algorithm': 'activity_selector'}
I0119 22:38:50.092375 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0119 22:38:51.024050 127225725752832 run.py:748] Algo activity_selector step 4100 current loss 0.624096, current_train_items 113088.
I0119 22:38:51.063921 127225725752832 run.py:783] (val) algo activity_selector step 4100: {'selected': 0.9650092081031307, 'score': 0.9650092081031307, 'examples_seen': 113088, 'step': 4100, 'algorithm': 'activity_selector'}
I0119 22:38:51.064073 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0119 22:38:51.990674 127225725752832 run.py:748] Algo activity_selector step 4150 current loss 0.767522, current_train_items 114480.
I0119 22:38:52.030927 127225725752832 run.py:783] (val) algo activity_selector step 4150: {'selected': 0.9509433962264151, 'score': 0.9509433962264151, 'examples_seen': 114480, 'step': 4150, 'algorithm': 'activity_selector'}
I0119 22:38:52.031093 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0119 22:38:52.960387 127225725752832 run.py:748] Algo activity_selector step 4200 current loss 1.206145, current_train_items 115856.
I0119 22:38:53.000789 127225725752832 run.py:783] (val) algo activity_selector step 4200: {'selected': 0.9333333333333333, 'score': 0.9333333333333333, 'examples_seen': 115856, 'step': 4200, 'algorithm': 'activity_selector'}
I0119 22:38:53.000941 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.933, val scores are: activity_selector: 0.933
I0119 22:38:53.916269 127225725752832 run.py:748] Algo activity_selector step 4250 current loss 0.734588, current_train_items 117216.
I0119 22:38:53.957791 127225725752832 run.py:783] (val) algo activity_selector step 4250: {'selected': 0.9349112426035502, 'score': 0.9349112426035502, 'examples_seen': 117216, 'step': 4250, 'algorithm': 'activity_selector'}
I0119 22:38:53.957940 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0119 22:38:54.894502 127225725752832 run.py:748] Algo activity_selector step 4300 current loss 1.598140, current_train_items 118624.
I0119 22:38:54.937131 127225725752832 run.py:783] (val) algo activity_selector step 4300: {'selected': 0.906015037593985, 'score': 0.906015037593985, 'examples_seen': 118624, 'step': 4300, 'algorithm': 'activity_selector'}
I0119 22:38:54.937285 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.906, val scores are: activity_selector: 0.906
I0119 22:38:55.877186 127225725752832 run.py:748] Algo activity_selector step 4350 current loss 0.679719, current_train_items 119984.
I0119 22:38:55.917153 127225725752832 run.py:783] (val) algo activity_selector step 4350: {'selected': 0.9310344827586207, 'score': 0.9310344827586207, 'examples_seen': 119984, 'step': 4350, 'algorithm': 'activity_selector'}
I0119 22:38:55.917304 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0119 22:38:56.858195 127225725752832 run.py:748] Algo activity_selector step 4400 current loss 0.840850, current_train_items 121360.
I0119 22:38:56.898130 127225725752832 run.py:783] (val) algo activity_selector step 4400: {'selected': 0.9411764705882353, 'score': 0.9411764705882353, 'examples_seen': 121360, 'step': 4400, 'algorithm': 'activity_selector'}
I0119 22:38:56.898287 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0119 22:38:57.829566 127225725752832 run.py:748] Algo activity_selector step 4450 current loss 1.190683, current_train_items 122752.
I0119 22:38:57.868243 127225725752832 run.py:783] (val) algo activity_selector step 4450: {'selected': 0.9298597194388778, 'score': 0.9298597194388778, 'examples_seen': 122752, 'step': 4450, 'algorithm': 'activity_selector'}
I0119 22:38:57.868407 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0119 22:38:58.801275 127225725752832 run.py:748] Algo activity_selector step 4500 current loss 0.788501, current_train_items 124128.
I0119 22:38:58.843131 127225725752832 run.py:783] (val) algo activity_selector step 4500: {'selected': 0.9606299212598426, 'score': 0.9606299212598426, 'examples_seen': 124128, 'step': 4500, 'algorithm': 'activity_selector'}
I0119 22:38:58.843276 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.961, val scores are: activity_selector: 0.961
I0119 22:38:59.785256 127225725752832 run.py:748] Algo activity_selector step 4550 current loss 0.631059, current_train_items 125504.
I0119 22:38:59.825006 127225725752832 run.py:783] (val) algo activity_selector step 4550: {'selected': 0.9206963249516441, 'score': 0.9206963249516441, 'examples_seen': 125504, 'step': 4550, 'algorithm': 'activity_selector'}
I0119 22:38:59.825155 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0119 22:39:00.750405 127225725752832 run.py:748] Algo activity_selector step 4600 current loss 1.274600, current_train_items 126880.
I0119 22:39:00.789825 127225725752832 run.py:783] (val) algo activity_selector step 4600: {'selected': 0.8797127468581688, 'score': 0.8797127468581688, 'examples_seen': 126880, 'step': 4600, 'algorithm': 'activity_selector'}
I0119 22:39:00.789976 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.880, val scores are: activity_selector: 0.880
I0119 22:39:01.730860 127225725752832 run.py:748] Algo activity_selector step 4650 current loss 0.987662, current_train_items 128272.
I0119 22:39:01.770970 127225725752832 run.py:783] (val) algo activity_selector step 4650: {'selected': 0.9473684210526316, 'score': 0.9473684210526316, 'examples_seen': 128272, 'step': 4650, 'algorithm': 'activity_selector'}
I0119 22:39:01.771121 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0119 22:39:02.704593 127225725752832 run.py:748] Algo activity_selector step 4700 current loss 0.740471, current_train_items 129632.
I0119 22:39:02.743923 127225725752832 run.py:783] (val) algo activity_selector step 4700: {'selected': 0.9213893967093235, 'score': 0.9213893967093235, 'examples_seen': 129632, 'step': 4700, 'algorithm': 'activity_selector'}
I0119 22:39:02.744073 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.921, val scores are: activity_selector: 0.921
I0119 22:39:03.678927 127225725752832 run.py:748] Algo activity_selector step 4750 current loss 0.925336, current_train_items 131024.
I0119 22:39:03.719957 127225725752832 run.py:783] (val) algo activity_selector step 4750: {'selected': 0.9447619047619049, 'score': 0.9447619047619049, 'examples_seen': 131024, 'step': 4750, 'algorithm': 'activity_selector'}
I0119 22:39:03.720107 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0119 22:39:04.657155 127225725752832 run.py:748] Algo activity_selector step 4800 current loss 0.793881, current_train_items 132400.
I0119 22:39:04.696372 127225725752832 run.py:783] (val) algo activity_selector step 4800: {'selected': 0.9411764705882353, 'score': 0.9411764705882353, 'examples_seen': 132400, 'step': 4800, 'algorithm': 'activity_selector'}
I0119 22:39:04.696524 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0119 22:39:05.622911 127225725752832 run.py:748] Algo activity_selector step 4850 current loss 0.655772, current_train_items 133760.
I0119 22:39:05.664016 127225725752832 run.py:783] (val) algo activity_selector step 4850: {'selected': 0.9386281588447652, 'score': 0.9386281588447652, 'examples_seen': 133760, 'step': 4850, 'algorithm': 'activity_selector'}
I0119 22:39:05.664166 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0119 22:39:06.611756 127225725752832 run.py:748] Algo activity_selector step 4900 current loss 0.563437, current_train_items 135168.
I0119 22:39:06.651321 127225725752832 run.py:783] (val) algo activity_selector step 4900: {'selected': 0.9587073608617595, 'score': 0.9587073608617595, 'examples_seen': 135168, 'step': 4900, 'algorithm': 'activity_selector'}
I0119 22:39:06.651469 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0119 22:39:07.578504 127225725752832 run.py:748] Algo activity_selector step 4950 current loss 0.599720, current_train_items 136528.
I0119 22:39:07.619376 127225725752832 run.py:783] (val) algo activity_selector step 4950: {'selected': 0.9692307692307692, 'score': 0.9692307692307692, 'examples_seen': 136528, 'step': 4950, 'algorithm': 'activity_selector'}
I0119 22:39:07.619528 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.969, val scores are: activity_selector: 0.969
I0119 22:39:08.555413 127225725752832 run.py:748] Algo activity_selector step 5000 current loss 0.839361, current_train_items 137920.
I0119 22:39:08.596008 127225725752832 run.py:783] (val) algo activity_selector step 5000: {'selected': 0.9137254901960785, 'score': 0.9137254901960785, 'examples_seen': 137920, 'step': 5000, 'algorithm': 'activity_selector'}
I0119 22:39:08.596156 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.914, val scores are: activity_selector: 0.914
I0119 22:39:09.523287 127225725752832 run.py:748] Algo activity_selector step 5050 current loss 0.861214, current_train_items 139296.
I0119 22:39:09.562383 127225725752832 run.py:783] (val) algo activity_selector step 5050: {'selected': 0.956, 'score': 0.956, 'examples_seen': 139296, 'step': 5050, 'algorithm': 'activity_selector'}
I0119 22:39:09.562535 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0119 22:39:10.485174 127225725752832 run.py:748] Algo activity_selector step 5100 current loss 0.750787, current_train_items 140656.
I0119 22:39:10.525289 127225725752832 run.py:783] (val) algo activity_selector step 5100: {'selected': 0.9555555555555556, 'score': 0.9555555555555556, 'examples_seen': 140656, 'step': 5100, 'algorithm': 'activity_selector'}
I0119 22:39:10.525440 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0119 22:39:11.461748 127225725752832 run.py:748] Algo activity_selector step 5150 current loss 1.223949, current_train_items 142048.
I0119 22:39:11.502068 127225725752832 run.py:783] (val) algo activity_selector step 5150: {'selected': 0.9546351084812623, 'score': 0.9546351084812623, 'examples_seen': 142048, 'step': 5150, 'algorithm': 'activity_selector'}
I0119 22:39:11.502218 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0119 22:39:12.414161 127225725752832 run.py:748] Algo activity_selector step 5200 current loss 0.565798, current_train_items 143424.
I0119 22:39:12.454471 127225725752832 run.py:783] (val) algo activity_selector step 5200: {'selected': 0.958904109589041, 'score': 0.958904109589041, 'examples_seen': 143424, 'step': 5200, 'algorithm': 'activity_selector'}
I0119 22:39:12.454630 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0119 22:39:13.394654 127225725752832 run.py:748] Algo activity_selector step 5250 current loss 0.714153, current_train_items 144816.
I0119 22:39:13.433686 127225725752832 run.py:783] (val) algo activity_selector step 5250: {'selected': 0.9357798165137615, 'score': 0.9357798165137615, 'examples_seen': 144816, 'step': 5250, 'algorithm': 'activity_selector'}
I0119 22:39:13.433855 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0119 22:39:14.352129 127225725752832 run.py:748] Algo activity_selector step 5300 current loss 0.743286, current_train_items 146176.
I0119 22:39:14.392047 127225725752832 run.py:783] (val) algo activity_selector step 5300: {'selected': 0.9218749999999999, 'score': 0.9218749999999999, 'examples_seen': 146176, 'step': 5300, 'algorithm': 'activity_selector'}
I0119 22:39:14.392199 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.922, val scores are: activity_selector: 0.922
I0119 22:39:15.324115 127225725752832 run.py:748] Algo activity_selector step 5350 current loss 0.814519, current_train_items 147584.
I0119 22:39:15.367380 127225725752832 run.py:783] (val) algo activity_selector step 5350: {'selected': 0.9304812834224598, 'score': 0.9304812834224598, 'examples_seen': 147584, 'step': 5350, 'algorithm': 'activity_selector'}
I0119 22:39:15.367529 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.930, val scores are: activity_selector: 0.930
I0119 22:39:16.308918 127225725752832 run.py:748] Algo activity_selector step 5400 current loss 0.574571, current_train_items 148944.
I0119 22:39:16.348275 127225725752832 run.py:783] (val) algo activity_selector step 5400: {'selected': 0.9437751004016064, 'score': 0.9437751004016064, 'examples_seen': 148944, 'step': 5400, 'algorithm': 'activity_selector'}
I0119 22:39:16.348422 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0119 22:39:17.278803 127225725752832 run.py:748] Algo activity_selector step 5450 current loss 0.705710, current_train_items 150304.
I0119 22:39:17.322422 127225725752832 run.py:783] (val) algo activity_selector step 5450: {'selected': 0.967741935483871, 'score': 0.967741935483871, 'examples_seen': 150304, 'step': 5450, 'algorithm': 'activity_selector'}
I0119 22:39:17.322589 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.968, val scores are: activity_selector: 0.968
I0119 22:39:18.263484 127225725752832 run.py:748] Algo activity_selector step 5500 current loss 0.552800, current_train_items 151712.
I0119 22:39:18.305329 127225725752832 run.py:783] (val) algo activity_selector step 5500: {'selected': 0.9168278529980659, 'score': 0.9168278529980659, 'examples_seen': 151712, 'step': 5500, 'algorithm': 'activity_selector'}
I0119 22:39:18.305478 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.970, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0119 22:39:19.233243 127225725752832 run.py:748] Algo activity_selector step 5550 current loss 0.701233, current_train_items 153072.
I0119 22:39:19.273599 127225725752832 run.py:783] (val) algo activity_selector step 5550: {'selected': 0.9706959706959706, 'score': 0.9706959706959706, 'examples_seen': 153072, 'step': 5550, 'algorithm': 'activity_selector'}
I0119 22:39:19.273750 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.970, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0119 22:39:20.245430 127225725752832 run.py:748] Algo activity_selector step 5600 current loss 0.640132, current_train_items 154464.
I0119 22:39:20.284948 127225725752832 run.py:783] (val) algo activity_selector step 5600: {'selected': 0.9338842975206612, 'score': 0.9338842975206612, 'examples_seen': 154464, 'step': 5600, 'algorithm': 'activity_selector'}
I0119 22:39:20.285110 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.934, val scores are: activity_selector: 0.934
I0119 22:39:21.205972 127225725752832 run.py:748] Algo activity_selector step 5650 current loss 0.603963, current_train_items 155840.
I0119 22:39:21.246236 127225725752832 run.py:783] (val) algo activity_selector step 5650: {'selected': 0.9169811320754717, 'score': 0.9169811320754717, 'examples_seen': 155840, 'step': 5650, 'algorithm': 'activity_selector'}
I0119 22:39:21.246387 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0119 22:39:22.173111 127225725752832 run.py:748] Algo activity_selector step 5700 current loss 0.665782, current_train_items 157216.
I0119 22:39:22.212801 127225725752832 run.py:783] (val) algo activity_selector step 5700: {'selected': 0.9556025369978857, 'score': 0.9556025369978857, 'examples_seen': 157216, 'step': 5700, 'algorithm': 'activity_selector'}
I0119 22:39:22.212950 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.971, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0119 22:39:23.153725 127225725752832 run.py:748] Algo activity_selector step 5750 current loss 0.786190, current_train_items 158592.
I0119 22:39:23.193093 127225725752832 run.py:783] (val) algo activity_selector step 5750: {'selected': 0.973630831643002, 'score': 0.973630831643002, 'examples_seen': 158592, 'step': 5750, 'algorithm': 'activity_selector'}
I0119 22:39:23.193244 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.971, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0119 22:39:24.151130 127225725752832 run.py:748] Algo activity_selector step 5800 current loss 0.647125, current_train_items 159968.
I0119 22:39:24.191009 127225725752832 run.py:783] (val) algo activity_selector step 5800: {'selected': 0.9566854990583804, 'score': 0.9566854990583804, 'examples_seen': 159968, 'step': 5800, 'algorithm': 'activity_selector'}
I0119 22:39:24.191155 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.974, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0119 22:39:25.132744 127225725752832 run.py:748] Algo activity_selector step 5850 current loss 0.658544, current_train_items 161360.
I0119 22:39:25.176269 127225725752832 run.py:783] (val) algo activity_selector step 5850: {'selected': 0.9574036511156186, 'score': 0.9574036511156186, 'examples_seen': 161360, 'step': 5850, 'algorithm': 'activity_selector'}
I0119 22:39:25.176420 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.974, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0119 22:39:26.096639 127225725752832 run.py:748] Algo activity_selector step 5900 current loss 0.573919, current_train_items 162720.
I0119 22:39:26.137504 127225725752832 run.py:783] (val) algo activity_selector step 5900: {'selected': 0.9555555555555555, 'score': 0.9555555555555555, 'examples_seen': 162720, 'step': 5900, 'algorithm': 'activity_selector'}
I0119 22:39:26.137660 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.974, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0119 22:39:27.061771 127225725752832 run.py:748] Algo activity_selector step 5950 current loss 0.495763, current_train_items 164112.
I0119 22:39:27.101740 127225725752832 run.py:783] (val) algo activity_selector step 5950: {'selected': 0.9442379182156133, 'score': 0.9442379182156133, 'examples_seen': 164112, 'step': 5950, 'algorithm': 'activity_selector'}
I0119 22:39:27.101886 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.974, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0119 22:39:28.047091 127225725752832 run.py:748] Algo activity_selector step 6000 current loss 0.686845, current_train_items 165488.
I0119 22:39:28.086482 127225725752832 run.py:783] (val) algo activity_selector step 6000: {'selected': 0.972972972972973, 'score': 0.972972972972973, 'examples_seen': 165488, 'step': 6000, 'algorithm': 'activity_selector'}
I0119 22:39:28.086639 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.974, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0119 22:39:29.013516 127225725752832 run.py:748] Algo activity_selector step 6050 current loss 0.652234, current_train_items 166864.
I0119 22:39:29.052812 127225725752832 run.py:783] (val) algo activity_selector step 6050: {'selected': 0.9165048543689321, 'score': 0.9165048543689321, 'examples_seen': 166864, 'step': 6050, 'algorithm': 'activity_selector'}
I0119 22:39:29.052961 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.974, current avg val score is 0.917, val scores are: activity_selector: 0.917
I0119 22:39:29.997951 127225725752832 run.py:748] Algo activity_selector step 6100 current loss 0.775276, current_train_items 168256.
I0119 22:39:30.037894 127225725752832 run.py:783] (val) algo activity_selector step 6100: {'selected': 0.9529411764705882, 'score': 0.9529411764705882, 'examples_seen': 168256, 'step': 6100, 'algorithm': 'activity_selector'}
I0119 22:39:30.038043 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.974, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0119 22:39:30.971931 127225725752832 run.py:748] Algo activity_selector step 6150 current loss 0.704184, current_train_items 169616.
I0119 22:39:31.011660 127225725752832 run.py:783] (val) algo activity_selector step 6150: {'selected': 0.9554140127388534, 'score': 0.9554140127388534, 'examples_seen': 169616, 'step': 6150, 'algorithm': 'activity_selector'}
I0119 22:39:31.011810 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.974, current avg val score is 0.955, val scores are: activity_selector: 0.955
I0119 22:39:31.943930 127225725752832 run.py:748] Algo activity_selector step 6200 current loss 0.662926, current_train_items 171008.
I0119 22:39:31.987514 127225725752832 run.py:783] (val) algo activity_selector step 6200: {'selected': 0.9188034188034189, 'score': 0.9188034188034189, 'examples_seen': 171008, 'step': 6200, 'algorithm': 'activity_selector'}
I0119 22:39:31.987674 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.974, current avg val score is 0.919, val scores are: activity_selector: 0.919
I0119 22:39:32.917927 127225725752832 run.py:748] Algo activity_selector step 6250 current loss 0.538542, current_train_items 172384.
I0119 22:39:32.958510 127225725752832 run.py:783] (val) algo activity_selector step 6250: {'selected': 0.9636711281070747, 'score': 0.9636711281070747, 'examples_seen': 172384, 'step': 6250, 'algorithm': 'activity_selector'}
I0119 22:39:32.958690 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.974, current avg val score is 0.964, val scores are: activity_selector: 0.964
I0119 22:39:33.893769 127225725752832 run.py:748] Algo activity_selector step 6300 current loss 0.552444, current_train_items 173760.
I0119 22:39:33.933588 127225725752832 run.py:783] (val) algo activity_selector step 6300: {'selected': 0.9727626459143969, 'score': 0.9727626459143969, 'examples_seen': 173760, 'step': 6300, 'algorithm': 'activity_selector'}
I0119 22:39:33.933783 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.974, current avg val score is 0.973, val scores are: activity_selector: 0.973
I0119 22:39:34.868487 127225725752832 run.py:748] Algo activity_selector step 6350 current loss 0.581945, current_train_items 175136.
I0119 22:39:34.912124 127225725752832 run.py:783] (val) algo activity_selector step 6350: {'selected': 0.9351669941060904, 'score': 0.9351669941060904, 'examples_seen': 175136, 'step': 6350, 'algorithm': 'activity_selector'}
I0119 22:39:34.912285 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.974, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0119 22:39:35.836185 127225725752832 run.py:748] Algo activity_selector step 6400 current loss 0.828575, current_train_items 176528.
I0119 22:39:35.876340 127225725752832 run.py:783] (val) algo activity_selector step 6400: {'selected': 0.9357429718875503, 'score': 0.9357429718875503, 'examples_seen': 176528, 'step': 6400, 'algorithm': 'activity_selector'}
I0119 22:39:35.876492 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.974, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0119 22:39:36.817042 127225725752832 run.py:748] Algo activity_selector step 6450 current loss 0.517990, current_train_items 177904.
I0119 22:39:36.856222 127225725752832 run.py:783] (val) algo activity_selector step 6450: {'selected': 0.9357142857142856, 'score': 0.9357142857142856, 'examples_seen': 177904, 'step': 6450, 'algorithm': 'activity_selector'}
I0119 22:39:36.856373 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.974, current avg val score is 0.936, val scores are: activity_selector: 0.936
I0119 22:39:37.781031 127225725752832 run.py:748] Algo activity_selector step 6500 current loss 0.512442, current_train_items 179264.
I0119 22:39:37.820803 127225725752832 run.py:783] (val) algo activity_selector step 6500: {'selected': 0.9615384615384615, 'score': 0.9615384615384615, 'examples_seen': 179264, 'step': 6500, 'algorithm': 'activity_selector'}
I0119 22:39:37.820953 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.974, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0119 22:39:38.749668 127225725752832 run.py:748] Algo activity_selector step 6550 current loss 0.648315, current_train_items 180656.
I0119 22:39:38.789604 127225725752832 run.py:783] (val) algo activity_selector step 6550: {'selected': 0.9589552238805971, 'score': 0.9589552238805971, 'examples_seen': 180656, 'step': 6550, 'algorithm': 'activity_selector'}
I0119 22:39:38.789765 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.974, current avg val score is 0.959, val scores are: activity_selector: 0.959
I0119 22:39:39.731638 127225725752832 run.py:748] Algo activity_selector step 6600 current loss 0.722173, current_train_items 182032.
I0119 22:39:39.771710 127225725752832 run.py:783] (val) algo activity_selector step 6600: {'selected': 0.9394495412844035, 'score': 0.9394495412844035, 'examples_seen': 182032, 'step': 6600, 'algorithm': 'activity_selector'}
I0119 22:39:39.771861 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.974, current avg val score is 0.939, val scores are: activity_selector: 0.939
I0119 22:39:40.701460 127225725752832 run.py:748] Algo activity_selector step 6650 current loss 0.821522, current_train_items 183408.
I0119 22:39:40.745522 127225725752832 run.py:783] (val) algo activity_selector step 6650: {'selected': 0.8854368932038834, 'score': 0.8854368932038834, 'examples_seen': 183408, 'step': 6650, 'algorithm': 'activity_selector'}
I0119 22:39:40.745678 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.974, current avg val score is 0.885, val scores are: activity_selector: 0.885
I0119 22:39:41.683817 127225725752832 run.py:748] Algo activity_selector step 6700 current loss 0.666889, current_train_items 184800.
I0119 22:39:41.723375 127225725752832 run.py:783] (val) algo activity_selector step 6700: {'selected': 0.9707602339181287, 'score': 0.9707602339181287, 'examples_seen': 184800, 'step': 6700, 'algorithm': 'activity_selector'}
I0119 22:39:41.723531 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.974, current avg val score is 0.971, val scores are: activity_selector: 0.971
I0119 22:39:42.650558 127225725752832 run.py:748] Algo activity_selector step 6750 current loss 0.582882, current_train_items 186176.
I0119 22:39:42.691047 127225725752832 run.py:783] (val) algo activity_selector step 6750: {'selected': 0.9758064516129032, 'score': 0.9758064516129032, 'examples_seen': 186176, 'step': 6750, 'algorithm': 'activity_selector'}
I0119 22:39:42.691197 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.974, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0119 22:39:43.655680 127225725752832 run.py:748] Algo activity_selector step 6800 current loss 0.671595, current_train_items 187536.
I0119 22:39:43.695702 127225725752832 run.py:783] (val) algo activity_selector step 6800: {'selected': 0.9289827255278311, 'score': 0.9289827255278311, 'examples_seen': 187536, 'step': 6800, 'algorithm': 'activity_selector'}
I0119 22:39:43.695849 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.929, val scores are: activity_selector: 0.929
I0119 22:39:44.631136 127225725752832 run.py:748] Algo activity_selector step 6850 current loss 0.825054, current_train_items 188928.
I0119 22:39:44.671410 127225725752832 run.py:783] (val) algo activity_selector step 6850: {'selected': 0.9757914338919926, 'score': 0.9757914338919926, 'examples_seen': 188928, 'step': 6850, 'algorithm': 'activity_selector'}
I0119 22:39:44.671567 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.976, val scores are: activity_selector: 0.976
I0119 22:39:45.606931 127225725752832 run.py:748] Algo activity_selector step 6900 current loss 0.850861, current_train_items 190304.
I0119 22:39:45.647305 127225725752832 run.py:783] (val) algo activity_selector step 6900: {'selected': 0.9427480916030534, 'score': 0.9427480916030534, 'examples_seen': 190304, 'step': 6900, 'algorithm': 'activity_selector'}
I0119 22:39:45.647454 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0119 22:39:46.579446 127225725752832 run.py:748] Algo activity_selector step 6950 current loss 0.560974, current_train_items 191680.
I0119 22:39:46.619570 127225725752832 run.py:783] (val) algo activity_selector step 6950: {'selected': 0.9458917835671343, 'score': 0.9458917835671343, 'examples_seen': 191680, 'step': 6950, 'algorithm': 'activity_selector'}
I0119 22:39:46.619721 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0119 22:39:47.545164 127225725752832 run.py:748] Algo activity_selector step 7000 current loss 0.730224, current_train_items 193072.
I0119 22:39:47.584778 127225725752832 run.py:783] (val) algo activity_selector step 7000: {'selected': 0.9574036511156186, 'score': 0.9574036511156186, 'examples_seen': 193072, 'step': 7000, 'algorithm': 'activity_selector'}
I0119 22:39:47.584932 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0119 22:39:48.513981 127225725752832 run.py:748] Algo activity_selector step 7050 current loss 0.408086, current_train_items 194448.
I0119 22:39:48.556812 127225725752832 run.py:783] (val) algo activity_selector step 7050: {'selected': 0.941398865784499, 'score': 0.941398865784499, 'examples_seen': 194448, 'step': 7050, 'algorithm': 'activity_selector'}
I0119 22:39:48.556962 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0119 22:39:49.482431 127225725752832 run.py:748] Algo activity_selector step 7100 current loss 0.579095, current_train_items 195824.
I0119 22:39:49.522536 127225725752832 run.py:783] (val) algo activity_selector step 7100: {'selected': 0.955719557195572, 'score': 0.955719557195572, 'examples_seen': 195824, 'step': 7100, 'algorithm': 'activity_selector'}
I0119 22:39:49.522696 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0119 22:39:50.450784 127225725752832 run.py:748] Algo activity_selector step 7150 current loss 0.636984, current_train_items 197200.
I0119 22:39:50.491106 127225725752832 run.py:783] (val) algo activity_selector step 7150: {'selected': 0.9457943925233646, 'score': 0.9457943925233646, 'examples_seen': 197200, 'step': 7150, 'algorithm': 'activity_selector'}
I0119 22:39:50.491257 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0119 22:39:51.431961 127225725752832 run.py:748] Algo activity_selector step 7200 current loss 0.598302, current_train_items 198576.
I0119 22:39:51.472984 127225725752832 run.py:783] (val) algo activity_selector step 7200: {'selected': 0.9473684210526315, 'score': 0.9473684210526315, 'examples_seen': 198576, 'step': 7200, 'algorithm': 'activity_selector'}
I0119 22:39:51.473134 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.947, val scores are: activity_selector: 0.947
I0119 22:39:52.402223 127225725752832 run.py:748] Algo activity_selector step 7250 current loss 0.628031, current_train_items 199952.
I0119 22:39:52.441538 127225725752832 run.py:783] (val) algo activity_selector step 7250: {'selected': 0.9647058823529412, 'score': 0.9647058823529412, 'examples_seen': 199952, 'step': 7250, 'algorithm': 'activity_selector'}
I0119 22:39:52.441694 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0119 22:39:53.374517 127225725752832 run.py:748] Algo activity_selector step 7300 current loss 0.789058, current_train_items 201344.
I0119 22:39:53.414321 127225725752832 run.py:783] (val) algo activity_selector step 7300: {'selected': 0.940952380952381, 'score': 0.940952380952381, 'examples_seen': 201344, 'step': 7300, 'algorithm': 'activity_selector'}
I0119 22:39:53.414471 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0119 22:39:54.342599 127225725752832 run.py:748] Algo activity_selector step 7350 current loss 0.747819, current_train_items 202720.
I0119 22:39:54.382678 127225725752832 run.py:783] (val) algo activity_selector step 7350: {'selected': 0.9352818371607515, 'score': 0.9352818371607515, 'examples_seen': 202720, 'step': 7350, 'algorithm': 'activity_selector'}
I0119 22:39:54.382824 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0119 22:39:55.300047 127225725752832 run.py:748] Algo activity_selector step 7400 current loss 0.579286, current_train_items 204080.
I0119 22:39:55.340184 127225725752832 run.py:783] (val) algo activity_selector step 7400: {'selected': 0.9700598802395209, 'score': 0.9700598802395209, 'examples_seen': 204080, 'step': 7400, 'algorithm': 'activity_selector'}
I0119 22:39:55.340365 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.970, val scores are: activity_selector: 0.970
I0119 22:39:56.280234 127225725752832 run.py:748] Algo activity_selector step 7450 current loss 0.594010, current_train_items 205488.
I0119 22:39:56.319859 127225725752832 run.py:783] (val) algo activity_selector step 7450: {'selected': 0.9518518518518518, 'score': 0.9518518518518518, 'examples_seen': 205488, 'step': 7450, 'algorithm': 'activity_selector'}
I0119 22:39:56.320044 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.976, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0119 22:39:57.248822 127225725752832 run.py:748] Algo activity_selector step 7500 current loss 0.538354, current_train_items 206848.
I0119 22:39:57.292832 127225725752832 run.py:783] (val) algo activity_selector step 7500: {'selected': 0.9845559845559846, 'score': 0.9845559845559846, 'examples_seen': 206848, 'step': 7500, 'algorithm': 'activity_selector'}
I0119 22:39:57.293030 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.976, current avg val score is 0.985, val scores are: activity_selector: 0.985
I0119 22:39:58.256729 127225725752832 run.py:748] Algo activity_selector step 7550 current loss 0.694780, current_train_items 208224.
I0119 22:39:58.296846 127225725752832 run.py:783] (val) algo activity_selector step 7550: {'selected': 0.9565217391304348, 'score': 0.9565217391304348, 'examples_seen': 208224, 'step': 7550, 'algorithm': 'activity_selector'}
I0119 22:39:58.297029 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.985, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0119 22:39:59.225137 127225725752832 run.py:748] Algo activity_selector step 7600 current loss 0.638032, current_train_items 209616.
I0119 22:39:59.265187 127225725752832 run.py:783] (val) algo activity_selector step 7600: {'selected': 0.9579524680073126, 'score': 0.9579524680073126, 'examples_seen': 209616, 'step': 7600, 'algorithm': 'activity_selector'}
I0119 22:39:59.265337 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.985, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0119 22:40:00.191050 127225725752832 run.py:748] Algo activity_selector step 7650 current loss 0.893195, current_train_items 210976.
I0119 22:40:00.232178 127225725752832 run.py:783] (val) algo activity_selector step 7650: {'selected': 0.925589836660617, 'score': 0.925589836660617, 'examples_seen': 210976, 'step': 7650, 'algorithm': 'activity_selector'}
I0119 22:40:00.232328 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.985, current avg val score is 0.926, val scores are: activity_selector: 0.926
I0119 22:40:01.169641 127225725752832 run.py:748] Algo activity_selector step 7700 current loss 0.789470, current_train_items 212368.
I0119 22:40:01.209726 127225725752832 run.py:783] (val) algo activity_selector step 7700: {'selected': 0.9516129032258065, 'score': 0.9516129032258065, 'examples_seen': 212368, 'step': 7700, 'algorithm': 'activity_selector'}
I0119 22:40:01.209880 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.985, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0119 22:40:02.129712 127225725752832 run.py:748] Algo activity_selector step 7750 current loss 0.755223, current_train_items 213744.
I0119 22:40:02.169850 127225725752832 run.py:783] (val) algo activity_selector step 7750: {'selected': 0.943609022556391, 'score': 0.943609022556391, 'examples_seen': 213744, 'step': 7750, 'algorithm': 'activity_selector'}
I0119 22:40:02.169999 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.985, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0119 22:40:03.107281 127225725752832 run.py:748] Algo activity_selector step 7800 current loss 0.608997, current_train_items 215136.
I0119 22:40:03.146885 127225725752832 run.py:783] (val) algo activity_selector step 7800: {'selected': 0.9315589353612167, 'score': 0.9315589353612167, 'examples_seen': 215136, 'step': 7800, 'algorithm': 'activity_selector'}
I0119 22:40:03.147035 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.985, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0119 22:40:04.073859 127225725752832 run.py:748] Algo activity_selector step 7850 current loss 0.407948, current_train_items 216496.
I0119 22:40:04.113631 127225725752832 run.py:783] (val) algo activity_selector step 7850: {'selected': 0.9461077844311377, 'score': 0.9461077844311377, 'examples_seen': 216496, 'step': 7850, 'algorithm': 'activity_selector'}
I0119 22:40:04.113780 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.985, current avg val score is 0.946, val scores are: activity_selector: 0.946
I0119 22:40:05.036298 127225725752832 run.py:748] Algo activity_selector step 7900 current loss 0.659231, current_train_items 217888.
I0119 22:40:05.080940 127225725752832 run.py:783] (val) algo activity_selector step 7900: {'selected': 0.9532374100719424, 'score': 0.9532374100719424, 'examples_seen': 217888, 'step': 7900, 'algorithm': 'activity_selector'}
I0119 22:40:05.081091 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.985, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0119 22:40:06.023965 127225725752832 run.py:748] Algo activity_selector step 7950 current loss 0.640936, current_train_items 219264.
I0119 22:40:06.064392 127225725752832 run.py:783] (val) algo activity_selector step 7950: {'selected': 0.9516728624535316, 'score': 0.9516728624535316, 'examples_seen': 219264, 'step': 7950, 'algorithm': 'activity_selector'}
I0119 22:40:06.064543 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.985, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0119 22:40:06.990454 127225725752832 run.py:748] Algo activity_selector step 8000 current loss 0.744330, current_train_items 220624.
I0119 22:40:07.032144 127225725752832 run.py:783] (val) algo activity_selector step 8000: {'selected': 0.9745596868884541, 'score': 0.9745596868884541, 'examples_seen': 220624, 'step': 8000, 'algorithm': 'activity_selector'}
I0119 22:40:07.032296 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.985, current avg val score is 0.975, val scores are: activity_selector: 0.975
I0119 22:40:07.977632 127225725752832 run.py:748] Algo activity_selector step 8050 current loss 0.609287, current_train_items 222032.
I0119 22:40:08.017759 127225725752832 run.py:783] (val) algo activity_selector step 8050: {'selected': 0.9811320754716981, 'score': 0.9811320754716981, 'examples_seen': 222032, 'step': 8050, 'algorithm': 'activity_selector'}
I0119 22:40:08.017909 127225725752832 run.py:804] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.981, val scores are: activity_selector: 0.981
I0119 22:40:08.992795 127225725752832 run.py:748] Algo activity_selector step 8100 current loss 0.534651, current_train_items 223392.
I0119 22:40:09.032396 127225725752832 run.py:783] (val) algo activity_selector step 8100: {'selected': 0.9556451612903225, 'score': 0.9556451612903225, 'examples_seen': 223392, 'step': 8100, 'algorithm': 'activity_selector'}
I0119 22:40:09.032557 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.956, val scores are: activity_selector: 0.956
I0119 22:40:09.974563 127225725752832 run.py:748] Algo activity_selector step 8150 current loss 0.687006, current_train_items 224784.
I0119 22:40:10.014880 127225725752832 run.py:783] (val) algo activity_selector step 8150: {'selected': 0.9525691699604742, 'score': 0.9525691699604742, 'examples_seen': 224784, 'step': 8150, 'algorithm': 'activity_selector'}
I0119 22:40:10.015035 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0119 22:40:10.942522 127225725752832 run.py:748] Algo activity_selector step 8200 current loss 0.576647, current_train_items 226160.
I0119 22:40:10.984899 127225725752832 run.py:783] (val) algo activity_selector step 8200: {'selected': 0.9573283858998144, 'score': 0.9573283858998144, 'examples_seen': 226160, 'step': 8200, 'algorithm': 'activity_selector'}
I0119 22:40:10.985050 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.957, val scores are: activity_selector: 0.957
I0119 22:40:11.914840 127225725752832 run.py:748] Algo activity_selector step 8250 current loss 0.602087, current_train_items 227520.
I0119 22:40:11.959079 127225725752832 run.py:783] (val) algo activity_selector step 8250: {'selected': 0.9477756286266925, 'score': 0.9477756286266925, 'examples_seen': 227520, 'step': 8250, 'algorithm': 'activity_selector'}
I0119 22:40:11.959257 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.948, val scores are: activity_selector: 0.948
I0119 22:40:12.900404 127225725752832 run.py:748] Algo activity_selector step 8300 current loss 0.635714, current_train_items 228912.
I0119 22:40:12.943095 127225725752832 run.py:783] (val) algo activity_selector step 8300: {'selected': 0.9578544061302683, 'score': 0.9578544061302683, 'examples_seen': 228912, 'step': 8300, 'algorithm': 'activity_selector'}
I0119 22:40:12.943247 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0119 22:40:13.868411 127225725752832 run.py:748] Algo activity_selector step 8350 current loss 0.513740, current_train_items 230288.
I0119 22:40:13.908612 127225725752832 run.py:783] (val) algo activity_selector step 8350: {'selected': 0.945054945054945, 'score': 0.945054945054945, 'examples_seen': 230288, 'step': 8350, 'algorithm': 'activity_selector'}
I0119 22:40:13.908759 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.945, val scores are: activity_selector: 0.945
I0119 22:40:14.859945 127225725752832 run.py:748] Algo activity_selector step 8400 current loss 0.477158, current_train_items 231680.
I0119 22:40:14.903910 127225725752832 run.py:783] (val) algo activity_selector step 8400: {'selected': 0.9436090225563909, 'score': 0.9436090225563909, 'examples_seen': 231680, 'step': 8400, 'algorithm': 'activity_selector'}
I0119 22:40:14.904059 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0119 22:40:15.829765 127225725752832 run.py:748] Algo activity_selector step 8450 current loss 0.469701, current_train_items 233040.
I0119 22:40:15.869110 127225725752832 run.py:783] (val) algo activity_selector step 8450: {'selected': 0.9520153550863724, 'score': 0.9520153550863724, 'examples_seen': 233040, 'step': 8450, 'algorithm': 'activity_selector'}
I0119 22:40:15.869263 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.952, val scores are: activity_selector: 0.952
I0119 22:40:16.792519 127225725752832 run.py:748] Algo activity_selector step 8500 current loss 0.656535, current_train_items 234432.
I0119 22:40:16.832613 127225725752832 run.py:783] (val) algo activity_selector step 8500: {'selected': 0.9441233140655106, 'score': 0.9441233140655106, 'examples_seen': 234432, 'step': 8500, 'algorithm': 'activity_selector'}
I0119 22:40:16.832763 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0119 22:40:17.779238 127225725752832 run.py:748] Algo activity_selector step 8550 current loss 0.864868, current_train_items 235808.
I0119 22:40:17.819364 127225725752832 run.py:783] (val) algo activity_selector step 8550: {'selected': 0.9578544061302682, 'score': 0.9578544061302682, 'examples_seen': 235808, 'step': 8550, 'algorithm': 'activity_selector'}
I0119 22:40:17.819514 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0119 22:40:18.740013 127225725752832 run.py:748] Algo activity_selector step 8600 current loss 0.478262, current_train_items 237168.
I0119 22:40:18.780051 127225725752832 run.py:783] (val) algo activity_selector step 8600: {'selected': 0.9502982107355865, 'score': 0.9502982107355865, 'examples_seen': 237168, 'step': 8600, 'algorithm': 'activity_selector'}
I0119 22:40:18.780202 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.950, val scores are: activity_selector: 0.950
I0119 22:40:19.732687 127225725752832 run.py:748] Algo activity_selector step 8650 current loss 0.695791, current_train_items 238576.
I0119 22:40:19.772133 127225725752832 run.py:783] (val) algo activity_selector step 8650: {'selected': 0.9346534653465346, 'score': 0.9346534653465346, 'examples_seen': 238576, 'step': 8650, 'algorithm': 'activity_selector'}
I0119 22:40:19.772285 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0119 22:40:20.701242 127225725752832 run.py:748] Algo activity_selector step 8700 current loss 0.567687, current_train_items 239936.
I0119 22:40:20.741338 127225725752832 run.py:783] (val) algo activity_selector step 8700: {'selected': 0.9739776951672863, 'score': 0.9739776951672863, 'examples_seen': 239936, 'step': 8700, 'algorithm': 'activity_selector'}
I0119 22:40:20.741489 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.974, val scores are: activity_selector: 0.974
I0119 22:40:21.678931 127225725752832 run.py:748] Algo activity_selector step 8750 current loss 0.796850, current_train_items 241328.
I0119 22:40:21.720278 127225725752832 run.py:783] (val) algo activity_selector step 8750: {'selected': 0.9666666666666667, 'score': 0.9666666666666667, 'examples_seen': 241328, 'step': 8750, 'algorithm': 'activity_selector'}
I0119 22:40:21.720432 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.967, val scores are: activity_selector: 0.967
I0119 22:40:22.656616 127225725752832 run.py:748] Algo activity_selector step 8800 current loss 0.613502, current_train_items 242704.
I0119 22:40:22.695699 127225725752832 run.py:783] (val) algo activity_selector step 8800: {'selected': 0.9511278195488722, 'score': 0.9511278195488722, 'examples_seen': 242704, 'step': 8800, 'algorithm': 'activity_selector'}
I0119 22:40:22.695849 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0119 22:40:23.641769 127225725752832 run.py:748] Algo activity_selector step 8850 current loss 0.595019, current_train_items 244080.
I0119 22:40:23.681807 127225725752832 run.py:783] (val) algo activity_selector step 8850: {'selected': 0.9307692307692308, 'score': 0.9307692307692308, 'examples_seen': 244080, 'step': 8850, 'algorithm': 'activity_selector'}
I0119 22:40:23.681959 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.931, val scores are: activity_selector: 0.931
I0119 22:40:24.634625 127225725752832 run.py:748] Algo activity_selector step 8900 current loss 0.523675, current_train_items 245456.
I0119 22:40:24.677965 127225725752832 run.py:783] (val) algo activity_selector step 8900: {'selected': 0.9158878504672898, 'score': 0.9158878504672898, 'examples_seen': 245456, 'step': 8900, 'algorithm': 'activity_selector'}
I0119 22:40:24.678116 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.916, val scores are: activity_selector: 0.916
I0119 22:40:25.608810 127225725752832 run.py:748] Algo activity_selector step 8950 current loss 0.613957, current_train_items 246832.
I0119 22:40:25.649087 127225725752832 run.py:783] (val) algo activity_selector step 8950: {'selected': 0.9380165289256198, 'score': 0.9380165289256198, 'examples_seen': 246832, 'step': 8950, 'algorithm': 'activity_selector'}
I0119 22:40:25.649239 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0119 22:40:26.597362 127225725752832 run.py:748] Algo activity_selector step 9000 current loss 0.714458, current_train_items 248224.
I0119 22:40:26.637903 127225725752832 run.py:783] (val) algo activity_selector step 9000: {'selected': 0.9437386569872959, 'score': 0.9437386569872959, 'examples_seen': 248224, 'step': 9000, 'algorithm': 'activity_selector'}
I0119 22:40:26.638085 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.944, val scores are: activity_selector: 0.944
I0119 22:40:27.563232 127225725752832 run.py:748] Algo activity_selector step 9050 current loss 0.517203, current_train_items 249584.
I0119 22:40:27.602565 127225725752832 run.py:783] (val) algo activity_selector step 9050: {'selected': 0.9433962264150944, 'score': 0.9433962264150944, 'examples_seen': 249584, 'step': 9050, 'algorithm': 'activity_selector'}
I0119 22:40:27.602717 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.943, val scores are: activity_selector: 0.943
I0119 22:40:28.531980 127225725752832 run.py:748] Algo activity_selector step 9100 current loss 0.550394, current_train_items 250976.
I0119 22:40:28.571618 127225725752832 run.py:783] (val) algo activity_selector step 9100: {'selected': 0.9789674952198852, 'score': 0.9789674952198852, 'examples_seen': 250976, 'step': 9100, 'algorithm': 'activity_selector'}
I0119 22:40:28.571766 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.979, val scores are: activity_selector: 0.979
I0119 22:40:29.513418 127225725752832 run.py:748] Algo activity_selector step 9150 current loss 0.818184, current_train_items 252352.
I0119 22:40:29.553936 127225725752832 run.py:783] (val) algo activity_selector step 9150: {'selected': 0.9083820662768031, 'score': 0.9083820662768031, 'examples_seen': 252352, 'step': 9150, 'algorithm': 'activity_selector'}
I0119 22:40:29.554087 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.908, val scores are: activity_selector: 0.908
I0119 22:40:30.479676 127225725752832 run.py:748] Algo activity_selector step 9200 current loss 0.548372, current_train_items 253728.
I0119 22:40:30.519726 127225725752832 run.py:783] (val) algo activity_selector step 9200: {'selected': 0.9575289575289576, 'score': 0.9575289575289576, 'examples_seen': 253728, 'step': 9200, 'algorithm': 'activity_selector'}
I0119 22:40:30.519878 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.958, val scores are: activity_selector: 0.958
I0119 22:40:31.463470 127225725752832 run.py:748] Algo activity_selector step 9250 current loss 0.743179, current_train_items 255120.
I0119 22:40:31.507872 127225725752832 run.py:783] (val) algo activity_selector step 9250: {'selected': 0.9623762376237625, 'score': 0.9623762376237625, 'examples_seen': 255120, 'step': 9250, 'algorithm': 'activity_selector'}
I0119 22:40:31.508026 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.962, val scores are: activity_selector: 0.962
I0119 22:40:32.435433 127225725752832 run.py:748] Algo activity_selector step 9300 current loss 0.641683, current_train_items 256480.
I0119 22:40:32.476479 127225725752832 run.py:783] (val) algo activity_selector step 9300: {'selected': 0.9353049907578558, 'score': 0.9353049907578558, 'examples_seen': 256480, 'step': 9300, 'algorithm': 'activity_selector'}
I0119 22:40:32.476638 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.935, val scores are: activity_selector: 0.935
I0119 22:40:33.400880 127225725752832 run.py:748] Algo activity_selector step 9350 current loss 0.468495, current_train_items 257856.
I0119 22:40:33.441471 127225725752832 run.py:783] (val) algo activity_selector step 9350: {'selected': 0.9525547445255474, 'score': 0.9525547445255474, 'examples_seen': 257856, 'step': 9350, 'algorithm': 'activity_selector'}
I0119 22:40:33.441627 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.953, val scores are: activity_selector: 0.953
I0119 22:40:34.369620 127225725752832 run.py:748] Algo activity_selector step 9400 current loss 0.761064, current_train_items 259248.
I0119 22:40:34.409747 127225725752832 run.py:783] (val) algo activity_selector step 9400: {'selected': 0.9407265774378585, 'score': 0.9407265774378585, 'examples_seen': 259248, 'step': 9400, 'algorithm': 'activity_selector'}
I0119 22:40:34.409909 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.981, current avg val score is 0.941, val scores are: activity_selector: 0.941
I0119 22:40:35.342029 127225725752832 run.py:748] Algo activity_selector step 9450 current loss 0.546976, current_train_items 260624.
I0119 22:40:35.381955 127225725752832 run.py:783] (val) algo activity_selector step 9450: {'selected': 0.9857433808553971, 'score': 0.9857433808553971, 'examples_seen': 260624, 'step': 9450, 'algorithm': 'activity_selector'}
I0119 22:40:35.382102 127225725752832 run.py:804] Checkpointing best model, best avg val score was 0.981, current avg val score is 0.986, val scores are: activity_selector: 0.986
I0119 22:40:36.351607 127225725752832 run.py:748] Algo activity_selector step 9500 current loss 0.605875, current_train_items 262000.
I0119 22:40:36.391272 127225725752832 run.py:783] (val) algo activity_selector step 9500: {'selected': 0.9628180039138944, 'score': 0.9628180039138944, 'examples_seen': 262000, 'step': 9500, 'algorithm': 'activity_selector'}
I0119 22:40:36.391423 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.986, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0119 22:40:37.313076 127225725752832 run.py:748] Algo activity_selector step 9550 current loss 0.546011, current_train_items 263392.
I0119 22:40:37.352832 127225725752832 run.py:783] (val) algo activity_selector step 9550: {'selected': 0.9319587628865978, 'score': 0.9319587628865978, 'examples_seen': 263392, 'step': 9550, 'algorithm': 'activity_selector'}
I0119 22:40:37.352983 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.986, current avg val score is 0.932, val scores are: activity_selector: 0.932
I0119 22:40:38.287886 127225725752832 run.py:748] Algo activity_selector step 9600 current loss 0.796973, current_train_items 264768.
I0119 22:40:38.330620 127225725752832 run.py:783] (val) algo activity_selector step 9600: {'selected': 0.9488188976377953, 'score': 0.9488188976377953, 'examples_seen': 264768, 'step': 9600, 'algorithm': 'activity_selector'}
I0119 22:40:38.330770 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.986, current avg val score is 0.949, val scores are: activity_selector: 0.949
I0119 22:40:39.255375 127225725752832 run.py:748] Algo activity_selector step 9650 current loss 0.621625, current_train_items 266128.
I0119 22:40:39.297288 127225725752832 run.py:783] (val) algo activity_selector step 9650: {'selected': 0.926829268292683, 'score': 0.926829268292683, 'examples_seen': 266128, 'step': 9650, 'algorithm': 'activity_selector'}
I0119 22:40:39.297438 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.986, current avg val score is 0.927, val scores are: activity_selector: 0.927
I0119 22:40:40.221443 127225725752832 run.py:748] Algo activity_selector step 9700 current loss 0.459562, current_train_items 267520.
I0119 22:40:40.261287 127225725752832 run.py:783] (val) algo activity_selector step 9700: {'selected': 0.9633911368015415, 'score': 0.9633911368015415, 'examples_seen': 267520, 'step': 9700, 'algorithm': 'activity_selector'}
I0119 22:40:40.261438 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.986, current avg val score is 0.963, val scores are: activity_selector: 0.963
I0119 22:40:41.192375 127225725752832 run.py:748] Algo activity_selector step 9750 current loss 0.764977, current_train_items 268896.
I0119 22:40:41.232288 127225725752832 run.py:783] (val) algo activity_selector step 9750: {'selected': 0.9402390438247012, 'score': 0.9402390438247012, 'examples_seen': 268896, 'step': 9750, 'algorithm': 'activity_selector'}
I0119 22:40:41.232440 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.986, current avg val score is 0.940, val scores are: activity_selector: 0.940
I0119 22:40:42.153145 127225725752832 run.py:748] Algo activity_selector step 9800 current loss 0.686534, current_train_items 270272.
I0119 22:40:42.193618 127225725752832 run.py:783] (val) algo activity_selector step 9800: {'selected': 0.9722222222222222, 'score': 0.9722222222222222, 'examples_seen': 270272, 'step': 9800, 'algorithm': 'activity_selector'}
I0119 22:40:42.193766 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.986, current avg val score is 0.972, val scores are: activity_selector: 0.972
I0119 22:40:43.124261 127225725752832 run.py:748] Algo activity_selector step 9850 current loss 0.503937, current_train_items 271664.
I0119 22:40:43.166611 127225725752832 run.py:783] (val) algo activity_selector step 9850: {'selected': 0.9648798521256932, 'score': 0.9648798521256932, 'examples_seen': 271664, 'step': 9850, 'algorithm': 'activity_selector'}
I0119 22:40:43.166761 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.986, current avg val score is 0.965, val scores are: activity_selector: 0.965
I0119 22:40:44.092736 127225725752832 run.py:748] Algo activity_selector step 9900 current loss 0.606313, current_train_items 273040.
I0119 22:40:44.132631 127225725752832 run.py:783] (val) algo activity_selector step 9900: {'selected': 0.9384615384615385, 'score': 0.9384615384615385, 'examples_seen': 273040, 'step': 9900, 'algorithm': 'activity_selector'}
I0119 22:40:44.132799 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.986, current avg val score is 0.938, val scores are: activity_selector: 0.938
I0119 22:40:45.058063 127225725752832 run.py:748] Algo activity_selector step 9950 current loss 0.506705, current_train_items 274400.
I0119 22:40:45.098102 127225725752832 run.py:783] (val) algo activity_selector step 9950: {'selected': 0.9513108614232209, 'score': 0.9513108614232209, 'examples_seen': 274400, 'step': 9950, 'algorithm': 'activity_selector'}
I0119 22:40:45.098253 127225725752832 run.py:807] Not saving new best model, best avg val score was 0.986, current avg val score is 0.951, val scores are: activity_selector: 0.951
I0119 22:40:46.010795 127225725752832 run.py:813] Restoring best model from checkpoint...
I0119 22:40:53.230935 127225725752832 run.py:828] (test) algo activity_selector : {'selected': 0.8980322003577818, 'score': 0.8980322003577818, 'examples_seen': 275760, 'step': 10000, 'algorithm': 'activity_selector'}
I0119 22:40:53.231051 127225725752832 run.py:830] Done!
