I1128 21:36:38.452734 133056749540864 xla_bridge.py:889] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I1128 21:36:38.455040 133056749540864 xla_bridge.py:889] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I1128 21:36:38.785703 133056749540864 run.py:453] Model: f7 ['activity_selector']
I1128 21:36:38.785799 133056749540864 run.py:455] algorithms ['activity_selector']
I1128 21:36:38.785977 133056749540864 run.py:456] train_lengths ['4', '7', '11', '13', '16']
I1128 21:36:38.786016 133056749540864 run.py:457] train_batch_size 32
I1128 21:36:38.786115 133056749540864 run.py:458] val_batch_size 16
I1128 21:36:38.786146 133056749540864 run.py:459] test_batch_size 16
I1128 21:36:38.786175 133056749540864 run.py:460] chunked_training True
I1128 21:36:38.786264 133056749540864 run.py:461] chunk_length 16
I1128 21:36:38.786293 133056749540864 run.py:462] train_steps 10000
I1128 21:36:38.786323 133056749540864 run.py:463] eval_every 50
I1128 21:36:38.786351 133056749540864 run.py:464] test_every 500
I1128 21:36:38.786382 133056749540864 run.py:465] hidden_size 256
I1128 21:36:38.786410 133056749540864 run.py:466] nb_msg_passing_steps 1
I1128 21:36:38.786438 133056749540864 run.py:467] learning_rate 0.001
I1128 21:36:38.786525 133056749540864 run.py:468] grad_clip_max_norm 1.0
I1128 21:36:38.786557 133056749540864 run.py:469] dropout_prob 0.0
I1128 21:36:38.786585 133056749540864 run.py:470] hint_teacher_forcing 0.0
I1128 21:36:38.786613 133056749540864 run.py:471] hint_mode encoded_decoded
I1128 21:36:38.786715 133056749540864 run.py:472] hint_repred_mode soft
I1128 21:36:38.786744 133056749540864 run.py:473] use_ln True
I1128 21:36:38.786772 133056749540864 run.py:474] use_lstm True
I1128 21:36:38.786800 133056749540864 run.py:475] nb_triplet_fts 16
I1128 21:36:38.786827 133056749540864 run.py:476] encoder_init xavier_on_scalars
I1128 21:36:38.786854 133056749540864 run.py:477] processor_type f7
I1128 21:36:38.786886 133056749540864 run.py:478] checkpoint_path CLRS30
I1128 21:36:38.786915 133056749540864 run.py:479] dataset_path CLRS30
I1128 21:36:38.786943 133056749540864 run.py:480] freeze_processor False
I1128 21:36:38.786971 133056749540864 run.py:481] reduction min
I1128 21:36:38.786999 133056749540864 run.py:482] activation elu
I1128 21:36:38.787027 133056749540864 run.py:483] restore_model 
I1128 21:36:38.787057 133056749540864 run.py:484] gated True
I1128 21:36:38.787092 133056749540864 run.py:485] gated_activation tanh
I1128 21:36:38.789925 133056749540864 run.py:511] Creating samplers for algo activity_selector
W1128 21:36:38.790136 133056749540864 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1128 21:36:38.790395 133056749540864 samplers.py:109] Sampling dataset on-the-fly, unlimited samples.
W1128 21:36:38.999639 133056749540864 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1128 21:36:39.241325 133056749540864 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1128 21:36:39.542346 133056749540864 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1128 21:36:39.876580 133056749540864 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
W1128 21:36:40.262914 133056749540864 samplers.py:299] Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.ActivitySampler'>
I1128 21:36:40.263213 133056749540864 samplers.py:124] Creating a dataset with 64 samples.
I1128 21:36:40.289166 133056749540864 run.py:297] Dataset found at CLRS30/CLRS30_v1.0.0. Skipping download.
I1128 21:36:40.289916 133056749540864 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I1128 21:36:40.293389 133056749540864 dataset_info.py:708] Load dataset info from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
I1128 21:36:40.296930 133056749540864 reader.py:262] Creating a tf.data.Dataset reading 1 files located in folders: CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0.
I1128 21:36:40.351034 133056749540864 logging_logger.py:49] Constructing tf.data.Dataset clrs_dataset for split test, from CLRS30/CLRS30_v1.0.0/clrs_dataset/activity_selector_test/1.0.0
W1128 21:36:40.372349 133056749540864 ag_logging.py:142] AutoGraph could not transform <function _preprocess at 0x79032bbc0a40> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: `haiku.experimental.flax` features require `flax` to be installed.
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I1128 21:37:15.954860 133056749540864 run.py:734] Algo activity_selector step 0 current loss 5.706794, current_train_items 64.
I1128 21:37:26.180952 133056749540864 run.py:769] (val) algo activity_selector step 0: {'selected': 0.05633802816901409, 'score': 0.05633802816901409, 'examples_seen': 64, 'step': 0, 'algorithm': 'activity_selector'}
I1128 21:37:26.181159 133056749540864 run.py:790] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.056, val scores are: activity_selector: 0.056
I1128 21:38:24.913607 133056749540864 run.py:734] Algo activity_selector step 50 current loss 3.354776, current_train_items 2816.
I1128 21:38:25.066177 133056749540864 run.py:769] (val) algo activity_selector step 50: {'selected': 0.6365688487584651, 'score': 0.6365688487584651, 'examples_seen': 2816, 'step': 50, 'algorithm': 'activity_selector'}
I1128 21:38:25.066449 133056749540864 run.py:790] Checkpointing best model, best avg val score was 0.056, current avg val score is 0.637, val scores are: activity_selector: 0.637
I1128 21:38:26.825194 133056749540864 run.py:734] Algo activity_selector step 100 current loss 2.911435, current_train_items 5600.
I1128 21:38:27.024122 133056749540864 run.py:769] (val) algo activity_selector step 100: {'selected': 0.7336860670194003, 'score': 0.7336860670194003, 'examples_seen': 5600, 'step': 100, 'algorithm': 'activity_selector'}
I1128 21:38:27.024352 133056749540864 run.py:790] Checkpointing best model, best avg val score was 0.637, current avg val score is 0.734, val scores are: activity_selector: 0.734
I1128 21:38:28.797726 133056749540864 run.py:734] Algo activity_selector step 150 current loss 2.701087, current_train_items 8352.
I1128 21:38:28.987885 133056749540864 run.py:769] (val) algo activity_selector step 150: {'selected': 0.74235807860262, 'score': 0.74235807860262, 'examples_seen': 8352, 'step': 150, 'algorithm': 'activity_selector'}
I1128 21:38:28.988120 133056749540864 run.py:790] Checkpointing best model, best avg val score was 0.734, current avg val score is 0.742, val scores are: activity_selector: 0.742
I1128 21:38:30.755186 133056749540864 run.py:734] Algo activity_selector step 200 current loss 2.668167, current_train_items 11072.
I1128 21:38:30.934369 133056749540864 run.py:769] (val) algo activity_selector step 200: {'selected': 0.8038461538461539, 'score': 0.8038461538461539, 'examples_seen': 11072, 'step': 200, 'algorithm': 'activity_selector'}
I1128 21:38:30.934597 133056749540864 run.py:790] Checkpointing best model, best avg val score was 0.742, current avg val score is 0.804, val scores are: activity_selector: 0.804
I1128 21:38:32.709633 133056749540864 run.py:734] Algo activity_selector step 250 current loss 2.057561, current_train_items 13888.
I1128 21:38:32.889857 133056749540864 run.py:769] (val) algo activity_selector step 250: {'selected': 0.8252252252252253, 'score': 0.8252252252252253, 'examples_seen': 13888, 'step': 250, 'algorithm': 'activity_selector'}
I1128 21:38:32.890078 133056749540864 run.py:790] Checkpointing best model, best avg val score was 0.804, current avg val score is 0.825, val scores are: activity_selector: 0.825
I1128 21:38:34.669649 133056749540864 run.py:734] Algo activity_selector step 300 current loss 2.637925, current_train_items 16608.
I1128 21:38:34.847681 133056749540864 run.py:769] (val) algo activity_selector step 300: {'selected': 0.8556521739130435, 'score': 0.8556521739130435, 'examples_seen': 16608, 'step': 300, 'algorithm': 'activity_selector'}
I1128 21:38:34.847898 133056749540864 run.py:790] Checkpointing best model, best avg val score was 0.825, current avg val score is 0.856, val scores are: activity_selector: 0.856
I1128 21:38:36.616206 133056749540864 run.py:734] Algo activity_selector step 350 current loss 1.773421, current_train_items 19360.
I1128 21:38:36.794945 133056749540864 run.py:769] (val) algo activity_selector step 350: {'selected': 0.8382608695652174, 'score': 0.8382608695652174, 'examples_seen': 19360, 'step': 350, 'algorithm': 'activity_selector'}
I1128 21:38:36.795190 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.856, current avg val score is 0.838, val scores are: activity_selector: 0.838
I1128 21:38:38.519203 133056749540864 run.py:734] Algo activity_selector step 400 current loss 2.136991, current_train_items 22144.
I1128 21:38:38.694464 133056749540864 run.py:769] (val) algo activity_selector step 400: {'selected': 0.8617021276595745, 'score': 0.8617021276595745, 'examples_seen': 22144, 'step': 400, 'algorithm': 'activity_selector'}
I1128 21:38:38.694684 133056749540864 run.py:790] Checkpointing best model, best avg val score was 0.856, current avg val score is 0.862, val scores are: activity_selector: 0.862
I1128 21:38:40.473324 133056749540864 run.py:734] Algo activity_selector step 450 current loss 1.872847, current_train_items 24896.
I1128 21:38:40.650262 133056749540864 run.py:769] (val) algo activity_selector step 450: {'selected': 0.9021113243761996, 'score': 0.9021113243761996, 'examples_seen': 24896, 'step': 450, 'algorithm': 'activity_selector'}
I1128 21:38:40.650484 133056749540864 run.py:790] Checkpointing best model, best avg val score was 0.862, current avg val score is 0.902, val scores are: activity_selector: 0.902
I1128 21:38:42.423647 133056749540864 run.py:734] Algo activity_selector step 500 current loss 1.656289, current_train_items 27648.
I1128 21:38:42.602783 133056749540864 run.py:769] (val) algo activity_selector step 500: {'selected': 0.8329896907216495, 'score': 0.8329896907216495, 'examples_seen': 27648, 'step': 500, 'algorithm': 'activity_selector'}
I1128 21:38:42.603009 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.902, current avg val score is 0.833, val scores are: activity_selector: 0.833
I1128 21:38:44.322200 133056749540864 run.py:734] Algo activity_selector step 550 current loss 1.639379, current_train_items 30400.
I1128 21:38:44.500489 133056749540864 run.py:769] (val) algo activity_selector step 550: {'selected': 0.8796844181459567, 'score': 0.8796844181459567, 'examples_seen': 30400, 'step': 550, 'algorithm': 'activity_selector'}
I1128 21:38:44.500712 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.902, current avg val score is 0.880, val scores are: activity_selector: 0.880
I1128 21:38:46.229555 133056749540864 run.py:734] Algo activity_selector step 600 current loss 1.516582, current_train_items 33152.
I1128 21:38:46.408698 133056749540864 run.py:769] (val) algo activity_selector step 600: {'selected': 0.9409523809523811, 'score': 0.9409523809523811, 'examples_seen': 33152, 'step': 600, 'algorithm': 'activity_selector'}
I1128 21:38:46.408918 133056749540864 run.py:790] Checkpointing best model, best avg val score was 0.902, current avg val score is 0.941, val scores are: activity_selector: 0.941
I1128 21:38:48.215651 133056749540864 run.py:734] Algo activity_selector step 650 current loss 1.408074, current_train_items 35904.
I1128 21:38:48.368611 133056749540864 run.py:769] (val) algo activity_selector step 650: {'selected': 0.9236499068901304, 'score': 0.9236499068901304, 'examples_seen': 35904, 'step': 650, 'algorithm': 'activity_selector'}
I1128 21:38:48.368856 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.941, current avg val score is 0.924, val scores are: activity_selector: 0.924
I1128 21:38:50.095555 133056749540864 run.py:734] Algo activity_selector step 700 current loss 1.722234, current_train_items 38688.
I1128 21:38:50.266780 133056749540864 run.py:769] (val) algo activity_selector step 700: {'selected': 0.8706739526411658, 'score': 0.8706739526411658, 'examples_seen': 38688, 'step': 700, 'algorithm': 'activity_selector'}
I1128 21:38:50.267006 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.941, current avg val score is 0.871, val scores are: activity_selector: 0.871
I1128 21:38:52.009139 133056749540864 run.py:734] Algo activity_selector step 750 current loss 1.488523, current_train_items 41440.
I1128 21:38:52.177073 133056749540864 run.py:769] (val) algo activity_selector step 750: {'selected': 0.8893528183716075, 'score': 0.8893528183716075, 'examples_seen': 41440, 'step': 750, 'algorithm': 'activity_selector'}
I1128 21:38:52.177326 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.941, current avg val score is 0.889, val scores are: activity_selector: 0.889
I1128 21:38:53.899994 133056749540864 run.py:734] Algo activity_selector step 800 current loss 1.744686, current_train_items 44192.
I1128 21:38:54.077759 133056749540864 run.py:769] (val) algo activity_selector step 800: {'selected': 0.8049281314168378, 'score': 0.8049281314168378, 'examples_seen': 44192, 'step': 800, 'algorithm': 'activity_selector'}
I1128 21:38:54.077983 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.941, current avg val score is 0.805, val scores are: activity_selector: 0.805
I1128 21:38:55.751289 133056749540864 run.py:734] Algo activity_selector step 850 current loss 1.258711, current_train_items 46944.
I1128 21:38:55.974295 133056749540864 run.py:769] (val) algo activity_selector step 850: {'selected': 0.9077490774907749, 'score': 0.9077490774907749, 'examples_seen': 46944, 'step': 850, 'algorithm': 'activity_selector'}
I1128 21:38:55.974519 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.941, current avg val score is 0.908, val scores are: activity_selector: 0.908
I1128 21:38:57.707495 133056749540864 run.py:734] Algo activity_selector step 900 current loss 1.470572, current_train_items 49696.
I1128 21:38:57.887133 133056749540864 run.py:769] (val) algo activity_selector step 900: {'selected': 0.9087136929460581, 'score': 0.9087136929460581, 'examples_seen': 49696, 'step': 900, 'algorithm': 'activity_selector'}
I1128 21:38:57.887360 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.941, current avg val score is 0.909, val scores are: activity_selector: 0.909
I1128 21:38:59.606180 133056749540864 run.py:734] Algo activity_selector step 950 current loss 1.570407, current_train_items 52448.
I1128 21:38:59.784022 133056749540864 run.py:769] (val) algo activity_selector step 950: {'selected': 0.8596802841918294, 'score': 0.8596802841918294, 'examples_seen': 52448, 'step': 950, 'algorithm': 'activity_selector'}
I1128 21:38:59.784259 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.941, current avg val score is 0.860, val scores are: activity_selector: 0.860
I1128 21:39:01.503746 133056749540864 run.py:734] Algo activity_selector step 1000 current loss 1.427431, current_train_items 55232.
I1128 21:39:01.681919 133056749540864 run.py:769] (val) algo activity_selector step 1000: {'selected': 0.9155722326454033, 'score': 0.9155722326454033, 'examples_seen': 55232, 'step': 1000, 'algorithm': 'activity_selector'}
I1128 21:39:01.682157 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.941, current avg val score is 0.916, val scores are: activity_selector: 0.916
I1128 21:39:03.415240 133056749540864 run.py:734] Algo activity_selector step 1050 current loss 1.333408, current_train_items 57984.
I1128 21:39:03.595244 133056749540864 run.py:769] (val) algo activity_selector step 1050: {'selected': 0.8247863247863249, 'score': 0.8247863247863249, 'examples_seen': 57984, 'step': 1050, 'algorithm': 'activity_selector'}
I1128 21:39:03.595489 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.941, current avg val score is 0.825, val scores are: activity_selector: 0.825
I1128 21:39:05.312320 133056749540864 run.py:734] Algo activity_selector step 1100 current loss 1.589703, current_train_items 60736.
I1128 21:39:05.490779 133056749540864 run.py:769] (val) algo activity_selector step 1100: {'selected': 0.9227557411273487, 'score': 0.9227557411273487, 'examples_seen': 60736, 'step': 1100, 'algorithm': 'activity_selector'}
I1128 21:39:05.491001 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.941, current avg val score is 0.923, val scores are: activity_selector: 0.923
I1128 21:39:07.236602 133056749540864 run.py:734] Algo activity_selector step 1150 current loss 1.336721, current_train_items 63520.
I1128 21:39:07.387669 133056749540864 run.py:769] (val) algo activity_selector step 1150: {'selected': 0.8469184890656064, 'score': 0.8469184890656064, 'examples_seen': 63520, 'step': 1150, 'algorithm': 'activity_selector'}
I1128 21:39:07.387898 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.941, current avg val score is 0.847, val scores are: activity_selector: 0.847
I1128 21:39:09.083646 133056749540864 run.py:734] Algo activity_selector step 1200 current loss 0.950561, current_train_items 66240.
I1128 21:39:09.300261 133056749540864 run.py:769] (val) algo activity_selector step 1200: {'selected': 0.9542743538767396, 'score': 0.9542743538767396, 'examples_seen': 66240, 'step': 1200, 'algorithm': 'activity_selector'}
I1128 21:39:09.300483 133056749540864 run.py:790] Checkpointing best model, best avg val score was 0.941, current avg val score is 0.954, val scores are: activity_selector: 0.954
I1128 21:39:11.086250 133056749540864 run.py:734] Algo activity_selector step 1250 current loss 0.979405, current_train_items 68992.
I1128 21:39:11.256423 133056749540864 run.py:769] (val) algo activity_selector step 1250: {'selected': 0.9100917431192661, 'score': 0.9100917431192661, 'examples_seen': 68992, 'step': 1250, 'algorithm': 'activity_selector'}
I1128 21:39:11.256645 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.954, current avg val score is 0.910, val scores are: activity_selector: 0.910
I1128 21:39:12.979589 133056749540864 run.py:734] Algo activity_selector step 1300 current loss 1.082848, current_train_items 71776.
I1128 21:39:13.159740 133056749540864 run.py:769] (val) algo activity_selector step 1300: {'selected': 0.8876611418047881, 'score': 0.8876611418047881, 'examples_seen': 71776, 'step': 1300, 'algorithm': 'activity_selector'}
I1128 21:39:13.159978 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.954, current avg val score is 0.888, val scores are: activity_selector: 0.888
I1128 21:39:14.907755 133056749540864 run.py:734] Algo activity_selector step 1350 current loss 1.225580, current_train_items 74528.
I1128 21:39:15.072208 133056749540864 run.py:769] (val) algo activity_selector step 1350: {'selected': 0.9224652087475148, 'score': 0.9224652087475148, 'examples_seen': 74528, 'step': 1350, 'algorithm': 'activity_selector'}
I1128 21:39:15.072431 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.954, current avg val score is 0.922, val scores are: activity_selector: 0.922
I1128 21:39:16.788170 133056749540864 run.py:734] Algo activity_selector step 1400 current loss 1.269659, current_train_items 77280.
I1128 21:39:16.973928 133056749540864 run.py:769] (val) algo activity_selector step 1400: {'selected': 0.9383177570093458, 'score': 0.9383177570093458, 'examples_seen': 77280, 'step': 1400, 'algorithm': 'activity_selector'}
I1128 21:39:16.974170 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.954, current avg val score is 0.938, val scores are: activity_selector: 0.938
I1128 21:39:18.700566 133056749540864 run.py:734] Algo activity_selector step 1450 current loss 1.107408, current_train_items 80032.
I1128 21:39:18.881424 133056749540864 run.py:769] (val) algo activity_selector step 1450: {'selected': 0.830188679245283, 'score': 0.830188679245283, 'examples_seen': 80032, 'step': 1450, 'algorithm': 'activity_selector'}
I1128 21:39:18.881646 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.954, current avg val score is 0.830, val scores are: activity_selector: 0.830
I1128 21:39:20.614472 133056749540864 run.py:734] Algo activity_selector step 1500 current loss 1.042732, current_train_items 82816.
I1128 21:39:20.794715 133056749540864 run.py:769] (val) algo activity_selector step 1500: {'selected': 0.95703125, 'score': 0.95703125, 'examples_seen': 82816, 'step': 1500, 'algorithm': 'activity_selector'}
I1128 21:39:20.794938 133056749540864 run.py:790] Checkpointing best model, best avg val score was 0.954, current avg val score is 0.957, val scores are: activity_selector: 0.957
I1128 21:39:22.568256 133056749540864 run.py:734] Algo activity_selector step 1550 current loss 0.970735, current_train_items 85536.
I1128 21:39:22.741410 133056749540864 run.py:769] (val) algo activity_selector step 1550: {'selected': 0.9418181818181819, 'score': 0.9418181818181819, 'examples_seen': 85536, 'step': 1550, 'algorithm': 'activity_selector'}
I1128 21:39:22.741634 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.957, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1128 21:39:24.470053 133056749540864 run.py:734] Algo activity_selector step 1600 current loss 1.147389, current_train_items 88320.
I1128 21:39:24.649710 133056749540864 run.py:769] (val) algo activity_selector step 1600: {'selected': 0.8931297709923663, 'score': 0.8931297709923663, 'examples_seen': 88320, 'step': 1600, 'algorithm': 'activity_selector'}
I1128 21:39:24.649934 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.957, current avg val score is 0.893, val scores are: activity_selector: 0.893
I1128 21:39:26.383580 133056749540864 run.py:734] Algo activity_selector step 1650 current loss 0.973636, current_train_items 91072.
I1128 21:39:26.562880 133056749540864 run.py:769] (val) algo activity_selector step 1650: {'selected': 0.9193548387096775, 'score': 0.9193548387096775, 'examples_seen': 91072, 'step': 1650, 'algorithm': 'activity_selector'}
I1128 21:39:26.563119 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.957, current avg val score is 0.919, val scores are: activity_selector: 0.919
I1128 21:39:28.284793 133056749540864 run.py:734] Algo activity_selector step 1700 current loss 0.746382, current_train_items 93792.
I1128 21:39:28.463392 133056749540864 run.py:769] (val) algo activity_selector step 1700: {'selected': 0.9469387755102041, 'score': 0.9469387755102041, 'examples_seen': 93792, 'step': 1700, 'algorithm': 'activity_selector'}
I1128 21:39:28.463624 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.957, current avg val score is 0.947, val scores are: activity_selector: 0.947
I1128 21:39:30.189265 133056749540864 run.py:734] Algo activity_selector step 1750 current loss 1.107893, current_train_items 96608.
I1128 21:39:30.367851 133056749540864 run.py:769] (val) algo activity_selector step 1750: {'selected': 0.8848263254113345, 'score': 0.8848263254113345, 'examples_seen': 96608, 'step': 1750, 'algorithm': 'activity_selector'}
I1128 21:39:30.368075 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.957, current avg val score is 0.885, val scores are: activity_selector: 0.885
I1128 21:39:32.100895 133056749540864 run.py:734] Algo activity_selector step 1800 current loss 1.122455, current_train_items 99328.
I1128 21:39:32.278361 133056749540864 run.py:769] (val) algo activity_selector step 1800: {'selected': 0.9520153550863724, 'score': 0.9520153550863724, 'examples_seen': 99328, 'step': 1800, 'algorithm': 'activity_selector'}
I1128 21:39:32.278536 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.957, current avg val score is 0.952, val scores are: activity_selector: 0.952
I1128 21:39:33.993473 133056749540864 run.py:734] Algo activity_selector step 1850 current loss 0.918018, current_train_items 102112.
I1128 21:39:34.174830 133056749540864 run.py:769] (val) algo activity_selector step 1850: {'selected': 0.8622754491017964, 'score': 0.8622754491017964, 'examples_seen': 102112, 'step': 1850, 'algorithm': 'activity_selector'}
I1128 21:39:34.175060 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.957, current avg val score is 0.862, val scores are: activity_selector: 0.862
I1128 21:39:35.898402 133056749540864 run.py:734] Algo activity_selector step 1900 current loss 0.996021, current_train_items 104864.
I1128 21:39:36.075439 133056749540864 run.py:769] (val) algo activity_selector step 1900: {'selected': 0.9477611940298508, 'score': 0.9477611940298508, 'examples_seen': 104864, 'step': 1900, 'algorithm': 'activity_selector'}
I1128 21:39:36.075602 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.957, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1128 21:39:37.799433 133056749540864 run.py:734] Algo activity_selector step 1950 current loss 0.990534, current_train_items 107616.
I1128 21:39:37.966964 133056749540864 run.py:769] (val) algo activity_selector step 1950: {'selected': 0.9365079365079365, 'score': 0.9365079365079365, 'examples_seen': 107616, 'step': 1950, 'algorithm': 'activity_selector'}
I1128 21:39:37.967180 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.957, current avg val score is 0.937, val scores are: activity_selector: 0.937
I1128 21:39:39.704012 133056749540864 run.py:734] Algo activity_selector step 2000 current loss 0.983395, current_train_items 110368.
I1128 21:39:39.855520 133056749540864 run.py:769] (val) algo activity_selector step 2000: {'selected': 0.923679060665362, 'score': 0.923679060665362, 'examples_seen': 110368, 'step': 2000, 'algorithm': 'activity_selector'}
I1128 21:39:39.855684 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.957, current avg val score is 0.924, val scores are: activity_selector: 0.924
I1128 21:39:41.559362 133056749540864 run.py:734] Algo activity_selector step 2050 current loss 0.861607, current_train_items 113120.
I1128 21:39:41.738618 133056749540864 run.py:769] (val) algo activity_selector step 2050: {'selected': 0.921606118546845, 'score': 0.921606118546845, 'examples_seen': 113120, 'step': 2050, 'algorithm': 'activity_selector'}
I1128 21:39:41.738841 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.957, current avg val score is 0.922, val scores are: activity_selector: 0.922
I1128 21:39:43.443769 133056749540864 run.py:734] Algo activity_selector step 2100 current loss 1.182626, current_train_items 115904.
I1128 21:39:43.651471 133056749540864 run.py:769] (val) algo activity_selector step 2100: {'selected': 0.9294117647058823, 'score': 0.9294117647058823, 'examples_seen': 115904, 'step': 2100, 'algorithm': 'activity_selector'}
I1128 21:39:43.651697 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.957, current avg val score is 0.929, val scores are: activity_selector: 0.929
I1128 21:39:45.358345 133056749540864 run.py:734] Algo activity_selector step 2150 current loss 0.888571, current_train_items 118624.
I1128 21:39:45.558652 133056749540864 run.py:769] (val) algo activity_selector step 2150: {'selected': 0.9120654396728016, 'score': 0.9120654396728016, 'examples_seen': 118624, 'step': 2150, 'algorithm': 'activity_selector'}
I1128 21:39:45.558881 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.957, current avg val score is 0.912, val scores are: activity_selector: 0.912
I1128 21:39:47.237568 133056749540864 run.py:734] Algo activity_selector step 2200 current loss 0.872618, current_train_items 121440.
I1128 21:39:47.460864 133056749540864 run.py:769] (val) algo activity_selector step 2200: {'selected': 0.9374999999999999, 'score': 0.9374999999999999, 'examples_seen': 121440, 'step': 2200, 'algorithm': 'activity_selector'}
I1128 21:39:47.461101 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.957, current avg val score is 0.937, val scores are: activity_selector: 0.937
I1128 21:39:49.185302 133056749540864 run.py:734] Algo activity_selector step 2250 current loss 0.833309, current_train_items 124160.
I1128 21:39:49.377849 133056749540864 run.py:769] (val) algo activity_selector step 2250: {'selected': 0.9355432780847145, 'score': 0.9355432780847145, 'examples_seen': 124160, 'step': 2250, 'algorithm': 'activity_selector'}
I1128 21:39:49.378073 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.957, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1128 21:39:51.128975 133056749540864 run.py:734] Algo activity_selector step 2300 current loss 1.012378, current_train_items 126880.
I1128 21:39:51.278787 133056749540864 run.py:769] (val) algo activity_selector step 2300: {'selected': 0.9440298507462687, 'score': 0.9440298507462687, 'examples_seen': 126880, 'step': 2300, 'algorithm': 'activity_selector'}
I1128 21:39:51.278954 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.957, current avg val score is 0.944, val scores are: activity_selector: 0.944
I1128 21:39:52.994019 133056749540864 run.py:734] Algo activity_selector step 2350 current loss 0.787135, current_train_items 129696.
I1128 21:39:53.170226 133056749540864 run.py:769] (val) algo activity_selector step 2350: {'selected': 0.9792843691148776, 'score': 0.9792843691148776, 'examples_seen': 129696, 'step': 2350, 'algorithm': 'activity_selector'}
I1128 21:39:53.170392 133056749540864 run.py:790] Checkpointing best model, best avg val score was 0.957, current avg val score is 0.979, val scores are: activity_selector: 0.979
I1128 21:39:54.923677 133056749540864 run.py:734] Algo activity_selector step 2400 current loss 0.971872, current_train_items 132416.
I1128 21:39:55.146676 133056749540864 run.py:769] (val) algo activity_selector step 2400: {'selected': 0.9148514851485148, 'score': 0.9148514851485148, 'examples_seen': 132416, 'step': 2400, 'algorithm': 'activity_selector'}
I1128 21:39:55.146898 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.915, val scores are: activity_selector: 0.915
I1128 21:39:56.869585 133056749540864 run.py:734] Algo activity_selector step 2450 current loss 0.791753, current_train_items 135200.
I1128 21:39:57.047801 133056749540864 run.py:769] (val) algo activity_selector step 2450: {'selected': 0.92, 'score': 0.92, 'examples_seen': 135200, 'step': 2450, 'algorithm': 'activity_selector'}
I1128 21:39:57.048024 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.920, val scores are: activity_selector: 0.920
I1128 21:39:58.770398 133056749540864 run.py:734] Algo activity_selector step 2500 current loss 0.592821, current_train_items 137952.
I1128 21:39:58.949450 133056749540864 run.py:769] (val) algo activity_selector step 2500: {'selected': 0.953307392996109, 'score': 0.953307392996109, 'examples_seen': 137952, 'step': 2500, 'algorithm': 'activity_selector'}
I1128 21:39:58.949674 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1128 21:40:00.689073 133056749540864 run.py:734] Algo activity_selector step 2550 current loss 0.873567, current_train_items 140704.
I1128 21:40:00.868162 133056749540864 run.py:769] (val) algo activity_selector step 2550: {'selected': 0.9481765834932822, 'score': 0.9481765834932822, 'examples_seen': 140704, 'step': 2550, 'algorithm': 'activity_selector'}
I1128 21:40:00.868403 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1128 21:40:02.618204 133056749540864 run.py:734] Algo activity_selector step 2600 current loss 0.724323, current_train_items 143456.
I1128 21:40:02.770304 133056749540864 run.py:769] (val) algo activity_selector step 2600: {'selected': 0.9510763209393347, 'score': 0.9510763209393347, 'examples_seen': 143456, 'step': 2600, 'algorithm': 'activity_selector'}
I1128 21:40:02.770528 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.951, val scores are: activity_selector: 0.951
I1128 21:40:04.492074 133056749540864 run.py:734] Algo activity_selector step 2650 current loss 0.697659, current_train_items 146208.
I1128 21:40:04.672638 133056749540864 run.py:769] (val) algo activity_selector step 2650: {'selected': 0.9482071713147411, 'score': 0.9482071713147411, 'examples_seen': 146208, 'step': 2650, 'algorithm': 'activity_selector'}
I1128 21:40:04.672904 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1128 21:40:06.408524 133056749540864 run.py:734] Algo activity_selector step 2700 current loss 0.865892, current_train_items 148992.
I1128 21:40:06.589392 133056749540864 run.py:769] (val) algo activity_selector step 2700: {'selected': 0.9141856392294221, 'score': 0.9141856392294221, 'examples_seen': 148992, 'step': 2700, 'algorithm': 'activity_selector'}
I1128 21:40:06.589616 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.914, val scores are: activity_selector: 0.914
I1128 21:40:08.312134 133056749540864 run.py:734] Algo activity_selector step 2750 current loss 0.922942, current_train_items 151712.
I1128 21:40:08.490716 133056749540864 run.py:769] (val) algo activity_selector step 2750: {'selected': 0.9433962264150944, 'score': 0.9433962264150944, 'examples_seen': 151712, 'step': 2750, 'algorithm': 'activity_selector'}
I1128 21:40:08.490943 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1128 21:40:10.215584 133056749540864 run.py:734] Algo activity_selector step 2800 current loss 0.901636, current_train_items 154528.
I1128 21:40:10.397185 133056749540864 run.py:769] (val) algo activity_selector step 2800: {'selected': 0.9246031746031746, 'score': 0.9246031746031746, 'examples_seen': 154528, 'step': 2800, 'algorithm': 'activity_selector'}
I1128 21:40:10.397413 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.925, val scores are: activity_selector: 0.925
I1128 21:40:12.130636 133056749540864 run.py:734] Algo activity_selector step 2850 current loss 1.034234, current_train_items 157248.
I1128 21:40:12.309906 133056749540864 run.py:769] (val) algo activity_selector step 2850: {'selected': 0.9706457925636007, 'score': 0.9706457925636007, 'examples_seen': 157248, 'step': 2850, 'algorithm': 'activity_selector'}
I1128 21:40:12.310151 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.971, val scores are: activity_selector: 0.971
I1128 21:40:14.032612 133056749540864 run.py:734] Algo activity_selector step 2900 current loss 0.794229, current_train_items 160000.
I1128 21:40:14.210200 133056749540864 run.py:769] (val) algo activity_selector step 2900: {'selected': 0.9425742574257425, 'score': 0.9425742574257425, 'examples_seen': 160000, 'step': 2900, 'algorithm': 'activity_selector'}
I1128 21:40:14.210431 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1128 21:40:15.943703 133056749540864 run.py:734] Algo activity_selector step 2950 current loss 0.821756, current_train_items 162784.
I1128 21:40:16.117789 133056749540864 run.py:769] (val) algo activity_selector step 2950: {'selected': 0.961089494163424, 'score': 0.961089494163424, 'examples_seen': 162784, 'step': 2950, 'algorithm': 'activity_selector'}
I1128 21:40:16.118014 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.961, val scores are: activity_selector: 0.961
I1128 21:40:17.840745 133056749540864 run.py:734] Algo activity_selector step 3000 current loss 0.619447, current_train_items 165504.
I1128 21:40:18.030129 133056749540864 run.py:769] (val) algo activity_selector step 3000: {'selected': 0.931297709923664, 'score': 0.931297709923664, 'examples_seen': 165504, 'step': 3000, 'algorithm': 'activity_selector'}
I1128 21:40:18.030356 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1128 21:40:19.753015 133056749540864 run.py:734] Algo activity_selector step 3050 current loss 0.544779, current_train_items 168288.
I1128 21:40:19.932111 133056749540864 run.py:769] (val) algo activity_selector step 3050: {'selected': 0.9755102040816327, 'score': 0.9755102040816327, 'examples_seen': 168288, 'step': 3050, 'algorithm': 'activity_selector'}
I1128 21:40:19.932340 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.976, val scores are: activity_selector: 0.976
I1128 21:40:21.660150 133056749540864 run.py:734] Algo activity_selector step 3100 current loss 0.780375, current_train_items 171040.
I1128 21:40:21.837940 133056749540864 run.py:769] (val) algo activity_selector step 3100: {'selected': 0.9213893967093236, 'score': 0.9213893967093236, 'examples_seen': 171040, 'step': 3100, 'algorithm': 'activity_selector'}
I1128 21:40:21.838205 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.921, val scores are: activity_selector: 0.921
I1128 21:40:23.553228 133056749540864 run.py:734] Algo activity_selector step 3150 current loss 0.629140, current_train_items 173792.
I1128 21:40:23.730894 133056749540864 run.py:769] (val) algo activity_selector step 3150: {'selected': 0.9048473967684022, 'score': 0.9048473967684022, 'examples_seen': 173792, 'step': 3150, 'algorithm': 'activity_selector'}
I1128 21:40:23.731136 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.905, val scores are: activity_selector: 0.905
I1128 21:40:25.454348 133056749540864 run.py:734] Algo activity_selector step 3200 current loss 0.855782, current_train_items 176544.
I1128 21:40:25.633749 133056749540864 run.py:769] (val) algo activity_selector step 3200: {'selected': 0.918918918918919, 'score': 0.918918918918919, 'examples_seen': 176544, 'step': 3200, 'algorithm': 'activity_selector'}
I1128 21:40:25.633910 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.919, val scores are: activity_selector: 0.919
I1128 21:40:27.301425 133056749540864 run.py:734] Algo activity_selector step 3250 current loss 0.738714, current_train_items 179328.
I1128 21:40:27.524138 133056749540864 run.py:769] (val) algo activity_selector step 3250: {'selected': 0.9678638941398866, 'score': 0.9678638941398866, 'examples_seen': 179328, 'step': 3250, 'algorithm': 'activity_selector'}
I1128 21:40:27.524387 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.968, val scores are: activity_selector: 0.968
I1128 21:40:29.272114 133056749540864 run.py:734] Algo activity_selector step 3300 current loss 0.619202, current_train_items 182080.
I1128 21:40:29.438549 133056749540864 run.py:769] (val) algo activity_selector step 3300: {'selected': 0.9541984732824428, 'score': 0.9541984732824428, 'examples_seen': 182080, 'step': 3300, 'algorithm': 'activity_selector'}
I1128 21:40:29.438768 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.954, val scores are: activity_selector: 0.954
I1128 21:40:31.165238 133056749540864 run.py:734] Algo activity_selector step 3350 current loss 1.015847, current_train_items 184800.
I1128 21:40:31.344800 133056749540864 run.py:769] (val) algo activity_selector step 3350: {'selected': 0.9625246548323472, 'score': 0.9625246548323472, 'examples_seen': 184800, 'step': 3350, 'algorithm': 'activity_selector'}
I1128 21:40:31.345025 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.963, val scores are: activity_selector: 0.963
I1128 21:40:33.039978 133056749540864 run.py:734] Algo activity_selector step 3400 current loss 0.765492, current_train_items 187584.
I1128 21:40:33.246051 133056749540864 run.py:769] (val) algo activity_selector step 3400: {'selected': 0.8877005347593582, 'score': 0.8877005347593582, 'examples_seen': 187584, 'step': 3400, 'algorithm': 'activity_selector'}
I1128 21:40:33.246285 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.888, val scores are: activity_selector: 0.888
I1128 21:40:34.967350 133056749540864 run.py:734] Algo activity_selector step 3450 current loss 0.946573, current_train_items 190336.
I1128 21:40:35.158713 133056749540864 run.py:769] (val) algo activity_selector step 3450: {'selected': 0.9759036144578314, 'score': 0.9759036144578314, 'examples_seen': 190336, 'step': 3450, 'algorithm': 'activity_selector'}
I1128 21:40:35.158932 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.976, val scores are: activity_selector: 0.976
I1128 21:40:36.877336 133056749540864 run.py:734] Algo activity_selector step 3500 current loss 0.594719, current_train_items 193088.
I1128 21:40:37.065967 133056749540864 run.py:769] (val) algo activity_selector step 3500: {'selected': 0.9436893203883495, 'score': 0.9436893203883495, 'examples_seen': 193088, 'step': 3500, 'algorithm': 'activity_selector'}
I1128 21:40:37.066216 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.944, val scores are: activity_selector: 0.944
I1128 21:40:38.788393 133056749540864 run.py:734] Algo activity_selector step 3550 current loss 0.703446, current_train_items 195872.
I1128 21:40:38.964902 133056749540864 run.py:769] (val) algo activity_selector step 3550: {'selected': 0.9642184557438795, 'score': 0.9642184557438795, 'examples_seen': 195872, 'step': 3550, 'algorithm': 'activity_selector'}
I1128 21:40:38.965140 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.964, val scores are: activity_selector: 0.964
I1128 21:40:40.698678 133056749540864 run.py:734] Algo activity_selector step 3600 current loss 0.661432, current_train_items 198624.
I1128 21:40:40.879402 133056749540864 run.py:769] (val) algo activity_selector step 3600: {'selected': 0.962962962962963, 'score': 0.962962962962963, 'examples_seen': 198624, 'step': 3600, 'algorithm': 'activity_selector'}
I1128 21:40:40.879595 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.963, val scores are: activity_selector: 0.963
I1128 21:40:42.593729 133056749540864 run.py:734] Algo activity_selector step 3650 current loss 0.764368, current_train_items 201376.
I1128 21:40:42.771334 133056749540864 run.py:769] (val) algo activity_selector step 3650: {'selected': 0.9523809523809524, 'score': 0.9523809523809524, 'examples_seen': 201376, 'step': 3650, 'algorithm': 'activity_selector'}
I1128 21:40:42.771483 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.952, val scores are: activity_selector: 0.952
I1128 21:40:44.501938 133056749540864 run.py:734] Algo activity_selector step 3700 current loss 0.606996, current_train_items 204128.
I1128 21:40:44.654241 133056749540864 run.py:769] (val) algo activity_selector step 3700: {'selected': 0.9598393574297189, 'score': 0.9598393574297189, 'examples_seen': 204128, 'step': 3700, 'algorithm': 'activity_selector'}
I1128 21:40:44.654484 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.960, val scores are: activity_selector: 0.960
I1128 21:40:46.399374 133056749540864 run.py:734] Algo activity_selector step 3750 current loss 0.533161, current_train_items 206880.
I1128 21:40:46.569511 133056749540864 run.py:769] (val) algo activity_selector step 3750: {'selected': 0.9601518026565464, 'score': 0.9601518026565464, 'examples_seen': 206880, 'step': 3750, 'algorithm': 'activity_selector'}
I1128 21:40:46.569658 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.960, val scores are: activity_selector: 0.960
I1128 21:40:48.299752 133056749540864 run.py:734] Algo activity_selector step 3800 current loss 0.570715, current_train_items 209632.
I1128 21:40:48.450316 133056749540864 run.py:769] (val) algo activity_selector step 3800: {'selected': 0.9712092130518234, 'score': 0.9712092130518234, 'examples_seen': 209632, 'step': 3800, 'algorithm': 'activity_selector'}
I1128 21:40:48.450463 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.971, val scores are: activity_selector: 0.971
I1128 21:40:50.173346 133056749540864 run.py:734] Algo activity_selector step 3850 current loss 0.691833, current_train_items 212416.
I1128 21:40:50.337249 133056749540864 run.py:769] (val) algo activity_selector step 3850: {'selected': 0.9296875, 'score': 0.9296875, 'examples_seen': 212416, 'step': 3850, 'algorithm': 'activity_selector'}
I1128 21:40:50.337429 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.930, val scores are: activity_selector: 0.930
I1128 21:40:52.056543 133056749540864 run.py:734] Algo activity_selector step 3900 current loss 0.690648, current_train_items 215168.
I1128 21:40:52.234398 133056749540864 run.py:769] (val) algo activity_selector step 3900: {'selected': 0.9285714285714286, 'score': 0.9285714285714286, 'examples_seen': 215168, 'step': 3900, 'algorithm': 'activity_selector'}
I1128 21:40:52.234656 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.929, val scores are: activity_selector: 0.929
I1128 21:40:53.956204 133056749540864 run.py:734] Algo activity_selector step 3950 current loss 0.793950, current_train_items 217920.
I1128 21:40:54.135303 133056749540864 run.py:769] (val) algo activity_selector step 3950: {'selected': 0.931098696461825, 'score': 0.931098696461825, 'examples_seen': 217920, 'step': 3950, 'algorithm': 'activity_selector'}
I1128 21:40:54.135560 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1128 21:40:55.856486 133056749540864 run.py:734] Algo activity_selector step 4000 current loss 0.690597, current_train_items 220672.
I1128 21:40:56.034802 133056749540864 run.py:769] (val) algo activity_selector step 4000: {'selected': 0.9281553398058252, 'score': 0.9281553398058252, 'examples_seen': 220672, 'step': 4000, 'algorithm': 'activity_selector'}
I1128 21:40:56.035023 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.928, val scores are: activity_selector: 0.928
I1128 21:40:57.755968 133056749540864 run.py:734] Algo activity_selector step 4050 current loss 0.609158, current_train_items 223424.
I1128 21:40:57.933792 133056749540864 run.py:769] (val) algo activity_selector step 4050: {'selected': 0.974757281553398, 'score': 0.974757281553398, 'examples_seen': 223424, 'step': 4050, 'algorithm': 'activity_selector'}
I1128 21:40:57.934013 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.975, val scores are: activity_selector: 0.975
I1128 21:40:59.683476 133056749540864 run.py:734] Algo activity_selector step 4100 current loss 0.843012, current_train_items 226176.
I1128 21:40:59.834704 133056749540864 run.py:769] (val) algo activity_selector step 4100: {'selected': 0.9346153846153847, 'score': 0.9346153846153847, 'examples_seen': 226176, 'step': 4100, 'algorithm': 'activity_selector'}
I1128 21:40:59.834930 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.935, val scores are: activity_selector: 0.935
I1128 21:41:01.562533 133056749540864 run.py:734] Algo activity_selector step 4150 current loss 0.737767, current_train_items 228960.
I1128 21:41:01.737383 133056749540864 run.py:769] (val) algo activity_selector step 4150: {'selected': 0.9143968871595332, 'score': 0.9143968871595332, 'examples_seen': 228960, 'step': 4150, 'algorithm': 'activity_selector'}
I1128 21:41:01.737534 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.914, val scores are: activity_selector: 0.914
I1128 21:41:03.460410 133056749540864 run.py:734] Algo activity_selector step 4200 current loss 0.598362, current_train_items 231712.
I1128 21:41:03.641142 133056749540864 run.py:769] (val) algo activity_selector step 4200: {'selected': 0.9242718446601942, 'score': 0.9242718446601942, 'examples_seen': 231712, 'step': 4200, 'algorithm': 'activity_selector'}
I1128 21:41:03.641373 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.924, val scores are: activity_selector: 0.924
I1128 21:41:05.365240 133056749540864 run.py:734] Algo activity_selector step 4250 current loss 0.746586, current_train_items 234432.
I1128 21:41:05.541729 133056749540864 run.py:769] (val) algo activity_selector step 4250: {'selected': 0.9543726235741444, 'score': 0.9543726235741444, 'examples_seen': 234432, 'step': 4250, 'algorithm': 'activity_selector'}
I1128 21:41:05.541970 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.979, current avg val score is 0.954, val scores are: activity_selector: 0.954
I1128 21:41:07.266984 133056749540864 run.py:734] Algo activity_selector step 4300 current loss 0.611307, current_train_items 237248.
I1128 21:41:07.448512 133056749540864 run.py:769] (val) algo activity_selector step 4300: {'selected': 0.9833641404805915, 'score': 0.9833641404805915, 'examples_seen': 237248, 'step': 4300, 'algorithm': 'activity_selector'}
I1128 21:41:07.448734 133056749540864 run.py:790] Checkpointing best model, best avg val score was 0.979, current avg val score is 0.983, val scores are: activity_selector: 0.983
I1128 21:41:09.234785 133056749540864 run.py:734] Algo activity_selector step 4350 current loss 0.616418, current_train_items 239968.
I1128 21:41:09.412451 133056749540864 run.py:769] (val) algo activity_selector step 4350: {'selected': 0.9762845849802372, 'score': 0.9762845849802372, 'examples_seen': 239968, 'step': 4350, 'algorithm': 'activity_selector'}
I1128 21:41:09.412687 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.983, current avg val score is 0.976, val scores are: activity_selector: 0.976
I1128 21:41:11.134948 133056749540864 run.py:734] Algo activity_selector step 4400 current loss 0.599260, current_train_items 242720.
I1128 21:41:11.313827 133056749540864 run.py:769] (val) algo activity_selector step 4400: {'selected': 0.9477756286266924, 'score': 0.9477756286266924, 'examples_seen': 242720, 'step': 4400, 'algorithm': 'activity_selector'}
I1128 21:41:11.314052 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.983, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1128 21:41:13.042600 133056749540864 run.py:734] Algo activity_selector step 4450 current loss 0.641321, current_train_items 245504.
I1128 21:41:13.220515 133056749540864 run.py:769] (val) algo activity_selector step 4450: {'selected': 0.9556451612903226, 'score': 0.9556451612903226, 'examples_seen': 245504, 'step': 4450, 'algorithm': 'activity_selector'}
I1128 21:41:13.220664 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.983, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1128 21:41:14.934128 133056749540864 run.py:734] Algo activity_selector step 4500 current loss 0.830972, current_train_items 248256.
I1128 21:41:15.112051 133056749540864 run.py:769] (val) algo activity_selector step 4500: {'selected': 0.9704142011834319, 'score': 0.9704142011834319, 'examples_seen': 248256, 'step': 4500, 'algorithm': 'activity_selector'}
I1128 21:41:15.112295 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.983, current avg val score is 0.970, val scores are: activity_selector: 0.970
I1128 21:41:16.844186 133056749540864 run.py:734] Algo activity_selector step 4550 current loss 0.809926, current_train_items 251008.
I1128 21:41:16.994098 133056749540864 run.py:769] (val) algo activity_selector step 4550: {'selected': 0.9333333333333332, 'score': 0.9333333333333332, 'examples_seen': 251008, 'step': 4550, 'algorithm': 'activity_selector'}
I1128 21:41:16.994268 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.983, current avg val score is 0.933, val scores are: activity_selector: 0.933
I1128 21:41:18.701677 133056749540864 run.py:734] Algo activity_selector step 4600 current loss 0.653426, current_train_items 253760.
I1128 21:41:18.879910 133056749540864 run.py:769] (val) algo activity_selector step 4600: {'selected': 0.9724409448818899, 'score': 0.9724409448818899, 'examples_seen': 253760, 'step': 4600, 'algorithm': 'activity_selector'}
I1128 21:41:18.880128 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.983, current avg val score is 0.972, val scores are: activity_selector: 0.972
I1128 21:41:20.596570 133056749540864 run.py:734] Algo activity_selector step 4650 current loss 0.622137, current_train_items 256544.
I1128 21:41:20.775459 133056749540864 run.py:769] (val) algo activity_selector step 4650: {'selected': 0.9538461538461538, 'score': 0.9538461538461538, 'examples_seen': 256544, 'step': 4650, 'algorithm': 'activity_selector'}
I1128 21:41:20.775698 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.983, current avg val score is 0.954, val scores are: activity_selector: 0.954
I1128 21:41:22.498471 133056749540864 run.py:734] Algo activity_selector step 4700 current loss 0.728272, current_train_items 259264.
I1128 21:41:22.682766 133056749540864 run.py:769] (val) algo activity_selector step 4700: {'selected': 0.9500924214417745, 'score': 0.9500924214417745, 'examples_seen': 259264, 'step': 4700, 'algorithm': 'activity_selector'}
I1128 21:41:22.682991 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.983, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1128 21:41:24.411101 133056749540864 run.py:734] Algo activity_selector step 4750 current loss 0.603685, current_train_items 262048.
I1128 21:41:24.587409 133056749540864 run.py:769] (val) algo activity_selector step 4750: {'selected': 0.9275929549902153, 'score': 0.9275929549902153, 'examples_seen': 262048, 'step': 4750, 'algorithm': 'activity_selector'}
I1128 21:41:24.587632 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.983, current avg val score is 0.928, val scores are: activity_selector: 0.928
I1128 21:41:26.347756 133056749540864 run.py:734] Algo activity_selector step 4800 current loss 0.570802, current_train_items 264800.
I1128 21:41:26.499898 133056749540864 run.py:769] (val) algo activity_selector step 4800: {'selected': 0.9616858237547893, 'score': 0.9616858237547893, 'examples_seen': 264800, 'step': 4800, 'algorithm': 'activity_selector'}
I1128 21:41:26.500137 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.983, current avg val score is 0.962, val scores are: activity_selector: 0.962
I1128 21:41:28.226228 133056749540864 run.py:734] Algo activity_selector step 4850 current loss 0.927348, current_train_items 267520.
I1128 21:41:28.405321 133056749540864 run.py:769] (val) algo activity_selector step 4850: {'selected': 0.9268292682926829, 'score': 0.9268292682926829, 'examples_seen': 267520, 'step': 4850, 'algorithm': 'activity_selector'}
I1128 21:41:28.405565 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.983, current avg val score is 0.927, val scores are: activity_selector: 0.927
I1128 21:41:30.154564 133056749540864 run.py:734] Algo activity_selector step 4900 current loss 0.835204, current_train_items 270336.
I1128 21:41:30.305840 133056749540864 run.py:769] (val) algo activity_selector step 4900: {'selected': 0.9219858156028369, 'score': 0.9219858156028369, 'examples_seen': 270336, 'step': 4900, 'algorithm': 'activity_selector'}
I1128 21:41:30.306063 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.983, current avg val score is 0.922, val scores are: activity_selector: 0.922
I1128 21:41:32.054703 133056749540864 run.py:734] Algo activity_selector step 4950 current loss 0.665380, current_train_items 273056.
I1128 21:41:32.219597 133056749540864 run.py:769] (val) algo activity_selector step 4950: {'selected': 0.9604743083003953, 'score': 0.9604743083003953, 'examples_seen': 273056, 'step': 4950, 'algorithm': 'activity_selector'}
I1128 21:41:32.219822 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.983, current avg val score is 0.960, val scores are: activity_selector: 0.960
I1128 21:41:33.945843 133056749540864 run.py:734] Algo activity_selector step 5000 current loss 0.732861, current_train_items 275840.
I1128 21:41:34.125912 133056749540864 run.py:769] (val) algo activity_selector step 5000: {'selected': 0.9473684210526315, 'score': 0.9473684210526315, 'examples_seen': 275840, 'step': 5000, 'algorithm': 'activity_selector'}
I1128 21:41:34.126151 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.983, current avg val score is 0.947, val scores are: activity_selector: 0.947
I1128 21:41:35.849585 133056749540864 run.py:734] Algo activity_selector step 5050 current loss 0.539940, current_train_items 278592.
I1128 21:41:36.028122 133056749540864 run.py:769] (val) algo activity_selector step 5050: {'selected': 0.979757085020243, 'score': 0.979757085020243, 'examples_seen': 278592, 'step': 5050, 'algorithm': 'activity_selector'}
I1128 21:41:36.028347 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.983, current avg val score is 0.980, val scores are: activity_selector: 0.980
I1128 21:41:37.794781 133056749540864 run.py:734] Algo activity_selector step 5100 current loss 0.696138, current_train_items 281312.
I1128 21:41:37.979932 133056749540864 run.py:769] (val) algo activity_selector step 5100: {'selected': 0.9133574007220218, 'score': 0.9133574007220218, 'examples_seen': 281312, 'step': 5100, 'algorithm': 'activity_selector'}
I1128 21:41:37.980179 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.983, current avg val score is 0.913, val scores are: activity_selector: 0.913
I1128 21:41:39.702783 133056749540864 run.py:734] Algo activity_selector step 5150 current loss 0.860205, current_train_items 284096.
I1128 21:41:39.880047 133056749540864 run.py:769] (val) algo activity_selector step 5150: {'selected': 0.9560229445506693, 'score': 0.9560229445506693, 'examples_seen': 284096, 'step': 5150, 'algorithm': 'activity_selector'}
I1128 21:41:39.880285 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.983, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1128 21:41:41.634407 133056749540864 run.py:734] Algo activity_selector step 5200 current loss 0.630469, current_train_items 286848.
I1128 21:41:41.786850 133056749540864 run.py:769] (val) algo activity_selector step 5200: {'selected': 0.9864603481624757, 'score': 0.9864603481624757, 'examples_seen': 286848, 'step': 5200, 'algorithm': 'activity_selector'}
I1128 21:41:41.787070 133056749540864 run.py:790] Checkpointing best model, best avg val score was 0.983, current avg val score is 0.986, val scores are: activity_selector: 0.986
I1128 21:41:43.600525 133056749540864 run.py:734] Algo activity_selector step 5250 current loss 0.527300, current_train_items 289632.
I1128 21:41:43.754775 133056749540864 run.py:769] (val) algo activity_selector step 5250: {'selected': 0.9538461538461538, 'score': 0.9538461538461538, 'examples_seen': 289632, 'step': 5250, 'algorithm': 'activity_selector'}
I1128 21:41:43.754999 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.954, val scores are: activity_selector: 0.954
I1128 21:41:45.509710 133056749540864 run.py:734] Algo activity_selector step 5300 current loss 0.883162, current_train_items 292352.
I1128 21:41:45.661507 133056749540864 run.py:769] (val) algo activity_selector step 5300: {'selected': 0.969811320754717, 'score': 0.969811320754717, 'examples_seen': 292352, 'step': 5300, 'algorithm': 'activity_selector'}
I1128 21:41:45.661735 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.970, val scores are: activity_selector: 0.970
I1128 21:41:47.388370 133056749540864 run.py:734] Algo activity_selector step 5350 current loss 0.563052, current_train_items 295168.
I1128 21:41:47.567845 133056749540864 run.py:769] (val) algo activity_selector step 5350: {'selected': 0.9681050656660413, 'score': 0.9681050656660413, 'examples_seen': 295168, 'step': 5350, 'algorithm': 'activity_selector'}
I1128 21:41:47.568069 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.968, val scores are: activity_selector: 0.968
I1128 21:41:49.325966 133056749540864 run.py:734] Algo activity_selector step 5400 current loss 0.500127, current_train_items 297888.
I1128 21:41:49.486764 133056749540864 run.py:769] (val) algo activity_selector step 5400: {'selected': 0.9609375, 'score': 0.9609375, 'examples_seen': 297888, 'step': 5400, 'algorithm': 'activity_selector'}
I1128 21:41:49.486990 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.961, val scores are: activity_selector: 0.961
I1128 21:41:51.240608 133056749540864 run.py:734] Algo activity_selector step 5450 current loss 0.488958, current_train_items 300608.
I1128 21:41:51.393286 133056749540864 run.py:769] (val) algo activity_selector step 5450: {'selected': 0.962962962962963, 'score': 0.962962962962963, 'examples_seen': 300608, 'step': 5450, 'algorithm': 'activity_selector'}
I1128 21:41:51.393522 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.963, val scores are: activity_selector: 0.963
I1128 21:41:53.120265 133056749540864 run.py:734] Algo activity_selector step 5500 current loss 0.585755, current_train_items 303424.
I1128 21:41:53.298923 133056749540864 run.py:769] (val) algo activity_selector step 5500: {'selected': 0.8819188191881919, 'score': 0.8819188191881919, 'examples_seen': 303424, 'step': 5500, 'algorithm': 'activity_selector'}
I1128 21:41:53.299164 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.882, val scores are: activity_selector: 0.882
I1128 21:41:55.071575 133056749540864 run.py:734] Algo activity_selector step 5550 current loss 0.547136, current_train_items 306144.
I1128 21:41:55.223271 133056749540864 run.py:769] (val) algo activity_selector step 5550: {'selected': 0.96, 'score': 0.96, 'examples_seen': 306144, 'step': 5550, 'algorithm': 'activity_selector'}
I1128 21:41:55.223496 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.960, val scores are: activity_selector: 0.960
I1128 21:41:56.975573 133056749540864 run.py:734] Algo activity_selector step 5600 current loss 0.725969, current_train_items 308928.
I1128 21:41:57.127729 133056749540864 run.py:769] (val) algo activity_selector step 5600: {'selected': 0.9305263157894738, 'score': 0.9305263157894738, 'examples_seen': 308928, 'step': 5600, 'algorithm': 'activity_selector'}
I1128 21:41:57.127972 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1128 21:41:58.863041 133056749540864 run.py:734] Algo activity_selector step 5650 current loss 0.601975, current_train_items 311680.
I1128 21:41:59.039129 133056749540864 run.py:769] (val) algo activity_selector step 5650: {'selected': 0.9579524680073127, 'score': 0.9579524680073127, 'examples_seen': 311680, 'step': 5650, 'algorithm': 'activity_selector'}
I1128 21:41:59.039353 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.958, val scores are: activity_selector: 0.958
I1128 21:42:00.774816 133056749540864 run.py:734] Algo activity_selector step 5700 current loss 0.676129, current_train_items 314432.
I1128 21:42:00.954033 133056749540864 run.py:769] (val) algo activity_selector step 5700: {'selected': 0.965065502183406, 'score': 0.965065502183406, 'examples_seen': 314432, 'step': 5700, 'algorithm': 'activity_selector'}
I1128 21:42:00.954281 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.965, val scores are: activity_selector: 0.965
I1128 21:42:02.708292 133056749540864 run.py:734] Algo activity_selector step 5750 current loss 0.663546, current_train_items 317184.
I1128 21:42:02.859984 133056749540864 run.py:769] (val) algo activity_selector step 5750: {'selected': 0.969574036511156, 'score': 0.969574036511156, 'examples_seen': 317184, 'step': 5750, 'algorithm': 'activity_selector'}
I1128 21:42:02.860227 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.970, val scores are: activity_selector: 0.970
I1128 21:42:04.589596 133056749540864 run.py:734] Algo activity_selector step 5800 current loss 0.743419, current_train_items 319936.
I1128 21:42:04.765068 133056749540864 run.py:769] (val) algo activity_selector step 5800: {'selected': 0.9447852760736196, 'score': 0.9447852760736196, 'examples_seen': 319936, 'step': 5800, 'algorithm': 'activity_selector'}
I1128 21:42:04.765306 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.945, val scores are: activity_selector: 0.945
I1128 21:42:06.503165 133056749540864 run.py:734] Algo activity_selector step 5850 current loss 0.568319, current_train_items 322720.
I1128 21:42:06.681699 133056749540864 run.py:769] (val) algo activity_selector step 5850: {'selected': 0.9613034623217922, 'score': 0.9613034623217922, 'examples_seen': 322720, 'step': 5850, 'algorithm': 'activity_selector'}
I1128 21:42:06.681927 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.961, val scores are: activity_selector: 0.961
I1128 21:42:08.434922 133056749540864 run.py:734] Algo activity_selector step 5900 current loss 0.555474, current_train_items 325440.
I1128 21:42:08.588355 133056749540864 run.py:769] (val) algo activity_selector step 5900: {'selected': 0.9357798165137615, 'score': 0.9357798165137615, 'examples_seen': 325440, 'step': 5900, 'algorithm': 'activity_selector'}
I1128 21:42:08.588577 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.936, val scores are: activity_selector: 0.936
I1128 21:42:10.315191 133056749540864 run.py:734] Algo activity_selector step 5950 current loss 0.619146, current_train_items 328224.
I1128 21:42:10.498375 133056749540864 run.py:769] (val) algo activity_selector step 5950: {'selected': 0.9629629629629629, 'score': 0.9629629629629629, 'examples_seen': 328224, 'step': 5950, 'algorithm': 'activity_selector'}
I1128 21:42:10.498598 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.963, val scores are: activity_selector: 0.963
I1128 21:42:12.242599 133056749540864 run.py:734] Algo activity_selector step 6000 current loss 0.525051, current_train_items 330976.
I1128 21:42:12.420239 133056749540864 run.py:769] (val) algo activity_selector step 6000: {'selected': 0.9691470054446462, 'score': 0.9691470054446462, 'examples_seen': 330976, 'step': 6000, 'algorithm': 'activity_selector'}
I1128 21:42:12.420469 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.969, val scores are: activity_selector: 0.969
I1128 21:42:14.172456 133056749540864 run.py:734] Algo activity_selector step 6050 current loss 0.755731, current_train_items 333728.
I1128 21:42:14.325730 133056749540864 run.py:769] (val) algo activity_selector step 6050: {'selected': 0.970954356846473, 'score': 0.970954356846473, 'examples_seen': 333728, 'step': 6050, 'algorithm': 'activity_selector'}
I1128 21:42:14.325950 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.971, val scores are: activity_selector: 0.971
I1128 21:42:16.081505 133056749540864 run.py:734] Algo activity_selector step 6100 current loss 0.595110, current_train_items 336512.
I1128 21:42:16.235373 133056749540864 run.py:769] (val) algo activity_selector step 6100: {'selected': 0.9682539682539683, 'score': 0.9682539682539683, 'examples_seen': 336512, 'step': 6100, 'algorithm': 'activity_selector'}
I1128 21:42:16.235597 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.968, val scores are: activity_selector: 0.968
I1128 21:42:17.972133 133056749540864 run.py:734] Algo activity_selector step 6150 current loss 0.767843, current_train_items 339232.
I1128 21:42:18.151170 133056749540864 run.py:769] (val) algo activity_selector step 6150: {'selected': 0.9308943089430894, 'score': 0.9308943089430894, 'examples_seen': 339232, 'step': 6150, 'algorithm': 'activity_selector'}
I1128 21:42:18.151394 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1128 21:42:19.879616 133056749540864 run.py:734] Algo activity_selector step 6200 current loss 0.541177, current_train_items 342016.
I1128 21:42:20.057465 133056749540864 run.py:769] (val) algo activity_selector step 6200: {'selected': 0.9475890985324948, 'score': 0.9475890985324948, 'examples_seen': 342016, 'step': 6200, 'algorithm': 'activity_selector'}
I1128 21:42:20.057689 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1128 21:42:21.812427 133056749540864 run.py:734] Algo activity_selector step 6250 current loss 0.504750, current_train_items 344768.
I1128 21:42:21.963272 133056749540864 run.py:769] (val) algo activity_selector step 6250: {'selected': 0.9767441860465116, 'score': 0.9767441860465116, 'examples_seen': 344768, 'step': 6250, 'algorithm': 'activity_selector'}
I1128 21:42:21.963498 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.977, val scores are: activity_selector: 0.977
I1128 21:42:23.704013 133056749540864 run.py:734] Algo activity_selector step 6300 current loss 0.579114, current_train_items 347520.
I1128 21:42:23.880433 133056749540864 run.py:769] (val) algo activity_selector step 6300: {'selected': 0.9338521400778209, 'score': 0.9338521400778209, 'examples_seen': 347520, 'step': 6300, 'algorithm': 'activity_selector'}
I1128 21:42:23.880676 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.934, val scores are: activity_selector: 0.934
I1128 21:42:25.605730 133056749540864 run.py:734] Algo activity_selector step 6350 current loss 0.640069, current_train_items 350272.
I1128 21:42:25.786735 133056749540864 run.py:769] (val) algo activity_selector step 6350: {'selected': 0.9409448818897638, 'score': 0.9409448818897638, 'examples_seen': 350272, 'step': 6350, 'algorithm': 'activity_selector'}
I1128 21:42:25.786960 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.941, val scores are: activity_selector: 0.941
I1128 21:42:27.514893 133056749540864 run.py:734] Algo activity_selector step 6400 current loss 0.556357, current_train_items 353056.
I1128 21:42:27.692372 133056749540864 run.py:769] (val) algo activity_selector step 6400: {'selected': 0.9737373737373737, 'score': 0.9737373737373737, 'examples_seen': 353056, 'step': 6400, 'algorithm': 'activity_selector'}
I1128 21:42:27.692594 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.974, val scores are: activity_selector: 0.974
I1128 21:42:29.448120 133056749540864 run.py:734] Algo activity_selector step 6450 current loss 0.484194, current_train_items 355808.
I1128 21:42:29.616794 133056749540864 run.py:769] (val) algo activity_selector step 6450: {'selected': 0.9701492537313433, 'score': 0.9701492537313433, 'examples_seen': 355808, 'step': 6450, 'algorithm': 'activity_selector'}
I1128 21:42:29.617019 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.970, val scores are: activity_selector: 0.970
I1128 21:42:31.347418 133056749540864 run.py:734] Algo activity_selector step 6500 current loss 0.457421, current_train_items 358528.
I1128 21:42:31.522613 133056749540864 run.py:769] (val) algo activity_selector step 6500: {'selected': 0.951219512195122, 'score': 0.951219512195122, 'examples_seen': 358528, 'step': 6500, 'algorithm': 'activity_selector'}
I1128 21:42:31.522839 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.951, val scores are: activity_selector: 0.951
I1128 21:42:33.251570 133056749540864 run.py:734] Algo activity_selector step 6550 current loss 0.497333, current_train_items 361312.
I1128 21:42:33.431296 133056749540864 run.py:769] (val) algo activity_selector step 6550: {'selected': 0.9253187613843351, 'score': 0.9253187613843351, 'examples_seen': 361312, 'step': 6550, 'algorithm': 'activity_selector'}
I1128 21:42:33.431519 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.925, val scores are: activity_selector: 0.925
I1128 21:42:35.130429 133056749540864 run.py:734] Algo activity_selector step 6600 current loss 0.862121, current_train_items 364064.
I1128 21:42:35.345268 133056749540864 run.py:769] (val) algo activity_selector step 6600: {'selected': 0.9653846153846154, 'score': 0.9653846153846154, 'examples_seen': 364064, 'step': 6600, 'algorithm': 'activity_selector'}
I1128 21:42:35.345496 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.965, val scores are: activity_selector: 0.965
I1128 21:42:37.074640 133056749540864 run.py:734] Algo activity_selector step 6650 current loss 0.468411, current_train_items 366816.
I1128 21:42:37.251922 133056749540864 run.py:769] (val) algo activity_selector step 6650: {'selected': 0.9609856262833676, 'score': 0.9609856262833676, 'examples_seen': 366816, 'step': 6650, 'algorithm': 'activity_selector'}
I1128 21:42:37.252160 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.961, val scores are: activity_selector: 0.961
I1128 21:42:39.089587 133056749540864 run.py:734] Algo activity_selector step 6700 current loss 0.467931, current_train_items 369600.
I1128 21:42:39.266664 133056749540864 run.py:769] (val) algo activity_selector step 6700: {'selected': 0.9471544715447155, 'score': 0.9471544715447155, 'examples_seen': 369600, 'step': 6700, 'algorithm': 'activity_selector'}
I1128 21:42:39.266890 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.947, val scores are: activity_selector: 0.947
I1128 21:42:41.007193 133056749540864 run.py:734] Algo activity_selector step 6750 current loss 0.518193, current_train_items 372352.
I1128 21:42:41.192297 133056749540864 run.py:769] (val) algo activity_selector step 6750: {'selected': 0.9409448818897638, 'score': 0.9409448818897638, 'examples_seen': 372352, 'step': 6750, 'algorithm': 'activity_selector'}
I1128 21:42:41.192570 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.941, val scores are: activity_selector: 0.941
I1128 21:42:42.977252 133056749540864 run.py:734] Algo activity_selector step 6800 current loss 0.623012, current_train_items 375072.
I1128 21:42:43.163348 133056749540864 run.py:769] (val) algo activity_selector step 6800: {'selected': 0.9386138613861386, 'score': 0.9386138613861386, 'examples_seen': 375072, 'step': 6800, 'algorithm': 'activity_selector'}
I1128 21:42:43.163577 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.939, val scores are: activity_selector: 0.939
I1128 21:42:44.991330 133056749540864 run.py:734] Algo activity_selector step 6850 current loss 0.617382, current_train_items 377856.
I1128 21:42:45.167562 133056749540864 run.py:769] (val) algo activity_selector step 6850: {'selected': 0.9773584905660377, 'score': 0.9773584905660377, 'examples_seen': 377856, 'step': 6850, 'algorithm': 'activity_selector'}
I1128 21:42:45.167801 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.977, val scores are: activity_selector: 0.977
I1128 21:42:47.036677 133056749540864 run.py:734] Algo activity_selector step 6900 current loss 0.747945, current_train_items 380608.
I1128 21:42:47.144451 133056749540864 run.py:769] (val) algo activity_selector step 6900: {'selected': 0.9705304518664047, 'score': 0.9705304518664047, 'examples_seen': 380608, 'step': 6900, 'algorithm': 'activity_selector'}
I1128 21:42:47.144696 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.971, val scores are: activity_selector: 0.971
I1128 21:42:48.996950 133056749540864 run.py:734] Algo activity_selector step 6950 current loss 0.480700, current_train_items 383360.
I1128 21:42:49.123743 133056749540864 run.py:769] (val) algo activity_selector step 6950: {'selected': 0.9838709677419354, 'score': 0.9838709677419354, 'examples_seen': 383360, 'step': 6950, 'algorithm': 'activity_selector'}
I1128 21:42:49.123920 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.986, current avg val score is 0.984, val scores are: activity_selector: 0.984
I1128 21:42:50.990542 133056749540864 run.py:734] Algo activity_selector step 7000 current loss 0.616969, current_train_items 386144.
I1128 21:42:51.186077 133056749540864 run.py:769] (val) algo activity_selector step 7000: {'selected': 0.9919028340080972, 'score': 0.9919028340080972, 'examples_seen': 386144, 'step': 7000, 'algorithm': 'activity_selector'}
I1128 21:42:51.186280 133056749540864 run.py:790] Checkpointing best model, best avg val score was 0.986, current avg val score is 0.992, val scores are: activity_selector: 0.992
I1128 21:42:53.272078 133056749540864 run.py:734] Algo activity_selector step 7050 current loss 0.722257, current_train_items 388896.
I1128 21:42:53.363816 133056749540864 run.py:769] (val) algo activity_selector step 7050: {'selected': 0.9563636363636364, 'score': 0.9563636363636364, 'examples_seen': 388896, 'step': 7050, 'algorithm': 'activity_selector'}
I1128 21:42:53.364109 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1128 21:42:55.292207 133056749540864 run.py:734] Algo activity_selector step 7100 current loss 0.560959, current_train_items 391648.
I1128 21:42:55.408619 133056749540864 run.py:769] (val) algo activity_selector step 7100: {'selected': 0.9813432835820894, 'score': 0.9813432835820894, 'examples_seen': 391648, 'step': 7100, 'algorithm': 'activity_selector'}
I1128 21:42:55.408838 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.981, val scores are: activity_selector: 0.981
I1128 21:42:57.266139 133056749540864 run.py:734] Algo activity_selector step 7150 current loss 0.813476, current_train_items 394400.
I1128 21:42:57.447264 133056749540864 run.py:769] (val) algo activity_selector step 7150: {'selected': 0.9539594843462247, 'score': 0.9539594843462247, 'examples_seen': 394400, 'step': 7150, 'algorithm': 'activity_selector'}
I1128 21:42:57.447526 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.954, val scores are: activity_selector: 0.954
I1128 21:42:59.517359 133056749540864 run.py:734] Algo activity_selector step 7200 current loss 0.574535, current_train_items 397152.
I1128 21:42:59.586565 133056749540864 run.py:769] (val) algo activity_selector step 7200: {'selected': 0.9698189134808854, 'score': 0.9698189134808854, 'examples_seen': 397152, 'step': 7200, 'algorithm': 'activity_selector'}
I1128 21:42:59.586768 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.970, val scores are: activity_selector: 0.970
I1128 21:43:01.531774 133056749540864 run.py:734] Algo activity_selector step 7250 current loss 0.518209, current_train_items 399904.
I1128 21:43:01.665793 133056749540864 run.py:769] (val) algo activity_selector step 7250: {'selected': 0.9721115537848605, 'score': 0.9721115537848605, 'examples_seen': 399904, 'step': 7250, 'algorithm': 'activity_selector'}
I1128 21:43:01.665969 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.972, val scores are: activity_selector: 0.972
I1128 21:43:03.334320 133056749540864 run.py:734] Algo activity_selector step 7300 current loss 0.629848, current_train_items 402688.
I1128 21:43:03.551399 133056749540864 run.py:769] (val) algo activity_selector step 7300: {'selected': 0.9492187499999999, 'score': 0.9492187499999999, 'examples_seen': 402688, 'step': 7300, 'algorithm': 'activity_selector'}
I1128 21:43:03.551621 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.949, val scores are: activity_selector: 0.949
I1128 21:43:05.290164 133056749540864 run.py:734] Algo activity_selector step 7350 current loss 0.641321, current_train_items 405440.
I1128 21:43:05.467530 133056749540864 run.py:769] (val) algo activity_selector step 7350: {'selected': 0.9461077844311377, 'score': 0.9461077844311377, 'examples_seen': 405440, 'step': 7350, 'algorithm': 'activity_selector'}
I1128 21:43:05.467679 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.946, val scores are: activity_selector: 0.946
I1128 21:43:07.160828 133056749540864 run.py:734] Algo activity_selector step 7400 current loss 0.427062, current_train_items 408160.
I1128 21:43:07.372235 133056749540864 run.py:769] (val) algo activity_selector step 7400: {'selected': 0.9780439121756487, 'score': 0.9780439121756487, 'examples_seen': 408160, 'step': 7400, 'algorithm': 'activity_selector'}
I1128 21:43:07.372495 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.978, val scores are: activity_selector: 0.978
I1128 21:43:09.095420 133056749540864 run.py:734] Algo activity_selector step 7450 current loss 0.372454, current_train_items 410976.
I1128 21:43:09.275049 133056749540864 run.py:769] (val) algo activity_selector step 7450: {'selected': 0.944649446494465, 'score': 0.944649446494465, 'examples_seen': 410976, 'step': 7450, 'algorithm': 'activity_selector'}
I1128 21:43:09.275289 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.945, val scores are: activity_selector: 0.945
I1128 21:43:11.008518 133056749540864 run.py:734] Algo activity_selector step 7500 current loss 0.473269, current_train_items 413696.
I1128 21:43:11.188272 133056749540864 run.py:769] (val) algo activity_selector step 7500: {'selected': 0.9847328244274809, 'score': 0.9847328244274809, 'examples_seen': 413696, 'step': 7500, 'algorithm': 'activity_selector'}
I1128 21:43:11.188514 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.985, val scores are: activity_selector: 0.985
I1128 21:43:12.922790 133056749540864 run.py:734] Algo activity_selector step 7550 current loss 0.501255, current_train_items 416448.
I1128 21:43:13.166332 133056749540864 run.py:769] (val) algo activity_selector step 7550: {'selected': 0.98046875, 'score': 0.98046875, 'examples_seen': 416448, 'step': 7550, 'algorithm': 'activity_selector'}
I1128 21:43:13.166558 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.980, val scores are: activity_selector: 0.980
I1128 21:43:14.989608 133056749540864 run.py:734] Algo activity_selector step 7600 current loss 0.671997, current_train_items 419232.
I1128 21:43:15.167869 133056749540864 run.py:769] (val) algo activity_selector step 7600: {'selected': 0.9434697855750487, 'score': 0.9434697855750487, 'examples_seen': 419232, 'step': 7600, 'algorithm': 'activity_selector'}
I1128 21:43:15.168111 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1128 21:43:16.952080 133056749540864 run.py:734] Algo activity_selector step 7650 current loss 0.405267, current_train_items 421952.
I1128 21:43:17.186258 133056749540864 run.py:769] (val) algo activity_selector step 7650: {'selected': 0.9543726235741444, 'score': 0.9543726235741444, 'examples_seen': 421952, 'step': 7650, 'algorithm': 'activity_selector'}
I1128 21:43:17.186485 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.954, val scores are: activity_selector: 0.954
I1128 21:43:19.026715 133056749540864 run.py:734] Algo activity_selector step 7700 current loss 0.588772, current_train_items 424736.
I1128 21:43:19.203985 133056749540864 run.py:769] (val) algo activity_selector step 7700: {'selected': 0.9565217391304348, 'score': 0.9565217391304348, 'examples_seen': 424736, 'step': 7700, 'algorithm': 'activity_selector'}
I1128 21:43:19.204183 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.957, val scores are: activity_selector: 0.957
I1128 21:43:20.989060 133056749540864 run.py:734] Algo activity_selector step 7750 current loss 0.511621, current_train_items 427488.
I1128 21:43:21.221724 133056749540864 run.py:769] (val) algo activity_selector step 7750: {'selected': 0.9712092130518234, 'score': 0.9712092130518234, 'examples_seen': 427488, 'step': 7750, 'algorithm': 'activity_selector'}
I1128 21:43:21.221873 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.971, val scores are: activity_selector: 0.971
I1128 21:43:22.926442 133056749540864 run.py:734] Algo activity_selector step 7800 current loss 0.487205, current_train_items 430272.
I1128 21:43:23.114218 133056749540864 run.py:769] (val) algo activity_selector step 7800: {'selected': 0.9644268774703557, 'score': 0.9644268774703557, 'examples_seen': 430272, 'step': 7800, 'algorithm': 'activity_selector'}
I1128 21:43:23.114433 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.964, val scores are: activity_selector: 0.964
I1128 21:43:24.804112 133056749540864 run.py:734] Algo activity_selector step 7850 current loss 0.584553, current_train_items 432992.
I1128 21:43:24.995739 133056749540864 run.py:769] (val) algo activity_selector step 7850: {'selected': 0.9760956175298805, 'score': 0.9760956175298805, 'examples_seen': 432992, 'step': 7850, 'algorithm': 'activity_selector'}
I1128 21:43:24.995888 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.976, val scores are: activity_selector: 0.976
I1128 21:43:26.687437 133056749540864 run.py:734] Algo activity_selector step 7900 current loss 0.702589, current_train_items 435776.
I1128 21:43:26.916110 133056749540864 run.py:769] (val) algo activity_selector step 7900: {'selected': 0.9758812615955473, 'score': 0.9758812615955473, 'examples_seen': 435776, 'step': 7900, 'algorithm': 'activity_selector'}
I1128 21:43:26.916350 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.976, val scores are: activity_selector: 0.976
I1128 21:43:28.766970 133056749540864 run.py:734] Algo activity_selector step 7950 current loss 0.600406, current_train_items 438528.
I1128 21:43:28.953420 133056749540864 run.py:769] (val) algo activity_selector step 7950: {'selected': 0.9853479853479854, 'score': 0.9853479853479854, 'examples_seen': 438528, 'step': 7950, 'algorithm': 'activity_selector'}
I1128 21:43:28.953655 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.985, val scores are: activity_selector: 0.985
I1128 21:43:30.836555 133056749540864 run.py:734] Algo activity_selector step 8000 current loss 0.499835, current_train_items 441248.
I1128 21:43:30.985684 133056749540864 run.py:769] (val) algo activity_selector step 8000: {'selected': 0.9639468690702087, 'score': 0.9639468690702087, 'examples_seen': 441248, 'step': 8000, 'algorithm': 'activity_selector'}
I1128 21:43:30.985980 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.992, current avg val score is 0.964, val scores are: activity_selector: 0.964
I1128 21:43:32.820376 133056749540864 run.py:734] Algo activity_selector step 8050 current loss 0.499520, current_train_items 444064.
I1128 21:43:32.999121 133056749540864 run.py:769] (val) algo activity_selector step 8050: {'selected': 0.9477756286266924, 'score': 0.9477756286266924, 'examples_seen': 444064, 'step': 8050, 'algorithm': 'activity_selector'}
I1128 21:43:32.999352 133056749540864 run.py:790] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1128 21:43:34.776664 133056749540864 run.py:734] Algo activity_selector step 8100 current loss 0.489421, current_train_items 446784.
I1128 21:43:34.956270 133056749540864 run.py:769] (val) algo activity_selector step 8100: {'selected': 0.9486652977412731, 'score': 0.9486652977412731, 'examples_seen': 446784, 'step': 8100, 'algorithm': 'activity_selector'}
I1128 21:43:34.956491 133056749540864 run.py:790] Checkpointing best model, best avg val score was 0.948, current avg val score is 0.949, val scores are: activity_selector: 0.949
I1128 21:43:36.826378 133056749540864 run.py:734] Algo activity_selector step 8150 current loss 0.403249, current_train_items 449568.
I1128 21:43:37.002614 133056749540864 run.py:769] (val) algo activity_selector step 8150: {'selected': 0.9783889980353634, 'score': 0.9783889980353634, 'examples_seen': 449568, 'step': 8150, 'algorithm': 'activity_selector'}
I1128 21:43:37.002842 133056749540864 run.py:790] Checkpointing best model, best avg val score was 0.949, current avg val score is 0.978, val scores are: activity_selector: 0.978
I1128 21:43:38.824975 133056749540864 run.py:734] Algo activity_selector step 8200 current loss 0.389889, current_train_items 452320.
I1128 21:43:39.002002 133056749540864 run.py:769] (val) algo activity_selector step 8200: {'selected': 0.9662921348314607, 'score': 0.9662921348314607, 'examples_seen': 452320, 'step': 8200, 'algorithm': 'activity_selector'}
I1128 21:43:39.002240 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.966, val scores are: activity_selector: 0.966
I1128 21:43:40.733760 133056749540864 run.py:734] Algo activity_selector step 8250 current loss 0.510300, current_train_items 455040.
I1128 21:43:40.915590 133056749540864 run.py:769] (val) algo activity_selector step 8250: {'selected': 0.9570312500000001, 'score': 0.9570312500000001, 'examples_seen': 455040, 'step': 8250, 'algorithm': 'activity_selector'}
I1128 21:43:40.915814 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.957, val scores are: activity_selector: 0.957
I1128 21:43:42.591193 133056749540864 run.py:734] Algo activity_selector step 8300 current loss 0.465500, current_train_items 457824.
I1128 21:43:42.800985 133056749540864 run.py:769] (val) algo activity_selector step 8300: {'selected': 0.9481765834932822, 'score': 0.9481765834932822, 'examples_seen': 457824, 'step': 8300, 'algorithm': 'activity_selector'}
I1128 21:43:42.801231 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1128 21:43:44.550102 133056749540864 run.py:734] Algo activity_selector step 8350 current loss 0.568893, current_train_items 460576.
I1128 21:43:44.703476 133056749540864 run.py:769] (val) algo activity_selector step 8350: {'selected': 0.9775280898876405, 'score': 0.9775280898876405, 'examples_seen': 460576, 'step': 8350, 'algorithm': 'activity_selector'}
I1128 21:43:44.703710 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.978, val scores are: activity_selector: 0.978
I1128 21:43:46.460353 133056749540864 run.py:734] Algo activity_selector step 8400 current loss 0.473828, current_train_items 463360.
I1128 21:43:46.611306 133056749540864 run.py:769] (val) algo activity_selector step 8400: {'selected': 0.945736434108527, 'score': 0.945736434108527, 'examples_seen': 463360, 'step': 8400, 'algorithm': 'activity_selector'}
I1128 21:43:46.611530 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.946, val scores are: activity_selector: 0.946
I1128 21:43:48.321238 133056749540864 run.py:734] Algo activity_selector step 8450 current loss 0.702698, current_train_items 466080.
I1128 21:43:48.500333 133056749540864 run.py:769] (val) algo activity_selector step 8450: {'selected': 0.9330855018587361, 'score': 0.9330855018587361, 'examples_seen': 466080, 'step': 8450, 'algorithm': 'activity_selector'}
I1128 21:43:48.500561 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.978, current avg val score is 0.933, val scores are: activity_selector: 0.933
I1128 21:43:50.222495 133056749540864 run.py:734] Algo activity_selector step 8500 current loss 0.415327, current_train_items 468864.
I1128 21:43:50.400743 133056749540864 run.py:769] (val) algo activity_selector step 8500: {'selected': 0.9866156787762906, 'score': 0.9866156787762906, 'examples_seen': 468864, 'step': 8500, 'algorithm': 'activity_selector'}
I1128 21:43:50.400962 133056749540864 run.py:790] Checkpointing best model, best avg val score was 0.978, current avg val score is 0.987, val scores are: activity_selector: 0.987
I1128 21:43:52.189197 133056749540864 run.py:734] Algo activity_selector step 8550 current loss 0.592125, current_train_items 471616.
I1128 21:43:52.367687 133056749540864 run.py:769] (val) algo activity_selector step 8550: {'selected': 0.9534883720930233, 'score': 0.9534883720930233, 'examples_seen': 471616, 'step': 8550, 'algorithm': 'activity_selector'}
I1128 21:43:52.367861 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.953, val scores are: activity_selector: 0.953
I1128 21:43:54.089040 133056749540864 run.py:734] Algo activity_selector step 8600 current loss 0.432719, current_train_items 474336.
I1128 21:43:54.269642 133056749540864 run.py:769] (val) algo activity_selector step 8600: {'selected': 0.962671905697446, 'score': 0.962671905697446, 'examples_seen': 474336, 'step': 8600, 'algorithm': 'activity_selector'}
I1128 21:43:54.269864 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.963, val scores are: activity_selector: 0.963
I1128 21:43:55.991719 133056749540864 run.py:734] Algo activity_selector step 8650 current loss 0.461950, current_train_items 477152.
I1128 21:43:56.171307 133056749540864 run.py:769] (val) algo activity_selector step 8650: {'selected': 0.9300567107750471, 'score': 0.9300567107750471, 'examples_seen': 477152, 'step': 8650, 'algorithm': 'activity_selector'}
I1128 21:43:56.171550 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.930, val scores are: activity_selector: 0.930
I1128 21:43:57.903776 133056749540864 run.py:734] Algo activity_selector step 8700 current loss 0.414392, current_train_items 479872.
I1128 21:43:58.083015 133056749540864 run.py:769] (val) algo activity_selector step 8700: {'selected': 0.9576427255985267, 'score': 0.9576427255985267, 'examples_seen': 479872, 'step': 8700, 'algorithm': 'activity_selector'}
I1128 21:43:58.083172 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.958, val scores are: activity_selector: 0.958
I1128 21:43:59.785494 133056749540864 run.py:734] Algo activity_selector step 8750 current loss 0.527143, current_train_items 482656.
I1128 21:43:59.963724 133056749540864 run.py:769] (val) algo activity_selector step 8750: {'selected': 0.9724770642201835, 'score': 0.9724770642201835, 'examples_seen': 482656, 'step': 8750, 'algorithm': 'activity_selector'}
I1128 21:43:59.963879 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.972, val scores are: activity_selector: 0.972
I1128 21:44:01.666673 133056749540864 run.py:734] Algo activity_selector step 8800 current loss 0.578913, current_train_items 485408.
I1128 21:44:01.844538 133056749540864 run.py:769] (val) algo activity_selector step 8800: {'selected': 0.9687500000000001, 'score': 0.9687500000000001, 'examples_seen': 485408, 'step': 8800, 'algorithm': 'activity_selector'}
I1128 21:44:01.844691 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.969, val scores are: activity_selector: 0.969
I1128 21:44:03.585566 133056749540864 run.py:734] Algo activity_selector step 8850 current loss 0.666622, current_train_items 488160.
I1128 21:44:03.737232 133056749540864 run.py:769] (val) algo activity_selector step 8850: {'selected': 0.9429657794676807, 'score': 0.9429657794676807, 'examples_seen': 488160, 'step': 8850, 'algorithm': 'activity_selector'}
I1128 21:44:03.737458 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.943, val scores are: activity_selector: 0.943
I1128 21:44:05.459357 133056749540864 run.py:734] Algo activity_selector step 8900 current loss 0.445858, current_train_items 490912.
I1128 21:44:05.639507 133056749540864 run.py:769] (val) algo activity_selector step 8900: {'selected': 0.976, 'score': 0.976, 'examples_seen': 490912, 'step': 8900, 'algorithm': 'activity_selector'}
I1128 21:44:05.639730 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.976, val scores are: activity_selector: 0.976
I1128 21:44:07.340643 133056749540864 run.py:734] Algo activity_selector step 8950 current loss 0.560526, current_train_items 493664.
I1128 21:44:07.541724 133056749540864 run.py:769] (val) algo activity_selector step 8950: {'selected': 0.9416342412451363, 'score': 0.9416342412451363, 'examples_seen': 493664, 'step': 8950, 'algorithm': 'activity_selector'}
I1128 21:44:07.541947 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.942, val scores are: activity_selector: 0.942
I1128 21:44:09.274268 133056749540864 run.py:734] Algo activity_selector step 9000 current loss 0.491525, current_train_items 496448.
I1128 21:44:09.453673 133056749540864 run.py:769] (val) algo activity_selector step 9000: {'selected': 0.9655172413793104, 'score': 0.9655172413793104, 'examples_seen': 496448, 'step': 9000, 'algorithm': 'activity_selector'}
I1128 21:44:09.453898 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.966, val scores are: activity_selector: 0.966
I1128 21:44:11.154747 133056749540864 run.py:734] Algo activity_selector step 9050 current loss 0.597412, current_train_items 499168.
I1128 21:44:11.356079 133056749540864 run.py:769] (val) algo activity_selector step 9050: {'selected': 0.9748549323017408, 'score': 0.9748549323017408, 'examples_seen': 499168, 'step': 9050, 'algorithm': 'activity_selector'}
I1128 21:44:11.356320 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.975, val scores are: activity_selector: 0.975
I1128 21:44:13.078173 133056749540864 run.py:734] Algo activity_selector step 9100 current loss 0.435774, current_train_items 501952.
I1128 21:44:13.258285 133056749540864 run.py:769] (val) algo activity_selector step 9100: {'selected': 0.9561904761904763, 'score': 0.9561904761904763, 'examples_seen': 501952, 'step': 9100, 'algorithm': 'activity_selector'}
I1128 21:44:13.258508 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1128 21:44:14.980364 133056749540864 run.py:734] Algo activity_selector step 9150 current loss 0.483872, current_train_items 504704.
I1128 21:44:15.169048 133056749540864 run.py:769] (val) algo activity_selector step 9150: {'selected': 0.9563567362428843, 'score': 0.9563567362428843, 'examples_seen': 504704, 'step': 9150, 'algorithm': 'activity_selector'}
I1128 21:44:15.169285 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.956, val scores are: activity_selector: 0.956
I1128 21:44:16.919539 133056749540864 run.py:734] Algo activity_selector step 9200 current loss 0.559430, current_train_items 507456.
I1128 21:44:17.072205 133056749540864 run.py:769] (val) algo activity_selector step 9200: {'selected': 0.969811320754717, 'score': 0.969811320754717, 'examples_seen': 507456, 'step': 9200, 'algorithm': 'activity_selector'}
I1128 21:44:17.072450 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.970, val scores are: activity_selector: 0.970
I1128 21:44:18.794927 133056749540864 run.py:734] Algo activity_selector step 9250 current loss 0.391455, current_train_items 510240.
I1128 21:44:18.975116 133056749540864 run.py:769] (val) algo activity_selector step 9250: {'selected': 0.923076923076923, 'score': 0.923076923076923, 'examples_seen': 510240, 'step': 9250, 'algorithm': 'activity_selector'}
I1128 21:44:18.975350 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.923, val scores are: activity_selector: 0.923
I1128 21:44:20.708441 133056749540864 run.py:734] Algo activity_selector step 9300 current loss 0.557208, current_train_items 512960.
I1128 21:44:20.886764 133056749540864 run.py:769] (val) algo activity_selector step 9300: {'selected': 0.9330922242314649, 'score': 0.9330922242314649, 'examples_seen': 512960, 'step': 9300, 'algorithm': 'activity_selector'}
I1128 21:44:20.886990 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.933, val scores are: activity_selector: 0.933
I1128 21:44:22.610625 133056749540864 run.py:734] Algo activity_selector step 9350 current loss 0.621487, current_train_items 515712.
I1128 21:44:22.790934 133056749540864 run.py:769] (val) algo activity_selector step 9350: {'selected': 0.9481481481481482, 'score': 0.9481481481481482, 'examples_seen': 515712, 'step': 9350, 'algorithm': 'activity_selector'}
I1128 21:44:22.791225 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.948, val scores are: activity_selector: 0.948
I1128 21:44:24.629620 133056749540864 run.py:734] Algo activity_selector step 9400 current loss 0.435638, current_train_items 518496.
I1128 21:44:24.724913 133056749540864 run.py:769] (val) algo activity_selector step 9400: {'selected': 0.9151291512915128, 'score': 0.9151291512915128, 'examples_seen': 518496, 'step': 9400, 'algorithm': 'activity_selector'}
I1128 21:44:24.725100 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.915, val scores are: activity_selector: 0.915
I1128 21:44:26.445785 133056749540864 run.py:734] Algo activity_selector step 9450 current loss 0.448476, current_train_items 521248.
I1128 21:44:26.626865 133056749540864 run.py:769] (val) algo activity_selector step 9450: {'selected': 0.9497907949790796, 'score': 0.9497907949790796, 'examples_seen': 521248, 'step': 9450, 'algorithm': 'activity_selector'}
I1128 21:44:26.627102 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.950, val scores are: activity_selector: 0.950
I1128 21:44:28.347658 133056749540864 run.py:734] Algo activity_selector step 9500 current loss 0.474195, current_train_items 524000.
I1128 21:44:28.526476 133056749540864 run.py:769] (val) algo activity_selector step 9500: {'selected': 0.9674952198852772, 'score': 0.9674952198852772, 'examples_seen': 524000, 'step': 9500, 'algorithm': 'activity_selector'}
I1128 21:44:28.526700 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.967, val scores are: activity_selector: 0.967
I1128 21:44:30.247835 133056749540864 run.py:734] Algo activity_selector step 9550 current loss 0.700213, current_train_items 526784.
I1128 21:44:30.427428 133056749540864 run.py:769] (val) algo activity_selector step 9550: {'selected': 0.9554655870445344, 'score': 0.9554655870445344, 'examples_seen': 526784, 'step': 9550, 'algorithm': 'activity_selector'}
I1128 21:44:30.427652 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.955, val scores are: activity_selector: 0.955
I1128 21:44:32.160998 133056749540864 run.py:734] Algo activity_selector step 9600 current loss 0.428154, current_train_items 529536.
I1128 21:44:32.343201 133056749540864 run.py:769] (val) algo activity_selector step 9600: {'selected': 0.9777777777777779, 'score': 0.9777777777777779, 'examples_seen': 529536, 'step': 9600, 'algorithm': 'activity_selector'}
I1128 21:44:32.343423 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.978, val scores are: activity_selector: 0.978
I1128 21:44:34.043658 133056749540864 run.py:734] Algo activity_selector step 9650 current loss 0.566736, current_train_items 532256.
I1128 21:44:34.245729 133056749540864 run.py:769] (val) algo activity_selector step 9650: {'selected': 0.9782178217821783, 'score': 0.9782178217821783, 'examples_seen': 532256, 'step': 9650, 'algorithm': 'activity_selector'}
I1128 21:44:34.245954 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.978, val scores are: activity_selector: 0.978
I1128 21:44:35.973444 133056749540864 run.py:734] Algo activity_selector step 9700 current loss 0.534105, current_train_items 535040.
I1128 21:44:36.148346 133056749540864 run.py:769] (val) algo activity_selector step 9700: {'selected': 0.931159420289855, 'score': 0.931159420289855, 'examples_seen': 535040, 'step': 9700, 'algorithm': 'activity_selector'}
I1128 21:44:36.148591 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.931, val scores are: activity_selector: 0.931
I1128 21:44:37.881331 133056749540864 run.py:734] Algo activity_selector step 9750 current loss 0.607696, current_train_items 537792.
I1128 21:44:38.060903 133056749540864 run.py:769] (val) algo activity_selector step 9750: {'selected': 0.972, 'score': 0.972, 'examples_seen': 537792, 'step': 9750, 'algorithm': 'activity_selector'}
I1128 21:44:38.061163 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.972, val scores are: activity_selector: 0.972
I1128 21:44:39.783430 133056749540864 run.py:734] Algo activity_selector step 9800 current loss 0.955642, current_train_items 540544.
I1128 21:44:39.962969 133056749540864 run.py:769] (val) algo activity_selector step 9800: {'selected': 0.9053497942386831, 'score': 0.9053497942386831, 'examples_seen': 540544, 'step': 9800, 'algorithm': 'activity_selector'}
I1128 21:44:39.963228 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.905, val scores are: activity_selector: 0.905
I1128 21:44:41.686030 133056749540864 run.py:734] Algo activity_selector step 9850 current loss 0.507761, current_train_items 543328.
I1128 21:44:41.864973 133056749540864 run.py:769] (val) algo activity_selector step 9850: {'selected': 0.9168141592920354, 'score': 0.9168141592920354, 'examples_seen': 543328, 'step': 9850, 'algorithm': 'activity_selector'}
I1128 21:44:41.865235 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.917, val scores are: activity_selector: 0.917
I1128 21:44:43.625102 133056749540864 run.py:734] Algo activity_selector step 9900 current loss 0.468570, current_train_items 546080.
I1128 21:44:43.777398 133056749540864 run.py:769] (val) algo activity_selector step 9900: {'selected': 0.9838056680161944, 'score': 0.9838056680161944, 'examples_seen': 546080, 'step': 9900, 'algorithm': 'activity_selector'}
I1128 21:44:43.777632 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.984, val scores are: activity_selector: 0.984
I1128 21:44:45.499055 133056749540864 run.py:734] Algo activity_selector step 9950 current loss 0.481124, current_train_items 548800.
I1128 21:44:45.677495 133056749540864 run.py:769] (val) algo activity_selector step 9950: {'selected': 0.9457943925233644, 'score': 0.9457943925233644, 'examples_seen': 548800, 'step': 9950, 'algorithm': 'activity_selector'}
I1128 21:44:45.677731 133056749540864 run.py:793] Not saving new best model, best avg val score was 0.987, current avg val score is 0.946, val scores are: activity_selector: 0.946
I1128 21:44:47.368932 133056749540864 run.py:799] Restoring best model from checkpoint...
I1128 21:44:58.460345 133056749540864 run.py:814] (test) algo activity_selector : {'selected': 0.9169675090252707, 'score': 0.9169675090252707, 'examples_seen': 551520, 'step': 10000, 'algorithm': 'activity_selector'}
I1128 21:44:58.460521 133056749540864 run.py:816] Done!
